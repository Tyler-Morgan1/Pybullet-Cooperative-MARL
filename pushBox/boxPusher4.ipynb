{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pybullet build time: Nov 28 2023 23:48:36\n"
     ]
    }
   ],
   "source": [
    "import gymnasium\n",
    "import push_box\n",
    "import pybullet as p\n",
    "import pybullet_data\n",
    "import time\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.callbacks import EvalCallback, StopTrainingOnRewardThreshold\n",
    "import os\n",
    "from typing import Any, Dict\n",
    "import torch as th"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numActiveThreads = 0\n",
      "stopping threads\n",
      "Thread with taskId 0 exiting\n",
      "Thread TERMINATED\n",
      "destroy semaphore\n",
      "semaphore destroyed\n",
      "destroy main semaphore\n",
      "main semaphore destroyed\n",
      "finished\n",
      "numActiveThreads = 0\n",
      "btShutDownExampleBrowser stopping threads\n",
      "destroy semaphore\n",
      "semaphore destroyed\n",
      "Thread with taskId 0 exiting\n",
      "Thread TERMINATED\n",
      "destroy main semaphore\n",
      "main semaphore destroyed\n"
     ]
    }
   ],
   "source": [
    "p.disconnect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_path = os.path.join('Training', 'Logs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gymnasium.make('pushBox-v0')\n",
    "env = DummyVecEnv([lambda: env])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a callback to training stage for early stopping\n",
    "save_path = os.path.join('Training', 'SavedModels', 'PPO_63_best')\n",
    "stop_callback = StopTrainingOnRewardThreshold(reward_threshold = 100, verbose = 1)\n",
    "eval_callback = EvalCallback(env, \n",
    "                            callback_on_new_best = stop_callback,\n",
    "                            eval_freq = 10000, \n",
    "                            best_model_save_path = save_path, \n",
    "                            verbose = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "model = PPO('MlpPolicy', env, verbose=1, tensorboard_log=log_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to Training/Logs/PPO_63\n",
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 551  |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 3    |\n",
      "|    total_timesteps | 2048 |\n",
      "-----------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 424         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 9           |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014632185 |\n",
      "|    clip_fraction        | 0.187       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.6        |\n",
      "|    explained_variance   | 0.881       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0274     |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0127     |\n",
      "|    value_loss           | 0.000236    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 400         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 15          |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016647076 |\n",
      "|    clip_fraction        | 0.262       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.55       |\n",
      "|    explained_variance   | 0.522       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0144     |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0238     |\n",
      "|    value_loss           | 3.23e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 392         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 20          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017461367 |\n",
      "|    clip_fraction        | 0.291       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.55       |\n",
      "|    explained_variance   | 0.877       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0316     |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0251     |\n",
      "|    value_loss           | 0.00013     |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/danielmasamba/anaconda3/envs/dan/lib/python3.11/site-packages/stable_baselines3/common/evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eval num_timesteps=10000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 10000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+04       |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 10000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018308181 |\n",
      "|    clip_fraction        | 0.221       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.51       |\n",
      "|    explained_variance   | 0.865       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.062      |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0191     |\n",
      "|    value_loss           | 0.000152    |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 146   |\n",
      "|    iterations      | 5     |\n",
      "|    time_elapsed    | 69    |\n",
      "|    total_timesteps | 10240 |\n",
      "------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 162         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 75          |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017640457 |\n",
      "|    clip_fraction        | 0.276       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.47       |\n",
      "|    explained_variance   | 0.874       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0368     |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0146     |\n",
      "|    value_loss           | 0.000961    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 176         |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 81          |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013092911 |\n",
      "|    clip_fraction        | 0.189       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.58       |\n",
      "|    explained_variance   | 0.505       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0385     |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0133     |\n",
      "|    value_loss           | 0.000143    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 188         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 86          |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010719194 |\n",
      "|    clip_fraction        | 0.0911      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.56       |\n",
      "|    explained_variance   | 0.872       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0154      |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.00615    |\n",
      "|    value_loss           | 0.000282    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 199         |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 92          |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016021132 |\n",
      "|    clip_fraction        | 0.223       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.52       |\n",
      "|    explained_variance   | 0.95        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0379     |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0146     |\n",
      "|    value_loss           | 0.000238    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=20000, episode_reward=0.03 +/- 0.06\n",
      "Episode length: 10000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+04       |\n",
      "|    mean_reward          | 0.029       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 20000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017206116 |\n",
      "|    clip_fraction        | 0.322       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.52       |\n",
      "|    explained_variance   | 0.912       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0206     |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.0208     |\n",
      "|    value_loss           | 0.000579    |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 144   |\n",
      "|    iterations      | 10    |\n",
      "|    time_elapsed    | 142   |\n",
      "|    total_timesteps | 20480 |\n",
      "------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 152         |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 147         |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015830426 |\n",
      "|    clip_fraction        | 0.0821      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.51       |\n",
      "|    explained_variance   | 0.924       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00546     |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.00261    |\n",
      "|    value_loss           | 0.00218     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 160         |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 153         |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015448663 |\n",
      "|    clip_fraction        | 0.146       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.38       |\n",
      "|    explained_variance   | -0.072      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0331     |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.00955    |\n",
      "|    value_loss           | 4.56e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 167         |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 158         |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014734309 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.4        |\n",
      "|    explained_variance   | 0.955       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0182     |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.0149     |\n",
      "|    value_loss           | 1.76e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 174         |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 164         |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004396322 |\n",
      "|    clip_fraction        | 0.0597      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.37       |\n",
      "|    explained_variance   | -0.384      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00367     |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.00239    |\n",
      "|    value_loss           | 1.74e-05    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=30000, episode_reward=0.01 +/- 0.02\n",
      "Episode length: 10000.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1e+04        |\n",
      "|    mean_reward          | 0.00868      |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 30000        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0094564725 |\n",
      "|    clip_fraction        | 0.0631       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.36        |\n",
      "|    explained_variance   | -0.0788      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.00097      |\n",
      "|    n_updates            | 140          |\n",
      "|    policy_gradient_loss | -0.002       |\n",
      "|    value_loss           | 4.05e-05     |\n",
      "------------------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 144   |\n",
      "|    iterations      | 15    |\n",
      "|    time_elapsed    | 212   |\n",
      "|    total_timesteps | 30720 |\n",
      "------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 150        |\n",
      "|    iterations           | 16         |\n",
      "|    time_elapsed         | 218        |\n",
      "|    total_timesteps      | 32768      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01852486 |\n",
      "|    clip_fraction        | 0.158      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.47      |\n",
      "|    explained_variance   | 0.895      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0564    |\n",
      "|    n_updates            | 150        |\n",
      "|    policy_gradient_loss | -0.0135    |\n",
      "|    value_loss           | 0.000105   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 155        |\n",
      "|    iterations           | 17         |\n",
      "|    time_elapsed         | 224        |\n",
      "|    total_timesteps      | 34816      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00809239 |\n",
      "|    clip_fraction        | 0.0471     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.42      |\n",
      "|    explained_variance   | 0.571      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0214     |\n",
      "|    n_updates            | 160        |\n",
      "|    policy_gradient_loss | -0.00376   |\n",
      "|    value_loss           | 2.66e-05   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 160         |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 229         |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010004586 |\n",
      "|    clip_fraction        | 0.0374      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.36       |\n",
      "|    explained_variance   | -0.763      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0484     |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.000837   |\n",
      "|    value_loss           | 8.82e-06    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 166         |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 234         |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007708697 |\n",
      "|    clip_fraction        | 0.0983      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.26       |\n",
      "|    explained_variance   | -0.27       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0107     |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.00428    |\n",
      "|    value_loss           | 8.69e-06    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=40000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 10000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+04       |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 40000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014559619 |\n",
      "|    clip_fraction        | 0.08        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.16       |\n",
      "|    explained_variance   | -0.0977     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0366     |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.00261    |\n",
      "|    value_loss           | 7.39e-06    |\n",
      "-----------------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 144   |\n",
      "|    iterations      | 20    |\n",
      "|    time_elapsed    | 283   |\n",
      "|    total_timesteps | 40960 |\n",
      "------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 149         |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 288         |\n",
      "|    total_timesteps      | 43008       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029556563 |\n",
      "|    clip_fraction        | 0.226       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.15       |\n",
      "|    explained_variance   | 0.933       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0402     |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.00893    |\n",
      "|    value_loss           | 0.000126    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 153         |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 293         |\n",
      "|    total_timesteps      | 45056       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015229972 |\n",
      "|    clip_fraction        | 0.241       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.41       |\n",
      "|    explained_variance   | 0.833       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0425     |\n",
      "|    n_updates            | 210         |\n",
      "|    policy_gradient_loss | -0.0139     |\n",
      "|    value_loss           | 2.02e-05    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 157        |\n",
      "|    iterations           | 23         |\n",
      "|    time_elapsed         | 299        |\n",
      "|    total_timesteps      | 47104      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01419875 |\n",
      "|    clip_fraction        | 0.103      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.43      |\n",
      "|    explained_variance   | 0.947      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0131     |\n",
      "|    n_updates            | 220        |\n",
      "|    policy_gradient_loss | -0.00573   |\n",
      "|    value_loss           | 2.15e-05   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 161         |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 305         |\n",
      "|    total_timesteps      | 49152       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018862896 |\n",
      "|    clip_fraction        | 0.208       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.41       |\n",
      "|    explained_variance   | 0.939       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00127    |\n",
      "|    n_updates            | 230         |\n",
      "|    policy_gradient_loss | -0.0111     |\n",
      "|    value_loss           | 4.12e-05    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=50000, episode_reward=0.11 +/- 0.15\n",
      "Episode length: 10000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+04       |\n",
      "|    mean_reward          | 0.111       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 50000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009425776 |\n",
      "|    clip_fraction        | 0.0558      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.42       |\n",
      "|    explained_variance   | -0.178      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0115      |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.00254    |\n",
      "|    value_loss           | 7.6e-05     |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 144   |\n",
      "|    iterations      | 25    |\n",
      "|    time_elapsed    | 353   |\n",
      "|    total_timesteps | 51200 |\n",
      "------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 148         |\n",
      "|    iterations           | 26          |\n",
      "|    time_elapsed         | 358         |\n",
      "|    total_timesteps      | 53248       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033516444 |\n",
      "|    clip_fraction        | 0.219       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.5        |\n",
      "|    explained_variance   | 0.95        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00241     |\n",
      "|    n_updates            | 250         |\n",
      "|    policy_gradient_loss | -0.0108     |\n",
      "|    value_loss           | 0.000166    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 364         |\n",
      "|    total_timesteps      | 55296       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014280094 |\n",
      "|    clip_fraction        | 0.255       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.5        |\n",
      "|    explained_variance   | 0.396       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0497     |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | -0.0222     |\n",
      "|    value_loss           | 6.78e-05    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 154        |\n",
      "|    iterations           | 28         |\n",
      "|    time_elapsed         | 370        |\n",
      "|    total_timesteps      | 57344      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01991177 |\n",
      "|    clip_fraction        | 0.312      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.5       |\n",
      "|    explained_variance   | 0.9        |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0415    |\n",
      "|    n_updates            | 270        |\n",
      "|    policy_gradient_loss | -0.0249    |\n",
      "|    value_loss           | 8.59e-05   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 158         |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 375         |\n",
      "|    total_timesteps      | 59392       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009258509 |\n",
      "|    clip_fraction        | 0.135       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.5        |\n",
      "|    explained_variance   | 0.935       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0191     |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | -0.00767    |\n",
      "|    value_loss           | 4.19e-05    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=60000, episode_reward=-0.06 +/- 0.11\n",
      "Episode length: 10000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+04       |\n",
      "|    mean_reward          | -0.0552     |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 60000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010449842 |\n",
      "|    clip_fraction        | 0.0944      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.45       |\n",
      "|    explained_variance   | 0.74        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.029      |\n",
      "|    n_updates            | 290         |\n",
      "|    policy_gradient_loss | -0.00463    |\n",
      "|    value_loss           | 1.9e-05     |\n",
      "-----------------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 145   |\n",
      "|    iterations      | 30    |\n",
      "|    time_elapsed    | 423   |\n",
      "|    total_timesteps | 61440 |\n",
      "------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 148         |\n",
      "|    iterations           | 31          |\n",
      "|    time_elapsed         | 428         |\n",
      "|    total_timesteps      | 63488       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015033614 |\n",
      "|    clip_fraction        | 0.216       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.43       |\n",
      "|    explained_variance   | 0.924       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0066     |\n",
      "|    n_updates            | 300         |\n",
      "|    policy_gradient_loss | -0.0129     |\n",
      "|    value_loss           | 0.000134    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 150         |\n",
      "|    iterations           | 32          |\n",
      "|    time_elapsed         | 434         |\n",
      "|    total_timesteps      | 65536       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005815723 |\n",
      "|    clip_fraction        | 0.0739      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.28       |\n",
      "|    explained_variance   | 0.594       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00917    |\n",
      "|    n_updates            | 310         |\n",
      "|    policy_gradient_loss | -0.00238    |\n",
      "|    value_loss           | 2.19e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 153         |\n",
      "|    iterations           | 33          |\n",
      "|    time_elapsed         | 440         |\n",
      "|    total_timesteps      | 67584       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008138723 |\n",
      "|    clip_fraction        | 0.125       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.32       |\n",
      "|    explained_variance   | 0.407       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00583    |\n",
      "|    n_updates            | 320         |\n",
      "|    policy_gradient_loss | -0.0052     |\n",
      "|    value_loss           | 1.76e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 156         |\n",
      "|    iterations           | 34          |\n",
      "|    time_elapsed         | 445         |\n",
      "|    total_timesteps      | 69632       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007122116 |\n",
      "|    clip_fraction        | 0.0874      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.32       |\n",
      "|    explained_variance   | 0.376       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.000231    |\n",
      "|    n_updates            | 330         |\n",
      "|    policy_gradient_loss | -0.0028     |\n",
      "|    value_loss           | 1.12e-05    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=70000, episode_reward=-0.07 +/- 0.10\n",
      "Episode length: 10000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+04       |\n",
      "|    mean_reward          | -0.068      |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 70000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008182317 |\n",
      "|    clip_fraction        | 0.0888      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.3        |\n",
      "|    explained_variance   | 0.139       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00901     |\n",
      "|    n_updates            | 340         |\n",
      "|    policy_gradient_loss | -0.00281    |\n",
      "|    value_loss           | 1.21e-05    |\n",
      "-----------------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 145   |\n",
      "|    iterations      | 35    |\n",
      "|    time_elapsed    | 493   |\n",
      "|    total_timesteps | 71680 |\n",
      "------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 147         |\n",
      "|    iterations           | 36          |\n",
      "|    time_elapsed         | 498         |\n",
      "|    total_timesteps      | 73728       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019901473 |\n",
      "|    clip_fraction        | 0.108       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.42       |\n",
      "|    explained_variance   | 0.93        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0294     |\n",
      "|    n_updates            | 350         |\n",
      "|    policy_gradient_loss | -0.0144     |\n",
      "|    value_loss           | 0.000166    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 150          |\n",
      "|    iterations           | 37           |\n",
      "|    time_elapsed         | 504          |\n",
      "|    total_timesteps      | 75776        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064994516 |\n",
      "|    clip_fraction        | 0.0288       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.4         |\n",
      "|    explained_variance   | 0.704        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0119      |\n",
      "|    n_updates            | 360          |\n",
      "|    policy_gradient_loss | -0.000203    |\n",
      "|    value_loss           | 6.24e-05     |\n",
      "------------------------------------------\n",
      "--------------------------------------\n",
      "| time/                   |          |\n",
      "|    fps                  | 152      |\n",
      "|    iterations           | 38       |\n",
      "|    time_elapsed         | 510      |\n",
      "|    total_timesteps      | 77824    |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.017834 |\n",
      "|    clip_fraction        | 0.146    |\n",
      "|    clip_range           | 0.2      |\n",
      "|    entropy_loss         | -1.33    |\n",
      "|    explained_variance   | 0.816    |\n",
      "|    learning_rate        | 0.0003   |\n",
      "|    loss                 | 0.0117   |\n",
      "|    n_updates            | 370      |\n",
      "|    policy_gradient_loss | -0.00908 |\n",
      "|    value_loss           | 3.72e-05 |\n",
      "--------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 154         |\n",
      "|    iterations           | 39          |\n",
      "|    time_elapsed         | 515         |\n",
      "|    total_timesteps      | 79872       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013763286 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.26       |\n",
      "|    explained_variance   | 0.365       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00856    |\n",
      "|    n_updates            | 380         |\n",
      "|    policy_gradient_loss | -0.0088     |\n",
      "|    value_loss           | 1.49e-05    |\n",
      "-----------------------------------------\n",
      "box reached target\n",
      "Eval num_timesteps=80000, episode_reward=1.12 +/- 2.00\n",
      "Episode length: 8031.20 +/- 3937.60\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 8.03e+03    |\n",
      "|    mean_reward          | 1.12        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 80000       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013378944 |\n",
      "|    clip_fraction        | 0.0759      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.32       |\n",
      "|    explained_variance   | -0.419      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0243     |\n",
      "|    n_updates            | 390         |\n",
      "|    policy_gradient_loss | -0.000952   |\n",
      "|    value_loss           | 9e-06       |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 147   |\n",
      "|    iterations      | 40    |\n",
      "|    time_elapsed    | 555   |\n",
      "|    total_timesteps | 81920 |\n",
      "------------------------------\n",
      "box reached target\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 149         |\n",
      "|    iterations           | 41          |\n",
      "|    time_elapsed         | 561         |\n",
      "|    total_timesteps      | 83968       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019340742 |\n",
      "|    clip_fraction        | 0.369       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.43       |\n",
      "|    explained_variance   | 0.819       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0133     |\n",
      "|    n_updates            | 400         |\n",
      "|    policy_gradient_loss | -0.031      |\n",
      "|    value_loss           | 0.00014     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 42          |\n",
      "|    time_elapsed         | 566         |\n",
      "|    total_timesteps      | 86016       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012369097 |\n",
      "|    clip_fraction        | 0.116       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.54       |\n",
      "|    explained_variance   | 0.0745      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0148     |\n",
      "|    n_updates            | 410         |\n",
      "|    policy_gradient_loss | -0.00605    |\n",
      "|    value_loss           | 0.0829      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 153         |\n",
      "|    iterations           | 43          |\n",
      "|    time_elapsed         | 572         |\n",
      "|    total_timesteps      | 88064       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016747342 |\n",
      "|    clip_fraction        | 0.279       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.53       |\n",
      "|    explained_variance   | 0.923       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.034      |\n",
      "|    n_updates            | 420         |\n",
      "|    policy_gradient_loss | -0.0175     |\n",
      "|    value_loss           | 1.72e-05    |\n",
      "-----------------------------------------\n",
      "box reached target\n",
      "Eval num_timesteps=90000, episode_reward=1.04 +/- 2.05\n",
      "Episode length: 8062.40 +/- 3875.20\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 8.06e+03   |\n",
      "|    mean_reward          | 1.04       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 90000      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01353899 |\n",
      "|    clip_fraction        | 0.133      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.59      |\n",
      "|    explained_variance   | 0.945      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0185     |\n",
      "|    n_updates            | 430        |\n",
      "|    policy_gradient_loss | -0.00792   |\n",
      "|    value_loss           | 4.42e-05   |\n",
      "----------------------------------------\n",
      "------------------------------\n",
      "| time/              |       |\n",
      "|    fps             | 147   |\n",
      "|    iterations      | 44    |\n",
      "|    time_elapsed    | 611   |\n",
      "|    total_timesteps | 90112 |\n",
      "------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 149        |\n",
      "|    iterations           | 45         |\n",
      "|    time_elapsed         | 617        |\n",
      "|    total_timesteps      | 92160      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03424371 |\n",
      "|    clip_fraction        | 0.243      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.52      |\n",
      "|    explained_variance   | 0.903      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0344     |\n",
      "|    n_updates            | 440        |\n",
      "|    policy_gradient_loss | -0.00656   |\n",
      "|    value_loss           | 0.00411    |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 46          |\n",
      "|    time_elapsed         | 622         |\n",
      "|    total_timesteps      | 94208       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019815478 |\n",
      "|    clip_fraction        | 0.122       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.42       |\n",
      "|    explained_variance   | 0.905       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0026      |\n",
      "|    n_updates            | 450         |\n",
      "|    policy_gradient_loss | -0.00375    |\n",
      "|    value_loss           | 0.000995    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 153          |\n",
      "|    iterations           | 47           |\n",
      "|    time_elapsed         | 628          |\n",
      "|    total_timesteps      | 96256        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0104438085 |\n",
      "|    clip_fraction        | 0.109        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.49        |\n",
      "|    explained_variance   | -0.178       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.00425      |\n",
      "|    n_updates            | 460          |\n",
      "|    policy_gradient_loss | -0.00584     |\n",
      "|    value_loss           | 0.000102     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 155         |\n",
      "|    iterations           | 48          |\n",
      "|    time_elapsed         | 633         |\n",
      "|    total_timesteps      | 98304       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003999346 |\n",
      "|    clip_fraction        | 0.0206      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.47       |\n",
      "|    explained_variance   | 0.207       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0188     |\n",
      "|    n_updates            | 470         |\n",
      "|    policy_gradient_loss | -0.000112   |\n",
      "|    value_loss           | 6.98e-05    |\n",
      "-----------------------------------------\n",
      "box reached target\n",
      "box reached target\n",
      "box reached target\n",
      "Eval num_timesteps=100000, episode_reward=3.05 +/- 2.49\n",
      "Episode length: 4087.00 +/- 4827.96\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 4.09e+03    |\n",
      "|    mean_reward          | 3.05        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 100000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009423286 |\n",
      "|    clip_fraction        | 0.0945      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.37       |\n",
      "|    explained_variance   | 0.0331      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00526     |\n",
      "|    n_updates            | 480         |\n",
      "|    policy_gradient_loss | -0.00445    |\n",
      "|    value_loss           | 4.51e-05    |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 152    |\n",
      "|    iterations      | 49     |\n",
      "|    time_elapsed    | 656    |\n",
      "|    total_timesteps | 100352 |\n",
      "-------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 154         |\n",
      "|    iterations           | 50          |\n",
      "|    time_elapsed         | 661         |\n",
      "|    total_timesteps      | 102400      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018586736 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.38       |\n",
      "|    explained_variance   | 0.676       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.000634    |\n",
      "|    n_updates            | 490         |\n",
      "|    policy_gradient_loss | -0.00963    |\n",
      "|    value_loss           | 0.000236    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 156         |\n",
      "|    iterations           | 51          |\n",
      "|    time_elapsed         | 667         |\n",
      "|    total_timesteps      | 104448      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008156188 |\n",
      "|    clip_fraction        | 0.0532      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.35       |\n",
      "|    explained_variance   | 0.425       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00129     |\n",
      "|    n_updates            | 500         |\n",
      "|    policy_gradient_loss | -0.00811    |\n",
      "|    value_loss           | 6.25e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 158         |\n",
      "|    iterations           | 52          |\n",
      "|    time_elapsed         | 673         |\n",
      "|    total_timesteps      | 106496      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018546965 |\n",
      "|    clip_fraction        | 0.254       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.34       |\n",
      "|    explained_variance   | 0.487       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0249     |\n",
      "|    n_updates            | 510         |\n",
      "|    policy_gradient_loss | -0.0161     |\n",
      "|    value_loss           | 4.57e-06    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 159         |\n",
      "|    iterations           | 53          |\n",
      "|    time_elapsed         | 678         |\n",
      "|    total_timesteps      | 108544      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013378104 |\n",
      "|    clip_fraction        | 0.207       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.31       |\n",
      "|    explained_variance   | -0.604      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -2.09e-05   |\n",
      "|    n_updates            | 520         |\n",
      "|    policy_gradient_loss | -0.0121     |\n",
      "|    value_loss           | 1.44e-05    |\n",
      "-----------------------------------------\n",
      "box reached target\n",
      "Eval num_timesteps=110000, episode_reward=1.09 +/- 2.00\n",
      "Episode length: 8022.40 +/- 3955.20\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 8.02e+03    |\n",
      "|    mean_reward          | 1.09        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 110000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010630185 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.31       |\n",
      "|    explained_variance   | 0.603       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0425     |\n",
      "|    n_updates            | 530         |\n",
      "|    policy_gradient_loss | -0.00847    |\n",
      "|    value_loss           | 1.04e-06    |\n",
      "-----------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 153    |\n",
      "|    iterations      | 54     |\n",
      "|    time_elapsed    | 718    |\n",
      "|    total_timesteps | 110592 |\n",
      "-------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 155         |\n",
      "|    iterations           | 55          |\n",
      "|    time_elapsed         | 724         |\n",
      "|    total_timesteps      | 112640      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014453268 |\n",
      "|    clip_fraction        | 0.14        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.38       |\n",
      "|    explained_variance   | 0.687       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0242     |\n",
      "|    n_updates            | 540         |\n",
      "|    policy_gradient_loss | -0.0216     |\n",
      "|    value_loss           | 6.87e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 157         |\n",
      "|    iterations           | 56          |\n",
      "|    time_elapsed         | 729         |\n",
      "|    total_timesteps      | 114688      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018124823 |\n",
      "|    clip_fraction        | 0.292       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.46       |\n",
      "|    explained_variance   | 0.606       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0171      |\n",
      "|    n_updates            | 550         |\n",
      "|    policy_gradient_loss | -0.0169     |\n",
      "|    value_loss           | 5.78e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 158         |\n",
      "|    iterations           | 57          |\n",
      "|    time_elapsed         | 735         |\n",
      "|    total_timesteps      | 116736      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012977113 |\n",
      "|    clip_fraction        | 0.115       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.46       |\n",
      "|    explained_variance   | 0.757       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0286      |\n",
      "|    n_updates            | 560         |\n",
      "|    policy_gradient_loss | -0.00525    |\n",
      "|    value_loss           | 8.29e-06    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 160         |\n",
      "|    iterations           | 58          |\n",
      "|    time_elapsed         | 740         |\n",
      "|    total_timesteps      | 118784      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018053345 |\n",
      "|    clip_fraction        | 0.237       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.42       |\n",
      "|    explained_variance   | 0.535       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0237     |\n",
      "|    n_updates            | 570         |\n",
      "|    policy_gradient_loss | -0.0152     |\n",
      "|    value_loss           | 1.23e-05    |\n",
      "-----------------------------------------\n",
      "box reached target\n",
      "Eval num_timesteps=120000, episode_reward=1.01 +/- 2.02\n",
      "Episode length: 8028.60 +/- 3942.80\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 8.03e+03    |\n",
      "|    mean_reward          | 1.01        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 120000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009125156 |\n",
      "|    clip_fraction        | 0.109       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.39       |\n",
      "|    explained_variance   | 0.274       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00458    |\n",
      "|    n_updates            | 580         |\n",
      "|    policy_gradient_loss | -0.00577    |\n",
      "|    value_loss           | 1.37e-05    |\n",
      "-----------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 154    |\n",
      "|    iterations      | 59     |\n",
      "|    time_elapsed    | 781    |\n",
      "|    total_timesteps | 120832 |\n",
      "-------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 156         |\n",
      "|    iterations           | 60          |\n",
      "|    time_elapsed         | 786         |\n",
      "|    total_timesteps      | 122880      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007844597 |\n",
      "|    clip_fraction        | 0.133       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.41       |\n",
      "|    explained_variance   | 0.285       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0232     |\n",
      "|    n_updates            | 590         |\n",
      "|    policy_gradient_loss | -0.0192     |\n",
      "|    value_loss           | 0.000706    |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 157       |\n",
      "|    iterations           | 61        |\n",
      "|    time_elapsed         | 792       |\n",
      "|    total_timesteps      | 124928    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0166751 |\n",
      "|    clip_fraction        | 0.236     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -1.52     |\n",
      "|    explained_variance   | 0.659     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -0.0132   |\n",
      "|    n_updates            | 600       |\n",
      "|    policy_gradient_loss | -0.0214   |\n",
      "|    value_loss           | 0.000229  |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 159         |\n",
      "|    iterations           | 62          |\n",
      "|    time_elapsed         | 797         |\n",
      "|    total_timesteps      | 126976      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016324166 |\n",
      "|    clip_fraction        | 0.219       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.5        |\n",
      "|    explained_variance   | 0.917       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00796    |\n",
      "|    n_updates            | 610         |\n",
      "|    policy_gradient_loss | -0.0178     |\n",
      "|    value_loss           | 3.25e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 160         |\n",
      "|    iterations           | 63          |\n",
      "|    time_elapsed         | 803         |\n",
      "|    total_timesteps      | 129024      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013375971 |\n",
      "|    clip_fraction        | 0.192       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.54       |\n",
      "|    explained_variance   | 0.891       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0317     |\n",
      "|    n_updates            | 620         |\n",
      "|    policy_gradient_loss | -0.013      |\n",
      "|    value_loss           | 5.9e-05     |\n",
      "-----------------------------------------\n",
      "box reached target\n",
      "Eval num_timesteps=130000, episode_reward=1.01 +/- 2.04\n",
      "Episode length: 8024.80 +/- 3950.40\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 8.02e+03    |\n",
      "|    mean_reward          | 1.01        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 130000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019727446 |\n",
      "|    clip_fraction        | 0.363       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.53       |\n",
      "|    explained_variance   | 0.437       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0214     |\n",
      "|    n_updates            | 630         |\n",
      "|    policy_gradient_loss | -0.0302     |\n",
      "|    value_loss           | 1.97e-05    |\n",
      "-----------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 155    |\n",
      "|    iterations      | 64     |\n",
      "|    time_elapsed    | 841    |\n",
      "|    total_timesteps | 131072 |\n",
      "-------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 157         |\n",
      "|    iterations           | 65          |\n",
      "|    time_elapsed         | 847         |\n",
      "|    total_timesteps      | 133120      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017030198 |\n",
      "|    clip_fraction        | 0.248       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.44       |\n",
      "|    explained_variance   | 0.742       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0151     |\n",
      "|    n_updates            | 640         |\n",
      "|    policy_gradient_loss | -0.0185     |\n",
      "|    value_loss           | 0.000759    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 158         |\n",
      "|    iterations           | 66          |\n",
      "|    time_elapsed         | 853         |\n",
      "|    total_timesteps      | 135168      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012896506 |\n",
      "|    clip_fraction        | 0.169       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.51       |\n",
      "|    explained_variance   | 0.923       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00282    |\n",
      "|    n_updates            | 650         |\n",
      "|    policy_gradient_loss | -0.01       |\n",
      "|    value_loss           | 4.7e-05     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 159         |\n",
      "|    iterations           | 67          |\n",
      "|    time_elapsed         | 859         |\n",
      "|    total_timesteps      | 137216      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017844226 |\n",
      "|    clip_fraction        | 0.367       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.54       |\n",
      "|    explained_variance   | 0.898       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0505     |\n",
      "|    n_updates            | 660         |\n",
      "|    policy_gradient_loss | -0.0177     |\n",
      "|    value_loss           | 4.42e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 161         |\n",
      "|    iterations           | 68          |\n",
      "|    time_elapsed         | 864         |\n",
      "|    total_timesteps      | 139264      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013530244 |\n",
      "|    clip_fraction        | 0.101       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.53       |\n",
      "|    explained_variance   | 0.917       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0193     |\n",
      "|    n_updates            | 670         |\n",
      "|    policy_gradient_loss | -0.00991    |\n",
      "|    value_loss           | 2.7e-05     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=140000, episode_reward=-0.04 +/- 0.08\n",
      "Episode length: 10000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+04       |\n",
      "|    mean_reward          | -0.0391     |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 140000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021750068 |\n",
      "|    clip_fraction        | 0.223       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.52       |\n",
      "|    explained_variance   | 0.94        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0223     |\n",
      "|    n_updates            | 680         |\n",
      "|    policy_gradient_loss | -0.0105     |\n",
      "|    value_loss           | 1.15e-05    |\n",
      "-----------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 154    |\n",
      "|    iterations      | 69     |\n",
      "|    time_elapsed    | 912    |\n",
      "|    total_timesteps | 141312 |\n",
      "-------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 156        |\n",
      "|    iterations           | 70         |\n",
      "|    time_elapsed         | 918        |\n",
      "|    total_timesteps      | 143360     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02064137 |\n",
      "|    clip_fraction        | 0.278      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.43      |\n",
      "|    explained_variance   | 0.929      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0193    |\n",
      "|    n_updates            | 690        |\n",
      "|    policy_gradient_loss | -0.0195    |\n",
      "|    value_loss           | 0.000114   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 157         |\n",
      "|    iterations           | 71          |\n",
      "|    time_elapsed         | 923         |\n",
      "|    total_timesteps      | 145408      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013960933 |\n",
      "|    clip_fraction        | 0.243       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.49       |\n",
      "|    explained_variance   | 0.387       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0256     |\n",
      "|    n_updates            | 700         |\n",
      "|    policy_gradient_loss | -0.0179     |\n",
      "|    value_loss           | 3.59e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 158         |\n",
      "|    iterations           | 72          |\n",
      "|    time_elapsed         | 928         |\n",
      "|    total_timesteps      | 147456      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011720242 |\n",
      "|    clip_fraction        | 0.195       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.44       |\n",
      "|    explained_variance   | 0.785       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0287     |\n",
      "|    n_updates            | 710         |\n",
      "|    policy_gradient_loss | -0.0123     |\n",
      "|    value_loss           | 3.21e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 159         |\n",
      "|    iterations           | 73          |\n",
      "|    time_elapsed         | 934         |\n",
      "|    total_timesteps      | 149504      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008545015 |\n",
      "|    clip_fraction        | 0.104       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.42       |\n",
      "|    explained_variance   | 0.773       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0112     |\n",
      "|    n_updates            | 720         |\n",
      "|    policy_gradient_loss | -0.00628    |\n",
      "|    value_loss           | 2.67e-05    |\n",
      "-----------------------------------------\n",
      "box reached target\n",
      "Eval num_timesteps=150000, episode_reward=1.01 +/- 2.02\n",
      "Episode length: 8028.00 +/- 3944.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 8.03e+03    |\n",
      "|    mean_reward          | 1.01        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 150000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013722536 |\n",
      "|    clip_fraction        | 0.251       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.4        |\n",
      "|    explained_variance   | 0.204       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0242     |\n",
      "|    n_updates            | 730         |\n",
      "|    policy_gradient_loss | -0.0137     |\n",
      "|    value_loss           | 4.19e-05    |\n",
      "-----------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 155    |\n",
      "|    iterations      | 74     |\n",
      "|    time_elapsed    | 973    |\n",
      "|    total_timesteps | 151552 |\n",
      "-------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 156         |\n",
      "|    iterations           | 75          |\n",
      "|    time_elapsed         | 978         |\n",
      "|    total_timesteps      | 153600      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025029674 |\n",
      "|    clip_fraction        | 0.189       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.41       |\n",
      "|    explained_variance   | 0.93        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00319     |\n",
      "|    n_updates            | 740         |\n",
      "|    policy_gradient_loss | -0.00741    |\n",
      "|    value_loss           | 0.000164    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 158         |\n",
      "|    iterations           | 76          |\n",
      "|    time_elapsed         | 984         |\n",
      "|    total_timesteps      | 155648      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014867188 |\n",
      "|    clip_fraction        | 0.292       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.51       |\n",
      "|    explained_variance   | 0.307       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0201     |\n",
      "|    n_updates            | 750         |\n",
      "|    policy_gradient_loss | -0.0217     |\n",
      "|    value_loss           | 0.000183    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 159         |\n",
      "|    iterations           | 77          |\n",
      "|    time_elapsed         | 989         |\n",
      "|    total_timesteps      | 157696      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012800023 |\n",
      "|    clip_fraction        | 0.263       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.54       |\n",
      "|    explained_variance   | 0.654       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0224     |\n",
      "|    n_updates            | 760         |\n",
      "|    policy_gradient_loss | -0.0193     |\n",
      "|    value_loss           | 6.19e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 160         |\n",
      "|    iterations           | 78          |\n",
      "|    time_elapsed         | 995         |\n",
      "|    total_timesteps      | 159744      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015392771 |\n",
      "|    clip_fraction        | 0.298       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.57       |\n",
      "|    explained_variance   | 0.878       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0091     |\n",
      "|    n_updates            | 770         |\n",
      "|    policy_gradient_loss | -0.0178     |\n",
      "|    value_loss           | 7.08e-05    |\n",
      "-----------------------------------------\n",
      "box reached target\n",
      "box reached target\n",
      "Eval num_timesteps=160000, episode_reward=1.98 +/- 2.53\n",
      "Episode length: 6037.80 +/- 4852.68\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 6.04e+03    |\n",
      "|    mean_reward          | 1.98        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 160000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018948521 |\n",
      "|    clip_fraction        | 0.355       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.55       |\n",
      "|    explained_variance   | 0.704       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0336     |\n",
      "|    n_updates            | 780         |\n",
      "|    policy_gradient_loss | -0.0263     |\n",
      "|    value_loss           | 2.24e-05    |\n",
      "-----------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 157    |\n",
      "|    iterations      | 79     |\n",
      "|    time_elapsed    | 1026   |\n",
      "|    total_timesteps | 161792 |\n",
      "-------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 158         |\n",
      "|    iterations           | 80          |\n",
      "|    time_elapsed         | 1031        |\n",
      "|    total_timesteps      | 163840      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016512103 |\n",
      "|    clip_fraction        | 0.201       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.32       |\n",
      "|    explained_variance   | 0.922       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0156      |\n",
      "|    n_updates            | 790         |\n",
      "|    policy_gradient_loss | -0.0188     |\n",
      "|    value_loss           | 0.000104    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 159         |\n",
      "|    iterations           | 81          |\n",
      "|    time_elapsed         | 1037        |\n",
      "|    total_timesteps      | 165888      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017081866 |\n",
      "|    clip_fraction        | 0.265       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.22       |\n",
      "|    explained_variance   | -0.534      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0147     |\n",
      "|    n_updates            | 800         |\n",
      "|    policy_gradient_loss | -0.0278     |\n",
      "|    value_loss           | 2.98e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 161         |\n",
      "|    iterations           | 82          |\n",
      "|    time_elapsed         | 1042        |\n",
      "|    total_timesteps      | 167936      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015281579 |\n",
      "|    clip_fraction        | 0.196       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.26       |\n",
      "|    explained_variance   | 0.739       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0682     |\n",
      "|    n_updates            | 810         |\n",
      "|    policy_gradient_loss | -0.0176     |\n",
      "|    value_loss           | 1.95e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 162         |\n",
      "|    iterations           | 83          |\n",
      "|    time_elapsed         | 1048        |\n",
      "|    total_timesteps      | 169984      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016874729 |\n",
      "|    clip_fraction        | 0.309       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.21       |\n",
      "|    explained_variance   | 0.784       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0285     |\n",
      "|    n_updates            | 820         |\n",
      "|    policy_gradient_loss | -0.021      |\n",
      "|    value_loss           | 2.2e-05     |\n",
      "-----------------------------------------\n",
      "box reached target\n",
      "box reached target\n",
      "Eval num_timesteps=170000, episode_reward=2.04 +/- 2.50\n",
      "Episode length: 6048.00 +/- 4840.23\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 6.05e+03    |\n",
      "|    mean_reward          | 2.04        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 170000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017497625 |\n",
      "|    clip_fraction        | 0.298       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.21       |\n",
      "|    explained_variance   | -0.587      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0515     |\n",
      "|    n_updates            | 830         |\n",
      "|    policy_gradient_loss | -0.0204     |\n",
      "|    value_loss           | 1.97e-05    |\n",
      "-----------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 159    |\n",
      "|    iterations      | 84     |\n",
      "|    time_elapsed    | 1078   |\n",
      "|    total_timesteps | 172032 |\n",
      "-------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 160       |\n",
      "|    iterations           | 85        |\n",
      "|    time_elapsed         | 1084      |\n",
      "|    total_timesteps      | 174080    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0329139 |\n",
      "|    clip_fraction        | 0.343     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -1.34     |\n",
      "|    explained_variance   | 0.925     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -0.0214   |\n",
      "|    n_updates            | 840       |\n",
      "|    policy_gradient_loss | -0.0126   |\n",
      "|    value_loss           | 0.000192  |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 161         |\n",
      "|    iterations           | 86          |\n",
      "|    time_elapsed         | 1089        |\n",
      "|    total_timesteps      | 176128      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018120607 |\n",
      "|    clip_fraction        | 0.364       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.44       |\n",
      "|    explained_variance   | 0.347       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0293     |\n",
      "|    n_updates            | 850         |\n",
      "|    policy_gradient_loss | -0.0238     |\n",
      "|    value_loss           | 6.47e-05    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 162        |\n",
      "|    iterations           | 87         |\n",
      "|    time_elapsed         | 1095       |\n",
      "|    total_timesteps      | 178176     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02605218 |\n",
      "|    clip_fraction        | 0.192      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.45      |\n",
      "|    explained_variance   | 0.939      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0483    |\n",
      "|    n_updates            | 860        |\n",
      "|    policy_gradient_loss | -0.0147    |\n",
      "|    value_loss           | 0.000137   |\n",
      "----------------------------------------\n",
      "box reached target\n",
      "Eval num_timesteps=180000, episode_reward=1.09 +/- 2.02\n",
      "Episode length: 8040.00 +/- 3920.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 8.04e+03    |\n",
      "|    mean_reward          | 1.09        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 180000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015166902 |\n",
      "|    clip_fraction        | 0.177       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.43       |\n",
      "|    explained_variance   | -0.57       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0294     |\n",
      "|    n_updates            | 870         |\n",
      "|    policy_gradient_loss | -0.0123     |\n",
      "|    value_loss           | 2.59e-05    |\n",
      "-----------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 158    |\n",
      "|    iterations      | 88     |\n",
      "|    time_elapsed    | 1135   |\n",
      "|    total_timesteps | 180224 |\n",
      "-------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 159         |\n",
      "|    iterations           | 89          |\n",
      "|    time_elapsed         | 1140        |\n",
      "|    total_timesteps      | 182272      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033362865 |\n",
      "|    clip_fraction        | 0.215       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.41       |\n",
      "|    explained_variance   | 0.958       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0151     |\n",
      "|    n_updates            | 880         |\n",
      "|    policy_gradient_loss | -0.00555    |\n",
      "|    value_loss           | 8.81e-05    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 160        |\n",
      "|    iterations           | 90         |\n",
      "|    time_elapsed         | 1146       |\n",
      "|    total_timesteps      | 184320     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02125591 |\n",
      "|    clip_fraction        | 0.41       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.29      |\n",
      "|    explained_variance   | 0.882      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.00175    |\n",
      "|    n_updates            | 890        |\n",
      "|    policy_gradient_loss | -0.0124    |\n",
      "|    value_loss           | 3.37e-05   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 161         |\n",
      "|    iterations           | 91          |\n",
      "|    time_elapsed         | 1151        |\n",
      "|    total_timesteps      | 186368      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019505028 |\n",
      "|    clip_fraction        | 0.39        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.38       |\n",
      "|    explained_variance   | 0.707       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0305     |\n",
      "|    n_updates            | 900         |\n",
      "|    policy_gradient_loss | -0.0224     |\n",
      "|    value_loss           | 1.13e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 162         |\n",
      "|    iterations           | 92          |\n",
      "|    time_elapsed         | 1157        |\n",
      "|    total_timesteps      | 188416      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015800375 |\n",
      "|    clip_fraction        | 0.147       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.44       |\n",
      "|    explained_variance   | 0.919       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00492     |\n",
      "|    n_updates            | 910         |\n",
      "|    policy_gradient_loss | -0.0112     |\n",
      "|    value_loss           | 5.8e-05     |\n",
      "-----------------------------------------\n",
      "box reached target\n",
      "Eval num_timesteps=190000, episode_reward=1.07 +/- 2.02\n",
      "Episode length: 8026.80 +/- 3946.40\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 8.03e+03    |\n",
      "|    mean_reward          | 1.07        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 190000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011665393 |\n",
      "|    clip_fraction        | 0.149       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.44       |\n",
      "|    explained_variance   | -1.71       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0143      |\n",
      "|    n_updates            | 920         |\n",
      "|    policy_gradient_loss | -0.00619    |\n",
      "|    value_loss           | 2.22e-05    |\n",
      "-----------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 159    |\n",
      "|    iterations      | 93     |\n",
      "|    time_elapsed    | 1197   |\n",
      "|    total_timesteps | 190464 |\n",
      "-------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 160         |\n",
      "|    iterations           | 94          |\n",
      "|    time_elapsed         | 1203        |\n",
      "|    total_timesteps      | 192512      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009814284 |\n",
      "|    clip_fraction        | 0.123       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.39       |\n",
      "|    explained_variance   | 0.873       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00895    |\n",
      "|    n_updates            | 930         |\n",
      "|    policy_gradient_loss | -0.0106     |\n",
      "|    value_loss           | 9.35e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 160         |\n",
      "|    iterations           | 95          |\n",
      "|    time_elapsed         | 1208        |\n",
      "|    total_timesteps      | 194560      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018235147 |\n",
      "|    clip_fraction        | 0.355       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.09       |\n",
      "|    explained_variance   | 0.542       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0289     |\n",
      "|    n_updates            | 940         |\n",
      "|    policy_gradient_loss | -0.0283     |\n",
      "|    value_loss           | 2.12e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 161         |\n",
      "|    iterations           | 96          |\n",
      "|    time_elapsed         | 1214        |\n",
      "|    total_timesteps      | 196608      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017248534 |\n",
      "|    clip_fraction        | 0.313       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.27       |\n",
      "|    explained_variance   | 0.875       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00232    |\n",
      "|    n_updates            | 950         |\n",
      "|    policy_gradient_loss | -0.0236     |\n",
      "|    value_loss           | 2.89e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 162         |\n",
      "|    iterations           | 97          |\n",
      "|    time_elapsed         | 1219        |\n",
      "|    total_timesteps      | 198656      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019900842 |\n",
      "|    clip_fraction        | 0.392       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.54       |\n",
      "|    explained_variance   | -1.66       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0214     |\n",
      "|    n_updates            | 960         |\n",
      "|    policy_gradient_loss | -0.0284     |\n",
      "|    value_loss           | 4.29e-06    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=200000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 10000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+04       |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 200000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015856657 |\n",
      "|    clip_fraction        | 0.219       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.48       |\n",
      "|    explained_variance   | 0.678       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00308    |\n",
      "|    n_updates            | 970         |\n",
      "|    policy_gradient_loss | -0.0152     |\n",
      "|    value_loss           | 2.51e-06    |\n",
      "-----------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 158    |\n",
      "|    iterations      | 98     |\n",
      "|    time_elapsed    | 1266   |\n",
      "|    total_timesteps | 200704 |\n",
      "-------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 159         |\n",
      "|    iterations           | 99          |\n",
      "|    time_elapsed         | 1272        |\n",
      "|    total_timesteps      | 202752      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018057214 |\n",
      "|    clip_fraction        | 0.175       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.38       |\n",
      "|    explained_variance   | 0.958       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0243     |\n",
      "|    n_updates            | 980         |\n",
      "|    policy_gradient_loss | -0.00866    |\n",
      "|    value_loss           | 3.83e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 160         |\n",
      "|    iterations           | 100         |\n",
      "|    time_elapsed         | 1277        |\n",
      "|    total_timesteps      | 204800      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014567612 |\n",
      "|    clip_fraction        | 0.225       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.44       |\n",
      "|    explained_variance   | 0.727       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.03       |\n",
      "|    n_updates            | 990         |\n",
      "|    policy_gradient_loss | -0.0139     |\n",
      "|    value_loss           | 3.74e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 161         |\n",
      "|    iterations           | 101         |\n",
      "|    time_elapsed         | 1282        |\n",
      "|    total_timesteps      | 206848      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020227604 |\n",
      "|    clip_fraction        | 0.41        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.31       |\n",
      "|    explained_variance   | 0.762       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0389     |\n",
      "|    n_updates            | 1000        |\n",
      "|    policy_gradient_loss | -0.027      |\n",
      "|    value_loss           | 7.91e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 162         |\n",
      "|    iterations           | 102         |\n",
      "|    time_elapsed         | 1288        |\n",
      "|    total_timesteps      | 208896      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018545404 |\n",
      "|    clip_fraction        | 0.434       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.28       |\n",
      "|    explained_variance   | 0.0933      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.014      |\n",
      "|    n_updates            | 1010        |\n",
      "|    policy_gradient_loss | -0.0206     |\n",
      "|    value_loss           | 2.05e-05    |\n",
      "-----------------------------------------\n",
      "box reached target\n",
      "Eval num_timesteps=210000, episode_reward=1.02 +/- 2.02\n",
      "Episode length: 8028.20 +/- 3943.60\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 8.03e+03    |\n",
      "|    mean_reward          | 1.02        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 210000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016727123 |\n",
      "|    clip_fraction        | 0.216       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.34       |\n",
      "|    explained_variance   | -0.0286     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00195     |\n",
      "|    n_updates            | 1020        |\n",
      "|    policy_gradient_loss | -0.0105     |\n",
      "|    value_loss           | 1e-05       |\n",
      "-----------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 158    |\n",
      "|    iterations      | 103    |\n",
      "|    time_elapsed    | 1327   |\n",
      "|    total_timesteps | 210944 |\n",
      "-------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 159         |\n",
      "|    iterations           | 104         |\n",
      "|    time_elapsed         | 1333        |\n",
      "|    total_timesteps      | 212992      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029935248 |\n",
      "|    clip_fraction        | 0.189       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.37       |\n",
      "|    explained_variance   | 0.942       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0297     |\n",
      "|    n_updates            | 1030        |\n",
      "|    policy_gradient_loss | -0.0116     |\n",
      "|    value_loss           | 0.000105    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 160         |\n",
      "|    iterations           | 105         |\n",
      "|    time_elapsed         | 1339        |\n",
      "|    total_timesteps      | 215040      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018044887 |\n",
      "|    clip_fraction        | 0.338       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.4        |\n",
      "|    explained_variance   | 0.901       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.000223    |\n",
      "|    n_updates            | 1040        |\n",
      "|    policy_gradient_loss | -0.0176     |\n",
      "|    value_loss           | 5.84e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 161         |\n",
      "|    iterations           | 106         |\n",
      "|    time_elapsed         | 1344        |\n",
      "|    total_timesteps      | 217088      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025089381 |\n",
      "|    clip_fraction        | 0.186       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.23       |\n",
      "|    explained_variance   | 0.953       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0555     |\n",
      "|    n_updates            | 1050        |\n",
      "|    policy_gradient_loss | -0.0107     |\n",
      "|    value_loss           | 0.000134    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 162         |\n",
      "|    iterations           | 107         |\n",
      "|    time_elapsed         | 1350        |\n",
      "|    total_timesteps      | 219136      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017279234 |\n",
      "|    clip_fraction        | 0.167       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.14       |\n",
      "|    explained_variance   | 0.846       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.058      |\n",
      "|    n_updates            | 1060        |\n",
      "|    policy_gradient_loss | -0.0187     |\n",
      "|    value_loss           | 0.000193    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=220000, episode_reward=0.02 +/- 0.04\n",
      "Episode length: 10000.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1e+04        |\n",
      "|    mean_reward          | 0.0194       |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 220000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0047592917 |\n",
      "|    clip_fraction        | 0.0713       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.11        |\n",
      "|    explained_variance   | -0.00137     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.00508     |\n",
      "|    n_updates            | 1070         |\n",
      "|    policy_gradient_loss | -0.00092     |\n",
      "|    value_loss           | 8.37e-05     |\n",
      "------------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 158    |\n",
      "|    iterations      | 108    |\n",
      "|    time_elapsed    | 1398   |\n",
      "|    total_timesteps | 221184 |\n",
      "-------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 159         |\n",
      "|    iterations           | 109         |\n",
      "|    time_elapsed         | 1403        |\n",
      "|    total_timesteps      | 223232      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016733576 |\n",
      "|    clip_fraction        | 0.215       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.25       |\n",
      "|    explained_variance   | 0.914       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0394     |\n",
      "|    n_updates            | 1080        |\n",
      "|    policy_gradient_loss | -0.0127     |\n",
      "|    value_loss           | 0.00021     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 159         |\n",
      "|    iterations           | 110         |\n",
      "|    time_elapsed         | 1409        |\n",
      "|    total_timesteps      | 225280      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010603365 |\n",
      "|    clip_fraction        | 0.253       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.41       |\n",
      "|    explained_variance   | 0.861       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00968    |\n",
      "|    n_updates            | 1090        |\n",
      "|    policy_gradient_loss | -0.0147     |\n",
      "|    value_loss           | 3e-05       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 160         |\n",
      "|    iterations           | 111         |\n",
      "|    time_elapsed         | 1414        |\n",
      "|    total_timesteps      | 227328      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013634749 |\n",
      "|    clip_fraction        | 0.259       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.25       |\n",
      "|    explained_variance   | 0.324       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00569     |\n",
      "|    n_updates            | 1100        |\n",
      "|    policy_gradient_loss | -0.0195     |\n",
      "|    value_loss           | 9.84e-06    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 161         |\n",
      "|    iterations           | 112         |\n",
      "|    time_elapsed         | 1419        |\n",
      "|    total_timesteps      | 229376      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011684129 |\n",
      "|    clip_fraction        | 0.0955      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.21       |\n",
      "|    explained_variance   | 0.952       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00466    |\n",
      "|    n_updates            | 1110        |\n",
      "|    policy_gradient_loss | -0.00277    |\n",
      "|    value_loss           | 1.76e-06    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=230000, episode_reward=0.03 +/- 0.02\n",
      "Episode length: 10000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+04       |\n",
      "|    mean_reward          | 0.0264      |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 230000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010962537 |\n",
      "|    clip_fraction        | 0.227       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.14       |\n",
      "|    explained_variance   | 0.862       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0309     |\n",
      "|    n_updates            | 1120        |\n",
      "|    policy_gradient_loss | -0.0203     |\n",
      "|    value_loss           | 1.61e-05    |\n",
      "-----------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 157    |\n",
      "|    iterations      | 113    |\n",
      "|    time_elapsed    | 1468   |\n",
      "|    total_timesteps | 231424 |\n",
      "-------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 158         |\n",
      "|    iterations           | 114         |\n",
      "|    time_elapsed         | 1473        |\n",
      "|    total_timesteps      | 233472      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028589249 |\n",
      "|    clip_fraction        | 0.234       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.08       |\n",
      "|    explained_variance   | 0.913       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0688     |\n",
      "|    n_updates            | 1130        |\n",
      "|    policy_gradient_loss | -0.0217     |\n",
      "|    value_loss           | 0.00017     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 159         |\n",
      "|    iterations           | 115         |\n",
      "|    time_elapsed         | 1478        |\n",
      "|    total_timesteps      | 235520      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021042202 |\n",
      "|    clip_fraction        | 0.224       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.17       |\n",
      "|    explained_variance   | 0.374       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00768     |\n",
      "|    n_updates            | 1140        |\n",
      "|    policy_gradient_loss | -0.015      |\n",
      "|    value_loss           | 4.36e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 160         |\n",
      "|    iterations           | 116         |\n",
      "|    time_elapsed         | 1484        |\n",
      "|    total_timesteps      | 237568      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017420135 |\n",
      "|    clip_fraction        | 0.344       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.2        |\n",
      "|    explained_variance   | 0.7         |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.012      |\n",
      "|    n_updates            | 1150        |\n",
      "|    policy_gradient_loss | -0.0229     |\n",
      "|    value_loss           | 3.2e-05     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 160         |\n",
      "|    iterations           | 117         |\n",
      "|    time_elapsed         | 1489        |\n",
      "|    total_timesteps      | 239616      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019232161 |\n",
      "|    clip_fraction        | 0.447       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.14       |\n",
      "|    explained_variance   | 0.397       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0251     |\n",
      "|    n_updates            | 1160        |\n",
      "|    policy_gradient_loss | -0.0254     |\n",
      "|    value_loss           | 1.14e-05    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=240000, episode_reward=0.13 +/- 0.26\n",
      "Episode length: 10000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+04       |\n",
      "|    mean_reward          | 0.129       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 240000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011994239 |\n",
      "|    clip_fraction        | 0.227       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.05       |\n",
      "|    explained_variance   | 0.914       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00124     |\n",
      "|    n_updates            | 1170        |\n",
      "|    policy_gradient_loss | -0.00767    |\n",
      "|    value_loss           | 0.000115    |\n",
      "-----------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 157    |\n",
      "|    iterations      | 118    |\n",
      "|    time_elapsed    | 1537   |\n",
      "|    total_timesteps | 241664 |\n",
      "-------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 157         |\n",
      "|    iterations           | 119         |\n",
      "|    time_elapsed         | 1542        |\n",
      "|    total_timesteps      | 243712      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015608384 |\n",
      "|    clip_fraction        | 0.251       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.869      |\n",
      "|    explained_variance   | 0.878       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0194     |\n",
      "|    n_updates            | 1180        |\n",
      "|    policy_gradient_loss | -0.00922    |\n",
      "|    value_loss           | 3.72e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 158         |\n",
      "|    iterations           | 120         |\n",
      "|    time_elapsed         | 1548        |\n",
      "|    total_timesteps      | 245760      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015990984 |\n",
      "|    clip_fraction        | 0.149       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.99       |\n",
      "|    explained_variance   | -1.88       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00755    |\n",
      "|    n_updates            | 1190        |\n",
      "|    policy_gradient_loss | -0.0111     |\n",
      "|    value_loss           | 3.4e-06     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 159         |\n",
      "|    iterations           | 121         |\n",
      "|    time_elapsed         | 1553        |\n",
      "|    total_timesteps      | 247808      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013615262 |\n",
      "|    clip_fraction        | 0.111       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.16       |\n",
      "|    explained_variance   | -0.0277     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0365     |\n",
      "|    n_updates            | 1200        |\n",
      "|    policy_gradient_loss | -0.0145     |\n",
      "|    value_loss           | 2.63e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 160         |\n",
      "|    iterations           | 122         |\n",
      "|    time_elapsed         | 1559        |\n",
      "|    total_timesteps      | 249856      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014453001 |\n",
      "|    clip_fraction        | 0.263       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.34       |\n",
      "|    explained_variance   | 0.679       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0177     |\n",
      "|    n_updates            | 1210        |\n",
      "|    policy_gradient_loss | -0.0159     |\n",
      "|    value_loss           | 1.16e-06    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=250000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 10000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+04       |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 250000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032894753 |\n",
      "|    clip_fraction        | 0.179       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.21       |\n",
      "|    explained_variance   | 0.943       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0441     |\n",
      "|    n_updates            | 1220        |\n",
      "|    policy_gradient_loss | -0.0134     |\n",
      "|    value_loss           | 3.48e-05    |\n",
      "-----------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 156    |\n",
      "|    iterations      | 123    |\n",
      "|    time_elapsed    | 1608   |\n",
      "|    total_timesteps | 251904 |\n",
      "-------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 157         |\n",
      "|    iterations           | 124         |\n",
      "|    time_elapsed         | 1614        |\n",
      "|    total_timesteps      | 253952      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020409308 |\n",
      "|    clip_fraction        | 0.31        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.827      |\n",
      "|    explained_variance   | 0.897       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00536    |\n",
      "|    n_updates            | 1230        |\n",
      "|    policy_gradient_loss | -0.0188     |\n",
      "|    value_loss           | 2.4e-05     |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 158        |\n",
      "|    iterations           | 125        |\n",
      "|    time_elapsed         | 1619       |\n",
      "|    total_timesteps      | 256000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01544458 |\n",
      "|    clip_fraction        | 0.185      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.809     |\n",
      "|    explained_variance   | 0.899      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0114     |\n",
      "|    n_updates            | 1240       |\n",
      "|    policy_gradient_loss | -0.00698   |\n",
      "|    value_loss           | 1.97e-05   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 158        |\n",
      "|    iterations           | 126        |\n",
      "|    time_elapsed         | 1625       |\n",
      "|    total_timesteps      | 258048     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01790615 |\n",
      "|    clip_fraction        | 0.375      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.902     |\n",
      "|    explained_variance   | -0.0795    |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0471    |\n",
      "|    n_updates            | 1250       |\n",
      "|    policy_gradient_loss | -0.0178    |\n",
      "|    value_loss           | 0.0001     |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=260000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 10000.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1e+04      |\n",
      "|    mean_reward          | 0          |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 260000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01838588 |\n",
      "|    clip_fraction        | 0.341      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.903     |\n",
      "|    explained_variance   | 0.183      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0137    |\n",
      "|    n_updates            | 1260       |\n",
      "|    policy_gradient_loss | -0.0179    |\n",
      "|    value_loss           | 9.96e-06   |\n",
      "----------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 155    |\n",
      "|    iterations      | 127    |\n",
      "|    time_elapsed    | 1673   |\n",
      "|    total_timesteps | 260096 |\n",
      "-------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 156         |\n",
      "|    iterations           | 128         |\n",
      "|    time_elapsed         | 1678        |\n",
      "|    total_timesteps      | 262144      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018631432 |\n",
      "|    clip_fraction        | 0.37        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.938      |\n",
      "|    explained_variance   | 0.58        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.016       |\n",
      "|    n_updates            | 1270        |\n",
      "|    policy_gradient_loss | -0.00995    |\n",
      "|    value_loss           | 4.33e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 156         |\n",
      "|    iterations           | 129         |\n",
      "|    time_elapsed         | 1684        |\n",
      "|    total_timesteps      | 264192      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011107357 |\n",
      "|    clip_fraction        | 0.0939      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.22       |\n",
      "|    explained_variance   | 0.55        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0457     |\n",
      "|    n_updates            | 1280        |\n",
      "|    policy_gradient_loss | -0.00734    |\n",
      "|    value_loss           | 3.58e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 157         |\n",
      "|    iterations           | 130         |\n",
      "|    time_elapsed         | 1690        |\n",
      "|    total_timesteps      | 266240      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012806907 |\n",
      "|    clip_fraction        | 0.0647      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.16       |\n",
      "|    explained_variance   | -1.03       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.018      |\n",
      "|    n_updates            | 1290        |\n",
      "|    policy_gradient_loss | -0.00277    |\n",
      "|    value_loss           | 1.12e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 158         |\n",
      "|    iterations           | 131         |\n",
      "|    time_elapsed         | 1695        |\n",
      "|    total_timesteps      | 268288      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014911815 |\n",
      "|    clip_fraction        | 0.095       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.09       |\n",
      "|    explained_variance   | -0.092      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0202     |\n",
      "|    n_updates            | 1300        |\n",
      "|    policy_gradient_loss | -0.00213    |\n",
      "|    value_loss           | 1.34e-05    |\n",
      "-----------------------------------------\n",
      "box reached target\n",
      "Eval num_timesteps=270000, episode_reward=1.02 +/- 2.03\n",
      "Episode length: 8022.60 +/- 3954.80\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 8.02e+03     |\n",
      "|    mean_reward          | 1.02         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 270000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0045049926 |\n",
      "|    clip_fraction        | 0.0475       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.03        |\n",
      "|    explained_variance   | -0.0893      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0114      |\n",
      "|    n_updates            | 1310         |\n",
      "|    policy_gradient_loss | 0.00101      |\n",
      "|    value_loss           | 3.8e-06      |\n",
      "------------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 155    |\n",
      "|    iterations      | 132    |\n",
      "|    time_elapsed    | 1735   |\n",
      "|    total_timesteps | 270336 |\n",
      "-------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 156         |\n",
      "|    iterations           | 133         |\n",
      "|    time_elapsed         | 1741        |\n",
      "|    total_timesteps      | 272384      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029630948 |\n",
      "|    clip_fraction        | 0.197       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.09       |\n",
      "|    explained_variance   | 0.819       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00467     |\n",
      "|    n_updates            | 1320        |\n",
      "|    policy_gradient_loss | -0.00544    |\n",
      "|    value_loss           | 1.64e-05    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 157        |\n",
      "|    iterations           | 134        |\n",
      "|    time_elapsed         | 1746       |\n",
      "|    total_timesteps      | 274432     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.05669069 |\n",
      "|    clip_fraction        | 0.161      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.24      |\n",
      "|    explained_variance   | 0.959      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0795    |\n",
      "|    n_updates            | 1330       |\n",
      "|    policy_gradient_loss | -0.0112    |\n",
      "|    value_loss           | 6.92e-06   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 157         |\n",
      "|    iterations           | 135         |\n",
      "|    time_elapsed         | 1752        |\n",
      "|    total_timesteps      | 276480      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012250817 |\n",
      "|    clip_fraction        | 0.0894      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.17       |\n",
      "|    explained_variance   | -0.226      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0067     |\n",
      "|    n_updates            | 1340        |\n",
      "|    policy_gradient_loss | -0.00439    |\n",
      "|    value_loss           | 1.25e-05    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 158          |\n",
      "|    iterations           | 136          |\n",
      "|    time_elapsed         | 1758         |\n",
      "|    total_timesteps      | 278528       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062593003 |\n",
      "|    clip_fraction        | 0.0732       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.09        |\n",
      "|    explained_variance   | -0.0565      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0143       |\n",
      "|    n_updates            | 1350         |\n",
      "|    policy_gradient_loss | -0.00182     |\n",
      "|    value_loss           | 1.27e-05     |\n",
      "------------------------------------------\n",
      "box reached target\n",
      "Eval num_timesteps=280000, episode_reward=1.01 +/- 2.03\n",
      "Episode length: 8038.40 +/- 3923.20\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 8.04e+03    |\n",
      "|    mean_reward          | 1.01        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 280000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008665277 |\n",
      "|    clip_fraction        | 0.111       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.09       |\n",
      "|    explained_variance   | -0.0813     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00677     |\n",
      "|    n_updates            | 1360        |\n",
      "|    policy_gradient_loss | -0.00501    |\n",
      "|    value_loss           | 1.52e-06    |\n",
      "-----------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 156    |\n",
      "|    iterations      | 137    |\n",
      "|    time_elapsed    | 1798   |\n",
      "|    total_timesteps | 280576 |\n",
      "-------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 156          |\n",
      "|    iterations           | 138          |\n",
      "|    time_elapsed         | 1803         |\n",
      "|    total_timesteps      | 282624       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0095787095 |\n",
      "|    clip_fraction        | 0.0806       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.15        |\n",
      "|    explained_variance   | 0.967        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0155       |\n",
      "|    n_updates            | 1370         |\n",
      "|    policy_gradient_loss | -0.00732     |\n",
      "|    value_loss           | 1.52e-05     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 157         |\n",
      "|    iterations           | 139         |\n",
      "|    time_elapsed         | 1809        |\n",
      "|    total_timesteps      | 284672      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018369403 |\n",
      "|    clip_fraction        | 0.151       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.23       |\n",
      "|    explained_variance   | 0.681       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0247     |\n",
      "|    n_updates            | 1380        |\n",
      "|    policy_gradient_loss | -0.0104     |\n",
      "|    value_loss           | 0.000104    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 157         |\n",
      "|    iterations           | 140         |\n",
      "|    time_elapsed         | 1815        |\n",
      "|    total_timesteps      | 286720      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007924182 |\n",
      "|    clip_fraction        | 0.0474      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.3        |\n",
      "|    explained_variance   | -0.138      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0177     |\n",
      "|    n_updates            | 1390        |\n",
      "|    policy_gradient_loss | -3.07e-05   |\n",
      "|    value_loss           | 1.02e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 158         |\n",
      "|    iterations           | 141         |\n",
      "|    time_elapsed         | 1821        |\n",
      "|    total_timesteps      | 288768      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013505177 |\n",
      "|    clip_fraction        | 0.167       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.32       |\n",
      "|    explained_variance   | 0.595       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0311     |\n",
      "|    n_updates            | 1400        |\n",
      "|    policy_gradient_loss | -0.008      |\n",
      "|    value_loss           | 5.16e-05    |\n",
      "-----------------------------------------\n",
      "box reached target\n",
      "Eval num_timesteps=290000, episode_reward=1.02 +/- 2.03\n",
      "Episode length: 8022.20 +/- 3955.60\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 8.02e+03    |\n",
      "|    mean_reward          | 1.02        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 290000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011271828 |\n",
      "|    clip_fraction        | 0.172       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.3        |\n",
      "|    explained_variance   | 0.207       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0124      |\n",
      "|    n_updates            | 1410        |\n",
      "|    policy_gradient_loss | -0.00814    |\n",
      "|    value_loss           | 1.13e-05    |\n",
      "-----------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 156    |\n",
      "|    iterations      | 142    |\n",
      "|    time_elapsed    | 1860   |\n",
      "|    total_timesteps | 290816 |\n",
      "-------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 156         |\n",
      "|    iterations           | 143         |\n",
      "|    time_elapsed         | 1865        |\n",
      "|    total_timesteps      | 292864      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028271163 |\n",
      "|    clip_fraction        | 0.252       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.13       |\n",
      "|    explained_variance   | 0.953       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00755    |\n",
      "|    n_updates            | 1420        |\n",
      "|    policy_gradient_loss | -0.00897    |\n",
      "|    value_loss           | 3.97e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 157         |\n",
      "|    iterations           | 144         |\n",
      "|    time_elapsed         | 1871        |\n",
      "|    total_timesteps      | 294912      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004994685 |\n",
      "|    clip_fraction        | 0.0876      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.945      |\n",
      "|    explained_variance   | -0.0674     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00175    |\n",
      "|    n_updates            | 1430        |\n",
      "|    policy_gradient_loss | -0.00163    |\n",
      "|    value_loss           | 7.38e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 158         |\n",
      "|    iterations           | 145         |\n",
      "|    time_elapsed         | 1877        |\n",
      "|    total_timesteps      | 296960      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007748549 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.01       |\n",
      "|    explained_variance   | -0.022      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00848    |\n",
      "|    n_updates            | 1440        |\n",
      "|    policy_gradient_loss | -0.00137    |\n",
      "|    value_loss           | 1.8e-05     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 158         |\n",
      "|    iterations           | 146         |\n",
      "|    time_elapsed         | 1882        |\n",
      "|    total_timesteps      | 299008      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012869645 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.08       |\n",
      "|    explained_variance   | -0.0278     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0275     |\n",
      "|    n_updates            | 1450        |\n",
      "|    policy_gradient_loss | -0.000622   |\n",
      "|    value_loss           | 5.53e-06    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=300000, episode_reward=0.01 +/- 0.01\n",
      "Episode length: 10000.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1e+04        |\n",
      "|    mean_reward          | 0.00656      |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 300000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0051383134 |\n",
      "|    clip_fraction        | 0.104        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.15        |\n",
      "|    explained_variance   | -0.0353      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.00537     |\n",
      "|    n_updates            | 1460         |\n",
      "|    policy_gradient_loss | -0.00185     |\n",
      "|    value_loss           | 2.4e-06      |\n",
      "------------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 155    |\n",
      "|    iterations      | 147    |\n",
      "|    time_elapsed    | 1930   |\n",
      "|    total_timesteps | 301056 |\n",
      "-------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 156         |\n",
      "|    iterations           | 148         |\n",
      "|    time_elapsed         | 1935        |\n",
      "|    total_timesteps      | 303104      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010071516 |\n",
      "|    clip_fraction        | 0.0913      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.07       |\n",
      "|    explained_variance   | 0.724       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0235     |\n",
      "|    n_updates            | 1470        |\n",
      "|    policy_gradient_loss | -0.00842    |\n",
      "|    value_loss           | 5.8e-05     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 157         |\n",
      "|    iterations           | 149         |\n",
      "|    time_elapsed         | 1941        |\n",
      "|    total_timesteps      | 305152      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021455102 |\n",
      "|    clip_fraction        | 0.444       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.04       |\n",
      "|    explained_variance   | -0.297      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00166     |\n",
      "|    n_updates            | 1480        |\n",
      "|    policy_gradient_loss | -0.0206     |\n",
      "|    value_loss           | 5.68e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 157         |\n",
      "|    iterations           | 150         |\n",
      "|    time_elapsed         | 1946        |\n",
      "|    total_timesteps      | 307200      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012507898 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.15       |\n",
      "|    explained_variance   | -2.87       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00223    |\n",
      "|    n_updates            | 1490        |\n",
      "|    policy_gradient_loss | -0.0043     |\n",
      "|    value_loss           | 2.1e-05     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 158         |\n",
      "|    iterations           | 151         |\n",
      "|    time_elapsed         | 1952        |\n",
      "|    total_timesteps      | 309248      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011243885 |\n",
      "|    clip_fraction        | 0.0767      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.15       |\n",
      "|    explained_variance   | -2.42       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00451     |\n",
      "|    n_updates            | 1500        |\n",
      "|    policy_gradient_loss | -0.003      |\n",
      "|    value_loss           | 5.9e-06     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=310000, episode_reward=0.00 +/- 0.01\n",
      "Episode length: 10000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+04       |\n",
      "|    mean_reward          | 0.00368     |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 310000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005897327 |\n",
      "|    clip_fraction        | 0.0907      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.13       |\n",
      "|    explained_variance   | -3.16       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00758    |\n",
      "|    n_updates            | 1510        |\n",
      "|    policy_gradient_loss | -0.00555    |\n",
      "|    value_loss           | 2.3e-06     |\n",
      "-----------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 155    |\n",
      "|    iterations      | 152    |\n",
      "|    time_elapsed    | 2000   |\n",
      "|    total_timesteps | 311296 |\n",
      "-------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 156        |\n",
      "|    iterations           | 153        |\n",
      "|    time_elapsed         | 2006       |\n",
      "|    total_timesteps      | 313344     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03434668 |\n",
      "|    clip_fraction        | 0.32       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.12      |\n",
      "|    explained_variance   | 0.914      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0765    |\n",
      "|    n_updates            | 1520       |\n",
      "|    policy_gradient_loss | -0.0236    |\n",
      "|    value_loss           | 1.47e-05   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 156         |\n",
      "|    iterations           | 154         |\n",
      "|    time_elapsed         | 2011        |\n",
      "|    total_timesteps      | 315392      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020341147 |\n",
      "|    clip_fraction        | 0.428       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.18       |\n",
      "|    explained_variance   | -2.01       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00546     |\n",
      "|    n_updates            | 1530        |\n",
      "|    policy_gradient_loss | -0.0185     |\n",
      "|    value_loss           | 3.63e-05    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 157        |\n",
      "|    iterations           | 155        |\n",
      "|    time_elapsed         | 2016       |\n",
      "|    total_timesteps      | 317440     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01777782 |\n",
      "|    clip_fraction        | 0.23       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.19      |\n",
      "|    explained_variance   | -0.227     |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0205    |\n",
      "|    n_updates            | 1540       |\n",
      "|    policy_gradient_loss | -0.014     |\n",
      "|    value_loss           | 2.03e-06   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 157         |\n",
      "|    iterations           | 156         |\n",
      "|    time_elapsed         | 2022        |\n",
      "|    total_timesteps      | 319488      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005405536 |\n",
      "|    clip_fraction        | 0.0988      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.23       |\n",
      "|    explained_variance   | 0.831       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00264     |\n",
      "|    n_updates            | 1550        |\n",
      "|    policy_gradient_loss | -0.0055     |\n",
      "|    value_loss           | 2.58e-06    |\n",
      "-----------------------------------------\n",
      "box reached target\n",
      "Eval num_timesteps=320000, episode_reward=1.01 +/- 2.02\n",
      "Episode length: 8012.80 +/- 3974.40\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 8.01e+03    |\n",
      "|    mean_reward          | 1.01        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 320000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016766459 |\n",
      "|    clip_fraction        | 0.363       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.18       |\n",
      "|    explained_variance   | 0.748       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.01       |\n",
      "|    n_updates            | 1560        |\n",
      "|    policy_gradient_loss | -0.014      |\n",
      "|    value_loss           | 3.91e-06    |\n",
      "-----------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 155    |\n",
      "|    iterations      | 157    |\n",
      "|    time_elapsed    | 2062   |\n",
      "|    total_timesteps | 321536 |\n",
      "-------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 156         |\n",
      "|    iterations           | 158         |\n",
      "|    time_elapsed         | 2068        |\n",
      "|    total_timesteps      | 323584      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016593752 |\n",
      "|    clip_fraction        | 0.346       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.17       |\n",
      "|    explained_variance   | 0.945       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0294     |\n",
      "|    n_updates            | 1570        |\n",
      "|    policy_gradient_loss | -0.0171     |\n",
      "|    value_loss           | 0.000125    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 157        |\n",
      "|    iterations           | 159        |\n",
      "|    time_elapsed         | 2073       |\n",
      "|    total_timesteps      | 325632     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04998838 |\n",
      "|    clip_fraction        | 0.183      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.09      |\n",
      "|    explained_variance   | 0.94       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0323    |\n",
      "|    n_updates            | 1580       |\n",
      "|    policy_gradient_loss | -0.0152    |\n",
      "|    value_loss           | 6.38e-05   |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 157          |\n",
      "|    iterations           | 160          |\n",
      "|    time_elapsed         | 2079         |\n",
      "|    total_timesteps      | 327680       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062221913 |\n",
      "|    clip_fraction        | 0.0478       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.04        |\n",
      "|    explained_variance   | 0.907        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.00701     |\n",
      "|    n_updates            | 1590         |\n",
      "|    policy_gradient_loss | 0.000596     |\n",
      "|    value_loss           | 4.06e-06     |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 158        |\n",
      "|    iterations           | 161        |\n",
      "|    time_elapsed         | 2084       |\n",
      "|    total_timesteps      | 329728     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00801823 |\n",
      "|    clip_fraction        | 0.0749     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.01      |\n",
      "|    explained_variance   | 0.919      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0335    |\n",
      "|    n_updates            | 1600       |\n",
      "|    policy_gradient_loss | -0.00457   |\n",
      "|    value_loss           | 6.81e-05   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=330000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 10000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+04       |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 330000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005828664 |\n",
      "|    clip_fraction        | 0.0615      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.933      |\n",
      "|    explained_variance   | 0.815       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0106     |\n",
      "|    n_updates            | 1610        |\n",
      "|    policy_gradient_loss | -0.00252    |\n",
      "|    value_loss           | 3.62e-06    |\n",
      "-----------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 155    |\n",
      "|    iterations      | 162    |\n",
      "|    time_elapsed    | 2132   |\n",
      "|    total_timesteps | 331776 |\n",
      "-------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 156         |\n",
      "|    iterations           | 163         |\n",
      "|    time_elapsed         | 2138        |\n",
      "|    total_timesteps      | 333824      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029944444 |\n",
      "|    clip_fraction        | 0.237       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.18       |\n",
      "|    explained_variance   | 0.928       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.000515    |\n",
      "|    n_updates            | 1620        |\n",
      "|    policy_gradient_loss | -0.00798    |\n",
      "|    value_loss           | 3.45e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 156         |\n",
      "|    iterations           | 164         |\n",
      "|    time_elapsed         | 2144        |\n",
      "|    total_timesteps      | 335872      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010374665 |\n",
      "|    clip_fraction        | 0.108       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.11       |\n",
      "|    explained_variance   | 0.959       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0199     |\n",
      "|    n_updates            | 1630        |\n",
      "|    policy_gradient_loss | -0.009      |\n",
      "|    value_loss           | 1.71e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 157         |\n",
      "|    iterations           | 165         |\n",
      "|    time_elapsed         | 2149        |\n",
      "|    total_timesteps      | 337920      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013927238 |\n",
      "|    clip_fraction        | 0.115       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.09       |\n",
      "|    explained_variance   | 0.838       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0109     |\n",
      "|    n_updates            | 1640        |\n",
      "|    policy_gradient_loss | -0.00983    |\n",
      "|    value_loss           | 1.13e-05    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 157          |\n",
      "|    iterations           | 166          |\n",
      "|    time_elapsed         | 2155         |\n",
      "|    total_timesteps      | 339968       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061651003 |\n",
      "|    clip_fraction        | 0.0963       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.998       |\n",
      "|    explained_variance   | 0.425        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0134      |\n",
      "|    n_updates            | 1650         |\n",
      "|    policy_gradient_loss | -0.00309     |\n",
      "|    value_loss           | 1.89e-05     |\n",
      "------------------------------------------\n",
      "box reached target\n",
      "Eval num_timesteps=340000, episode_reward=1.03 +/- 2.01\n",
      "Episode length: 8011.40 +/- 3977.20\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 8.01e+03    |\n",
      "|    mean_reward          | 1.03        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 340000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008396409 |\n",
      "|    clip_fraction        | 0.0686      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.923      |\n",
      "|    explained_variance   | 0.142       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0173     |\n",
      "|    n_updates            | 1660        |\n",
      "|    policy_gradient_loss | -0.0019     |\n",
      "|    value_loss           | 1.37e-07    |\n",
      "-----------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 155    |\n",
      "|    iterations      | 167    |\n",
      "|    time_elapsed    | 2194   |\n",
      "|    total_timesteps | 342016 |\n",
      "-------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 156         |\n",
      "|    iterations           | 168         |\n",
      "|    time_elapsed         | 2200        |\n",
      "|    total_timesteps      | 344064      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009965831 |\n",
      "|    clip_fraction        | 0.106       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.811      |\n",
      "|    explained_variance   | 0.935       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00935     |\n",
      "|    n_updates            | 1670        |\n",
      "|    policy_gradient_loss | -0.0018     |\n",
      "|    value_loss           | 1.94e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 156         |\n",
      "|    iterations           | 169         |\n",
      "|    time_elapsed         | 2205        |\n",
      "|    total_timesteps      | 346112      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020631839 |\n",
      "|    clip_fraction        | 0.252       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.986      |\n",
      "|    explained_variance   | -1.66       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0306      |\n",
      "|    n_updates            | 1680        |\n",
      "|    policy_gradient_loss | -0.0115     |\n",
      "|    value_loss           | 8.9e-06     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 157         |\n",
      "|    iterations           | 170         |\n",
      "|    time_elapsed         | 2211        |\n",
      "|    total_timesteps      | 348160      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017121632 |\n",
      "|    clip_fraction        | 0.278       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.03       |\n",
      "|    explained_variance   | 0.275       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0258     |\n",
      "|    n_updates            | 1690        |\n",
      "|    policy_gradient_loss | -0.0152     |\n",
      "|    value_loss           | 3.97e-06    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=350000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 10000.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1e+04        |\n",
      "|    mean_reward          | 0.00107      |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 350000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061528855 |\n",
      "|    clip_fraction        | 0.15         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.06        |\n",
      "|    explained_variance   | -0.499       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0178       |\n",
      "|    n_updates            | 1700         |\n",
      "|    policy_gradient_loss | -0.00372     |\n",
      "|    value_loss           | 2.26e-06     |\n",
      "------------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 155    |\n",
      "|    iterations      | 171    |\n",
      "|    time_elapsed    | 2259   |\n",
      "|    total_timesteps | 350208 |\n",
      "-------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 155         |\n",
      "|    iterations           | 172         |\n",
      "|    time_elapsed         | 2264        |\n",
      "|    total_timesteps      | 352256      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009126352 |\n",
      "|    clip_fraction        | 0.084       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.09       |\n",
      "|    explained_variance   | 0.962       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0209     |\n",
      "|    n_updates            | 1710        |\n",
      "|    policy_gradient_loss | -0.00847    |\n",
      "|    value_loss           | 5.86e-06    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 156        |\n",
      "|    iterations           | 173        |\n",
      "|    time_elapsed         | 2270       |\n",
      "|    total_timesteps      | 354304     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01022909 |\n",
      "|    clip_fraction        | 0.199      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.37      |\n",
      "|    explained_variance   | 0.761      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.00106    |\n",
      "|    n_updates            | 1720       |\n",
      "|    policy_gradient_loss | -0.0102    |\n",
      "|    value_loss           | 5.68e-05   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 156         |\n",
      "|    iterations           | 174         |\n",
      "|    time_elapsed         | 2275        |\n",
      "|    total_timesteps      | 356352      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013555091 |\n",
      "|    clip_fraction        | 0.109       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.19       |\n",
      "|    explained_variance   | 0.937       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00109    |\n",
      "|    n_updates            | 1730        |\n",
      "|    policy_gradient_loss | -0.00717    |\n",
      "|    value_loss           | 8.12e-06    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 157          |\n",
      "|    iterations           | 175          |\n",
      "|    time_elapsed         | 2281         |\n",
      "|    total_timesteps      | 358400       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058659967 |\n",
      "|    clip_fraction        | 0.0712       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.907       |\n",
      "|    explained_variance   | -1.46        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0116      |\n",
      "|    n_updates            | 1740         |\n",
      "|    policy_gradient_loss | -0.0014      |\n",
      "|    value_loss           | 1.05e-05     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=360000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 10000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+04       |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 360000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011070338 |\n",
      "|    clip_fraction        | 0.0414      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.811      |\n",
      "|    explained_variance   | -0.793      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0115      |\n",
      "|    n_updates            | 1750        |\n",
      "|    policy_gradient_loss | -0.00153    |\n",
      "|    value_loss           | 5.11e-06    |\n",
      "-----------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 154    |\n",
      "|    iterations      | 176    |\n",
      "|    time_elapsed    | 2328   |\n",
      "|    total_timesteps | 360448 |\n",
      "-------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 155         |\n",
      "|    iterations           | 177         |\n",
      "|    time_elapsed         | 2334        |\n",
      "|    total_timesteps      | 362496      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009207076 |\n",
      "|    clip_fraction        | 0.0435      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.857      |\n",
      "|    explained_variance   | 0.838       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0205     |\n",
      "|    n_updates            | 1760        |\n",
      "|    policy_gradient_loss | -0.00732    |\n",
      "|    value_loss           | 4.7e-05     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 155         |\n",
      "|    iterations           | 178         |\n",
      "|    time_elapsed         | 2339        |\n",
      "|    total_timesteps      | 364544      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002751756 |\n",
      "|    clip_fraction        | 0.0402      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.676      |\n",
      "|    explained_variance   | -11.4       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00434     |\n",
      "|    n_updates            | 1770        |\n",
      "|    policy_gradient_loss | -0.00218    |\n",
      "|    value_loss           | 3.55e-06    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 156          |\n",
      "|    iterations           | 179          |\n",
      "|    time_elapsed         | 2345         |\n",
      "|    total_timesteps      | 366592       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038848436 |\n",
      "|    clip_fraction        | 0.0579       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.673       |\n",
      "|    explained_variance   | -29.5        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.000216     |\n",
      "|    n_updates            | 1780         |\n",
      "|    policy_gradient_loss | -0.00275     |\n",
      "|    value_loss           | 1.98e-07     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 156          |\n",
      "|    iterations           | 180          |\n",
      "|    time_elapsed         | 2350         |\n",
      "|    total_timesteps      | 368640       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0057350527 |\n",
      "|    clip_fraction        | 0.101        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.613       |\n",
      "|    explained_variance   | -10.2        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0157      |\n",
      "|    n_updates            | 1790         |\n",
      "|    policy_gradient_loss | -0.00544     |\n",
      "|    value_loss           | 2.72e-07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=370000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 10000.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1e+04        |\n",
      "|    mean_reward          | 0            |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 370000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010804848 |\n",
      "|    clip_fraction        | 0.025        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.618       |\n",
      "|    explained_variance   | -6.51        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.00505      |\n",
      "|    n_updates            | 1800         |\n",
      "|    policy_gradient_loss | -0.0016      |\n",
      "|    value_loss           | 5.32e-07     |\n",
      "------------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 154    |\n",
      "|    iterations      | 181    |\n",
      "|    time_elapsed    | 2399   |\n",
      "|    total_timesteps | 370688 |\n",
      "-------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 155        |\n",
      "|    iterations           | 182        |\n",
      "|    time_elapsed         | 2404       |\n",
      "|    total_timesteps      | 372736     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06520808 |\n",
      "|    clip_fraction        | 0.194      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.883     |\n",
      "|    explained_variance   | 0.918      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0353    |\n",
      "|    n_updates            | 1810       |\n",
      "|    policy_gradient_loss | -0.0107    |\n",
      "|    value_loss           | 6.66e-06   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 155         |\n",
      "|    iterations           | 183         |\n",
      "|    time_elapsed         | 2410        |\n",
      "|    total_timesteps      | 374784      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006612474 |\n",
      "|    clip_fraction        | 0.11        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.986      |\n",
      "|    explained_variance   | -6.95       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00506    |\n",
      "|    n_updates            | 1820        |\n",
      "|    policy_gradient_loss | -0.00474    |\n",
      "|    value_loss           | 3.11e-05    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 155          |\n",
      "|    iterations           | 184          |\n",
      "|    time_elapsed         | 2415         |\n",
      "|    total_timesteps      | 376832       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070867464 |\n",
      "|    clip_fraction        | 0.0657       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.966       |\n",
      "|    explained_variance   | -2.13        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0311       |\n",
      "|    n_updates            | 1830         |\n",
      "|    policy_gradient_loss | -0.00241     |\n",
      "|    value_loss           | 3.68e-08     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 156         |\n",
      "|    iterations           | 185         |\n",
      "|    time_elapsed         | 2421        |\n",
      "|    total_timesteps      | 378880      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011253234 |\n",
      "|    clip_fraction        | 0.107       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.03       |\n",
      "|    explained_variance   | -0.788      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0204      |\n",
      "|    n_updates            | 1840        |\n",
      "|    policy_gradient_loss | -0.00364    |\n",
      "|    value_loss           | 1.72e-08    |\n",
      "-----------------------------------------\n",
      "box reached target\n",
      "Eval num_timesteps=380000, episode_reward=1.03 +/- 2.06\n",
      "Episode length: 8037.40 +/- 3925.20\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 8.04e+03    |\n",
      "|    mean_reward          | 1.03        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 380000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007477752 |\n",
      "|    clip_fraction        | 0.0603      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.02       |\n",
      "|    explained_variance   | -0.203      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0116     |\n",
      "|    n_updates            | 1850        |\n",
      "|    policy_gradient_loss | -0.00334    |\n",
      "|    value_loss           | 3.14e-08    |\n",
      "-----------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 154    |\n",
      "|    iterations      | 186    |\n",
      "|    time_elapsed    | 2460   |\n",
      "|    total_timesteps | 380928 |\n",
      "-------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 155         |\n",
      "|    iterations           | 187         |\n",
      "|    time_elapsed         | 2465        |\n",
      "|    total_timesteps      | 382976      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023895787 |\n",
      "|    clip_fraction        | 0.182       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.12       |\n",
      "|    explained_variance   | 0.736       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0266     |\n",
      "|    n_updates            | 1860        |\n",
      "|    policy_gradient_loss | -0.0142     |\n",
      "|    value_loss           | 1.39e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 155         |\n",
      "|    iterations           | 188         |\n",
      "|    time_elapsed         | 2471        |\n",
      "|    total_timesteps      | 385024      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009644574 |\n",
      "|    clip_fraction        | 0.161       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.11       |\n",
      "|    explained_variance   | -2.62       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0314     |\n",
      "|    n_updates            | 1870        |\n",
      "|    policy_gradient_loss | -0.0111     |\n",
      "|    value_loss           | 3.88e-06    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 156         |\n",
      "|    iterations           | 189         |\n",
      "|    time_elapsed         | 2476        |\n",
      "|    total_timesteps      | 387072      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011424624 |\n",
      "|    clip_fraction        | 0.0907      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.15       |\n",
      "|    explained_variance   | 0.451       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0153      |\n",
      "|    n_updates            | 1880        |\n",
      "|    policy_gradient_loss | -0.00508    |\n",
      "|    value_loss           | 1.75e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 156         |\n",
      "|    iterations           | 190         |\n",
      "|    time_elapsed         | 2482        |\n",
      "|    total_timesteps      | 389120      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015957307 |\n",
      "|    clip_fraction        | 0.155       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.19       |\n",
      "|    explained_variance   | 0.143       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0188      |\n",
      "|    n_updates            | 1890        |\n",
      "|    policy_gradient_loss | -0.0086     |\n",
      "|    value_loss           | 2.82e-07    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=390000, episode_reward=0.02 +/- 0.04\n",
      "Episode length: 10000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+04       |\n",
      "|    mean_reward          | 0.0222      |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 390000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016708871 |\n",
      "|    clip_fraction        | 0.132       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.21       |\n",
      "|    explained_variance   | -0.632      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0242     |\n",
      "|    n_updates            | 1900        |\n",
      "|    policy_gradient_loss | -0.0128     |\n",
      "|    value_loss           | 3.41e-07    |\n",
      "-----------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 154    |\n",
      "|    iterations      | 191    |\n",
      "|    time_elapsed    | 2529   |\n",
      "|    total_timesteps | 391168 |\n",
      "-------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 155         |\n",
      "|    iterations           | 192         |\n",
      "|    time_elapsed         | 2535        |\n",
      "|    total_timesteps      | 393216      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016433131 |\n",
      "|    clip_fraction        | 0.168       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.19       |\n",
      "|    explained_variance   | 0.906       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00514     |\n",
      "|    n_updates            | 1910        |\n",
      "|    policy_gradient_loss | -0.00794    |\n",
      "|    value_loss           | 1.64e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 155         |\n",
      "|    iterations           | 193         |\n",
      "|    time_elapsed         | 2540        |\n",
      "|    total_timesteps      | 395264      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023013651 |\n",
      "|    clip_fraction        | 0.269       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.899      |\n",
      "|    explained_variance   | 0.898       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0298     |\n",
      "|    n_updates            | 1920        |\n",
      "|    policy_gradient_loss | -0.0243     |\n",
      "|    value_loss           | 2.5e-05     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 156         |\n",
      "|    iterations           | 194         |\n",
      "|    time_elapsed         | 2545        |\n",
      "|    total_timesteps      | 397312      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022995884 |\n",
      "|    clip_fraction        | 0.423       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.912      |\n",
      "|    explained_variance   | 0.0937      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0504     |\n",
      "|    n_updates            | 1930        |\n",
      "|    policy_gradient_loss | -0.014      |\n",
      "|    value_loss           | 9.39e-06    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 156         |\n",
      "|    iterations           | 195         |\n",
      "|    time_elapsed         | 2551        |\n",
      "|    total_timesteps      | 399360      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010078605 |\n",
      "|    clip_fraction        | 0.165       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.928      |\n",
      "|    explained_variance   | -0.438      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0327     |\n",
      "|    n_updates            | 1940        |\n",
      "|    policy_gradient_loss | -0.00736    |\n",
      "|    value_loss           | 5.5e-05     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=400000, episode_reward=0.10 +/- 0.19\n",
      "Episode length: 10000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+04       |\n",
      "|    mean_reward          | 0.0963      |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 400000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015475381 |\n",
      "|    clip_fraction        | 0.202       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.992      |\n",
      "|    explained_variance   | -0.136      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0222     |\n",
      "|    n_updates            | 1950        |\n",
      "|    policy_gradient_loss | -0.00685    |\n",
      "|    value_loss           | 7.26e-07    |\n",
      "-----------------------------------------\n",
      "box reached target\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 154    |\n",
      "|    iterations      | 196    |\n",
      "|    time_elapsed    | 2600   |\n",
      "|    total_timesteps | 401408 |\n",
      "-------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 154         |\n",
      "|    iterations           | 197         |\n",
      "|    time_elapsed         | 2605        |\n",
      "|    total_timesteps      | 403456      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009529604 |\n",
      "|    clip_fraction        | 0.0958      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.765      |\n",
      "|    explained_variance   | 0.221       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0143     |\n",
      "|    n_updates            | 1960        |\n",
      "|    policy_gradient_loss | -0.000716   |\n",
      "|    value_loss           | 0.0858      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 155         |\n",
      "|    iterations           | 198         |\n",
      "|    time_elapsed         | 2611        |\n",
      "|    total_timesteps      | 405504      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022687126 |\n",
      "|    clip_fraction        | 0.333       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.1        |\n",
      "|    explained_variance   | 0.463       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00536     |\n",
      "|    n_updates            | 1970        |\n",
      "|    policy_gradient_loss | -0.00969    |\n",
      "|    value_loss           | 2.95e-05    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 155        |\n",
      "|    iterations           | 199        |\n",
      "|    time_elapsed         | 2616       |\n",
      "|    total_timesteps      | 407552     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01518052 |\n",
      "|    clip_fraction        | 0.224      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.12      |\n",
      "|    explained_variance   | -1.33      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0193    |\n",
      "|    n_updates            | 1980       |\n",
      "|    policy_gradient_loss | -0.00751   |\n",
      "|    value_loss           | 6.42e-06   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 156         |\n",
      "|    iterations           | 200         |\n",
      "|    time_elapsed         | 2622        |\n",
      "|    total_timesteps      | 409600      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010713791 |\n",
      "|    clip_fraction        | 0.195       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.13       |\n",
      "|    explained_variance   | 0.336       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00928    |\n",
      "|    n_updates            | 1990        |\n",
      "|    policy_gradient_loss | -0.0111     |\n",
      "|    value_loss           | 3.12e-06    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=410000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 10000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+04       |\n",
      "|    mean_reward          | 0.000196    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 410000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012163803 |\n",
      "|    clip_fraction        | 0.157       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.12       |\n",
      "|    explained_variance   | 0.896       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00195     |\n",
      "|    n_updates            | 2000        |\n",
      "|    policy_gradient_loss | -0.00447    |\n",
      "|    value_loss           | 2.04e-06    |\n",
      "-----------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 154    |\n",
      "|    iterations      | 201    |\n",
      "|    time_elapsed    | 2670   |\n",
      "|    total_timesteps | 411648 |\n",
      "-------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 154         |\n",
      "|    iterations           | 202         |\n",
      "|    time_elapsed         | 2675        |\n",
      "|    total_timesteps      | 413696      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032057222 |\n",
      "|    clip_fraction        | 0.19        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.08       |\n",
      "|    explained_variance   | 0.949       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0571     |\n",
      "|    n_updates            | 2010        |\n",
      "|    policy_gradient_loss | -0.00868    |\n",
      "|    value_loss           | 4.76e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 155         |\n",
      "|    iterations           | 203         |\n",
      "|    time_elapsed         | 2681        |\n",
      "|    total_timesteps      | 415744      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031521935 |\n",
      "|    clip_fraction        | 0.486       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.715      |\n",
      "|    explained_variance   | 0.577       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0234     |\n",
      "|    n_updates            | 2020        |\n",
      "|    policy_gradient_loss | -0.0316     |\n",
      "|    value_loss           | 4.34e-05    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 155        |\n",
      "|    iterations           | 204        |\n",
      "|    time_elapsed         | 2686       |\n",
      "|    total_timesteps      | 417792     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02271384 |\n",
      "|    clip_fraction        | 0.45       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.756     |\n",
      "|    explained_variance   | 0.833      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0496    |\n",
      "|    n_updates            | 2030       |\n",
      "|    policy_gradient_loss | -0.0194    |\n",
      "|    value_loss           | 7.51e-06   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 155         |\n",
      "|    iterations           | 205         |\n",
      "|    time_elapsed         | 2692        |\n",
      "|    total_timesteps      | 419840      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021555737 |\n",
      "|    clip_fraction        | 0.374       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.755      |\n",
      "|    explained_variance   | 0.902       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.039      |\n",
      "|    n_updates            | 2040        |\n",
      "|    policy_gradient_loss | -0.0158     |\n",
      "|    value_loss           | 1.11e-05    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=420000, episode_reward=0.23 +/- 0.29\n",
      "Episode length: 10000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+04       |\n",
      "|    mean_reward          | 0.233       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 420000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017534444 |\n",
      "|    clip_fraction        | 0.261       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.764      |\n",
      "|    explained_variance   | 0.929       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0435     |\n",
      "|    n_updates            | 2050        |\n",
      "|    policy_gradient_loss | -0.0153     |\n",
      "|    value_loss           | 1.18e-06    |\n",
      "-----------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 153    |\n",
      "|    iterations      | 206    |\n",
      "|    time_elapsed    | 2740   |\n",
      "|    total_timesteps | 421888 |\n",
      "-------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 154         |\n",
      "|    iterations           | 207         |\n",
      "|    time_elapsed         | 2745        |\n",
      "|    total_timesteps      | 423936      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013915885 |\n",
      "|    clip_fraction        | 0.162       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.04       |\n",
      "|    explained_variance   | 0.921       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00425    |\n",
      "|    n_updates            | 2060        |\n",
      "|    policy_gradient_loss | -0.0069     |\n",
      "|    value_loss           | 3.55e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 154         |\n",
      "|    iterations           | 208         |\n",
      "|    time_elapsed         | 2751        |\n",
      "|    total_timesteps      | 425984      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012524171 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.04       |\n",
      "|    explained_variance   | -0.00687    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00876     |\n",
      "|    n_updates            | 2070        |\n",
      "|    policy_gradient_loss | -0.0023     |\n",
      "|    value_loss           | 6.16e-06    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 155          |\n",
      "|    iterations           | 209          |\n",
      "|    time_elapsed         | 2757         |\n",
      "|    total_timesteps      | 428032       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068879155 |\n",
      "|    clip_fraction        | 0.0392       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.06        |\n",
      "|    explained_variance   | 0.0403       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.00154      |\n",
      "|    n_updates            | 2080         |\n",
      "|    policy_gradient_loss | 0.00101      |\n",
      "|    value_loss           | 7.08e-06     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=430000, episode_reward=0.01 +/- 0.01\n",
      "Episode length: 10000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+04       |\n",
      "|    mean_reward          | 0.00526     |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 430000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017782222 |\n",
      "|    clip_fraction        | 0.111       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.08       |\n",
      "|    explained_variance   | -0.00662    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0114     |\n",
      "|    n_updates            | 2090        |\n",
      "|    policy_gradient_loss | -0.000664   |\n",
      "|    value_loss           | 6.91e-06    |\n",
      "-----------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 153    |\n",
      "|    iterations      | 210    |\n",
      "|    time_elapsed    | 2804   |\n",
      "|    total_timesteps | 430080 |\n",
      "-------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 153         |\n",
      "|    iterations           | 211         |\n",
      "|    time_elapsed         | 2810        |\n",
      "|    total_timesteps      | 432128      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015020899 |\n",
      "|    clip_fraction        | 0.146       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.06       |\n",
      "|    explained_variance   | 0.0482      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.024      |\n",
      "|    n_updates            | 2100        |\n",
      "|    policy_gradient_loss | -0.00652    |\n",
      "|    value_loss           | 3.04e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 154         |\n",
      "|    iterations           | 212         |\n",
      "|    time_elapsed         | 2815        |\n",
      "|    total_timesteps      | 434176      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016023707 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.808      |\n",
      "|    explained_variance   | 0.93        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0206     |\n",
      "|    n_updates            | 2110        |\n",
      "|    policy_gradient_loss | -0.00831    |\n",
      "|    value_loss           | 0.000122    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 154         |\n",
      "|    iterations           | 213         |\n",
      "|    time_elapsed         | 2821        |\n",
      "|    total_timesteps      | 436224      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017024875 |\n",
      "|    clip_fraction        | 0.3         |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.974      |\n",
      "|    explained_variance   | -0.191      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0277     |\n",
      "|    n_updates            | 2120        |\n",
      "|    policy_gradient_loss | -0.0102     |\n",
      "|    value_loss           | 0.000227    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 155        |\n",
      "|    iterations           | 214        |\n",
      "|    time_elapsed         | 2826       |\n",
      "|    total_timesteps      | 438272     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01412346 |\n",
      "|    clip_fraction        | 0.192      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.965     |\n",
      "|    explained_variance   | -0.0825    |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.00612    |\n",
      "|    n_updates            | 2130       |\n",
      "|    policy_gradient_loss | -0.00898   |\n",
      "|    value_loss           | 0.000173   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=440000, episode_reward=0.10 +/- 0.19\n",
      "Episode length: 10000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+04       |\n",
      "|    mean_reward          | 0.0965      |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 440000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009600532 |\n",
      "|    clip_fraction        | 0.101       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.02       |\n",
      "|    explained_variance   | -0.0591     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0178      |\n",
      "|    n_updates            | 2140        |\n",
      "|    policy_gradient_loss | -0.00285    |\n",
      "|    value_loss           | 5.02e-05    |\n",
      "-----------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 153    |\n",
      "|    iterations      | 215    |\n",
      "|    time_elapsed    | 2874   |\n",
      "|    total_timesteps | 440320 |\n",
      "-------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 153        |\n",
      "|    iterations           | 216        |\n",
      "|    time_elapsed         | 2880       |\n",
      "|    total_timesteps      | 442368     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01798227 |\n",
      "|    clip_fraction        | 0.143      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.01      |\n",
      "|    explained_variance   | 0.966      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.032     |\n",
      "|    n_updates            | 2150       |\n",
      "|    policy_gradient_loss | -0.00664   |\n",
      "|    value_loss           | 0.000212   |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 153          |\n",
      "|    iterations           | 217          |\n",
      "|    time_elapsed         | 2886         |\n",
      "|    total_timesteps      | 444416       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060920143 |\n",
      "|    clip_fraction        | 0.0742       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.998       |\n",
      "|    explained_variance   | -0.107       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.00851      |\n",
      "|    n_updates            | 2160         |\n",
      "|    policy_gradient_loss | -0.00313     |\n",
      "|    value_loss           | 0.000205     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 154         |\n",
      "|    iterations           | 218         |\n",
      "|    time_elapsed         | 2891        |\n",
      "|    total_timesteps      | 446464      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010740167 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.04       |\n",
      "|    explained_variance   | -0.101      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00952     |\n",
      "|    n_updates            | 2170        |\n",
      "|    policy_gradient_loss | -0.00182    |\n",
      "|    value_loss           | 5.73e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 154         |\n",
      "|    iterations           | 219         |\n",
      "|    time_elapsed         | 2897        |\n",
      "|    total_timesteps      | 448512      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012462744 |\n",
      "|    clip_fraction        | 0.118       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.09       |\n",
      "|    explained_variance   | -0.0673     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0105     |\n",
      "|    n_updates            | 2180        |\n",
      "|    policy_gradient_loss | -0.000447   |\n",
      "|    value_loss           | 3.7e-05     |\n",
      "-----------------------------------------\n",
      "box reached target\n",
      "Eval num_timesteps=450000, episode_reward=1.06 +/- 2.12\n",
      "Episode length: 8061.80 +/- 3876.40\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 8.06e+03    |\n",
      "|    mean_reward          | 1.06        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 450000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015037151 |\n",
      "|    clip_fraction        | 0.0683      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.09       |\n",
      "|    explained_variance   | -0.179      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00645    |\n",
      "|    n_updates            | 2190        |\n",
      "|    policy_gradient_loss | -0.00109    |\n",
      "|    value_loss           | 3.02e-05    |\n",
      "-----------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 153    |\n",
      "|    iterations      | 220    |\n",
      "|    time_elapsed    | 2936   |\n",
      "|    total_timesteps | 450560 |\n",
      "-------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 153         |\n",
      "|    iterations           | 221         |\n",
      "|    time_elapsed         | 2942        |\n",
      "|    total_timesteps      | 452608      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020310696 |\n",
      "|    clip_fraction        | 0.292       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.07       |\n",
      "|    explained_variance   | 0.713       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0192      |\n",
      "|    n_updates            | 2200        |\n",
      "|    policy_gradient_loss | -0.00683    |\n",
      "|    value_loss           | 0.000102    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 154         |\n",
      "|    iterations           | 222         |\n",
      "|    time_elapsed         | 2948        |\n",
      "|    total_timesteps      | 454656      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022008426 |\n",
      "|    clip_fraction        | 0.384       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.19       |\n",
      "|    explained_variance   | -0.378      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.018      |\n",
      "|    n_updates            | 2210        |\n",
      "|    policy_gradient_loss | -0.0163     |\n",
      "|    value_loss           | 1.57e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 154         |\n",
      "|    iterations           | 223         |\n",
      "|    time_elapsed         | 2953        |\n",
      "|    total_timesteps      | 456704      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018495016 |\n",
      "|    clip_fraction        | 0.303       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.19       |\n",
      "|    explained_variance   | -0.703      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0331     |\n",
      "|    n_updates            | 2220        |\n",
      "|    policy_gradient_loss | -0.00989    |\n",
      "|    value_loss           | 1.31e-05    |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 155       |\n",
      "|    iterations           | 224       |\n",
      "|    time_elapsed         | 2959      |\n",
      "|    total_timesteps      | 458752    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0126338 |\n",
      "|    clip_fraction        | 0.176     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -1.25     |\n",
      "|    explained_variance   | 0.455     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.0213    |\n",
      "|    n_updates            | 2230      |\n",
      "|    policy_gradient_loss | -0.00836  |\n",
      "|    value_loss           | 6.45e-06  |\n",
      "---------------------------------------\n",
      "box reached target\n",
      "Eval num_timesteps=460000, episode_reward=1.23 +/- 2.47\n",
      "Episode length: 8534.80 +/- 2930.40\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 8.53e+03    |\n",
      "|    mean_reward          | 1.23        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 460000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013298288 |\n",
      "|    clip_fraction        | 0.166       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.21       |\n",
      "|    explained_variance   | 0.74        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0197     |\n",
      "|    n_updates            | 2240        |\n",
      "|    policy_gradient_loss | -0.00567    |\n",
      "|    value_loss           | 2.33e-06    |\n",
      "-----------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 153    |\n",
      "|    iterations      | 225    |\n",
      "|    time_elapsed    | 3000   |\n",
      "|    total_timesteps | 460800 |\n",
      "-------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 153        |\n",
      "|    iterations           | 226        |\n",
      "|    time_elapsed         | 3005       |\n",
      "|    total_timesteps      | 462848     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03088487 |\n",
      "|    clip_fraction        | 0.144      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.12      |\n",
      "|    explained_variance   | 0.937      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0358    |\n",
      "|    n_updates            | 2250       |\n",
      "|    policy_gradient_loss | -0.0104    |\n",
      "|    value_loss           | 4.1e-05    |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 154         |\n",
      "|    iterations           | 227         |\n",
      "|    time_elapsed         | 3011        |\n",
      "|    total_timesteps      | 464896      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007026007 |\n",
      "|    clip_fraction        | 0.0666      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.959      |\n",
      "|    explained_variance   | -0.000726   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0186     |\n",
      "|    n_updates            | 2260        |\n",
      "|    policy_gradient_loss | -0.00311    |\n",
      "|    value_loss           | 1.21e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 154         |\n",
      "|    iterations           | 228         |\n",
      "|    time_elapsed         | 3017        |\n",
      "|    total_timesteps      | 466944      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004106352 |\n",
      "|    clip_fraction        | 0.0738      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.875      |\n",
      "|    explained_variance   | -0.00747    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00367     |\n",
      "|    n_updates            | 2270        |\n",
      "|    policy_gradient_loss | -0.00106    |\n",
      "|    value_loss           | 6.85e-06    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 155         |\n",
      "|    iterations           | 229         |\n",
      "|    time_elapsed         | 3022        |\n",
      "|    total_timesteps      | 468992      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013831861 |\n",
      "|    clip_fraction        | 0.0486      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.929      |\n",
      "|    explained_variance   | -0.00505    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0108     |\n",
      "|    n_updates            | 2280        |\n",
      "|    policy_gradient_loss | -0.00163    |\n",
      "|    value_loss           | 6.41e-06    |\n",
      "-----------------------------------------\n",
      "box reached target\n",
      "Eval num_timesteps=470000, episode_reward=1.24 +/- 2.46\n",
      "Episode length: 8536.80 +/- 2926.40\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 8.54e+03    |\n",
      "|    mean_reward          | 1.24        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 470000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014401856 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.969      |\n",
      "|    explained_variance   | -0.00254    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.026      |\n",
      "|    n_updates            | 2290        |\n",
      "|    policy_gradient_loss | -0.00697    |\n",
      "|    value_loss           | 5.09e-06    |\n",
      "-----------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 153    |\n",
      "|    iterations      | 230    |\n",
      "|    time_elapsed    | 3063   |\n",
      "|    total_timesteps | 471040 |\n",
      "-------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 154         |\n",
      "|    iterations           | 231         |\n",
      "|    time_elapsed         | 3068        |\n",
      "|    total_timesteps      | 473088      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016062092 |\n",
      "|    clip_fraction        | 0.244       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.884      |\n",
      "|    explained_variance   | 0.795       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0116     |\n",
      "|    n_updates            | 2300        |\n",
      "|    policy_gradient_loss | -0.00988    |\n",
      "|    value_loss           | 2.81e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 154         |\n",
      "|    iterations           | 232         |\n",
      "|    time_elapsed         | 3074        |\n",
      "|    total_timesteps      | 475136      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022291169 |\n",
      "|    clip_fraction        | 0.301       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.962      |\n",
      "|    explained_variance   | 0.488       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00953     |\n",
      "|    n_updates            | 2310        |\n",
      "|    policy_gradient_loss | -0.0119     |\n",
      "|    value_loss           | 1.44e-06    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 154         |\n",
      "|    iterations           | 233         |\n",
      "|    time_elapsed         | 3080        |\n",
      "|    total_timesteps      | 477184      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013311051 |\n",
      "|    clip_fraction        | 0.18        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.01       |\n",
      "|    explained_variance   | 0.875       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0361     |\n",
      "|    n_updates            | 2320        |\n",
      "|    policy_gradient_loss | -0.00945    |\n",
      "|    value_loss           | 0.000117    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 155         |\n",
      "|    iterations           | 234         |\n",
      "|    time_elapsed         | 3085        |\n",
      "|    total_timesteps      | 479232      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017404675 |\n",
      "|    clip_fraction        | 0.368       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.957      |\n",
      "|    explained_variance   | 0.662       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00184     |\n",
      "|    n_updates            | 2330        |\n",
      "|    policy_gradient_loss | -0.0174     |\n",
      "|    value_loss           | 3.06e-07    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=480000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 10000.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1e+04        |\n",
      "|    mean_reward          | 0            |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 480000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0055172388 |\n",
      "|    clip_fraction        | 0.103        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.927       |\n",
      "|    explained_variance   | 0.937        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0151      |\n",
      "|    n_updates            | 2340         |\n",
      "|    policy_gradient_loss | -0.00403     |\n",
      "|    value_loss           | 1.19e-06     |\n",
      "------------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 153    |\n",
      "|    iterations      | 235    |\n",
      "|    time_elapsed    | 3134   |\n",
      "|    total_timesteps | 481280 |\n",
      "-------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 153         |\n",
      "|    iterations           | 236         |\n",
      "|    time_elapsed         | 3139        |\n",
      "|    total_timesteps      | 483328      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.047956128 |\n",
      "|    clip_fraction        | 0.175       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.1        |\n",
      "|    explained_variance   | 0.949       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0688      |\n",
      "|    n_updates            | 2350        |\n",
      "|    policy_gradient_loss | -0.0123     |\n",
      "|    value_loss           | 1.67e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 154         |\n",
      "|    iterations           | 237         |\n",
      "|    time_elapsed         | 3145        |\n",
      "|    total_timesteps      | 485376      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028668337 |\n",
      "|    clip_fraction        | 0.209       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.18       |\n",
      "|    explained_variance   | 0.952       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.033      |\n",
      "|    n_updates            | 2360        |\n",
      "|    policy_gradient_loss | -0.00998    |\n",
      "|    value_loss           | 8.31e-06    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 154         |\n",
      "|    iterations           | 238         |\n",
      "|    time_elapsed         | 3151        |\n",
      "|    total_timesteps      | 487424      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011387382 |\n",
      "|    clip_fraction        | 0.0803      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.01       |\n",
      "|    explained_variance   | -8.38       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00789     |\n",
      "|    n_updates            | 2370        |\n",
      "|    policy_gradient_loss | -0.00322    |\n",
      "|    value_loss           | 6.01e-07    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 155          |\n",
      "|    iterations           | 239          |\n",
      "|    time_elapsed         | 3156         |\n",
      "|    total_timesteps      | 489472       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033157538 |\n",
      "|    clip_fraction        | 0.0605       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.03        |\n",
      "|    explained_variance   | -4.13        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.00896     |\n",
      "|    n_updates            | 2380         |\n",
      "|    policy_gradient_loss | -0.00279     |\n",
      "|    value_loss           | 1.47e-05     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=490000, episode_reward=0.02 +/- 0.04\n",
      "Episode length: 10000.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1e+04      |\n",
      "|    mean_reward          | 0.0181     |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 490000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01331239 |\n",
      "|    clip_fraction        | 0.108      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.12      |\n",
      "|    explained_variance   | -1.81      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0284     |\n",
      "|    n_updates            | 2390       |\n",
      "|    policy_gradient_loss | -0.00698   |\n",
      "|    value_loss           | 4.57e-07   |\n",
      "----------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 153    |\n",
      "|    iterations      | 240    |\n",
      "|    time_elapsed    | 3205   |\n",
      "|    total_timesteps | 491520 |\n",
      "-------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 153         |\n",
      "|    iterations           | 241         |\n",
      "|    time_elapsed         | 3210        |\n",
      "|    total_timesteps      | 493568      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016022433 |\n",
      "|    clip_fraction        | 0.123       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.25       |\n",
      "|    explained_variance   | 0.831       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0403     |\n",
      "|    n_updates            | 2400        |\n",
      "|    policy_gradient_loss | -0.0189     |\n",
      "|    value_loss           | 9.73e-06    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 154         |\n",
      "|    iterations           | 242         |\n",
      "|    time_elapsed         | 3216        |\n",
      "|    total_timesteps      | 495616      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031141117 |\n",
      "|    clip_fraction        | 0.473       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.822      |\n",
      "|    explained_variance   | -0.0885     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.026      |\n",
      "|    n_updates            | 2410        |\n",
      "|    policy_gradient_loss | -0.0194     |\n",
      "|    value_loss           | 2.4e-05     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 154         |\n",
      "|    iterations           | 243         |\n",
      "|    time_elapsed         | 3221        |\n",
      "|    total_timesteps      | 497664      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020545565 |\n",
      "|    clip_fraction        | 0.308       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.927      |\n",
      "|    explained_variance   | 0.736       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0107     |\n",
      "|    n_updates            | 2420        |\n",
      "|    policy_gradient_loss | -0.00828    |\n",
      "|    value_loss           | 1.69e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 154         |\n",
      "|    iterations           | 244         |\n",
      "|    time_elapsed         | 3227        |\n",
      "|    total_timesteps      | 499712      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005610601 |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.999      |\n",
      "|    explained_variance   | 0.875       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00577    |\n",
      "|    n_updates            | 2430        |\n",
      "|    policy_gradient_loss | -0.000677   |\n",
      "|    value_loss           | 8.88e-07    |\n",
      "-----------------------------------------\n",
      "box reached target\n",
      "Eval num_timesteps=500000, episode_reward=1.21 +/- 2.40\n",
      "Episode length: 8293.40 +/- 3413.20\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 8.29e+03    |\n",
      "|    mean_reward          | 1.21        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 500000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007234916 |\n",
      "|    clip_fraction        | 0.103       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.04       |\n",
      "|    explained_variance   | -0.953      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.000109   |\n",
      "|    n_updates            | 2440        |\n",
      "|    policy_gradient_loss | -0.00625    |\n",
      "|    value_loss           | 5.29e-07    |\n",
      "-----------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 153    |\n",
      "|    iterations      | 245    |\n",
      "|    time_elapsed    | 3267   |\n",
      "|    total_timesteps | 501760 |\n",
      "-------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 153         |\n",
      "|    iterations           | 246         |\n",
      "|    time_elapsed         | 3272        |\n",
      "|    total_timesteps      | 503808      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012385938 |\n",
      "|    clip_fraction        | 0.181       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.913      |\n",
      "|    explained_variance   | 0.95        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.000713   |\n",
      "|    n_updates            | 2450        |\n",
      "|    policy_gradient_loss | -0.00918    |\n",
      "|    value_loss           | 7.28e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 154         |\n",
      "|    iterations           | 247         |\n",
      "|    time_elapsed         | 3278        |\n",
      "|    total_timesteps      | 505856      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023938814 |\n",
      "|    clip_fraction        | 0.402       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.886      |\n",
      "|    explained_variance   | 0.312       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0163     |\n",
      "|    n_updates            | 2460        |\n",
      "|    policy_gradient_loss | -0.0156     |\n",
      "|    value_loss           | 2.83e-05    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 154          |\n",
      "|    iterations           | 248          |\n",
      "|    time_elapsed         | 3284         |\n",
      "|    total_timesteps      | 507904       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0121154785 |\n",
      "|    clip_fraction        | 0.152        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.892       |\n",
      "|    explained_variance   | 0.532        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.000758    |\n",
      "|    n_updates            | 2470         |\n",
      "|    policy_gradient_loss | -0.0063      |\n",
      "|    value_loss           | 1.31e-05     |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 155        |\n",
      "|    iterations           | 249        |\n",
      "|    time_elapsed         | 3289       |\n",
      "|    total_timesteps      | 509952     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01367369 |\n",
      "|    clip_fraction        | 0.207      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.881     |\n",
      "|    explained_variance   | 0.221      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0244    |\n",
      "|    n_updates            | 2480       |\n",
      "|    policy_gradient_loss | -0.00966   |\n",
      "|    value_loss           | 2.11e-05   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=510000, episode_reward=0.01 +/- 0.01\n",
      "Episode length: 10000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+04       |\n",
      "|    mean_reward          | 0.00592     |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 510000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010215027 |\n",
      "|    clip_fraction        | 0.0677      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.848      |\n",
      "|    explained_variance   | 0.633       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00829    |\n",
      "|    n_updates            | 2490        |\n",
      "|    policy_gradient_loss | -0.00126    |\n",
      "|    value_loss           | 2.76e-05    |\n",
      "-----------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 153    |\n",
      "|    iterations      | 250    |\n",
      "|    time_elapsed    | 3337   |\n",
      "|    total_timesteps | 512000 |\n",
      "-------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 153         |\n",
      "|    iterations           | 251         |\n",
      "|    time_elapsed         | 3342        |\n",
      "|    total_timesteps      | 514048      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029646091 |\n",
      "|    clip_fraction        | 0.0983      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.862      |\n",
      "|    explained_variance   | 0.795       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.041      |\n",
      "|    n_updates            | 2500        |\n",
      "|    policy_gradient_loss | -0.0097     |\n",
      "|    value_loss           | 2.95e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 154         |\n",
      "|    iterations           | 252         |\n",
      "|    time_elapsed         | 3348        |\n",
      "|    total_timesteps      | 516096      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004618792 |\n",
      "|    clip_fraction        | 0.0728      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.683      |\n",
      "|    explained_variance   | -2.84       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00354     |\n",
      "|    n_updates            | 2510        |\n",
      "|    policy_gradient_loss | -0.00287    |\n",
      "|    value_loss           | 1.07e-06    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 154         |\n",
      "|    iterations           | 253         |\n",
      "|    time_elapsed         | 3353        |\n",
      "|    total_timesteps      | 518144      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.047415823 |\n",
      "|    clip_fraction        | 0.0574      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.838      |\n",
      "|    explained_variance   | -1.56       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00726    |\n",
      "|    n_updates            | 2520        |\n",
      "|    policy_gradient_loss | -0.0046     |\n",
      "|    value_loss           | 3.71e-07    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=520000, episode_reward=0.02 +/- 0.05\n",
      "Episode length: 10000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+04       |\n",
      "|    mean_reward          | 0.0225      |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 520000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020933941 |\n",
      "|    clip_fraction        | 0.288       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.1        |\n",
      "|    explained_variance   | 0.858       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0315     |\n",
      "|    n_updates            | 2530        |\n",
      "|    policy_gradient_loss | -0.00631    |\n",
      "|    value_loss           | 6.13e-05    |\n",
      "-----------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 152    |\n",
      "|    iterations      | 254    |\n",
      "|    time_elapsed    | 3402   |\n",
      "|    total_timesteps | 520192 |\n",
      "-------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 153        |\n",
      "|    iterations           | 255        |\n",
      "|    time_elapsed         | 3407       |\n",
      "|    total_timesteps      | 522240     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02043137 |\n",
      "|    clip_fraction        | 0.222      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.2       |\n",
      "|    explained_variance   | 0.849      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0051     |\n",
      "|    n_updates            | 2540       |\n",
      "|    policy_gradient_loss | -0.00571   |\n",
      "|    value_loss           | 3.79e-06   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 153         |\n",
      "|    iterations           | 256         |\n",
      "|    time_elapsed         | 3413        |\n",
      "|    total_timesteps      | 524288      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015942127 |\n",
      "|    clip_fraction        | 0.272       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.05       |\n",
      "|    explained_variance   | 0.345       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0339     |\n",
      "|    n_updates            | 2550        |\n",
      "|    policy_gradient_loss | -0.0093     |\n",
      "|    value_loss           | 1.58e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 153         |\n",
      "|    iterations           | 257         |\n",
      "|    time_elapsed         | 3418        |\n",
      "|    total_timesteps      | 526336      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015372541 |\n",
      "|    clip_fraction        | 0.306       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.08       |\n",
      "|    explained_variance   | 0.188       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0243     |\n",
      "|    n_updates            | 2560        |\n",
      "|    policy_gradient_loss | -0.0122     |\n",
      "|    value_loss           | 1.71e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 154         |\n",
      "|    iterations           | 258         |\n",
      "|    time_elapsed         | 3424        |\n",
      "|    total_timesteps      | 528384      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015055774 |\n",
      "|    clip_fraction        | 0.262       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.17       |\n",
      "|    explained_variance   | 0.393       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0434      |\n",
      "|    n_updates            | 2570        |\n",
      "|    policy_gradient_loss | -0.00417    |\n",
      "|    value_loss           | 2.72e-05    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=530000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 10000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+04       |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 530000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006504174 |\n",
      "|    clip_fraction        | 0.0899      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.21       |\n",
      "|    explained_variance   | 0.498       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0038     |\n",
      "|    n_updates            | 2580        |\n",
      "|    policy_gradient_loss | -0.00358    |\n",
      "|    value_loss           | 3.68e-06    |\n",
      "-----------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 152    |\n",
      "|    iterations      | 259    |\n",
      "|    time_elapsed    | 3471   |\n",
      "|    total_timesteps | 530432 |\n",
      "-------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 153         |\n",
      "|    iterations           | 260         |\n",
      "|    time_elapsed         | 3477        |\n",
      "|    total_timesteps      | 532480      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010812089 |\n",
      "|    clip_fraction        | 0.154       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.17       |\n",
      "|    explained_variance   | 0.902       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0183      |\n",
      "|    n_updates            | 2590        |\n",
      "|    policy_gradient_loss | -0.00473    |\n",
      "|    value_loss           | 2.12e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 153         |\n",
      "|    iterations           | 261         |\n",
      "|    time_elapsed         | 3482        |\n",
      "|    total_timesteps      | 534528      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.043018542 |\n",
      "|    clip_fraction        | 0.166       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.977      |\n",
      "|    explained_variance   | 0.941       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0431      |\n",
      "|    n_updates            | 2600        |\n",
      "|    policy_gradient_loss | -0.0168     |\n",
      "|    value_loss           | 1.83e-05    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 153        |\n",
      "|    iterations           | 262        |\n",
      "|    time_elapsed         | 3488       |\n",
      "|    total_timesteps      | 536576     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01896977 |\n",
      "|    clip_fraction        | 0.32       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.12      |\n",
      "|    explained_variance   | 0.837      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0302    |\n",
      "|    n_updates            | 2610       |\n",
      "|    policy_gradient_loss | -0.00699   |\n",
      "|    value_loss           | 3.71e-05   |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 154          |\n",
      "|    iterations           | 263          |\n",
      "|    time_elapsed         | 3494         |\n",
      "|    total_timesteps      | 538624       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035548164 |\n",
      "|    clip_fraction        | 0.0795       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.02        |\n",
      "|    explained_variance   | -0.101       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.00694     |\n",
      "|    n_updates            | 2620         |\n",
      "|    policy_gradient_loss | 0.000149     |\n",
      "|    value_loss           | 1.58e-05     |\n",
      "------------------------------------------\n",
      "box reached target\n",
      "Eval num_timesteps=540000, episode_reward=1.11 +/- 2.23\n",
      "Episode length: 8211.80 +/- 3576.40\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 8.21e+03    |\n",
      "|    mean_reward          | 1.11        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 540000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013406535 |\n",
      "|    clip_fraction        | 0.18        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.979      |\n",
      "|    explained_variance   | -0.588      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0742      |\n",
      "|    n_updates            | 2630        |\n",
      "|    policy_gradient_loss | -0.00571    |\n",
      "|    value_loss           | 3.3e-05     |\n",
      "-----------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 152    |\n",
      "|    iterations      | 264    |\n",
      "|    time_elapsed    | 3534   |\n",
      "|    total_timesteps | 540672 |\n",
      "-------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 153         |\n",
      "|    iterations           | 265         |\n",
      "|    time_elapsed         | 3539        |\n",
      "|    total_timesteps      | 542720      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005964363 |\n",
      "|    clip_fraction        | 0.149       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.956      |\n",
      "|    explained_variance   | 0.634       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0253     |\n",
      "|    n_updates            | 2640        |\n",
      "|    policy_gradient_loss | -0.00837    |\n",
      "|    value_loss           | 3.93e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 153         |\n",
      "|    iterations           | 266         |\n",
      "|    time_elapsed         | 3545        |\n",
      "|    total_timesteps      | 544768      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014589505 |\n",
      "|    clip_fraction        | 0.229       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.909      |\n",
      "|    explained_variance   | 0.87        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0152     |\n",
      "|    n_updates            | 2650        |\n",
      "|    policy_gradient_loss | -0.0123     |\n",
      "|    value_loss           | 1.07e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 153         |\n",
      "|    iterations           | 267         |\n",
      "|    time_elapsed         | 3550        |\n",
      "|    total_timesteps      | 546816      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008669788 |\n",
      "|    clip_fraction        | 0.12        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.957      |\n",
      "|    explained_variance   | 0.932       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00352    |\n",
      "|    n_updates            | 2660        |\n",
      "|    policy_gradient_loss | -0.00217    |\n",
      "|    value_loss           | 2.83e-06    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 154          |\n",
      "|    iterations           | 268          |\n",
      "|    time_elapsed         | 3556         |\n",
      "|    total_timesteps      | 548864       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0102411285 |\n",
      "|    clip_fraction        | 0.0543       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.969       |\n",
      "|    explained_variance   | 0.883        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0389       |\n",
      "|    n_updates            | 2670         |\n",
      "|    policy_gradient_loss | 0.00146      |\n",
      "|    value_loss           | 6.58e-05     |\n",
      "------------------------------------------\n",
      "box reached target\n",
      "Eval num_timesteps=550000, episode_reward=1.02 +/- 2.05\n",
      "Episode length: 8025.20 +/- 3949.60\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 8.03e+03    |\n",
      "|    mean_reward          | 1.02        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 550000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006042156 |\n",
      "|    clip_fraction        | 0.0755      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.98       |\n",
      "|    explained_variance   | 0.797       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0237      |\n",
      "|    n_updates            | 2680        |\n",
      "|    policy_gradient_loss | -0.00123    |\n",
      "|    value_loss           | 3.52e-06    |\n",
      "-----------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 153    |\n",
      "|    iterations      | 269    |\n",
      "|    time_elapsed    | 3595   |\n",
      "|    total_timesteps | 550912 |\n",
      "-------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 153         |\n",
      "|    iterations           | 270         |\n",
      "|    time_elapsed         | 3601        |\n",
      "|    total_timesteps      | 552960      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023785766 |\n",
      "|    clip_fraction        | 0.119       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.874      |\n",
      "|    explained_variance   | 0.827       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0149     |\n",
      "|    n_updates            | 2690        |\n",
      "|    policy_gradient_loss | -0.00772    |\n",
      "|    value_loss           | 1.86e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 153         |\n",
      "|    iterations           | 271         |\n",
      "|    time_elapsed         | 3606        |\n",
      "|    total_timesteps      | 555008      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005878781 |\n",
      "|    clip_fraction        | 0.182       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.947      |\n",
      "|    explained_variance   | 0.935       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0047      |\n",
      "|    n_updates            | 2700        |\n",
      "|    policy_gradient_loss | -0.0103     |\n",
      "|    value_loss           | 9.68e-06    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 154         |\n",
      "|    iterations           | 272         |\n",
      "|    time_elapsed         | 3612        |\n",
      "|    total_timesteps      | 557056      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.001468958 |\n",
      "|    clip_fraction        | 0.115       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.883      |\n",
      "|    explained_variance   | 0.927       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00378    |\n",
      "|    n_updates            | 2710        |\n",
      "|    policy_gradient_loss | -0.000562   |\n",
      "|    value_loss           | 8.79e-06    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 154         |\n",
      "|    iterations           | 273         |\n",
      "|    time_elapsed         | 3618        |\n",
      "|    total_timesteps      | 559104      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027618267 |\n",
      "|    clip_fraction        | 0.527       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.79       |\n",
      "|    explained_variance   | 0.334       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0319     |\n",
      "|    n_updates            | 2720        |\n",
      "|    policy_gradient_loss | -0.0224     |\n",
      "|    value_loss           | 3.01e-05    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=560000, episode_reward=0.09 +/- 0.18\n",
      "Episode length: 10000.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1e+04      |\n",
      "|    mean_reward          | 0.0941     |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 560000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02213691 |\n",
      "|    clip_fraction        | 0.413      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.789     |\n",
      "|    explained_variance   | 0.644      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0145    |\n",
      "|    n_updates            | 2730       |\n",
      "|    policy_gradient_loss | -0.014     |\n",
      "|    value_loss           | 2.24e-06   |\n",
      "----------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 153    |\n",
      "|    iterations      | 274    |\n",
      "|    time_elapsed    | 3665   |\n",
      "|    total_timesteps | 561152 |\n",
      "-------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 153         |\n",
      "|    iterations           | 275         |\n",
      "|    time_elapsed         | 3670        |\n",
      "|    total_timesteps      | 563200      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013384832 |\n",
      "|    clip_fraction        | 0.109       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.08       |\n",
      "|    explained_variance   | 0.928       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0168     |\n",
      "|    n_updates            | 2740        |\n",
      "|    policy_gradient_loss | -0.00634    |\n",
      "|    value_loss           | 2.86e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 153         |\n",
      "|    iterations           | 276         |\n",
      "|    time_elapsed         | 3676        |\n",
      "|    total_timesteps      | 565248      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014059337 |\n",
      "|    clip_fraction        | 0.106       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.08       |\n",
      "|    explained_variance   | 0.946       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0403      |\n",
      "|    n_updates            | 2750        |\n",
      "|    policy_gradient_loss | -0.0122     |\n",
      "|    value_loss           | 1.47e-05    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 154          |\n",
      "|    iterations           | 277          |\n",
      "|    time_elapsed         | 3682         |\n",
      "|    total_timesteps      | 567296       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0056489413 |\n",
      "|    clip_fraction        | 0.159        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.14        |\n",
      "|    explained_variance   | 0.914        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0116      |\n",
      "|    n_updates            | 2760         |\n",
      "|    policy_gradient_loss | -0.00475     |\n",
      "|    value_loss           | 0.00013      |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 154         |\n",
      "|    iterations           | 278         |\n",
      "|    time_elapsed         | 3687        |\n",
      "|    total_timesteps      | 569344      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016383782 |\n",
      "|    clip_fraction        | 0.337       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.13       |\n",
      "|    explained_variance   | 0.284       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0128      |\n",
      "|    n_updates            | 2770        |\n",
      "|    policy_gradient_loss | -0.0116     |\n",
      "|    value_loss           | 8.38e-06    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=570000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 10000.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1e+04      |\n",
      "|    mean_reward          | 0          |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 570000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01666535 |\n",
      "|    clip_fraction        | 0.225      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.11      |\n",
      "|    explained_variance   | 0.479      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0225    |\n",
      "|    n_updates            | 2780       |\n",
      "|    policy_gradient_loss | -0.0104    |\n",
      "|    value_loss           | 9.01e-06   |\n",
      "----------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 152    |\n",
      "|    iterations      | 279    |\n",
      "|    time_elapsed    | 3735   |\n",
      "|    total_timesteps | 571392 |\n",
      "-------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 153        |\n",
      "|    iterations           | 280        |\n",
      "|    time_elapsed         | 3740       |\n",
      "|    total_timesteps      | 573440     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02232564 |\n",
      "|    clip_fraction        | 0.179      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.972     |\n",
      "|    explained_variance   | 0.895      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0696    |\n",
      "|    n_updates            | 2790       |\n",
      "|    policy_gradient_loss | -0.0142    |\n",
      "|    value_loss           | 3.56e-05   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 153         |\n",
      "|    iterations           | 281         |\n",
      "|    time_elapsed         | 3746        |\n",
      "|    total_timesteps      | 575488      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022477182 |\n",
      "|    clip_fraction        | 0.291       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.886      |\n",
      "|    explained_variance   | 0.868       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0202     |\n",
      "|    n_updates            | 2800        |\n",
      "|    policy_gradient_loss | -0.00846    |\n",
      "|    value_loss           | 2.8e-05     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 153         |\n",
      "|    iterations           | 282         |\n",
      "|    time_elapsed         | 3751        |\n",
      "|    total_timesteps      | 577536      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007006867 |\n",
      "|    clip_fraction        | 0.0559      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.89       |\n",
      "|    explained_variance   | 0.962       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0249     |\n",
      "|    n_updates            | 2810        |\n",
      "|    policy_gradient_loss | -0.00264    |\n",
      "|    value_loss           | 6.37e-07    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 154        |\n",
      "|    iterations           | 283        |\n",
      "|    time_elapsed         | 3757       |\n",
      "|    total_timesteps      | 579584     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00982345 |\n",
      "|    clip_fraction        | 0.0542     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.879     |\n",
      "|    explained_variance   | 0.788      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0186    |\n",
      "|    n_updates            | 2820       |\n",
      "|    policy_gradient_loss | -0.00203   |\n",
      "|    value_loss           | 5.33e-05   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=580000, episode_reward=0.01 +/- 0.02\n",
      "Episode length: 10000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+04       |\n",
      "|    mean_reward          | 0.00782     |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 580000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011091825 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.835      |\n",
      "|    explained_variance   | 0.859       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00278    |\n",
      "|    n_updates            | 2830        |\n",
      "|    policy_gradient_loss | -0.00594    |\n",
      "|    value_loss           | 2.71e-07    |\n",
      "-----------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 152    |\n",
      "|    iterations      | 284    |\n",
      "|    time_elapsed    | 3804   |\n",
      "|    total_timesteps | 581632 |\n",
      "-------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 153        |\n",
      "|    iterations           | 285        |\n",
      "|    time_elapsed         | 3810       |\n",
      "|    total_timesteps      | 583680     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01615646 |\n",
      "|    clip_fraction        | 0.177      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.19      |\n",
      "|    explained_variance   | 0.905      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0137    |\n",
      "|    n_updates            | 2840       |\n",
      "|    policy_gradient_loss | -0.0108    |\n",
      "|    value_loss           | 3.79e-05   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 153         |\n",
      "|    iterations           | 286         |\n",
      "|    time_elapsed         | 3815        |\n",
      "|    total_timesteps      | 585728      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007411452 |\n",
      "|    clip_fraction        | 0.114       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.22       |\n",
      "|    explained_variance   | 0.384       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0485      |\n",
      "|    n_updates            | 2850        |\n",
      "|    policy_gradient_loss | -0.00824    |\n",
      "|    value_loss           | 8.15e-06    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 153          |\n",
      "|    iterations           | 287          |\n",
      "|    time_elapsed         | 3821         |\n",
      "|    total_timesteps      | 587776       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0057380637 |\n",
      "|    clip_fraction        | 0.0291       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.2         |\n",
      "|    explained_variance   | -0.154       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0167      |\n",
      "|    n_updates            | 2860         |\n",
      "|    policy_gradient_loss | -3.16e-05    |\n",
      "|    value_loss           | 1.31e-05     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 154          |\n",
      "|    iterations           | 288          |\n",
      "|    time_elapsed         | 3827         |\n",
      "|    total_timesteps      | 589824       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063658897 |\n",
      "|    clip_fraction        | 0.0557       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.24        |\n",
      "|    explained_variance   | -0.172       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0259      |\n",
      "|    n_updates            | 2870         |\n",
      "|    policy_gradient_loss | -0.00125     |\n",
      "|    value_loss           | 6.39e-06     |\n",
      "------------------------------------------\n",
      "box reached target\n",
      "box reached target\n",
      "Eval num_timesteps=590000, episode_reward=2.20 +/- 2.40\n",
      "Episode length: 6092.40 +/- 4786.22\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 6.09e+03     |\n",
      "|    mean_reward          | 2.2          |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 590000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0146768745 |\n",
      "|    clip_fraction        | 0.139        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.31        |\n",
      "|    explained_variance   | -0.197       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0163      |\n",
      "|    n_updates            | 2880         |\n",
      "|    policy_gradient_loss | -0.0139      |\n",
      "|    value_loss           | 7.24e-06     |\n",
      "------------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 153    |\n",
      "|    iterations      | 289    |\n",
      "|    time_elapsed    | 3858   |\n",
      "|    total_timesteps | 591872 |\n",
      "-------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 153         |\n",
      "|    iterations           | 290         |\n",
      "|    time_elapsed         | 3864        |\n",
      "|    total_timesteps      | 593920      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012476178 |\n",
      "|    clip_fraction        | 0.185       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.14       |\n",
      "|    explained_variance   | 0.885       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0432     |\n",
      "|    n_updates            | 2890        |\n",
      "|    policy_gradient_loss | -0.0148     |\n",
      "|    value_loss           | 2.47e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 154         |\n",
      "|    iterations           | 291         |\n",
      "|    time_elapsed         | 3869        |\n",
      "|    total_timesteps      | 595968      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005463653 |\n",
      "|    clip_fraction        | 0.0687      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.1        |\n",
      "|    explained_variance   | 0.934       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0038      |\n",
      "|    n_updates            | 2900        |\n",
      "|    policy_gradient_loss | -0.00346    |\n",
      "|    value_loss           | 1.42e-06    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 154         |\n",
      "|    iterations           | 292         |\n",
      "|    time_elapsed         | 3875        |\n",
      "|    total_timesteps      | 598016      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019734276 |\n",
      "|    clip_fraction        | 0.379       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.13       |\n",
      "|    explained_variance   | -5.12       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0285     |\n",
      "|    n_updates            | 2910        |\n",
      "|    policy_gradient_loss | -0.0145     |\n",
      "|    value_loss           | 6.37e-07    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=600000, episode_reward=0.04 +/- 0.10\n",
      "Episode length: 10000.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1e+04        |\n",
      "|    mean_reward          | 0.0394       |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 600000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0046092905 |\n",
      "|    clip_fraction        | 0.0595       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.07        |\n",
      "|    explained_variance   | -4.32        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.00736     |\n",
      "|    n_updates            | 2920         |\n",
      "|    policy_gradient_loss | -0.00299     |\n",
      "|    value_loss           | 0.000126     |\n",
      "------------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 152    |\n",
      "|    iterations      | 293    |\n",
      "|    time_elapsed    | 3923   |\n",
      "|    total_timesteps | 600064 |\n",
      "-------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 153         |\n",
      "|    iterations           | 294         |\n",
      "|    time_elapsed         | 3928        |\n",
      "|    total_timesteps      | 602112      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005573973 |\n",
      "|    clip_fraction        | 0.0419      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.06       |\n",
      "|    explained_variance   | 0.916       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0329     |\n",
      "|    n_updates            | 2930        |\n",
      "|    policy_gradient_loss | -0.00546    |\n",
      "|    value_loss           | 2.5e-06     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 153         |\n",
      "|    iterations           | 295         |\n",
      "|    time_elapsed         | 3934        |\n",
      "|    total_timesteps      | 604160      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016969085 |\n",
      "|    clip_fraction        | 0.247       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.18       |\n",
      "|    explained_variance   | 0.927       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0236     |\n",
      "|    n_updates            | 2940        |\n",
      "|    policy_gradient_loss | -0.00832    |\n",
      "|    value_loss           | 1.08e-05    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 153        |\n",
      "|    iterations           | 296        |\n",
      "|    time_elapsed         | 3939       |\n",
      "|    total_timesteps      | 606208     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01273761 |\n",
      "|    clip_fraction        | 0.128      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.907     |\n",
      "|    explained_variance   | 0.774      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0239    |\n",
      "|    n_updates            | 2950       |\n",
      "|    policy_gradient_loss | -0.00388   |\n",
      "|    value_loss           | 2.24e-05   |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 154          |\n",
      "|    iterations           | 297          |\n",
      "|    time_elapsed         | 3945         |\n",
      "|    total_timesteps      | 608256       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0048476635 |\n",
      "|    clip_fraction        | 0.06         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.933       |\n",
      "|    explained_variance   | 0.793        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.00541      |\n",
      "|    n_updates            | 2960         |\n",
      "|    policy_gradient_loss | -0.000735    |\n",
      "|    value_loss           | 3.76e-05     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=610000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 10000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+04       |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 610000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005764612 |\n",
      "|    clip_fraction        | 0.0834      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.911      |\n",
      "|    explained_variance   | 0.557       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.000134    |\n",
      "|    n_updates            | 2970        |\n",
      "|    policy_gradient_loss | -0.000523   |\n",
      "|    value_loss           | 3.27e-06    |\n",
      "-----------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 152    |\n",
      "|    iterations      | 298    |\n",
      "|    time_elapsed    | 3992   |\n",
      "|    total_timesteps | 610304 |\n",
      "-------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 153         |\n",
      "|    iterations           | 299         |\n",
      "|    time_elapsed         | 3998        |\n",
      "|    total_timesteps      | 612352      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017385848 |\n",
      "|    clip_fraction        | 0.0591      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.971      |\n",
      "|    explained_variance   | 0.835       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0941      |\n",
      "|    n_updates            | 2980        |\n",
      "|    policy_gradient_loss | -0.00179    |\n",
      "|    value_loss           | 8.1e-06     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 153         |\n",
      "|    iterations           | 300         |\n",
      "|    time_elapsed         | 4003        |\n",
      "|    total_timesteps      | 614400      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020663552 |\n",
      "|    clip_fraction        | 0.256       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.28       |\n",
      "|    explained_variance   | 0.0971      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0491     |\n",
      "|    n_updates            | 2990        |\n",
      "|    policy_gradient_loss | -0.0131     |\n",
      "|    value_loss           | 1.51e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 153         |\n",
      "|    iterations           | 301         |\n",
      "|    time_elapsed         | 4009        |\n",
      "|    total_timesteps      | 616448      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014864199 |\n",
      "|    clip_fraction        | 0.15        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.34       |\n",
      "|    explained_variance   | 0.932       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0153     |\n",
      "|    n_updates            | 3000        |\n",
      "|    policy_gradient_loss | -0.00871    |\n",
      "|    value_loss           | 6.51e-06    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 154        |\n",
      "|    iterations           | 302        |\n",
      "|    time_elapsed         | 4014       |\n",
      "|    total_timesteps      | 618496     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01094254 |\n",
      "|    clip_fraction        | 0.147      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.31      |\n",
      "|    explained_variance   | 0.943      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0159    |\n",
      "|    n_updates            | 3010       |\n",
      "|    policy_gradient_loss | -0.00683   |\n",
      "|    value_loss           | 2.69e-06   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=620000, episode_reward=0.01 +/- 0.02\n",
      "Episode length: 10000.00 +/- 0.00\n",
      "---------------------------------------\n",
      "| eval/                   |           |\n",
      "|    mean_ep_length       | 1e+04     |\n",
      "|    mean_reward          | 0.0146    |\n",
      "| time/                   |           |\n",
      "|    total_timesteps      | 620000    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0796721 |\n",
      "|    clip_fraction        | 0.0735    |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -1.33     |\n",
      "|    explained_variance   | -9.78     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -0.0373   |\n",
      "|    n_updates            | 3020      |\n",
      "|    policy_gradient_loss | -0.00966  |\n",
      "|    value_loss           | 9.33e-07  |\n",
      "---------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 152    |\n",
      "|    iterations      | 303    |\n",
      "|    time_elapsed    | 4061   |\n",
      "|    total_timesteps | 620544 |\n",
      "-------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 153         |\n",
      "|    iterations           | 304         |\n",
      "|    time_elapsed         | 4067        |\n",
      "|    total_timesteps      | 622592      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011827649 |\n",
      "|    clip_fraction        | 0.125       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.23       |\n",
      "|    explained_variance   | 0.77        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00237     |\n",
      "|    n_updates            | 3030        |\n",
      "|    policy_gradient_loss | -0.00484    |\n",
      "|    value_loss           | 2.96e-06    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 153          |\n",
      "|    iterations           | 305          |\n",
      "|    time_elapsed         | 4072         |\n",
      "|    total_timesteps      | 624640       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0146118095 |\n",
      "|    clip_fraction        | 0.212        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.2         |\n",
      "|    explained_variance   | 0.948        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0204      |\n",
      "|    n_updates            | 3040         |\n",
      "|    policy_gradient_loss | -0.00389     |\n",
      "|    value_loss           | 4.42e-06     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 153          |\n",
      "|    iterations           | 306          |\n",
      "|    time_elapsed         | 4078         |\n",
      "|    total_timesteps      | 626688       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0026081163 |\n",
      "|    clip_fraction        | 0.0959       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.18        |\n",
      "|    explained_variance   | -1.56        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.00287     |\n",
      "|    n_updates            | 3050         |\n",
      "|    policy_gradient_loss | -0.000379    |\n",
      "|    value_loss           | 0.000591     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 153         |\n",
      "|    iterations           | 307         |\n",
      "|    time_elapsed         | 4084        |\n",
      "|    total_timesteps      | 628736      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004411035 |\n",
      "|    clip_fraction        | 0.0757      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.17       |\n",
      "|    explained_variance   | -0.289      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0255     |\n",
      "|    n_updates            | 3060        |\n",
      "|    policy_gradient_loss | 0.00137     |\n",
      "|    value_loss           | 1.35e-06    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=630000, episode_reward=0.01 +/- 0.02\n",
      "Episode length: 10000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+04       |\n",
      "|    mean_reward          | 0.0111      |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 630000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012018503 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.15       |\n",
      "|    explained_variance   | -0.495      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0125      |\n",
      "|    n_updates            | 3070        |\n",
      "|    policy_gradient_loss | 0.000234    |\n",
      "|    value_loss           | 4.14e-07    |\n",
      "-----------------------------------------\n",
      "box reached target\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 152    |\n",
      "|    iterations      | 308    |\n",
      "|    time_elapsed    | 4132   |\n",
      "|    total_timesteps | 630784 |\n",
      "-------------------------------\n",
      "box reached target\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 152         |\n",
      "|    iterations           | 309         |\n",
      "|    time_elapsed         | 4137        |\n",
      "|    total_timesteps      | 632832      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009241857 |\n",
      "|    clip_fraction        | 0.0576      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.02       |\n",
      "|    explained_variance   | -0.00749    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00851    |\n",
      "|    n_updates            | 3080        |\n",
      "|    policy_gradient_loss | -0.00503    |\n",
      "|    value_loss           | 0.0216      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 153         |\n",
      "|    iterations           | 310         |\n",
      "|    time_elapsed         | 4143        |\n",
      "|    total_timesteps      | 634880      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013518331 |\n",
      "|    clip_fraction        | 0.132       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.76       |\n",
      "|    explained_variance   | 0.111       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0849      |\n",
      "|    n_updates            | 3090        |\n",
      "|    policy_gradient_loss | -0.00643    |\n",
      "|    value_loss           | 0.0775      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 153         |\n",
      "|    iterations           | 311         |\n",
      "|    time_elapsed         | 4148        |\n",
      "|    total_timesteps      | 636928      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012134319 |\n",
      "|    clip_fraction        | 0.217       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.09       |\n",
      "|    explained_variance   | 0.91        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0125     |\n",
      "|    n_updates            | 3100        |\n",
      "|    policy_gradient_loss | -0.0149     |\n",
      "|    value_loss           | 0.00948     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 153          |\n",
      "|    iterations           | 312          |\n",
      "|    time_elapsed         | 4154         |\n",
      "|    total_timesteps      | 638976       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066819848 |\n",
      "|    clip_fraction        | 0.0728       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.936       |\n",
      "|    explained_variance   | 0.922        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0248      |\n",
      "|    n_updates            | 3110         |\n",
      "|    policy_gradient_loss | -0.00221     |\n",
      "|    value_loss           | 0.000262     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=640000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 10000.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1e+04        |\n",
      "|    mean_reward          | 0            |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 640000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0039092987 |\n",
      "|    clip_fraction        | 0.0702       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.904       |\n",
      "|    explained_variance   | 0.899        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0136      |\n",
      "|    n_updates            | 3120         |\n",
      "|    policy_gradient_loss | -0.00105     |\n",
      "|    value_loss           | 0.000246     |\n",
      "------------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 152    |\n",
      "|    iterations      | 313    |\n",
      "|    time_elapsed    | 4202   |\n",
      "|    total_timesteps | 641024 |\n",
      "-------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 152         |\n",
      "|    iterations           | 314         |\n",
      "|    time_elapsed         | 4207        |\n",
      "|    total_timesteps      | 643072      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017878229 |\n",
      "|    clip_fraction        | 0.235       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.08       |\n",
      "|    explained_variance   | 0.862       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0214     |\n",
      "|    n_updates            | 3130        |\n",
      "|    policy_gradient_loss | -0.0138     |\n",
      "|    value_loss           | 0.00506     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 153         |\n",
      "|    iterations           | 315         |\n",
      "|    time_elapsed         | 4213        |\n",
      "|    total_timesteps      | 645120      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008306131 |\n",
      "|    clip_fraction        | 0.0795      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.24       |\n",
      "|    explained_variance   | -8.32       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0221     |\n",
      "|    n_updates            | 3140        |\n",
      "|    policy_gradient_loss | -0.00168    |\n",
      "|    value_loss           | 0.000147    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 153          |\n",
      "|    iterations           | 316          |\n",
      "|    time_elapsed         | 4219         |\n",
      "|    total_timesteps      | 647168       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060599726 |\n",
      "|    clip_fraction        | 0.0881       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.14        |\n",
      "|    explained_variance   | -5.79        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0236      |\n",
      "|    n_updates            | 3150         |\n",
      "|    policy_gradient_loss | -0.00233     |\n",
      "|    value_loss           | 9.41e-05     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 153         |\n",
      "|    iterations           | 317         |\n",
      "|    time_elapsed         | 4224        |\n",
      "|    total_timesteps      | 649216      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007753362 |\n",
      "|    clip_fraction        | 0.0681      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.1        |\n",
      "|    explained_variance   | -2.51       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00316     |\n",
      "|    n_updates            | 3160        |\n",
      "|    policy_gradient_loss | -0.00114    |\n",
      "|    value_loss           | 9.48e-05    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=650000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 10000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+04       |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 650000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009362513 |\n",
      "|    clip_fraction        | 0.0593      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.09       |\n",
      "|    explained_variance   | -2.18       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00319    |\n",
      "|    n_updates            | 3170        |\n",
      "|    policy_gradient_loss | -0.000296   |\n",
      "|    value_loss           | 5.5e-05     |\n",
      "-----------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 152    |\n",
      "|    iterations      | 318    |\n",
      "|    time_elapsed    | 4272   |\n",
      "|    total_timesteps | 651264 |\n",
      "-------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 152         |\n",
      "|    iterations           | 319         |\n",
      "|    time_elapsed         | 4278        |\n",
      "|    total_timesteps      | 653312      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020480128 |\n",
      "|    clip_fraction        | 0.302       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.14       |\n",
      "|    explained_variance   | 0.923       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0361      |\n",
      "|    n_updates            | 3180        |\n",
      "|    policy_gradient_loss | -0.0228     |\n",
      "|    value_loss           | 0.00173     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 152         |\n",
      "|    iterations           | 320         |\n",
      "|    time_elapsed         | 4283        |\n",
      "|    total_timesteps      | 655360      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019186053 |\n",
      "|    clip_fraction        | 0.152       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.18       |\n",
      "|    explained_variance   | 0.0628      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0137     |\n",
      "|    n_updates            | 3190        |\n",
      "|    policy_gradient_loss | -0.00492    |\n",
      "|    value_loss           | 0.00041     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 153          |\n",
      "|    iterations           | 321          |\n",
      "|    time_elapsed         | 4288         |\n",
      "|    total_timesteps      | 657408       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059641693 |\n",
      "|    clip_fraction        | 0.1          |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.08        |\n",
      "|    explained_variance   | 0.859        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0129       |\n",
      "|    n_updates            | 3200         |\n",
      "|    policy_gradient_loss | -0.000684    |\n",
      "|    value_loss           | 5.22e-05     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 153         |\n",
      "|    iterations           | 322         |\n",
      "|    time_elapsed         | 4294        |\n",
      "|    total_timesteps      | 659456      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017095162 |\n",
      "|    clip_fraction        | 0.158       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.03       |\n",
      "|    explained_variance   | 0.84        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0122     |\n",
      "|    n_updates            | 3210        |\n",
      "|    policy_gradient_loss | -0.00657    |\n",
      "|    value_loss           | 2.94e-05    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=660000, episode_reward=0.04 +/- 0.07\n",
      "Episode length: 10000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+04       |\n",
      "|    mean_reward          | 0.0356      |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 660000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015402908 |\n",
      "|    clip_fraction        | 0.158       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.1        |\n",
      "|    explained_variance   | 0.656       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0314      |\n",
      "|    n_updates            | 3220        |\n",
      "|    policy_gradient_loss | -0.00399    |\n",
      "|    value_loss           | 3.96e-05    |\n",
      "-----------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 152    |\n",
      "|    iterations      | 323    |\n",
      "|    time_elapsed    | 4343   |\n",
      "|    total_timesteps | 661504 |\n",
      "-------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 152         |\n",
      "|    iterations           | 324         |\n",
      "|    time_elapsed         | 4348        |\n",
      "|    total_timesteps      | 663552      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028294357 |\n",
      "|    clip_fraction        | 0.267       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.87       |\n",
      "|    explained_variance   | 0.495       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0454     |\n",
      "|    n_updates            | 3230        |\n",
      "|    policy_gradient_loss | -0.0169     |\n",
      "|    value_loss           | 0.000172    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 152         |\n",
      "|    iterations           | 325         |\n",
      "|    time_elapsed         | 4353        |\n",
      "|    total_timesteps      | 665600      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024077892 |\n",
      "|    clip_fraction        | 0.0854      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.19       |\n",
      "|    explained_variance   | 0.918       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0394     |\n",
      "|    n_updates            | 3240        |\n",
      "|    policy_gradient_loss | -0.00982    |\n",
      "|    value_loss           | 0.000166    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 153          |\n",
      "|    iterations           | 326          |\n",
      "|    time_elapsed         | 4359         |\n",
      "|    total_timesteps      | 667648       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064212037 |\n",
      "|    clip_fraction        | 0.0419       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.15        |\n",
      "|    explained_variance   | 0.899        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0101       |\n",
      "|    n_updates            | 3250         |\n",
      "|    policy_gradient_loss | 0.000424     |\n",
      "|    value_loss           | 4.12e-05     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 153         |\n",
      "|    iterations           | 327         |\n",
      "|    time_elapsed         | 4364        |\n",
      "|    total_timesteps      | 669696      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015958088 |\n",
      "|    clip_fraction        | 0.214       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.22       |\n",
      "|    explained_variance   | 0.777       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00483    |\n",
      "|    n_updates            | 3260        |\n",
      "|    policy_gradient_loss | -0.00714    |\n",
      "|    value_loss           | 2.95e-05    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=670000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 10000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+04       |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 670000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009065002 |\n",
      "|    clip_fraction        | 0.0667      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.23       |\n",
      "|    explained_variance   | 0.928       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00877    |\n",
      "|    n_updates            | 3270        |\n",
      "|    policy_gradient_loss | -0.00186    |\n",
      "|    value_loss           | 0.000127    |\n",
      "-----------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 152    |\n",
      "|    iterations      | 328    |\n",
      "|    time_elapsed    | 4413   |\n",
      "|    total_timesteps | 671744 |\n",
      "-------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 152         |\n",
      "|    iterations           | 329         |\n",
      "|    time_elapsed         | 4418        |\n",
      "|    total_timesteps      | 673792      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008869729 |\n",
      "|    clip_fraction        | 0.13        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.39       |\n",
      "|    explained_variance   | 0.826       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0196     |\n",
      "|    n_updates            | 3280        |\n",
      "|    policy_gradient_loss | -0.0071     |\n",
      "|    value_loss           | 0.000724    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 152        |\n",
      "|    iterations           | 330        |\n",
      "|    time_elapsed         | 4424       |\n",
      "|    total_timesteps      | 675840     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01798469 |\n",
      "|    clip_fraction        | 0.235      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.31      |\n",
      "|    explained_variance   | -2.65      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0109    |\n",
      "|    n_updates            | 3290       |\n",
      "|    policy_gradient_loss | -0.00845   |\n",
      "|    value_loss           | 1.51e-05   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 153         |\n",
      "|    iterations           | 331         |\n",
      "|    time_elapsed         | 4429        |\n",
      "|    total_timesteps      | 677888      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013208499 |\n",
      "|    clip_fraction        | 0.156       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.34       |\n",
      "|    explained_variance   | -0.401      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0345     |\n",
      "|    n_updates            | 3300        |\n",
      "|    policy_gradient_loss | -0.00592    |\n",
      "|    value_loss           | 3.91e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 153         |\n",
      "|    iterations           | 332         |\n",
      "|    time_elapsed         | 4435        |\n",
      "|    total_timesteps      | 679936      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008402788 |\n",
      "|    clip_fraction        | 0.0989      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.33       |\n",
      "|    explained_variance   | 0.698       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0146      |\n",
      "|    n_updates            | 3310        |\n",
      "|    policy_gradient_loss | -0.00495    |\n",
      "|    value_loss           | 8.82e-06    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=680000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 10000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+04       |\n",
      "|    mean_reward          | 0.00222     |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 680000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011644805 |\n",
      "|    clip_fraction        | 0.106       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.31       |\n",
      "|    explained_variance   | 0.831       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0233     |\n",
      "|    n_updates            | 3320        |\n",
      "|    policy_gradient_loss | -0.0025     |\n",
      "|    value_loss           | 1.13e-05    |\n",
      "-----------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 152    |\n",
      "|    iterations      | 333    |\n",
      "|    time_elapsed    | 4484   |\n",
      "|    total_timesteps | 681984 |\n",
      "-------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 152         |\n",
      "|    iterations           | 334         |\n",
      "|    time_elapsed         | 4489        |\n",
      "|    total_timesteps      | 684032      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019511733 |\n",
      "|    clip_fraction        | 0.323       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.36       |\n",
      "|    explained_variance   | 0.534       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0632     |\n",
      "|    n_updates            | 3330        |\n",
      "|    policy_gradient_loss | -0.0196     |\n",
      "|    value_loss           | 4.34e-05    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 152        |\n",
      "|    iterations           | 335        |\n",
      "|    time_elapsed         | 4495       |\n",
      "|    total_timesteps      | 686080     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00714321 |\n",
      "|    clip_fraction        | 0.0635     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.32      |\n",
      "|    explained_variance   | 0.914      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0341    |\n",
      "|    n_updates            | 3340       |\n",
      "|    policy_gradient_loss | -0.00566   |\n",
      "|    value_loss           | 2.04e-05   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 152         |\n",
      "|    iterations           | 336         |\n",
      "|    time_elapsed         | 4500        |\n",
      "|    total_timesteps      | 688128      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018395804 |\n",
      "|    clip_fraction        | 0.155       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.39       |\n",
      "|    explained_variance   | -0.0214     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0221      |\n",
      "|    n_updates            | 3350        |\n",
      "|    policy_gradient_loss | -7.98e-05   |\n",
      "|    value_loss           | 2e-05       |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=690000, episode_reward=0.03 +/- 0.06\n",
      "Episode length: 10000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+04       |\n",
      "|    mean_reward          | 0.0321      |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 690000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009068152 |\n",
      "|    clip_fraction        | 0.14        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.39       |\n",
      "|    explained_variance   | 0.0772      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00169     |\n",
      "|    n_updates            | 3360        |\n",
      "|    policy_gradient_loss | -0.00408    |\n",
      "|    value_loss           | 6.16e-06    |\n",
      "-----------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 151    |\n",
      "|    iterations      | 337    |\n",
      "|    time_elapsed    | 4549   |\n",
      "|    total_timesteps | 690176 |\n",
      "-------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 338         |\n",
      "|    time_elapsed         | 4554        |\n",
      "|    total_timesteps      | 692224      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024484135 |\n",
      "|    clip_fraction        | 0.111       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.35       |\n",
      "|    explained_variance   | 0.976       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0213      |\n",
      "|    n_updates            | 3370        |\n",
      "|    policy_gradient_loss | -0.00217    |\n",
      "|    value_loss           | 2.05e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 152         |\n",
      "|    iterations           | 339         |\n",
      "|    time_elapsed         | 4560        |\n",
      "|    total_timesteps      | 694272      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009359585 |\n",
      "|    clip_fraction        | 0.109       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.27       |\n",
      "|    explained_variance   | 0.907       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0127     |\n",
      "|    n_updates            | 3380        |\n",
      "|    policy_gradient_loss | -0.00792    |\n",
      "|    value_loss           | 0.000101    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 152          |\n",
      "|    iterations           | 340          |\n",
      "|    time_elapsed         | 4565         |\n",
      "|    total_timesteps      | 696320       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061386516 |\n",
      "|    clip_fraction        | 0.0992       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.16        |\n",
      "|    explained_variance   | 0.121        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.00622     |\n",
      "|    n_updates            | 3390         |\n",
      "|    policy_gradient_loss | -0.00322     |\n",
      "|    value_loss           | 6.41e-05     |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 152        |\n",
      "|    iterations           | 341        |\n",
      "|    time_elapsed         | 4571       |\n",
      "|    total_timesteps      | 698368     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00589291 |\n",
      "|    clip_fraction        | 0.132      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.05      |\n",
      "|    explained_variance   | 0.0559     |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.00474    |\n",
      "|    n_updates            | 3400       |\n",
      "|    policy_gradient_loss | -0.00307   |\n",
      "|    value_loss           | 4.17e-05   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=700000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 10000.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1e+04        |\n",
      "|    mean_reward          | 0            |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 700000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0056509487 |\n",
      "|    clip_fraction        | 0.0964       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.894       |\n",
      "|    explained_variance   | 0.066        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0163       |\n",
      "|    n_updates            | 3410         |\n",
      "|    policy_gradient_loss | -7.63e-05    |\n",
      "|    value_loss           | 4.35e-05     |\n",
      "------------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 151    |\n",
      "|    iterations      | 342    |\n",
      "|    time_elapsed    | 4618   |\n",
      "|    total_timesteps | 700416 |\n",
      "-------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 343         |\n",
      "|    time_elapsed         | 4624        |\n",
      "|    total_timesteps      | 702464      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011181855 |\n",
      "|    clip_fraction        | 0.0648      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.884      |\n",
      "|    explained_variance   | 0.945       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0281     |\n",
      "|    n_updates            | 3420        |\n",
      "|    policy_gradient_loss | -0.00803    |\n",
      "|    value_loss           | 0.000165    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 152         |\n",
      "|    iterations           | 344         |\n",
      "|    time_elapsed         | 4629        |\n",
      "|    total_timesteps      | 704512      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016905164 |\n",
      "|    clip_fraction        | 0.21        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.947      |\n",
      "|    explained_variance   | 0.119       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0372     |\n",
      "|    n_updates            | 3430        |\n",
      "|    policy_gradient_loss | -0.00631    |\n",
      "|    value_loss           | 0.000199    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 152         |\n",
      "|    iterations           | 345         |\n",
      "|    time_elapsed         | 4635        |\n",
      "|    total_timesteps      | 706560      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012430451 |\n",
      "|    clip_fraction        | 0.119       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.948      |\n",
      "|    explained_variance   | 0.528       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00437    |\n",
      "|    n_updates            | 3440        |\n",
      "|    policy_gradient_loss | -0.0061     |\n",
      "|    value_loss           | 4.48e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 152         |\n",
      "|    iterations           | 346         |\n",
      "|    time_elapsed         | 4640        |\n",
      "|    total_timesteps      | 708608      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014701604 |\n",
      "|    clip_fraction        | 0.193       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.914      |\n",
      "|    explained_variance   | -0.0165     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0296     |\n",
      "|    n_updates            | 3450        |\n",
      "|    policy_gradient_loss | -0.00511    |\n",
      "|    value_loss           | 5.16e-05    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=710000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 10000.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1e+04        |\n",
      "|    mean_reward          | 0            |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 710000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058689034 |\n",
      "|    clip_fraction        | 0.0693       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.96        |\n",
      "|    explained_variance   | 0.456        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0401      |\n",
      "|    n_updates            | 3460         |\n",
      "|    policy_gradient_loss | -0.00445     |\n",
      "|    value_loss           | 6.42e-05     |\n",
      "------------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 151    |\n",
      "|    iterations      | 347    |\n",
      "|    time_elapsed    | 4689   |\n",
      "|    total_timesteps | 710656 |\n",
      "-------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 348         |\n",
      "|    time_elapsed         | 4694        |\n",
      "|    total_timesteps      | 712704      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025161825 |\n",
      "|    clip_fraction        | 0.103       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.951      |\n",
      "|    explained_variance   | 0.946       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00826    |\n",
      "|    n_updates            | 3470        |\n",
      "|    policy_gradient_loss | -0.00281    |\n",
      "|    value_loss           | 0.000102    |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 152       |\n",
      "|    iterations           | 349       |\n",
      "|    time_elapsed         | 4699      |\n",
      "|    total_timesteps      | 714752    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0131579 |\n",
      "|    clip_fraction        | 0.14      |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.738    |\n",
      "|    explained_variance   | 0.949     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.00312   |\n",
      "|    n_updates            | 3480      |\n",
      "|    policy_gradient_loss | -0.00856  |\n",
      "|    value_loss           | 5.77e-06  |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 152         |\n",
      "|    iterations           | 350         |\n",
      "|    time_elapsed         | 4705        |\n",
      "|    total_timesteps      | 716800      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015642952 |\n",
      "|    clip_fraction        | 0.193       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.05       |\n",
      "|    explained_variance   | 0.923       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0337     |\n",
      "|    n_updates            | 3490        |\n",
      "|    policy_gradient_loss | -0.0109     |\n",
      "|    value_loss           | 7.75e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 152         |\n",
      "|    iterations           | 351         |\n",
      "|    time_elapsed         | 4710        |\n",
      "|    total_timesteps      | 718848      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012671957 |\n",
      "|    clip_fraction        | 0.151       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.33       |\n",
      "|    explained_variance   | 0.795       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0281     |\n",
      "|    n_updates            | 3500        |\n",
      "|    policy_gradient_loss | -0.013      |\n",
      "|    value_loss           | 1.27e-05    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=720000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 10000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+04       |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 720000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012128791 |\n",
      "|    clip_fraction        | 0.086       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.3        |\n",
      "|    explained_variance   | 0.863       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0168      |\n",
      "|    n_updates            | 3510        |\n",
      "|    policy_gradient_loss | -0.00294    |\n",
      "|    value_loss           | 0.000118    |\n",
      "-----------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 151    |\n",
      "|    iterations      | 352    |\n",
      "|    time_elapsed    | 4758   |\n",
      "|    total_timesteps | 720896 |\n",
      "-------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 353         |\n",
      "|    time_elapsed         | 4764        |\n",
      "|    total_timesteps      | 722944      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.039590754 |\n",
      "|    clip_fraction        | 0.197       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.33       |\n",
      "|    explained_variance   | 0.946       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.029       |\n",
      "|    n_updates            | 3520        |\n",
      "|    policy_gradient_loss | -0.0065     |\n",
      "|    value_loss           | 8.73e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 152         |\n",
      "|    iterations           | 354         |\n",
      "|    time_elapsed         | 4769        |\n",
      "|    total_timesteps      | 724992      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004500913 |\n",
      "|    clip_fraction        | 0.065       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.934      |\n",
      "|    explained_variance   | 0.757       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0124     |\n",
      "|    n_updates            | 3530        |\n",
      "|    policy_gradient_loss | -0.00436    |\n",
      "|    value_loss           | 0.000103    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 152         |\n",
      "|    iterations           | 355         |\n",
      "|    time_elapsed         | 4774        |\n",
      "|    total_timesteps      | 727040      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005446433 |\n",
      "|    clip_fraction        | 0.0837      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.875      |\n",
      "|    explained_variance   | -0.228      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0103      |\n",
      "|    n_updates            | 3540        |\n",
      "|    policy_gradient_loss | -0.00315    |\n",
      "|    value_loss           | 2.09e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 152         |\n",
      "|    iterations           | 356         |\n",
      "|    time_elapsed         | 4780        |\n",
      "|    total_timesteps      | 729088      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010493796 |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.978      |\n",
      "|    explained_variance   | -0.168      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00922     |\n",
      "|    n_updates            | 3550        |\n",
      "|    policy_gradient_loss | -0.00389    |\n",
      "|    value_loss           | 1.15e-05    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=730000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 10000.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1e+04        |\n",
      "|    mean_reward          | 0            |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 730000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032356952 |\n",
      "|    clip_fraction        | 0.0906       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.04        |\n",
      "|    explained_variance   | -0.141       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.00694     |\n",
      "|    n_updates            | 3560         |\n",
      "|    policy_gradient_loss | -0.000591    |\n",
      "|    value_loss           | 9.31e-06     |\n",
      "------------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 151    |\n",
      "|    iterations      | 357    |\n",
      "|    time_elapsed    | 4828   |\n",
      "|    total_timesteps | 731136 |\n",
      "-------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 151        |\n",
      "|    iterations           | 358        |\n",
      "|    time_elapsed         | 4833       |\n",
      "|    total_timesteps      | 733184     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.12620549 |\n",
      "|    clip_fraction        | 0.307      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.904     |\n",
      "|    explained_variance   | 0.954      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.137      |\n",
      "|    n_updates            | 3570       |\n",
      "|    policy_gradient_loss | -0.0261    |\n",
      "|    value_loss           | 5.82e-05   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 359         |\n",
      "|    time_elapsed         | 4839        |\n",
      "|    total_timesteps      | 735232      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012855025 |\n",
      "|    clip_fraction        | 0.169       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.23       |\n",
      "|    explained_variance   | 0.953       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.016      |\n",
      "|    n_updates            | 3580        |\n",
      "|    policy_gradient_loss | -0.0122     |\n",
      "|    value_loss           | 5.17e-05    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 152          |\n",
      "|    iterations           | 360          |\n",
      "|    time_elapsed         | 4844         |\n",
      "|    total_timesteps      | 737280       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0033512362 |\n",
      "|    clip_fraction        | 0.0542       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.877       |\n",
      "|    explained_variance   | 0.911        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.00327     |\n",
      "|    n_updates            | 3590         |\n",
      "|    policy_gradient_loss | -0.00211     |\n",
      "|    value_loss           | 4.18e-06     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 152         |\n",
      "|    iterations           | 361         |\n",
      "|    time_elapsed         | 4850        |\n",
      "|    total_timesteps      | 739328      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004549224 |\n",
      "|    clip_fraction        | 0.0657      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.855      |\n",
      "|    explained_variance   | -0.52       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.000757    |\n",
      "|    n_updates            | 3600        |\n",
      "|    policy_gradient_loss | -0.00274    |\n",
      "|    value_loss           | 6.04e-06    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=740000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 10000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+04       |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 740000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005945119 |\n",
      "|    clip_fraction        | 0.095       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.902      |\n",
      "|    explained_variance   | 0.608       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00403    |\n",
      "|    n_updates            | 3610        |\n",
      "|    policy_gradient_loss | -0.0084     |\n",
      "|    value_loss           | 1.2e-05     |\n",
      "-----------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 151    |\n",
      "|    iterations      | 362    |\n",
      "|    time_elapsed    | 4898   |\n",
      "|    total_timesteps | 741376 |\n",
      "-------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 151        |\n",
      "|    iterations           | 363        |\n",
      "|    time_elapsed         | 4904       |\n",
      "|    total_timesteps      | 743424     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.05068545 |\n",
      "|    clip_fraction        | 0.18       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.01      |\n",
      "|    explained_variance   | 0.956      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0211     |\n",
      "|    n_updates            | 3620       |\n",
      "|    policy_gradient_loss | -0.0116    |\n",
      "|    value_loss           | 4.19e-05   |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 151          |\n",
      "|    iterations           | 364          |\n",
      "|    time_elapsed         | 4909         |\n",
      "|    total_timesteps      | 745472       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0058478164 |\n",
      "|    clip_fraction        | 0.0686       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.14        |\n",
      "|    explained_variance   | 0.811        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0252      |\n",
      "|    n_updates            | 3630         |\n",
      "|    policy_gradient_loss | -0.000486    |\n",
      "|    value_loss           | 3.01e-05     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 152          |\n",
      "|    iterations           | 365          |\n",
      "|    time_elapsed         | 4915         |\n",
      "|    total_timesteps      | 747520       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0067273946 |\n",
      "|    clip_fraction        | 0.0869       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.11        |\n",
      "|    explained_variance   | 0.621        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0227      |\n",
      "|    n_updates            | 3640         |\n",
      "|    policy_gradient_loss | -0.00398     |\n",
      "|    value_loss           | 2.21e-05     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 152         |\n",
      "|    iterations           | 366         |\n",
      "|    time_elapsed         | 4920        |\n",
      "|    total_timesteps      | 749568      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011639463 |\n",
      "|    clip_fraction        | 0.145       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.09       |\n",
      "|    explained_variance   | -0.362      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00838    |\n",
      "|    n_updates            | 3650        |\n",
      "|    policy_gradient_loss | -0.00467    |\n",
      "|    value_loss           | 3.64e-06    |\n",
      "-----------------------------------------\n",
      "box reached target\n",
      "box reached target\n",
      "Eval num_timesteps=750000, episode_reward=2.03 +/- 2.47\n",
      "Episode length: 6026.20 +/- 4866.89\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 6.03e+03    |\n",
      "|    mean_reward          | 2.03        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 750000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009970419 |\n",
      "|    clip_fraction        | 0.11        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.05       |\n",
      "|    explained_variance   | -0.377      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00102    |\n",
      "|    n_updates            | 3660        |\n",
      "|    policy_gradient_loss | -0.00316    |\n",
      "|    value_loss           | 1.68e-05    |\n",
      "-----------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 151    |\n",
      "|    iterations      | 367    |\n",
      "|    time_elapsed    | 4952   |\n",
      "|    total_timesteps | 751616 |\n",
      "-------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 152         |\n",
      "|    iterations           | 368         |\n",
      "|    time_elapsed         | 4957        |\n",
      "|    total_timesteps      | 753664      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017575111 |\n",
      "|    clip_fraction        | 0.169       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.875      |\n",
      "|    explained_variance   | 0.894       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.011      |\n",
      "|    n_updates            | 3670        |\n",
      "|    policy_gradient_loss | -0.0126     |\n",
      "|    value_loss           | 8.08e-05    |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 152       |\n",
      "|    iterations           | 369       |\n",
      "|    time_elapsed         | 4962      |\n",
      "|    total_timesteps      | 755712    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0016225 |\n",
      "|    clip_fraction        | 0.0332    |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.503    |\n",
      "|    explained_variance   | -0.0924   |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -0.00211  |\n",
      "|    n_updates            | 3680      |\n",
      "|    policy_gradient_loss | 0.000455  |\n",
      "|    value_loss           | 2.09e-06  |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 152         |\n",
      "|    iterations           | 370         |\n",
      "|    time_elapsed         | 4968        |\n",
      "|    total_timesteps      | 757760      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002923103 |\n",
      "|    clip_fraction        | 0.0566      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.568      |\n",
      "|    explained_variance   | -0.0909     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0021     |\n",
      "|    n_updates            | 3690        |\n",
      "|    policy_gradient_loss | -0.00227    |\n",
      "|    value_loss           | 2.05e-06    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 152         |\n",
      "|    iterations           | 371         |\n",
      "|    time_elapsed         | 4974        |\n",
      "|    total_timesteps      | 759808      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005124579 |\n",
      "|    clip_fraction        | 0.0811      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.629      |\n",
      "|    explained_variance   | -0.179      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0286     |\n",
      "|    n_updates            | 3700        |\n",
      "|    policy_gradient_loss | -0.00252    |\n",
      "|    value_loss           | 1.99e-06    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=760000, episode_reward=0.01 +/- 0.02\n",
      "Episode length: 10000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+04       |\n",
      "|    mean_reward          | 0.0113      |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 760000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002428725 |\n",
      "|    clip_fraction        | 0.0679      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.693      |\n",
      "|    explained_variance   | -0.447      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00209    |\n",
      "|    n_updates            | 3710        |\n",
      "|    policy_gradient_loss | -0.00034    |\n",
      "|    value_loss           | 1.75e-05    |\n",
      "-----------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 151    |\n",
      "|    iterations      | 372    |\n",
      "|    time_elapsed    | 5022   |\n",
      "|    total_timesteps | 761856 |\n",
      "-------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 373         |\n",
      "|    time_elapsed         | 5028        |\n",
      "|    total_timesteps      | 763904      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008134437 |\n",
      "|    clip_fraction        | 0.0422      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.1        |\n",
      "|    explained_variance   | 0.951       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0116     |\n",
      "|    n_updates            | 3720        |\n",
      "|    policy_gradient_loss | -0.000129   |\n",
      "|    value_loss           | 3.36e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 152         |\n",
      "|    iterations           | 374         |\n",
      "|    time_elapsed         | 5033        |\n",
      "|    total_timesteps      | 765952      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009362155 |\n",
      "|    clip_fraction        | 0.167       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.15       |\n",
      "|    explained_variance   | 0.166       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0465     |\n",
      "|    n_updates            | 3730        |\n",
      "|    policy_gradient_loss | -0.00715    |\n",
      "|    value_loss           | 2.41e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 152         |\n",
      "|    iterations           | 375         |\n",
      "|    time_elapsed         | 5039        |\n",
      "|    total_timesteps      | 768000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011296554 |\n",
      "|    clip_fraction        | 0.15        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.17       |\n",
      "|    explained_variance   | -0.312      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0243      |\n",
      "|    n_updates            | 3740        |\n",
      "|    policy_gradient_loss | -0.00866    |\n",
      "|    value_loss           | 1.11e-05    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=770000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 10000.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1e+04      |\n",
      "|    mean_reward          | 0          |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 770000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01089056 |\n",
      "|    clip_fraction        | 0.113      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.16      |\n",
      "|    explained_variance   | 0.0112     |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0118    |\n",
      "|    n_updates            | 3750       |\n",
      "|    policy_gradient_loss | -0.00858   |\n",
      "|    value_loss           | 1.33e-05   |\n",
      "----------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 151    |\n",
      "|    iterations      | 376    |\n",
      "|    time_elapsed    | 5086   |\n",
      "|    total_timesteps | 770048 |\n",
      "-------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 377         |\n",
      "|    time_elapsed         | 5092        |\n",
      "|    total_timesteps      | 772096      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010650937 |\n",
      "|    clip_fraction        | 0.0575      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.13       |\n",
      "|    explained_variance   | 0.533       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0171      |\n",
      "|    n_updates            | 3760        |\n",
      "|    policy_gradient_loss | -0.00604    |\n",
      "|    value_loss           | 5.51e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 378         |\n",
      "|    time_elapsed         | 5097        |\n",
      "|    total_timesteps      | 774144      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013025517 |\n",
      "|    clip_fraction        | 0.208       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.04       |\n",
      "|    explained_variance   | 0.771       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0306     |\n",
      "|    n_updates            | 3770        |\n",
      "|    policy_gradient_loss | -0.0136     |\n",
      "|    value_loss           | 1.73e-05    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 152        |\n",
      "|    iterations           | 379        |\n",
      "|    time_elapsed         | 5103       |\n",
      "|    total_timesteps      | 776192     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00609496 |\n",
      "|    clip_fraction        | 0.109      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.846     |\n",
      "|    explained_variance   | 0.494      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.00405    |\n",
      "|    n_updates            | 3780       |\n",
      "|    policy_gradient_loss | -0.0141    |\n",
      "|    value_loss           | 5.73e-06   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 152         |\n",
      "|    iterations           | 380         |\n",
      "|    time_elapsed         | 5108        |\n",
      "|    total_timesteps      | 778240      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014013443 |\n",
      "|    clip_fraction        | 0.196       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.09       |\n",
      "|    explained_variance   | 0.806       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.036      |\n",
      "|    n_updates            | 3790        |\n",
      "|    policy_gradient_loss | -0.0222     |\n",
      "|    value_loss           | 5.12e-05    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=780000, episode_reward=0.01 +/- 0.02\n",
      "Episode length: 10000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+04       |\n",
      "|    mean_reward          | 0.00915     |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 780000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016950864 |\n",
      "|    clip_fraction        | 0.196       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.22       |\n",
      "|    explained_variance   | 0.847       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00437     |\n",
      "|    n_updates            | 3800        |\n",
      "|    policy_gradient_loss | -0.0215     |\n",
      "|    value_loss           | 0.00015     |\n",
      "-----------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 151    |\n",
      "|    iterations      | 381    |\n",
      "|    time_elapsed    | 5156   |\n",
      "|    total_timesteps | 780288 |\n",
      "-------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 382         |\n",
      "|    time_elapsed         | 5162        |\n",
      "|    total_timesteps      | 782336      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010149258 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.19       |\n",
      "|    explained_variance   | 0.897       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0105     |\n",
      "|    n_updates            | 3810        |\n",
      "|    policy_gradient_loss | -0.00959    |\n",
      "|    value_loss           | 8.04e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 383         |\n",
      "|    time_elapsed         | 5168        |\n",
      "|    total_timesteps      | 784384      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019408468 |\n",
      "|    clip_fraction        | 0.188       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.06       |\n",
      "|    explained_variance   | 0.898       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.018      |\n",
      "|    n_updates            | 3820        |\n",
      "|    policy_gradient_loss | -0.019      |\n",
      "|    value_loss           | 4.09e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 152         |\n",
      "|    iterations           | 384         |\n",
      "|    time_elapsed         | 5173        |\n",
      "|    total_timesteps      | 786432      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017532807 |\n",
      "|    clip_fraction        | 0.145       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.21       |\n",
      "|    explained_variance   | 0.879       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0391     |\n",
      "|    n_updates            | 3830        |\n",
      "|    policy_gradient_loss | -0.0122     |\n",
      "|    value_loss           | 2.26e-05    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 152          |\n",
      "|    iterations           | 385          |\n",
      "|    time_elapsed         | 5179         |\n",
      "|    total_timesteps      | 788480       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061364113 |\n",
      "|    clip_fraction        | 0.0687       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.13        |\n",
      "|    explained_variance   | 0.873        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0104      |\n",
      "|    n_updates            | 3840         |\n",
      "|    policy_gradient_loss | -0.00669     |\n",
      "|    value_loss           | 1.56e-05     |\n",
      "------------------------------------------\n",
      "box reached target\n",
      "Eval num_timesteps=790000, episode_reward=0.98 +/- 2.09\n",
      "Episode length: 9393.60 +/- 1212.80\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 9.39e+03   |\n",
      "|    mean_reward          | 0.976      |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 790000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01215978 |\n",
      "|    clip_fraction        | 0.112      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.01      |\n",
      "|    explained_variance   | 0.899      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.000313  |\n",
      "|    n_updates            | 3850       |\n",
      "|    policy_gradient_loss | -0.0113    |\n",
      "|    value_loss           | 8.29e-06   |\n",
      "----------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 151    |\n",
      "|    iterations      | 386    |\n",
      "|    time_elapsed    | 5224   |\n",
      "|    total_timesteps | 790528 |\n",
      "-------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 387         |\n",
      "|    time_elapsed         | 5229        |\n",
      "|    total_timesteps      | 792576      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005393057 |\n",
      "|    clip_fraction        | 0.0608      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.11       |\n",
      "|    explained_variance   | 0.918       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00861    |\n",
      "|    n_updates            | 3860        |\n",
      "|    policy_gradient_loss | -0.00363    |\n",
      "|    value_loss           | 2.89e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 388         |\n",
      "|    time_elapsed         | 5235        |\n",
      "|    total_timesteps      | 794624      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012821533 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.13       |\n",
      "|    explained_variance   | 0.758       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0423     |\n",
      "|    n_updates            | 3870        |\n",
      "|    policy_gradient_loss | -0.0139     |\n",
      "|    value_loss           | 1.12e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 152         |\n",
      "|    iterations           | 389         |\n",
      "|    time_elapsed         | 5240        |\n",
      "|    total_timesteps      | 796672      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017501874 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.14       |\n",
      "|    explained_variance   | 0.809       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0562     |\n",
      "|    n_updates            | 3880        |\n",
      "|    policy_gradient_loss | -0.0143     |\n",
      "|    value_loss           | 1.39e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 152         |\n",
      "|    iterations           | 390         |\n",
      "|    time_elapsed         | 5246        |\n",
      "|    total_timesteps      | 798720      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008512491 |\n",
      "|    clip_fraction        | 0.0865      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.02       |\n",
      "|    explained_variance   | 0.832       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0408     |\n",
      "|    n_updates            | 3890        |\n",
      "|    policy_gradient_loss | -0.0121     |\n",
      "|    value_loss           | 1.9e-05     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=800000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 10000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+04       |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 800000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021382146 |\n",
      "|    clip_fraction        | 0.119       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.887      |\n",
      "|    explained_variance   | -1.51       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00522     |\n",
      "|    n_updates            | 3900        |\n",
      "|    policy_gradient_loss | -0.00553    |\n",
      "|    value_loss           | 4.47e-06    |\n",
      "-----------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 151    |\n",
      "|    iterations      | 391    |\n",
      "|    time_elapsed    | 5293   |\n",
      "|    total_timesteps | 800768 |\n",
      "-------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 151        |\n",
      "|    iterations           | 392        |\n",
      "|    time_elapsed         | 5298       |\n",
      "|    total_timesteps      | 802816     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04593388 |\n",
      "|    clip_fraction        | 0.201      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1         |\n",
      "|    explained_variance   | 0.859      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.00592    |\n",
      "|    n_updates            | 3910       |\n",
      "|    policy_gradient_loss | -0.00616   |\n",
      "|    value_loss           | 4.81e-05   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 151        |\n",
      "|    iterations           | 393        |\n",
      "|    time_elapsed         | 5304       |\n",
      "|    total_timesteps      | 804864     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00796489 |\n",
      "|    clip_fraction        | 0.1        |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.01      |\n",
      "|    explained_variance   | -0.774     |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0147    |\n",
      "|    n_updates            | 3920       |\n",
      "|    policy_gradient_loss | -0.00489   |\n",
      "|    value_loss           | 2.9e-06    |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 394         |\n",
      "|    time_elapsed         | 5309        |\n",
      "|    total_timesteps      | 806912      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013376335 |\n",
      "|    clip_fraction        | 0.15        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.984      |\n",
      "|    explained_variance   | -0.123      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0387      |\n",
      "|    n_updates            | 3930        |\n",
      "|    policy_gradient_loss | -0.00375    |\n",
      "|    value_loss           | 7.57e-06    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 152         |\n",
      "|    iterations           | 395         |\n",
      "|    time_elapsed         | 5315        |\n",
      "|    total_timesteps      | 808960      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016461443 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.04       |\n",
      "|    explained_variance   | 0.883       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0247     |\n",
      "|    n_updates            | 3940        |\n",
      "|    policy_gradient_loss | -0.0105     |\n",
      "|    value_loss           | 5.27e-06    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=810000, episode_reward=0.23 +/- 0.45\n",
      "Episode length: 10000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+04       |\n",
      "|    mean_reward          | 0.225       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 810000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011843732 |\n",
      "|    clip_fraction        | 0.0678      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.957      |\n",
      "|    explained_variance   | -0.103      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.000845   |\n",
      "|    n_updates            | 3950        |\n",
      "|    policy_gradient_loss | -0.0028     |\n",
      "|    value_loss           | 1.35e-06    |\n",
      "-----------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 151    |\n",
      "|    iterations      | 396    |\n",
      "|    time_elapsed    | 5362   |\n",
      "|    total_timesteps | 811008 |\n",
      "-------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 397         |\n",
      "|    time_elapsed         | 5368        |\n",
      "|    total_timesteps      | 813056      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008611229 |\n",
      "|    clip_fraction        | 0.115       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.02       |\n",
      "|    explained_variance   | 0.914       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.000652    |\n",
      "|    n_updates            | 3960        |\n",
      "|    policy_gradient_loss | -0.00628    |\n",
      "|    value_loss           | 2.46e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 398         |\n",
      "|    time_elapsed         | 5373        |\n",
      "|    total_timesteps      | 815104      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010338424 |\n",
      "|    clip_fraction        | 0.135       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.831      |\n",
      "|    explained_variance   | -3.77       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00134    |\n",
      "|    n_updates            | 3970        |\n",
      "|    policy_gradient_loss | -0.00315    |\n",
      "|    value_loss           | 1.1e-05     |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 151        |\n",
      "|    iterations           | 399        |\n",
      "|    time_elapsed         | 5379       |\n",
      "|    total_timesteps      | 817152     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02824572 |\n",
      "|    clip_fraction        | 0.0462     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.99      |\n",
      "|    explained_variance   | 0.376      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0156     |\n",
      "|    n_updates            | 3980       |\n",
      "|    policy_gradient_loss | -0.00178   |\n",
      "|    value_loss           | 3.64e-06   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 152         |\n",
      "|    iterations           | 400         |\n",
      "|    time_elapsed         | 5385        |\n",
      "|    total_timesteps      | 819200      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007963078 |\n",
      "|    clip_fraction        | 0.0826      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.03       |\n",
      "|    explained_variance   | 0.856       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0397     |\n",
      "|    n_updates            | 3990        |\n",
      "|    policy_gradient_loss | -0.00481    |\n",
      "|    value_loss           | 4.56e-06    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=820000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 10000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+04       |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 820000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013082787 |\n",
      "|    clip_fraction        | 0.11        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.08       |\n",
      "|    explained_variance   | 0.565       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0114     |\n",
      "|    n_updates            | 4000        |\n",
      "|    policy_gradient_loss | -0.00477    |\n",
      "|    value_loss           | 5.48e-05    |\n",
      "-----------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 151    |\n",
      "|    iterations      | 401    |\n",
      "|    time_elapsed    | 5432   |\n",
      "|    total_timesteps | 821248 |\n",
      "-------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 402         |\n",
      "|    time_elapsed         | 5438        |\n",
      "|    total_timesteps      | 823296      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011414874 |\n",
      "|    clip_fraction        | 0.174       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.957      |\n",
      "|    explained_variance   | 0.895       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00923     |\n",
      "|    n_updates            | 4010        |\n",
      "|    policy_gradient_loss | -0.00453    |\n",
      "|    value_loss           | 1.13e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 403         |\n",
      "|    time_elapsed         | 5443        |\n",
      "|    total_timesteps      | 825344      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009500224 |\n",
      "|    clip_fraction        | 0.109       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.934      |\n",
      "|    explained_variance   | 0.846       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0188     |\n",
      "|    n_updates            | 4020        |\n",
      "|    policy_gradient_loss | -0.00338    |\n",
      "|    value_loss           | 9.75e-07    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 404         |\n",
      "|    time_elapsed         | 5449        |\n",
      "|    total_timesteps      | 827392      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006899126 |\n",
      "|    clip_fraction        | 0.0958      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.866      |\n",
      "|    explained_variance   | 0.958       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0247      |\n",
      "|    n_updates            | 4030        |\n",
      "|    policy_gradient_loss | -0.00265    |\n",
      "|    value_loss           | 1.02e-06    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 152          |\n",
      "|    iterations           | 405          |\n",
      "|    time_elapsed         | 5454         |\n",
      "|    total_timesteps      | 829440       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070099756 |\n",
      "|    clip_fraction        | 0.079        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.773       |\n",
      "|    explained_variance   | 0.91         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0175      |\n",
      "|    n_updates            | 4040         |\n",
      "|    policy_gradient_loss | -0.002       |\n",
      "|    value_loss           | 0.000142     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=830000, episode_reward=0.01 +/- 0.03\n",
      "Episode length: 10000.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1e+04        |\n",
      "|    mean_reward          | 0.013        |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 830000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0059668864 |\n",
      "|    clip_fraction        | 0.118        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.777       |\n",
      "|    explained_variance   | -0.317       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0134      |\n",
      "|    n_updates            | 4050         |\n",
      "|    policy_gradient_loss | -0.00321     |\n",
      "|    value_loss           | 2.75e-06     |\n",
      "------------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 151    |\n",
      "|    iterations      | 406    |\n",
      "|    time_elapsed    | 5503   |\n",
      "|    total_timesteps | 831488 |\n",
      "-------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 151        |\n",
      "|    iterations           | 407        |\n",
      "|    time_elapsed         | 5508       |\n",
      "|    total_timesteps      | 833536     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.14347596 |\n",
      "|    clip_fraction        | 0.196      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.925     |\n",
      "|    explained_variance   | 0.947      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.081     |\n",
      "|    n_updates            | 4060       |\n",
      "|    policy_gradient_loss | -0.0167    |\n",
      "|    value_loss           | 1.48e-05   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 151        |\n",
      "|    iterations           | 408        |\n",
      "|    time_elapsed         | 5514       |\n",
      "|    total_timesteps      | 835584     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01976845 |\n",
      "|    clip_fraction        | 0.143      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.2       |\n",
      "|    explained_variance   | 0.812      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0278    |\n",
      "|    n_updates            | 4070       |\n",
      "|    policy_gradient_loss | -0.0139    |\n",
      "|    value_loss           | 9.74e-06   |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 151          |\n",
      "|    iterations           | 409          |\n",
      "|    time_elapsed         | 5519         |\n",
      "|    total_timesteps      | 837632       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0049344795 |\n",
      "|    clip_fraction        | 0.0383       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.908       |\n",
      "|    explained_variance   | 0.94         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0435       |\n",
      "|    n_updates            | 4080         |\n",
      "|    policy_gradient_loss | -0.00198     |\n",
      "|    value_loss           | 6.37e-06     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 151          |\n",
      "|    iterations           | 410          |\n",
      "|    time_elapsed         | 5525         |\n",
      "|    total_timesteps      | 839680       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038783825 |\n",
      "|    clip_fraction        | 0.0456       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.594       |\n",
      "|    explained_variance   | 0.902        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0129      |\n",
      "|    n_updates            | 4090         |\n",
      "|    policy_gradient_loss | -0.00268     |\n",
      "|    value_loss           | 7.5e-06      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=840000, episode_reward=0.05 +/- 0.04\n",
      "Episode length: 10000.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1e+04        |\n",
      "|    mean_reward          | 0.0477       |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 840000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0029926351 |\n",
      "|    clip_fraction        | 0.0514       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.492       |\n",
      "|    explained_variance   | -0.0958      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.00272     |\n",
      "|    n_updates            | 4100         |\n",
      "|    policy_gradient_loss | -0.00216     |\n",
      "|    value_loss           | 3.7e-06      |\n",
      "------------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 151    |\n",
      "|    iterations      | 411    |\n",
      "|    time_elapsed    | 5573   |\n",
      "|    total_timesteps | 841728 |\n",
      "-------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 412         |\n",
      "|    time_elapsed         | 5579        |\n",
      "|    total_timesteps      | 843776      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011365391 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.14       |\n",
      "|    explained_variance   | 0.753       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0204     |\n",
      "|    n_updates            | 4110        |\n",
      "|    policy_gradient_loss | -0.00922    |\n",
      "|    value_loss           | 0.00015     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 413         |\n",
      "|    time_elapsed         | 5584        |\n",
      "|    total_timesteps      | 845824      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013845247 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.32       |\n",
      "|    explained_variance   | 0.841       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0324     |\n",
      "|    n_updates            | 4120        |\n",
      "|    policy_gradient_loss | -0.0136     |\n",
      "|    value_loss           | 1.63e-06    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 414         |\n",
      "|    time_elapsed         | 5590        |\n",
      "|    total_timesteps      | 847872      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009131514 |\n",
      "|    clip_fraction        | 0.111       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.15       |\n",
      "|    explained_variance   | 0.929       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00937    |\n",
      "|    n_updates            | 4130        |\n",
      "|    policy_gradient_loss | -0.0083     |\n",
      "|    value_loss           | 4.02e-06    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 415         |\n",
      "|    time_elapsed         | 5596        |\n",
      "|    total_timesteps      | 849920      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005047635 |\n",
      "|    clip_fraction        | 0.0838      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.09       |\n",
      "|    explained_variance   | 0.697       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0131     |\n",
      "|    n_updates            | 4140        |\n",
      "|    policy_gradient_loss | -0.00301    |\n",
      "|    value_loss           | 3.52e-06    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=850000, episode_reward=0.01 +/- 0.03\n",
      "Episode length: 10000.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1e+04        |\n",
      "|    mean_reward          | 0.0145       |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 850000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073723057 |\n",
      "|    clip_fraction        | 0.119        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.12        |\n",
      "|    explained_variance   | 0.924        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.00865      |\n",
      "|    n_updates            | 4150         |\n",
      "|    policy_gradient_loss | -0.00756     |\n",
      "|    value_loss           | 2.94e-06     |\n",
      "------------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 150    |\n",
      "|    iterations      | 416    |\n",
      "|    time_elapsed    | 5642   |\n",
      "|    total_timesteps | 851968 |\n",
      "-------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 417         |\n",
      "|    time_elapsed         | 5648        |\n",
      "|    total_timesteps      | 854016      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033313382 |\n",
      "|    clip_fraction        | 0.198       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.06       |\n",
      "|    explained_variance   | 0.888       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0355     |\n",
      "|    n_updates            | 4160        |\n",
      "|    policy_gradient_loss | -0.0158     |\n",
      "|    value_loss           | 0.000143    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 418         |\n",
      "|    time_elapsed         | 5654        |\n",
      "|    total_timesteps      | 856064      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020778988 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.04       |\n",
      "|    explained_variance   | 0.872       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00951     |\n",
      "|    n_updates            | 4170        |\n",
      "|    policy_gradient_loss | -0.00467    |\n",
      "|    value_loss           | 3.18e-05    |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 151       |\n",
      "|    iterations           | 419       |\n",
      "|    time_elapsed         | 5659      |\n",
      "|    total_timesteps      | 858112    |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0067233 |\n",
      "|    clip_fraction        | 0.0756    |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -1.06     |\n",
      "|    explained_variance   | -6.2      |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | 0.00583   |\n",
      "|    n_updates            | 4180      |\n",
      "|    policy_gradient_loss | -0.00216  |\n",
      "|    value_loss           | 1.07e-05  |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=860000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 10000.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1e+04      |\n",
      "|    mean_reward          | 0          |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 860000     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02578459 |\n",
      "|    clip_fraction        | 0.104      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.07      |\n",
      "|    explained_variance   | -9.54      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.157      |\n",
      "|    n_updates            | 4190       |\n",
      "|    policy_gradient_loss | -0.00336   |\n",
      "|    value_loss           | 1.04e-06   |\n",
      "----------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 150    |\n",
      "|    iterations      | 420    |\n",
      "|    time_elapsed    | 5706   |\n",
      "|    total_timesteps | 860160 |\n",
      "-------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 150         |\n",
      "|    iterations           | 421         |\n",
      "|    time_elapsed         | 5712        |\n",
      "|    total_timesteps      | 862208      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032107078 |\n",
      "|    clip_fraction        | 0.295       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1          |\n",
      "|    explained_variance   | 0.936       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.037      |\n",
      "|    n_updates            | 4200        |\n",
      "|    policy_gradient_loss | -0.0136     |\n",
      "|    value_loss           | 4.12e-06    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 151        |\n",
      "|    iterations           | 422        |\n",
      "|    time_elapsed         | 5718       |\n",
      "|    total_timesteps      | 864256     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02048735 |\n",
      "|    clip_fraction        | 0.167      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.18      |\n",
      "|    explained_variance   | 0.956      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0322    |\n",
      "|    n_updates            | 4210       |\n",
      "|    policy_gradient_loss | -0.011     |\n",
      "|    value_loss           | 7.18e-05   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 151        |\n",
      "|    iterations           | 423        |\n",
      "|    time_elapsed         | 5723       |\n",
      "|    total_timesteps      | 866304     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01086336 |\n",
      "|    clip_fraction        | 0.0831     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.25      |\n",
      "|    explained_variance   | 0.929      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0248    |\n",
      "|    n_updates            | 4220       |\n",
      "|    policy_gradient_loss | -0.00675   |\n",
      "|    value_loss           | 0.000338   |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 151          |\n",
      "|    iterations           | 424          |\n",
      "|    time_elapsed         | 5728         |\n",
      "|    total_timesteps      | 868352       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070432806 |\n",
      "|    clip_fraction        | 0.095        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.44        |\n",
      "|    explained_variance   | 0.769        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.000204     |\n",
      "|    n_updates            | 4230         |\n",
      "|    policy_gradient_loss | -0.00357     |\n",
      "|    value_loss           | 0.000195     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=870000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 10000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+04       |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 870000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013539679 |\n",
      "|    clip_fraction        | 0.176       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.39       |\n",
      "|    explained_variance   | 0.507       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00525    |\n",
      "|    n_updates            | 4240        |\n",
      "|    policy_gradient_loss | -0.00963    |\n",
      "|    value_loss           | 0.000115    |\n",
      "-----------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 150    |\n",
      "|    iterations      | 425    |\n",
      "|    time_elapsed    | 5775   |\n",
      "|    total_timesteps | 870400 |\n",
      "-------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 150         |\n",
      "|    iterations           | 426         |\n",
      "|    time_elapsed         | 5780        |\n",
      "|    total_timesteps      | 872448      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024873339 |\n",
      "|    clip_fraction        | 0.26        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.35       |\n",
      "|    explained_variance   | 0.912       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0232     |\n",
      "|    n_updates            | 4250        |\n",
      "|    policy_gradient_loss | -0.00619    |\n",
      "|    value_loss           | 0.000429    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 427         |\n",
      "|    time_elapsed         | 5786        |\n",
      "|    total_timesteps      | 874496      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011183261 |\n",
      "|    clip_fraction        | 0.156       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.4        |\n",
      "|    explained_variance   | 0.932       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0279     |\n",
      "|    n_updates            | 4260        |\n",
      "|    policy_gradient_loss | -0.0115     |\n",
      "|    value_loss           | 1.83e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 428         |\n",
      "|    time_elapsed         | 5791        |\n",
      "|    total_timesteps      | 876544      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011519544 |\n",
      "|    clip_fraction        | 0.173       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.46       |\n",
      "|    explained_variance   | -0.6        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0275      |\n",
      "|    n_updates            | 4270        |\n",
      "|    policy_gradient_loss | -0.00969    |\n",
      "|    value_loss           | 8.91e-06    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 429         |\n",
      "|    time_elapsed         | 5796        |\n",
      "|    total_timesteps      | 878592      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014888523 |\n",
      "|    clip_fraction        | 0.218       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.45       |\n",
      "|    explained_variance   | -0.277      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0156     |\n",
      "|    n_updates            | 4280        |\n",
      "|    policy_gradient_loss | -0.00828    |\n",
      "|    value_loss           | 5.54e-06    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=880000, episode_reward=-0.06 +/- 0.11\n",
      "Episode length: 10000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+04       |\n",
      "|    mean_reward          | -0.0555     |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 880000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008210471 |\n",
      "|    clip_fraction        | 0.229       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.44       |\n",
      "|    explained_variance   | 0.347       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00103     |\n",
      "|    n_updates            | 4290        |\n",
      "|    policy_gradient_loss | -0.0083     |\n",
      "|    value_loss           | 3.3e-05     |\n",
      "-----------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 150    |\n",
      "|    iterations      | 430    |\n",
      "|    time_elapsed    | 5844   |\n",
      "|    total_timesteps | 880640 |\n",
      "-------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 150         |\n",
      "|    iterations           | 431         |\n",
      "|    time_elapsed         | 5849        |\n",
      "|    total_timesteps      | 882688      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.041458935 |\n",
      "|    clip_fraction        | 0.214       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.35       |\n",
      "|    explained_variance   | 0.879       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0179      |\n",
      "|    n_updates            | 4300        |\n",
      "|    policy_gradient_loss | -0.00846    |\n",
      "|    value_loss           | 1.42e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 432         |\n",
      "|    time_elapsed         | 5854        |\n",
      "|    total_timesteps      | 884736      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012786062 |\n",
      "|    clip_fraction        | 0.0805      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.07       |\n",
      "|    explained_variance   | 0.963       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0405      |\n",
      "|    n_updates            | 4310        |\n",
      "|    policy_gradient_loss | -0.00452    |\n",
      "|    value_loss           | 5.19e-06    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 433         |\n",
      "|    time_elapsed         | 5860        |\n",
      "|    total_timesteps      | 886784      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014878147 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.2        |\n",
      "|    explained_variance   | 0.972       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0466      |\n",
      "|    n_updates            | 4320        |\n",
      "|    policy_gradient_loss | -0.0152     |\n",
      "|    value_loss           | 2.77e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 434         |\n",
      "|    time_elapsed         | 5865        |\n",
      "|    total_timesteps      | 888832      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015156468 |\n",
      "|    clip_fraction        | 0.276       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.39       |\n",
      "|    explained_variance   | 0.911       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00157     |\n",
      "|    n_updates            | 4330        |\n",
      "|    policy_gradient_loss | -0.0161     |\n",
      "|    value_loss           | 0.00018     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=890000, episode_reward=0.47 +/- 0.60\n",
      "Episode length: 10000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+04       |\n",
      "|    mean_reward          | 0.469       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 890000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008073026 |\n",
      "|    clip_fraction        | 0.13        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1          |\n",
      "|    explained_variance   | 0.89        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00973     |\n",
      "|    n_updates            | 4340        |\n",
      "|    policy_gradient_loss | -0.0054     |\n",
      "|    value_loss           | 2.97e-06    |\n",
      "-----------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 150    |\n",
      "|    iterations      | 435    |\n",
      "|    time_elapsed    | 5914   |\n",
      "|    total_timesteps | 890880 |\n",
      "-------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 150         |\n",
      "|    iterations           | 436         |\n",
      "|    time_elapsed         | 5919        |\n",
      "|    total_timesteps      | 892928      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017138552 |\n",
      "|    clip_fraction        | 0.195       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.821      |\n",
      "|    explained_variance   | 0.877       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.026      |\n",
      "|    n_updates            | 4350        |\n",
      "|    policy_gradient_loss | -0.00985    |\n",
      "|    value_loss           | 6.19e-06    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 437         |\n",
      "|    time_elapsed         | 5925        |\n",
      "|    total_timesteps      | 894976      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011717817 |\n",
      "|    clip_fraction        | 0.118       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.06       |\n",
      "|    explained_variance   | 0.919       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0113     |\n",
      "|    n_updates            | 4360        |\n",
      "|    policy_gradient_loss | -0.00706    |\n",
      "|    value_loss           | 2.85e-06    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 438         |\n",
      "|    time_elapsed         | 5930        |\n",
      "|    total_timesteps      | 897024      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009540656 |\n",
      "|    clip_fraction        | 0.127       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.05       |\n",
      "|    explained_variance   | -2.31       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0117      |\n",
      "|    n_updates            | 4370        |\n",
      "|    policy_gradient_loss | -0.0044     |\n",
      "|    value_loss           | 5.84e-07    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 439         |\n",
      "|    time_elapsed         | 5936        |\n",
      "|    total_timesteps      | 899072      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007209249 |\n",
      "|    clip_fraction        | 0.0869      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.08       |\n",
      "|    explained_variance   | -0.465      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0118     |\n",
      "|    n_updates            | 4380        |\n",
      "|    policy_gradient_loss | -0.00194    |\n",
      "|    value_loss           | 3.67e-06    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=900000, episode_reward=0.03 +/- 0.07\n",
      "Episode length: 10000.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1e+04        |\n",
      "|    mean_reward          | 0.0327       |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 900000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0031767325 |\n",
      "|    clip_fraction        | 0.0422       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.09        |\n",
      "|    explained_variance   | -0.0399      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.00242      |\n",
      "|    n_updates            | 4390         |\n",
      "|    policy_gradient_loss | 0.000376     |\n",
      "|    value_loss           | 1.92e-07     |\n",
      "------------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 150    |\n",
      "|    iterations      | 440    |\n",
      "|    time_elapsed    | 5985   |\n",
      "|    total_timesteps | 901120 |\n",
      "-------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 150         |\n",
      "|    iterations           | 441         |\n",
      "|    time_elapsed         | 5990        |\n",
      "|    total_timesteps      | 903168      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033450004 |\n",
      "|    clip_fraction        | 0.285       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.16       |\n",
      "|    explained_variance   | 0.935       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0106      |\n",
      "|    n_updates            | 4400        |\n",
      "|    policy_gradient_loss | -0.0212     |\n",
      "|    value_loss           | 1.62e-05    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 150          |\n",
      "|    iterations           | 442          |\n",
      "|    time_elapsed         | 5996         |\n",
      "|    total_timesteps      | 905216       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0069510085 |\n",
      "|    clip_fraction        | 0.195        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.27        |\n",
      "|    explained_variance   | -6.72        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0361      |\n",
      "|    n_updates            | 4410         |\n",
      "|    policy_gradient_loss | -0.00565     |\n",
      "|    value_loss           | 1.79e-05     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 443         |\n",
      "|    time_elapsed         | 6001        |\n",
      "|    total_timesteps      | 907264      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015883168 |\n",
      "|    clip_fraction        | 0.21        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.18       |\n",
      "|    explained_variance   | -0.359      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00486    |\n",
      "|    n_updates            | 4420        |\n",
      "|    policy_gradient_loss | -0.00929    |\n",
      "|    value_loss           | 6.21e-06    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 151          |\n",
      "|    iterations           | 444          |\n",
      "|    time_elapsed         | 6007         |\n",
      "|    total_timesteps      | 909312       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0079446165 |\n",
      "|    clip_fraction        | 0.0945       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.18        |\n",
      "|    explained_variance   | 0.759        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.00629      |\n",
      "|    n_updates            | 4430         |\n",
      "|    policy_gradient_loss | -0.0126      |\n",
      "|    value_loss           | 4.11e-05     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=910000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 10000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+04       |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 910000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016875014 |\n",
      "|    clip_fraction        | 0.158       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.17       |\n",
      "|    explained_variance   | 0.583       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0398     |\n",
      "|    n_updates            | 4440        |\n",
      "|    policy_gradient_loss | -0.00565    |\n",
      "|    value_loss           | 5.59e-06    |\n",
      "-----------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 150    |\n",
      "|    iterations      | 445    |\n",
      "|    time_elapsed    | 6054   |\n",
      "|    total_timesteps | 911360 |\n",
      "-------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 150        |\n",
      "|    iterations           | 446        |\n",
      "|    time_elapsed         | 6060       |\n",
      "|    total_timesteps      | 913408     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03444524 |\n",
      "|    clip_fraction        | 0.236      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.1       |\n",
      "|    explained_variance   | 0.947      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0175    |\n",
      "|    n_updates            | 4450       |\n",
      "|    policy_gradient_loss | -0.0142    |\n",
      "|    value_loss           | 2.38e-05   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 150         |\n",
      "|    iterations           | 447         |\n",
      "|    time_elapsed         | 6065        |\n",
      "|    total_timesteps      | 915456      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011929714 |\n",
      "|    clip_fraction        | 0.134       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.09       |\n",
      "|    explained_variance   | 0.631       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0244     |\n",
      "|    n_updates            | 4460        |\n",
      "|    policy_gradient_loss | -0.0131     |\n",
      "|    value_loss           | 1.69e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 448         |\n",
      "|    time_elapsed         | 6071        |\n",
      "|    total_timesteps      | 917504      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003662094 |\n",
      "|    clip_fraction        | 0.0306      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.83       |\n",
      "|    explained_variance   | 0.905       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00707    |\n",
      "|    n_updates            | 4470        |\n",
      "|    policy_gradient_loss | -0.00541    |\n",
      "|    value_loss           | 1.98e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 449         |\n",
      "|    time_elapsed         | 6077        |\n",
      "|    total_timesteps      | 919552      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010701453 |\n",
      "|    clip_fraction        | 0.11        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.764      |\n",
      "|    explained_variance   | 0.0748      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00852    |\n",
      "|    n_updates            | 4480        |\n",
      "|    policy_gradient_loss | -0.000729   |\n",
      "|    value_loss           | 2.06e-05    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=920000, episode_reward=0.06 +/- 0.07\n",
      "Episode length: 10000.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1e+04        |\n",
      "|    mean_reward          | 0.0558       |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 920000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0025600418 |\n",
      "|    clip_fraction        | 0.0378       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.735       |\n",
      "|    explained_variance   | 0.123        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.00774      |\n",
      "|    n_updates            | 4490         |\n",
      "|    policy_gradient_loss | -0.000494    |\n",
      "|    value_loss           | 1.46e-06     |\n",
      "------------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 150    |\n",
      "|    iterations      | 450    |\n",
      "|    time_elapsed    | 6124   |\n",
      "|    total_timesteps | 921600 |\n",
      "-------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 150         |\n",
      "|    iterations           | 451         |\n",
      "|    time_elapsed         | 6129        |\n",
      "|    total_timesteps      | 923648      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.038890347 |\n",
      "|    clip_fraction        | 0.184       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.21       |\n",
      "|    explained_variance   | 0.946       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0215     |\n",
      "|    n_updates            | 4500        |\n",
      "|    policy_gradient_loss | -0.0194     |\n",
      "|    value_loss           | 4.89e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 150         |\n",
      "|    iterations           | 452         |\n",
      "|    time_elapsed         | 6135        |\n",
      "|    total_timesteps      | 925696      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013289781 |\n",
      "|    clip_fraction        | 0.167       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.4        |\n",
      "|    explained_variance   | 0.805       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0314     |\n",
      "|    n_updates            | 4510        |\n",
      "|    policy_gradient_loss | -0.0102     |\n",
      "|    value_loss           | 1.45e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 453         |\n",
      "|    time_elapsed         | 6140        |\n",
      "|    total_timesteps      | 927744      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018881472 |\n",
      "|    clip_fraction        | 0.255       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.38       |\n",
      "|    explained_variance   | -0.185      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0289     |\n",
      "|    n_updates            | 4520        |\n",
      "|    policy_gradient_loss | -0.0115     |\n",
      "|    value_loss           | 1.36e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 454         |\n",
      "|    time_elapsed         | 6146        |\n",
      "|    total_timesteps      | 929792      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021610953 |\n",
      "|    clip_fraction        | 0.247       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.33       |\n",
      "|    explained_variance   | 0.728       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.045      |\n",
      "|    n_updates            | 4530        |\n",
      "|    policy_gradient_loss | -0.0186     |\n",
      "|    value_loss           | 6.01e-06    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=930000, episode_reward=0.01 +/- 0.02\n",
      "Episode length: 10000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+04       |\n",
      "|    mean_reward          | 0.0107      |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 930000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014873287 |\n",
      "|    clip_fraction        | 0.196       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.35       |\n",
      "|    explained_variance   | 0.928       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0127     |\n",
      "|    n_updates            | 4540        |\n",
      "|    policy_gradient_loss | -0.0127     |\n",
      "|    value_loss           | 2.8e-06     |\n",
      "-----------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 150    |\n",
      "|    iterations      | 455    |\n",
      "|    time_elapsed    | 6194   |\n",
      "|    total_timesteps | 931840 |\n",
      "-------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 150         |\n",
      "|    iterations           | 456         |\n",
      "|    time_elapsed         | 6199        |\n",
      "|    total_timesteps      | 933888      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023403713 |\n",
      "|    clip_fraction        | 0.258       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.15       |\n",
      "|    explained_variance   | 0.764       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0501     |\n",
      "|    n_updates            | 4550        |\n",
      "|    policy_gradient_loss | -0.0281     |\n",
      "|    value_loss           | 2.46e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 150         |\n",
      "|    iterations           | 457         |\n",
      "|    time_elapsed         | 6205        |\n",
      "|    total_timesteps      | 935936      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019128624 |\n",
      "|    clip_fraction        | 0.284       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.19       |\n",
      "|    explained_variance   | 0.704       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0378     |\n",
      "|    n_updates            | 4560        |\n",
      "|    policy_gradient_loss | -0.024      |\n",
      "|    value_loss           | 2.5e-05     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 458         |\n",
      "|    time_elapsed         | 6210        |\n",
      "|    total_timesteps      | 937984      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018135983 |\n",
      "|    clip_fraction        | 0.224       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.26       |\n",
      "|    explained_variance   | 0.723       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0597     |\n",
      "|    n_updates            | 4570        |\n",
      "|    policy_gradient_loss | -0.0199     |\n",
      "|    value_loss           | 8.45e-06    |\n",
      "-----------------------------------------\n",
      "box reached target\n",
      "box reached target\n",
      "Eval num_timesteps=940000, episode_reward=2.22 +/- 2.74\n",
      "Episode length: 6883.20 +/- 4022.40\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 6.88e+03    |\n",
      "|    mean_reward          | 2.22        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 940000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010124988 |\n",
      "|    clip_fraction        | 0.205       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.23       |\n",
      "|    explained_variance   | 0.781       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.017      |\n",
      "|    n_updates            | 4580        |\n",
      "|    policy_gradient_loss | -0.014      |\n",
      "|    value_loss           | 6.17e-06    |\n",
      "-----------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 150    |\n",
      "|    iterations      | 459    |\n",
      "|    time_elapsed    | 6244   |\n",
      "|    total_timesteps | 940032 |\n",
      "-------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 150         |\n",
      "|    iterations           | 460         |\n",
      "|    time_elapsed         | 6250        |\n",
      "|    total_timesteps      | 942080      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018764045 |\n",
      "|    clip_fraction        | 0.181       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.14       |\n",
      "|    explained_variance   | 0.506       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00114    |\n",
      "|    n_updates            | 4590        |\n",
      "|    policy_gradient_loss | -0.00567    |\n",
      "|    value_loss           | 0.00011     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 150         |\n",
      "|    iterations           | 461         |\n",
      "|    time_elapsed         | 6256        |\n",
      "|    total_timesteps      | 944128      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009633661 |\n",
      "|    clip_fraction        | 0.136       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.12       |\n",
      "|    explained_variance   | 0.94        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0343      |\n",
      "|    n_updates            | 4600        |\n",
      "|    policy_gradient_loss | -0.0147     |\n",
      "|    value_loss           | 3.57e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 462         |\n",
      "|    time_elapsed         | 6261        |\n",
      "|    total_timesteps      | 946176      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015357088 |\n",
      "|    clip_fraction        | 0.147       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.11       |\n",
      "|    explained_variance   | -3.06       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00415    |\n",
      "|    n_updates            | 4610        |\n",
      "|    policy_gradient_loss | -0.007      |\n",
      "|    value_loss           | 6.52e-06    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 463         |\n",
      "|    time_elapsed         | 6267        |\n",
      "|    total_timesteps      | 948224      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009755367 |\n",
      "|    clip_fraction        | 0.108       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.14       |\n",
      "|    explained_variance   | -0.53       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0108     |\n",
      "|    n_updates            | 4620        |\n",
      "|    policy_gradient_loss | 0.000324    |\n",
      "|    value_loss           | 1.25e-05    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=950000, episode_reward=0.07 +/- 0.14\n",
      "Episode length: 10000.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1e+04        |\n",
      "|    mean_reward          | 0.0683       |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 950000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074049802 |\n",
      "|    clip_fraction        | 0.14         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.07        |\n",
      "|    explained_variance   | -0.14        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0219      |\n",
      "|    n_updates            | 4630         |\n",
      "|    policy_gradient_loss | -0.00339     |\n",
      "|    value_loss           | 1.24e-06     |\n",
      "------------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 150    |\n",
      "|    iterations      | 464    |\n",
      "|    time_elapsed    | 6314   |\n",
      "|    total_timesteps | 950272 |\n",
      "-------------------------------\n",
      "box reached target\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 150         |\n",
      "|    iterations           | 465         |\n",
      "|    time_elapsed         | 6319        |\n",
      "|    total_timesteps      | 952320      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006598763 |\n",
      "|    clip_fraction        | 0.0513      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.04       |\n",
      "|    explained_variance   | -3.8        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0233     |\n",
      "|    n_updates            | 4640        |\n",
      "|    policy_gradient_loss | -0.00375    |\n",
      "|    value_loss           | 3.58e-05    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 150        |\n",
      "|    iterations           | 466        |\n",
      "|    time_elapsed         | 6325       |\n",
      "|    total_timesteps      | 954368     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02146917 |\n",
      "|    clip_fraction        | 0.175      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.29      |\n",
      "|    explained_variance   | -0.141     |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0296    |\n",
      "|    n_updates            | 4650       |\n",
      "|    policy_gradient_loss | -0.0028    |\n",
      "|    value_loss           | 0.0285     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 467         |\n",
      "|    time_elapsed         | 6330        |\n",
      "|    total_timesteps      | 956416      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019140637 |\n",
      "|    clip_fraction        | 0.31        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.28       |\n",
      "|    explained_variance   | 0.821       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0485     |\n",
      "|    n_updates            | 4660        |\n",
      "|    policy_gradient_loss | -0.0294     |\n",
      "|    value_loss           | 0.000141    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 151          |\n",
      "|    iterations           | 468          |\n",
      "|    time_elapsed         | 6336         |\n",
      "|    total_timesteps      | 958464       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0135304555 |\n",
      "|    clip_fraction        | 0.193        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.24        |\n",
      "|    explained_variance   | 0.947        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0227      |\n",
      "|    n_updates            | 4670         |\n",
      "|    policy_gradient_loss | -0.0166      |\n",
      "|    value_loss           | 0.000123     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=960000, episode_reward=0.06 +/- 0.10\n",
      "Episode length: 10000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+04       |\n",
      "|    mean_reward          | 0.0571      |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 960000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021348678 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.16       |\n",
      "|    explained_variance   | 0.804       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0545     |\n",
      "|    n_updates            | 4680        |\n",
      "|    policy_gradient_loss | -0.016      |\n",
      "|    value_loss           | 0.000106    |\n",
      "-----------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 150    |\n",
      "|    iterations      | 469    |\n",
      "|    time_elapsed    | 6384   |\n",
      "|    total_timesteps | 960512 |\n",
      "-------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 150         |\n",
      "|    iterations           | 470         |\n",
      "|    time_elapsed         | 6389        |\n",
      "|    total_timesteps      | 962560      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021983162 |\n",
      "|    clip_fraction        | 0.252       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.04       |\n",
      "|    explained_variance   | 0.885       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00449     |\n",
      "|    n_updates            | 4690        |\n",
      "|    policy_gradient_loss | -0.00462    |\n",
      "|    value_loss           | 0.00543     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 150         |\n",
      "|    iterations           | 471         |\n",
      "|    time_elapsed         | 6394        |\n",
      "|    total_timesteps      | 964608      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019263238 |\n",
      "|    clip_fraction        | 0.168       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.11       |\n",
      "|    explained_variance   | 0.925       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0956      |\n",
      "|    n_updates            | 4700        |\n",
      "|    policy_gradient_loss | -0.0172     |\n",
      "|    value_loss           | 0.000125    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 472         |\n",
      "|    time_elapsed         | 6400        |\n",
      "|    total_timesteps      | 966656      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005383409 |\n",
      "|    clip_fraction        | 0.0723      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.79       |\n",
      "|    explained_variance   | 0.234       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00965    |\n",
      "|    n_updates            | 4710        |\n",
      "|    policy_gradient_loss | -0.00112    |\n",
      "|    value_loss           | 0.000107    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 473         |\n",
      "|    time_elapsed         | 6405        |\n",
      "|    total_timesteps      | 968704      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017371323 |\n",
      "|    clip_fraction        | 0.137       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.971      |\n",
      "|    explained_variance   | 0.954       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.047      |\n",
      "|    n_updates            | 4720        |\n",
      "|    policy_gradient_loss | -0.0127     |\n",
      "|    value_loss           | 8.32e-05    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=970000, episode_reward=-0.51 +/- 1.02\n",
      "Episode length: 10000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+04       |\n",
      "|    mean_reward          | -0.509      |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 970000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018405871 |\n",
      "|    clip_fraction        | 0.316       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.36       |\n",
      "|    explained_variance   | 0.853       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0626     |\n",
      "|    n_updates            | 4730        |\n",
      "|    policy_gradient_loss | -0.0277     |\n",
      "|    value_loss           | 0.000105    |\n",
      "-----------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 150    |\n",
      "|    iterations      | 474    |\n",
      "|    time_elapsed    | 6453   |\n",
      "|    total_timesteps | 970752 |\n",
      "-------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 150         |\n",
      "|    iterations           | 475         |\n",
      "|    time_elapsed         | 6458        |\n",
      "|    total_timesteps      | 972800      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011955097 |\n",
      "|    clip_fraction        | 0.0958      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.28       |\n",
      "|    explained_variance   | 0.957       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00171     |\n",
      "|    n_updates            | 4740        |\n",
      "|    policy_gradient_loss | -0.00327    |\n",
      "|    value_loss           | 0.000553    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 150          |\n",
      "|    iterations           | 476          |\n",
      "|    time_elapsed         | 6463         |\n",
      "|    total_timesteps      | 974848       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0070695477 |\n",
      "|    clip_fraction        | 0.0702       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.3         |\n",
      "|    explained_variance   | 0.954        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.00271     |\n",
      "|    n_updates            | 4750         |\n",
      "|    policy_gradient_loss | -0.00676     |\n",
      "|    value_loss           | 0.000377     |\n",
      "------------------------------------------\n",
      "--------------------------------------\n",
      "| time/                   |          |\n",
      "|    fps                  | 151      |\n",
      "|    iterations           | 477      |\n",
      "|    time_elapsed         | 6469     |\n",
      "|    total_timesteps      | 976896   |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.022246 |\n",
      "|    clip_fraction        | 0.293    |\n",
      "|    clip_range           | 0.2      |\n",
      "|    entropy_loss         | -1.46    |\n",
      "|    explained_variance   | 0.189    |\n",
      "|    learning_rate        | 0.0003   |\n",
      "|    loss                 | -0.0216  |\n",
      "|    n_updates            | 4760     |\n",
      "|    policy_gradient_loss | -0.0267  |\n",
      "|    value_loss           | 0.000257 |\n",
      "--------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 478         |\n",
      "|    time_elapsed         | 6474        |\n",
      "|    total_timesteps      | 978944      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017015496 |\n",
      "|    clip_fraction        | 0.34        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.43       |\n",
      "|    explained_variance   | 0.856       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0403     |\n",
      "|    n_updates            | 4770        |\n",
      "|    policy_gradient_loss | -0.0203     |\n",
      "|    value_loss           | 0.000187    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=980000, episode_reward=0.38 +/- 0.67\n",
      "Episode length: 10000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+04       |\n",
      "|    mean_reward          | 0.376       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 980000      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016265566 |\n",
      "|    clip_fraction        | 0.346       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.39       |\n",
      "|    explained_variance   | 0.822       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0288     |\n",
      "|    n_updates            | 4780        |\n",
      "|    policy_gradient_loss | -0.0279     |\n",
      "|    value_loss           | 5.82e-05    |\n",
      "-----------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 150    |\n",
      "|    iterations      | 479    |\n",
      "|    time_elapsed    | 6522   |\n",
      "|    total_timesteps | 980992 |\n",
      "-------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 150        |\n",
      "|    iterations           | 480        |\n",
      "|    time_elapsed         | 6528       |\n",
      "|    total_timesteps      | 983040     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01336804 |\n",
      "|    clip_fraction        | 0.229      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.12      |\n",
      "|    explained_variance   | 0.883      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0329    |\n",
      "|    n_updates            | 4790       |\n",
      "|    policy_gradient_loss | -0.0131    |\n",
      "|    value_loss           | 0.00032    |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 150         |\n",
      "|    iterations           | 481         |\n",
      "|    time_elapsed         | 6533        |\n",
      "|    total_timesteps      | 985088      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005802679 |\n",
      "|    clip_fraction        | 0.0938      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.766      |\n",
      "|    explained_variance   | 0.483       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.000901   |\n",
      "|    n_updates            | 4800        |\n",
      "|    policy_gradient_loss | -0.00457    |\n",
      "|    value_loss           | 7.52e-05    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 150          |\n",
      "|    iterations           | 482          |\n",
      "|    time_elapsed         | 6539         |\n",
      "|    total_timesteps      | 987136       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0076403506 |\n",
      "|    clip_fraction        | 0.131        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.86        |\n",
      "|    explained_variance   | 0.301        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0122      |\n",
      "|    n_updates            | 4810         |\n",
      "|    policy_gradient_loss | -0.00433     |\n",
      "|    value_loss           | 5.7e-05      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 151          |\n",
      "|    iterations           | 483          |\n",
      "|    time_elapsed         | 6544         |\n",
      "|    total_timesteps      | 989184       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061780396 |\n",
      "|    clip_fraction        | 0.0733       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.877       |\n",
      "|    explained_variance   | 0.394        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.00337     |\n",
      "|    n_updates            | 4820         |\n",
      "|    policy_gradient_loss | -0.0019      |\n",
      "|    value_loss           | 3.98e-05     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=990000, episode_reward=0.06 +/- 0.11\n",
      "Episode length: 10000.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1e+04        |\n",
      "|    mean_reward          | 0.0568       |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 990000       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075065275 |\n",
      "|    clip_fraction        | 0.111        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.95        |\n",
      "|    explained_variance   | 0.402        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0184      |\n",
      "|    n_updates            | 4830         |\n",
      "|    policy_gradient_loss | -0.00279     |\n",
      "|    value_loss           | 3.11e-05     |\n",
      "------------------------------------------\n",
      "-------------------------------\n",
      "| time/              |        |\n",
      "|    fps             | 150    |\n",
      "|    iterations      | 484    |\n",
      "|    time_elapsed    | 6592   |\n",
      "|    total_timesteps | 991232 |\n",
      "-------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 150        |\n",
      "|    iterations           | 485        |\n",
      "|    time_elapsed         | 6597       |\n",
      "|    total_timesteps      | 993280     |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01531096 |\n",
      "|    clip_fraction        | 0.111      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.849     |\n",
      "|    explained_variance   | -0.06      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.00166   |\n",
      "|    n_updates            | 4840       |\n",
      "|    policy_gradient_loss | -0.000849  |\n",
      "|    value_loss           | 0.000131   |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 150          |\n",
      "|    iterations           | 486          |\n",
      "|    time_elapsed         | 6603         |\n",
      "|    total_timesteps      | 995328       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0068475585 |\n",
      "|    clip_fraction        | 0.0552       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.905       |\n",
      "|    explained_variance   | 0.864        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0073       |\n",
      "|    n_updates            | 4850         |\n",
      "|    policy_gradient_loss | -0.000202    |\n",
      "|    value_loss           | 1.62e-05     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 150          |\n",
      "|    iterations           | 487          |\n",
      "|    time_elapsed         | 6608         |\n",
      "|    total_timesteps      | 997376       |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0043659257 |\n",
      "|    clip_fraction        | 0.0688       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.949       |\n",
      "|    explained_variance   | 0.863        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.00519     |\n",
      "|    n_updates            | 4860         |\n",
      "|    policy_gradient_loss | -0.00319     |\n",
      "|    value_loss           | 2.51e-05     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 488         |\n",
      "|    time_elapsed         | 6614        |\n",
      "|    total_timesteps      | 999424      |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008869236 |\n",
      "|    clip_fraction        | 0.147       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.916      |\n",
      "|    explained_variance   | 0.952       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0167     |\n",
      "|    n_updates            | 4870        |\n",
      "|    policy_gradient_loss | -0.00816    |\n",
      "|    value_loss           | 1.35e-05    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1000000, episode_reward=0.11 +/- 0.12\n",
      "Episode length: 10000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+04       |\n",
      "|    mean_reward          | 0.107       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1000000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011368118 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.09       |\n",
      "|    explained_variance   | 0.963       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00334    |\n",
      "|    n_updates            | 4880        |\n",
      "|    policy_gradient_loss | -0.00888    |\n",
      "|    value_loss           | 1.74e-05    |\n",
      "-----------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 150     |\n",
      "|    iterations      | 489     |\n",
      "|    time_elapsed    | 6661    |\n",
      "|    total_timesteps | 1001472 |\n",
      "--------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 150         |\n",
      "|    iterations           | 490         |\n",
      "|    time_elapsed         | 6666        |\n",
      "|    total_timesteps      | 1003520     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014131614 |\n",
      "|    clip_fraction        | 0.103       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.27       |\n",
      "|    explained_variance   | 0.829       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00996    |\n",
      "|    n_updates            | 4890        |\n",
      "|    policy_gradient_loss | -0.00759    |\n",
      "|    value_loss           | 0.000203    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 150         |\n",
      "|    iterations           | 491         |\n",
      "|    time_elapsed         | 6672        |\n",
      "|    total_timesteps      | 1005568     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014645393 |\n",
      "|    clip_fraction        | 0.268       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.27       |\n",
      "|    explained_variance   | 0.934       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0374     |\n",
      "|    n_updates            | 4900        |\n",
      "|    policy_gradient_loss | -0.0209     |\n",
      "|    value_loss           | 1.53e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 150         |\n",
      "|    iterations           | 492         |\n",
      "|    time_elapsed         | 6678        |\n",
      "|    total_timesteps      | 1007616     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013968395 |\n",
      "|    clip_fraction        | 0.251       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.34       |\n",
      "|    explained_variance   | 0.787       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0214     |\n",
      "|    n_updates            | 4910        |\n",
      "|    policy_gradient_loss | -0.0219     |\n",
      "|    value_loss           | 1.16e-05    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 151        |\n",
      "|    iterations           | 493        |\n",
      "|    time_elapsed         | 6683       |\n",
      "|    total_timesteps      | 1009664    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01469586 |\n",
      "|    clip_fraction        | 0.165      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.37      |\n",
      "|    explained_variance   | 0.872      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0185    |\n",
      "|    n_updates            | 4920       |\n",
      "|    policy_gradient_loss | -0.0127    |\n",
      "|    value_loss           | 1.29e-05   |\n",
      "----------------------------------------\n",
      "box reached target\n",
      "Eval num_timesteps=1010000, episode_reward=1.34 +/- 2.05\n",
      "Episode length: 8061.00 +/- 3878.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 8.06e+03    |\n",
      "|    mean_reward          | 1.34        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1010000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011033019 |\n",
      "|    clip_fraction        | 0.176       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.38       |\n",
      "|    explained_variance   | 0.441       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.017      |\n",
      "|    n_updates            | 4930        |\n",
      "|    policy_gradient_loss | -0.0167     |\n",
      "|    value_loss           | 5.84e-06    |\n",
      "-----------------------------------------\n",
      "box reached target\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 150     |\n",
      "|    iterations      | 494     |\n",
      "|    time_elapsed    | 6722    |\n",
      "|    total_timesteps | 1011712 |\n",
      "--------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 150         |\n",
      "|    iterations           | 495         |\n",
      "|    time_elapsed         | 6728        |\n",
      "|    total_timesteps      | 1013760     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010982007 |\n",
      "|    clip_fraction        | 0.108       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.3        |\n",
      "|    explained_variance   | 0.327       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00593     |\n",
      "|    n_updates            | 4940        |\n",
      "|    policy_gradient_loss | -0.0118     |\n",
      "|    value_loss           | 0.0116      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 150         |\n",
      "|    iterations           | 496         |\n",
      "|    time_elapsed         | 6733        |\n",
      "|    total_timesteps      | 1015808     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018333564 |\n",
      "|    clip_fraction        | 0.254       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.45       |\n",
      "|    explained_variance   | 0.222       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0177      |\n",
      "|    n_updates            | 4950        |\n",
      "|    policy_gradient_loss | -0.0162     |\n",
      "|    value_loss           | 0.000199    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 151        |\n",
      "|    iterations           | 497        |\n",
      "|    time_elapsed         | 6739       |\n",
      "|    total_timesteps      | 1017856    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01841625 |\n",
      "|    clip_fraction        | 0.389      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.38      |\n",
      "|    explained_variance   | 0.555      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0148    |\n",
      "|    n_updates            | 4960       |\n",
      "|    policy_gradient_loss | -0.019     |\n",
      "|    value_loss           | 9.83e-05   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 498         |\n",
      "|    time_elapsed         | 6744        |\n",
      "|    total_timesteps      | 1019904     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018990062 |\n",
      "|    clip_fraction        | 0.374       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.34       |\n",
      "|    explained_variance   | 0.607       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0259     |\n",
      "|    n_updates            | 4970        |\n",
      "|    policy_gradient_loss | -0.0233     |\n",
      "|    value_loss           | 2.93e-05    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1020000, episode_reward=0.13 +/- 0.23\n",
      "Episode length: 10000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+04       |\n",
      "|    mean_reward          | 0.131       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1020000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014198905 |\n",
      "|    clip_fraction        | 0.164       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.33       |\n",
      "|    explained_variance   | 0.796       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0152     |\n",
      "|    n_updates            | 4980        |\n",
      "|    policy_gradient_loss | -0.0111     |\n",
      "|    value_loss           | 2.38e-05    |\n",
      "-----------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 150     |\n",
      "|    iterations      | 499     |\n",
      "|    time_elapsed    | 6792    |\n",
      "|    total_timesteps | 1021952 |\n",
      "--------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 150         |\n",
      "|    iterations           | 500         |\n",
      "|    time_elapsed         | 6798        |\n",
      "|    total_timesteps      | 1024000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022885678 |\n",
      "|    clip_fraction        | 0.326       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.15       |\n",
      "|    explained_variance   | -0.165      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0243      |\n",
      "|    n_updates            | 4990        |\n",
      "|    policy_gradient_loss | -0.019      |\n",
      "|    value_loss           | 0.000267    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 150        |\n",
      "|    iterations           | 501        |\n",
      "|    time_elapsed         | 6803       |\n",
      "|    total_timesteps      | 1026048    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02646355 |\n",
      "|    clip_fraction        | 0.388      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.06      |\n",
      "|    explained_variance   | 0.832      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0446    |\n",
      "|    n_updates            | 5000       |\n",
      "|    policy_gradient_loss | -0.0179    |\n",
      "|    value_loss           | 0.000307   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 150         |\n",
      "|    iterations           | 502         |\n",
      "|    time_elapsed         | 6809        |\n",
      "|    total_timesteps      | 1028096     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018926844 |\n",
      "|    clip_fraction        | 0.374       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.21       |\n",
      "|    explained_variance   | 0.905       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.029      |\n",
      "|    n_updates            | 5010        |\n",
      "|    policy_gradient_loss | -0.0183     |\n",
      "|    value_loss           | 0.000222    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1030000, episode_reward=0.47 +/- 0.61\n",
      "Episode length: 10000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+04       |\n",
      "|    mean_reward          | 0.471       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1030000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016212266 |\n",
      "|    clip_fraction        | 0.251       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.32       |\n",
      "|    explained_variance   | 0.888       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.01       |\n",
      "|    n_updates            | 5020        |\n",
      "|    policy_gradient_loss | -0.015      |\n",
      "|    value_loss           | 0.000283    |\n",
      "-----------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 150     |\n",
      "|    iterations      | 503     |\n",
      "|    time_elapsed    | 6857    |\n",
      "|    total_timesteps | 1030144 |\n",
      "--------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 150        |\n",
      "|    iterations           | 504        |\n",
      "|    time_elapsed         | 6862       |\n",
      "|    total_timesteps      | 1032192    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02979483 |\n",
      "|    clip_fraction        | 0.26       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.33      |\n",
      "|    explained_variance   | 0.91       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0169    |\n",
      "|    n_updates            | 5030       |\n",
      "|    policy_gradient_loss | -0.00423   |\n",
      "|    value_loss           | 0.00136    |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 150         |\n",
      "|    iterations           | 505         |\n",
      "|    time_elapsed         | 6868        |\n",
      "|    total_timesteps      | 1034240     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.036238763 |\n",
      "|    clip_fraction        | 0.188       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.16       |\n",
      "|    explained_variance   | 0.883       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0262     |\n",
      "|    n_updates            | 5040        |\n",
      "|    policy_gradient_loss | -0.0117     |\n",
      "|    value_loss           | 1.79e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 150         |\n",
      "|    iterations           | 506         |\n",
      "|    time_elapsed         | 6873        |\n",
      "|    total_timesteps      | 1036288     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030217767 |\n",
      "|    clip_fraction        | 0.389       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.21       |\n",
      "|    explained_variance   | -2.5        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0271      |\n",
      "|    n_updates            | 5050        |\n",
      "|    policy_gradient_loss | -0.0191     |\n",
      "|    value_loss           | 3.49e-06    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 150         |\n",
      "|    iterations           | 507         |\n",
      "|    time_elapsed         | 6879        |\n",
      "|    total_timesteps      | 1038336     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012714906 |\n",
      "|    clip_fraction        | 0.194       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.32       |\n",
      "|    explained_variance   | 0.782       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0585     |\n",
      "|    n_updates            | 5060        |\n",
      "|    policy_gradient_loss | -0.0126     |\n",
      "|    value_loss           | 1.69e-06    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1040000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 10000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+04       |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1040000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010962109 |\n",
      "|    clip_fraction        | 0.229       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.37       |\n",
      "|    explained_variance   | -0.0397     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0106      |\n",
      "|    n_updates            | 5070        |\n",
      "|    policy_gradient_loss | -0.0094     |\n",
      "|    value_loss           | 2.04e-06    |\n",
      "-----------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 150     |\n",
      "|    iterations      | 508     |\n",
      "|    time_elapsed    | 6927    |\n",
      "|    total_timesteps | 1040384 |\n",
      "--------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 150         |\n",
      "|    iterations           | 509         |\n",
      "|    time_elapsed         | 6932        |\n",
      "|    total_timesteps      | 1042432     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018546129 |\n",
      "|    clip_fraction        | 0.147       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.4        |\n",
      "|    explained_variance   | 0.928       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.048       |\n",
      "|    n_updates            | 5080        |\n",
      "|    policy_gradient_loss | -0.0106     |\n",
      "|    value_loss           | 3.68e-05    |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 150       |\n",
      "|    iterations           | 510       |\n",
      "|    time_elapsed         | 6938      |\n",
      "|    total_timesteps      | 1044480   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0141212 |\n",
      "|    clip_fraction        | 0.275     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -1.36     |\n",
      "|    explained_variance   | 0.862     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -0.0164   |\n",
      "|    n_updates            | 5090      |\n",
      "|    policy_gradient_loss | -0.0172   |\n",
      "|    value_loss           | 0.000158  |\n",
      "---------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 150          |\n",
      "|    iterations           | 511          |\n",
      "|    time_elapsed         | 6943         |\n",
      "|    total_timesteps      | 1046528      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0078921355 |\n",
      "|    clip_fraction        | 0.0732       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.48        |\n",
      "|    explained_variance   | 0.938        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0294      |\n",
      "|    n_updates            | 5100         |\n",
      "|    policy_gradient_loss | -0.00213     |\n",
      "|    value_loss           | 6.44e-05     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 150         |\n",
      "|    iterations           | 512         |\n",
      "|    time_elapsed         | 6949        |\n",
      "|    total_timesteps      | 1048576     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014409456 |\n",
      "|    clip_fraction        | 0.173       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.48       |\n",
      "|    explained_variance   | 0.825       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00619    |\n",
      "|    n_updates            | 5110        |\n",
      "|    policy_gradient_loss | -0.00694    |\n",
      "|    value_loss           | 7.75e-05    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1050000, episode_reward=0.05 +/- 0.07\n",
      "Episode length: 10000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+04       |\n",
      "|    mean_reward          | 0.0458      |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1050000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016665624 |\n",
      "|    clip_fraction        | 0.261       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.44       |\n",
      "|    explained_variance   | 0.547       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00223     |\n",
      "|    n_updates            | 5120        |\n",
      "|    policy_gradient_loss | -0.0108     |\n",
      "|    value_loss           | 3.06e-05    |\n",
      "-----------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 150     |\n",
      "|    iterations      | 513     |\n",
      "|    time_elapsed    | 6996    |\n",
      "|    total_timesteps | 1050624 |\n",
      "--------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 150         |\n",
      "|    iterations           | 514         |\n",
      "|    time_elapsed         | 7002        |\n",
      "|    total_timesteps      | 1052672     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019987829 |\n",
      "|    clip_fraction        | 0.234       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.31       |\n",
      "|    explained_variance   | 0.929       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0144     |\n",
      "|    n_updates            | 5130        |\n",
      "|    policy_gradient_loss | -0.0102     |\n",
      "|    value_loss           | 0.000193    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 150        |\n",
      "|    iterations           | 515        |\n",
      "|    time_elapsed         | 7007       |\n",
      "|    total_timesteps      | 1054720    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01169157 |\n",
      "|    clip_fraction        | 0.213      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.35      |\n",
      "|    explained_variance   | 0.937      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0278    |\n",
      "|    n_updates            | 5140       |\n",
      "|    policy_gradient_loss | -0.0114    |\n",
      "|    value_loss           | 3.35e-05   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 150         |\n",
      "|    iterations           | 516         |\n",
      "|    time_elapsed         | 7013        |\n",
      "|    total_timesteps      | 1056768     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007453768 |\n",
      "|    clip_fraction        | 0.0919      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.47       |\n",
      "|    explained_variance   | 0.902       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.000877    |\n",
      "|    n_updates            | 5150        |\n",
      "|    policy_gradient_loss | -0.00477    |\n",
      "|    value_loss           | 2.07e-06    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 150         |\n",
      "|    iterations           | 517         |\n",
      "|    time_elapsed         | 7018        |\n",
      "|    total_timesteps      | 1058816     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009755449 |\n",
      "|    clip_fraction        | 0.0911      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.48       |\n",
      "|    explained_variance   | 0.754       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0235     |\n",
      "|    n_updates            | 5160        |\n",
      "|    policy_gradient_loss | -0.00676    |\n",
      "|    value_loss           | 2.9e-06     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1060000, episode_reward=0.13 +/- 0.18\n",
      "Episode length: 10000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+04       |\n",
      "|    mean_reward          | 0.134       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1060000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012356507 |\n",
      "|    clip_fraction        | 0.205       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.49       |\n",
      "|    explained_variance   | 0.28        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0305     |\n",
      "|    n_updates            | 5170        |\n",
      "|    policy_gradient_loss | -0.0164     |\n",
      "|    value_loss           | 3.05e-06    |\n",
      "-----------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 150     |\n",
      "|    iterations      | 518     |\n",
      "|    time_elapsed    | 7066    |\n",
      "|    total_timesteps | 1060864 |\n",
      "--------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 150         |\n",
      "|    iterations           | 519         |\n",
      "|    time_elapsed         | 7072        |\n",
      "|    total_timesteps      | 1062912     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027967546 |\n",
      "|    clip_fraction        | 0.206       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.23       |\n",
      "|    explained_variance   | 0.458       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0347     |\n",
      "|    n_updates            | 5180        |\n",
      "|    policy_gradient_loss | -0.0197     |\n",
      "|    value_loss           | 6.03e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 150         |\n",
      "|    iterations           | 520         |\n",
      "|    time_elapsed         | 7077        |\n",
      "|    total_timesteps      | 1064960     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012612668 |\n",
      "|    clip_fraction        | 0.207       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.09       |\n",
      "|    explained_variance   | 0.398       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0102     |\n",
      "|    n_updates            | 5190        |\n",
      "|    policy_gradient_loss | -0.0204     |\n",
      "|    value_loss           | 0.000276    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 150         |\n",
      "|    iterations           | 521         |\n",
      "|    time_elapsed         | 7083        |\n",
      "|    total_timesteps      | 1067008     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020105043 |\n",
      "|    clip_fraction        | 0.225       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.15       |\n",
      "|    explained_variance   | 0.838       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0333      |\n",
      "|    n_updates            | 5200        |\n",
      "|    policy_gradient_loss | -0.0174     |\n",
      "|    value_loss           | 8.5e-05     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 150         |\n",
      "|    iterations           | 522         |\n",
      "|    time_elapsed         | 7088        |\n",
      "|    total_timesteps      | 1069056     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015430932 |\n",
      "|    clip_fraction        | 0.159       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.25       |\n",
      "|    explained_variance   | 0.56        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0488     |\n",
      "|    n_updates            | 5210        |\n",
      "|    policy_gradient_loss | -0.0141     |\n",
      "|    value_loss           | 1.57e-05    |\n",
      "-----------------------------------------\n",
      "box reached target\n",
      "Eval num_timesteps=1070000, episode_reward=1.03 +/- 2.06\n",
      "Episode length: 8052.00 +/- 3896.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 8.05e+03    |\n",
      "|    mean_reward          | 1.03        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1070000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021913739 |\n",
      "|    clip_fraction        | 0.245       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.3        |\n",
      "|    explained_variance   | 0.75        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0224     |\n",
      "|    n_updates            | 5220        |\n",
      "|    policy_gradient_loss | -0.0187     |\n",
      "|    value_loss           | 1.38e-05    |\n",
      "-----------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 150     |\n",
      "|    iterations      | 523     |\n",
      "|    time_elapsed    | 7128    |\n",
      "|    total_timesteps | 1071104 |\n",
      "--------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 150         |\n",
      "|    iterations           | 524         |\n",
      "|    time_elapsed         | 7133        |\n",
      "|    total_timesteps      | 1073152     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019290883 |\n",
      "|    clip_fraction        | 0.244       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.26       |\n",
      "|    explained_variance   | 0.829       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0445     |\n",
      "|    n_updates            | 5230        |\n",
      "|    policy_gradient_loss | -0.0168     |\n",
      "|    value_loss           | 5.75e-05    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 150          |\n",
      "|    iterations           | 525          |\n",
      "|    time_elapsed         | 7139         |\n",
      "|    total_timesteps      | 1075200      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0139673045 |\n",
      "|    clip_fraction        | 0.162        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.27        |\n",
      "|    explained_variance   | 0.653        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0128      |\n",
      "|    n_updates            | 5240         |\n",
      "|    policy_gradient_loss | -0.0129      |\n",
      "|    value_loss           | 3.16e-05     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 150         |\n",
      "|    iterations           | 526         |\n",
      "|    time_elapsed         | 7144        |\n",
      "|    total_timesteps      | 1077248     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017257012 |\n",
      "|    clip_fraction        | 0.227       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.33       |\n",
      "|    explained_variance   | 0.821       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00245    |\n",
      "|    n_updates            | 5250        |\n",
      "|    policy_gradient_loss | -0.0185     |\n",
      "|    value_loss           | 1.96e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 150         |\n",
      "|    iterations           | 527         |\n",
      "|    time_elapsed         | 7150        |\n",
      "|    total_timesteps      | 1079296     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012018682 |\n",
      "|    clip_fraction        | 0.212       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.35       |\n",
      "|    explained_variance   | 0.813       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0249     |\n",
      "|    n_updates            | 5260        |\n",
      "|    policy_gradient_loss | -0.0198     |\n",
      "|    value_loss           | 1.41e-05    |\n",
      "-----------------------------------------\n",
      "box reached target\n",
      "Eval num_timesteps=1080000, episode_reward=1.35 +/- 1.99\n",
      "Episode length: 8069.20 +/- 3861.60\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 8.07e+03     |\n",
      "|    mean_reward          | 1.35         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1080000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037186965 |\n",
      "|    clip_fraction        | 0.0554       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.33        |\n",
      "|    explained_variance   | 0.907        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0078      |\n",
      "|    n_updates            | 5270         |\n",
      "|    policy_gradient_loss | -0.00361     |\n",
      "|    value_loss           | 3.28e-05     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 150     |\n",
      "|    iterations      | 528     |\n",
      "|    time_elapsed    | 7190    |\n",
      "|    total_timesteps | 1081344 |\n",
      "--------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 150         |\n",
      "|    iterations           | 529         |\n",
      "|    time_elapsed         | 7195        |\n",
      "|    total_timesteps      | 1083392     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011173019 |\n",
      "|    clip_fraction        | 0.0893      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.26       |\n",
      "|    explained_variance   | 0.884       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0148     |\n",
      "|    n_updates            | 5280        |\n",
      "|    policy_gradient_loss | -0.00692    |\n",
      "|    value_loss           | 0.000129    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 150         |\n",
      "|    iterations           | 530         |\n",
      "|    time_elapsed         | 7201        |\n",
      "|    total_timesteps      | 1085440     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015714983 |\n",
      "|    clip_fraction        | 0.181       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.38       |\n",
      "|    explained_variance   | 0.764       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0148     |\n",
      "|    n_updates            | 5290        |\n",
      "|    policy_gradient_loss | -0.0126     |\n",
      "|    value_loss           | 2.99e-06    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 150         |\n",
      "|    iterations           | 531         |\n",
      "|    time_elapsed         | 7206        |\n",
      "|    total_timesteps      | 1087488     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013926916 |\n",
      "|    clip_fraction        | 0.246       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.3        |\n",
      "|    explained_variance   | 0.407       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0504     |\n",
      "|    n_updates            | 5300        |\n",
      "|    policy_gradient_loss | -0.0223     |\n",
      "|    value_loss           | 1.46e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 532         |\n",
      "|    time_elapsed         | 7212        |\n",
      "|    total_timesteps      | 1089536     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019437414 |\n",
      "|    clip_fraction        | 0.262       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.26       |\n",
      "|    explained_variance   | 0.819       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.057      |\n",
      "|    n_updates            | 5310        |\n",
      "|    policy_gradient_loss | -0.018      |\n",
      "|    value_loss           | 0.000103    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1090000, episode_reward=0.09 +/- 0.17\n",
      "Episode length: 10000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+04       |\n",
      "|    mean_reward          | 0.0853      |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1090000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014302856 |\n",
      "|    clip_fraction        | 0.189       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.26       |\n",
      "|    explained_variance   | 0.788       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0033     |\n",
      "|    n_updates            | 5320        |\n",
      "|    policy_gradient_loss | -0.015      |\n",
      "|    value_loss           | 1.09e-05    |\n",
      "-----------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 150     |\n",
      "|    iterations      | 533     |\n",
      "|    time_elapsed    | 7260    |\n",
      "|    total_timesteps | 1091584 |\n",
      "--------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 150         |\n",
      "|    iterations           | 534         |\n",
      "|    time_elapsed         | 7265        |\n",
      "|    total_timesteps      | 1093632     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021885108 |\n",
      "|    clip_fraction        | 0.312       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.34       |\n",
      "|    explained_variance   | 0.812       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00436     |\n",
      "|    n_updates            | 5330        |\n",
      "|    policy_gradient_loss | -0.0229     |\n",
      "|    value_loss           | 4.06e-05    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 150        |\n",
      "|    iterations           | 535        |\n",
      "|    time_elapsed         | 7271       |\n",
      "|    total_timesteps      | 1095680    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01656505 |\n",
      "|    clip_fraction        | 0.324      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.34      |\n",
      "|    explained_variance   | 0.226      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.00469    |\n",
      "|    n_updates            | 5340       |\n",
      "|    policy_gradient_loss | -0.0253    |\n",
      "|    value_loss           | 2.66e-06   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 150         |\n",
      "|    iterations           | 536         |\n",
      "|    time_elapsed         | 7277        |\n",
      "|    total_timesteps      | 1097728     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021832677 |\n",
      "|    clip_fraction        | 0.338       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.33       |\n",
      "|    explained_variance   | 0.523       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0788     |\n",
      "|    n_updates            | 5350        |\n",
      "|    policy_gradient_loss | -0.025      |\n",
      "|    value_loss           | 5.25e-06    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 537         |\n",
      "|    time_elapsed         | 7282        |\n",
      "|    total_timesteps      | 1099776     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009169733 |\n",
      "|    clip_fraction        | 0.12        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.3        |\n",
      "|    explained_variance   | 0.895       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0274     |\n",
      "|    n_updates            | 5360        |\n",
      "|    policy_gradient_loss | -0.0117     |\n",
      "|    value_loss           | 4.75e-05    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1100000, episode_reward=0.02 +/- 0.02\n",
      "Episode length: 10000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+04       |\n",
      "|    mean_reward          | 0.0154      |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1100000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015191935 |\n",
      "|    clip_fraction        | 0.226       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.21       |\n",
      "|    explained_variance   | 0.864       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0319     |\n",
      "|    n_updates            | 5370        |\n",
      "|    policy_gradient_loss | -0.0183     |\n",
      "|    value_loss           | 4.11e-05    |\n",
      "-----------------------------------------\n",
      "box reached target\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 150     |\n",
      "|    iterations      | 538     |\n",
      "|    time_elapsed    | 7330    |\n",
      "|    total_timesteps | 1101824 |\n",
      "--------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 150        |\n",
      "|    iterations           | 539        |\n",
      "|    time_elapsed         | 7335       |\n",
      "|    total_timesteps      | 1103872    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01999813 |\n",
      "|    clip_fraction        | 0.191      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.21      |\n",
      "|    explained_variance   | 0.198      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.014     |\n",
      "|    n_updates            | 5380       |\n",
      "|    policy_gradient_loss | -0.00954   |\n",
      "|    value_loss           | 0.0476     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 150        |\n",
      "|    iterations           | 540        |\n",
      "|    time_elapsed         | 7341       |\n",
      "|    total_timesteps      | 1105920    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01935871 |\n",
      "|    clip_fraction        | 0.171      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.17      |\n",
      "|    explained_variance   | 0.809      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.00922   |\n",
      "|    n_updates            | 5390       |\n",
      "|    policy_gradient_loss | -0.00879   |\n",
      "|    value_loss           | 0.000354   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 150         |\n",
      "|    iterations           | 541         |\n",
      "|    time_elapsed         | 7346        |\n",
      "|    total_timesteps      | 1107968     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023163825 |\n",
      "|    clip_fraction        | 0.244       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.2        |\n",
      "|    explained_variance   | 0.894       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0359     |\n",
      "|    n_updates            | 5400        |\n",
      "|    policy_gradient_loss | -0.0242     |\n",
      "|    value_loss           | 0.00176     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1110000, episode_reward=0.14 +/- 0.22\n",
      "Episode length: 10000.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1e+04        |\n",
      "|    mean_reward          | 0.137        |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1110000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0142334895 |\n",
      "|    clip_fraction        | 0.154        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.17        |\n",
      "|    explained_variance   | 0.931        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.00557      |\n",
      "|    n_updates            | 5410         |\n",
      "|    policy_gradient_loss | -0.0106      |\n",
      "|    value_loss           | 0.000403     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 150     |\n",
      "|    iterations      | 542     |\n",
      "|    time_elapsed    | 7395    |\n",
      "|    total_timesteps | 1110016 |\n",
      "--------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 150        |\n",
      "|    iterations           | 543        |\n",
      "|    time_elapsed         | 7400       |\n",
      "|    total_timesteps      | 1112064    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02721114 |\n",
      "|    clip_fraction        | 0.249      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.09      |\n",
      "|    explained_variance   | 0.844      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.045     |\n",
      "|    n_updates            | 5420       |\n",
      "|    policy_gradient_loss | -0.0108    |\n",
      "|    value_loss           | 0.000579   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 150         |\n",
      "|    iterations           | 544         |\n",
      "|    time_elapsed         | 7406        |\n",
      "|    total_timesteps      | 1114112     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016679574 |\n",
      "|    clip_fraction        | 0.263       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.23       |\n",
      "|    explained_variance   | -0.129      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0187     |\n",
      "|    n_updates            | 5430        |\n",
      "|    policy_gradient_loss | -0.0174     |\n",
      "|    value_loss           | 6.56e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 150         |\n",
      "|    iterations           | 545         |\n",
      "|    time_elapsed         | 7411        |\n",
      "|    total_timesteps      | 1116160     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014098752 |\n",
      "|    clip_fraction        | 0.214       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.36       |\n",
      "|    explained_variance   | 0.887       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0187      |\n",
      "|    n_updates            | 5440        |\n",
      "|    policy_gradient_loss | -0.0144     |\n",
      "|    value_loss           | 5.75e-06    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 150         |\n",
      "|    iterations           | 546         |\n",
      "|    time_elapsed         | 7416        |\n",
      "|    total_timesteps      | 1118208     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016758997 |\n",
      "|    clip_fraction        | 0.32        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.4        |\n",
      "|    explained_variance   | 0.522       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0487     |\n",
      "|    n_updates            | 5450        |\n",
      "|    policy_gradient_loss | -0.0244     |\n",
      "|    value_loss           | 3.36e-06    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1120000, episode_reward=0.07 +/- 0.36\n",
      "Episode length: 10000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+04       |\n",
      "|    mean_reward          | 0.0672      |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1120000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017292548 |\n",
      "|    clip_fraction        | 0.315       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.36       |\n",
      "|    explained_variance   | 0.812       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0128     |\n",
      "|    n_updates            | 5460        |\n",
      "|    policy_gradient_loss | -0.0184     |\n",
      "|    value_loss           | 5.87e-06    |\n",
      "-----------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 150     |\n",
      "|    iterations      | 547     |\n",
      "|    time_elapsed    | 7464    |\n",
      "|    total_timesteps | 1120256 |\n",
      "--------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 150        |\n",
      "|    iterations           | 548        |\n",
      "|    time_elapsed         | 7469       |\n",
      "|    total_timesteps      | 1122304    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01568147 |\n",
      "|    clip_fraction        | 0.121      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.34      |\n",
      "|    explained_variance   | 0.953      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.00224   |\n",
      "|    n_updates            | 5470       |\n",
      "|    policy_gradient_loss | -0.0039    |\n",
      "|    value_loss           | 0.00047    |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 150          |\n",
      "|    iterations           | 549          |\n",
      "|    time_elapsed         | 7474         |\n",
      "|    total_timesteps      | 1124352      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0039696814 |\n",
      "|    clip_fraction        | 0.0652       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.67        |\n",
      "|    explained_variance   | 0.739        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0315       |\n",
      "|    n_updates            | 5480         |\n",
      "|    policy_gradient_loss | -0.00286     |\n",
      "|    value_loss           | 0.000384     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 150         |\n",
      "|    iterations           | 550         |\n",
      "|    time_elapsed         | 7480        |\n",
      "|    total_timesteps      | 1126400     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004442412 |\n",
      "|    clip_fraction        | 0.0718      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.686      |\n",
      "|    explained_variance   | 0.693       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00632    |\n",
      "|    n_updates            | 5490        |\n",
      "|    policy_gradient_loss | -0.00186    |\n",
      "|    value_loss           | 0.000135    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 150         |\n",
      "|    iterations           | 551         |\n",
      "|    time_elapsed         | 7485        |\n",
      "|    total_timesteps      | 1128448     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003882024 |\n",
      "|    clip_fraction        | 0.0569      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.762      |\n",
      "|    explained_variance   | 0.309       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00862    |\n",
      "|    n_updates            | 5500        |\n",
      "|    policy_gradient_loss | -0.00236    |\n",
      "|    value_loss           | 8.02e-05    |\n",
      "-----------------------------------------\n",
      "box reached target\n",
      "Eval num_timesteps=1130000, episode_reward=1.02 +/- 2.04\n",
      "Episode length: 8042.20 +/- 3915.60\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 8.04e+03    |\n",
      "|    mean_reward          | 1.02        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1130000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010656645 |\n",
      "|    clip_fraction        | 0.135       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.84       |\n",
      "|    explained_variance   | 0.768       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0067      |\n",
      "|    n_updates            | 5510        |\n",
      "|    policy_gradient_loss | -0.015      |\n",
      "|    value_loss           | 6.41e-05    |\n",
      "-----------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 150     |\n",
      "|    iterations      | 552     |\n",
      "|    time_elapsed    | 7525    |\n",
      "|    total_timesteps | 1130496 |\n",
      "--------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 150        |\n",
      "|    iterations           | 553        |\n",
      "|    time_elapsed         | 7530       |\n",
      "|    total_timesteps      | 1132544    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04337132 |\n",
      "|    clip_fraction        | 0.193      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.21      |\n",
      "|    explained_variance   | 0.907      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0332    |\n",
      "|    n_updates            | 5520       |\n",
      "|    policy_gradient_loss | -0.0187    |\n",
      "|    value_loss           | 0.000131   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 150         |\n",
      "|    iterations           | 554         |\n",
      "|    time_elapsed         | 7535        |\n",
      "|    total_timesteps      | 1134592     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012299363 |\n",
      "|    clip_fraction        | 0.109       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.31       |\n",
      "|    explained_variance   | 0.939       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0179     |\n",
      "|    n_updates            | 5530        |\n",
      "|    policy_gradient_loss | -0.0121     |\n",
      "|    value_loss           | 5.98e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 150         |\n",
      "|    iterations           | 555         |\n",
      "|    time_elapsed         | 7541        |\n",
      "|    total_timesteps      | 1136640     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015291369 |\n",
      "|    clip_fraction        | 0.203       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.28       |\n",
      "|    explained_variance   | 0.946       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0161     |\n",
      "|    n_updates            | 5540        |\n",
      "|    policy_gradient_loss | -0.0161     |\n",
      "|    value_loss           | 5.66e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 150         |\n",
      "|    iterations           | 556         |\n",
      "|    time_elapsed         | 7546        |\n",
      "|    total_timesteps      | 1138688     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019523365 |\n",
      "|    clip_fraction        | 0.242       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.35       |\n",
      "|    explained_variance   | 0.971       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.014       |\n",
      "|    n_updates            | 5550        |\n",
      "|    policy_gradient_loss | -0.0125     |\n",
      "|    value_loss           | 2.17e-05    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1140000, episode_reward=0.24 +/- 0.25\n",
      "Episode length: 10000.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1e+04      |\n",
      "|    mean_reward          | 0.243      |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 1140000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01909111 |\n",
      "|    clip_fraction        | 0.21       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.26      |\n",
      "|    explained_variance   | 0.918      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.02      |\n",
      "|    n_updates            | 5560       |\n",
      "|    policy_gradient_loss | -0.0137    |\n",
      "|    value_loss           | 7.87e-05   |\n",
      "----------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 150     |\n",
      "|    iterations      | 557     |\n",
      "|    time_elapsed    | 7594    |\n",
      "|    total_timesteps | 1140736 |\n",
      "--------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 150         |\n",
      "|    iterations           | 558         |\n",
      "|    time_elapsed         | 7599        |\n",
      "|    total_timesteps      | 1142784     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013511572 |\n",
      "|    clip_fraction        | 0.101       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.16       |\n",
      "|    explained_variance   | 0.964       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00606     |\n",
      "|    n_updates            | 5570        |\n",
      "|    policy_gradient_loss | -0.00879    |\n",
      "|    value_loss           | 0.000152    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 150         |\n",
      "|    iterations           | 559         |\n",
      "|    time_elapsed         | 7604        |\n",
      "|    total_timesteps      | 1144832     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019065585 |\n",
      "|    clip_fraction        | 0.146       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.24       |\n",
      "|    explained_variance   | 0.916       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0168      |\n",
      "|    n_updates            | 5580        |\n",
      "|    policy_gradient_loss | -0.0157     |\n",
      "|    value_loss           | 0.000734    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 150         |\n",
      "|    iterations           | 560         |\n",
      "|    time_elapsed         | 7609        |\n",
      "|    total_timesteps      | 1146880     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020373348 |\n",
      "|    clip_fraction        | 0.251       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.29       |\n",
      "|    explained_variance   | 0.942       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0546     |\n",
      "|    n_updates            | 5590        |\n",
      "|    policy_gradient_loss | -0.02       |\n",
      "|    value_loss           | 0.000193    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 150         |\n",
      "|    iterations           | 561         |\n",
      "|    time_elapsed         | 7615        |\n",
      "|    total_timesteps      | 1148928     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032234874 |\n",
      "|    clip_fraction        | 0.226       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.3        |\n",
      "|    explained_variance   | 0.93        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0461     |\n",
      "|    n_updates            | 5600        |\n",
      "|    policy_gradient_loss | -0.0245     |\n",
      "|    value_loss           | 0.000331    |\n",
      "-----------------------------------------\n",
      "box reached target\n",
      "box reached target\n",
      "Eval num_timesteps=1150000, episode_reward=2.09 +/- 2.55\n",
      "Episode length: 6192.60 +/- 4666.79\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 6.19e+03    |\n",
      "|    mean_reward          | 2.09        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1150000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022060195 |\n",
      "|    clip_fraction        | 0.205       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.28       |\n",
      "|    explained_variance   | 0.877       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0194     |\n",
      "|    n_updates            | 5610        |\n",
      "|    policy_gradient_loss | -0.0152     |\n",
      "|    value_loss           | 0.00035     |\n",
      "-----------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 150     |\n",
      "|    iterations      | 562     |\n",
      "|    time_elapsed    | 7647    |\n",
      "|    total_timesteps | 1150976 |\n",
      "--------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 150         |\n",
      "|    iterations           | 563         |\n",
      "|    time_elapsed         | 7652        |\n",
      "|    total_timesteps      | 1153024     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019246008 |\n",
      "|    clip_fraction        | 0.22        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.15       |\n",
      "|    explained_variance   | 0.876       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00782     |\n",
      "|    n_updates            | 5620        |\n",
      "|    policy_gradient_loss | -0.0146     |\n",
      "|    value_loss           | 0.000386    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 150        |\n",
      "|    iterations           | 564        |\n",
      "|    time_elapsed         | 7658       |\n",
      "|    total_timesteps      | 1155072    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01239808 |\n",
      "|    clip_fraction        | 0.204      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.22      |\n",
      "|    explained_variance   | 0.832      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.017     |\n",
      "|    n_updates            | 5630       |\n",
      "|    policy_gradient_loss | -0.0105    |\n",
      "|    value_loss           | 3.51e-05   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 150         |\n",
      "|    iterations           | 565         |\n",
      "|    time_elapsed         | 7663        |\n",
      "|    total_timesteps      | 1157120     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014598349 |\n",
      "|    clip_fraction        | 0.219       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.22       |\n",
      "|    explained_variance   | 0.426       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0264     |\n",
      "|    n_updates            | 5640        |\n",
      "|    policy_gradient_loss | -0.012      |\n",
      "|    value_loss           | 3.25e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 566         |\n",
      "|    time_elapsed         | 7668        |\n",
      "|    total_timesteps      | 1159168     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014986552 |\n",
      "|    clip_fraction        | 0.24        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.29       |\n",
      "|    explained_variance   | 0.719       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0314     |\n",
      "|    n_updates            | 5650        |\n",
      "|    policy_gradient_loss | -0.0167     |\n",
      "|    value_loss           | 1.6e-05     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1160000, episode_reward=0.45 +/- 0.48\n",
      "Episode length: 10000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+04       |\n",
      "|    mean_reward          | 0.45        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1160000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016950713 |\n",
      "|    clip_fraction        | 0.346       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.28       |\n",
      "|    explained_variance   | 0.723       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0483     |\n",
      "|    n_updates            | 5660        |\n",
      "|    policy_gradient_loss | -0.0259     |\n",
      "|    value_loss           | 1.79e-05    |\n",
      "-----------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 150     |\n",
      "|    iterations      | 567     |\n",
      "|    time_elapsed    | 7716    |\n",
      "|    total_timesteps | 1161216 |\n",
      "--------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 150         |\n",
      "|    iterations           | 568         |\n",
      "|    time_elapsed         | 7721        |\n",
      "|    total_timesteps      | 1163264     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009705357 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.989      |\n",
      "|    explained_variance   | 0.883       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.023      |\n",
      "|    n_updates            | 5670        |\n",
      "|    policy_gradient_loss | -0.00565    |\n",
      "|    value_loss           | 8.69e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 150         |\n",
      "|    iterations           | 569         |\n",
      "|    time_elapsed         | 7727        |\n",
      "|    total_timesteps      | 1165312     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009483391 |\n",
      "|    clip_fraction        | 0.113       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.79       |\n",
      "|    explained_variance   | 0.95        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0343     |\n",
      "|    n_updates            | 5680        |\n",
      "|    policy_gradient_loss | -0.00619    |\n",
      "|    value_loss           | 7.53e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 150         |\n",
      "|    iterations           | 570         |\n",
      "|    time_elapsed         | 7732        |\n",
      "|    total_timesteps      | 1167360     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015954144 |\n",
      "|    clip_fraction        | 0.165       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.14       |\n",
      "|    explained_variance   | 0.871       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.038      |\n",
      "|    n_updates            | 5690        |\n",
      "|    policy_gradient_loss | -0.0155     |\n",
      "|    value_loss           | 2.19e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 571         |\n",
      "|    time_elapsed         | 7737        |\n",
      "|    total_timesteps      | 1169408     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007121041 |\n",
      "|    clip_fraction        | 0.0915      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.14       |\n",
      "|    explained_variance   | 0.469       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00995     |\n",
      "|    n_updates            | 5700        |\n",
      "|    policy_gradient_loss | -0.00167    |\n",
      "|    value_loss           | 2.32e-05    |\n",
      "-----------------------------------------\n",
      "box reached target\n",
      "Eval num_timesteps=1170000, episode_reward=1.04 +/- 2.08\n",
      "Episode length: 8045.40 +/- 3909.20\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 8.05e+03    |\n",
      "|    mean_reward          | 1.04        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1170000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008715887 |\n",
      "|    clip_fraction        | 0.137       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.1        |\n",
      "|    explained_variance   | 0.204       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0118      |\n",
      "|    n_updates            | 5710        |\n",
      "|    policy_gradient_loss | -0.00572    |\n",
      "|    value_loss           | 4.36e-05    |\n",
      "-----------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 150     |\n",
      "|    iterations      | 572     |\n",
      "|    time_elapsed    | 7777    |\n",
      "|    total_timesteps | 1171456 |\n",
      "--------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 150        |\n",
      "|    iterations           | 573        |\n",
      "|    time_elapsed         | 7782       |\n",
      "|    total_timesteps      | 1173504    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01998135 |\n",
      "|    clip_fraction        | 0.166      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.16      |\n",
      "|    explained_variance   | 0.537      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0349    |\n",
      "|    n_updates            | 5720       |\n",
      "|    policy_gradient_loss | -0.0156    |\n",
      "|    value_loss           | 0.000164   |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 150       |\n",
      "|    iterations           | 574       |\n",
      "|    time_elapsed         | 7788      |\n",
      "|    total_timesteps      | 1175552   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0292423 |\n",
      "|    clip_fraction        | 0.211     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -1.27     |\n",
      "|    explained_variance   | 0.894     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -0.0467   |\n",
      "|    n_updates            | 5730      |\n",
      "|    policy_gradient_loss | -0.0189   |\n",
      "|    value_loss           | 3.62e-05  |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 575         |\n",
      "|    time_elapsed         | 7793        |\n",
      "|    total_timesteps      | 1177600     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012419162 |\n",
      "|    clip_fraction        | 0.164       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.34       |\n",
      "|    explained_variance   | 0.681       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00647    |\n",
      "|    n_updates            | 5740        |\n",
      "|    policy_gradient_loss | -0.00968    |\n",
      "|    value_loss           | 1.23e-05    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 151          |\n",
      "|    iterations           | 576          |\n",
      "|    time_elapsed         | 7798         |\n",
      "|    total_timesteps      | 1179648      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073606824 |\n",
      "|    clip_fraction        | 0.128        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.4         |\n",
      "|    explained_variance   | -0.0743      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.026       |\n",
      "|    n_updates            | 5750         |\n",
      "|    policy_gradient_loss | -0.00516     |\n",
      "|    value_loss           | 5.02e-05     |\n",
      "------------------------------------------\n",
      "box reached target\n",
      "Eval num_timesteps=1180000, episode_reward=1.31 +/- 2.42\n",
      "Episode length: 8316.60 +/- 3366.80\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 8.32e+03   |\n",
      "|    mean_reward          | 1.31       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 1180000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01218235 |\n",
      "|    clip_fraction        | 0.134      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.37      |\n",
      "|    explained_variance   | 0.503      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0239    |\n",
      "|    n_updates            | 5760       |\n",
      "|    policy_gradient_loss | -0.00215   |\n",
      "|    value_loss           | 1.03e-05   |\n",
      "----------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 150     |\n",
      "|    iterations      | 577     |\n",
      "|    time_elapsed    | 7839    |\n",
      "|    total_timesteps | 1181696 |\n",
      "--------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 150        |\n",
      "|    iterations           | 578        |\n",
      "|    time_elapsed         | 7844       |\n",
      "|    total_timesteps      | 1183744    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01228961 |\n",
      "|    clip_fraction        | 0.103      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.21      |\n",
      "|    explained_variance   | 0.902      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.00968    |\n",
      "|    n_updates            | 5770       |\n",
      "|    policy_gradient_loss | -0.0106    |\n",
      "|    value_loss           | 3.81e-05   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 579         |\n",
      "|    time_elapsed         | 7850        |\n",
      "|    total_timesteps      | 1185792     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013511313 |\n",
      "|    clip_fraction        | 0.189       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.4        |\n",
      "|    explained_variance   | 0.939       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0203     |\n",
      "|    n_updates            | 5780        |\n",
      "|    policy_gradient_loss | -0.00925    |\n",
      "|    value_loss           | 5.75e-06    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 580         |\n",
      "|    time_elapsed         | 7855        |\n",
      "|    total_timesteps      | 1187840     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008124585 |\n",
      "|    clip_fraction        | 0.101       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.43       |\n",
      "|    explained_variance   | 0.871       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0093     |\n",
      "|    n_updates            | 5790        |\n",
      "|    policy_gradient_loss | -0.00462    |\n",
      "|    value_loss           | 1.05e-06    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 151          |\n",
      "|    iterations           | 581          |\n",
      "|    time_elapsed         | 7861         |\n",
      "|    total_timesteps      | 1189888      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0105223935 |\n",
      "|    clip_fraction        | 0.102        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.41        |\n",
      "|    explained_variance   | 0.737        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.00952     |\n",
      "|    n_updates            | 5800         |\n",
      "|    policy_gradient_loss | -0.00387     |\n",
      "|    value_loss           | 1.23e-06     |\n",
      "------------------------------------------\n",
      "box reached target\n",
      "Eval num_timesteps=1190000, episode_reward=1.06 +/- 2.12\n",
      "Episode length: 8077.40 +/- 3845.20\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 8.08e+03    |\n",
      "|    mean_reward          | 1.06        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1190000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012008624 |\n",
      "|    clip_fraction        | 0.163       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.37       |\n",
      "|    explained_variance   | 0.646       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00557    |\n",
      "|    n_updates            | 5810        |\n",
      "|    policy_gradient_loss | -0.00678    |\n",
      "|    value_loss           | 8.26e-06    |\n",
      "-----------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 150     |\n",
      "|    iterations      | 582     |\n",
      "|    time_elapsed    | 7901    |\n",
      "|    total_timesteps | 1191936 |\n",
      "--------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 583         |\n",
      "|    time_elapsed         | 7906        |\n",
      "|    total_timesteps      | 1193984     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014158923 |\n",
      "|    clip_fraction        | 0.219       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.32       |\n",
      "|    explained_variance   | 0.935       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0228     |\n",
      "|    n_updates            | 5820        |\n",
      "|    policy_gradient_loss | -0.0118     |\n",
      "|    value_loss           | 3.54e-05    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 151        |\n",
      "|    iterations           | 584        |\n",
      "|    time_elapsed         | 7912       |\n",
      "|    total_timesteps      | 1196032    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00979754 |\n",
      "|    clip_fraction        | 0.109      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.01      |\n",
      "|    explained_variance   | -0.0647    |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0077     |\n",
      "|    n_updates            | 5830       |\n",
      "|    policy_gradient_loss | 0.000978   |\n",
      "|    value_loss           | 0.000108   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 585         |\n",
      "|    time_elapsed         | 7917        |\n",
      "|    total_timesteps      | 1198080     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008221971 |\n",
      "|    clip_fraction        | 0.132       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.92       |\n",
      "|    explained_variance   | -0.0503     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.022       |\n",
      "|    n_updates            | 5840        |\n",
      "|    policy_gradient_loss | 0.00071     |\n",
      "|    value_loss           | 1.5e-05     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1200000, episode_reward=-0.03 +/- 0.07\n",
      "Episode length: 10000.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1e+04        |\n",
      "|    mean_reward          | -0.0327      |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1200000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0065209204 |\n",
      "|    clip_fraction        | 0.109        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.755       |\n",
      "|    explained_variance   | -0.0436      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.00403     |\n",
      "|    n_updates            | 5850         |\n",
      "|    policy_gradient_loss | 0.0011       |\n",
      "|    value_loss           | 5.59e-06     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 150     |\n",
      "|    iterations      | 586     |\n",
      "|    time_elapsed    | 7966    |\n",
      "|    total_timesteps | 1200128 |\n",
      "--------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 150        |\n",
      "|    iterations           | 587        |\n",
      "|    time_elapsed         | 7971       |\n",
      "|    total_timesteps      | 1202176    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.07960592 |\n",
      "|    clip_fraction        | 0.282      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.03      |\n",
      "|    explained_variance   | 0.949      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.022     |\n",
      "|    n_updates            | 5860       |\n",
      "|    policy_gradient_loss | -0.00829   |\n",
      "|    value_loss           | 3.14e-05   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 150         |\n",
      "|    iterations           | 588         |\n",
      "|    time_elapsed         | 7977        |\n",
      "|    total_timesteps      | 1204224     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015153749 |\n",
      "|    clip_fraction        | 0.18        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.14       |\n",
      "|    explained_variance   | 0.968       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00589    |\n",
      "|    n_updates            | 5870        |\n",
      "|    policy_gradient_loss | -0.0111     |\n",
      "|    value_loss           | 2.47e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 589         |\n",
      "|    time_elapsed         | 7983        |\n",
      "|    total_timesteps      | 1206272     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017860007 |\n",
      "|    clip_fraction        | 0.159       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.32       |\n",
      "|    explained_variance   | 0.955       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0284     |\n",
      "|    n_updates            | 5880        |\n",
      "|    policy_gradient_loss | -0.00951    |\n",
      "|    value_loss           | 3.28e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 590         |\n",
      "|    time_elapsed         | 7988        |\n",
      "|    total_timesteps      | 1208320     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019354308 |\n",
      "|    clip_fraction        | 0.164       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.14       |\n",
      "|    explained_variance   | 0.672       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00852    |\n",
      "|    n_updates            | 5890        |\n",
      "|    policy_gradient_loss | -0.0126     |\n",
      "|    value_loss           | 3.27e-05    |\n",
      "-----------------------------------------\n",
      "box reached target\n",
      "Eval num_timesteps=1210000, episode_reward=0.99 +/- 2.03\n",
      "Episode length: 8012.00 +/- 3976.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 8.01e+03    |\n",
      "|    mean_reward          | 0.994       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1210000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010817675 |\n",
      "|    clip_fraction        | 0.108       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.08       |\n",
      "|    explained_variance   | -0.683      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00155     |\n",
      "|    n_updates            | 5900        |\n",
      "|    policy_gradient_loss | -0.00269    |\n",
      "|    value_loss           | 5.65e-06    |\n",
      "-----------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 150     |\n",
      "|    iterations      | 591     |\n",
      "|    time_elapsed    | 8028    |\n",
      "|    total_timesteps | 1210368 |\n",
      "--------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 150         |\n",
      "|    iterations           | 592         |\n",
      "|    time_elapsed         | 8034        |\n",
      "|    total_timesteps      | 1212416     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008986984 |\n",
      "|    clip_fraction        | 0.081       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.17       |\n",
      "|    explained_variance   | 0.944       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00795    |\n",
      "|    n_updates            | 5910        |\n",
      "|    policy_gradient_loss | -0.00623    |\n",
      "|    value_loss           | 3.35e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 593         |\n",
      "|    time_elapsed         | 8039        |\n",
      "|    total_timesteps      | 1214464     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026697401 |\n",
      "|    clip_fraction        | 0.256       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.42       |\n",
      "|    explained_variance   | 0.935       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0428     |\n",
      "|    n_updates            | 5920        |\n",
      "|    policy_gradient_loss | -0.0168     |\n",
      "|    value_loss           | 1.03e-05    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 151          |\n",
      "|    iterations           | 594          |\n",
      "|    time_elapsed         | 8045         |\n",
      "|    total_timesteps      | 1216512      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0126499785 |\n",
      "|    clip_fraction        | 0.191        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.45        |\n",
      "|    explained_variance   | 0.94         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.00175      |\n",
      "|    n_updates            | 5930         |\n",
      "|    policy_gradient_loss | -0.0122      |\n",
      "|    value_loss           | 4.55e-07     |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 151        |\n",
      "|    iterations           | 595        |\n",
      "|    time_elapsed         | 8050       |\n",
      "|    total_timesteps      | 1218560    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01235615 |\n",
      "|    clip_fraction        | 0.212      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.48      |\n",
      "|    explained_variance   | 0.888      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0128    |\n",
      "|    n_updates            | 5940       |\n",
      "|    policy_gradient_loss | -0.0134    |\n",
      "|    value_loss           | 3.63e-06   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=1220000, episode_reward=0.04 +/- 0.07\n",
      "Episode length: 10000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+04       |\n",
      "|    mean_reward          | 0.036       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1220000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014175589 |\n",
      "|    clip_fraction        | 0.196       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.44       |\n",
      "|    explained_variance   | 0.953       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0138     |\n",
      "|    n_updates            | 5950        |\n",
      "|    policy_gradient_loss | -0.0153     |\n",
      "|    value_loss           | 1.02e-06    |\n",
      "-----------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 150     |\n",
      "|    iterations      | 596     |\n",
      "|    time_elapsed    | 8099    |\n",
      "|    total_timesteps | 1220608 |\n",
      "--------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 150         |\n",
      "|    iterations           | 597         |\n",
      "|    time_elapsed         | 8104        |\n",
      "|    total_timesteps      | 1222656     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007380931 |\n",
      "|    clip_fraction        | 0.0711      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.4        |\n",
      "|    explained_variance   | 0.912       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0223     |\n",
      "|    n_updates            | 5960        |\n",
      "|    policy_gradient_loss | -0.00426    |\n",
      "|    value_loss           | 3.59e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 598         |\n",
      "|    time_elapsed         | 8110        |\n",
      "|    total_timesteps      | 1224704     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008070125 |\n",
      "|    clip_fraction        | 0.166       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.43       |\n",
      "|    explained_variance   | 0.93        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0319     |\n",
      "|    n_updates            | 5970        |\n",
      "|    policy_gradient_loss | -0.00805    |\n",
      "|    value_loss           | 1.86e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 599         |\n",
      "|    time_elapsed         | 8115        |\n",
      "|    total_timesteps      | 1226752     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014692271 |\n",
      "|    clip_fraction        | 0.159       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.43       |\n",
      "|    explained_variance   | 0.945       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00221    |\n",
      "|    n_updates            | 5980        |\n",
      "|    policy_gradient_loss | -0.0106     |\n",
      "|    value_loss           | 1.2e-06     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 600         |\n",
      "|    time_elapsed         | 8121        |\n",
      "|    total_timesteps      | 1228800     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011372215 |\n",
      "|    clip_fraction        | 0.14        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.36       |\n",
      "|    explained_variance   | 0.955       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0367     |\n",
      "|    n_updates            | 5990        |\n",
      "|    policy_gradient_loss | -0.00705    |\n",
      "|    value_loss           | 2.8e-06     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1230000, episode_reward=0.15 +/- 0.24\n",
      "Episode length: 10000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+04       |\n",
      "|    mean_reward          | 0.15        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1230000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007195754 |\n",
      "|    clip_fraction        | 0.117       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.32       |\n",
      "|    explained_variance   | 0.89        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00725    |\n",
      "|    n_updates            | 6000        |\n",
      "|    policy_gradient_loss | -0.00292    |\n",
      "|    value_loss           | 7.69e-07    |\n",
      "-----------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 150     |\n",
      "|    iterations      | 601     |\n",
      "|    time_elapsed    | 8168    |\n",
      "|    total_timesteps | 1230848 |\n",
      "--------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 150         |\n",
      "|    iterations           | 602         |\n",
      "|    time_elapsed         | 8174        |\n",
      "|    total_timesteps      | 1232896     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008304933 |\n",
      "|    clip_fraction        | 0.0697      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.29       |\n",
      "|    explained_variance   | 0.911       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.018       |\n",
      "|    n_updates            | 6010        |\n",
      "|    policy_gradient_loss | -0.00662    |\n",
      "|    value_loss           | 4.83e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 150         |\n",
      "|    iterations           | 603         |\n",
      "|    time_elapsed         | 8180        |\n",
      "|    total_timesteps      | 1234944     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015481787 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.2        |\n",
      "|    explained_variance   | 0.928       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0231     |\n",
      "|    n_updates            | 6020        |\n",
      "|    policy_gradient_loss | -0.0103     |\n",
      "|    value_loss           | 1.3e-05     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 604         |\n",
      "|    time_elapsed         | 8185        |\n",
      "|    total_timesteps      | 1236992     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010509253 |\n",
      "|    clip_fraction        | 0.0763      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.935      |\n",
      "|    explained_variance   | 0.342       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0109     |\n",
      "|    n_updates            | 6030        |\n",
      "|    policy_gradient_loss | -0.00268    |\n",
      "|    value_loss           | 8.21e-06    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 605         |\n",
      "|    time_elapsed         | 8191        |\n",
      "|    total_timesteps      | 1239040     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005388968 |\n",
      "|    clip_fraction        | 0.0567      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.02       |\n",
      "|    explained_variance   | 0.264       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0118     |\n",
      "|    n_updates            | 6040        |\n",
      "|    policy_gradient_loss | -0.000499   |\n",
      "|    value_loss           | 7.19e-06    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1240000, episode_reward=0.39 +/- 0.53\n",
      "Episode length: 10000.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1e+04        |\n",
      "|    mean_reward          | 0.394        |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1240000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0014683377 |\n",
      "|    clip_fraction        | 0.0358       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.01        |\n",
      "|    explained_variance   | 0.394        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.00689      |\n",
      "|    n_updates            | 6050         |\n",
      "|    policy_gradient_loss | -0.000602    |\n",
      "|    value_loss           | 1.2e-05      |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 150     |\n",
      "|    iterations      | 606     |\n",
      "|    time_elapsed    | 8239    |\n",
      "|    total_timesteps | 1241088 |\n",
      "--------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 150         |\n",
      "|    iterations           | 607         |\n",
      "|    time_elapsed         | 8244        |\n",
      "|    total_timesteps      | 1243136     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005854395 |\n",
      "|    clip_fraction        | 0.0635      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.926      |\n",
      "|    explained_variance   | 0.865       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.000785    |\n",
      "|    n_updates            | 6060        |\n",
      "|    policy_gradient_loss | -0.00783    |\n",
      "|    value_loss           | 1.81e-05    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 150        |\n",
      "|    iterations           | 608        |\n",
      "|    time_elapsed         | 8249       |\n",
      "|    total_timesteps      | 1245184    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00375496 |\n",
      "|    clip_fraction        | 0.0839     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.896     |\n",
      "|    explained_variance   | 0.892      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.00217    |\n",
      "|    n_updates            | 6070       |\n",
      "|    policy_gradient_loss | -0.00378   |\n",
      "|    value_loss           | 2.61e-05   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 609         |\n",
      "|    time_elapsed         | 8255        |\n",
      "|    total_timesteps      | 1247232     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011119662 |\n",
      "|    clip_fraction        | 0.199       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.19       |\n",
      "|    explained_variance   | 0.867       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0247     |\n",
      "|    n_updates            | 6080        |\n",
      "|    policy_gradient_loss | -0.0105     |\n",
      "|    value_loss           | 1.21e-05    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 151        |\n",
      "|    iterations           | 610        |\n",
      "|    time_elapsed         | 8260       |\n",
      "|    total_timesteps      | 1249280    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01511439 |\n",
      "|    clip_fraction        | 0.305      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.28      |\n",
      "|    explained_variance   | 0.883      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0114    |\n",
      "|    n_updates            | 6090       |\n",
      "|    policy_gradient_loss | -0.0141    |\n",
      "|    value_loss           | 3.7e-06    |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=1250000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 10000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+04       |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1250000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018240137 |\n",
      "|    clip_fraction        | 0.294       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.26       |\n",
      "|    explained_variance   | 0.845       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0344     |\n",
      "|    n_updates            | 6100        |\n",
      "|    policy_gradient_loss | -0.0159     |\n",
      "|    value_loss           | 1.65e-05    |\n",
      "-----------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 150     |\n",
      "|    iterations      | 611     |\n",
      "|    time_elapsed    | 8307    |\n",
      "|    total_timesteps | 1251328 |\n",
      "--------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 150         |\n",
      "|    iterations           | 612         |\n",
      "|    time_elapsed         | 8313        |\n",
      "|    total_timesteps      | 1253376     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016093127 |\n",
      "|    clip_fraction        | 0.125       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.13       |\n",
      "|    explained_variance   | 0.931       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0298     |\n",
      "|    n_updates            | 6110        |\n",
      "|    policy_gradient_loss | -0.00755    |\n",
      "|    value_loss           | 1.66e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 150         |\n",
      "|    iterations           | 613         |\n",
      "|    time_elapsed         | 8318        |\n",
      "|    total_timesteps      | 1255424     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011829453 |\n",
      "|    clip_fraction        | 0.104       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.26       |\n",
      "|    explained_variance   | 0.925       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0435     |\n",
      "|    n_updates            | 6120        |\n",
      "|    policy_gradient_loss | -0.0107     |\n",
      "|    value_loss           | 9.59e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 614         |\n",
      "|    time_elapsed         | 8324        |\n",
      "|    total_timesteps      | 1257472     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016177028 |\n",
      "|    clip_fraction        | 0.281       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.34       |\n",
      "|    explained_variance   | -0.399      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00155    |\n",
      "|    n_updates            | 6130        |\n",
      "|    policy_gradient_loss | -0.0155     |\n",
      "|    value_loss           | 1.23e-06    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 615         |\n",
      "|    time_elapsed         | 8329        |\n",
      "|    total_timesteps      | 1259520     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010421952 |\n",
      "|    clip_fraction        | 0.156       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.34       |\n",
      "|    explained_variance   | -1.86       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00645    |\n",
      "|    n_updates            | 6140        |\n",
      "|    policy_gradient_loss | -0.00577    |\n",
      "|    value_loss           | 2.57e-06    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1260000, episode_reward=0.11 +/- 0.21\n",
      "Episode length: 10000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+04       |\n",
      "|    mean_reward          | 0.107       |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1260000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008615721 |\n",
      "|    clip_fraction        | 0.0682      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.32       |\n",
      "|    explained_variance   | -1.32       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0322     |\n",
      "|    n_updates            | 6150        |\n",
      "|    policy_gradient_loss | -0.00212    |\n",
      "|    value_loss           | 3.91e-07    |\n",
      "-----------------------------------------\n",
      "box reached target\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 150     |\n",
      "|    iterations      | 616     |\n",
      "|    time_elapsed    | 8378    |\n",
      "|    total_timesteps | 1261568 |\n",
      "--------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 150         |\n",
      "|    iterations           | 617         |\n",
      "|    time_elapsed         | 8383        |\n",
      "|    total_timesteps      | 1263616     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009720441 |\n",
      "|    clip_fraction        | 0.108       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.17       |\n",
      "|    explained_variance   | -0.12       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0265     |\n",
      "|    n_updates            | 6160        |\n",
      "|    policy_gradient_loss | -0.00429    |\n",
      "|    value_loss           | 0.0436      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 150        |\n",
      "|    iterations           | 618        |\n",
      "|    time_elapsed         | 8389       |\n",
      "|    total_timesteps      | 1265664    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03206926 |\n",
      "|    clip_fraction        | 0.255      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.4       |\n",
      "|    explained_variance   | 0.744      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.029     |\n",
      "|    n_updates            | 6170       |\n",
      "|    policy_gradient_loss | -0.0232    |\n",
      "|    value_loss           | 0.000617   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 619         |\n",
      "|    time_elapsed         | 8394        |\n",
      "|    total_timesteps      | 1267712     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019635074 |\n",
      "|    clip_fraction        | 0.295       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.36       |\n",
      "|    explained_variance   | -5.8        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0301     |\n",
      "|    n_updates            | 6180        |\n",
      "|    policy_gradient_loss | -0.0141     |\n",
      "|    value_loss           | 1.64e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 620         |\n",
      "|    time_elapsed         | 8400        |\n",
      "|    total_timesteps      | 1269760     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014238716 |\n",
      "|    clip_fraction        | 0.152       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.32       |\n",
      "|    explained_variance   | -0.137      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0383      |\n",
      "|    n_updates            | 6190        |\n",
      "|    policy_gradient_loss | -0.0075     |\n",
      "|    value_loss           | 1.52e-05    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1270000, episode_reward=0.03 +/- 0.07\n",
      "Episode length: 10000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+04       |\n",
      "|    mean_reward          | 0.0348      |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1270000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011890177 |\n",
      "|    clip_fraction        | 0.107       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.25       |\n",
      "|    explained_variance   | -0.241      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.000712   |\n",
      "|    n_updates            | 6200        |\n",
      "|    policy_gradient_loss | -0.00588    |\n",
      "|    value_loss           | 3.18e-06    |\n",
      "-----------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 150     |\n",
      "|    iterations      | 621     |\n",
      "|    time_elapsed    | 8448    |\n",
      "|    total_timesteps | 1271808 |\n",
      "--------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 150         |\n",
      "|    iterations           | 622         |\n",
      "|    time_elapsed         | 8454        |\n",
      "|    total_timesteps      | 1273856     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019976512 |\n",
      "|    clip_fraction        | 0.306       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.03       |\n",
      "|    explained_variance   | 0.259       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0247     |\n",
      "|    n_updates            | 6210        |\n",
      "|    policy_gradient_loss | -0.0253     |\n",
      "|    value_loss           | 0.00157     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 150         |\n",
      "|    iterations           | 623         |\n",
      "|    time_elapsed         | 8459        |\n",
      "|    total_timesteps      | 1275904     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019680804 |\n",
      "|    clip_fraction        | 0.378       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.19       |\n",
      "|    explained_variance   | 0.117       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0624     |\n",
      "|    n_updates            | 6220        |\n",
      "|    policy_gradient_loss | -0.0359     |\n",
      "|    value_loss           | 0.00209     |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 150        |\n",
      "|    iterations           | 624        |\n",
      "|    time_elapsed         | 8465       |\n",
      "|    total_timesteps      | 1277952    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01880095 |\n",
      "|    clip_fraction        | 0.374      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.27      |\n",
      "|    explained_variance   | 0.344      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0247    |\n",
      "|    n_updates            | 6230       |\n",
      "|    policy_gradient_loss | -0.0291    |\n",
      "|    value_loss           | 0.000561   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=1280000, episode_reward=0.06 +/- 0.10\n",
      "Episode length: 10000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+04       |\n",
      "|    mean_reward          | 0.0558      |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1280000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016849257 |\n",
      "|    clip_fraction        | 0.274       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.31       |\n",
      "|    explained_variance   | 0.883       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0407     |\n",
      "|    n_updates            | 6240        |\n",
      "|    policy_gradient_loss | -0.0175     |\n",
      "|    value_loss           | 0.000228    |\n",
      "-----------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 150     |\n",
      "|    iterations      | 625     |\n",
      "|    time_elapsed    | 8512    |\n",
      "|    total_timesteps | 1280000 |\n",
      "--------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 150         |\n",
      "|    iterations           | 626         |\n",
      "|    time_elapsed         | 8518        |\n",
      "|    total_timesteps      | 1282048     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013124547 |\n",
      "|    clip_fraction        | 0.123       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.28       |\n",
      "|    explained_variance   | 0.701       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0439     |\n",
      "|    n_updates            | 6250        |\n",
      "|    policy_gradient_loss | -0.00247    |\n",
      "|    value_loss           | 0.00251     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 150         |\n",
      "|    iterations           | 627         |\n",
      "|    time_elapsed         | 8523        |\n",
      "|    total_timesteps      | 1284096     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023778815 |\n",
      "|    clip_fraction        | 0.439       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.39       |\n",
      "|    explained_variance   | -0.113      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00653     |\n",
      "|    n_updates            | 6260        |\n",
      "|    policy_gradient_loss | -0.0297     |\n",
      "|    value_loss           | 0.000113    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 150        |\n",
      "|    iterations           | 628        |\n",
      "|    time_elapsed         | 8529       |\n",
      "|    total_timesteps      | 1286144    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02411919 |\n",
      "|    clip_fraction        | 0.368      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.27      |\n",
      "|    explained_variance   | 0.843      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0544    |\n",
      "|    n_updates            | 6270       |\n",
      "|    policy_gradient_loss | -0.0251    |\n",
      "|    value_loss           | 5.72e-05   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 150         |\n",
      "|    iterations           | 629         |\n",
      "|    time_elapsed         | 8535        |\n",
      "|    total_timesteps      | 1288192     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015039584 |\n",
      "|    clip_fraction        | 0.239       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.31       |\n",
      "|    explained_variance   | 0.922       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.05e-05    |\n",
      "|    n_updates            | 6280        |\n",
      "|    policy_gradient_loss | -0.018      |\n",
      "|    value_loss           | 4.05e-06    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1290000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 10000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+04       |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1290000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023933694 |\n",
      "|    clip_fraction        | 0.469       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.22       |\n",
      "|    explained_variance   | 0.709       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0391     |\n",
      "|    n_updates            | 6290        |\n",
      "|    policy_gradient_loss | -0.032      |\n",
      "|    value_loss           | 7.75e-07    |\n",
      "-----------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 150     |\n",
      "|    iterations      | 630     |\n",
      "|    time_elapsed    | 8583    |\n",
      "|    total_timesteps | 1290240 |\n",
      "--------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 150         |\n",
      "|    iterations           | 631         |\n",
      "|    time_elapsed         | 8588        |\n",
      "|    total_timesteps      | 1292288     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015151773 |\n",
      "|    clip_fraction        | 0.24        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.13       |\n",
      "|    explained_variance   | 0.764       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00759     |\n",
      "|    n_updates            | 6300        |\n",
      "|    policy_gradient_loss | -0.0149     |\n",
      "|    value_loss           | 9.04e-06    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 150         |\n",
      "|    iterations           | 632         |\n",
      "|    time_elapsed         | 8594        |\n",
      "|    total_timesteps      | 1294336     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.037258282 |\n",
      "|    clip_fraction        | 0.315       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.04       |\n",
      "|    explained_variance   | -0.404      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0253     |\n",
      "|    n_updates            | 6310        |\n",
      "|    policy_gradient_loss | -0.021      |\n",
      "|    value_loss           | 1.02e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 150         |\n",
      "|    iterations           | 633         |\n",
      "|    time_elapsed         | 8600        |\n",
      "|    total_timesteps      | 1296384     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016003482 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.14       |\n",
      "|    explained_variance   | 0.925       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0125     |\n",
      "|    n_updates            | 6320        |\n",
      "|    policy_gradient_loss | -0.00845    |\n",
      "|    value_loss           | 2.26e-06    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 150         |\n",
      "|    iterations           | 634         |\n",
      "|    time_elapsed         | 8605        |\n",
      "|    total_timesteps      | 1298432     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011706205 |\n",
      "|    clip_fraction        | 0.149       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.35       |\n",
      "|    explained_variance   | 0.932       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00506    |\n",
      "|    n_updates            | 6330        |\n",
      "|    policy_gradient_loss | -0.00858    |\n",
      "|    value_loss           | 2.78e-06    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1300000, episode_reward=-0.19 +/- 0.74\n",
      "Episode length: 10000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+04       |\n",
      "|    mean_reward          | -0.189      |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1300000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012203718 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.35       |\n",
      "|    explained_variance   | 0.932       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00285    |\n",
      "|    n_updates            | 6340        |\n",
      "|    policy_gradient_loss | -0.0102     |\n",
      "|    value_loss           | 6.37e-06    |\n",
      "-----------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 150     |\n",
      "|    iterations      | 635     |\n",
      "|    time_elapsed    | 8652    |\n",
      "|    total_timesteps | 1300480 |\n",
      "--------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 150        |\n",
      "|    iterations           | 636        |\n",
      "|    time_elapsed         | 8657       |\n",
      "|    total_timesteps      | 1302528    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04263576 |\n",
      "|    clip_fraction        | 0.253      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.17      |\n",
      "|    explained_variance   | 0.834      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0328    |\n",
      "|    n_updates            | 6350       |\n",
      "|    policy_gradient_loss | -0.0188    |\n",
      "|    value_loss           | 0.000171   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 150         |\n",
      "|    iterations           | 637         |\n",
      "|    time_elapsed         | 8663        |\n",
      "|    total_timesteps      | 1304576     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023222737 |\n",
      "|    clip_fraction        | 0.32        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.939      |\n",
      "|    explained_variance   | 0.886       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0178      |\n",
      "|    n_updates            | 6360        |\n",
      "|    policy_gradient_loss | -0.0112     |\n",
      "|    value_loss           | 1.03e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 150         |\n",
      "|    iterations           | 638         |\n",
      "|    time_elapsed         | 8668        |\n",
      "|    total_timesteps      | 1306624     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023130506 |\n",
      "|    clip_fraction        | 0.3         |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.1        |\n",
      "|    explained_variance   | 0.817       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0237     |\n",
      "|    n_updates            | 6370        |\n",
      "|    policy_gradient_loss | -0.0236     |\n",
      "|    value_loss           | 5.75e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 150         |\n",
      "|    iterations           | 639         |\n",
      "|    time_elapsed         | 8674        |\n",
      "|    total_timesteps      | 1308672     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019569438 |\n",
      "|    clip_fraction        | 0.36        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.31       |\n",
      "|    explained_variance   | 0.408       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0479     |\n",
      "|    n_updates            | 6380        |\n",
      "|    policy_gradient_loss | -0.028      |\n",
      "|    value_loss           | 0.000107    |\n",
      "-----------------------------------------\n",
      "box reached target\n",
      "Eval num_timesteps=1310000, episode_reward=1.02 +/- 2.02\n",
      "Episode length: 8012.40 +/- 3975.20\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 8.01e+03    |\n",
      "|    mean_reward          | 1.02        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1310000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020873977 |\n",
      "|    clip_fraction        | 0.322       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.38       |\n",
      "|    explained_variance   | 0.641       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0243     |\n",
      "|    n_updates            | 6390        |\n",
      "|    policy_gradient_loss | -0.0296     |\n",
      "|    value_loss           | 6.4e-05     |\n",
      "-----------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 150     |\n",
      "|    iterations      | 640     |\n",
      "|    time_elapsed    | 8713    |\n",
      "|    total_timesteps | 1310720 |\n",
      "--------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 150         |\n",
      "|    iterations           | 641         |\n",
      "|    time_elapsed         | 8718        |\n",
      "|    total_timesteps      | 1312768     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011024125 |\n",
      "|    clip_fraction        | 0.193       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.12       |\n",
      "|    explained_variance   | 0.885       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00565    |\n",
      "|    n_updates            | 6400        |\n",
      "|    policy_gradient_loss | -0.0107     |\n",
      "|    value_loss           | 0.000221    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 150         |\n",
      "|    iterations           | 642         |\n",
      "|    time_elapsed         | 8724        |\n",
      "|    total_timesteps      | 1314816     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007888237 |\n",
      "|    clip_fraction        | 0.089       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.715      |\n",
      "|    explained_variance   | 0.937       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0148      |\n",
      "|    n_updates            | 6410        |\n",
      "|    policy_gradient_loss | -0.00829    |\n",
      "|    value_loss           | 2.35e-06    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 150         |\n",
      "|    iterations           | 643         |\n",
      "|    time_elapsed         | 8729        |\n",
      "|    total_timesteps      | 1316864     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006204772 |\n",
      "|    clip_fraction        | 0.102       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.531      |\n",
      "|    explained_variance   | 0.765       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0215     |\n",
      "|    n_updates            | 6420        |\n",
      "|    policy_gradient_loss | -0.0144     |\n",
      "|    value_loss           | 0.00247     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 150         |\n",
      "|    iterations           | 644         |\n",
      "|    time_elapsed         | 8735        |\n",
      "|    total_timesteps      | 1318912     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012686562 |\n",
      "|    clip_fraction        | 0.0885      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.45       |\n",
      "|    explained_variance   | -2.84       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0261     |\n",
      "|    n_updates            | 6430        |\n",
      "|    policy_gradient_loss | -0.0096     |\n",
      "|    value_loss           | 0.000113    |\n",
      "-----------------------------------------\n",
      "box reached target\n",
      "Eval num_timesteps=1320000, episode_reward=1.03 +/- 2.01\n",
      "Episode length: 8014.60 +/- 3970.80\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 8.01e+03   |\n",
      "|    mean_reward          | 1.03       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 1320000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02020432 |\n",
      "|    clip_fraction        | 0.29       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.31      |\n",
      "|    explained_variance   | -0.018     |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.00939   |\n",
      "|    n_updates            | 6440       |\n",
      "|    policy_gradient_loss | -0.019     |\n",
      "|    value_loss           | 0.000466   |\n",
      "----------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 150     |\n",
      "|    iterations      | 645     |\n",
      "|    time_elapsed    | 8774    |\n",
      "|    total_timesteps | 1320960 |\n",
      "--------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 150        |\n",
      "|    iterations           | 646        |\n",
      "|    time_elapsed         | 8779       |\n",
      "|    total_timesteps      | 1323008    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02309575 |\n",
      "|    clip_fraction        | 0.273      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.2       |\n",
      "|    explained_variance   | 0.554      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0428    |\n",
      "|    n_updates            | 6450       |\n",
      "|    policy_gradient_loss | -0.0192    |\n",
      "|    value_loss           | 0.000363   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 150         |\n",
      "|    iterations           | 647         |\n",
      "|    time_elapsed         | 8785        |\n",
      "|    total_timesteps      | 1325056     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029707134 |\n",
      "|    clip_fraction        | 0.292       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.14       |\n",
      "|    explained_variance   | 0.785       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0136      |\n",
      "|    n_updates            | 6460        |\n",
      "|    policy_gradient_loss | -0.0144     |\n",
      "|    value_loss           | 0.00245     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 150         |\n",
      "|    iterations           | 648         |\n",
      "|    time_elapsed         | 8790        |\n",
      "|    total_timesteps      | 1327104     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016773432 |\n",
      "|    clip_fraction        | 0.232       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.27       |\n",
      "|    explained_variance   | 0.869       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0288     |\n",
      "|    n_updates            | 6470        |\n",
      "|    policy_gradient_loss | -0.0136     |\n",
      "|    value_loss           | 0.00092     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 649         |\n",
      "|    time_elapsed         | 8796        |\n",
      "|    total_timesteps      | 1329152     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013354142 |\n",
      "|    clip_fraction        | 0.278       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.31       |\n",
      "|    explained_variance   | 0.212       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0592     |\n",
      "|    n_updates            | 6480        |\n",
      "|    policy_gradient_loss | -0.0195     |\n",
      "|    value_loss           | 0.000746    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1330000, episode_reward=0.01 +/- 0.01\n",
      "Episode length: 10000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+04       |\n",
      "|    mean_reward          | 0.00706     |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1330000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016370695 |\n",
      "|    clip_fraction        | 0.268       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.35       |\n",
      "|    explained_variance   | -0.364      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0467     |\n",
      "|    n_updates            | 6490        |\n",
      "|    policy_gradient_loss | -0.0162     |\n",
      "|    value_loss           | 0.000455    |\n",
      "-----------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 150     |\n",
      "|    iterations      | 650     |\n",
      "|    time_elapsed    | 8842    |\n",
      "|    total_timesteps | 1331200 |\n",
      "--------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 150         |\n",
      "|    iterations           | 651         |\n",
      "|    time_elapsed         | 8848        |\n",
      "|    total_timesteps      | 1333248     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022225328 |\n",
      "|    clip_fraction        | 0.134       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.09       |\n",
      "|    explained_variance   | 0.929       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0123     |\n",
      "|    n_updates            | 6500        |\n",
      "|    policy_gradient_loss | -0.0078     |\n",
      "|    value_loss           | 0.00137     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 150         |\n",
      "|    iterations           | 652         |\n",
      "|    time_elapsed         | 8853        |\n",
      "|    total_timesteps      | 1335296     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016677331 |\n",
      "|    clip_fraction        | 0.279       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.11       |\n",
      "|    explained_variance   | 0.621       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0192     |\n",
      "|    n_updates            | 6510        |\n",
      "|    policy_gradient_loss | -0.0328     |\n",
      "|    value_loss           | 0.000118    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 150         |\n",
      "|    iterations           | 653         |\n",
      "|    time_elapsed         | 8858        |\n",
      "|    total_timesteps      | 1337344     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014799679 |\n",
      "|    clip_fraction        | 0.241       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.13       |\n",
      "|    explained_variance   | 0.481       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0344     |\n",
      "|    n_updates            | 6520        |\n",
      "|    policy_gradient_loss | -0.0211     |\n",
      "|    value_loss           | 0.000225    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 654         |\n",
      "|    time_elapsed         | 8864        |\n",
      "|    total_timesteps      | 1339392     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024573056 |\n",
      "|    clip_fraction        | 0.337       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.34       |\n",
      "|    explained_variance   | -0.0899     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00392     |\n",
      "|    n_updates            | 6530        |\n",
      "|    policy_gradient_loss | -0.0306     |\n",
      "|    value_loss           | 9.85e-05    |\n",
      "-----------------------------------------\n",
      "box reached target\n",
      "box reached target\n",
      "Eval num_timesteps=1340000, episode_reward=2.30 +/- 2.41\n",
      "Episode length: 6205.00 +/- 4655.76\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 6.2e+03     |\n",
      "|    mean_reward          | 2.3         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1340000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013980775 |\n",
      "|    clip_fraction        | 0.21        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.3        |\n",
      "|    explained_variance   | 0.45        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00685     |\n",
      "|    n_updates            | 6540        |\n",
      "|    policy_gradient_loss | -0.0115     |\n",
      "|    value_loss           | 6.03e-05    |\n",
      "-----------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 150     |\n",
      "|    iterations      | 655     |\n",
      "|    time_elapsed    | 8895    |\n",
      "|    total_timesteps | 1341440 |\n",
      "--------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 150         |\n",
      "|    iterations           | 656         |\n",
      "|    time_elapsed         | 8901        |\n",
      "|    total_timesteps      | 1343488     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014283873 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.13       |\n",
      "|    explained_variance   | 0.947       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0307     |\n",
      "|    n_updates            | 6550        |\n",
      "|    policy_gradient_loss | -0.00988    |\n",
      "|    value_loss           | 0.000267    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 657         |\n",
      "|    time_elapsed         | 8906        |\n",
      "|    total_timesteps      | 1345536     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020943146 |\n",
      "|    clip_fraction        | 0.377       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.37       |\n",
      "|    explained_variance   | 0.636       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0316     |\n",
      "|    n_updates            | 6560        |\n",
      "|    policy_gradient_loss | -0.0292     |\n",
      "|    value_loss           | 0.000171    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 658         |\n",
      "|    time_elapsed         | 8911        |\n",
      "|    total_timesteps      | 1347584     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019016435 |\n",
      "|    clip_fraction        | 0.341       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.38       |\n",
      "|    explained_variance   | 0.623       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0155     |\n",
      "|    n_updates            | 6570        |\n",
      "|    policy_gradient_loss | -0.0238     |\n",
      "|    value_loss           | 4.64e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 659         |\n",
      "|    time_elapsed         | 8916        |\n",
      "|    total_timesteps      | 1349632     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017736863 |\n",
      "|    clip_fraction        | 0.292       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.44       |\n",
      "|    explained_variance   | -0.0107     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.025      |\n",
      "|    n_updates            | 6580        |\n",
      "|    policy_gradient_loss | -0.0205     |\n",
      "|    value_loss           | 1.24e-05    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1350000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 10000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+04       |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1350000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014421441 |\n",
      "|    clip_fraction        | 0.271       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.46       |\n",
      "|    explained_variance   | -0.487      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.01       |\n",
      "|    n_updates            | 6590        |\n",
      "|    policy_gradient_loss | -0.0174     |\n",
      "|    value_loss           | 1.18e-05    |\n",
      "-----------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 150     |\n",
      "|    iterations      | 660     |\n",
      "|    time_elapsed    | 8964    |\n",
      "|    total_timesteps | 1351680 |\n",
      "--------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 150         |\n",
      "|    iterations           | 661         |\n",
      "|    time_elapsed         | 8969        |\n",
      "|    total_timesteps      | 1353728     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023622856 |\n",
      "|    clip_fraction        | 0.166       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.26       |\n",
      "|    explained_variance   | 0.954       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0253     |\n",
      "|    n_updates            | 6600        |\n",
      "|    policy_gradient_loss | -0.0113     |\n",
      "|    value_loss           | 7.28e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 662         |\n",
      "|    time_elapsed         | 8975        |\n",
      "|    total_timesteps      | 1355776     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008566713 |\n",
      "|    clip_fraction        | 0.087       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.39       |\n",
      "|    explained_variance   | 0.799       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0127     |\n",
      "|    n_updates            | 6610        |\n",
      "|    policy_gradient_loss | -0.00828    |\n",
      "|    value_loss           | 7.29e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 663         |\n",
      "|    time_elapsed         | 8980        |\n",
      "|    total_timesteps      | 1357824     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012480887 |\n",
      "|    clip_fraction        | 0.202       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.4        |\n",
      "|    explained_variance   | 0.61        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0292     |\n",
      "|    n_updates            | 6620        |\n",
      "|    policy_gradient_loss | -0.0124     |\n",
      "|    value_loss           | 4.72e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 664         |\n",
      "|    time_elapsed         | 8985        |\n",
      "|    total_timesteps      | 1359872     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010307036 |\n",
      "|    clip_fraction        | 0.125       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.44       |\n",
      "|    explained_variance   | 0.769       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0106     |\n",
      "|    n_updates            | 6630        |\n",
      "|    policy_gradient_loss | -0.00577    |\n",
      "|    value_loss           | 2.94e-05    |\n",
      "-----------------------------------------\n",
      "box reached target\n",
      "Eval num_timesteps=1360000, episode_reward=1.26 +/- 1.91\n",
      "Episode length: 8011.60 +/- 3976.80\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 8.01e+03    |\n",
      "|    mean_reward          | 1.26        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1360000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014970137 |\n",
      "|    clip_fraction        | 0.257       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.44       |\n",
      "|    explained_variance   | 0.36        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0191     |\n",
      "|    n_updates            | 6640        |\n",
      "|    policy_gradient_loss | -0.0159     |\n",
      "|    value_loss           | 1.77e-05    |\n",
      "-----------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 150     |\n",
      "|    iterations      | 665     |\n",
      "|    time_elapsed    | 9025    |\n",
      "|    total_timesteps | 1361920 |\n",
      "--------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 666         |\n",
      "|    time_elapsed         | 9030        |\n",
      "|    total_timesteps      | 1363968     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016700529 |\n",
      "|    clip_fraction        | 0.3         |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.26       |\n",
      "|    explained_variance   | 0.255       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0157     |\n",
      "|    n_updates            | 6650        |\n",
      "|    policy_gradient_loss | -0.0239     |\n",
      "|    value_loss           | 0.000158    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 667         |\n",
      "|    time_elapsed         | 9036        |\n",
      "|    total_timesteps      | 1366016     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017267222 |\n",
      "|    clip_fraction        | 0.258       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.29       |\n",
      "|    explained_variance   | -0.879      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0151     |\n",
      "|    n_updates            | 6660        |\n",
      "|    policy_gradient_loss | -0.0172     |\n",
      "|    value_loss           | 4.51e-06    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 151        |\n",
      "|    iterations           | 668        |\n",
      "|    time_elapsed         | 9041       |\n",
      "|    total_timesteps      | 1368064    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02512848 |\n",
      "|    clip_fraction        | 0.276      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.37      |\n",
      "|    explained_variance   | -0.716     |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0101     |\n",
      "|    n_updates            | 6670       |\n",
      "|    policy_gradient_loss | -0.0163    |\n",
      "|    value_loss           | 1.98e-06   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=1370000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 10000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+04       |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1370000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020287298 |\n",
      "|    clip_fraction        | 0.225       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.36       |\n",
      "|    explained_variance   | -1.31       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0352     |\n",
      "|    n_updates            | 6680        |\n",
      "|    policy_gradient_loss | -0.012      |\n",
      "|    value_loss           | 1.47e-05    |\n",
      "-----------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 150     |\n",
      "|    iterations      | 669     |\n",
      "|    time_elapsed    | 9089    |\n",
      "|    total_timesteps | 1370112 |\n",
      "--------------------------------\n",
      "box reached target\n",
      "box reached target\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 150          |\n",
      "|    iterations           | 670          |\n",
      "|    time_elapsed         | 9094         |\n",
      "|    total_timesteps      | 1372160      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0136397015 |\n",
      "|    clip_fraction        | 0.173        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.36        |\n",
      "|    explained_variance   | 0.942        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.00507     |\n",
      "|    n_updates            | 6690         |\n",
      "|    policy_gradient_loss | -0.00632     |\n",
      "|    value_loss           | 2.63e-05     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 671         |\n",
      "|    time_elapsed         | 9100        |\n",
      "|    total_timesteps      | 1374208     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019353554 |\n",
      "|    clip_fraction        | 0.157       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.878      |\n",
      "|    explained_variance   | 0.000281    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0171      |\n",
      "|    n_updates            | 6700        |\n",
      "|    policy_gradient_loss | -0.0103     |\n",
      "|    value_loss           | 0.125       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 151       |\n",
      "|    iterations           | 672       |\n",
      "|    time_elapsed         | 9105      |\n",
      "|    total_timesteps      | 1376256   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0126477 |\n",
      "|    clip_fraction        | 0.15      |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -0.987    |\n",
      "|    explained_variance   | 0.778     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -0.00435  |\n",
      "|    n_updates            | 6710      |\n",
      "|    policy_gradient_loss | -0.0121   |\n",
      "|    value_loss           | 0.000245  |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 673         |\n",
      "|    time_elapsed         | 9110        |\n",
      "|    total_timesteps      | 1378304     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026880786 |\n",
      "|    clip_fraction        | 0.304       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.25       |\n",
      "|    explained_variance   | 0.149       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0348     |\n",
      "|    n_updates            | 6720        |\n",
      "|    policy_gradient_loss | -0.027      |\n",
      "|    value_loss           | 9.06e-05    |\n",
      "-----------------------------------------\n",
      "box reached target\n",
      "box reached target\n",
      "box reached target\n",
      "Eval num_timesteps=1380000, episode_reward=3.39 +/- 2.80\n",
      "Episode length: 4523.20 +/- 4495.88\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 4.52e+03    |\n",
      "|    mean_reward          | 3.39        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1380000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009124044 |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.29       |\n",
      "|    explained_variance   | 0.919       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0237     |\n",
      "|    n_updates            | 6730        |\n",
      "|    policy_gradient_loss | -0.00666    |\n",
      "|    value_loss           | 0.000101    |\n",
      "-----------------------------------------\n",
      "New best mean reward!\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 151     |\n",
      "|    iterations      | 674     |\n",
      "|    time_elapsed    | 9135    |\n",
      "|    total_timesteps | 1380352 |\n",
      "--------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 151        |\n",
      "|    iterations           | 675        |\n",
      "|    time_elapsed         | 9141       |\n",
      "|    total_timesteps      | 1382400    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02087224 |\n",
      "|    clip_fraction        | 0.174      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.25      |\n",
      "|    explained_variance   | 0.917      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0139     |\n",
      "|    n_updates            | 6740       |\n",
      "|    policy_gradient_loss | -0.00419   |\n",
      "|    value_loss           | 0.000626   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 151        |\n",
      "|    iterations           | 676        |\n",
      "|    time_elapsed         | 9146       |\n",
      "|    total_timesteps      | 1384448    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00588847 |\n",
      "|    clip_fraction        | 0.0611     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.06      |\n",
      "|    explained_variance   | 0.963      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0194     |\n",
      "|    n_updates            | 6750       |\n",
      "|    policy_gradient_loss | -0.00055   |\n",
      "|    value_loss           | 1.12e-05   |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 151          |\n",
      "|    iterations           | 677          |\n",
      "|    time_elapsed         | 9151         |\n",
      "|    total_timesteps      | 1386496      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066215927 |\n",
      "|    clip_fraction        | 0.0677       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.1         |\n",
      "|    explained_variance   | 0.961        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.00286      |\n",
      "|    n_updates            | 6760         |\n",
      "|    policy_gradient_loss | -0.000356    |\n",
      "|    value_loss           | 3.06e-05     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 678         |\n",
      "|    time_elapsed         | 9157        |\n",
      "|    total_timesteps      | 1388544     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004605313 |\n",
      "|    clip_fraction        | 0.044       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.09       |\n",
      "|    explained_variance   | 0.955       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0094     |\n",
      "|    n_updates            | 6770        |\n",
      "|    policy_gradient_loss | -0.00339    |\n",
      "|    value_loss           | 6.85e-05    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1390000, episode_reward=0.04 +/- 0.06\n",
      "Episode length: 10000.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1e+04        |\n",
      "|    mean_reward          | 0.0365       |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1390000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0083629545 |\n",
      "|    clip_fraction        | 0.0777       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.2         |\n",
      "|    explained_variance   | 0.916        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.00285     |\n",
      "|    n_updates            | 6780         |\n",
      "|    policy_gradient_loss | -0.00225     |\n",
      "|    value_loss           | 7.14e-05     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 151     |\n",
      "|    iterations      | 679     |\n",
      "|    time_elapsed    | 9205    |\n",
      "|    total_timesteps | 1390592 |\n",
      "--------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 680         |\n",
      "|    time_elapsed         | 9210        |\n",
      "|    total_timesteps      | 1392640     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.054198436 |\n",
      "|    clip_fraction        | 0.183       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.04       |\n",
      "|    explained_variance   | 0.972       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0732     |\n",
      "|    n_updates            | 6790        |\n",
      "|    policy_gradient_loss | -0.0209     |\n",
      "|    value_loss           | 0.000533    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 681         |\n",
      "|    time_elapsed         | 9215        |\n",
      "|    total_timesteps      | 1394688     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016881991 |\n",
      "|    clip_fraction        | 0.252       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.05       |\n",
      "|    explained_variance   | 0.697       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0269     |\n",
      "|    n_updates            | 6800        |\n",
      "|    policy_gradient_loss | -0.0224     |\n",
      "|    value_loss           | 0.000617    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 151        |\n",
      "|    iterations           | 682        |\n",
      "|    time_elapsed         | 9221       |\n",
      "|    total_timesteps      | 1396736    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02109716 |\n",
      "|    clip_fraction        | 0.371      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.2       |\n",
      "|    explained_variance   | 0.661      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0725    |\n",
      "|    n_updates            | 6810       |\n",
      "|    policy_gradient_loss | -0.0279    |\n",
      "|    value_loss           | 0.00102    |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 683         |\n",
      "|    time_elapsed         | 9226        |\n",
      "|    total_timesteps      | 1398784     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022439305 |\n",
      "|    clip_fraction        | 0.28        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.21       |\n",
      "|    explained_variance   | 0.636       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0346     |\n",
      "|    n_updates            | 6820        |\n",
      "|    policy_gradient_loss | -0.0219     |\n",
      "|    value_loss           | 0.000819    |\n",
      "-----------------------------------------\n",
      "box reached target\n",
      "box reached target\n",
      "Eval num_timesteps=1400000, episode_reward=2.22 +/- 2.60\n",
      "Episode length: 6290.20 +/- 4549.31\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 6.29e+03   |\n",
      "|    mean_reward          | 2.22       |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 1400000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02148287 |\n",
      "|    clip_fraction        | 0.3        |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.25      |\n",
      "|    explained_variance   | 0.829      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0539    |\n",
      "|    n_updates            | 6830       |\n",
      "|    policy_gradient_loss | -0.0257    |\n",
      "|    value_loss           | 0.000525   |\n",
      "----------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 151     |\n",
      "|    iterations      | 684     |\n",
      "|    time_elapsed    | 9257    |\n",
      "|    total_timesteps | 1400832 |\n",
      "--------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 151        |\n",
      "|    iterations           | 685        |\n",
      "|    time_elapsed         | 9262       |\n",
      "|    total_timesteps      | 1402880    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04194905 |\n",
      "|    clip_fraction        | 0.19       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.18      |\n",
      "|    explained_variance   | 0.914      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0209    |\n",
      "|    n_updates            | 6840       |\n",
      "|    policy_gradient_loss | -0.00986   |\n",
      "|    value_loss           | 0.00291    |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 686         |\n",
      "|    time_elapsed         | 9268        |\n",
      "|    total_timesteps      | 1404928     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012749577 |\n",
      "|    clip_fraction        | 0.0863      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.906      |\n",
      "|    explained_variance   | 0.95        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0359      |\n",
      "|    n_updates            | 6850        |\n",
      "|    policy_gradient_loss | -0.00405    |\n",
      "|    value_loss           | 1.19e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 687         |\n",
      "|    time_elapsed         | 9273        |\n",
      "|    total_timesteps      | 1406976     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009675765 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.03       |\n",
      "|    explained_variance   | 0.755       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00922    |\n",
      "|    n_updates            | 6860        |\n",
      "|    policy_gradient_loss | -0.00611    |\n",
      "|    value_loss           | 9.58e-06    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 688         |\n",
      "|    time_elapsed         | 9278        |\n",
      "|    total_timesteps      | 1409024     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019653516 |\n",
      "|    clip_fraction        | 0.231       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.04       |\n",
      "|    explained_variance   | 0.704       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0495     |\n",
      "|    n_updates            | 6870        |\n",
      "|    policy_gradient_loss | -0.023      |\n",
      "|    value_loss           | 1.14e-05    |\n",
      "-----------------------------------------\n",
      "box reached target\n",
      "Eval num_timesteps=1410000, episode_reward=1.27 +/- 2.16\n",
      "Episode length: 8153.20 +/- 3693.60\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 8.15e+03    |\n",
      "|    mean_reward          | 1.27        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1410000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011707755 |\n",
      "|    clip_fraction        | 0.143       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.08       |\n",
      "|    explained_variance   | 0.827       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0412     |\n",
      "|    n_updates            | 6880        |\n",
      "|    policy_gradient_loss | -0.0162     |\n",
      "|    value_loss           | 8.88e-05    |\n",
      "-----------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 151     |\n",
      "|    iterations      | 689     |\n",
      "|    time_elapsed    | 9318    |\n",
      "|    total_timesteps | 1411072 |\n",
      "--------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 690         |\n",
      "|    time_elapsed         | 9323        |\n",
      "|    total_timesteps      | 1413120     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016549788 |\n",
      "|    clip_fraction        | 0.238       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.15       |\n",
      "|    explained_variance   | 0.742       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0236     |\n",
      "|    n_updates            | 6890        |\n",
      "|    policy_gradient_loss | -0.0186     |\n",
      "|    value_loss           | 0.00113     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 691         |\n",
      "|    time_elapsed         | 9328        |\n",
      "|    total_timesteps      | 1415168     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019658733 |\n",
      "|    clip_fraction        | 0.226       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.885      |\n",
      "|    explained_variance   | 0.714       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.042      |\n",
      "|    n_updates            | 6900        |\n",
      "|    policy_gradient_loss | -0.0173     |\n",
      "|    value_loss           | 6.44e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 692         |\n",
      "|    time_elapsed         | 9334        |\n",
      "|    total_timesteps      | 1417216     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017484043 |\n",
      "|    clip_fraction        | 0.214       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.898      |\n",
      "|    explained_variance   | -0.141      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0529     |\n",
      "|    n_updates            | 6910        |\n",
      "|    policy_gradient_loss | -0.0149     |\n",
      "|    value_loss           | 2.28e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 693         |\n",
      "|    time_elapsed         | 9339        |\n",
      "|    total_timesteps      | 1419264     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013882367 |\n",
      "|    clip_fraction        | 0.171       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.01       |\n",
      "|    explained_variance   | 0.879       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0267     |\n",
      "|    n_updates            | 6920        |\n",
      "|    policy_gradient_loss | -0.0174     |\n",
      "|    value_loss           | 0.000134    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1420000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 10000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+04       |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1420000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020912424 |\n",
      "|    clip_fraction        | 0.299       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.04       |\n",
      "|    explained_variance   | 0.751       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0463     |\n",
      "|    n_updates            | 6930        |\n",
      "|    policy_gradient_loss | -0.0273     |\n",
      "|    value_loss           | 5.54e-05    |\n",
      "-----------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 151     |\n",
      "|    iterations      | 694     |\n",
      "|    time_elapsed    | 9387    |\n",
      "|    total_timesteps | 1421312 |\n",
      "--------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 695         |\n",
      "|    time_elapsed         | 9392        |\n",
      "|    total_timesteps      | 1423360     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013325563 |\n",
      "|    clip_fraction        | 0.184       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.14       |\n",
      "|    explained_variance   | 0.95        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0442     |\n",
      "|    n_updates            | 6940        |\n",
      "|    policy_gradient_loss | -0.0167     |\n",
      "|    value_loss           | 0.000245    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 696         |\n",
      "|    time_elapsed         | 9397        |\n",
      "|    total_timesteps      | 1425408     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019250695 |\n",
      "|    clip_fraction        | 0.325       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.27       |\n",
      "|    explained_variance   | 0.908       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0337     |\n",
      "|    n_updates            | 6950        |\n",
      "|    policy_gradient_loss | -0.0194     |\n",
      "|    value_loss           | 0.00074     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 697         |\n",
      "|    time_elapsed         | 9402        |\n",
      "|    total_timesteps      | 1427456     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019413544 |\n",
      "|    clip_fraction        | 0.296       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.39       |\n",
      "|    explained_variance   | 0.56        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0104      |\n",
      "|    n_updates            | 6960        |\n",
      "|    policy_gradient_loss | -0.0166     |\n",
      "|    value_loss           | 0.000493    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 698         |\n",
      "|    time_elapsed         | 9408        |\n",
      "|    total_timesteps      | 1429504     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010358347 |\n",
      "|    clip_fraction        | 0.203       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.37       |\n",
      "|    explained_variance   | 0.403       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0216     |\n",
      "|    n_updates            | 6970        |\n",
      "|    policy_gradient_loss | -0.0103     |\n",
      "|    value_loss           | 0.000254    |\n",
      "-----------------------------------------\n",
      "box reached target\n",
      "Eval num_timesteps=1430000, episode_reward=1.22 +/- 2.13\n",
      "Episode length: 8095.80 +/- 3808.40\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 8.1e+03     |\n",
      "|    mean_reward          | 1.22        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1430000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014074122 |\n",
      "|    clip_fraction        | 0.208       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.38       |\n",
      "|    explained_variance   | 0.303       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0111      |\n",
      "|    n_updates            | 6980        |\n",
      "|    policy_gradient_loss | -0.00796    |\n",
      "|    value_loss           | 0.000183    |\n",
      "-----------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 151     |\n",
      "|    iterations      | 699     |\n",
      "|    time_elapsed    | 9448    |\n",
      "|    total_timesteps | 1431552 |\n",
      "--------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 700         |\n",
      "|    time_elapsed         | 9453        |\n",
      "|    total_timesteps      | 1433600     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025702521 |\n",
      "|    clip_fraction        | 0.243       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.13       |\n",
      "|    explained_variance   | 0.738       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00235     |\n",
      "|    n_updates            | 6990        |\n",
      "|    policy_gradient_loss | -0.0143     |\n",
      "|    value_loss           | 0.00105     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 701         |\n",
      "|    time_elapsed         | 9459        |\n",
      "|    total_timesteps      | 1435648     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025543123 |\n",
      "|    clip_fraction        | 0.383       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.37       |\n",
      "|    explained_variance   | -2.06       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0847     |\n",
      "|    n_updates            | 7000        |\n",
      "|    policy_gradient_loss | -0.0268     |\n",
      "|    value_loss           | 9.51e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 702         |\n",
      "|    time_elapsed         | 9464        |\n",
      "|    total_timesteps      | 1437696     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022938289 |\n",
      "|    clip_fraction        | 0.412       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.42       |\n",
      "|    explained_variance   | 0.098       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0372     |\n",
      "|    n_updates            | 7010        |\n",
      "|    policy_gradient_loss | -0.0313     |\n",
      "|    value_loss           | 2.72e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 152         |\n",
      "|    iterations           | 703         |\n",
      "|    time_elapsed         | 9469        |\n",
      "|    total_timesteps      | 1439744     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020020986 |\n",
      "|    clip_fraction        | 0.345       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.41       |\n",
      "|    explained_variance   | 0.511       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0638     |\n",
      "|    n_updates            | 7020        |\n",
      "|    policy_gradient_loss | -0.0274     |\n",
      "|    value_loss           | 1.77e-05    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1440000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 10000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+04       |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1440000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021791704 |\n",
      "|    clip_fraction        | 0.328       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.39       |\n",
      "|    explained_variance   | 0.393       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00668    |\n",
      "|    n_updates            | 7030        |\n",
      "|    policy_gradient_loss | -0.0242     |\n",
      "|    value_loss           | 1.73e-05    |\n",
      "-----------------------------------------\n",
      "box reached target\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 151     |\n",
      "|    iterations      | 704     |\n",
      "|    time_elapsed    | 9516    |\n",
      "|    total_timesteps | 1441792 |\n",
      "--------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 705         |\n",
      "|    time_elapsed         | 9522        |\n",
      "|    total_timesteps      | 1443840     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010107214 |\n",
      "|    clip_fraction        | 0.106       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.12       |\n",
      "|    explained_variance   | 0.241       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00896    |\n",
      "|    n_updates            | 7040        |\n",
      "|    policy_gradient_loss | -0.00195    |\n",
      "|    value_loss           | 0.0229      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 706         |\n",
      "|    time_elapsed         | 9527        |\n",
      "|    total_timesteps      | 1445888     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013669563 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.04       |\n",
      "|    explained_variance   | 0.958       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00211    |\n",
      "|    n_updates            | 7050        |\n",
      "|    policy_gradient_loss | -0.00867    |\n",
      "|    value_loss           | 4.82e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 707         |\n",
      "|    time_elapsed         | 9533        |\n",
      "|    total_timesteps      | 1447936     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012118818 |\n",
      "|    clip_fraction        | 0.101       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.01       |\n",
      "|    explained_variance   | 0.956       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00695    |\n",
      "|    n_updates            | 7060        |\n",
      "|    policy_gradient_loss | -0.0067     |\n",
      "|    value_loss           | 0.000168    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 152          |\n",
      "|    iterations           | 708          |\n",
      "|    time_elapsed         | 9538         |\n",
      "|    total_timesteps      | 1449984      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0074383207 |\n",
      "|    clip_fraction        | 0.0888       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.926       |\n",
      "|    explained_variance   | 0.789        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0257      |\n",
      "|    n_updates            | 7070         |\n",
      "|    policy_gradient_loss | -0.00594     |\n",
      "|    value_loss           | 0.000133     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1450000, episode_reward=0.06 +/- 0.09\n",
      "Episode length: 10000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+04       |\n",
      "|    mean_reward          | 0.0633      |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1450000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003518283 |\n",
      "|    clip_fraction        | 0.0653      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.886      |\n",
      "|    explained_variance   | 0.925       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00406     |\n",
      "|    n_updates            | 7080        |\n",
      "|    policy_gradient_loss | -0.00438    |\n",
      "|    value_loss           | 0.000188    |\n",
      "-----------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 151     |\n",
      "|    iterations      | 709     |\n",
      "|    time_elapsed    | 9586    |\n",
      "|    total_timesteps | 1452032 |\n",
      "--------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 710         |\n",
      "|    time_elapsed         | 9591        |\n",
      "|    total_timesteps      | 1454080     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014286568 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.29       |\n",
      "|    explained_variance   | 0.906       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0479     |\n",
      "|    n_updates            | 7090        |\n",
      "|    policy_gradient_loss | -0.00862    |\n",
      "|    value_loss           | 0.0002      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 711         |\n",
      "|    time_elapsed         | 9596        |\n",
      "|    total_timesteps      | 1456128     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012433319 |\n",
      "|    clip_fraction        | 0.181       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.47       |\n",
      "|    explained_variance   | 0.948       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0143     |\n",
      "|    n_updates            | 7100        |\n",
      "|    policy_gradient_loss | -0.0124     |\n",
      "|    value_loss           | 0.000343    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 712         |\n",
      "|    time_elapsed         | 9601        |\n",
      "|    total_timesteps      | 1458176     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021028373 |\n",
      "|    clip_fraction        | 0.267       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.41       |\n",
      "|    explained_variance   | 0.588       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0204      |\n",
      "|    n_updates            | 7110        |\n",
      "|    policy_gradient_loss | -0.0157     |\n",
      "|    value_loss           | 0.000257    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1460000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 10000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+04       |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1460000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012019507 |\n",
      "|    clip_fraction        | 0.0796      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.42       |\n",
      "|    explained_variance   | 0.945       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0276      |\n",
      "|    n_updates            | 7120        |\n",
      "|    policy_gradient_loss | -0.0049     |\n",
      "|    value_loss           | 0.000151    |\n",
      "-----------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 151     |\n",
      "|    iterations      | 713     |\n",
      "|    time_elapsed    | 9649    |\n",
      "|    total_timesteps | 1460224 |\n",
      "--------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 714         |\n",
      "|    time_elapsed         | 9655        |\n",
      "|    total_timesteps      | 1462272     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034434922 |\n",
      "|    clip_fraction        | 0.133       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.39       |\n",
      "|    explained_variance   | 0.955       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.326       |\n",
      "|    n_updates            | 7130        |\n",
      "|    policy_gradient_loss | 0.000297    |\n",
      "|    value_loss           | 0.000243    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 715         |\n",
      "|    time_elapsed         | 9660        |\n",
      "|    total_timesteps      | 1464320     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022053711 |\n",
      "|    clip_fraction        | 0.248       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.11       |\n",
      "|    explained_variance   | 0.536       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0458     |\n",
      "|    n_updates            | 7140        |\n",
      "|    policy_gradient_loss | -0.0126     |\n",
      "|    value_loss           | 0.000298    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 151          |\n",
      "|    iterations           | 716          |\n",
      "|    time_elapsed         | 9665         |\n",
      "|    total_timesteps      | 1466368      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0062619047 |\n",
      "|    clip_fraction        | 0.0813       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.939       |\n",
      "|    explained_variance   | 0.635        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0348       |\n",
      "|    n_updates            | 7150         |\n",
      "|    policy_gradient_loss | 0.000905     |\n",
      "|    value_loss           | 0.000123     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 151          |\n",
      "|    iterations           | 717          |\n",
      "|    time_elapsed         | 9671         |\n",
      "|    total_timesteps      | 1468416      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034260117 |\n",
      "|    clip_fraction        | 0.0698       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.798       |\n",
      "|    explained_variance   | 0.313        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.00449      |\n",
      "|    n_updates            | 7160         |\n",
      "|    policy_gradient_loss | -0.000199    |\n",
      "|    value_loss           | 6.02e-05     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1470000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 10000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+04       |\n",
      "|    mean_reward          | 0.000791    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1470000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.003145413 |\n",
      "|    clip_fraction        | 0.0282      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.749      |\n",
      "|    explained_variance   | 0.347       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00324    |\n",
      "|    n_updates            | 7170        |\n",
      "|    policy_gradient_loss | 0.00134     |\n",
      "|    value_loss           | 4.43e-05    |\n",
      "-----------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 151     |\n",
      "|    iterations      | 718     |\n",
      "|    time_elapsed    | 9718    |\n",
      "|    total_timesteps | 1470464 |\n",
      "--------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 719         |\n",
      "|    time_elapsed         | 9724        |\n",
      "|    total_timesteps      | 1472512     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010862004 |\n",
      "|    clip_fraction        | 0.112       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.773      |\n",
      "|    explained_variance   | 0.955       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0211     |\n",
      "|    n_updates            | 7180        |\n",
      "|    policy_gradient_loss | -0.00616    |\n",
      "|    value_loss           | 0.000266    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 151          |\n",
      "|    iterations           | 720          |\n",
      "|    time_elapsed         | 9729         |\n",
      "|    total_timesteps      | 1474560      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072303116 |\n",
      "|    clip_fraction        | 0.0964       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.12        |\n",
      "|    explained_variance   | 0.486        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0165      |\n",
      "|    n_updates            | 7190         |\n",
      "|    policy_gradient_loss | -0.00435     |\n",
      "|    value_loss           | 0.000172     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 151          |\n",
      "|    iterations           | 721          |\n",
      "|    time_elapsed         | 9735         |\n",
      "|    total_timesteps      | 1476608      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0072104866 |\n",
      "|    clip_fraction        | 0.108        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.15        |\n",
      "|    explained_variance   | 0.738        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.00526     |\n",
      "|    n_updates            | 7200         |\n",
      "|    policy_gradient_loss | -0.00681     |\n",
      "|    value_loss           | 9.35e-05     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 151          |\n",
      "|    iterations           | 722          |\n",
      "|    time_elapsed         | 9741         |\n",
      "|    total_timesteps      | 1478656      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0076125497 |\n",
      "|    clip_fraction        | 0.156        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.15        |\n",
      "|    explained_variance   | 0.648        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0261      |\n",
      "|    n_updates            | 7210         |\n",
      "|    policy_gradient_loss | -0.0136      |\n",
      "|    value_loss           | 6.17e-05     |\n",
      "------------------------------------------\n",
      "box reached target\n",
      "Eval num_timesteps=1480000, episode_reward=1.05 +/- 2.05\n",
      "Episode length: 8045.00 +/- 3910.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 8.04e+03    |\n",
      "|    mean_reward          | 1.05        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1480000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020399116 |\n",
      "|    clip_fraction        | 0.289       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.12       |\n",
      "|    explained_variance   | 0.73        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0355     |\n",
      "|    n_updates            | 7220        |\n",
      "|    policy_gradient_loss | -0.0264     |\n",
      "|    value_loss           | 8.39e-05    |\n",
      "-----------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 151     |\n",
      "|    iterations      | 723     |\n",
      "|    time_elapsed    | 9780    |\n",
      "|    total_timesteps | 1480704 |\n",
      "--------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 724         |\n",
      "|    time_elapsed         | 9785        |\n",
      "|    total_timesteps      | 1482752     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022990597 |\n",
      "|    clip_fraction        | 0.211       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.988      |\n",
      "|    explained_variance   | 0.872       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.004       |\n",
      "|    n_updates            | 7230        |\n",
      "|    policy_gradient_loss | -0.0133     |\n",
      "|    value_loss           | 0.0018      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 725         |\n",
      "|    time_elapsed         | 9791        |\n",
      "|    total_timesteps      | 1484800     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026646238 |\n",
      "|    clip_fraction        | 0.277       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.34       |\n",
      "|    explained_variance   | 0.931       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0382     |\n",
      "|    n_updates            | 7240        |\n",
      "|    policy_gradient_loss | -0.022      |\n",
      "|    value_loss           | 0.000148    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 151        |\n",
      "|    iterations           | 726        |\n",
      "|    time_elapsed         | 9797       |\n",
      "|    total_timesteps      | 1486848    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02061785 |\n",
      "|    clip_fraction        | 0.309      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.36      |\n",
      "|    explained_variance   | 0.211      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0237    |\n",
      "|    n_updates            | 7250       |\n",
      "|    policy_gradient_loss | -0.0238    |\n",
      "|    value_loss           | 3.46e-05   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 727         |\n",
      "|    time_elapsed         | 9802        |\n",
      "|    total_timesteps      | 1488896     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010279557 |\n",
      "|    clip_fraction        | 0.152       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.41       |\n",
      "|    explained_variance   | -0.0112     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0286     |\n",
      "|    n_updates            | 7260        |\n",
      "|    policy_gradient_loss | -0.00505    |\n",
      "|    value_loss           | 2.1e-05     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1490000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 10000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+04       |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1490000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012873305 |\n",
      "|    clip_fraction        | 0.114       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.34       |\n",
      "|    explained_variance   | 0.0451      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0256     |\n",
      "|    n_updates            | 7270        |\n",
      "|    policy_gradient_loss | -0.003      |\n",
      "|    value_loss           | 9.95e-06    |\n",
      "-----------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 151     |\n",
      "|    iterations      | 728     |\n",
      "|    time_elapsed    | 9850    |\n",
      "|    total_timesteps | 1490944 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 151          |\n",
      "|    iterations           | 729          |\n",
      "|    time_elapsed         | 9855         |\n",
      "|    total_timesteps      | 1492992      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0075878743 |\n",
      "|    clip_fraction        | 0.0581       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.14        |\n",
      "|    explained_variance   | 0.837        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0261      |\n",
      "|    n_updates            | 7280         |\n",
      "|    policy_gradient_loss | -0.00509     |\n",
      "|    value_loss           | 0.000171     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 730         |\n",
      "|    time_elapsed         | 9861        |\n",
      "|    total_timesteps      | 1495040     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018313719 |\n",
      "|    clip_fraction        | 0.218       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.21       |\n",
      "|    explained_variance   | 0.766       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0213     |\n",
      "|    n_updates            | 7290        |\n",
      "|    policy_gradient_loss | -0.022      |\n",
      "|    value_loss           | 4.92e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 731         |\n",
      "|    time_elapsed         | 9866        |\n",
      "|    total_timesteps      | 1497088     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014892481 |\n",
      "|    clip_fraction        | 0.252       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.26       |\n",
      "|    explained_variance   | 0.442       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0241     |\n",
      "|    n_updates            | 7300        |\n",
      "|    policy_gradient_loss | -0.0115     |\n",
      "|    value_loss           | 1.04e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 732         |\n",
      "|    time_elapsed         | 9872        |\n",
      "|    total_timesteps      | 1499136     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018797599 |\n",
      "|    clip_fraction        | 0.295       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.28       |\n",
      "|    explained_variance   | 0.899       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00253    |\n",
      "|    n_updates            | 7310        |\n",
      "|    policy_gradient_loss | -0.0139     |\n",
      "|    value_loss           | 3.05e-06    |\n",
      "-----------------------------------------\n",
      "box reached target\n",
      "box reached target\n",
      "Eval num_timesteps=1500000, episode_reward=2.19 +/- 2.66\n",
      "Episode length: 6430.00 +/- 4372.94\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 6.43e+03    |\n",
      "|    mean_reward          | 2.19        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1500000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012402309 |\n",
      "|    clip_fraction        | 0.196       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.31       |\n",
      "|    explained_variance   | 0.939       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.029      |\n",
      "|    n_updates            | 7320        |\n",
      "|    policy_gradient_loss | -0.0112     |\n",
      "|    value_loss           | 3.36e-06    |\n",
      "-----------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 151     |\n",
      "|    iterations      | 733     |\n",
      "|    time_elapsed    | 9904    |\n",
      "|    total_timesteps | 1501184 |\n",
      "--------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 734         |\n",
      "|    time_elapsed         | 9910        |\n",
      "|    total_timesteps      | 1503232     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034613673 |\n",
      "|    clip_fraction        | 0.156       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.2        |\n",
      "|    explained_variance   | 0.946       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0232     |\n",
      "|    n_updates            | 7330        |\n",
      "|    policy_gradient_loss | -0.00752    |\n",
      "|    value_loss           | 2.13e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 735         |\n",
      "|    time_elapsed         | 9915        |\n",
      "|    total_timesteps      | 1505280     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021510601 |\n",
      "|    clip_fraction        | 0.27        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.09       |\n",
      "|    explained_variance   | -0.285      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00648    |\n",
      "|    n_updates            | 7340        |\n",
      "|    policy_gradient_loss | -0.0181     |\n",
      "|    value_loss           | 1.15e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 736         |\n",
      "|    time_elapsed         | 9921        |\n",
      "|    total_timesteps      | 1507328     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029948015 |\n",
      "|    clip_fraction        | 0.272       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.04       |\n",
      "|    explained_variance   | 0.783       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0573     |\n",
      "|    n_updates            | 7350        |\n",
      "|    policy_gradient_loss | -0.0192     |\n",
      "|    value_loss           | 5.15e-06    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 152         |\n",
      "|    iterations           | 737         |\n",
      "|    time_elapsed         | 9926        |\n",
      "|    total_timesteps      | 1509376     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013883176 |\n",
      "|    clip_fraction        | 0.141       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.11       |\n",
      "|    explained_variance   | 0.899       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00301    |\n",
      "|    n_updates            | 7360        |\n",
      "|    policy_gradient_loss | -0.00545    |\n",
      "|    value_loss           | 7.75e-06    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1510000, episode_reward=-0.09 +/- 0.11\n",
      "Episode length: 10000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+04       |\n",
      "|    mean_reward          | -0.0934     |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1510000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007046325 |\n",
      "|    clip_fraction        | 0.078       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.05       |\n",
      "|    explained_variance   | 0.419       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0161     |\n",
      "|    n_updates            | 7370        |\n",
      "|    policy_gradient_loss | -0.00182    |\n",
      "|    value_loss           | 2.72e-06    |\n",
      "-----------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 151     |\n",
      "|    iterations      | 738     |\n",
      "|    time_elapsed    | 9974    |\n",
      "|    total_timesteps | 1511424 |\n",
      "--------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 739         |\n",
      "|    time_elapsed         | 9980        |\n",
      "|    total_timesteps      | 1513472     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011017208 |\n",
      "|    clip_fraction        | 0.181       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.1        |\n",
      "|    explained_variance   | 0.95        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0429     |\n",
      "|    n_updates            | 7380        |\n",
      "|    policy_gradient_loss | -0.0116     |\n",
      "|    value_loss           | 0.000114    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 740         |\n",
      "|    time_elapsed         | 9986        |\n",
      "|    total_timesteps      | 1515520     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013810656 |\n",
      "|    clip_fraction        | 0.0931      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.18       |\n",
      "|    explained_variance   | 0.0377      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00223    |\n",
      "|    n_updates            | 7390        |\n",
      "|    policy_gradient_loss | -0.000709   |\n",
      "|    value_loss           | 4.54e-05    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 151          |\n",
      "|    iterations           | 741          |\n",
      "|    time_elapsed         | 9991         |\n",
      "|    total_timesteps      | 1517568      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0049028806 |\n",
      "|    clip_fraction        | 0.0829       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.19        |\n",
      "|    explained_variance   | 0.9          |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.00556      |\n",
      "|    n_updates            | 7400         |\n",
      "|    policy_gradient_loss | -0.00302     |\n",
      "|    value_loss           | 5.04e-05     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 152          |\n",
      "|    iterations           | 742          |\n",
      "|    time_elapsed         | 9997         |\n",
      "|    total_timesteps      | 1519616      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0056230575 |\n",
      "|    clip_fraction        | 0.0571       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.16        |\n",
      "|    explained_variance   | 0.921        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0131      |\n",
      "|    n_updates            | 7410         |\n",
      "|    policy_gradient_loss | 0.000216     |\n",
      "|    value_loss           | 2.91e-05     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1520000, episode_reward=0.03 +/- 0.04\n",
      "Episode length: 10000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+04       |\n",
      "|    mean_reward          | 0.0324      |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1520000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008147267 |\n",
      "|    clip_fraction        | 0.123       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.1        |\n",
      "|    explained_variance   | 0.807       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0109      |\n",
      "|    n_updates            | 7420        |\n",
      "|    policy_gradient_loss | -0.00206    |\n",
      "|    value_loss           | 5.7e-05     |\n",
      "-----------------------------------------\n",
      "box reached target\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 151     |\n",
      "|    iterations      | 743     |\n",
      "|    time_elapsed    | 10045   |\n",
      "|    total_timesteps | 1521664 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 151          |\n",
      "|    iterations           | 744          |\n",
      "|    time_elapsed         | 10050        |\n",
      "|    total_timesteps      | 1523712      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0052361176 |\n",
      "|    clip_fraction        | 0.0568       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.828       |\n",
      "|    explained_variance   | 0.621        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -8.98e-05    |\n",
      "|    n_updates            | 7430         |\n",
      "|    policy_gradient_loss | -0.00365     |\n",
      "|    value_loss           | 0.00826      |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 745         |\n",
      "|    time_elapsed         | 10056       |\n",
      "|    total_timesteps      | 1525760     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026308833 |\n",
      "|    clip_fraction        | 0.178       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.88       |\n",
      "|    explained_variance   | -2.93       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0433     |\n",
      "|    n_updates            | 7440        |\n",
      "|    policy_gradient_loss | -0.0137     |\n",
      "|    value_loss           | 3.59e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 746         |\n",
      "|    time_elapsed         | 10061       |\n",
      "|    total_timesteps      | 1527808     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018724885 |\n",
      "|    clip_fraction        | 0.163       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.996      |\n",
      "|    explained_variance   | 0.929       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.000124   |\n",
      "|    n_updates            | 7450        |\n",
      "|    policy_gradient_loss | -0.0165     |\n",
      "|    value_loss           | 1.74e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 747         |\n",
      "|    time_elapsed         | 10067       |\n",
      "|    total_timesteps      | 1529856     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013144039 |\n",
      "|    clip_fraction        | 0.211       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.11       |\n",
      "|    explained_variance   | 0.847       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0458     |\n",
      "|    n_updates            | 7460        |\n",
      "|    policy_gradient_loss | -0.0101     |\n",
      "|    value_loss           | 1.69e-05    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1530000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 10000.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1e+04        |\n",
      "|    mean_reward          | 0.00107      |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1530000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073237293 |\n",
      "|    clip_fraction        | 0.141        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.98        |\n",
      "|    explained_variance   | 0.917        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0262      |\n",
      "|    n_updates            | 7470         |\n",
      "|    policy_gradient_loss | -0.00683     |\n",
      "|    value_loss           | 1.55e-05     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 151     |\n",
      "|    iterations      | 748     |\n",
      "|    time_elapsed    | 10115   |\n",
      "|    total_timesteps | 1531904 |\n",
      "--------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 151        |\n",
      "|    iterations           | 749        |\n",
      "|    time_elapsed         | 10120      |\n",
      "|    total_timesteps      | 1533952    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01676571 |\n",
      "|    clip_fraction        | 0.21       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.04      |\n",
      "|    explained_variance   | 0.804      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0364    |\n",
      "|    n_updates            | 7480       |\n",
      "|    policy_gradient_loss | -0.0249    |\n",
      "|    value_loss           | 0.000692   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 750         |\n",
      "|    time_elapsed         | 10126       |\n",
      "|    total_timesteps      | 1536000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010360191 |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.3        |\n",
      "|    explained_variance   | 0.849       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00334    |\n",
      "|    n_updates            | 7490        |\n",
      "|    policy_gradient_loss | -0.00711    |\n",
      "|    value_loss           | 5.5e-05     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 751         |\n",
      "|    time_elapsed         | 10131       |\n",
      "|    total_timesteps      | 1538048     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011751048 |\n",
      "|    clip_fraction        | 0.114       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.21       |\n",
      "|    explained_variance   | 0.942       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0375     |\n",
      "|    n_updates            | 7500        |\n",
      "|    policy_gradient_loss | -0.00729    |\n",
      "|    value_loss           | 0.000424    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1540000, episode_reward=0.02 +/- 0.04\n",
      "Episode length: 10000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+04       |\n",
      "|    mean_reward          | 0.0207      |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1540000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021679018 |\n",
      "|    clip_fraction        | 0.394       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.18       |\n",
      "|    explained_variance   | -1.41       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0121     |\n",
      "|    n_updates            | 7510        |\n",
      "|    policy_gradient_loss | -0.017      |\n",
      "|    value_loss           | 0.000249    |\n",
      "-----------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 151     |\n",
      "|    iterations      | 752     |\n",
      "|    time_elapsed    | 10180   |\n",
      "|    total_timesteps | 1540096 |\n",
      "--------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 753         |\n",
      "|    time_elapsed         | 10185       |\n",
      "|    total_timesteps      | 1542144     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015358746 |\n",
      "|    clip_fraction        | 0.151       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.21       |\n",
      "|    explained_variance   | 0.645       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0673      |\n",
      "|    n_updates            | 7520        |\n",
      "|    policy_gradient_loss | -0.00845    |\n",
      "|    value_loss           | 0.000566    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 151        |\n",
      "|    iterations           | 754        |\n",
      "|    time_elapsed         | 10191      |\n",
      "|    total_timesteps      | 1544192    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02446843 |\n",
      "|    clip_fraction        | 0.192      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.32      |\n",
      "|    explained_variance   | 0.906      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.023     |\n",
      "|    n_updates            | 7530       |\n",
      "|    policy_gradient_loss | -0.0107    |\n",
      "|    value_loss           | 8.41e-05   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 151        |\n",
      "|    iterations           | 755        |\n",
      "|    time_elapsed         | 10196      |\n",
      "|    total_timesteps      | 1546240    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01540092 |\n",
      "|    clip_fraction        | 0.166      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.18      |\n",
      "|    explained_variance   | -0.125     |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.00459   |\n",
      "|    n_updates            | 7540       |\n",
      "|    policy_gradient_loss | -0.00436   |\n",
      "|    value_loss           | 1.37e-05   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 756         |\n",
      "|    time_elapsed         | 10202       |\n",
      "|    total_timesteps      | 1548288     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017454201 |\n",
      "|    clip_fraction        | 0.26        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.11       |\n",
      "|    explained_variance   | -0.123      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0128      |\n",
      "|    n_updates            | 7550        |\n",
      "|    policy_gradient_loss | -0.00471    |\n",
      "|    value_loss           | 6.2e-06     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1550000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 10000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+04       |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1550000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007145357 |\n",
      "|    clip_fraction        | 0.112       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.04       |\n",
      "|    explained_variance   | -0.021      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0113      |\n",
      "|    n_updates            | 7560        |\n",
      "|    policy_gradient_loss | 0.000143    |\n",
      "|    value_loss           | 1.22e-05    |\n",
      "-----------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 151     |\n",
      "|    iterations      | 757     |\n",
      "|    time_elapsed    | 10250   |\n",
      "|    total_timesteps | 1550336 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 151          |\n",
      "|    iterations           | 758          |\n",
      "|    time_elapsed         | 10256        |\n",
      "|    total_timesteps      | 1552384      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0050194394 |\n",
      "|    clip_fraction        | 0.079        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.99        |\n",
      "|    explained_variance   | 0.968        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0433      |\n",
      "|    n_updates            | 7570         |\n",
      "|    policy_gradient_loss | -0.0072      |\n",
      "|    value_loss           | 0.000172     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 759         |\n",
      "|    time_elapsed         | 10261       |\n",
      "|    total_timesteps      | 1554432     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.036142588 |\n",
      "|    clip_fraction        | 0.152       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.27       |\n",
      "|    explained_variance   | 0.897       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0719      |\n",
      "|    n_updates            | 7580        |\n",
      "|    policy_gradient_loss | -0.00883    |\n",
      "|    value_loss           | 0.00011     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 760         |\n",
      "|    time_elapsed         | 10267       |\n",
      "|    total_timesteps      | 1556480     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011119731 |\n",
      "|    clip_fraction        | 0.222       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.41       |\n",
      "|    explained_variance   | -0.553      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00617     |\n",
      "|    n_updates            | 7590        |\n",
      "|    policy_gradient_loss | -0.00756    |\n",
      "|    value_loss           | 5.75e-06    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 761         |\n",
      "|    time_elapsed         | 10272       |\n",
      "|    total_timesteps      | 1558528     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012122474 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.46       |\n",
      "|    explained_variance   | 0.0244      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00614    |\n",
      "|    n_updates            | 7600        |\n",
      "|    policy_gradient_loss | -0.00877    |\n",
      "|    value_loss           | 1.85e-06    |\n",
      "-----------------------------------------\n",
      "box reached target\n",
      "Eval num_timesteps=1560000, episode_reward=1.09 +/- 2.07\n",
      "Episode length: 8071.60 +/- 3856.80\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 8.07e+03    |\n",
      "|    mean_reward          | 1.09        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1560000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014684042 |\n",
      "|    clip_fraction        | 0.107       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.07       |\n",
      "|    explained_variance   | 0.931       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.000897    |\n",
      "|    n_updates            | 7610        |\n",
      "|    policy_gradient_loss | -0.0104     |\n",
      "|    value_loss           | 0.000128    |\n",
      "-----------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 151     |\n",
      "|    iterations      | 762     |\n",
      "|    time_elapsed    | 10313   |\n",
      "|    total_timesteps | 1560576 |\n",
      "--------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 763         |\n",
      "|    time_elapsed         | 10318       |\n",
      "|    total_timesteps      | 1562624     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016054364 |\n",
      "|    clip_fraction        | 0.153       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.21       |\n",
      "|    explained_variance   | 0.927       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.01       |\n",
      "|    n_updates            | 7620        |\n",
      "|    policy_gradient_loss | -0.0179     |\n",
      "|    value_loss           | 0.00011     |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 151        |\n",
      "|    iterations           | 764        |\n",
      "|    time_elapsed         | 10324      |\n",
      "|    total_timesteps      | 1564672    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01167398 |\n",
      "|    clip_fraction        | 0.141      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.37      |\n",
      "|    explained_variance   | 0.927      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0288    |\n",
      "|    n_updates            | 7630       |\n",
      "|    policy_gradient_loss | -0.00963   |\n",
      "|    value_loss           | 2.4e-05    |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 765         |\n",
      "|    time_elapsed         | 10329       |\n",
      "|    total_timesteps      | 1566720     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020335134 |\n",
      "|    clip_fraction        | 0.236       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.18       |\n",
      "|    explained_variance   | 0.931       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0222     |\n",
      "|    n_updates            | 7640        |\n",
      "|    policy_gradient_loss | -0.0187     |\n",
      "|    value_loss           | 0.0001      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 766         |\n",
      "|    time_elapsed         | 10335       |\n",
      "|    total_timesteps      | 1568768     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012107357 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.16       |\n",
      "|    explained_variance   | 0.934       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0371     |\n",
      "|    n_updates            | 7650        |\n",
      "|    policy_gradient_loss | -0.0163     |\n",
      "|    value_loss           | 6.21e-05    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1570000, episode_reward=0.03 +/- 0.07\n",
      "Episode length: 10000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+04       |\n",
      "|    mean_reward          | 0.0296      |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1570000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017426517 |\n",
      "|    clip_fraction        | 0.101       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.05       |\n",
      "|    explained_variance   | 0.909       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0335     |\n",
      "|    n_updates            | 7660        |\n",
      "|    policy_gradient_loss | -0.00864    |\n",
      "|    value_loss           | 0.000193    |\n",
      "-----------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 151     |\n",
      "|    iterations      | 767     |\n",
      "|    time_elapsed    | 10382   |\n",
      "|    total_timesteps | 1570816 |\n",
      "--------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 768         |\n",
      "|    time_elapsed         | 10387       |\n",
      "|    total_timesteps      | 1572864     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010536298 |\n",
      "|    clip_fraction        | 0.103       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.98       |\n",
      "|    explained_variance   | 0.94        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0112      |\n",
      "|    n_updates            | 7670        |\n",
      "|    policy_gradient_loss | -0.00563    |\n",
      "|    value_loss           | 5.28e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 769         |\n",
      "|    time_elapsed         | 10393       |\n",
      "|    total_timesteps      | 1574912     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030061847 |\n",
      "|    clip_fraction        | 0.201       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.04       |\n",
      "|    explained_variance   | 0.947       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0139     |\n",
      "|    n_updates            | 7680        |\n",
      "|    policy_gradient_loss | -0.0104     |\n",
      "|    value_loss           | 0.000129    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 151        |\n",
      "|    iterations           | 770        |\n",
      "|    time_elapsed         | 10398      |\n",
      "|    total_timesteps      | 1576960    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04278048 |\n",
      "|    clip_fraction        | 0.246      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.07      |\n",
      "|    explained_variance   | 0.622      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0117    |\n",
      "|    n_updates            | 7690       |\n",
      "|    policy_gradient_loss | -0.0185    |\n",
      "|    value_loss           | 7.6e-06    |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 151          |\n",
      "|    iterations           | 771          |\n",
      "|    time_elapsed         | 10404        |\n",
      "|    total_timesteps      | 1579008      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073501505 |\n",
      "|    clip_fraction        | 0.115        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.03        |\n",
      "|    explained_variance   | 0.729        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0101       |\n",
      "|    n_updates            | 7700         |\n",
      "|    policy_gradient_loss | -0.00504     |\n",
      "|    value_loss           | 5.14e-07     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1580000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 10000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+04       |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1580000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009015215 |\n",
      "|    clip_fraction        | 0.136       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.995      |\n",
      "|    explained_variance   | 0.896       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0108      |\n",
      "|    n_updates            | 7710        |\n",
      "|    policy_gradient_loss | -0.00973    |\n",
      "|    value_loss           | 1.67e-05    |\n",
      "-----------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 151     |\n",
      "|    iterations      | 772     |\n",
      "|    time_elapsed    | 10451   |\n",
      "|    total_timesteps | 1581056 |\n",
      "--------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 773         |\n",
      "|    time_elapsed         | 10456       |\n",
      "|    total_timesteps      | 1583104     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018434143 |\n",
      "|    clip_fraction        | 0.2         |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.14       |\n",
      "|    explained_variance   | 0.929       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.03        |\n",
      "|    n_updates            | 7720        |\n",
      "|    policy_gradient_loss | -0.013      |\n",
      "|    value_loss           | 0.000429    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 774         |\n",
      "|    time_elapsed         | 10462       |\n",
      "|    total_timesteps      | 1585152     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007847264 |\n",
      "|    clip_fraction        | 0.0896      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.13       |\n",
      "|    explained_variance   | 0.938       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0219     |\n",
      "|    n_updates            | 7730        |\n",
      "|    policy_gradient_loss | -0.00957    |\n",
      "|    value_loss           | 0.000959    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 151        |\n",
      "|    iterations           | 775        |\n",
      "|    time_elapsed         | 10467      |\n",
      "|    total_timesteps      | 1587200    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01413031 |\n",
      "|    clip_fraction        | 0.17       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.21      |\n",
      "|    explained_variance   | 0.947      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0189    |\n",
      "|    n_updates            | 7740       |\n",
      "|    policy_gradient_loss | -0.0115    |\n",
      "|    value_loss           | 0.000501   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 776         |\n",
      "|    time_elapsed         | 10473       |\n",
      "|    total_timesteps      | 1589248     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016924094 |\n",
      "|    clip_fraction        | 0.18        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.45       |\n",
      "|    explained_variance   | 0.877       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00286     |\n",
      "|    n_updates            | 7750        |\n",
      "|    policy_gradient_loss | -0.0154     |\n",
      "|    value_loss           | 0.000492    |\n",
      "-----------------------------------------\n",
      "box reached target\n",
      "Eval num_timesteps=1590000, episode_reward=1.03 +/- 2.07\n",
      "Episode length: 8123.60 +/- 3752.80\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 8.12e+03    |\n",
      "|    mean_reward          | 1.03        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1590000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013527673 |\n",
      "|    clip_fraction        | 0.225       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.46       |\n",
      "|    explained_variance   | 0.942       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0426     |\n",
      "|    n_updates            | 7760        |\n",
      "|    policy_gradient_loss | -0.0138     |\n",
      "|    value_loss           | 5.75e-05    |\n",
      "-----------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 151     |\n",
      "|    iterations      | 777     |\n",
      "|    time_elapsed    | 10512   |\n",
      "|    total_timesteps | 1591296 |\n",
      "--------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 778         |\n",
      "|    time_elapsed         | 10518       |\n",
      "|    total_timesteps      | 1593344     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017375609 |\n",
      "|    clip_fraction        | 0.134       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.21       |\n",
      "|    explained_variance   | 0.857       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0297     |\n",
      "|    n_updates            | 7770        |\n",
      "|    policy_gradient_loss | -0.0088     |\n",
      "|    value_loss           | 0.000134    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 779         |\n",
      "|    time_elapsed         | 10523       |\n",
      "|    total_timesteps      | 1595392     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014565837 |\n",
      "|    clip_fraction        | 0.247       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.18       |\n",
      "|    explained_variance   | 0.559       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0404     |\n",
      "|    n_updates            | 7780        |\n",
      "|    policy_gradient_loss | -0.0168     |\n",
      "|    value_loss           | 3.06e-06    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 780         |\n",
      "|    time_elapsed         | 10529       |\n",
      "|    total_timesteps      | 1597440     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016194332 |\n",
      "|    clip_fraction        | 0.285       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.38       |\n",
      "|    explained_variance   | 0.908       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.012       |\n",
      "|    n_updates            | 7790        |\n",
      "|    policy_gradient_loss | -0.0224     |\n",
      "|    value_loss           | 1.04e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 781         |\n",
      "|    time_elapsed         | 10534       |\n",
      "|    total_timesteps      | 1599488     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005625647 |\n",
      "|    clip_fraction        | 0.0844      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.45       |\n",
      "|    explained_variance   | 0.79        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0233     |\n",
      "|    n_updates            | 7800        |\n",
      "|    policy_gradient_loss | -0.0114     |\n",
      "|    value_loss           | 1.62e-05    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1600000, episode_reward=0.05 +/- 0.07\n",
      "Episode length: 10000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+04       |\n",
      "|    mean_reward          | 0.0525      |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1600000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.037930533 |\n",
      "|    clip_fraction        | 0.0854      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.512      |\n",
      "|    explained_variance   | -0.553      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0508      |\n",
      "|    n_updates            | 7810        |\n",
      "|    policy_gradient_loss | -0.00545    |\n",
      "|    value_loss           | 9.17e-06    |\n",
      "-----------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 151     |\n",
      "|    iterations      | 782     |\n",
      "|    time_elapsed    | 10582   |\n",
      "|    total_timesteps | 1601536 |\n",
      "--------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 783         |\n",
      "|    time_elapsed         | 10587       |\n",
      "|    total_timesteps      | 1603584     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016168516 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.09       |\n",
      "|    explained_variance   | 0.901       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.047      |\n",
      "|    n_updates            | 7820        |\n",
      "|    policy_gradient_loss | -0.0148     |\n",
      "|    value_loss           | 0.000185    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 784         |\n",
      "|    time_elapsed         | 10592       |\n",
      "|    total_timesteps      | 1605632     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013297593 |\n",
      "|    clip_fraction        | 0.15        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.38       |\n",
      "|    explained_variance   | 0.935       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0389     |\n",
      "|    n_updates            | 7830        |\n",
      "|    policy_gradient_loss | -0.0106     |\n",
      "|    value_loss           | 8.33e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 785         |\n",
      "|    time_elapsed         | 10598       |\n",
      "|    total_timesteps      | 1607680     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010661041 |\n",
      "|    clip_fraction        | 0.188       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.42       |\n",
      "|    explained_variance   | 0.751       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00159    |\n",
      "|    n_updates            | 7840        |\n",
      "|    policy_gradient_loss | -0.0123     |\n",
      "|    value_loss           | 5.03e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 786         |\n",
      "|    time_elapsed         | 10603       |\n",
      "|    total_timesteps      | 1609728     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010490491 |\n",
      "|    clip_fraction        | 0.116       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.37       |\n",
      "|    explained_variance   | 0.705       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0245     |\n",
      "|    n_updates            | 7850        |\n",
      "|    policy_gradient_loss | -0.00539    |\n",
      "|    value_loss           | 1.13e-05    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1610000, episode_reward=0.06 +/- 0.13\n",
      "Episode length: 10000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+04       |\n",
      "|    mean_reward          | 0.0626      |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1610000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012455504 |\n",
      "|    clip_fraction        | 0.0944      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.32       |\n",
      "|    explained_variance   | 0.926       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0073     |\n",
      "|    n_updates            | 7860        |\n",
      "|    policy_gradient_loss | -0.00486    |\n",
      "|    value_loss           | 5.89e-06    |\n",
      "-----------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 151     |\n",
      "|    iterations      | 787     |\n",
      "|    time_elapsed    | 10651   |\n",
      "|    total_timesteps | 1611776 |\n",
      "--------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 788         |\n",
      "|    time_elapsed         | 10657       |\n",
      "|    total_timesteps      | 1613824     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022338783 |\n",
      "|    clip_fraction        | 0.232       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.29       |\n",
      "|    explained_variance   | 0.909       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00784    |\n",
      "|    n_updates            | 7870        |\n",
      "|    policy_gradient_loss | -0.0186     |\n",
      "|    value_loss           | 4.67e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 789         |\n",
      "|    time_elapsed         | 10662       |\n",
      "|    total_timesteps      | 1615872     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014594376 |\n",
      "|    clip_fraction        | 0.243       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.44       |\n",
      "|    explained_variance   | 0.934       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0146     |\n",
      "|    n_updates            | 7880        |\n",
      "|    policy_gradient_loss | -0.0155     |\n",
      "|    value_loss           | 1.44e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 790         |\n",
      "|    time_elapsed         | 10667       |\n",
      "|    total_timesteps      | 1617920     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012053462 |\n",
      "|    clip_fraction        | 0.204       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.43       |\n",
      "|    explained_variance   | 0.729       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00948    |\n",
      "|    n_updates            | 7890        |\n",
      "|    policy_gradient_loss | -0.0202     |\n",
      "|    value_loss           | 1.63e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 791         |\n",
      "|    time_elapsed         | 10672       |\n",
      "|    total_timesteps      | 1619968     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012258114 |\n",
      "|    clip_fraction        | 0.147       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.47       |\n",
      "|    explained_variance   | 0.921       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.014      |\n",
      "|    n_updates            | 7900        |\n",
      "|    policy_gradient_loss | -0.00901    |\n",
      "|    value_loss           | 3.83e-06    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1620000, episode_reward=0.06 +/- 0.09\n",
      "Episode length: 10000.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1e+04        |\n",
      "|    mean_reward          | 0.0564       |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1620000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0101066455 |\n",
      "|    clip_fraction        | 0.119        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.45        |\n",
      "|    explained_variance   | 0.932        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0166      |\n",
      "|    n_updates            | 7910         |\n",
      "|    policy_gradient_loss | -0.00992     |\n",
      "|    value_loss           | 2.7e-06      |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 151     |\n",
      "|    iterations      | 792     |\n",
      "|    time_elapsed    | 10720   |\n",
      "|    total_timesteps | 1622016 |\n",
      "--------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 793         |\n",
      "|    time_elapsed         | 10726       |\n",
      "|    total_timesteps      | 1624064     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012983333 |\n",
      "|    clip_fraction        | 0.099       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.994      |\n",
      "|    explained_variance   | 0.928       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.000345    |\n",
      "|    n_updates            | 7920        |\n",
      "|    policy_gradient_loss | -0.00911    |\n",
      "|    value_loss           | 3.29e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 794         |\n",
      "|    time_elapsed         | 10731       |\n",
      "|    total_timesteps      | 1626112     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011985682 |\n",
      "|    clip_fraction        | 0.183       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.15       |\n",
      "|    explained_variance   | 0.857       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.000973   |\n",
      "|    n_updates            | 7930        |\n",
      "|    policy_gradient_loss | -0.014      |\n",
      "|    value_loss           | 2.94e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 795         |\n",
      "|    time_elapsed         | 10737       |\n",
      "|    total_timesteps      | 1628160     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013399936 |\n",
      "|    clip_fraction        | 0.198       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.11       |\n",
      "|    explained_variance   | 0.851       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00765     |\n",
      "|    n_updates            | 7940        |\n",
      "|    policy_gradient_loss | -0.017      |\n",
      "|    value_loss           | 2.25e-05    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1630000, episode_reward=0.09 +/- 0.11\n",
      "Episode length: 10000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+04       |\n",
      "|    mean_reward          | 0.0856      |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1630000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012637254 |\n",
      "|    clip_fraction        | 0.204       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.01       |\n",
      "|    explained_variance   | 0.855       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0276     |\n",
      "|    n_updates            | 7950        |\n",
      "|    policy_gradient_loss | -0.0192     |\n",
      "|    value_loss           | 2.53e-05    |\n",
      "-----------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 151     |\n",
      "|    iterations      | 796     |\n",
      "|    time_elapsed    | 10784   |\n",
      "|    total_timesteps | 1630208 |\n",
      "--------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 151        |\n",
      "|    iterations           | 797        |\n",
      "|    time_elapsed         | 10789      |\n",
      "|    total_timesteps      | 1632256    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01556053 |\n",
      "|    clip_fraction        | 0.153      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.01      |\n",
      "|    explained_variance   | 0.798      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0348    |\n",
      "|    n_updates            | 7960       |\n",
      "|    policy_gradient_loss | -0.0109    |\n",
      "|    value_loss           | 8.76e-05   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 798         |\n",
      "|    time_elapsed         | 10795       |\n",
      "|    total_timesteps      | 1634304     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012122499 |\n",
      "|    clip_fraction        | 0.188       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1          |\n",
      "|    explained_variance   | 0.936       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0036      |\n",
      "|    n_updates            | 7970        |\n",
      "|    policy_gradient_loss | -0.00881    |\n",
      "|    value_loss           | 5.3e-05     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 799         |\n",
      "|    time_elapsed         | 10800       |\n",
      "|    total_timesteps      | 1636352     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011575347 |\n",
      "|    clip_fraction        | 0.145       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.17       |\n",
      "|    explained_variance   | 0.793       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0102     |\n",
      "|    n_updates            | 7980        |\n",
      "|    policy_gradient_loss | -0.0107     |\n",
      "|    value_loss           | 2.28e-05    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 151          |\n",
      "|    iterations           | 800          |\n",
      "|    time_elapsed         | 10805        |\n",
      "|    total_timesteps      | 1638400      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0086496025 |\n",
      "|    clip_fraction        | 0.153        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.19        |\n",
      "|    explained_variance   | 0.702        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0213      |\n",
      "|    n_updates            | 7990         |\n",
      "|    policy_gradient_loss | -0.0126      |\n",
      "|    value_loss           | 1.12e-05     |\n",
      "------------------------------------------\n",
      "box reached target\n",
      "box reached target\n",
      "Eval num_timesteps=1640000, episode_reward=2.19 +/- 2.68\n",
      "Episode length: 6326.80 +/- 4500.44\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 6.33e+03    |\n",
      "|    mean_reward          | 2.19        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1640000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016056508 |\n",
      "|    clip_fraction        | 0.307       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.2        |\n",
      "|    explained_variance   | 0.487       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0517     |\n",
      "|    n_updates            | 8000        |\n",
      "|    policy_gradient_loss | -0.0221     |\n",
      "|    value_loss           | 9.99e-06    |\n",
      "-----------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 151     |\n",
      "|    iterations      | 801     |\n",
      "|    time_elapsed    | 10838   |\n",
      "|    total_timesteps | 1640448 |\n",
      "--------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 802         |\n",
      "|    time_elapsed         | 10843       |\n",
      "|    total_timesteps      | 1642496     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011054094 |\n",
      "|    clip_fraction        | 0.134       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.03       |\n",
      "|    explained_variance   | 0.954       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0147      |\n",
      "|    n_updates            | 8010        |\n",
      "|    policy_gradient_loss | -0.00661    |\n",
      "|    value_loss           | 7.54e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 803         |\n",
      "|    time_elapsed         | 10849       |\n",
      "|    total_timesteps      | 1644544     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012940641 |\n",
      "|    clip_fraction        | 0.13        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.885      |\n",
      "|    explained_variance   | 0.905       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00107    |\n",
      "|    n_updates            | 8020        |\n",
      "|    policy_gradient_loss | -0.00669    |\n",
      "|    value_loss           | 1.44e-05    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 151          |\n",
      "|    iterations           | 804          |\n",
      "|    time_elapsed         | 10854        |\n",
      "|    total_timesteps      | 1646592      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0037831059 |\n",
      "|    clip_fraction        | 0.0611       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.678       |\n",
      "|    explained_variance   | 0.9          |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.00608      |\n",
      "|    n_updates            | 8030         |\n",
      "|    policy_gradient_loss | -0.00259     |\n",
      "|    value_loss           | 3.07e-06     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 805         |\n",
      "|    time_elapsed         | 10859       |\n",
      "|    total_timesteps      | 1648640     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008368386 |\n",
      "|    clip_fraction        | 0.114       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.602      |\n",
      "|    explained_variance   | 0.879       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0328     |\n",
      "|    n_updates            | 8040        |\n",
      "|    policy_gradient_loss | -0.014      |\n",
      "|    value_loss           | 1.16e-07    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1650000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 10000.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1e+04        |\n",
      "|    mean_reward          | 0            |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1650000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0035921305 |\n",
      "|    clip_fraction        | 0.0384       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.763       |\n",
      "|    explained_variance   | 0.914        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0245      |\n",
      "|    n_updates            | 8050         |\n",
      "|    policy_gradient_loss | -0.00584     |\n",
      "|    value_loss           | 1.38e-07     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 151     |\n",
      "|    iterations      | 806     |\n",
      "|    time_elapsed    | 10906   |\n",
      "|    total_timesteps | 1650688 |\n",
      "--------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 807         |\n",
      "|    time_elapsed         | 10912       |\n",
      "|    total_timesteps      | 1652736     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024059925 |\n",
      "|    clip_fraction        | 0.18        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.972      |\n",
      "|    explained_variance   | 0.958       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0121      |\n",
      "|    n_updates            | 8060        |\n",
      "|    policy_gradient_loss | -0.0107     |\n",
      "|    value_loss           | 2.05e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 808         |\n",
      "|    time_elapsed         | 10917       |\n",
      "|    total_timesteps      | 1654784     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011211687 |\n",
      "|    clip_fraction        | 0.229       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.42       |\n",
      "|    explained_variance   | 0.265       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0464     |\n",
      "|    n_updates            | 8070        |\n",
      "|    policy_gradient_loss | -0.0116     |\n",
      "|    value_loss           | 3.19e-05    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 151          |\n",
      "|    iterations           | 809          |\n",
      "|    time_elapsed         | 10922        |\n",
      "|    total_timesteps      | 1656832      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0063016643 |\n",
      "|    clip_fraction        | 0.0742       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.45        |\n",
      "|    explained_variance   | 0.778        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0107       |\n",
      "|    n_updates            | 8080         |\n",
      "|    policy_gradient_loss | -0.00343     |\n",
      "|    value_loss           | 3.5e-05      |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 151          |\n",
      "|    iterations           | 810          |\n",
      "|    time_elapsed         | 10928        |\n",
      "|    total_timesteps      | 1658880      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0060877744 |\n",
      "|    clip_fraction        | 0.0583       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.48        |\n",
      "|    explained_variance   | 0.66         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.00629      |\n",
      "|    n_updates            | 8090         |\n",
      "|    policy_gradient_loss | -0.00359     |\n",
      "|    value_loss           | 6.72e-06     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1660000, episode_reward=-0.01 +/- 0.04\n",
      "Episode length: 10000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+04       |\n",
      "|    mean_reward          | -0.00933    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1660000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009949541 |\n",
      "|    clip_fraction        | 0.271       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.47       |\n",
      "|    explained_variance   | 0.12        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.000763   |\n",
      "|    n_updates            | 8100        |\n",
      "|    policy_gradient_loss | -0.0136     |\n",
      "|    value_loss           | 8.43e-06    |\n",
      "-----------------------------------------\n",
      "box reached target\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 151     |\n",
      "|    iterations      | 811     |\n",
      "|    time_elapsed    | 10976   |\n",
      "|    total_timesteps | 1660928 |\n",
      "--------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 812         |\n",
      "|    time_elapsed         | 10982       |\n",
      "|    total_timesteps      | 1662976     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008350222 |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.17       |\n",
      "|    explained_variance   | -0.53       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00556     |\n",
      "|    n_updates            | 8110        |\n",
      "|    policy_gradient_loss | -0.00692    |\n",
      "|    value_loss           | 0.0257      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 813         |\n",
      "|    time_elapsed         | 10987       |\n",
      "|    total_timesteps      | 1665024     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012569081 |\n",
      "|    clip_fraction        | 0.177       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.13       |\n",
      "|    explained_variance   | 0.903       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.029      |\n",
      "|    n_updates            | 8120        |\n",
      "|    policy_gradient_loss | -0.0115     |\n",
      "|    value_loss           | 0.0021      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 151        |\n",
      "|    iterations           | 814        |\n",
      "|    time_elapsed         | 10993      |\n",
      "|    total_timesteps      | 1667072    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00817913 |\n",
      "|    clip_fraction        | 0.0807     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.29      |\n",
      "|    explained_variance   | 0.554      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.00652   |\n",
      "|    n_updates            | 8130       |\n",
      "|    policy_gradient_loss | -0.00563   |\n",
      "|    value_loss           | 0.000401   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 815         |\n",
      "|    time_elapsed         | 10998       |\n",
      "|    total_timesteps      | 1669120     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016671889 |\n",
      "|    clip_fraction        | 0.293       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.24       |\n",
      "|    explained_variance   | 0.868       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0423     |\n",
      "|    n_updates            | 8140        |\n",
      "|    policy_gradient_loss | -0.0243     |\n",
      "|    value_loss           | 0.000436    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1670000, episode_reward=0.09 +/- 0.10\n",
      "Episode length: 10000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+04       |\n",
      "|    mean_reward          | 0.0944      |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1670000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017854348 |\n",
      "|    clip_fraction        | 0.185       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.19       |\n",
      "|    explained_variance   | 0.938       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00498    |\n",
      "|    n_updates            | 8150        |\n",
      "|    policy_gradient_loss | -0.0125     |\n",
      "|    value_loss           | 0.0012      |\n",
      "-----------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 151     |\n",
      "|    iterations      | 816     |\n",
      "|    time_elapsed    | 11045   |\n",
      "|    total_timesteps | 1671168 |\n",
      "--------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 817         |\n",
      "|    time_elapsed         | 11051       |\n",
      "|    total_timesteps      | 1673216     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008918746 |\n",
      "|    clip_fraction        | 0.114       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.883      |\n",
      "|    explained_variance   | 0.912       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0196     |\n",
      "|    n_updates            | 8160        |\n",
      "|    policy_gradient_loss | -0.00579    |\n",
      "|    value_loss           | 0.00589     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 818         |\n",
      "|    time_elapsed         | 11056       |\n",
      "|    total_timesteps      | 1675264     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016074918 |\n",
      "|    clip_fraction        | 0.247       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.25       |\n",
      "|    explained_variance   | 0.667       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00621    |\n",
      "|    n_updates            | 8170        |\n",
      "|    policy_gradient_loss | -0.0133     |\n",
      "|    value_loss           | 0.000112    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 819         |\n",
      "|    time_elapsed         | 11062       |\n",
      "|    total_timesteps      | 1677312     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017377168 |\n",
      "|    clip_fraction        | 0.311       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.39       |\n",
      "|    explained_variance   | -0.185      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0193     |\n",
      "|    n_updates            | 8180        |\n",
      "|    policy_gradient_loss | -0.0143     |\n",
      "|    value_loss           | 4.66e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 820         |\n",
      "|    time_elapsed         | 11067       |\n",
      "|    total_timesteps      | 1679360     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012383109 |\n",
      "|    clip_fraction        | 0.205       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.4        |\n",
      "|    explained_variance   | 0.519       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00741    |\n",
      "|    n_updates            | 8190        |\n",
      "|    policy_gradient_loss | -0.00861    |\n",
      "|    value_loss           | 1.94e-05    |\n",
      "-----------------------------------------\n",
      "box reached target\n",
      "Eval num_timesteps=1680000, episode_reward=1.16 +/- 2.29\n",
      "Episode length: 8309.00 +/- 3382.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 8.31e+03    |\n",
      "|    mean_reward          | 1.16        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1680000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007831071 |\n",
      "|    clip_fraction        | 0.0558      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.41       |\n",
      "|    explained_variance   | 0.792       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00689    |\n",
      "|    n_updates            | 8200        |\n",
      "|    policy_gradient_loss | -0.00166    |\n",
      "|    value_loss           | 1.27e-05    |\n",
      "-----------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 151     |\n",
      "|    iterations      | 821     |\n",
      "|    time_elapsed    | 11107   |\n",
      "|    total_timesteps | 1681408 |\n",
      "--------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 822         |\n",
      "|    time_elapsed         | 11113       |\n",
      "|    total_timesteps      | 1683456     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007960672 |\n",
      "|    clip_fraction        | 0.0808      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.25       |\n",
      "|    explained_variance   | 0.947       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00944     |\n",
      "|    n_updates            | 8210        |\n",
      "|    policy_gradient_loss | -0.0057     |\n",
      "|    value_loss           | 0.000921    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 823         |\n",
      "|    time_elapsed         | 11118       |\n",
      "|    total_timesteps      | 1685504     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015487161 |\n",
      "|    clip_fraction        | 0.152       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.35       |\n",
      "|    explained_variance   | 0.931       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00144    |\n",
      "|    n_updates            | 8220        |\n",
      "|    policy_gradient_loss | -0.0069     |\n",
      "|    value_loss           | 2.56e-05    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 151        |\n",
      "|    iterations           | 824        |\n",
      "|    time_elapsed         | 11124      |\n",
      "|    total_timesteps      | 1687552    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00973037 |\n",
      "|    clip_fraction        | 0.101      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.32      |\n",
      "|    explained_variance   | -0.246     |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0261    |\n",
      "|    n_updates            | 8230       |\n",
      "|    policy_gradient_loss | -0.00484   |\n",
      "|    value_loss           | 1.78e-05   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 825         |\n",
      "|    time_elapsed         | 11129       |\n",
      "|    total_timesteps      | 1689600     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012973035 |\n",
      "|    clip_fraction        | 0.156       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.31       |\n",
      "|    explained_variance   | 0.53        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00641    |\n",
      "|    n_updates            | 8240        |\n",
      "|    policy_gradient_loss | -0.0114     |\n",
      "|    value_loss           | 6.76e-06    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1690000, episode_reward=0.05 +/- 0.07\n",
      "Episode length: 10000.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1e+04      |\n",
      "|    mean_reward          | 0.0537     |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 1690000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01700779 |\n",
      "|    clip_fraction        | 0.13       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.37      |\n",
      "|    explained_variance   | 0.535      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0131    |\n",
      "|    n_updates            | 8250       |\n",
      "|    policy_gradient_loss | -0.0102    |\n",
      "|    value_loss           | 6.85e-06   |\n",
      "----------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 151     |\n",
      "|    iterations      | 826     |\n",
      "|    time_elapsed    | 11177   |\n",
      "|    total_timesteps | 1691648 |\n",
      "--------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 827         |\n",
      "|    time_elapsed         | 11183       |\n",
      "|    total_timesteps      | 1693696     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011221455 |\n",
      "|    clip_fraction        | 0.146       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.17       |\n",
      "|    explained_variance   | 0.943       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0191     |\n",
      "|    n_updates            | 8260        |\n",
      "|    policy_gradient_loss | -0.0124     |\n",
      "|    value_loss           | 0.000308    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 828         |\n",
      "|    time_elapsed         | 11188       |\n",
      "|    total_timesteps      | 1695744     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013952628 |\n",
      "|    clip_fraction        | 0.196       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.3        |\n",
      "|    explained_variance   | 0.904       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0616     |\n",
      "|    n_updates            | 8270        |\n",
      "|    policy_gradient_loss | -0.00938    |\n",
      "|    value_loss           | 1.83e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 829         |\n",
      "|    time_elapsed         | 11193       |\n",
      "|    total_timesteps      | 1697792     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010825779 |\n",
      "|    clip_fraction        | 0.172       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.36       |\n",
      "|    explained_variance   | 0.915       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0189     |\n",
      "|    n_updates            | 8280        |\n",
      "|    policy_gradient_loss | -0.0105     |\n",
      "|    value_loss           | 1.94e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 830         |\n",
      "|    time_elapsed         | 11198       |\n",
      "|    total_timesteps      | 1699840     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012256887 |\n",
      "|    clip_fraction        | 0.116       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.38       |\n",
      "|    explained_variance   | 0.949       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00735     |\n",
      "|    n_updates            | 8290        |\n",
      "|    policy_gradient_loss | -0.0084     |\n",
      "|    value_loss           | 2.7e-05     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1700000, episode_reward=0.04 +/- 0.03\n",
      "Episode length: 10000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+04       |\n",
      "|    mean_reward          | 0.0448      |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1700000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016364012 |\n",
      "|    clip_fraction        | 0.343       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.36       |\n",
      "|    explained_variance   | 0.781       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0692     |\n",
      "|    n_updates            | 8300        |\n",
      "|    policy_gradient_loss | -0.031      |\n",
      "|    value_loss           | 5.41e-05    |\n",
      "-----------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 151     |\n",
      "|    iterations      | 831     |\n",
      "|    time_elapsed    | 11246   |\n",
      "|    total_timesteps | 1701888 |\n",
      "--------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 151        |\n",
      "|    iterations           | 832        |\n",
      "|    time_elapsed         | 11251      |\n",
      "|    total_timesteps      | 1703936    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01228619 |\n",
      "|    clip_fraction        | 0.156      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.22      |\n",
      "|    explained_variance   | 0.938      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0699     |\n",
      "|    n_updates            | 8310       |\n",
      "|    policy_gradient_loss | -0.0116    |\n",
      "|    value_loss           | 0.000212   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 833         |\n",
      "|    time_elapsed         | 11257       |\n",
      "|    total_timesteps      | 1705984     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013545217 |\n",
      "|    clip_fraction        | 0.173       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.39       |\n",
      "|    explained_variance   | 0.79        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0235     |\n",
      "|    n_updates            | 8320        |\n",
      "|    policy_gradient_loss | -0.00893    |\n",
      "|    value_loss           | 9.01e-06    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 834         |\n",
      "|    time_elapsed         | 11262       |\n",
      "|    total_timesteps      | 1708032     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019389052 |\n",
      "|    clip_fraction        | 0.297       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.36       |\n",
      "|    explained_variance   | 0.0376      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0369     |\n",
      "|    n_updates            | 8330        |\n",
      "|    policy_gradient_loss | -0.0147     |\n",
      "|    value_loss           | 8.92e-06    |\n",
      "-----------------------------------------\n",
      "box reached target\n",
      "box reached target\n",
      "box reached target\n",
      "Eval num_timesteps=1710000, episode_reward=3.22 +/- 2.63\n",
      "Episode length: 4625.00 +/- 4441.36\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 4.62e+03    |\n",
      "|    mean_reward          | 3.22        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1710000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008538149 |\n",
      "|    clip_fraction        | 0.125       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.35       |\n",
      "|    explained_variance   | 0.809       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0152      |\n",
      "|    n_updates            | 8340        |\n",
      "|    policy_gradient_loss | -0.00484    |\n",
      "|    value_loss           | 1.09e-05    |\n",
      "-----------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 151     |\n",
      "|    iterations      | 835     |\n",
      "|    time_elapsed    | 11287   |\n",
      "|    total_timesteps | 1710080 |\n",
      "--------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 836         |\n",
      "|    time_elapsed         | 11292       |\n",
      "|    total_timesteps      | 1712128     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017448429 |\n",
      "|    clip_fraction        | 0.132       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.34       |\n",
      "|    explained_variance   | 0.948       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0125     |\n",
      "|    n_updates            | 8350        |\n",
      "|    policy_gradient_loss | -0.00289    |\n",
      "|    value_loss           | 0.000188    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 837         |\n",
      "|    time_elapsed         | 11298       |\n",
      "|    total_timesteps      | 1714176     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017007459 |\n",
      "|    clip_fraction        | 0.227       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.908      |\n",
      "|    explained_variance   | 0.746       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00244    |\n",
      "|    n_updates            | 8360        |\n",
      "|    policy_gradient_loss | -0.0154     |\n",
      "|    value_loss           | 0.000264    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 838         |\n",
      "|    time_elapsed         | 11303       |\n",
      "|    total_timesteps      | 1716224     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016623376 |\n",
      "|    clip_fraction        | 0.153       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.994      |\n",
      "|    explained_variance   | 0.928       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0135      |\n",
      "|    n_updates            | 8370        |\n",
      "|    policy_gradient_loss | -0.0114     |\n",
      "|    value_loss           | 0.000775    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 839         |\n",
      "|    time_elapsed         | 11309       |\n",
      "|    total_timesteps      | 1718272     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010300445 |\n",
      "|    clip_fraction        | 0.0991      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.917      |\n",
      "|    explained_variance   | 0.949       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0144     |\n",
      "|    n_updates            | 8380        |\n",
      "|    policy_gradient_loss | -0.00537    |\n",
      "|    value_loss           | 0.00027     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1720000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 10000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+04       |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1720000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011981981 |\n",
      "|    clip_fraction        | 0.157       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.952      |\n",
      "|    explained_variance   | 0.933       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0139     |\n",
      "|    n_updates            | 8390        |\n",
      "|    policy_gradient_loss | -0.0129     |\n",
      "|    value_loss           | 8.94e-06    |\n",
      "-----------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 151     |\n",
      "|    iterations      | 840     |\n",
      "|    time_elapsed    | 11356   |\n",
      "|    total_timesteps | 1720320 |\n",
      "--------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 841         |\n",
      "|    time_elapsed         | 11362       |\n",
      "|    total_timesteps      | 1722368     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027410805 |\n",
      "|    clip_fraction        | 0.21        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.99       |\n",
      "|    explained_variance   | 0.928       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0477     |\n",
      "|    n_updates            | 8400        |\n",
      "|    policy_gradient_loss | -0.0165     |\n",
      "|    value_loss           | 6.2e-05     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 842         |\n",
      "|    time_elapsed         | 11367       |\n",
      "|    total_timesteps      | 1724416     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011158684 |\n",
      "|    clip_fraction        | 0.114       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.27       |\n",
      "|    explained_variance   | 0.942       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0196     |\n",
      "|    n_updates            | 8410        |\n",
      "|    policy_gradient_loss | -0.00658    |\n",
      "|    value_loss           | 2.48e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 843         |\n",
      "|    time_elapsed         | 11373       |\n",
      "|    total_timesteps      | 1726464     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014267501 |\n",
      "|    clip_fraction        | 0.228       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.48       |\n",
      "|    explained_variance   | -0.0242     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0279     |\n",
      "|    n_updates            | 8420        |\n",
      "|    policy_gradient_loss | -0.0117     |\n",
      "|    value_loss           | 4.13e-06    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 151          |\n",
      "|    iterations           | 844          |\n",
      "|    time_elapsed         | 11378        |\n",
      "|    total_timesteps      | 1728512      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0049667154 |\n",
      "|    clip_fraction        | 0.0333       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.5         |\n",
      "|    explained_variance   | 0.821        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0115      |\n",
      "|    n_updates            | 8430         |\n",
      "|    policy_gradient_loss | -0.000292    |\n",
      "|    value_loss           | 8.72e-06     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1730000, episode_reward=0.09 +/- 0.07\n",
      "Episode length: 10000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+04       |\n",
      "|    mean_reward          | 0.0885      |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1730000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008374903 |\n",
      "|    clip_fraction        | 0.0717      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.5        |\n",
      "|    explained_variance   | 0.866       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0122      |\n",
      "|    n_updates            | 8440        |\n",
      "|    policy_gradient_loss | -0.00536    |\n",
      "|    value_loss           | 3.59e-06    |\n",
      "-----------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 151     |\n",
      "|    iterations      | 845     |\n",
      "|    time_elapsed    | 11426   |\n",
      "|    total_timesteps | 1730560 |\n",
      "--------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 846         |\n",
      "|    time_elapsed         | 11431       |\n",
      "|    total_timesteps      | 1732608     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012940021 |\n",
      "|    clip_fraction        | 0.0979      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.43       |\n",
      "|    explained_variance   | 0.955       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00948     |\n",
      "|    n_updates            | 8450        |\n",
      "|    policy_gradient_loss | -0.00726    |\n",
      "|    value_loss           | 0.000205    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 847         |\n",
      "|    time_elapsed         | 11437       |\n",
      "|    total_timesteps      | 1734656     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016527757 |\n",
      "|    clip_fraction        | 0.149       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.19       |\n",
      "|    explained_variance   | 0.918       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0325     |\n",
      "|    n_updates            | 8460        |\n",
      "|    policy_gradient_loss | -0.00837    |\n",
      "|    value_loss           | 9.67e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 848         |\n",
      "|    time_elapsed         | 11442       |\n",
      "|    total_timesteps      | 1736704     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016128998 |\n",
      "|    clip_fraction        | 0.277       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.13       |\n",
      "|    explained_variance   | 0.0236      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0518     |\n",
      "|    n_updates            | 8470        |\n",
      "|    policy_gradient_loss | -0.0183     |\n",
      "|    value_loss           | 4e-05       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 151          |\n",
      "|    iterations           | 849          |\n",
      "|    time_elapsed         | 11448        |\n",
      "|    total_timesteps      | 1738752      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064421585 |\n",
      "|    clip_fraction        | 0.111        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.21        |\n",
      "|    explained_variance   | 0.181        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0143      |\n",
      "|    n_updates            | 8480         |\n",
      "|    policy_gradient_loss | -0.00745     |\n",
      "|    value_loss           | 5.85e-05     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1740000, episode_reward=0.04 +/- 0.05\n",
      "Episode length: 10000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+04       |\n",
      "|    mean_reward          | 0.0427      |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1740000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015157104 |\n",
      "|    clip_fraction        | 0.223       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.29       |\n",
      "|    explained_variance   | 0.0665      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0265     |\n",
      "|    n_updates            | 8490        |\n",
      "|    policy_gradient_loss | -0.00757    |\n",
      "|    value_loss           | 4.08e-05    |\n",
      "-----------------------------------------\n",
      "box reached target\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 151     |\n",
      "|    iterations      | 850     |\n",
      "|    time_elapsed    | 11496   |\n",
      "|    total_timesteps | 1740800 |\n",
      "--------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 851         |\n",
      "|    time_elapsed         | 11502       |\n",
      "|    total_timesteps      | 1742848     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010423541 |\n",
      "|    clip_fraction        | 0.0973      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.18       |\n",
      "|    explained_variance   | 0.899       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.048       |\n",
      "|    n_updates            | 8500        |\n",
      "|    policy_gradient_loss | -0.00135    |\n",
      "|    value_loss           | 0.00737     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 151          |\n",
      "|    iterations           | 852          |\n",
      "|    time_elapsed         | 11507        |\n",
      "|    total_timesteps      | 1744896      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0066629075 |\n",
      "|    clip_fraction        | 0.11         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.3         |\n",
      "|    explained_variance   | 0.941        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0285      |\n",
      "|    n_updates            | 8510         |\n",
      "|    policy_gradient_loss | -0.0096      |\n",
      "|    value_loss           | 0.000775     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 853         |\n",
      "|    time_elapsed         | 11513       |\n",
      "|    total_timesteps      | 1746944     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007549402 |\n",
      "|    clip_fraction        | 0.0902      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.44       |\n",
      "|    explained_variance   | 0.865       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00325    |\n",
      "|    n_updates            | 8520        |\n",
      "|    policy_gradient_loss | -0.00276    |\n",
      "|    value_loss           | 5.13e-05    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 151          |\n",
      "|    iterations           | 854          |\n",
      "|    time_elapsed         | 11518        |\n",
      "|    total_timesteps      | 1748992      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0134368315 |\n",
      "|    clip_fraction        | 0.143        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.48        |\n",
      "|    explained_variance   | 0.743        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0194      |\n",
      "|    n_updates            | 8530         |\n",
      "|    policy_gradient_loss | -0.00503     |\n",
      "|    value_loss           | 3.3e-05      |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=1750000, episode_reward=0.07 +/- 0.16\n",
      "Episode length: 10000.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1e+04      |\n",
      "|    mean_reward          | 0.072      |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 1750000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01689177 |\n",
      "|    clip_fraction        | 0.243      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.44      |\n",
      "|    explained_variance   | -0.0115    |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0182    |\n",
      "|    n_updates            | 8540       |\n",
      "|    policy_gradient_loss | -0.00931   |\n",
      "|    value_loss           | 2.71e-05   |\n",
      "----------------------------------------\n",
      "box reached target\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 151     |\n",
      "|    iterations      | 855     |\n",
      "|    time_elapsed    | 11566   |\n",
      "|    total_timesteps | 1751040 |\n",
      "--------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 856         |\n",
      "|    time_elapsed         | 11572       |\n",
      "|    total_timesteps      | 1753088     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013053557 |\n",
      "|    clip_fraction        | 0.112       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.18       |\n",
      "|    explained_variance   | 0.978       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00624    |\n",
      "|    n_updates            | 8550        |\n",
      "|    policy_gradient_loss | -0.00862    |\n",
      "|    value_loss           | 0.00392     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 857         |\n",
      "|    time_elapsed         | 11577       |\n",
      "|    total_timesteps      | 1755136     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015233127 |\n",
      "|    clip_fraction        | 0.134       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.32       |\n",
      "|    explained_variance   | 0.949       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00588    |\n",
      "|    n_updates            | 8560        |\n",
      "|    policy_gradient_loss | -0.00943    |\n",
      "|    value_loss           | 0.000361    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 858         |\n",
      "|    time_elapsed         | 11583       |\n",
      "|    total_timesteps      | 1757184     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020195682 |\n",
      "|    clip_fraction        | 0.374       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.23       |\n",
      "|    explained_variance   | 0.921       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0164     |\n",
      "|    n_updates            | 8570        |\n",
      "|    policy_gradient_loss | -0.0218     |\n",
      "|    value_loss           | 8.51e-06    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 859         |\n",
      "|    time_elapsed         | 11588       |\n",
      "|    total_timesteps      | 1759232     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015549625 |\n",
      "|    clip_fraction        | 0.222       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.36       |\n",
      "|    explained_variance   | 0.943       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0116     |\n",
      "|    n_updates            | 8580        |\n",
      "|    policy_gradient_loss | -0.01       |\n",
      "|    value_loss           | 7.01e-06    |\n",
      "-----------------------------------------\n",
      "box reached target\n",
      "Eval num_timesteps=1760000, episode_reward=1.22 +/- 1.97\n",
      "Episode length: 8096.20 +/- 3807.60\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 8.1e+03     |\n",
      "|    mean_reward          | 1.22        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1760000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006150526 |\n",
      "|    clip_fraction        | 0.0784      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.41       |\n",
      "|    explained_variance   | 0.938       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0123     |\n",
      "|    n_updates            | 8590        |\n",
      "|    policy_gradient_loss | -0.00467    |\n",
      "|    value_loss           | 8.85e-06    |\n",
      "-----------------------------------------\n",
      "box reached target\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 151     |\n",
      "|    iterations      | 860     |\n",
      "|    time_elapsed    | 11628   |\n",
      "|    total_timesteps | 1761280 |\n",
      "--------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 151       |\n",
      "|    iterations           | 861       |\n",
      "|    time_elapsed         | 11633     |\n",
      "|    total_timesteps      | 1763328   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0134895 |\n",
      "|    clip_fraction        | 0.199     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -1.2      |\n",
      "|    explained_variance   | 0.771     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -0.0186   |\n",
      "|    n_updates            | 8600      |\n",
      "|    policy_gradient_loss | -0.00877  |\n",
      "|    value_loss           | 0.0487    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 862         |\n",
      "|    time_elapsed         | 11639       |\n",
      "|    total_timesteps      | 1765376     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023430597 |\n",
      "|    clip_fraction        | 0.232       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.29       |\n",
      "|    explained_variance   | 0.935       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0237     |\n",
      "|    n_updates            | 8610        |\n",
      "|    policy_gradient_loss | -0.0134     |\n",
      "|    value_loss           | 0.000322    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 863         |\n",
      "|    time_elapsed         | 11644       |\n",
      "|    total_timesteps      | 1767424     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017827364 |\n",
      "|    clip_fraction        | 0.37        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.43       |\n",
      "|    explained_variance   | -0.0443     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0439     |\n",
      "|    n_updates            | 8620        |\n",
      "|    policy_gradient_loss | -0.0206     |\n",
      "|    value_loss           | 6.91e-05    |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 151       |\n",
      "|    iterations           | 864       |\n",
      "|    time_elapsed         | 11650     |\n",
      "|    total_timesteps      | 1769472   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0222474 |\n",
      "|    clip_fraction        | 0.453     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -1.34     |\n",
      "|    explained_variance   | -3.75     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -0.0651   |\n",
      "|    n_updates            | 8630      |\n",
      "|    policy_gradient_loss | -0.0264   |\n",
      "|    value_loss           | 3.44e-05  |\n",
      "---------------------------------------\n",
      "Eval num_timesteps=1770000, episode_reward=-0.04 +/- 0.08\n",
      "Episode length: 10000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+04       |\n",
      "|    mean_reward          | -0.0383     |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1770000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027493047 |\n",
      "|    clip_fraction        | 0.406       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.32       |\n",
      "|    explained_variance   | -0.922      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0289     |\n",
      "|    n_updates            | 8640        |\n",
      "|    policy_gradient_loss | -0.0286     |\n",
      "|    value_loss           | 2.34e-05    |\n",
      "-----------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 151     |\n",
      "|    iterations      | 865     |\n",
      "|    time_elapsed    | 11698   |\n",
      "|    total_timesteps | 1771520 |\n",
      "--------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 866         |\n",
      "|    time_elapsed         | 11703       |\n",
      "|    total_timesteps      | 1773568     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018841404 |\n",
      "|    clip_fraction        | 0.224       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.28       |\n",
      "|    explained_variance   | 0.866       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0179     |\n",
      "|    n_updates            | 8650        |\n",
      "|    policy_gradient_loss | -0.0145     |\n",
      "|    value_loss           | 0.00204     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 867         |\n",
      "|    time_elapsed         | 11708       |\n",
      "|    total_timesteps      | 1775616     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013119733 |\n",
      "|    clip_fraction        | 0.203       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.3        |\n",
      "|    explained_variance   | 0.917       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0243     |\n",
      "|    n_updates            | 8660        |\n",
      "|    policy_gradient_loss | -0.0115     |\n",
      "|    value_loss           | 9.21e-06    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 151          |\n",
      "|    iterations           | 868          |\n",
      "|    time_elapsed         | 11714        |\n",
      "|    total_timesteps      | 1777664      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0077461847 |\n",
      "|    clip_fraction        | 0.12         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.28        |\n",
      "|    explained_variance   | 0.901        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0118      |\n",
      "|    n_updates            | 8670         |\n",
      "|    policy_gradient_loss | -0.00764     |\n",
      "|    value_loss           | 2.12e-06     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 869         |\n",
      "|    time_elapsed         | 11720       |\n",
      "|    total_timesteps      | 1779712     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011846153 |\n",
      "|    clip_fraction        | 0.0966      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.28       |\n",
      "|    explained_variance   | 0.898       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0145     |\n",
      "|    n_updates            | 8680        |\n",
      "|    policy_gradient_loss | -0.00757    |\n",
      "|    value_loss           | 9.01e-07    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1780000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 10000.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1e+04      |\n",
      "|    mean_reward          | 0          |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 1780000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01213016 |\n",
      "|    clip_fraction        | 0.186      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.15      |\n",
      "|    explained_variance   | -5.25      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0289    |\n",
      "|    n_updates            | 8690       |\n",
      "|    policy_gradient_loss | -0.00943   |\n",
      "|    value_loss           | 1.95e-07   |\n",
      "----------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 151     |\n",
      "|    iterations      | 870     |\n",
      "|    time_elapsed    | 11767   |\n",
      "|    total_timesteps | 1781760 |\n",
      "--------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 871         |\n",
      "|    time_elapsed         | 11773       |\n",
      "|    total_timesteps      | 1783808     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.048525494 |\n",
      "|    clip_fraction        | 0.146       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.864      |\n",
      "|    explained_variance   | 0.952       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0794     |\n",
      "|    n_updates            | 8700        |\n",
      "|    policy_gradient_loss | -0.0129     |\n",
      "|    value_loss           | 0.000808    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 872         |\n",
      "|    time_elapsed         | 11778       |\n",
      "|    total_timesteps      | 1785856     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025586184 |\n",
      "|    clip_fraction        | 0.352       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.22       |\n",
      "|    explained_variance   | 0.542       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0246      |\n",
      "|    n_updates            | 8710        |\n",
      "|    policy_gradient_loss | -0.0211     |\n",
      "|    value_loss           | 5.56e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 873         |\n",
      "|    time_elapsed         | 11784       |\n",
      "|    total_timesteps      | 1787904     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022975266 |\n",
      "|    clip_fraction        | 0.158       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.33       |\n",
      "|    explained_variance   | 0.147       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00802    |\n",
      "|    n_updates            | 8720        |\n",
      "|    policy_gradient_loss | -0.00607    |\n",
      "|    value_loss           | 5.8e-05     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 874         |\n",
      "|    time_elapsed         | 11789       |\n",
      "|    total_timesteps      | 1789952     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019188438 |\n",
      "|    clip_fraction        | 0.292       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.33       |\n",
      "|    explained_variance   | -1.17       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00451     |\n",
      "|    n_updates            | 8730        |\n",
      "|    policy_gradient_loss | -0.00816    |\n",
      "|    value_loss           | 2.15e-05    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1790000, episode_reward=0.05 +/- 0.09\n",
      "Episode length: 10000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+04       |\n",
      "|    mean_reward          | 0.0474      |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1790000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019474532 |\n",
      "|    clip_fraction        | 0.289       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.34       |\n",
      "|    explained_variance   | -0.394      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00192    |\n",
      "|    n_updates            | 8740        |\n",
      "|    policy_gradient_loss | -0.0138     |\n",
      "|    value_loss           | 2.55e-05    |\n",
      "-----------------------------------------\n",
      "box reached target\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 151     |\n",
      "|    iterations      | 875     |\n",
      "|    time_elapsed    | 11837   |\n",
      "|    total_timesteps | 1792000 |\n",
      "--------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 151        |\n",
      "|    iterations           | 876        |\n",
      "|    time_elapsed         | 11842      |\n",
      "|    total_timesteps      | 1794048    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01503575 |\n",
      "|    clip_fraction        | 0.0673     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.697     |\n",
      "|    explained_variance   | 0.518      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0578     |\n",
      "|    n_updates            | 8750       |\n",
      "|    policy_gradient_loss | -0.00978   |\n",
      "|    value_loss           | 0.0185     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 151        |\n",
      "|    iterations           | 877        |\n",
      "|    time_elapsed         | 11848      |\n",
      "|    total_timesteps      | 1796096    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.07095831 |\n",
      "|    clip_fraction        | 0.341      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.854     |\n",
      "|    explained_variance   | 0.924      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.11      |\n",
      "|    n_updates            | 8760       |\n",
      "|    policy_gradient_loss | -0.0224    |\n",
      "|    value_loss           | 8.07e-05   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 878         |\n",
      "|    time_elapsed         | 11853       |\n",
      "|    total_timesteps      | 1798144     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007562221 |\n",
      "|    clip_fraction        | 0.0762      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.875      |\n",
      "|    explained_variance   | 0.906       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0223      |\n",
      "|    n_updates            | 8770        |\n",
      "|    policy_gradient_loss | -0.00289    |\n",
      "|    value_loss           | 2.51e-07    |\n",
      "-----------------------------------------\n",
      "box reached target\n",
      "Eval num_timesteps=1800000, episode_reward=1.11 +/- 1.98\n",
      "Episode length: 8013.60 +/- 3972.80\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 8.01e+03     |\n",
      "|    mean_reward          | 1.11         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1800000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0044981115 |\n",
      "|    clip_fraction        | 0.075        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.915       |\n",
      "|    explained_variance   | 0.941        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0436      |\n",
      "|    n_updates            | 8780         |\n",
      "|    policy_gradient_loss | -0.0068      |\n",
      "|    value_loss           | 5e-07        |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 151     |\n",
      "|    iterations      | 879     |\n",
      "|    time_elapsed    | 11893   |\n",
      "|    total_timesteps | 1800192 |\n",
      "--------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 151        |\n",
      "|    iterations           | 880        |\n",
      "|    time_elapsed         | 11899      |\n",
      "|    total_timesteps      | 1802240    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00927686 |\n",
      "|    clip_fraction        | 0.1        |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.951     |\n",
      "|    explained_variance   | 0.0494     |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0366    |\n",
      "|    n_updates            | 8790       |\n",
      "|    policy_gradient_loss | -0.0164    |\n",
      "|    value_loss           | 3.05e-05   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 881         |\n",
      "|    time_elapsed         | 11904       |\n",
      "|    total_timesteps      | 1804288     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013926769 |\n",
      "|    clip_fraction        | 0.073       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.05       |\n",
      "|    explained_variance   | 0.886       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0351     |\n",
      "|    n_updates            | 8800        |\n",
      "|    policy_gradient_loss | -0.00167    |\n",
      "|    value_loss           | 0.000238    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 882         |\n",
      "|    time_elapsed         | 11910       |\n",
      "|    total_timesteps      | 1806336     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.045721002 |\n",
      "|    clip_fraction        | 0.458       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.21       |\n",
      "|    explained_variance   | 0.705       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0765     |\n",
      "|    n_updates            | 8810        |\n",
      "|    policy_gradient_loss | -0.0189     |\n",
      "|    value_loss           | 3.25e-06    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 151        |\n",
      "|    iterations           | 883        |\n",
      "|    time_elapsed         | 11915      |\n",
      "|    total_timesteps      | 1808384    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01500858 |\n",
      "|    clip_fraction        | 0.17       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.35      |\n",
      "|    explained_variance   | 0.803      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.00789    |\n",
      "|    n_updates            | 8820       |\n",
      "|    policy_gradient_loss | -0.0108    |\n",
      "|    value_loss           | 4.6e-06    |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=1810000, episode_reward=0.02 +/- 0.05\n",
      "Episode length: 10000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+04       |\n",
      "|    mean_reward          | 0.0237      |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1810000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016228948 |\n",
      "|    clip_fraction        | 0.226       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.36       |\n",
      "|    explained_variance   | 0.903       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0189     |\n",
      "|    n_updates            | 8830        |\n",
      "|    policy_gradient_loss | -0.0135     |\n",
      "|    value_loss           | 2.07e-06    |\n",
      "-----------------------------------------\n",
      "box reached target\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 151     |\n",
      "|    iterations      | 884     |\n",
      "|    time_elapsed    | 11963   |\n",
      "|    total_timesteps | 1810432 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 151          |\n",
      "|    iterations           | 885          |\n",
      "|    time_elapsed         | 11968        |\n",
      "|    total_timesteps      | 1812480      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073703662 |\n",
      "|    clip_fraction        | 0.05         |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.26        |\n",
      "|    explained_variance   | 0.654        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0197      |\n",
      "|    n_updates            | 8840         |\n",
      "|    policy_gradient_loss | -0.00442     |\n",
      "|    value_loss           | 0.00313      |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 151        |\n",
      "|    iterations           | 886        |\n",
      "|    time_elapsed         | 11974      |\n",
      "|    total_timesteps      | 1814528    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01726274 |\n",
      "|    clip_fraction        | 0.136      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.14      |\n",
      "|    explained_variance   | 0.921      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0292    |\n",
      "|    n_updates            | 8850       |\n",
      "|    policy_gradient_loss | -0.0124    |\n",
      "|    value_loss           | 0.000204   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 887         |\n",
      "|    time_elapsed         | 11979       |\n",
      "|    total_timesteps      | 1816576     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016048715 |\n",
      "|    clip_fraction        | 0.221       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.29       |\n",
      "|    explained_variance   | -0.225      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00112     |\n",
      "|    n_updates            | 8860        |\n",
      "|    policy_gradient_loss | -0.0134     |\n",
      "|    value_loss           | 5.32e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 888         |\n",
      "|    time_elapsed         | 11984       |\n",
      "|    total_timesteps      | 1818624     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018779935 |\n",
      "|    clip_fraction        | 0.207       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.16       |\n",
      "|    explained_variance   | 0.555       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0131      |\n",
      "|    n_updates            | 8870        |\n",
      "|    policy_gradient_loss | -0.00871    |\n",
      "|    value_loss           | 2.48e-05    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1820000, episode_reward=0.02 +/- 0.04\n",
      "Episode length: 10000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+04       |\n",
      "|    mean_reward          | 0.0198      |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1820000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015995886 |\n",
      "|    clip_fraction        | 0.225       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.07       |\n",
      "|    explained_variance   | 0.675       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00339    |\n",
      "|    n_updates            | 8880        |\n",
      "|    policy_gradient_loss | -0.00773    |\n",
      "|    value_loss           | 1.79e-05    |\n",
      "-----------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 151     |\n",
      "|    iterations      | 889     |\n",
      "|    time_elapsed    | 12033   |\n",
      "|    total_timesteps | 1820672 |\n",
      "--------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 151        |\n",
      "|    iterations           | 890        |\n",
      "|    time_elapsed         | 12038      |\n",
      "|    total_timesteps      | 1822720    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06090694 |\n",
      "|    clip_fraction        | 0.214      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.15      |\n",
      "|    explained_variance   | 0.909      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0698    |\n",
      "|    n_updates            | 8890       |\n",
      "|    policy_gradient_loss | -0.00557   |\n",
      "|    value_loss           | 0.00137    |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 151        |\n",
      "|    iterations           | 891        |\n",
      "|    time_elapsed         | 12044      |\n",
      "|    total_timesteps      | 1824768    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01015192 |\n",
      "|    clip_fraction        | 0.132      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.22      |\n",
      "|    explained_variance   | 0.941      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0232    |\n",
      "|    n_updates            | 8900       |\n",
      "|    policy_gradient_loss | -0.00484   |\n",
      "|    value_loss           | 1.74e-05   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 892         |\n",
      "|    time_elapsed         | 12049       |\n",
      "|    total_timesteps      | 1826816     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020256396 |\n",
      "|    clip_fraction        | 0.168       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.3        |\n",
      "|    explained_variance   | 0.886       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00889     |\n",
      "|    n_updates            | 8910        |\n",
      "|    policy_gradient_loss | -0.0112     |\n",
      "|    value_loss           | 5.3e-06     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 893         |\n",
      "|    time_elapsed         | 12055       |\n",
      "|    total_timesteps      | 1828864     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020128256 |\n",
      "|    clip_fraction        | 0.276       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.27       |\n",
      "|    explained_variance   | 0.545       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0508     |\n",
      "|    n_updates            | 8920        |\n",
      "|    policy_gradient_loss | -0.0122     |\n",
      "|    value_loss           | 2.11e-06    |\n",
      "-----------------------------------------\n",
      "box reached target\n",
      "box reached target\n",
      "Eval num_timesteps=1830000, episode_reward=2.05 +/- 2.52\n",
      "Episode length: 6107.80 +/- 4767.60\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 6.11e+03    |\n",
      "|    mean_reward          | 2.05        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1830000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006892686 |\n",
      "|    clip_fraction        | 0.105       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.3        |\n",
      "|    explained_variance   | 0.902       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0167     |\n",
      "|    n_updates            | 8930        |\n",
      "|    policy_gradient_loss | -0.00599    |\n",
      "|    value_loss           | 1.62e-06    |\n",
      "-----------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 151     |\n",
      "|    iterations      | 894     |\n",
      "|    time_elapsed    | 12088   |\n",
      "|    total_timesteps | 1830912 |\n",
      "--------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 151        |\n",
      "|    iterations           | 895        |\n",
      "|    time_elapsed         | 12093      |\n",
      "|    total_timesteps      | 1832960    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04779374 |\n",
      "|    clip_fraction        | 0.252      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.15      |\n",
      "|    explained_variance   | 0.957      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0989    |\n",
      "|    n_updates            | 8940       |\n",
      "|    policy_gradient_loss | -0.0296    |\n",
      "|    value_loss           | 0.000289   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 896         |\n",
      "|    time_elapsed         | 12099       |\n",
      "|    total_timesteps      | 1835008     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013859751 |\n",
      "|    clip_fraction        | 0.115       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.28       |\n",
      "|    explained_variance   | 0.936       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0124     |\n",
      "|    n_updates            | 8950        |\n",
      "|    policy_gradient_loss | -0.00686    |\n",
      "|    value_loss           | 4.48e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 897         |\n",
      "|    time_elapsed         | 12104       |\n",
      "|    total_timesteps      | 1837056     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012659551 |\n",
      "|    clip_fraction        | 0.175       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.15       |\n",
      "|    explained_variance   | 0.278       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00546     |\n",
      "|    n_updates            | 8960        |\n",
      "|    policy_gradient_loss | -0.00805    |\n",
      "|    value_loss           | 1.94e-06    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 898         |\n",
      "|    time_elapsed         | 12110       |\n",
      "|    total_timesteps      | 1839104     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008604143 |\n",
      "|    clip_fraction        | 0.0947      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.984      |\n",
      "|    explained_variance   | 0.112       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0157      |\n",
      "|    n_updates            | 8970        |\n",
      "|    policy_gradient_loss | -0.00279    |\n",
      "|    value_loss           | 1.69e-05    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1840000, episode_reward=0.11 +/- 0.21\n",
      "Episode length: 10000.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1e+04        |\n",
      "|    mean_reward          | 0.11         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1840000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0071530943 |\n",
      "|    clip_fraction        | 0.112        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.846       |\n",
      "|    explained_variance   | -0.124       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0325       |\n",
      "|    n_updates            | 8980         |\n",
      "|    policy_gradient_loss | -0.00166     |\n",
      "|    value_loss           | 6.18e-07     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 151     |\n",
      "|    iterations      | 899     |\n",
      "|    time_elapsed    | 12158   |\n",
      "|    total_timesteps | 1841152 |\n",
      "--------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 900         |\n",
      "|    time_elapsed         | 12164       |\n",
      "|    total_timesteps      | 1843200     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010017625 |\n",
      "|    clip_fraction        | 0.0702      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.882      |\n",
      "|    explained_variance   | 0.897       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0146     |\n",
      "|    n_updates            | 8990        |\n",
      "|    policy_gradient_loss | -0.00254    |\n",
      "|    value_loss           | 0.000545    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 901         |\n",
      "|    time_elapsed         | 12169       |\n",
      "|    total_timesteps      | 1845248     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008844178 |\n",
      "|    clip_fraction        | 0.093       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.29       |\n",
      "|    explained_variance   | 0.514       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00283     |\n",
      "|    n_updates            | 9000        |\n",
      "|    policy_gradient_loss | -0.000442   |\n",
      "|    value_loss           | 2.37e-05    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 151          |\n",
      "|    iterations           | 902          |\n",
      "|    time_elapsed         | 12175        |\n",
      "|    total_timesteps      | 1847296      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0150333475 |\n",
      "|    clip_fraction        | 0.168        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.22        |\n",
      "|    explained_variance   | 0.37         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0303      |\n",
      "|    n_updates            | 9010         |\n",
      "|    policy_gradient_loss | -0.00623     |\n",
      "|    value_loss           | 3.84e-05     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 903         |\n",
      "|    time_elapsed         | 12180       |\n",
      "|    total_timesteps      | 1849344     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010618374 |\n",
      "|    clip_fraction        | 0.111       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.26       |\n",
      "|    explained_variance   | 0.858       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00994    |\n",
      "|    n_updates            | 9020        |\n",
      "|    policy_gradient_loss | -0.00556    |\n",
      "|    value_loss           | 1.39e-05    |\n",
      "-----------------------------------------\n",
      "box reached target\n",
      "Eval num_timesteps=1850000, episode_reward=1.02 +/- 2.05\n",
      "Episode length: 8083.80 +/- 3832.40\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 8.08e+03    |\n",
      "|    mean_reward          | 1.02        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1850000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009163643 |\n",
      "|    clip_fraction        | 0.132       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.22       |\n",
      "|    explained_variance   | 0.781       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0153      |\n",
      "|    n_updates            | 9030        |\n",
      "|    policy_gradient_loss | -0.00796    |\n",
      "|    value_loss           | 6.65e-06    |\n",
      "-----------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 151     |\n",
      "|    iterations      | 904     |\n",
      "|    time_elapsed    | 12220   |\n",
      "|    total_timesteps | 1851392 |\n",
      "--------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 905         |\n",
      "|    time_elapsed         | 12226       |\n",
      "|    total_timesteps      | 1853440     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011279962 |\n",
      "|    clip_fraction        | 0.138       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.18       |\n",
      "|    explained_variance   | 0.928       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0148      |\n",
      "|    n_updates            | 9040        |\n",
      "|    policy_gradient_loss | -0.0131     |\n",
      "|    value_loss           | 0.00018     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 906         |\n",
      "|    time_elapsed         | 12231       |\n",
      "|    total_timesteps      | 1855488     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017995391 |\n",
      "|    clip_fraction        | 0.302       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.27       |\n",
      "|    explained_variance   | 0.509       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0379     |\n",
      "|    n_updates            | 9050        |\n",
      "|    policy_gradient_loss | -0.0224     |\n",
      "|    value_loss           | 5.42e-06    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 151        |\n",
      "|    iterations           | 907        |\n",
      "|    time_elapsed         | 12237      |\n",
      "|    total_timesteps      | 1857536    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03342372 |\n",
      "|    clip_fraction        | 0.31       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.24      |\n",
      "|    explained_variance   | 0.0683     |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0542    |\n",
      "|    n_updates            | 9060       |\n",
      "|    policy_gradient_loss | -0.0165    |\n",
      "|    value_loss           | 5.22e-06   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 908         |\n",
      "|    time_elapsed         | 12242       |\n",
      "|    total_timesteps      | 1859584     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022692114 |\n",
      "|    clip_fraction        | 0.334       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.29       |\n",
      "|    explained_variance   | 0.756       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0375     |\n",
      "|    n_updates            | 9070        |\n",
      "|    policy_gradient_loss | -0.0172     |\n",
      "|    value_loss           | 2.87e-06    |\n",
      "-----------------------------------------\n",
      "box reached target\n",
      "Eval num_timesteps=1860000, episode_reward=1.06 +/- 2.02\n",
      "Episode length: 8052.60 +/- 3894.80\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 8.05e+03    |\n",
      "|    mean_reward          | 1.06        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1860000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007522596 |\n",
      "|    clip_fraction        | 0.102       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.3        |\n",
      "|    explained_variance   | 0.913       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00661     |\n",
      "|    n_updates            | 9080        |\n",
      "|    policy_gradient_loss | -0.00765    |\n",
      "|    value_loss           | 3.62e-06    |\n",
      "-----------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 151     |\n",
      "|    iterations      | 909     |\n",
      "|    time_elapsed    | 12282   |\n",
      "|    total_timesteps | 1861632 |\n",
      "--------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 151        |\n",
      "|    iterations           | 910        |\n",
      "|    time_elapsed         | 12288      |\n",
      "|    total_timesteps      | 1863680    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02295269 |\n",
      "|    clip_fraction        | 0.138      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.04      |\n",
      "|    explained_variance   | 0.941      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0255    |\n",
      "|    n_updates            | 9090       |\n",
      "|    policy_gradient_loss | -0.00927   |\n",
      "|    value_loss           | 0.000236   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 911         |\n",
      "|    time_elapsed         | 12293       |\n",
      "|    total_timesteps      | 1865728     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025051206 |\n",
      "|    clip_fraction        | 0.171       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.15       |\n",
      "|    explained_variance   | 0.941       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0424     |\n",
      "|    n_updates            | 9100        |\n",
      "|    policy_gradient_loss | -0.0175     |\n",
      "|    value_loss           | 0.000782    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 912         |\n",
      "|    time_elapsed         | 12299       |\n",
      "|    total_timesteps      | 1867776     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008913089 |\n",
      "|    clip_fraction        | 0.139       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.27       |\n",
      "|    explained_variance   | 0.935       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0214     |\n",
      "|    n_updates            | 9110        |\n",
      "|    policy_gradient_loss | -0.00845    |\n",
      "|    value_loss           | 0.000699    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 913         |\n",
      "|    time_elapsed         | 12305       |\n",
      "|    total_timesteps      | 1869824     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022402778 |\n",
      "|    clip_fraction        | 0.258       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.19       |\n",
      "|    explained_variance   | 0.942       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.036      |\n",
      "|    n_updates            | 9120        |\n",
      "|    policy_gradient_loss | -0.0187     |\n",
      "|    value_loss           | 0.0003      |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1870000, episode_reward=0.02 +/- 0.05\n",
      "Episode length: 10000.00 +/- 0.00\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 1e+04        |\n",
      "|    mean_reward          | 0.0235       |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1870000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061536115 |\n",
      "|    clip_fraction        | 0.0981       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.3         |\n",
      "|    explained_variance   | 0.888        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0203      |\n",
      "|    n_updates            | 9130         |\n",
      "|    policy_gradient_loss | -0.00542     |\n",
      "|    value_loss           | 0.00105      |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 151     |\n",
      "|    iterations      | 914     |\n",
      "|    time_elapsed    | 12353   |\n",
      "|    total_timesteps | 1871872 |\n",
      "--------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 915         |\n",
      "|    time_elapsed         | 12359       |\n",
      "|    total_timesteps      | 1873920     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018921452 |\n",
      "|    clip_fraction        | 0.162       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.11       |\n",
      "|    explained_variance   | 0.862       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00547    |\n",
      "|    n_updates            | 9140        |\n",
      "|    policy_gradient_loss | -0.0101     |\n",
      "|    value_loss           | 0.00317     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 916         |\n",
      "|    time_elapsed         | 12364       |\n",
      "|    total_timesteps      | 1875968     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008009531 |\n",
      "|    clip_fraction        | 0.0918      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.899      |\n",
      "|    explained_variance   | 0.924       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.026      |\n",
      "|    n_updates            | 9150        |\n",
      "|    policy_gradient_loss | -0.00817    |\n",
      "|    value_loss           | 9.68e-07    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 151          |\n",
      "|    iterations           | 917          |\n",
      "|    time_elapsed         | 12370        |\n",
      "|    total_timesteps      | 1878016      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0044992077 |\n",
      "|    clip_fraction        | 0.0802       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.548       |\n",
      "|    explained_variance   | 0.437        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.00865     |\n",
      "|    n_updates            | 9160         |\n",
      "|    policy_gradient_loss | -0.0015      |\n",
      "|    value_loss           | 1.17e-06     |\n",
      "------------------------------------------\n",
      "box reached target\n",
      "Eval num_timesteps=1880000, episode_reward=1.02 +/- 2.05\n",
      "Episode length: 8051.40 +/- 3897.20\n",
      "------------------------------------------\n",
      "| eval/                   |              |\n",
      "|    mean_ep_length       | 8.05e+03     |\n",
      "|    mean_reward          | 1.02         |\n",
      "| time/                   |              |\n",
      "|    total_timesteps      | 1880000      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0019329702 |\n",
      "|    clip_fraction        | 0.0328       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.538       |\n",
      "|    explained_variance   | 0.451        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.00158     |\n",
      "|    n_updates            | 9170         |\n",
      "|    policy_gradient_loss | -0.00258     |\n",
      "|    value_loss           | 6.46e-07     |\n",
      "------------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 151     |\n",
      "|    iterations      | 918     |\n",
      "|    time_elapsed    | 12410   |\n",
      "|    total_timesteps | 1880064 |\n",
      "--------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 151        |\n",
      "|    iterations           | 919        |\n",
      "|    time_elapsed         | 12416      |\n",
      "|    total_timesteps      | 1882112    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.09078722 |\n",
      "|    clip_fraction        | 0.301      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.887     |\n",
      "|    explained_variance   | 0.609      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.00628   |\n",
      "|    n_updates            | 9180       |\n",
      "|    policy_gradient_loss | -0.00513   |\n",
      "|    value_loss           | 8.65e-06   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 920         |\n",
      "|    time_elapsed         | 12421       |\n",
      "|    total_timesteps      | 1884160     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010165782 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.15       |\n",
      "|    explained_variance   | 0.657       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00569    |\n",
      "|    n_updates            | 9190        |\n",
      "|    policy_gradient_loss | -0.00412    |\n",
      "|    value_loss           | 0.000999    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 921         |\n",
      "|    time_elapsed         | 12427       |\n",
      "|    total_timesteps      | 1886208     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015533901 |\n",
      "|    clip_fraction        | 0.252       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.37       |\n",
      "|    explained_variance   | -0.301      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00858    |\n",
      "|    n_updates            | 9200        |\n",
      "|    policy_gradient_loss | -0.0123     |\n",
      "|    value_loss           | 1.04e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 922         |\n",
      "|    time_elapsed         | 12433       |\n",
      "|    total_timesteps      | 1888256     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017529417 |\n",
      "|    clip_fraction        | 0.205       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.39       |\n",
      "|    explained_variance   | -0.544      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0194     |\n",
      "|    n_updates            | 9210        |\n",
      "|    policy_gradient_loss | -0.0136     |\n",
      "|    value_loss           | 4.2e-06     |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1890000, episode_reward=0.04 +/- 0.04\n",
      "Episode length: 10000.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1e+04      |\n",
      "|    mean_reward          | 0.0392     |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 1890000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01370826 |\n",
      "|    clip_fraction        | 0.186      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.34      |\n",
      "|    explained_variance   | 0.93       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -8.78e-05  |\n",
      "|    n_updates            | 9220       |\n",
      "|    policy_gradient_loss | -0.0211    |\n",
      "|    value_loss           | 4.38e-05   |\n",
      "----------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 151     |\n",
      "|    iterations      | 923     |\n",
      "|    time_elapsed    | 12481   |\n",
      "|    total_timesteps | 1890304 |\n",
      "--------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 924         |\n",
      "|    time_elapsed         | 12487       |\n",
      "|    total_timesteps      | 1892352     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021914095 |\n",
      "|    clip_fraction        | 0.219       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.17       |\n",
      "|    explained_variance   | 0.901       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.04       |\n",
      "|    n_updates            | 9230        |\n",
      "|    policy_gradient_loss | -0.0162     |\n",
      "|    value_loss           | 0.000544    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 925         |\n",
      "|    time_elapsed         | 12492       |\n",
      "|    total_timesteps      | 1894400     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010346512 |\n",
      "|    clip_fraction        | 0.158       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.24       |\n",
      "|    explained_variance   | 0.929       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0216     |\n",
      "|    n_updates            | 9240        |\n",
      "|    policy_gradient_loss | -0.00544    |\n",
      "|    value_loss           | 8.12e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 926         |\n",
      "|    time_elapsed         | 12498       |\n",
      "|    total_timesteps      | 1896448     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023050433 |\n",
      "|    clip_fraction        | 0.243       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.32       |\n",
      "|    explained_variance   | 0.878       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0108      |\n",
      "|    n_updates            | 9250        |\n",
      "|    policy_gradient_loss | -0.0155     |\n",
      "|    value_loss           | 9.26e-07    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 927         |\n",
      "|    time_elapsed         | 12503       |\n",
      "|    total_timesteps      | 1898496     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017663747 |\n",
      "|    clip_fraction        | 0.331       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.22       |\n",
      "|    explained_variance   | 0.855       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0287     |\n",
      "|    n_updates            | 9260        |\n",
      "|    policy_gradient_loss | -0.0261     |\n",
      "|    value_loss           | 3.08e-06    |\n",
      "-----------------------------------------\n",
      "box reached target\n",
      "box reached target\n",
      "Eval num_timesteps=1900000, episode_reward=2.09 +/- 2.44\n",
      "Episode length: 6032.20 +/- 4859.55\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 6.03e+03    |\n",
      "|    mean_reward          | 2.09        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1900000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025140494 |\n",
      "|    clip_fraction        | 0.334       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.22       |\n",
      "|    explained_variance   | 0.472       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0531     |\n",
      "|    n_updates            | 9270        |\n",
      "|    policy_gradient_loss | -0.0239     |\n",
      "|    value_loss           | 1.48e-06    |\n",
      "-----------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 151     |\n",
      "|    iterations      | 928     |\n",
      "|    time_elapsed    | 12534   |\n",
      "|    total_timesteps | 1900544 |\n",
      "--------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 929         |\n",
      "|    time_elapsed         | 12540       |\n",
      "|    total_timesteps      | 1902592     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011594027 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.23       |\n",
      "|    explained_variance   | 0.985       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0107     |\n",
      "|    n_updates            | 9280        |\n",
      "|    policy_gradient_loss | -0.0148     |\n",
      "|    value_loss           | 3.51e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 930         |\n",
      "|    time_elapsed         | 12546       |\n",
      "|    total_timesteps      | 1904640     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014654547 |\n",
      "|    clip_fraction        | 0.194       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.05       |\n",
      "|    explained_variance   | 0.942       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0252      |\n",
      "|    n_updates            | 9290        |\n",
      "|    policy_gradient_loss | -0.00585    |\n",
      "|    value_loss           | 0.000189    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 931         |\n",
      "|    time_elapsed         | 12551       |\n",
      "|    total_timesteps      | 1906688     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006677718 |\n",
      "|    clip_fraction        | 0.0977      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.978      |\n",
      "|    explained_variance   | 0.913       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0118     |\n",
      "|    n_updates            | 9300        |\n",
      "|    policy_gradient_loss | -0.00555    |\n",
      "|    value_loss           | 9.73e-06    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 152          |\n",
      "|    iterations           | 932          |\n",
      "|    time_elapsed         | 12557        |\n",
      "|    total_timesteps      | 1908736      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0061964737 |\n",
      "|    clip_fraction        | 0.0968       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.953       |\n",
      "|    explained_variance   | 0.926        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.00894      |\n",
      "|    n_updates            | 9310         |\n",
      "|    policy_gradient_loss | -0.00621     |\n",
      "|    value_loss           | 2.78e-06     |\n",
      "------------------------------------------\n",
      "box reached target\n",
      "Eval num_timesteps=1910000, episode_reward=1.23 +/- 2.40\n",
      "Episode length: 8422.80 +/- 3154.40\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 8.42e+03    |\n",
      "|    mean_reward          | 1.23        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1910000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013309303 |\n",
      "|    clip_fraction        | 0.127       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.902      |\n",
      "|    explained_variance   | 0.876       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0363     |\n",
      "|    n_updates            | 9320        |\n",
      "|    policy_gradient_loss | -0.0102     |\n",
      "|    value_loss           | 1.26e-06    |\n",
      "-----------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 151     |\n",
      "|    iterations      | 933     |\n",
      "|    time_elapsed    | 12599   |\n",
      "|    total_timesteps | 1910784 |\n",
      "--------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 151        |\n",
      "|    iterations           | 934        |\n",
      "|    time_elapsed         | 12604      |\n",
      "|    total_timesteps      | 1912832    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01912541 |\n",
      "|    clip_fraction        | 0.135      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.913     |\n",
      "|    explained_variance   | 0.941      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0141     |\n",
      "|    n_updates            | 9330       |\n",
      "|    policy_gradient_loss | -0.0107    |\n",
      "|    value_loss           | 2.37e-05   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 935         |\n",
      "|    time_elapsed         | 12610       |\n",
      "|    total_timesteps      | 1914880     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006997767 |\n",
      "|    clip_fraction        | 0.089       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.748      |\n",
      "|    explained_variance   | -1.38       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0363     |\n",
      "|    n_updates            | 9340        |\n",
      "|    policy_gradient_loss | -0.00611    |\n",
      "|    value_loss           | 1.68e-06    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 151         |\n",
      "|    iterations           | 936         |\n",
      "|    time_elapsed         | 12616       |\n",
      "|    total_timesteps      | 1916928     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010706871 |\n",
      "|    clip_fraction        | 0.111       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.814      |\n",
      "|    explained_variance   | -0.713      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00184    |\n",
      "|    n_updates            | 9350        |\n",
      "|    policy_gradient_loss | -0.00812    |\n",
      "|    value_loss           | 1.27e-06    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 152         |\n",
      "|    iterations           | 937         |\n",
      "|    time_elapsed         | 12621       |\n",
      "|    total_timesteps      | 1918976     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013701772 |\n",
      "|    clip_fraction        | 0.165       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.933      |\n",
      "|    explained_variance   | 0.423       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0284     |\n",
      "|    n_updates            | 9360        |\n",
      "|    policy_gradient_loss | -0.0151     |\n",
      "|    value_loss           | 6.56e-07    |\n",
      "-----------------------------------------\n",
      "box reached target\n",
      "box reached target\n",
      "box reached target\n",
      "Eval num_timesteps=1920000, episode_reward=3.07 +/- 2.51\n",
      "Episode length: 4100.00 +/- 4817.48\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 4.1e+03     |\n",
      "|    mean_reward          | 3.07        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1920000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012581427 |\n",
      "|    clip_fraction        | 0.183       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.06       |\n",
      "|    explained_variance   | 0.888       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0349     |\n",
      "|    n_updates            | 9370        |\n",
      "|    policy_gradient_loss | -0.0168     |\n",
      "|    value_loss           | 4.98e-07    |\n",
      "-----------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 151     |\n",
      "|    iterations      | 938     |\n",
      "|    time_elapsed    | 12644   |\n",
      "|    total_timesteps | 1921024 |\n",
      "--------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 152         |\n",
      "|    iterations           | 939         |\n",
      "|    time_elapsed         | 12649       |\n",
      "|    total_timesteps      | 1923072     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011044333 |\n",
      "|    clip_fraction        | 0.0983      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.15       |\n",
      "|    explained_variance   | 0.679       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00667    |\n",
      "|    n_updates            | 9380        |\n",
      "|    policy_gradient_loss | -0.00577    |\n",
      "|    value_loss           | 0.000203    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 152         |\n",
      "|    iterations           | 940         |\n",
      "|    time_elapsed         | 12655       |\n",
      "|    total_timesteps      | 1925120     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015774526 |\n",
      "|    clip_fraction        | 0.128       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.11       |\n",
      "|    explained_variance   | 0.933       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00348     |\n",
      "|    n_updates            | 9390        |\n",
      "|    policy_gradient_loss | -0.0123     |\n",
      "|    value_loss           | 0.000672    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 152        |\n",
      "|    iterations           | 941        |\n",
      "|    time_elapsed         | 12661      |\n",
      "|    total_timesteps      | 1927168    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03493484 |\n",
      "|    clip_fraction        | 0.259      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.27      |\n",
      "|    explained_variance   | 0.931      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0232    |\n",
      "|    n_updates            | 9400       |\n",
      "|    policy_gradient_loss | -0.014     |\n",
      "|    value_loss           | 0.000417   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 152        |\n",
      "|    iterations           | 942        |\n",
      "|    time_elapsed         | 12666      |\n",
      "|    total_timesteps      | 1929216    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01665753 |\n",
      "|    clip_fraction        | 0.212      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.24      |\n",
      "|    explained_variance   | 0.917      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0327    |\n",
      "|    n_updates            | 9410       |\n",
      "|    policy_gradient_loss | -0.0215    |\n",
      "|    value_loss           | 0.000647   |\n",
      "----------------------------------------\n",
      "box reached target\n",
      "box reached target\n",
      "Eval num_timesteps=1930000, episode_reward=2.11 +/- 2.47\n",
      "Episode length: 6059.60 +/- 4825.99\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 6.06e+03    |\n",
      "|    mean_reward          | 2.11        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1930000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015066821 |\n",
      "|    clip_fraction        | 0.206       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.24       |\n",
      "|    explained_variance   | 0.91        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0202     |\n",
      "|    n_updates            | 9420        |\n",
      "|    policy_gradient_loss | -0.0178     |\n",
      "|    value_loss           | 0.000142    |\n",
      "-----------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 152     |\n",
      "|    iterations      | 943     |\n",
      "|    time_elapsed    | 12697   |\n",
      "|    total_timesteps | 1931264 |\n",
      "--------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 152         |\n",
      "|    iterations           | 944         |\n",
      "|    time_elapsed         | 12703       |\n",
      "|    total_timesteps      | 1933312     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024525627 |\n",
      "|    clip_fraction        | 0.224       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.09       |\n",
      "|    explained_variance   | 0.87        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0264     |\n",
      "|    n_updates            | 9430        |\n",
      "|    policy_gradient_loss | -0.012      |\n",
      "|    value_loss           | 0.00181     |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 152        |\n",
      "|    iterations           | 945        |\n",
      "|    time_elapsed         | 12708      |\n",
      "|    total_timesteps      | 1935360    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02009485 |\n",
      "|    clip_fraction        | 0.293      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.23      |\n",
      "|    explained_variance   | 0.859      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0418    |\n",
      "|    n_updates            | 9440       |\n",
      "|    policy_gradient_loss | -0.0234    |\n",
      "|    value_loss           | 0.00213    |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 152         |\n",
      "|    iterations           | 946         |\n",
      "|    time_elapsed         | 12714       |\n",
      "|    total_timesteps      | 1937408     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016990103 |\n",
      "|    clip_fraction        | 0.251       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.27       |\n",
      "|    explained_variance   | 0.904       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0478     |\n",
      "|    n_updates            | 9450        |\n",
      "|    policy_gradient_loss | -0.0187     |\n",
      "|    value_loss           | 0.00704     |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 152        |\n",
      "|    iterations           | 947        |\n",
      "|    time_elapsed         | 12719      |\n",
      "|    total_timesteps      | 1939456    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01623384 |\n",
      "|    clip_fraction        | 0.186      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.29      |\n",
      "|    explained_variance   | 0.905      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0183    |\n",
      "|    n_updates            | 9460       |\n",
      "|    policy_gradient_loss | -0.0172    |\n",
      "|    value_loss           | 0.00836    |\n",
      "----------------------------------------\n",
      "box reached target\n",
      "Eval num_timesteps=1940000, episode_reward=1.04 +/- 2.01\n",
      "Episode length: 8011.80 +/- 3976.40\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 8.01e+03    |\n",
      "|    mean_reward          | 1.04        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1940000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023001626 |\n",
      "|    clip_fraction        | 0.337       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.34       |\n",
      "|    explained_variance   | 0.802       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00919     |\n",
      "|    n_updates            | 9470        |\n",
      "|    policy_gradient_loss | -0.0344     |\n",
      "|    value_loss           | 0.0137      |\n",
      "-----------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 152     |\n",
      "|    iterations      | 948     |\n",
      "|    time_elapsed    | 12759   |\n",
      "|    total_timesteps | 1941504 |\n",
      "--------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 152         |\n",
      "|    iterations           | 949         |\n",
      "|    time_elapsed         | 12764       |\n",
      "|    total_timesteps      | 1943552     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013105157 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.21       |\n",
      "|    explained_variance   | 0.885       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0346      |\n",
      "|    n_updates            | 9480        |\n",
      "|    policy_gradient_loss | -0.01       |\n",
      "|    value_loss           | 0.00707     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 152         |\n",
      "|    iterations           | 950         |\n",
      "|    time_elapsed         | 12770       |\n",
      "|    total_timesteps      | 1945600     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020941414 |\n",
      "|    clip_fraction        | 0.38        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.23       |\n",
      "|    explained_variance   | 0.765       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0575     |\n",
      "|    n_updates            | 9490        |\n",
      "|    policy_gradient_loss | -0.0321     |\n",
      "|    value_loss           | 0.00185     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 152         |\n",
      "|    iterations           | 951         |\n",
      "|    time_elapsed         | 12775       |\n",
      "|    total_timesteps      | 1947648     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015022181 |\n",
      "|    clip_fraction        | 0.265       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.24       |\n",
      "|    explained_variance   | 0.783       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00673    |\n",
      "|    n_updates            | 9500        |\n",
      "|    policy_gradient_loss | -0.0203     |\n",
      "|    value_loss           | 0.00294     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 152         |\n",
      "|    iterations           | 952         |\n",
      "|    time_elapsed         | 12780       |\n",
      "|    total_timesteps      | 1949696     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015916958 |\n",
      "|    clip_fraction        | 0.293       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.24       |\n",
      "|    explained_variance   | 0.388       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00296    |\n",
      "|    n_updates            | 9510        |\n",
      "|    policy_gradient_loss | -0.0234     |\n",
      "|    value_loss           | 0.00117     |\n",
      "-----------------------------------------\n",
      "box reached target\n",
      "box reached target\n",
      "Eval num_timesteps=1950000, episode_reward=2.20 +/- 2.62\n",
      "Episode length: 6268.00 +/- 4574.43\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 6.27e+03    |\n",
      "|    mean_reward          | 2.2         |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1950000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016116545 |\n",
      "|    clip_fraction        | 0.279       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.24       |\n",
      "|    explained_variance   | 0.597       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0107      |\n",
      "|    n_updates            | 9520        |\n",
      "|    policy_gradient_loss | -0.0222     |\n",
      "|    value_loss           | 0.000391    |\n",
      "-----------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 152     |\n",
      "|    iterations      | 953     |\n",
      "|    time_elapsed    | 12812   |\n",
      "|    total_timesteps | 1951744 |\n",
      "--------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 152         |\n",
      "|    iterations           | 954         |\n",
      "|    time_elapsed         | 12817       |\n",
      "|    total_timesteps      | 1953792     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008924535 |\n",
      "|    clip_fraction        | 0.0753      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.988      |\n",
      "|    explained_variance   | 0.862       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0101     |\n",
      "|    n_updates            | 9530        |\n",
      "|    policy_gradient_loss | -0.0129     |\n",
      "|    value_loss           | 0.000948    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 152         |\n",
      "|    iterations           | 955         |\n",
      "|    time_elapsed         | 12823       |\n",
      "|    total_timesteps      | 1955840     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011742016 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.39       |\n",
      "|    explained_variance   | 0.888       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0459     |\n",
      "|    n_updates            | 9540        |\n",
      "|    policy_gradient_loss | -0.0127     |\n",
      "|    value_loss           | 3.74e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 152         |\n",
      "|    iterations           | 956         |\n",
      "|    time_elapsed         | 12828       |\n",
      "|    total_timesteps      | 1957888     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014751274 |\n",
      "|    clip_fraction        | 0.209       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.38       |\n",
      "|    explained_variance   | 0.919       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0246     |\n",
      "|    n_updates            | 9550        |\n",
      "|    policy_gradient_loss | -0.02       |\n",
      "|    value_loss           | 1.3e-05     |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 152        |\n",
      "|    iterations           | 957        |\n",
      "|    time_elapsed         | 12833      |\n",
      "|    total_timesteps      | 1959936    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02346512 |\n",
      "|    clip_fraction        | 0.301      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.35      |\n",
      "|    explained_variance   | 0.847      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0224     |\n",
      "|    n_updates            | 9560       |\n",
      "|    policy_gradient_loss | -0.028     |\n",
      "|    value_loss           | 6.66e-06   |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=1960000, episode_reward=0.03 +/- 0.06\n",
      "Episode length: 10000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+04       |\n",
      "|    mean_reward          | 0.0319      |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1960000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009256544 |\n",
      "|    clip_fraction        | 0.132       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.23       |\n",
      "|    explained_variance   | 0.945       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0313     |\n",
      "|    n_updates            | 9570        |\n",
      "|    policy_gradient_loss | -0.013      |\n",
      "|    value_loss           | 5.96e-05    |\n",
      "-----------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 152     |\n",
      "|    iterations      | 958     |\n",
      "|    time_elapsed    | 12881   |\n",
      "|    total_timesteps | 1961984 |\n",
      "--------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 152        |\n",
      "|    iterations           | 959        |\n",
      "|    time_elapsed         | 12886      |\n",
      "|    total_timesteps      | 1964032    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02016382 |\n",
      "|    clip_fraction        | 0.22       |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.28      |\n",
      "|    explained_variance   | 0.316      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0271    |\n",
      "|    n_updates            | 9580       |\n",
      "|    policy_gradient_loss | -0.0148    |\n",
      "|    value_loss           | 6.93e-05   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 152         |\n",
      "|    iterations           | 960         |\n",
      "|    time_elapsed         | 12892       |\n",
      "|    total_timesteps      | 1966080     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012196926 |\n",
      "|    clip_fraction        | 0.176       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.28       |\n",
      "|    explained_variance   | 0.947       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00529    |\n",
      "|    n_updates            | 9590        |\n",
      "|    policy_gradient_loss | -0.017      |\n",
      "|    value_loss           | 8.78e-06    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 152         |\n",
      "|    iterations           | 961         |\n",
      "|    time_elapsed         | 12897       |\n",
      "|    total_timesteps      | 1968128     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017122375 |\n",
      "|    clip_fraction        | 0.285       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.36       |\n",
      "|    explained_variance   | 0.897       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0496     |\n",
      "|    n_updates            | 9600        |\n",
      "|    policy_gradient_loss | -0.027      |\n",
      "|    value_loss           | 8.6e-05     |\n",
      "-----------------------------------------\n",
      "box reached target\n",
      "box reached target\n",
      "box reached target\n",
      "Eval num_timesteps=1970000, episode_reward=3.15 +/- 2.51\n",
      "Episode length: 4120.80 +/- 4800.41\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 4.12e+03    |\n",
      "|    mean_reward          | 3.15        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1970000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018041147 |\n",
      "|    clip_fraction        | 0.367       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.38       |\n",
      "|    explained_variance   | 0.511       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0279     |\n",
      "|    n_updates            | 9610        |\n",
      "|    policy_gradient_loss | -0.0358     |\n",
      "|    value_loss           | 8.6e-05     |\n",
      "-----------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 152     |\n",
      "|    iterations      | 962     |\n",
      "|    time_elapsed    | 12920   |\n",
      "|    total_timesteps | 1970176 |\n",
      "--------------------------------\n",
      "box reached target\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 152         |\n",
      "|    iterations           | 963         |\n",
      "|    time_elapsed         | 12925       |\n",
      "|    total_timesteps      | 1972224     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017673066 |\n",
      "|    clip_fraction        | 0.288       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.36       |\n",
      "|    explained_variance   | -0.437      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0389     |\n",
      "|    n_updates            | 9620        |\n",
      "|    policy_gradient_loss | -0.014      |\n",
      "|    value_loss           | 0.000111    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 152         |\n",
      "|    iterations           | 964         |\n",
      "|    time_elapsed         | 12930       |\n",
      "|    total_timesteps      | 1974272     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025663963 |\n",
      "|    clip_fraction        | 0.145       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.06       |\n",
      "|    explained_variance   | 0.266       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00828    |\n",
      "|    n_updates            | 9630        |\n",
      "|    policy_gradient_loss | -0.00824    |\n",
      "|    value_loss           | 0.0309      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 152         |\n",
      "|    iterations           | 965         |\n",
      "|    time_elapsed         | 12936       |\n",
      "|    total_timesteps      | 1976320     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016865589 |\n",
      "|    clip_fraction        | 0.306       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.21       |\n",
      "|    explained_variance   | 0.535       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.024      |\n",
      "|    n_updates            | 9640        |\n",
      "|    policy_gradient_loss | -0.0187     |\n",
      "|    value_loss           | 0.000769    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 152         |\n",
      "|    iterations           | 966         |\n",
      "|    time_elapsed         | 12941       |\n",
      "|    total_timesteps      | 1978368     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014634334 |\n",
      "|    clip_fraction        | 0.234       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.15       |\n",
      "|    explained_variance   | 0.474       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0192      |\n",
      "|    n_updates            | 9650        |\n",
      "|    policy_gradient_loss | -0.0134     |\n",
      "|    value_loss           | 0.000471    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1980000, episode_reward=-0.00 +/- 0.07\n",
      "Episode length: 10000.00 +/- 0.00\n",
      "----------------------------------------\n",
      "| eval/                   |            |\n",
      "|    mean_ep_length       | 1e+04      |\n",
      "|    mean_reward          | -0.00486   |\n",
      "| time/                   |            |\n",
      "|    total_timesteps      | 1980000    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01501436 |\n",
      "|    clip_fraction        | 0.178      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.99      |\n",
      "|    explained_variance   | 0.829      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.011     |\n",
      "|    n_updates            | 9660       |\n",
      "|    policy_gradient_loss | -0.0102    |\n",
      "|    value_loss           | 0.00054    |\n",
      "----------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 152     |\n",
      "|    iterations      | 967     |\n",
      "|    time_elapsed    | 12988   |\n",
      "|    total_timesteps | 1980416 |\n",
      "--------------------------------\n",
      "box reached target\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 152        |\n",
      "|    iterations           | 968        |\n",
      "|    time_elapsed         | 12994      |\n",
      "|    total_timesteps      | 1982464    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01176882 |\n",
      "|    clip_fraction        | 0.0903     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.871     |\n",
      "|    explained_variance   | 0.612      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.00714    |\n",
      "|    n_updates            | 9670       |\n",
      "|    policy_gradient_loss | -0.00487   |\n",
      "|    value_loss           | 0.00142    |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 152         |\n",
      "|    iterations           | 969         |\n",
      "|    time_elapsed         | 12999       |\n",
      "|    total_timesteps      | 1984512     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014917707 |\n",
      "|    clip_fraction        | 0.112       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.1        |\n",
      "|    explained_variance   | 0.297       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00325     |\n",
      "|    n_updates            | 9680        |\n",
      "|    policy_gradient_loss | -0.00737    |\n",
      "|    value_loss           | 0.0206      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 152         |\n",
      "|    iterations           | 970         |\n",
      "|    time_elapsed         | 13005       |\n",
      "|    total_timesteps      | 1986560     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010498831 |\n",
      "|    clip_fraction        | 0.134       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.39       |\n",
      "|    explained_variance   | 0.851       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0253     |\n",
      "|    n_updates            | 9690        |\n",
      "|    policy_gradient_loss | -0.0112     |\n",
      "|    value_loss           | 0.000853    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 152         |\n",
      "|    iterations           | 971         |\n",
      "|    time_elapsed         | 13010       |\n",
      "|    total_timesteps      | 1988608     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012103111 |\n",
      "|    clip_fraction        | 0.179       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.41       |\n",
      "|    explained_variance   | 0.307       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.023      |\n",
      "|    n_updates            | 9700        |\n",
      "|    policy_gradient_loss | -0.012      |\n",
      "|    value_loss           | 0.000584    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=1990000, episode_reward=0.12 +/- 0.24\n",
      "Episode length: 10000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+04       |\n",
      "|    mean_reward          | 0.12        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 1990000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013713187 |\n",
      "|    clip_fraction        | 0.289       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.36       |\n",
      "|    explained_variance   | -0.279      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0192     |\n",
      "|    n_updates            | 9710        |\n",
      "|    policy_gradient_loss | -0.019      |\n",
      "|    value_loss           | 0.000341    |\n",
      "-----------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 152     |\n",
      "|    iterations      | 972     |\n",
      "|    time_elapsed    | 13057   |\n",
      "|    total_timesteps | 1990656 |\n",
      "--------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 152         |\n",
      "|    iterations           | 973         |\n",
      "|    time_elapsed         | 13063       |\n",
      "|    total_timesteps      | 1992704     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014612393 |\n",
      "|    clip_fraction        | 0.142       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.21       |\n",
      "|    explained_variance   | 0.705       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.000297   |\n",
      "|    n_updates            | 9720        |\n",
      "|    policy_gradient_loss | -0.00669    |\n",
      "|    value_loss           | 0.00115     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 152         |\n",
      "|    iterations           | 974         |\n",
      "|    time_elapsed         | 13068       |\n",
      "|    total_timesteps      | 1994752     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026511677 |\n",
      "|    clip_fraction        | 0.199       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.22       |\n",
      "|    explained_variance   | 0.94        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0518     |\n",
      "|    n_updates            | 9730        |\n",
      "|    policy_gradient_loss | -0.0111     |\n",
      "|    value_loss           | 0.000671    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 152        |\n",
      "|    iterations           | 975        |\n",
      "|    time_elapsed         | 13073      |\n",
      "|    total_timesteps      | 1996800    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02486946 |\n",
      "|    clip_fraction        | 0.329      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.33      |\n",
      "|    explained_variance   | 0.326      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0257    |\n",
      "|    n_updates            | 9740       |\n",
      "|    policy_gradient_loss | -0.0165    |\n",
      "|    value_loss           | 0.000683   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 152         |\n",
      "|    iterations           | 976         |\n",
      "|    time_elapsed         | 13079       |\n",
      "|    total_timesteps      | 1998848     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016433619 |\n",
      "|    clip_fraction        | 0.237       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.35       |\n",
      "|    explained_variance   | 0.0739      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0212     |\n",
      "|    n_updates            | 9750        |\n",
      "|    policy_gradient_loss | -0.0134     |\n",
      "|    value_loss           | 0.000379    |\n",
      "-----------------------------------------\n",
      "box reached target\n",
      "Eval num_timesteps=2000000, episode_reward=1.03 +/- 2.01\n",
      "Episode length: 8012.00 +/- 3976.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 8.01e+03    |\n",
      "|    mean_reward          | 1.03        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2000000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017127458 |\n",
      "|    clip_fraction        | 0.319       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.35       |\n",
      "|    explained_variance   | 0.427       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0126     |\n",
      "|    n_updates            | 9760        |\n",
      "|    policy_gradient_loss | -0.0217     |\n",
      "|    value_loss           | 0.000216    |\n",
      "-----------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 152     |\n",
      "|    iterations      | 977     |\n",
      "|    time_elapsed    | 13118   |\n",
      "|    total_timesteps | 2000896 |\n",
      "--------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 152         |\n",
      "|    iterations           | 978         |\n",
      "|    time_elapsed         | 13123       |\n",
      "|    total_timesteps      | 2002944     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011114681 |\n",
      "|    clip_fraction        | 0.0803      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.23       |\n",
      "|    explained_variance   | 0.949       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0149     |\n",
      "|    n_updates            | 9770        |\n",
      "|    policy_gradient_loss | -0.00739    |\n",
      "|    value_loss           | 0.00108     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 152         |\n",
      "|    iterations           | 979         |\n",
      "|    time_elapsed         | 13129       |\n",
      "|    total_timesteps      | 2004992     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012520095 |\n",
      "|    clip_fraction        | 0.136       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.25       |\n",
      "|    explained_variance   | 0.928       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00701     |\n",
      "|    n_updates            | 9780        |\n",
      "|    policy_gradient_loss | -0.00924    |\n",
      "|    value_loss           | 0.00124     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 152         |\n",
      "|    iterations           | 980         |\n",
      "|    time_elapsed         | 13134       |\n",
      "|    total_timesteps      | 2007040     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018858109 |\n",
      "|    clip_fraction        | 0.232       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.29       |\n",
      "|    explained_variance   | 0.921       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.000441    |\n",
      "|    n_updates            | 9790        |\n",
      "|    policy_gradient_loss | -0.0161     |\n",
      "|    value_loss           | 0.000425    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 152         |\n",
      "|    iterations           | 981         |\n",
      "|    time_elapsed         | 13139       |\n",
      "|    total_timesteps      | 2009088     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015721984 |\n",
      "|    clip_fraction        | 0.162       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.27       |\n",
      "|    explained_variance   | 0.914       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0497     |\n",
      "|    n_updates            | 9800        |\n",
      "|    policy_gradient_loss | -0.0134     |\n",
      "|    value_loss           | 0.000284    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2010000, episode_reward=0.00 +/- 0.01\n",
      "Episode length: 10000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+04       |\n",
      "|    mean_reward          | 0.00472     |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2010000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022274924 |\n",
      "|    clip_fraction        | 0.189       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.33       |\n",
      "|    explained_variance   | 0.882       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0396     |\n",
      "|    n_updates            | 9810        |\n",
      "|    policy_gradient_loss | -0.0147     |\n",
      "|    value_loss           | 0.000136    |\n",
      "-----------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 152     |\n",
      "|    iterations      | 982     |\n",
      "|    time_elapsed    | 13187   |\n",
      "|    total_timesteps | 2011136 |\n",
      "--------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 152         |\n",
      "|    iterations           | 983         |\n",
      "|    time_elapsed         | 13193       |\n",
      "|    total_timesteps      | 2013184     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028587863 |\n",
      "|    clip_fraction        | 0.165       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.26       |\n",
      "|    explained_variance   | 0.94        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0317     |\n",
      "|    n_updates            | 9820        |\n",
      "|    policy_gradient_loss | -0.0125     |\n",
      "|    value_loss           | 0.000692    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 152         |\n",
      "|    iterations           | 984         |\n",
      "|    time_elapsed         | 13198       |\n",
      "|    total_timesteps      | 2015232     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016508603 |\n",
      "|    clip_fraction        | 0.228       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.22       |\n",
      "|    explained_variance   | 0.923       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0522     |\n",
      "|    n_updates            | 9830        |\n",
      "|    policy_gradient_loss | -0.0184     |\n",
      "|    value_loss           | 0.000242    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 152         |\n",
      "|    iterations           | 985         |\n",
      "|    time_elapsed         | 13204       |\n",
      "|    total_timesteps      | 2017280     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021908682 |\n",
      "|    clip_fraction        | 0.362       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.27       |\n",
      "|    explained_variance   | 0.738       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0219     |\n",
      "|    n_updates            | 9840        |\n",
      "|    policy_gradient_loss | -0.0312     |\n",
      "|    value_loss           | 0.000346    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 152         |\n",
      "|    iterations           | 986         |\n",
      "|    time_elapsed         | 13209       |\n",
      "|    total_timesteps      | 2019328     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015562258 |\n",
      "|    clip_fraction        | 0.259       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.23       |\n",
      "|    explained_variance   | 0.901       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00121     |\n",
      "|    n_updates            | 9850        |\n",
      "|    policy_gradient_loss | -0.0215     |\n",
      "|    value_loss           | 0.000796    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2020000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 10000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+04       |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2020000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018700488 |\n",
      "|    clip_fraction        | 0.305       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.2        |\n",
      "|    explained_variance   | 0.888       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0168      |\n",
      "|    n_updates            | 9860        |\n",
      "|    policy_gradient_loss | -0.0273     |\n",
      "|    value_loss           | 0.000963    |\n",
      "-----------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 152     |\n",
      "|    iterations      | 987     |\n",
      "|    time_elapsed    | 13257   |\n",
      "|    total_timesteps | 2021376 |\n",
      "--------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 152         |\n",
      "|    iterations           | 988         |\n",
      "|    time_elapsed         | 13262       |\n",
      "|    total_timesteps      | 2023424     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011645628 |\n",
      "|    clip_fraction        | 0.112       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.2        |\n",
      "|    explained_variance   | 0.922       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00944    |\n",
      "|    n_updates            | 9870        |\n",
      "|    policy_gradient_loss | -0.00882    |\n",
      "|    value_loss           | 0.00411     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 152         |\n",
      "|    iterations           | 989         |\n",
      "|    time_elapsed         | 13268       |\n",
      "|    total_timesteps      | 2025472     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009652875 |\n",
      "|    clip_fraction        | 0.144       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.15       |\n",
      "|    explained_variance   | 0.879       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00174    |\n",
      "|    n_updates            | 9880        |\n",
      "|    policy_gradient_loss | -0.0114     |\n",
      "|    value_loss           | 1.77e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 152         |\n",
      "|    iterations           | 990         |\n",
      "|    time_elapsed         | 13273       |\n",
      "|    total_timesteps      | 2027520     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013512081 |\n",
      "|    clip_fraction        | 0.181       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.18       |\n",
      "|    explained_variance   | 0.849       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0276      |\n",
      "|    n_updates            | 9890        |\n",
      "|    policy_gradient_loss | -0.0219     |\n",
      "|    value_loss           | 1.4e-05     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 152         |\n",
      "|    iterations           | 991         |\n",
      "|    time_elapsed         | 13278       |\n",
      "|    total_timesteps      | 2029568     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016828367 |\n",
      "|    clip_fraction        | 0.218       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.17       |\n",
      "|    explained_variance   | 0.689       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0321     |\n",
      "|    n_updates            | 9900        |\n",
      "|    policy_gradient_loss | -0.0216     |\n",
      "|    value_loss           | 2.52e-05    |\n",
      "-----------------------------------------\n",
      "box reached target\n",
      "Eval num_timesteps=2030000, episode_reward=1.02 +/- 2.02\n",
      "Episode length: 8015.60 +/- 3968.80\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 8.02e+03    |\n",
      "|    mean_reward          | 1.02        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2030000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012046087 |\n",
      "|    clip_fraction        | 0.191       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.17       |\n",
      "|    explained_variance   | 0.894       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0571     |\n",
      "|    n_updates            | 9910        |\n",
      "|    policy_gradient_loss | -0.0188     |\n",
      "|    value_loss           | 1.56e-05    |\n",
      "-----------------------------------------\n",
      "box reached target\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 152     |\n",
      "|    iterations      | 992     |\n",
      "|    time_elapsed    | 13317   |\n",
      "|    total_timesteps | 2031616 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 152          |\n",
      "|    iterations           | 993          |\n",
      "|    time_elapsed         | 13323        |\n",
      "|    total_timesteps      | 2033664      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0076987273 |\n",
      "|    clip_fraction        | 0.044        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.14        |\n",
      "|    explained_variance   | 0.783        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0304      |\n",
      "|    n_updates            | 9920         |\n",
      "|    policy_gradient_loss | 0.00013      |\n",
      "|    value_loss           | 0.00339      |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 152         |\n",
      "|    iterations           | 994         |\n",
      "|    time_elapsed         | 13328       |\n",
      "|    total_timesteps      | 2035712     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020452123 |\n",
      "|    clip_fraction        | 0.333       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.25       |\n",
      "|    explained_variance   | 0.905       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0335     |\n",
      "|    n_updates            | 9930        |\n",
      "|    policy_gradient_loss | -0.0236     |\n",
      "|    value_loss           | 6.58e-05    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 152        |\n",
      "|    iterations           | 995        |\n",
      "|    time_elapsed         | 13334      |\n",
      "|    total_timesteps      | 2037760    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02611653 |\n",
      "|    clip_fraction        | 0.372      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.17      |\n",
      "|    explained_variance   | 0.781      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0574    |\n",
      "|    n_updates            | 9940       |\n",
      "|    policy_gradient_loss | -0.0296    |\n",
      "|    value_loss           | 0.000145   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 152         |\n",
      "|    iterations           | 996         |\n",
      "|    time_elapsed         | 13339       |\n",
      "|    total_timesteps      | 2039808     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026354909 |\n",
      "|    clip_fraction        | 0.338       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.1        |\n",
      "|    explained_variance   | 0.646       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0264      |\n",
      "|    n_updates            | 9950        |\n",
      "|    policy_gradient_loss | -0.025      |\n",
      "|    value_loss           | 0.000131    |\n",
      "-----------------------------------------\n",
      "box reached target\n",
      "Eval num_timesteps=2040000, episode_reward=1.02 +/- 2.04\n",
      "Episode length: 8041.20 +/- 3917.60\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 8.04e+03    |\n",
      "|    mean_reward          | 1.02        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2040000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010192173 |\n",
      "|    clip_fraction        | 0.125       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.14       |\n",
      "|    explained_variance   | 0.785       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.048      |\n",
      "|    n_updates            | 9960        |\n",
      "|    policy_gradient_loss | -0.0105     |\n",
      "|    value_loss           | 0.000156    |\n",
      "-----------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 152     |\n",
      "|    iterations      | 997     |\n",
      "|    time_elapsed    | 13379   |\n",
      "|    total_timesteps | 2041856 |\n",
      "--------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 152         |\n",
      "|    iterations           | 998         |\n",
      "|    time_elapsed         | 13384       |\n",
      "|    total_timesteps      | 2043904     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013150937 |\n",
      "|    clip_fraction        | 0.131       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.12       |\n",
      "|    explained_variance   | 0.93        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0302      |\n",
      "|    n_updates            | 9970        |\n",
      "|    policy_gradient_loss | -0.0104     |\n",
      "|    value_loss           | 0.000612    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 152         |\n",
      "|    iterations           | 999         |\n",
      "|    time_elapsed         | 13389       |\n",
      "|    total_timesteps      | 2045952     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031509683 |\n",
      "|    clip_fraction        | 0.317       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.1        |\n",
      "|    explained_variance   | -0.706      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.061      |\n",
      "|    n_updates            | 9980        |\n",
      "|    policy_gradient_loss | -0.0267     |\n",
      "|    value_loss           | 1.09e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 152         |\n",
      "|    iterations           | 1000        |\n",
      "|    time_elapsed         | 13395       |\n",
      "|    total_timesteps      | 2048000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022087274 |\n",
      "|    clip_fraction        | 0.245       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.998      |\n",
      "|    explained_variance   | -1.42       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0477     |\n",
      "|    n_updates            | 9990        |\n",
      "|    policy_gradient_loss | -0.0212     |\n",
      "|    value_loss           | 1.02e-05    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2050000, episode_reward=0.07 +/- 0.09\n",
      "Episode length: 10000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+04       |\n",
      "|    mean_reward          | 0.0675      |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2050000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017602291 |\n",
      "|    clip_fraction        | 0.205       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.884      |\n",
      "|    explained_variance   | -0.627      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.058      |\n",
      "|    n_updates            | 10000       |\n",
      "|    policy_gradient_loss | -0.0246     |\n",
      "|    value_loss           | 2.99e-06    |\n",
      "-----------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 152     |\n",
      "|    iterations      | 1001    |\n",
      "|    time_elapsed    | 13442   |\n",
      "|    total_timesteps | 2050048 |\n",
      "--------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 152         |\n",
      "|    iterations           | 1002        |\n",
      "|    time_elapsed         | 13448       |\n",
      "|    total_timesteps      | 2052096     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009776143 |\n",
      "|    clip_fraction        | 0.114       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.821      |\n",
      "|    explained_variance   | 0.91        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0163      |\n",
      "|    n_updates            | 10010       |\n",
      "|    policy_gradient_loss | -0.00899    |\n",
      "|    value_loss           | 2.39e-05    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 152          |\n",
      "|    iterations           | 1003         |\n",
      "|    time_elapsed         | 13454        |\n",
      "|    total_timesteps      | 2054144      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0107934205 |\n",
      "|    clip_fraction        | 0.0953       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.967       |\n",
      "|    explained_variance   | 0.78         |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.00943     |\n",
      "|    n_updates            | 10020        |\n",
      "|    policy_gradient_loss | -0.00901     |\n",
      "|    value_loss           | 0.000614     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 152         |\n",
      "|    iterations           | 1004        |\n",
      "|    time_elapsed         | 13459       |\n",
      "|    total_timesteps      | 2056192     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014203282 |\n",
      "|    clip_fraction        | 0.189       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.3        |\n",
      "|    explained_variance   | 0.874       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0241     |\n",
      "|    n_updates            | 10030       |\n",
      "|    policy_gradient_loss | -0.0125     |\n",
      "|    value_loss           | 6.61e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 152         |\n",
      "|    iterations           | 1005        |\n",
      "|    time_elapsed         | 13464       |\n",
      "|    total_timesteps      | 2058240     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008811098 |\n",
      "|    clip_fraction        | 0.115       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.34       |\n",
      "|    explained_variance   | 0.934       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00595    |\n",
      "|    n_updates            | 10040       |\n",
      "|    policy_gradient_loss | -0.00711    |\n",
      "|    value_loss           | 5.55e-06    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2060000, episode_reward=0.07 +/- 0.13\n",
      "Episode length: 10000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+04       |\n",
      "|    mean_reward          | 0.0745      |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2060000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016620772 |\n",
      "|    clip_fraction        | 0.219       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.28       |\n",
      "|    explained_variance   | 0.906       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.023      |\n",
      "|    n_updates            | 10050       |\n",
      "|    policy_gradient_loss | -0.0174     |\n",
      "|    value_loss           | 5.64e-06    |\n",
      "-----------------------------------------\n",
      "box reached target\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 152     |\n",
      "|    iterations      | 1006    |\n",
      "|    time_elapsed    | 13513   |\n",
      "|    total_timesteps | 2060288 |\n",
      "--------------------------------\n",
      "box reached target\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 152          |\n",
      "|    iterations           | 1007         |\n",
      "|    time_elapsed         | 13518        |\n",
      "|    total_timesteps      | 2062336      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0089241695 |\n",
      "|    clip_fraction        | 0.0437       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.21        |\n",
      "|    explained_variance   | 0.967        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.022        |\n",
      "|    n_updates            | 10060        |\n",
      "|    policy_gradient_loss | -0.00413     |\n",
      "|    value_loss           | 0.00154      |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 152         |\n",
      "|    iterations           | 1008        |\n",
      "|    time_elapsed         | 13524       |\n",
      "|    total_timesteps      | 2064384     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004868236 |\n",
      "|    clip_fraction        | 0.0531      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.863      |\n",
      "|    explained_variance   | 0.816       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0111      |\n",
      "|    n_updates            | 10070       |\n",
      "|    policy_gradient_loss | -0.00756    |\n",
      "|    value_loss           | 0.00331     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 152          |\n",
      "|    iterations           | 1009         |\n",
      "|    time_elapsed         | 13529        |\n",
      "|    total_timesteps      | 2066432      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0078456225 |\n",
      "|    clip_fraction        | 0.0873       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.797       |\n",
      "|    explained_variance   | -0.155       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.000496    |\n",
      "|    n_updates            | 10080        |\n",
      "|    policy_gradient_loss | -0.00506     |\n",
      "|    value_loss           | 1.41e-06     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 152         |\n",
      "|    iterations           | 1010        |\n",
      "|    time_elapsed         | 13535       |\n",
      "|    total_timesteps      | 2068480     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007249175 |\n",
      "|    clip_fraction        | 0.0774      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.88       |\n",
      "|    explained_variance   | -0.853      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00805     |\n",
      "|    n_updates            | 10090       |\n",
      "|    policy_gradient_loss | -0.00603    |\n",
      "|    value_loss           | 8.45e-07    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2070000, episode_reward=-0.02 +/- 0.03\n",
      "Episode length: 10000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+04       |\n",
      "|    mean_reward          | -0.016      |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2070000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008850975 |\n",
      "|    clip_fraction        | 0.0829      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.934      |\n",
      "|    explained_variance   | -0.361      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00631    |\n",
      "|    n_updates            | 10100       |\n",
      "|    policy_gradient_loss | -0.00484    |\n",
      "|    value_loss           | 6.53e-07    |\n",
      "-----------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 152     |\n",
      "|    iterations      | 1011    |\n",
      "|    time_elapsed    | 13582   |\n",
      "|    total_timesteps | 2070528 |\n",
      "--------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 152         |\n",
      "|    iterations           | 1012        |\n",
      "|    time_elapsed         | 13588       |\n",
      "|    total_timesteps      | 2072576     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033805355 |\n",
      "|    clip_fraction        | 0.198       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.779      |\n",
      "|    explained_variance   | 0.919       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00386    |\n",
      "|    n_updates            | 10110       |\n",
      "|    policy_gradient_loss | -0.00836    |\n",
      "|    value_loss           | 0.000893    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 152        |\n",
      "|    iterations           | 1013       |\n",
      "|    time_elapsed         | 13593      |\n",
      "|    total_timesteps      | 2074624    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01814479 |\n",
      "|    clip_fraction        | 0.178      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.15      |\n",
      "|    explained_variance   | 0.929      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.036     |\n",
      "|    n_updates            | 10120      |\n",
      "|    policy_gradient_loss | -0.0125    |\n",
      "|    value_loss           | 5.37e-05   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 152         |\n",
      "|    iterations           | 1014        |\n",
      "|    time_elapsed         | 13599       |\n",
      "|    total_timesteps      | 2076672     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012261994 |\n",
      "|    clip_fraction        | 0.17        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.14       |\n",
      "|    explained_variance   | 0.652       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0343     |\n",
      "|    n_updates            | 10130       |\n",
      "|    policy_gradient_loss | -0.0124     |\n",
      "|    value_loss           | 9.45e-06    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 152         |\n",
      "|    iterations           | 1015        |\n",
      "|    time_elapsed         | 13604       |\n",
      "|    total_timesteps      | 2078720     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018134618 |\n",
      "|    clip_fraction        | 0.336       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.21       |\n",
      "|    explained_variance   | 0.578       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0295     |\n",
      "|    n_updates            | 10140       |\n",
      "|    policy_gradient_loss | -0.0279     |\n",
      "|    value_loss           | 8.99e-05    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2080000, episode_reward=-0.01 +/- 0.04\n",
      "Episode length: 10000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+04       |\n",
      "|    mean_reward          | -0.00779    |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2080000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017644651 |\n",
      "|    clip_fraction        | 0.289       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.28       |\n",
      "|    explained_variance   | 0.76        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00422    |\n",
      "|    n_updates            | 10150       |\n",
      "|    policy_gradient_loss | -0.0209     |\n",
      "|    value_loss           | 0.000121    |\n",
      "-----------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 152     |\n",
      "|    iterations      | 1016    |\n",
      "|    time_elapsed    | 13652   |\n",
      "|    total_timesteps | 2080768 |\n",
      "--------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 152         |\n",
      "|    iterations           | 1017        |\n",
      "|    time_elapsed         | 13657       |\n",
      "|    total_timesteps      | 2082816     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024481859 |\n",
      "|    clip_fraction        | 0.208       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.22       |\n",
      "|    explained_variance   | 0.937       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.032       |\n",
      "|    n_updates            | 10160       |\n",
      "|    policy_gradient_loss | -0.012      |\n",
      "|    value_loss           | 0.00152     |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 152       |\n",
      "|    iterations           | 1018      |\n",
      "|    time_elapsed         | 13662     |\n",
      "|    total_timesteps      | 2084864   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0264379 |\n",
      "|    clip_fraction        | 0.278     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -1.05     |\n",
      "|    explained_variance   | 0.904     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -0.0477   |\n",
      "|    n_updates            | 10170     |\n",
      "|    policy_gradient_loss | -0.0172   |\n",
      "|    value_loss           | 0.000647  |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 152         |\n",
      "|    iterations           | 1019        |\n",
      "|    time_elapsed         | 13668       |\n",
      "|    total_timesteps      | 2086912     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027669348 |\n",
      "|    clip_fraction        | 0.323       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.2        |\n",
      "|    explained_variance   | 0.532       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0492     |\n",
      "|    n_updates            | 10180       |\n",
      "|    policy_gradient_loss | -0.0215     |\n",
      "|    value_loss           | 0.00105     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 152         |\n",
      "|    iterations           | 1020        |\n",
      "|    time_elapsed         | 13673       |\n",
      "|    total_timesteps      | 2088960     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014772412 |\n",
      "|    clip_fraction        | 0.152       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.29       |\n",
      "|    explained_variance   | 0.913       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0111     |\n",
      "|    n_updates            | 10190       |\n",
      "|    policy_gradient_loss | -0.0134     |\n",
      "|    value_loss           | 0.000746    |\n",
      "-----------------------------------------\n",
      "Eval num_timesteps=2090000, episode_reward=0.00 +/- 0.00\n",
      "Episode length: 10000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+04       |\n",
      "|    mean_reward          | 0           |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2090000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019873083 |\n",
      "|    clip_fraction        | 0.281       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.33       |\n",
      "|    explained_variance   | 0.84        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0285     |\n",
      "|    n_updates            | 10200       |\n",
      "|    policy_gradient_loss | -0.0182     |\n",
      "|    value_loss           | 0.00038     |\n",
      "-----------------------------------------\n",
      "box reached target\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 152     |\n",
      "|    iterations      | 1021    |\n",
      "|    time_elapsed    | 13721   |\n",
      "|    total_timesteps | 2091008 |\n",
      "--------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 152         |\n",
      "|    iterations           | 1022        |\n",
      "|    time_elapsed         | 13726       |\n",
      "|    total_timesteps      | 2093056     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013560132 |\n",
      "|    clip_fraction        | 0.119       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.2        |\n",
      "|    explained_variance   | -0.0862     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00995    |\n",
      "|    n_updates            | 10210       |\n",
      "|    policy_gradient_loss | -0.0072     |\n",
      "|    value_loss           | 0.0334      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 152         |\n",
      "|    iterations           | 1023        |\n",
      "|    time_elapsed         | 13732       |\n",
      "|    total_timesteps      | 2095104     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011079102 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.16       |\n",
      "|    explained_variance   | 0.881       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.023      |\n",
      "|    n_updates            | 10220       |\n",
      "|    policy_gradient_loss | -0.012      |\n",
      "|    value_loss           | 0.00315     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 152         |\n",
      "|    iterations           | 1024        |\n",
      "|    time_elapsed         | 13737       |\n",
      "|    total_timesteps      | 2097152     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016031388 |\n",
      "|    clip_fraction        | 0.272       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.22       |\n",
      "|    explained_variance   | 0.809       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00588    |\n",
      "|    n_updates            | 10230       |\n",
      "|    policy_gradient_loss | -0.0226     |\n",
      "|    value_loss           | 0.00128     |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 152        |\n",
      "|    iterations           | 1025       |\n",
      "|    time_elapsed         | 13742      |\n",
      "|    total_timesteps      | 2099200    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01684013 |\n",
      "|    clip_fraction        | 0.192      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.28      |\n",
      "|    explained_variance   | 0.802      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0156    |\n",
      "|    n_updates            | 10240      |\n",
      "|    policy_gradient_loss | -0.0139    |\n",
      "|    value_loss           | 0.001      |\n",
      "----------------------------------------\n",
      "Eval num_timesteps=2100000, episode_reward=0.01 +/- 0.02\n",
      "Episode length: 10000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+04       |\n",
      "|    mean_reward          | 0.0116      |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2100000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019350175 |\n",
      "|    clip_fraction        | 0.278       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.2        |\n",
      "|    explained_variance   | 0.769       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0312     |\n",
      "|    n_updates            | 10250       |\n",
      "|    policy_gradient_loss | -0.021      |\n",
      "|    value_loss           | 0.00082     |\n",
      "-----------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 152     |\n",
      "|    iterations      | 1026    |\n",
      "|    time_elapsed    | 13789   |\n",
      "|    total_timesteps | 2101248 |\n",
      "--------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 152        |\n",
      "|    iterations           | 1027       |\n",
      "|    time_elapsed         | 13795      |\n",
      "|    total_timesteps      | 2103296    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01963112 |\n",
      "|    clip_fraction        | 0.167      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.23      |\n",
      "|    explained_variance   | 0.92       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.041     |\n",
      "|    n_updates            | 10260      |\n",
      "|    policy_gradient_loss | -0.0148    |\n",
      "|    value_loss           | 0.00143    |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 152        |\n",
      "|    iterations           | 1028       |\n",
      "|    time_elapsed         | 13800      |\n",
      "|    total_timesteps      | 2105344    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01894743 |\n",
      "|    clip_fraction        | 0.363      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.42      |\n",
      "|    explained_variance   | 0.847      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0338    |\n",
      "|    n_updates            | 10270      |\n",
      "|    policy_gradient_loss | -0.031     |\n",
      "|    value_loss           | 0.000209   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 152        |\n",
      "|    iterations           | 1029       |\n",
      "|    time_elapsed         | 13806      |\n",
      "|    total_timesteps      | 2107392    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01775245 |\n",
      "|    clip_fraction        | 0.347      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.42      |\n",
      "|    explained_variance   | 0.68       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0766    |\n",
      "|    n_updates            | 10280      |\n",
      "|    policy_gradient_loss | -0.0279    |\n",
      "|    value_loss           | 0.000119   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 152         |\n",
      "|    iterations           | 1030        |\n",
      "|    time_elapsed         | 13811       |\n",
      "|    total_timesteps      | 2109440     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016952632 |\n",
      "|    clip_fraction        | 0.195       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.36       |\n",
      "|    explained_variance   | 0.866       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0346     |\n",
      "|    n_updates            | 10290       |\n",
      "|    policy_gradient_loss | -0.0174     |\n",
      "|    value_loss           | 8.11e-05    |\n",
      "-----------------------------------------\n",
      "box reached target\n",
      "Eval num_timesteps=2110000, episode_reward=1.04 +/- 2.04\n",
      "Episode length: 8064.80 +/- 3870.40\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 8.06e+03    |\n",
      "|    mean_reward          | 1.04        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2110000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013237036 |\n",
      "|    clip_fraction        | 0.19        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.4        |\n",
      "|    explained_variance   | 0.547       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0367     |\n",
      "|    n_updates            | 10300       |\n",
      "|    policy_gradient_loss | -0.0103     |\n",
      "|    value_loss           | 5.35e-05    |\n",
      "-----------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 152     |\n",
      "|    iterations      | 1031    |\n",
      "|    time_elapsed    | 13851   |\n",
      "|    total_timesteps | 2111488 |\n",
      "--------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 152         |\n",
      "|    iterations           | 1032        |\n",
      "|    time_elapsed         | 13856       |\n",
      "|    total_timesteps      | 2113536     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014807505 |\n",
      "|    clip_fraction        | 0.151       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.35       |\n",
      "|    explained_variance   | 0.877       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0488     |\n",
      "|    n_updates            | 10310       |\n",
      "|    policy_gradient_loss | -0.00845    |\n",
      "|    value_loss           | 0.000787    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 152         |\n",
      "|    iterations           | 1033        |\n",
      "|    time_elapsed         | 13862       |\n",
      "|    total_timesteps      | 2115584     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019536799 |\n",
      "|    clip_fraction        | 0.393       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.36       |\n",
      "|    explained_variance   | 0.382       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0702     |\n",
      "|    n_updates            | 10320       |\n",
      "|    policy_gradient_loss | -0.0322     |\n",
      "|    value_loss           | 3.09e-05    |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                   |           |\n",
      "|    fps                  | 152       |\n",
      "|    iterations           | 1034      |\n",
      "|    time_elapsed         | 13868     |\n",
      "|    total_timesteps      | 2117632   |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0195395 |\n",
      "|    clip_fraction        | 0.366     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -1.39     |\n",
      "|    explained_variance   | 0.647     |\n",
      "|    learning_rate        | 0.0003    |\n",
      "|    loss                 | -0.0489   |\n",
      "|    n_updates            | 10330     |\n",
      "|    policy_gradient_loss | -0.029    |\n",
      "|    value_loss           | 4.83e-05  |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 152         |\n",
      "|    iterations           | 1035        |\n",
      "|    time_elapsed         | 13873       |\n",
      "|    total_timesteps      | 2119680     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016226992 |\n",
      "|    clip_fraction        | 0.289       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.43       |\n",
      "|    explained_variance   | 0.847       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0296     |\n",
      "|    n_updates            | 10340       |\n",
      "|    policy_gradient_loss | -0.025      |\n",
      "|    value_loss           | 3.43e-05    |\n",
      "-----------------------------------------\n",
      "box reached target\n",
      "Eval num_timesteps=2120000, episode_reward=1.03 +/- 2.06\n",
      "Episode length: 8063.40 +/- 3873.20\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 8.06e+03    |\n",
      "|    mean_reward          | 1.03        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2120000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015627014 |\n",
      "|    clip_fraction        | 0.254       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.41       |\n",
      "|    explained_variance   | 0.801       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0122     |\n",
      "|    n_updates            | 10350       |\n",
      "|    policy_gradient_loss | -0.0174     |\n",
      "|    value_loss           | 2.99e-05    |\n",
      "-----------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 152     |\n",
      "|    iterations      | 1036    |\n",
      "|    time_elapsed    | 13913   |\n",
      "|    total_timesteps | 2121728 |\n",
      "--------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 152          |\n",
      "|    iterations           | 1037         |\n",
      "|    time_elapsed         | 13918        |\n",
      "|    total_timesteps      | 2123776      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0155988075 |\n",
      "|    clip_fraction        | 0.224        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.01        |\n",
      "|    explained_variance   | 0.782        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0285      |\n",
      "|    n_updates            | 10360        |\n",
      "|    policy_gradient_loss | -0.0142      |\n",
      "|    value_loss           | 0.000698     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 152         |\n",
      "|    iterations           | 1038        |\n",
      "|    time_elapsed         | 13924       |\n",
      "|    total_timesteps      | 2125824     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018477954 |\n",
      "|    clip_fraction        | 0.319       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.18       |\n",
      "|    explained_variance   | 0.711       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0241     |\n",
      "|    n_updates            | 10370       |\n",
      "|    policy_gradient_loss | -0.0193     |\n",
      "|    value_loss           | 0.000573    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 152         |\n",
      "|    iterations           | 1039        |\n",
      "|    time_elapsed         | 13929       |\n",
      "|    total_timesteps      | 2127872     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016353847 |\n",
      "|    clip_fraction        | 0.272       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.31       |\n",
      "|    explained_variance   | 0.167       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00322     |\n",
      "|    n_updates            | 10380       |\n",
      "|    policy_gradient_loss | -0.0195     |\n",
      "|    value_loss           | 9.41e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 152         |\n",
      "|    iterations           | 1040        |\n",
      "|    time_elapsed         | 13935       |\n",
      "|    total_timesteps      | 2129920     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012534125 |\n",
      "|    clip_fraction        | 0.243       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.31       |\n",
      "|    explained_variance   | -0.162      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.018      |\n",
      "|    n_updates            | 10390       |\n",
      "|    policy_gradient_loss | -0.0116     |\n",
      "|    value_loss           | 6.37e-05    |\n",
      "-----------------------------------------\n",
      "box reached target\n",
      "box reached target\n",
      "box reached target\n",
      "Eval num_timesteps=2130000, episode_reward=3.08 +/- 2.52\n",
      "Episode length: 4157.00 +/- 4771.06\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 4.16e+03    |\n",
      "|    mean_reward          | 3.08        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2130000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011587253 |\n",
      "|    clip_fraction        | 0.182       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.3        |\n",
      "|    explained_variance   | 0.302       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0228     |\n",
      "|    n_updates            | 10400       |\n",
      "|    policy_gradient_loss | -0.00898    |\n",
      "|    value_loss           | 2.87e-05    |\n",
      "-----------------------------------------\n",
      "box reached target\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 152     |\n",
      "|    iterations      | 1041    |\n",
      "|    time_elapsed    | 13958   |\n",
      "|    total_timesteps | 2131968 |\n",
      "--------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 152         |\n",
      "|    iterations           | 1042        |\n",
      "|    time_elapsed         | 13963       |\n",
      "|    total_timesteps      | 2134016     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014593221 |\n",
      "|    clip_fraction        | 0.118       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.24       |\n",
      "|    explained_variance   | 0.344       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0158     |\n",
      "|    n_updates            | 10410       |\n",
      "|    policy_gradient_loss | -0.00945    |\n",
      "|    value_loss           | 0.0304      |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 152          |\n",
      "|    iterations           | 1043         |\n",
      "|    time_elapsed         | 13969        |\n",
      "|    total_timesteps      | 2136064      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0097324215 |\n",
      "|    clip_fraction        | 0.167        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.33        |\n",
      "|    explained_variance   | 0.802        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.008       |\n",
      "|    n_updates            | 10420        |\n",
      "|    policy_gradient_loss | -0.0122      |\n",
      "|    value_loss           | 0.000184     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 152         |\n",
      "|    iterations           | 1044        |\n",
      "|    time_elapsed         | 13974       |\n",
      "|    total_timesteps      | 2138112     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010826202 |\n",
      "|    clip_fraction        | 0.1         |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.44       |\n",
      "|    explained_variance   | 0.94        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0288     |\n",
      "|    n_updates            | 10430       |\n",
      "|    policy_gradient_loss | -0.0055     |\n",
      "|    value_loss           | 9.71e-05    |\n",
      "-----------------------------------------\n",
      "box reached target\n",
      "Eval num_timesteps=2140000, episode_reward=1.07 +/- 2.13\n",
      "Episode length: 8113.60 +/- 3772.80\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 8.11e+03    |\n",
      "|    mean_reward          | 1.07        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2140000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013065507 |\n",
      "|    clip_fraction        | 0.162       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.47       |\n",
      "|    explained_variance   | 0.949       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00746     |\n",
      "|    n_updates            | 10440       |\n",
      "|    policy_gradient_loss | -0.0167     |\n",
      "|    value_loss           | 3.12e-05    |\n",
      "-----------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 152     |\n",
      "|    iterations      | 1045    |\n",
      "|    time_elapsed    | 14014   |\n",
      "|    total_timesteps | 2140160 |\n",
      "--------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 152        |\n",
      "|    iterations           | 1046       |\n",
      "|    time_elapsed         | 14020      |\n",
      "|    total_timesteps      | 2142208    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01130718 |\n",
      "|    clip_fraction        | 0.128      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.41      |\n",
      "|    explained_variance   | 0.723      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0205    |\n",
      "|    n_updates            | 10450      |\n",
      "|    policy_gradient_loss | -0.00599   |\n",
      "|    value_loss           | 0.0011     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 152        |\n",
      "|    iterations           | 1047       |\n",
      "|    time_elapsed         | 14025      |\n",
      "|    total_timesteps      | 2144256    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02938807 |\n",
      "|    clip_fraction        | 0.215      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.36      |\n",
      "|    explained_variance   | 0.681      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0299    |\n",
      "|    n_updates            | 10460      |\n",
      "|    policy_gradient_loss | -0.00828   |\n",
      "|    value_loss           | 0.000147   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 152         |\n",
      "|    iterations           | 1048        |\n",
      "|    time_elapsed         | 14030       |\n",
      "|    total_timesteps      | 2146304     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008695735 |\n",
      "|    clip_fraction        | 0.072       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.48       |\n",
      "|    explained_variance   | 0.932       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0133     |\n",
      "|    n_updates            | 10470       |\n",
      "|    policy_gradient_loss | -0.00533    |\n",
      "|    value_loss           | 2.4e-05     |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 153          |\n",
      "|    iterations           | 1049         |\n",
      "|    time_elapsed         | 14036        |\n",
      "|    total_timesteps      | 2148352      |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0104183275 |\n",
      "|    clip_fraction        | 0.111        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.42        |\n",
      "|    explained_variance   | 0.953        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.0248      |\n",
      "|    n_updates            | 10480        |\n",
      "|    policy_gradient_loss | -0.00715     |\n",
      "|    value_loss           | 4.58e-06     |\n",
      "------------------------------------------\n",
      "Eval num_timesteps=2150000, episode_reward=0.03 +/- 0.07\n",
      "Episode length: 10000.00 +/- 0.00\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 1e+04       |\n",
      "|    mean_reward          | 0.0348      |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2150000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013703136 |\n",
      "|    clip_fraction        | 0.24        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.43       |\n",
      "|    explained_variance   | 0.945       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0432     |\n",
      "|    n_updates            | 10490       |\n",
      "|    policy_gradient_loss | -0.0155     |\n",
      "|    value_loss           | 2.31e-06    |\n",
      "-----------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 152     |\n",
      "|    iterations      | 1050    |\n",
      "|    time_elapsed    | 14084   |\n",
      "|    total_timesteps | 2150400 |\n",
      "--------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 152         |\n",
      "|    iterations           | 1051        |\n",
      "|    time_elapsed         | 14089       |\n",
      "|    total_timesteps      | 2152448     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032534894 |\n",
      "|    clip_fraction        | 0.231       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.29       |\n",
      "|    explained_variance   | 0.722       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.00342    |\n",
      "|    n_updates            | 10500       |\n",
      "|    policy_gradient_loss | -0.0101     |\n",
      "|    value_loss           | 0.00035     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 152         |\n",
      "|    iterations           | 1052        |\n",
      "|    time_elapsed         | 14095       |\n",
      "|    total_timesteps      | 2154496     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012760835 |\n",
      "|    clip_fraction        | 0.178       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.19       |\n",
      "|    explained_variance   | 0.599       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0226     |\n",
      "|    n_updates            | 10510       |\n",
      "|    policy_gradient_loss | -0.0159     |\n",
      "|    value_loss           | 5.55e-05    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 152         |\n",
      "|    iterations           | 1053        |\n",
      "|    time_elapsed         | 14100       |\n",
      "|    total_timesteps      | 2156544     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019680325 |\n",
      "|    clip_fraction        | 0.335       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.29       |\n",
      "|    explained_variance   | -0.532      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0255     |\n",
      "|    n_updates            | 10520       |\n",
      "|    policy_gradient_loss | -0.0191     |\n",
      "|    value_loss           | 3e-06       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 153         |\n",
      "|    iterations           | 1054        |\n",
      "|    time_elapsed         | 14105       |\n",
      "|    total_timesteps      | 2158592     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013501125 |\n",
      "|    clip_fraction        | 0.206       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.35       |\n",
      "|    explained_variance   | 0.892       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0139     |\n",
      "|    n_updates            | 10530       |\n",
      "|    policy_gradient_loss | -0.0187     |\n",
      "|    value_loss           | 2.27e-06    |\n",
      "-----------------------------------------\n",
      "box reached target\n",
      "Eval num_timesteps=2160000, episode_reward=1.16 +/- 2.06\n",
      "Episode length: 8085.80 +/- 3828.40\n",
      "-----------------------------------------\n",
      "| eval/                   |             |\n",
      "|    mean_ep_length       | 8.09e+03    |\n",
      "|    mean_reward          | 1.16        |\n",
      "| time/                   |             |\n",
      "|    total_timesteps      | 2160000     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010262337 |\n",
      "|    clip_fraction        | 0.116       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.31       |\n",
      "|    explained_variance   | 0.795       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0233     |\n",
      "|    n_updates            | 10540       |\n",
      "|    policy_gradient_loss | -0.00929    |\n",
      "|    value_loss           | 8.79e-07    |\n",
      "-----------------------------------------\n",
      "--------------------------------\n",
      "| time/              |         |\n",
      "|    fps             | 152     |\n",
      "|    iterations      | 1055    |\n",
      "|    time_elapsed    | 14145   |\n",
      "|    total_timesteps | 2160640 |\n",
      "--------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 152        |\n",
      "|    iterations           | 1056       |\n",
      "|    time_elapsed         | 14151      |\n",
      "|    total_timesteps      | 2162688    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01892418 |\n",
      "|    clip_fraction        | 0.137      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.2       |\n",
      "|    explained_variance   | 0.93       |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.00755   |\n",
      "|    n_updates            | 10550      |\n",
      "|    policy_gradient_loss | -0.0114    |\n",
      "|    value_loss           | 0.000946   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 152        |\n",
      "|    iterations           | 1057       |\n",
      "|    time_elapsed         | 14156      |\n",
      "|    total_timesteps      | 2164736    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01414212 |\n",
      "|    clip_fraction        | 0.206      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.15      |\n",
      "|    explained_variance   | 0.922      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0178    |\n",
      "|    n_updates            | 10560      |\n",
      "|    policy_gradient_loss | -0.02      |\n",
      "|    value_loss           | 0.000152   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 152         |\n",
      "|    iterations           | 1058        |\n",
      "|    time_elapsed         | 14162       |\n",
      "|    total_timesteps      | 2166784     |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010988624 |\n",
      "|    clip_fraction        | 0.126       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.11       |\n",
      "|    explained_variance   | 0.545       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0134     |\n",
      "|    n_updates            | 10570       |\n",
      "|    policy_gradient_loss | -0.0143     |\n",
      "|    value_loss           | 0.000224    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 153        |\n",
      "|    iterations           | 1059       |\n",
      "|    time_elapsed         | 14167      |\n",
      "|    total_timesteps      | 2168832    |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01767922 |\n",
      "|    clip_fraction        | 0.344      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.2       |\n",
      "|    explained_variance   | 0.456      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | -0.0365    |\n",
      "|    n_updates            | 10580      |\n",
      "|    policy_gradient_loss | -0.0285    |\n",
      "|    value_loss           | 0.000342   |\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model.learn(total_timesteps=10000000, callback=eval_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PPO_Path = os.path.join('Training', 'SavedModels', 'PPO_63_10M_360_linear_no_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(PPO_Path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PPO.load(PPO_Path, env=env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.08709977669059299, 0.17684880647524429)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_policy(model, env, n_eval_episodes=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dan",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
