CUDA_VISIBLE_DEVICES: 4,5
Activating TensorFlow-2.6.2 environment
Running clusterTrain.py
pybullet build time: Nov 28 2023 23:48:36
Using cuda device
Logging to Training/clusterResults/clusterLogs/PPO_19
-----------------------------
| time/              |      |
|    fps             | 951  |
|    iterations      | 1    |
|    time_elapsed    | 2    |
|    total_timesteps | 2048 |
-----------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 757         |
|    iterations           | 2           |
|    time_elapsed         | 5           |
|    total_timesteps      | 4096        |
| train/                  |             |
|    approx_kl            | 0.013598622 |
|    clip_fraction        | 0.141       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.88       |
|    explained_variance   | 0.876       |
|    learning_rate        | 0.002       |
|    loss                 | -0.0205     |
|    n_updates            | 10          |
|    policy_gradient_loss | -0.00572    |
|    std                  | 1.03        |
|    value_loss           | 0.0169      |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 722         |
|    iterations           | 3           |
|    time_elapsed         | 8           |
|    total_timesteps      | 6144        |
| train/                  |             |
|    approx_kl            | 0.009988245 |
|    clip_fraction        | 0.0835      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.92       |
|    explained_variance   | 0.895       |
|    learning_rate        | 0.002       |
|    loss                 | 0.0187      |
|    n_updates            | 20          |
|    policy_gradient_loss | -0.0045     |
|    std                  | 1.05        |
|    value_loss           | 0.00545     |
-----------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 706          |
|    iterations           | 4            |
|    time_elapsed         | 11           |
|    total_timesteps      | 8192         |
| train/                  |              |
|    approx_kl            | 0.0055681323 |
|    clip_fraction        | 0.0591       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.93        |
|    explained_variance   | 0.899        |
|    learning_rate        | 0.002        |
|    loss                 | 0.00253      |
|    n_updates            | 30           |
|    policy_gradient_loss | -0.00106     |
|    std                  | 1.05         |
|    value_loss           | 0.00609      |
------------------------------------------
/home/tmorgan01/anaconda3/envs/dan/lib/python3.11/site-packages/stable_baselines3/common/evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.
  warnings.warn(
Eval num_timesteps=10000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 300          |
|    mean_reward          | -1           |
| time/                   |              |
|    total_timesteps      | 10000        |
| train/                  |              |
|    approx_kl            | 0.0067120064 |
|    clip_fraction        | 0.0867       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.89        |
|    explained_variance   | 0.891        |
|    learning_rate        | 0.002        |
|    loss                 | 0.00819      |
|    n_updates            | 40           |
|    policy_gradient_loss | -0.00336     |
|    std                  | 1.02         |
|    value_loss           | 0.00285      |
------------------------------------------
New best mean reward!
------------------------------
| time/              |       |
|    fps             | 652   |
|    iterations      | 5     |
|    time_elapsed    | 15    |
|    total_timesteps | 10240 |
------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 653          |
|    iterations           | 6            |
|    time_elapsed         | 18           |
|    total_timesteps      | 12288        |
| train/                  |              |
|    approx_kl            | 0.0051785167 |
|    clip_fraction        | 0.0674       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.89        |
|    explained_variance   | 0.901        |
|    learning_rate        | 0.002        |
|    loss                 | -0.00664     |
|    n_updates            | 50           |
|    policy_gradient_loss | -0.00261     |
|    std                  | 1.04         |
|    value_loss           | 0.00185      |
------------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 654         |
|    iterations           | 7           |
|    time_elapsed         | 21          |
|    total_timesteps      | 14336       |
| train/                  |             |
|    approx_kl            | 0.008734048 |
|    clip_fraction        | 0.0739      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.85       |
|    explained_variance   | 0.891       |
|    learning_rate        | 0.002       |
|    loss                 | -0.0194     |
|    n_updates            | 60          |
|    policy_gradient_loss | -0.00228    |
|    std                  | 1           |
|    value_loss           | 0.00314     |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 654         |
|    iterations           | 8           |
|    time_elapsed         | 25          |
|    total_timesteps      | 16384       |
| train/                  |             |
|    approx_kl            | 0.013238723 |
|    clip_fraction        | 0.135       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.83       |
|    explained_variance   | 0.892       |
|    learning_rate        | 0.002       |
|    loss                 | -0.0156     |
|    n_updates            | 70          |
|    policy_gradient_loss | -0.00585    |
|    std                  | 0.993       |
|    value_loss           | 0.00309     |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 655         |
|    iterations           | 9           |
|    time_elapsed         | 28          |
|    total_timesteps      | 18432       |
| train/                  |             |
|    approx_kl            | 0.007881136 |
|    clip_fraction        | 0.0742      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.86       |
|    explained_variance   | 0.875       |
|    learning_rate        | 0.002       |
|    loss                 | 0.00222     |
|    n_updates            | 80          |
|    policy_gradient_loss | -0.00292    |
|    std                  | 1.01        |
|    value_loss           | 0.0019      |
-----------------------------------------
Eval num_timesteps=20000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 300          |
|    mean_reward          | -1           |
| time/                   |              |
|    total_timesteps      | 20000        |
| train/                  |              |
|    approx_kl            | 0.0117550455 |
|    clip_fraction        | 0.151        |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.84        |
|    explained_variance   | 0.829        |
|    learning_rate        | 0.002        |
|    loss                 | -0.006       |
|    n_updates            | 90           |
|    policy_gradient_loss | -0.00762     |
|    std                  | 0.998        |
|    value_loss           | 0.00153      |
------------------------------------------
------------------------------
| time/              |       |
|    fps             | 635   |
|    iterations      | 10    |
|    time_elapsed    | 32    |
|    total_timesteps | 20480 |
------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 637         |
|    iterations           | 11          |
|    time_elapsed         | 35          |
|    total_timesteps      | 22528       |
| train/                  |             |
|    approx_kl            | 0.011571644 |
|    clip_fraction        | 0.137       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.81       |
|    explained_variance   | 0.871       |
|    learning_rate        | 0.002       |
|    loss                 | 0.0334      |
|    n_updates            | 100         |
|    policy_gradient_loss | -0.00741    |
|    std                  | 0.978       |
|    value_loss           | 0.000966    |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 638         |
|    iterations           | 12          |
|    time_elapsed         | 38          |
|    total_timesteps      | 24576       |
| train/                  |             |
|    approx_kl            | 0.009882607 |
|    clip_fraction        | 0.106       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.78       |
|    explained_variance   | 0.88        |
|    learning_rate        | 0.002       |
|    loss                 | 0.00492     |
|    n_updates            | 110         |
|    policy_gradient_loss | -0.0045     |
|    std                  | 0.969       |
|    value_loss           | 0.00226     |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 640         |
|    iterations           | 13          |
|    time_elapsed         | 41          |
|    total_timesteps      | 26624       |
| train/                  |             |
|    approx_kl            | 0.008207198 |
|    clip_fraction        | 0.105       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.79       |
|    explained_variance   | 0.861       |
|    learning_rate        | 0.002       |
|    loss                 | 0.00683     |
|    n_updates            | 120         |
|    policy_gradient_loss | -0.00429    |
|    std                  | 0.979       |
|    value_loss           | 0.00161     |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 641         |
|    iterations           | 14          |
|    time_elapsed         | 44          |
|    total_timesteps      | 28672       |
| train/                  |             |
|    approx_kl            | 0.010092314 |
|    clip_fraction        | 0.126       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.79       |
|    explained_variance   | 0.811       |
|    learning_rate        | 0.00199     |
|    loss                 | -0.0196     |
|    n_updates            | 130         |
|    policy_gradient_loss | -0.0052     |
|    std                  | 0.973       |
|    value_loss           | 0.00176     |
-----------------------------------------
Eval num_timesteps=30000, episode_reward=-0.66 +/- 0.43
Episode length: 300.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 300         |
|    mean_reward          | -0.66       |
| time/                   |             |
|    total_timesteps      | 30000       |
| train/                  |             |
|    approx_kl            | 0.013313074 |
|    clip_fraction        | 0.113       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.73       |
|    explained_variance   | 0.83        |
|    learning_rate        | 0.00199     |
|    loss                 | 0.019       |
|    n_updates            | 140         |
|    policy_gradient_loss | -0.00571    |
|    std                  | 0.944       |
|    value_loss           | 0.000489    |
-----------------------------------------
New best mean reward!
------------------------------
| time/              |       |
|    fps             | 630   |
|    iterations      | 15    |
|    time_elapsed    | 48    |
|    total_timesteps | 30720 |
------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 632         |
|    iterations           | 16          |
|    time_elapsed         | 51          |
|    total_timesteps      | 32768       |
| train/                  |             |
|    approx_kl            | 0.009357597 |
|    clip_fraction        | 0.0958      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.66       |
|    explained_variance   | 0.787       |
|    learning_rate        | 0.00199     |
|    loss                 | -0.0378     |
|    n_updates            | 150         |
|    policy_gradient_loss | -0.00199    |
|    std                  | 0.912       |
|    value_loss           | 0.000909    |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 634         |
|    iterations           | 17          |
|    time_elapsed         | 54          |
|    total_timesteps      | 34816       |
| train/                  |             |
|    approx_kl            | 0.010530606 |
|    clip_fraction        | 0.106       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.62       |
|    explained_variance   | 0.92        |
|    learning_rate        | 0.00199     |
|    loss                 | 0.00197     |
|    n_updates            | 160         |
|    policy_gradient_loss | -0.000252   |
|    std                  | 0.888       |
|    value_loss           | 0.00133     |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 635         |
|    iterations           | 18          |
|    time_elapsed         | 57          |
|    total_timesteps      | 36864       |
| train/                  |             |
|    approx_kl            | 0.013202386 |
|    clip_fraction        | 0.147       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.63       |
|    explained_variance   | 0.835       |
|    learning_rate        | 0.00199     |
|    loss                 | -0.009      |
|    n_updates            | 170         |
|    policy_gradient_loss | -0.00394    |
|    std                  | 0.909       |
|    value_loss           | 0.000615    |
-----------------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 637         |
|    iterations           | 19          |
|    time_elapsed         | 61          |
|    total_timesteps      | 38912       |
| train/                  |             |
|    approx_kl            | 0.010570178 |
|    clip_fraction        | 0.14        |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.62       |
|    explained_variance   | 0.897       |
|    learning_rate        | 0.00199     |
|    loss                 | -0.0263     |
|    n_updates            | 180         |
|    policy_gradient_loss | -0.00412    |
|    std                  | 0.898       |
|    value_loss           | 0.000453    |
-----------------------------------------
box reached target
Eval num_timesteps=40000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 300          |
|    mean_reward          | -1           |
| time/                   |              |
|    total_timesteps      | 40000        |
| train/                  |              |
|    approx_kl            | 0.0076996647 |
|    clip_fraction        | 0.0957       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.58        |
|    explained_variance   | 0.109        |
|    learning_rate        | 0.00199      |
|    loss                 | 0.00935      |
|    n_updates            | 190          |
|    policy_gradient_loss | -0.00217     |
|    std                  | 0.873        |
|    value_loss           | 0.0393       |
------------------------------------------
------------------------------
| time/              |       |
|    fps             | 628   |
|    iterations      | 20    |
|    time_elapsed    | 65    |
|    total_timesteps | 40960 |
------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 630          |
|    iterations           | 21           |
|    time_elapsed         | 68           |
|    total_timesteps      | 43008        |
| train/                  |              |
|    approx_kl            | 0.0075285826 |
|    clip_fraction        | 0.0941       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.54        |
|    explained_variance   | 0.615        |
|    learning_rate        | 0.00199      |
|    loss                 | 0.00187      |
|    n_updates            | 200          |
|    policy_gradient_loss | -0.00125     |
|    std                  | 0.862        |
|    value_loss           | 0.0111       |
------------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 631         |
|    iterations           | 22          |
|    time_elapsed         | 71          |
|    total_timesteps      | 45056       |
| train/                  |             |
|    approx_kl            | 0.012021099 |
|    clip_fraction        | 0.13        |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.49       |
|    explained_variance   | 0.881       |
|    learning_rate        | 0.00199     |
|    loss                 | -0.00949    |
|    n_updates            | 210         |
|    policy_gradient_loss | -0.00569    |
|    std                  | 0.836       |
|    value_loss           | 0.00199     |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 630         |
|    iterations           | 23          |
|    time_elapsed         | 74          |
|    total_timesteps      | 47104       |
| train/                  |             |
|    approx_kl            | 0.012898052 |
|    clip_fraction        | 0.167       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.45       |
|    explained_variance   | 0.893       |
|    learning_rate        | 0.00199     |
|    loss                 | -0.0141     |
|    n_updates            | 220         |
|    policy_gradient_loss | -0.00632    |
|    std                  | 0.821       |
|    value_loss           | 0.00312     |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 631         |
|    iterations           | 24          |
|    time_elapsed         | 77          |
|    total_timesteps      | 49152       |
| train/                  |             |
|    approx_kl            | 0.012563125 |
|    clip_fraction        | 0.148       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.4        |
|    explained_variance   | 0.685       |
|    learning_rate        | 0.00199     |
|    loss                 | -0.0158     |
|    n_updates            | 230         |
|    policy_gradient_loss | -0.00374    |
|    std                  | 0.795       |
|    value_loss           | 0.00286     |
-----------------------------------------
box reached target
Eval num_timesteps=50000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 300         |
|    mean_reward          | -1          |
| time/                   |             |
|    total_timesteps      | 50000       |
| train/                  |             |
|    approx_kl            | 0.009896236 |
|    clip_fraction        | 0.159       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.36       |
|    explained_variance   | 0.856       |
|    learning_rate        | 0.00199     |
|    loss                 | -0.0399     |
|    n_updates            | 240         |
|    policy_gradient_loss | -0.0063     |
|    std                  | 0.78        |
|    value_loss           | 0.00147     |
-----------------------------------------
------------------------------
| time/              |       |
|    fps             | 625   |
|    iterations      | 25    |
|    time_elapsed    | 81    |
|    total_timesteps | 51200 |
------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 627         |
|    iterations           | 26          |
|    time_elapsed         | 84          |
|    total_timesteps      | 53248       |
| train/                  |             |
|    approx_kl            | 0.009498933 |
|    clip_fraction        | 0.118       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.33       |
|    explained_variance   | 0.835       |
|    learning_rate        | 0.00199     |
|    loss                 | -0.0193     |
|    n_updates            | 250         |
|    policy_gradient_loss | 0.000236    |
|    std                  | 0.774       |
|    value_loss           | 0.0112      |
-----------------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 628         |
|    iterations           | 27          |
|    time_elapsed         | 88          |
|    total_timesteps      | 55296       |
| train/                  |             |
|    approx_kl            | 0.014862594 |
|    clip_fraction        | 0.193       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.29       |
|    explained_variance   | 0.867       |
|    learning_rate        | 0.00199     |
|    loss                 | -0.00226    |
|    n_updates            | 260         |
|    policy_gradient_loss | -0.00872    |
|    std                  | 0.758       |
|    value_loss           | 0.00072     |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 629         |
|    iterations           | 28          |
|    time_elapsed         | 91          |
|    total_timesteps      | 57344       |
| train/                  |             |
|    approx_kl            | 0.011047116 |
|    clip_fraction        | 0.106       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.31       |
|    explained_variance   | 0.975       |
|    learning_rate        | 0.00199     |
|    loss                 | -0.0298     |
|    n_updates            | 270         |
|    policy_gradient_loss | -0.00209    |
|    std                  | 0.77        |
|    value_loss           | 0.00279     |
-----------------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 630         |
|    iterations           | 29          |
|    time_elapsed         | 94          |
|    total_timesteps      | 59392       |
| train/                  |             |
|    approx_kl            | 0.011063945 |
|    clip_fraction        | 0.119       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.3        |
|    explained_variance   | 0.883       |
|    learning_rate        | 0.00199     |
|    loss                 | -0.0211     |
|    n_updates            | 280         |
|    policy_gradient_loss | -0.00299    |
|    std                  | 0.76        |
|    value_loss           | 0.0012      |
-----------------------------------------
Eval num_timesteps=60000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1         |
| time/                   |            |
|    total_timesteps      | 60000      |
| train/                  |            |
|    approx_kl            | 0.01116143 |
|    clip_fraction        | 0.103      |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.3       |
|    explained_variance   | 0.905      |
|    learning_rate        | 0.00199    |
|    loss                 | 0.0115     |
|    n_updates            | 290        |
|    policy_gradient_loss | 0.00219    |
|    std                  | 0.764      |
|    value_loss           | 0.0111     |
----------------------------------------
------------------------------
| time/              |       |
|    fps             | 625   |
|    iterations      | 30    |
|    time_elapsed    | 98    |
|    total_timesteps | 61440 |
------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 626         |
|    iterations           | 31          |
|    time_elapsed         | 101         |
|    total_timesteps      | 63488       |
| train/                  |             |
|    approx_kl            | 0.009677175 |
|    clip_fraction        | 0.116       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.3        |
|    explained_variance   | 0.781       |
|    learning_rate        | 0.00199     |
|    loss                 | -0.0104     |
|    n_updates            | 300         |
|    policy_gradient_loss | -0.00249    |
|    std                  | 0.766       |
|    value_loss           | 0.00247     |
-----------------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 627         |
|    iterations           | 32          |
|    time_elapsed         | 104         |
|    total_timesteps      | 65536       |
| train/                  |             |
|    approx_kl            | 0.006178215 |
|    clip_fraction        | 0.0805      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.31       |
|    explained_variance   | 0.9         |
|    learning_rate        | 0.00199     |
|    loss                 | 0.00666     |
|    n_updates            | 310         |
|    policy_gradient_loss | 0.00157     |
|    std                  | 0.766       |
|    value_loss           | 0.00204     |
-----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 628        |
|    iterations           | 33         |
|    time_elapsed         | 107        |
|    total_timesteps      | 67584      |
| train/                  |            |
|    approx_kl            | 0.01754253 |
|    clip_fraction        | 0.146      |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.25      |
|    explained_variance   | 0.978      |
|    learning_rate        | 0.00199    |
|    loss                 | 0.0572     |
|    n_updates            | 320        |
|    policy_gradient_loss | -0.00184   |
|    std                  | 0.738      |
|    value_loss           | 0.00155    |
----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 629         |
|    iterations           | 34          |
|    time_elapsed         | 110         |
|    total_timesteps      | 69632       |
| train/                  |             |
|    approx_kl            | 0.008537484 |
|    clip_fraction        | 0.0985      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.27       |
|    explained_variance   | 0.852       |
|    learning_rate        | 0.00199     |
|    loss                 | -0.00969    |
|    n_updates            | 330         |
|    policy_gradient_loss | -0.00253    |
|    std                  | 0.757       |
|    value_loss           | 0.000682    |
-----------------------------------------
Eval num_timesteps=70000, episode_reward=-0.72 +/- 0.56
Episode length: 300.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 300         |
|    mean_reward          | -0.718      |
| time/                   |             |
|    total_timesteps      | 70000       |
| train/                  |             |
|    approx_kl            | 0.011770941 |
|    clip_fraction        | 0.113       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.32       |
|    explained_variance   | 0.899       |
|    learning_rate        | 0.00199     |
|    loss                 | 0.0014      |
|    n_updates            | 340         |
|    policy_gradient_loss | -0.00254    |
|    std                  | 0.779       |
|    value_loss           | 0.00321     |
-----------------------------------------
------------------------------
| time/              |       |
|    fps             | 624   |
|    iterations      | 35    |
|    time_elapsed    | 114   |
|    total_timesteps | 71680 |
------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 625         |
|    iterations           | 36          |
|    time_elapsed         | 117         |
|    total_timesteps      | 73728       |
| train/                  |             |
|    approx_kl            | 0.010224316 |
|    clip_fraction        | 0.139       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.37       |
|    explained_variance   | 0.884       |
|    learning_rate        | 0.00199     |
|    loss                 | -0.0309     |
|    n_updates            | 350         |
|    policy_gradient_loss | -0.00844    |
|    std                  | 0.801       |
|    value_loss           | 0.00162     |
-----------------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 626         |
|    iterations           | 37          |
|    time_elapsed         | 120         |
|    total_timesteps      | 75776       |
| train/                  |             |
|    approx_kl            | 0.011071177 |
|    clip_fraction        | 0.125       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.42       |
|    explained_variance   | 0.917       |
|    learning_rate        | 0.00199     |
|    loss                 | -0.0109     |
|    n_updates            | 360         |
|    policy_gradient_loss | 0.000657    |
|    std                  | 0.814       |
|    value_loss           | 0.0113      |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 627         |
|    iterations           | 38          |
|    time_elapsed         | 123         |
|    total_timesteps      | 77824       |
| train/                  |             |
|    approx_kl            | 0.007664542 |
|    clip_fraction        | 0.105       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.42       |
|    explained_variance   | 0.932       |
|    learning_rate        | 0.00199     |
|    loss                 | -0.021      |
|    n_updates            | 370         |
|    policy_gradient_loss | 0.000954    |
|    std                  | 0.808       |
|    value_loss           | 0.00239     |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 628         |
|    iterations           | 39          |
|    time_elapsed         | 127         |
|    total_timesteps      | 79872       |
| train/                  |             |
|    approx_kl            | 0.009406395 |
|    clip_fraction        | 0.112       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.42       |
|    explained_variance   | 0.863       |
|    learning_rate        | 0.00198     |
|    loss                 | -0.000258   |
|    n_updates            | 380         |
|    policy_gradient_loss | -0.000638   |
|    std                  | 0.816       |
|    value_loss           | 0.000356    |
-----------------------------------------
box reached target
Eval num_timesteps=80000, episode_reward=0.22 +/- 2.43
Episode length: 292.60 +/- 14.80
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 293         |
|    mean_reward          | 0.216       |
| time/                   |             |
|    total_timesteps      | 80000       |
| train/                  |             |
|    approx_kl            | 0.012575112 |
|    clip_fraction        | 0.117       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.4        |
|    explained_variance   | 0.929       |
|    learning_rate        | 0.00198     |
|    loss                 | 0.00454     |
|    n_updates            | 390         |
|    policy_gradient_loss | -0.00303    |
|    std                  | 0.795       |
|    value_loss           | 0.000744    |
-----------------------------------------
New best mean reward!
------------------------------
| time/              |       |
|    fps             | 624   |
|    iterations      | 40    |
|    time_elapsed    | 131   |
|    total_timesteps | 81920 |
------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 625         |
|    iterations           | 41          |
|    time_elapsed         | 134         |
|    total_timesteps      | 83968       |
| train/                  |             |
|    approx_kl            | 0.010951842 |
|    clip_fraction        | 0.116       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.38       |
|    explained_variance   | 0.926       |
|    learning_rate        | 0.00198     |
|    loss                 | -0.0156     |
|    n_updates            | 400         |
|    policy_gradient_loss | -0.000223   |
|    std                  | 0.796       |
|    value_loss           | 0.000917    |
-----------------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 626         |
|    iterations           | 42          |
|    time_elapsed         | 137         |
|    total_timesteps      | 86016       |
| train/                  |             |
|    approx_kl            | 0.011582045 |
|    clip_fraction        | 0.139       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.36       |
|    explained_variance   | 0.796       |
|    learning_rate        | 0.00198     |
|    loss                 | -0.0279     |
|    n_updates            | 410         |
|    policy_gradient_loss | -0.00574    |
|    std                  | 0.787       |
|    value_loss           | 0.0006      |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 627         |
|    iterations           | 43          |
|    time_elapsed         | 140         |
|    total_timesteps      | 88064       |
| train/                  |             |
|    approx_kl            | 0.012134735 |
|    clip_fraction        | 0.119       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.42       |
|    explained_variance   | 0.787       |
|    learning_rate        | 0.00198     |
|    loss                 | -0.0158     |
|    n_updates            | 420         |
|    policy_gradient_loss | -0.00191    |
|    std                  | 0.824       |
|    value_loss           | 0.0102      |
-----------------------------------------
Eval num_timesteps=90000, episode_reward=-0.90 +/- 0.20
Episode length: 300.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 300         |
|    mean_reward          | -0.898      |
| time/                   |             |
|    total_timesteps      | 90000       |
| train/                  |             |
|    approx_kl            | 0.009395292 |
|    clip_fraction        | 0.104       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.46       |
|    explained_variance   | 0.832       |
|    learning_rate        | 0.00198     |
|    loss                 | 0.0212      |
|    n_updates            | 430         |
|    policy_gradient_loss | -0.000356   |
|    std                  | 0.831       |
|    value_loss           | 0.00103     |
-----------------------------------------
------------------------------
| time/              |       |
|    fps             | 623   |
|    iterations      | 44    |
|    time_elapsed    | 144   |
|    total_timesteps | 90112 |
------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 624         |
|    iterations           | 45          |
|    time_elapsed         | 147         |
|    total_timesteps      | 92160       |
| train/                  |             |
|    approx_kl            | 0.014069772 |
|    clip_fraction        | 0.139       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.47       |
|    explained_variance   | 0.717       |
|    learning_rate        | 0.00198     |
|    loss                 | 0.00138     |
|    n_updates            | 440         |
|    policy_gradient_loss | -0.00548    |
|    std                  | 0.823       |
|    value_loss           | 0.0017      |
-----------------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 625         |
|    iterations           | 46          |
|    time_elapsed         | 150         |
|    total_timesteps      | 94208       |
| train/                  |             |
|    approx_kl            | 0.009237899 |
|    clip_fraction        | 0.127       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.44       |
|    explained_variance   | 0.914       |
|    learning_rate        | 0.00198     |
|    loss                 | 0.0131      |
|    n_updates            | 450         |
|    policy_gradient_loss | 0.000673    |
|    std                  | 0.816       |
|    value_loss           | 0.00778     |
-----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 625        |
|    iterations           | 47         |
|    time_elapsed         | 153        |
|    total_timesteps      | 96256      |
| train/                  |            |
|    approx_kl            | 0.01187597 |
|    clip_fraction        | 0.135      |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.4       |
|    explained_variance   | 0.436      |
|    learning_rate        | 0.00198    |
|    loss                 | 0.0203     |
|    n_updates            | 460        |
|    policy_gradient_loss | 0.0014     |
|    std                  | 0.802      |
|    value_loss           | 0.0153     |
----------------------------------------
box reached target
box reached target
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 626         |
|    iterations           | 48          |
|    time_elapsed         | 156         |
|    total_timesteps      | 98304       |
| train/                  |             |
|    approx_kl            | 0.013157469 |
|    clip_fraction        | 0.137       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.37       |
|    explained_variance   | 0.907       |
|    learning_rate        | 0.00198     |
|    loss                 | -0.0245     |
|    n_updates            | 470         |
|    policy_gradient_loss | -0.00289    |
|    std                  | 0.784       |
|    value_loss           | 0.00309     |
-----------------------------------------
box reached target
box reached target
Eval num_timesteps=100000, episode_reward=0.27 +/- 2.54
Episode length: 281.80 +/- 36.40
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 282         |
|    mean_reward          | 0.269       |
| time/                   |             |
|    total_timesteps      | 100000      |
| train/                  |             |
|    approx_kl            | 0.011405396 |
|    clip_fraction        | 0.123       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.36       |
|    explained_variance   | 0.924       |
|    learning_rate        | 0.00198     |
|    loss                 | 0.0169      |
|    n_updates            | 480         |
|    policy_gradient_loss | -0.00199    |
|    std                  | 0.795       |
|    value_loss           | 0.0131      |
-----------------------------------------
New best mean reward!
-------------------------------
| time/              |        |
|    fps             | 623    |
|    iterations      | 49     |
|    time_elapsed    | 160    |
|    total_timesteps | 100352 |
-------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 624         |
|    iterations           | 50          |
|    time_elapsed         | 164         |
|    total_timesteps      | 102400      |
| train/                  |             |
|    approx_kl            | 0.010020124 |
|    clip_fraction        | 0.138       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.38       |
|    explained_variance   | 0.915       |
|    learning_rate        | 0.00198     |
|    loss                 | -0.00254    |
|    n_updates            | 490         |
|    policy_gradient_loss | -0.000213   |
|    std                  | 0.788       |
|    value_loss           | 0.00696     |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 625         |
|    iterations           | 51          |
|    time_elapsed         | 167         |
|    total_timesteps      | 104448      |
| train/                  |             |
|    approx_kl            | 0.010105567 |
|    clip_fraction        | 0.12        |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.38       |
|    explained_variance   | 0.898       |
|    learning_rate        | 0.00198     |
|    loss                 | -0.00589    |
|    n_updates            | 500         |
|    policy_gradient_loss | -0.00147    |
|    std                  | 0.795       |
|    value_loss           | 0.00343     |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 625         |
|    iterations           | 52          |
|    time_elapsed         | 170         |
|    total_timesteps      | 106496      |
| train/                  |             |
|    approx_kl            | 0.010522375 |
|    clip_fraction        | 0.132       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.37       |
|    explained_variance   | 0.864       |
|    learning_rate        | 0.00198     |
|    loss                 | 0.0139      |
|    n_updates            | 510         |
|    policy_gradient_loss | 0.000418    |
|    std                  | 0.787       |
|    value_loss           | 0.00126     |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 626         |
|    iterations           | 53          |
|    time_elapsed         | 173         |
|    total_timesteps      | 108544      |
| train/                  |             |
|    approx_kl            | 0.014342122 |
|    clip_fraction        | 0.155       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.35       |
|    explained_variance   | 0.854       |
|    learning_rate        | 0.00198     |
|    loss                 | -0.0133     |
|    n_updates            | 520         |
|    policy_gradient_loss | -0.00306    |
|    std                  | 0.783       |
|    value_loss           | 0.00101     |
-----------------------------------------
box reached target
Eval num_timesteps=110000, episode_reward=0.26 +/- 2.52
Episode length: 280.40 +/- 39.20
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 280         |
|    mean_reward          | 0.262       |
| time/                   |             |
|    total_timesteps      | 110000      |
| train/                  |             |
|    approx_kl            | 0.011980245 |
|    clip_fraction        | 0.138       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.31       |
|    explained_variance   | 0.925       |
|    learning_rate        | 0.00198     |
|    loss                 | 0.00609     |
|    n_updates            | 530         |
|    policy_gradient_loss | -0.00172    |
|    std                  | 0.763       |
|    value_loss           | 0.000426    |
-----------------------------------------
-------------------------------
| time/              |        |
|    fps             | 623    |
|    iterations      | 54     |
|    time_elapsed    | 177    |
|    total_timesteps | 110592 |
-------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 624         |
|    iterations           | 55          |
|    time_elapsed         | 180         |
|    total_timesteps      | 112640      |
| train/                  |             |
|    approx_kl            | 0.009463888 |
|    clip_fraction        | 0.133       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.32       |
|    explained_variance   | 0.835       |
|    learning_rate        | 0.00198     |
|    loss                 | -0.0229     |
|    n_updates            | 540         |
|    policy_gradient_loss | -0.000894   |
|    std                  | 0.774       |
|    value_loss           | 0.00273     |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 625         |
|    iterations           | 56          |
|    time_elapsed         | 183         |
|    total_timesteps      | 114688      |
| train/                  |             |
|    approx_kl            | 0.016798098 |
|    clip_fraction        | 0.137       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.3        |
|    explained_variance   | 0.793       |
|    learning_rate        | 0.00198     |
|    loss                 | -0.0298     |
|    n_updates            | 550         |
|    policy_gradient_loss | -0.00551    |
|    std                  | 0.768       |
|    value_loss           | 0.000537    |
-----------------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 625         |
|    iterations           | 57          |
|    time_elapsed         | 186         |
|    total_timesteps      | 116736      |
| train/                  |             |
|    approx_kl            | 0.014449948 |
|    clip_fraction        | 0.132       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.32       |
|    explained_variance   | 0.706       |
|    learning_rate        | 0.00198     |
|    loss                 | -0.0241     |
|    n_updates            | 560         |
|    policy_gradient_loss | -0.00384    |
|    std                  | 0.776       |
|    value_loss           | 0.00231     |
-----------------------------------------
box reached target
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 626         |
|    iterations           | 58          |
|    time_elapsed         | 189         |
|    total_timesteps      | 118784      |
| train/                  |             |
|    approx_kl            | 0.012681156 |
|    clip_fraction        | 0.136       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.32       |
|    explained_variance   | 0.791       |
|    learning_rate        | 0.00198     |
|    loss                 | -0.00582    |
|    n_updates            | 570         |
|    policy_gradient_loss | -0.00186    |
|    std                  | 0.767       |
|    value_loss           | 0.00715     |
-----------------------------------------
Eval num_timesteps=120000, episode_reward=-0.87 +/- 0.25
Episode length: 300.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 300         |
|    mean_reward          | -0.874      |
| time/                   |             |
|    total_timesteps      | 120000      |
| train/                  |             |
|    approx_kl            | 0.013534704 |
|    clip_fraction        | 0.13        |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.24       |
|    explained_variance   | 0.849       |
|    learning_rate        | 0.00198     |
|    loss                 | -0.0175     |
|    n_updates            | 580         |
|    policy_gradient_loss | -0.00164    |
|    std                  | 0.729       |
|    value_loss           | 0.00837     |
-----------------------------------------
-------------------------------
| time/              |        |
|    fps             | 623    |
|    iterations      | 59     |
|    time_elapsed    | 193    |
|    total_timesteps | 120832 |
-------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 624       |
|    iterations           | 60        |
|    time_elapsed         | 196       |
|    total_timesteps      | 122880    |
| train/                  |           |
|    approx_kl            | 0.0148236 |
|    clip_fraction        | 0.127     |
|    clip_range           | 0.2       |
|    entropy_loss         | -2.26     |
|    explained_variance   | 0.787     |
|    learning_rate        | 0.00198   |
|    loss                 | 0.0109    |
|    n_updates            | 590       |
|    policy_gradient_loss | -0.00335  |
|    std                  | 0.756     |
|    value_loss           | 0.00134   |
---------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 624         |
|    iterations           | 61          |
|    time_elapsed         | 199         |
|    total_timesteps      | 124928      |
| train/                  |             |
|    approx_kl            | 0.009932574 |
|    clip_fraction        | 0.117       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.27       |
|    explained_variance   | 0.903       |
|    learning_rate        | 0.00198     |
|    loss                 | -0.0165     |
|    n_updates            | 600         |
|    policy_gradient_loss | 0.00109     |
|    std                  | 0.75        |
|    value_loss           | 0.00074     |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 625         |
|    iterations           | 62          |
|    time_elapsed         | 203         |
|    total_timesteps      | 126976      |
| train/                  |             |
|    approx_kl            | 0.013001524 |
|    clip_fraction        | 0.13        |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.24       |
|    explained_variance   | 0.785       |
|    learning_rate        | 0.00198     |
|    loss                 | -0.0161     |
|    n_updates            | 610         |
|    policy_gradient_loss | -0.00152    |
|    std                  | 0.738       |
|    value_loss           | 0.000635    |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 625         |
|    iterations           | 63          |
|    time_elapsed         | 206         |
|    total_timesteps      | 129024      |
| train/                  |             |
|    approx_kl            | 0.011184598 |
|    clip_fraction        | 0.113       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.25       |
|    explained_variance   | 0.763       |
|    learning_rate        | 0.00198     |
|    loss                 | -0.0116     |
|    n_updates            | 620         |
|    policy_gradient_loss | 0.00204     |
|    std                  | 0.755       |
|    value_loss           | 0.0257      |
-----------------------------------------
Eval num_timesteps=130000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 300         |
|    mean_reward          | -1          |
| time/                   |             |
|    total_timesteps      | 130000      |
| train/                  |             |
|    approx_kl            | 0.016050177 |
|    clip_fraction        | 0.166       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.27       |
|    explained_variance   | 0.875       |
|    learning_rate        | 0.00197     |
|    loss                 | 0.0201      |
|    n_updates            | 630         |
|    policy_gradient_loss | -0.00141    |
|    std                  | 0.75        |
|    value_loss           | 0.000426    |
-----------------------------------------
-------------------------------
| time/              |        |
|    fps             | 623    |
|    iterations      | 64     |
|    time_elapsed    | 210    |
|    total_timesteps | 131072 |
-------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 624         |
|    iterations           | 65          |
|    time_elapsed         | 213         |
|    total_timesteps      | 133120      |
| train/                  |             |
|    approx_kl            | 0.014620276 |
|    clip_fraction        | 0.153       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.23       |
|    explained_variance   | 0.735       |
|    learning_rate        | 0.00197     |
|    loss                 | 0.0348      |
|    n_updates            | 640         |
|    policy_gradient_loss | -0.0018     |
|    std                  | 0.733       |
|    value_loss           | 0.002       |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 624         |
|    iterations           | 66          |
|    time_elapsed         | 216         |
|    total_timesteps      | 135168      |
| train/                  |             |
|    approx_kl            | 0.010455564 |
|    clip_fraction        | 0.14        |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.22       |
|    explained_variance   | 0.851       |
|    learning_rate        | 0.00197     |
|    loss                 | -0.00502    |
|    n_updates            | 650         |
|    policy_gradient_loss | -0.0035     |
|    std                  | 0.736       |
|    value_loss           | 0.000643    |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 625         |
|    iterations           | 67          |
|    time_elapsed         | 219         |
|    total_timesteps      | 137216      |
| train/                  |             |
|    approx_kl            | 0.011217989 |
|    clip_fraction        | 0.124       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.19       |
|    explained_variance   | 0.747       |
|    learning_rate        | 0.00197     |
|    loss                 | 0.00604     |
|    n_updates            | 660         |
|    policy_gradient_loss | -0.000211   |
|    std                  | 0.721       |
|    value_loss           | 0.000511    |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 625         |
|    iterations           | 68          |
|    time_elapsed         | 222         |
|    total_timesteps      | 139264      |
| train/                  |             |
|    approx_kl            | 0.011097396 |
|    clip_fraction        | 0.131       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.18       |
|    explained_variance   | 0.898       |
|    learning_rate        | 0.00197     |
|    loss                 | -0.0101     |
|    n_updates            | 670         |
|    policy_gradient_loss | -0.00105    |
|    std                  | 0.721       |
|    value_loss           | 0.000302    |
-----------------------------------------
Eval num_timesteps=140000, episode_reward=-0.68 +/- 0.64
Episode length: 300.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 300         |
|    mean_reward          | -0.679      |
| time/                   |             |
|    total_timesteps      | 140000      |
| train/                  |             |
|    approx_kl            | 0.007342848 |
|    clip_fraction        | 0.108       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.18       |
|    explained_variance   | 0.897       |
|    learning_rate        | 0.00197     |
|    loss                 | 0.0427      |
|    n_updates            | 680         |
|    policy_gradient_loss | -0.000688   |
|    std                  | 0.726       |
|    value_loss           | 0.000607    |
-----------------------------------------
-------------------------------
| time/              |        |
|    fps             | 623    |
|    iterations      | 69     |
|    time_elapsed    | 226    |
|    total_timesteps | 141312 |
-------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 624          |
|    iterations           | 70           |
|    time_elapsed         | 229          |
|    total_timesteps      | 143360       |
| train/                  |              |
|    approx_kl            | 0.0092297625 |
|    clip_fraction        | 0.128        |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.21        |
|    explained_variance   | 0.661        |
|    learning_rate        | 0.00197      |
|    loss                 | -0.00327     |
|    n_updates            | 690          |
|    policy_gradient_loss | 0.00247      |
|    std                  | 0.727        |
|    value_loss           | 0.00131      |
------------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 624         |
|    iterations           | 71          |
|    time_elapsed         | 232         |
|    total_timesteps      | 145408      |
| train/                  |             |
|    approx_kl            | 0.012296889 |
|    clip_fraction        | 0.121       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.15       |
|    explained_variance   | 0.816       |
|    learning_rate        | 0.00197     |
|    loss                 | -0.014      |
|    n_updates            | 700         |
|    policy_gradient_loss | -0.00082    |
|    std                  | 0.702       |
|    value_loss           | 0.00315     |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 624         |
|    iterations           | 72          |
|    time_elapsed         | 235         |
|    total_timesteps      | 147456      |
| train/                  |             |
|    approx_kl            | 0.009512646 |
|    clip_fraction        | 0.127       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.14       |
|    explained_variance   | 0.824       |
|    learning_rate        | 0.00197     |
|    loss                 | -0.0106     |
|    n_updates            | 710         |
|    policy_gradient_loss | 0.000815    |
|    std                  | 0.708       |
|    value_loss           | 0.000991    |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 625         |
|    iterations           | 73          |
|    time_elapsed         | 239         |
|    total_timesteps      | 149504      |
| train/                  |             |
|    approx_kl            | 0.012157306 |
|    clip_fraction        | 0.122       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.2        |
|    explained_variance   | 0.809       |
|    learning_rate        | 0.00197     |
|    loss                 | -0.0329     |
|    n_updates            | 720         |
|    policy_gradient_loss | -0.00139    |
|    std                  | 0.732       |
|    value_loss           | 0.000287    |
-----------------------------------------
box reached target
box reached target
Eval num_timesteps=150000, episode_reward=1.57 +/- 3.15
Episode length: 273.00 +/- 33.50
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 273        |
|    mean_reward          | 1.57       |
| time/                   |            |
|    total_timesteps      | 150000     |
| train/                  |            |
|    approx_kl            | 0.01222228 |
|    clip_fraction        | 0.149      |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.2       |
|    explained_variance   | 0.723      |
|    learning_rate        | 0.00197    |
|    loss                 | -0.0406    |
|    n_updates            | 730        |
|    policy_gradient_loss | 2.82e-05   |
|    std                  | 0.727      |
|    value_loss           | 0.000522   |
----------------------------------------
New best mean reward!
-------------------------------
| time/              |        |
|    fps             | 623    |
|    iterations      | 74     |
|    time_elapsed    | 243    |
|    total_timesteps | 151552 |
-------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 624         |
|    iterations           | 75          |
|    time_elapsed         | 246         |
|    total_timesteps      | 153600      |
| train/                  |             |
|    approx_kl            | 0.015851405 |
|    clip_fraction        | 0.129       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.21       |
|    explained_variance   | 0.678       |
|    learning_rate        | 0.00197     |
|    loss                 | 0.132       |
|    n_updates            | 740         |
|    policy_gradient_loss | -0.00246    |
|    std                  | 0.731       |
|    value_loss           | 0.000945    |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 624         |
|    iterations           | 76          |
|    time_elapsed         | 249         |
|    total_timesteps      | 155648      |
| train/                  |             |
|    approx_kl            | 0.017629262 |
|    clip_fraction        | 0.16        |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.23       |
|    explained_variance   | 0.638       |
|    learning_rate        | 0.00197     |
|    loss                 | 0.00277     |
|    n_updates            | 750         |
|    policy_gradient_loss | -0.0041     |
|    std                  | 0.741       |
|    value_loss           | 0.000309    |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 625         |
|    iterations           | 77          |
|    time_elapsed         | 252         |
|    total_timesteps      | 157696      |
| train/                  |             |
|    approx_kl            | 0.012466615 |
|    clip_fraction        | 0.132       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.23       |
|    explained_variance   | 0.848       |
|    learning_rate        | 0.00197     |
|    loss                 | -0.0146     |
|    n_updates            | 760         |
|    policy_gradient_loss | -9.05e-05   |
|    std                  | 0.736       |
|    value_loss           | 0.000188    |
-----------------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 625         |
|    iterations           | 78          |
|    time_elapsed         | 255         |
|    total_timesteps      | 159744      |
| train/                  |             |
|    approx_kl            | 0.012509975 |
|    clip_fraction        | 0.154       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.23       |
|    explained_variance   | 0.906       |
|    learning_rate        | 0.00197     |
|    loss                 | 0.00495     |
|    n_updates            | 770         |
|    policy_gradient_loss | 0.00217     |
|    std                  | 0.742       |
|    value_loss           | 0.000542    |
-----------------------------------------
Eval num_timesteps=160000, episode_reward=-0.79 +/- 0.42
Episode length: 300.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 300         |
|    mean_reward          | -0.792      |
| time/                   |             |
|    total_timesteps      | 160000      |
| train/                  |             |
|    approx_kl            | 0.021048399 |
|    clip_fraction        | 0.18        |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.17       |
|    explained_variance   | 0.514       |
|    learning_rate        | 0.00197     |
|    loss                 | -0.0145     |
|    n_updates            | 780         |
|    policy_gradient_loss | -0.00388    |
|    std                  | 0.704       |
|    value_loss           | 0.00752     |
-----------------------------------------
-------------------------------
| time/              |        |
|    fps             | 623    |
|    iterations      | 79     |
|    time_elapsed    | 259    |
|    total_timesteps | 161792 |
-------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 623         |
|    iterations           | 80          |
|    time_elapsed         | 262         |
|    total_timesteps      | 163840      |
| train/                  |             |
|    approx_kl            | 0.012129933 |
|    clip_fraction        | 0.138       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.15       |
|    explained_variance   | 0.723       |
|    learning_rate        | 0.00197     |
|    loss                 | 0.0149      |
|    n_updates            | 790         |
|    policy_gradient_loss | 3.38e-05    |
|    std                  | 0.714       |
|    value_loss           | 0.00289     |
-----------------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 624         |
|    iterations           | 81          |
|    time_elapsed         | 265         |
|    total_timesteps      | 165888      |
| train/                  |             |
|    approx_kl            | 0.009613331 |
|    clip_fraction        | 0.148       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.16       |
|    explained_variance   | 0.821       |
|    learning_rate        | 0.00197     |
|    loss                 | -0.035      |
|    n_updates            | 800         |
|    policy_gradient_loss | -0.00297    |
|    std                  | 0.713       |
|    value_loss           | 0.000361    |
-----------------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 624         |
|    iterations           | 82          |
|    time_elapsed         | 268         |
|    total_timesteps      | 167936      |
| train/                  |             |
|    approx_kl            | 0.014742354 |
|    clip_fraction        | 0.136       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.11       |
|    explained_variance   | 0.427       |
|    learning_rate        | 0.00197     |
|    loss                 | -0.0143     |
|    n_updates            | 810         |
|    policy_gradient_loss | 0.00153     |
|    std                  | 0.683       |
|    value_loss           | 0.0184      |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 625         |
|    iterations           | 83          |
|    time_elapsed         | 271         |
|    total_timesteps      | 169984      |
| train/                  |             |
|    approx_kl            | 0.015510826 |
|    clip_fraction        | 0.205       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.03       |
|    explained_variance   | 0.295       |
|    learning_rate        | 0.00197     |
|    loss                 | -0.0113     |
|    n_updates            | 820         |
|    policy_gradient_loss | 0.00661     |
|    std                  | 0.665       |
|    value_loss           | 0.0151      |
-----------------------------------------
Eval num_timesteps=170000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 300         |
|    mean_reward          | -1          |
| time/                   |             |
|    total_timesteps      | 170000      |
| train/                  |             |
|    approx_kl            | 0.020665742 |
|    clip_fraction        | 0.169       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.95       |
|    explained_variance   | 0.854       |
|    learning_rate        | 0.00197     |
|    loss                 | -0.0108     |
|    n_updates            | 830         |
|    policy_gradient_loss | -0.00266    |
|    std                  | 0.647       |
|    value_loss           | 0.00065     |
-----------------------------------------
box reached target
box reached target
-------------------------------
| time/              |        |
|    fps             | 623    |
|    iterations      | 84     |
|    time_elapsed    | 275    |
|    total_timesteps | 172032 |
-------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 623          |
|    iterations           | 85           |
|    time_elapsed         | 279          |
|    total_timesteps      | 174080       |
| train/                  |              |
|    approx_kl            | 0.0113568995 |
|    clip_fraction        | 0.154        |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.93        |
|    explained_variance   | 0.913        |
|    learning_rate        | 0.00197      |
|    loss                 | -0.0124      |
|    n_updates            | 840          |
|    policy_gradient_loss | -0.00137     |
|    std                  | 0.638        |
|    value_loss           | 0.00281      |
------------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 624       |
|    iterations           | 86        |
|    time_elapsed         | 282       |
|    total_timesteps      | 176128    |
| train/                  |           |
|    approx_kl            | 0.0779482 |
|    clip_fraction        | 0.204     |
|    clip_range           | 0.2       |
|    entropy_loss         | -1.91     |
|    explained_variance   | 0.871     |
|    learning_rate        | 0.00197   |
|    loss                 | 0.0132    |
|    n_updates            | 850       |
|    policy_gradient_loss | 0.00117   |
|    std                  | 0.626     |
|    value_loss           | 0.00132   |
---------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 624         |
|    iterations           | 87          |
|    time_elapsed         | 285         |
|    total_timesteps      | 178176      |
| train/                  |             |
|    approx_kl            | 0.013226133 |
|    clip_fraction        | 0.198       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.9        |
|    explained_variance   | 0.906       |
|    learning_rate        | 0.00197     |
|    loss                 | -0.00171    |
|    n_updates            | 860         |
|    policy_gradient_loss | -0.00348    |
|    std                  | 0.633       |
|    value_loss           | 0.0022      |
-----------------------------------------
box reached target
Eval num_timesteps=180000, episode_reward=-0.68 +/- 0.64
Episode length: 300.00 +/- 0.00
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 300          |
|    mean_reward          | -0.678       |
| time/                   |              |
|    total_timesteps      | 180000       |
| train/                  |              |
|    approx_kl            | 0.0130964685 |
|    clip_fraction        | 0.191        |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.94        |
|    explained_variance   | 0.794        |
|    learning_rate        | 0.00197      |
|    loss                 | -0.0282      |
|    n_updates            | 870          |
|    policy_gradient_loss | -0.00312     |
|    std                  | 0.647        |
|    value_loss           | 0.00105      |
------------------------------------------
-------------------------------
| time/              |        |
|    fps             | 623    |
|    iterations      | 88     |
|    time_elapsed    | 289    |
|    total_timesteps | 180224 |
-------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 623         |
|    iterations           | 89          |
|    time_elapsed         | 292         |
|    total_timesteps      | 182272      |
| train/                  |             |
|    approx_kl            | 0.014340246 |
|    clip_fraction        | 0.131       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.92       |
|    explained_variance   | 0.518       |
|    learning_rate        | 0.00196     |
|    loss                 | 0.00509     |
|    n_updates            | 880         |
|    policy_gradient_loss | 0.00265     |
|    std                  | 0.626       |
|    value_loss           | 0.0315      |
-----------------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 623         |
|    iterations           | 90          |
|    time_elapsed         | 295         |
|    total_timesteps      | 184320      |
| train/                  |             |
|    approx_kl            | 0.012818072 |
|    clip_fraction        | 0.137       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.91       |
|    explained_variance   | 0.886       |
|    learning_rate        | 0.00196     |
|    loss                 | -0.0248     |
|    n_updates            | 890         |
|    policy_gradient_loss | -0.00346    |
|    std                  | 0.634       |
|    value_loss           | 0.00603     |
-----------------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 624         |
|    iterations           | 91          |
|    time_elapsed         | 298         |
|    total_timesteps      | 186368      |
| train/                  |             |
|    approx_kl            | 0.012949407 |
|    clip_fraction        | 0.176       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.88       |
|    explained_variance   | 0.753       |
|    learning_rate        | 0.00196     |
|    loss                 | -0.000317   |
|    n_updates            | 900         |
|    policy_gradient_loss | 0.00178     |
|    std                  | 0.62        |
|    value_loss           | 0.0239      |
-----------------------------------------
box reached target
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 624         |
|    iterations           | 92          |
|    time_elapsed         | 301         |
|    total_timesteps      | 188416      |
| train/                  |             |
|    approx_kl            | 0.017192228 |
|    clip_fraction        | 0.172       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.84       |
|    explained_variance   | 0.903       |
|    learning_rate        | 0.00196     |
|    loss                 | 0.0223      |
|    n_updates            | 910         |
|    policy_gradient_loss | -0.000836   |
|    std                  | 0.618       |
|    value_loss           | 0.00769     |
-----------------------------------------
box reached target
Eval num_timesteps=190000, episode_reward=0.23 +/- 2.45
Episode length: 271.80 +/- 56.40
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 272         |
|    mean_reward          | 0.227       |
| time/                   |             |
|    total_timesteps      | 190000      |
| train/                  |             |
|    approx_kl            | 0.015956433 |
|    clip_fraction        | 0.188       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.78       |
|    explained_variance   | 0.868       |
|    learning_rate        | 0.00196     |
|    loss                 | 0.00762     |
|    n_updates            | 920         |
|    policy_gradient_loss | 0.000374    |
|    std                  | 0.591       |
|    value_loss           | 0.00856     |
-----------------------------------------
-------------------------------
| time/              |        |
|    fps             | 623    |
|    iterations      | 93     |
|    time_elapsed    | 305    |
|    total_timesteps | 190464 |
-------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 623         |
|    iterations           | 94          |
|    time_elapsed         | 308         |
|    total_timesteps      | 192512      |
| train/                  |             |
|    approx_kl            | 0.007944673 |
|    clip_fraction        | 0.113       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.8        |
|    explained_variance   | 0.907       |
|    learning_rate        | 0.00196     |
|    loss                 | -0.00161    |
|    n_updates            | 930         |
|    policy_gradient_loss | -3.66e-06   |
|    std                  | 0.602       |
|    value_loss           | 0.0024      |
-----------------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 624         |
|    iterations           | 95          |
|    time_elapsed         | 311         |
|    total_timesteps      | 194560      |
| train/                  |             |
|    approx_kl            | 0.018042808 |
|    clip_fraction        | 0.178       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.77       |
|    explained_variance   | 0.892       |
|    learning_rate        | 0.00196     |
|    loss                 | -0.0138     |
|    n_updates            | 940         |
|    policy_gradient_loss | -0.000609   |
|    std                  | 0.589       |
|    value_loss           | 0.00348     |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 624         |
|    iterations           | 96          |
|    time_elapsed         | 314         |
|    total_timesteps      | 196608      |
| train/                  |             |
|    approx_kl            | 0.015334834 |
|    clip_fraction        | 0.16        |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.79       |
|    explained_variance   | 0.819       |
|    learning_rate        | 0.00196     |
|    loss                 | 0.00185     |
|    n_updates            | 950         |
|    policy_gradient_loss | 0.00338     |
|    std                  | 0.597       |
|    value_loss           | 0.0181      |
-----------------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 624         |
|    iterations           | 97          |
|    time_elapsed         | 317         |
|    total_timesteps      | 198656      |
| train/                  |             |
|    approx_kl            | 0.019621026 |
|    clip_fraction        | 0.19        |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.73       |
|    explained_variance   | 0.865       |
|    learning_rate        | 0.00196     |
|    loss                 | -0.0188     |
|    n_updates            | 960         |
|    policy_gradient_loss | -0.00329    |
|    std                  | 0.574       |
|    value_loss           | 0.00149     |
-----------------------------------------
box reached target
Eval num_timesteps=200000, episode_reward=0.61 +/- 2.30
Episode length: 273.60 +/- 52.80
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 274         |
|    mean_reward          | 0.608       |
| time/                   |             |
|    total_timesteps      | 200000      |
| train/                  |             |
|    approx_kl            | 0.020183949 |
|    clip_fraction        | 0.174       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.68       |
|    explained_variance   | 0.897       |
|    learning_rate        | 0.00196     |
|    loss                 | -0.00553    |
|    n_updates            | 970         |
|    policy_gradient_loss | 0.00267     |
|    std                  | 0.558       |
|    value_loss           | 0.00367     |
-----------------------------------------
-------------------------------
| time/              |        |
|    fps             | 623    |
|    iterations      | 98     |
|    time_elapsed    | 321    |
|    total_timesteps | 200704 |
-------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 623         |
|    iterations           | 99          |
|    time_elapsed         | 325         |
|    total_timesteps      | 202752      |
| train/                  |             |
|    approx_kl            | 0.010931984 |
|    clip_fraction        | 0.117       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.73       |
|    explained_variance   | 0.928       |
|    learning_rate        | 0.00196     |
|    loss                 | 0.0419      |
|    n_updates            | 980         |
|    policy_gradient_loss | 0.00762     |
|    std                  | 0.582       |
|    value_loss           | 0.0033      |
-----------------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 624         |
|    iterations           | 100         |
|    time_elapsed         | 328         |
|    total_timesteps      | 204800      |
| train/                  |             |
|    approx_kl            | 0.013459876 |
|    clip_fraction        | 0.194       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.73       |
|    explained_variance   | 0.767       |
|    learning_rate        | 0.00196     |
|    loss                 | -0.013      |
|    n_updates            | 990         |
|    policy_gradient_loss | 0.000679    |
|    std                  | 0.572       |
|    value_loss           | 0.00238     |
-----------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 624          |
|    iterations           | 101          |
|    time_elapsed         | 331          |
|    total_timesteps      | 206848       |
| train/                  |              |
|    approx_kl            | 0.0137916915 |
|    clip_fraction        | 0.15         |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.75        |
|    explained_variance   | 0.909        |
|    learning_rate        | 0.00196      |
|    loss                 | 0.00436      |
|    n_updates            | 1000         |
|    policy_gradient_loss | -0.00075     |
|    std                  | 0.585        |
|    value_loss           | 0.00274      |
------------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 624         |
|    iterations           | 102         |
|    time_elapsed         | 334         |
|    total_timesteps      | 208896      |
| train/                  |             |
|    approx_kl            | 0.011949139 |
|    clip_fraction        | 0.136       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.78       |
|    explained_variance   | 0.837       |
|    learning_rate        | 0.00196     |
|    loss                 | 0.0345      |
|    n_updates            | 1010        |
|    policy_gradient_loss | 0.00305     |
|    std                  | 0.586       |
|    value_loss           | 0.00349     |
-----------------------------------------
Eval num_timesteps=210000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 300         |
|    mean_reward          | -1          |
| time/                   |             |
|    total_timesteps      | 210000      |
| train/                  |             |
|    approx_kl            | 0.016199946 |
|    clip_fraction        | 0.179       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.77       |
|    explained_variance   | 0.788       |
|    learning_rate        | 0.00196     |
|    loss                 | 0.00276     |
|    n_updates            | 1020        |
|    policy_gradient_loss | 0.00168     |
|    std                  | 0.588       |
|    value_loss           | 0.00207     |
-----------------------------------------
box reached target
-------------------------------
| time/              |        |
|    fps             | 623    |
|    iterations      | 103    |
|    time_elapsed    | 338    |
|    total_timesteps | 210944 |
-------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 623         |
|    iterations           | 104         |
|    time_elapsed         | 341         |
|    total_timesteps      | 212992      |
| train/                  |             |
|    approx_kl            | 0.020789273 |
|    clip_fraction        | 0.212       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.79       |
|    explained_variance   | 0.894       |
|    learning_rate        | 0.00196     |
|    loss                 | 0.0202      |
|    n_updates            | 1030        |
|    policy_gradient_loss | 0.00141     |
|    std                  | 0.6         |
|    value_loss           | 0.00622     |
-----------------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 624         |
|    iterations           | 105         |
|    time_elapsed         | 344         |
|    total_timesteps      | 215040      |
| train/                  |             |
|    approx_kl            | 0.018040642 |
|    clip_fraction        | 0.178       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.8        |
|    explained_variance   | 0.967       |
|    learning_rate        | 0.00196     |
|    loss                 | 0.0166      |
|    n_updates            | 1040        |
|    policy_gradient_loss | -0.00273    |
|    std                  | 0.593       |
|    value_loss           | 0.000913    |
-----------------------------------------
box reached target
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 624         |
|    iterations           | 106         |
|    time_elapsed         | 347         |
|    total_timesteps      | 217088      |
| train/                  |             |
|    approx_kl            | 0.013877906 |
|    clip_fraction        | 0.134       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.83       |
|    explained_variance   | 0.879       |
|    learning_rate        | 0.00196     |
|    loss                 | 0.0421      |
|    n_updates            | 1050        |
|    policy_gradient_loss | -0.00174    |
|    std                  | 0.614       |
|    value_loss           | 0.00529     |
-----------------------------------------
box reached target
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 624         |
|    iterations           | 107         |
|    time_elapsed         | 350         |
|    total_timesteps      | 219136      |
| train/                  |             |
|    approx_kl            | 0.017703883 |
|    clip_fraction        | 0.169       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.84       |
|    explained_variance   | 0.983       |
|    learning_rate        | 0.00196     |
|    loss                 | 0.0187      |
|    n_updates            | 1060        |
|    policy_gradient_loss | -0.00181    |
|    std                  | 0.61        |
|    value_loss           | 0.00129     |
-----------------------------------------
Eval num_timesteps=220000, episode_reward=-0.54 +/- 0.67
Episode length: 300.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 300         |
|    mean_reward          | -0.539      |
| time/                   |             |
|    total_timesteps      | 220000      |
| train/                  |             |
|    approx_kl            | 0.016588433 |
|    clip_fraction        | 0.177       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.86       |
|    explained_variance   | 0.886       |
|    learning_rate        | 0.00196     |
|    loss                 | -0.0127     |
|    n_updates            | 1070        |
|    policy_gradient_loss | 0.00188     |
|    std                  | 0.615       |
|    value_loss           | 0.00671     |
-----------------------------------------
-------------------------------
| time/              |        |
|    fps             | 623    |
|    iterations      | 108    |
|    time_elapsed    | 354    |
|    total_timesteps | 221184 |
-------------------------------
box reached target
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 623         |
|    iterations           | 109         |
|    time_elapsed         | 357         |
|    total_timesteps      | 223232      |
| train/                  |             |
|    approx_kl            | 0.016493749 |
|    clip_fraction        | 0.176       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.92       |
|    explained_variance   | 0.894       |
|    learning_rate        | 0.00196     |
|    loss                 | 0.0032      |
|    n_updates            | 1080        |
|    policy_gradient_loss | -0.00433    |
|    std                  | 0.643       |
|    value_loss           | 0.0033      |
-----------------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 623         |
|    iterations           | 110         |
|    time_elapsed         | 361         |
|    total_timesteps      | 225280      |
| train/                  |             |
|    approx_kl            | 0.014585091 |
|    clip_fraction        | 0.197       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.93       |
|    explained_variance   | 0.944       |
|    learning_rate        | 0.00196     |
|    loss                 | -0.00346    |
|    n_updates            | 1090        |
|    policy_gradient_loss | -0.00261    |
|    std                  | 0.639       |
|    value_loss           | 0.00747     |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 624         |
|    iterations           | 111         |
|    time_elapsed         | 364         |
|    total_timesteps      | 227328      |
| train/                  |             |
|    approx_kl            | 0.013257314 |
|    clip_fraction        | 0.159       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.91       |
|    explained_variance   | 0.883       |
|    learning_rate        | 0.00196     |
|    loss                 | -0.00915    |
|    n_updates            | 1100        |
|    policy_gradient_loss | -0.00442    |
|    std                  | 0.628       |
|    value_loss           | 0.0117      |
-----------------------------------------
box reached target
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 624         |
|    iterations           | 112         |
|    time_elapsed         | 367         |
|    total_timesteps      | 229376      |
| train/                  |             |
|    approx_kl            | 0.016897116 |
|    clip_fraction        | 0.178       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.88       |
|    explained_variance   | 0.849       |
|    learning_rate        | 0.00196     |
|    loss                 | 0.00975     |
|    n_updates            | 1110        |
|    policy_gradient_loss | 0.00142     |
|    std                  | 0.623       |
|    value_loss           | 0.00295     |
-----------------------------------------
Eval num_timesteps=230000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 300         |
|    mean_reward          | -1          |
| time/                   |             |
|    total_timesteps      | 230000      |
| train/                  |             |
|    approx_kl            | 0.019333664 |
|    clip_fraction        | 0.172       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.88       |
|    explained_variance   | 0.841       |
|    learning_rate        | 0.00196     |
|    loss                 | -0.0113     |
|    n_updates            | 1120        |
|    policy_gradient_loss | 0.00532     |
|    std                  | 0.62        |
|    value_loss           | 0.00871     |
-----------------------------------------
box reached target
-------------------------------
| time/              |        |
|    fps             | 623    |
|    iterations      | 113    |
|    time_elapsed    | 371    |
|    total_timesteps | 231424 |
-------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 623         |
|    iterations           | 114         |
|    time_elapsed         | 374         |
|    total_timesteps      | 233472      |
| train/                  |             |
|    approx_kl            | 0.012254847 |
|    clip_fraction        | 0.153       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.85       |
|    explained_variance   | 0.884       |
|    learning_rate        | 0.00195     |
|    loss                 | -0.0123     |
|    n_updates            | 1130        |
|    policy_gradient_loss | 3.44e-05    |
|    std                  | 0.616       |
|    value_loss           | 0.00352     |
-----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 623       |
|    iterations           | 115       |
|    time_elapsed         | 377       |
|    total_timesteps      | 235520    |
| train/                  |           |
|    approx_kl            | 0.0207785 |
|    clip_fraction        | 0.16      |
|    clip_range           | 0.2       |
|    entropy_loss         | -1.82     |
|    explained_variance   | 0.987     |
|    learning_rate        | 0.00195   |
|    loss                 | 0.00381   |
|    n_updates            | 1140      |
|    policy_gradient_loss | -0.0014   |
|    std                  | 0.603     |
|    value_loss           | 0.000905  |
---------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 624         |
|    iterations           | 116         |
|    time_elapsed         | 380         |
|    total_timesteps      | 237568      |
| train/                  |             |
|    approx_kl            | 0.010591909 |
|    clip_fraction        | 0.141       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.83       |
|    explained_variance   | 0.815       |
|    learning_rate        | 0.00195     |
|    loss                 | 0.0256      |
|    n_updates            | 1150        |
|    policy_gradient_loss | 0.002       |
|    std                  | 0.612       |
|    value_loss           | 0.0145      |
-----------------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 624         |
|    iterations           | 117         |
|    time_elapsed         | 383         |
|    total_timesteps      | 239616      |
| train/                  |             |
|    approx_kl            | 0.015617348 |
|    clip_fraction        | 0.143       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.87       |
|    explained_variance   | 0.684       |
|    learning_rate        | 0.00195     |
|    loss                 | -0.0131     |
|    n_updates            | 1160        |
|    policy_gradient_loss | 0.000604    |
|    std                  | 0.627       |
|    value_loss           | 0.000677    |
-----------------------------------------
box reached target
Eval num_timesteps=240000, episode_reward=0.25 +/- 2.51
Episode length: 278.80 +/- 42.40
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 279         |
|    mean_reward          | 0.253       |
| time/                   |             |
|    total_timesteps      | 240000      |
| train/                  |             |
|    approx_kl            | 0.016210414 |
|    clip_fraction        | 0.171       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.82       |
|    explained_variance   | 0.845       |
|    learning_rate        | 0.00195     |
|    loss                 | -0.00551    |
|    n_updates            | 1170        |
|    policy_gradient_loss | 0.0015      |
|    std                  | 0.607       |
|    value_loss           | 0.00455     |
-----------------------------------------
-------------------------------
| time/              |        |
|    fps             | 623    |
|    iterations      | 118    |
|    time_elapsed    | 387    |
|    total_timesteps | 241664 |
-------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 623         |
|    iterations           | 119         |
|    time_elapsed         | 390         |
|    total_timesteps      | 243712      |
| train/                  |             |
|    approx_kl            | 0.026057646 |
|    clip_fraction        | 0.184       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.87       |
|    explained_variance   | 0.657       |
|    learning_rate        | 0.00195     |
|    loss                 | -0.0264     |
|    n_updates            | 1180        |
|    policy_gradient_loss | -0.0016     |
|    std                  | 0.64        |
|    value_loss           | 0.00621     |
-----------------------------------------
box reached target
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 623         |
|    iterations           | 120         |
|    time_elapsed         | 393         |
|    total_timesteps      | 245760      |
| train/                  |             |
|    approx_kl            | 0.019622598 |
|    clip_fraction        | 0.173       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.9        |
|    explained_variance   | 0.835       |
|    learning_rate        | 0.00195     |
|    loss                 | -0.0113     |
|    n_updates            | 1190        |
|    policy_gradient_loss | -0.00166    |
|    std                  | 0.635       |
|    value_loss           | 0.00333     |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 624         |
|    iterations           | 121         |
|    time_elapsed         | 397         |
|    total_timesteps      | 247808      |
| train/                  |             |
|    approx_kl            | 0.013055656 |
|    clip_fraction        | 0.159       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.89       |
|    explained_variance   | 0.864       |
|    learning_rate        | 0.00195     |
|    loss                 | 0.0243      |
|    n_updates            | 1200        |
|    policy_gradient_loss | 0.00384     |
|    std                  | 0.631       |
|    value_loss           | 0.00502     |
-----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 624        |
|    iterations           | 122        |
|    time_elapsed         | 400        |
|    total_timesteps      | 249856     |
| train/                  |            |
|    approx_kl            | 0.05784653 |
|    clip_fraction        | 0.191      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.86      |
|    explained_variance   | 0.415      |
|    learning_rate        | 0.00195    |
|    loss                 | 0.0018     |
|    n_updates            | 1210       |
|    policy_gradient_loss | -0.0102    |
|    std                  | 0.61       |
|    value_loss           | 0.00111    |
----------------------------------------
Eval num_timesteps=250000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 300         |
|    mean_reward          | -1          |
| time/                   |             |
|    total_timesteps      | 250000      |
| train/                  |             |
|    approx_kl            | 0.020294754 |
|    clip_fraction        | 0.192       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.85       |
|    explained_variance   | 0.751       |
|    learning_rate        | 0.00195     |
|    loss                 | -0.0029     |
|    n_updates            | 1220        |
|    policy_gradient_loss | 0.00298     |
|    std                  | 0.626       |
|    value_loss           | 0.00159     |
-----------------------------------------
-------------------------------
| time/              |        |
|    fps             | 623    |
|    iterations      | 123    |
|    time_elapsed    | 404    |
|    total_timesteps | 251904 |
-------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 623         |
|    iterations           | 124         |
|    time_elapsed         | 407         |
|    total_timesteps      | 253952      |
| train/                  |             |
|    approx_kl            | 0.016914755 |
|    clip_fraction        | 0.159       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.88       |
|    explained_variance   | 0.809       |
|    learning_rate        | 0.00195     |
|    loss                 | 0.00391     |
|    n_updates            | 1230        |
|    policy_gradient_loss | 0.00136     |
|    std                  | 0.623       |
|    value_loss           | 0.00101     |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 623         |
|    iterations           | 125         |
|    time_elapsed         | 410         |
|    total_timesteps      | 256000      |
| train/                  |             |
|    approx_kl            | 0.016752973 |
|    clip_fraction        | 0.16        |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.89       |
|    explained_variance   | 0.838       |
|    learning_rate        | 0.00195     |
|    loss                 | 0.0272      |
|    n_updates            | 1240        |
|    policy_gradient_loss | -0.000411   |
|    std                  | 0.634       |
|    value_loss           | 0.00103     |
-----------------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 624         |
|    iterations           | 126         |
|    time_elapsed         | 413         |
|    total_timesteps      | 258048      |
| train/                  |             |
|    approx_kl            | 0.018834673 |
|    clip_fraction        | 0.175       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.96       |
|    explained_variance   | 0.627       |
|    learning_rate        | 0.00195     |
|    loss                 | 0.00968     |
|    n_updates            | 1250        |
|    policy_gradient_loss | -0.00255    |
|    std                  | 0.657       |
|    value_loss           | 0.00117     |
-----------------------------------------
box reached target
Eval num_timesteps=260000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 300         |
|    mean_reward          | -1          |
| time/                   |             |
|    total_timesteps      | 260000      |
| train/                  |             |
|    approx_kl            | 0.017492529 |
|    clip_fraction        | 0.175       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.97       |
|    explained_variance   | 0.381       |
|    learning_rate        | 0.00195     |
|    loss                 | 0.00849     |
|    n_updates            | 1260        |
|    policy_gradient_loss | 0.00371     |
|    std                  | 0.655       |
|    value_loss           | 0.0161      |
-----------------------------------------
-------------------------------
| time/              |        |
|    fps             | 622    |
|    iterations      | 127    |
|    time_elapsed    | 417    |
|    total_timesteps | 260096 |
-------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 623         |
|    iterations           | 128         |
|    time_elapsed         | 420         |
|    total_timesteps      | 262144      |
| train/                  |             |
|    approx_kl            | 0.020596476 |
|    clip_fraction        | 0.17        |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.91       |
|    explained_variance   | 0.703       |
|    learning_rate        | 0.00195     |
|    loss                 | 0.0162      |
|    n_updates            | 1270        |
|    policy_gradient_loss | -0.000148   |
|    std                  | 0.631       |
|    value_loss           | 0.00575     |
-----------------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 623         |
|    iterations           | 129         |
|    time_elapsed         | 423         |
|    total_timesteps      | 264192      |
| train/                  |             |
|    approx_kl            | 0.019520782 |
|    clip_fraction        | 0.175       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.83       |
|    explained_variance   | 0.952       |
|    learning_rate        | 0.00195     |
|    loss                 | -0.0253     |
|    n_updates            | 1280        |
|    policy_gradient_loss | 0.00136     |
|    std                  | 0.61        |
|    value_loss           | 0.000739    |
-----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 623        |
|    iterations           | 130        |
|    time_elapsed         | 426        |
|    total_timesteps      | 266240     |
| train/                  |            |
|    approx_kl            | 0.02031944 |
|    clip_fraction        | 0.183      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.76      |
|    explained_variance   | 0.964      |
|    learning_rate        | 0.00195    |
|    loss                 | 0.0105     |
|    n_updates            | 1290       |
|    policy_gradient_loss | -0.00047   |
|    std                  | 0.587      |
|    value_loss           | 0.00121    |
----------------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 624         |
|    iterations           | 131         |
|    time_elapsed         | 429         |
|    total_timesteps      | 268288      |
| train/                  |             |
|    approx_kl            | 0.019708395 |
|    clip_fraction        | 0.188       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.71       |
|    explained_variance   | 0.171       |
|    learning_rate        | 0.00195     |
|    loss                 | 0.00941     |
|    n_updates            | 1300        |
|    policy_gradient_loss | 0.00678     |
|    std                  | 0.574       |
|    value_loss           | 0.0179      |
-----------------------------------------
Eval num_timesteps=270000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 300         |
|    mean_reward          | -1          |
| time/                   |             |
|    total_timesteps      | 270000      |
| train/                  |             |
|    approx_kl            | 0.015479116 |
|    clip_fraction        | 0.2         |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.74       |
|    explained_variance   | 0.88        |
|    learning_rate        | 0.00195     |
|    loss                 | -0.0361     |
|    n_updates            | 1310        |
|    policy_gradient_loss | -0.00184    |
|    std                  | 0.588       |
|    value_loss           | 0.00523     |
-----------------------------------------
-------------------------------
| time/              |        |
|    fps             | 622    |
|    iterations      | 132    |
|    time_elapsed    | 433    |
|    total_timesteps | 270336 |
-------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 623         |
|    iterations           | 133         |
|    time_elapsed         | 437         |
|    total_timesteps      | 272384      |
| train/                  |             |
|    approx_kl            | 0.021203075 |
|    clip_fraction        | 0.186       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.77       |
|    explained_variance   | 0.847       |
|    learning_rate        | 0.00195     |
|    loss                 | -0.0399     |
|    n_updates            | 1320        |
|    policy_gradient_loss | -0.00165    |
|    std                  | 0.597       |
|    value_loss           | 0.00394     |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 623         |
|    iterations           | 134         |
|    time_elapsed         | 440         |
|    total_timesteps      | 274432      |
| train/                  |             |
|    approx_kl            | 0.014689727 |
|    clip_fraction        | 0.19        |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.83       |
|    explained_variance   | 0.458       |
|    learning_rate        | 0.00195     |
|    loss                 | 0.00505     |
|    n_updates            | 1330        |
|    policy_gradient_loss | 0.00228     |
|    std                  | 0.619       |
|    value_loss           | 0.0106      |
-----------------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 623        |
|    iterations           | 135        |
|    time_elapsed         | 443        |
|    total_timesteps      | 276480     |
| train/                  |            |
|    approx_kl            | 0.01805808 |
|    clip_fraction        | 0.183      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.82      |
|    explained_variance   | 0.759      |
|    learning_rate        | 0.00195    |
|    loss                 | -0.0119    |
|    n_updates            | 1340       |
|    policy_gradient_loss | -0.00247   |
|    std                  | 0.608      |
|    value_loss           | 0.00391    |
----------------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 623         |
|    iterations           | 136         |
|    time_elapsed         | 446         |
|    total_timesteps      | 278528      |
| train/                  |             |
|    approx_kl            | 0.015642192 |
|    clip_fraction        | 0.169       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.82       |
|    explained_variance   | 0.957       |
|    learning_rate        | 0.00195     |
|    loss                 | 0.000897    |
|    n_updates            | 1350        |
|    policy_gradient_loss | 0.00179     |
|    std                  | 0.613       |
|    value_loss           | 0.00313     |
-----------------------------------------
box reached target
Eval num_timesteps=280000, episode_reward=-0.74 +/- 0.53
Episode length: 300.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 300         |
|    mean_reward          | -0.737      |
| time/                   |             |
|    total_timesteps      | 280000      |
| train/                  |             |
|    approx_kl            | 0.040665276 |
|    clip_fraction        | 0.231       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.79       |
|    explained_variance   | 0.536       |
|    learning_rate        | 0.00195     |
|    loss                 | 0.00058     |
|    n_updates            | 1360        |
|    policy_gradient_loss | 0.000443    |
|    std                  | 0.596       |
|    value_loss           | 0.0205      |
-----------------------------------------
-------------------------------
| time/              |        |
|    fps             | 622    |
|    iterations      | 137    |
|    time_elapsed    | 450    |
|    total_timesteps | 280576 |
-------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 623         |
|    iterations           | 138         |
|    time_elapsed         | 453         |
|    total_timesteps      | 282624      |
| train/                  |             |
|    approx_kl            | 0.021673266 |
|    clip_fraction        | 0.176       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.7        |
|    explained_variance   | 0.706       |
|    learning_rate        | 0.00195     |
|    loss                 | 0.0326      |
|    n_updates            | 1370        |
|    policy_gradient_loss | -0.00304    |
|    std                  | 0.572       |
|    value_loss           | 0.00481     |
-----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 623        |
|    iterations           | 139        |
|    time_elapsed         | 456        |
|    total_timesteps      | 284672     |
| train/                  |            |
|    approx_kl            | 0.02565679 |
|    clip_fraction        | 0.203      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.68      |
|    explained_variance   | 0.824      |
|    learning_rate        | 0.00194    |
|    loss                 | -0.0173    |
|    n_updates            | 1380       |
|    policy_gradient_loss | 0.000239   |
|    std                  | 0.583      |
|    value_loss           | 0.00259    |
----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 623         |
|    iterations           | 140         |
|    time_elapsed         | 459         |
|    total_timesteps      | 286720      |
| train/                  |             |
|    approx_kl            | 0.019389054 |
|    clip_fraction        | 0.197       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.72       |
|    explained_variance   | 0.81        |
|    learning_rate        | 0.00194     |
|    loss                 | 0.0191      |
|    n_updates            | 1390        |
|    policy_gradient_loss | -2.74e-05   |
|    std                  | 0.597       |
|    value_loss           | 0.00326     |
-----------------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 623         |
|    iterations           | 141         |
|    time_elapsed         | 462         |
|    total_timesteps      | 288768      |
| train/                  |             |
|    approx_kl            | 0.017117798 |
|    clip_fraction        | 0.171       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.73       |
|    explained_variance   | 0.712       |
|    learning_rate        | 0.00194     |
|    loss                 | 0.00941     |
|    n_updates            | 1400        |
|    policy_gradient_loss | 0.000595    |
|    std                  | 0.592       |
|    value_loss           | 0.00136     |
-----------------------------------------
box reached target
Eval num_timesteps=290000, episode_reward=0.52 +/- 2.48
Episode length: 284.00 +/- 32.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 284         |
|    mean_reward          | 0.517       |
| time/                   |             |
|    total_timesteps      | 290000      |
| train/                  |             |
|    approx_kl            | 0.020737454 |
|    clip_fraction        | 0.19        |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.73       |
|    explained_variance   | 0.87        |
|    learning_rate        | 0.00194     |
|    loss                 | 0.0184      |
|    n_updates            | 1410        |
|    policy_gradient_loss | -0.00347    |
|    std                  | 0.604       |
|    value_loss           | 0.00573     |
-----------------------------------------
box reached target
-------------------------------
| time/              |        |
|    fps             | 622    |
|    iterations      | 142    |
|    time_elapsed    | 466    |
|    total_timesteps | 290816 |
-------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 623         |
|    iterations           | 143         |
|    time_elapsed         | 469         |
|    total_timesteps      | 292864      |
| train/                  |             |
|    approx_kl            | 0.017824333 |
|    clip_fraction        | 0.181       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.73       |
|    explained_variance   | 0.909       |
|    learning_rate        | 0.00194     |
|    loss                 | 0.0217      |
|    n_updates            | 1420        |
|    policy_gradient_loss | 0.00343     |
|    std                  | 0.604       |
|    value_loss           | 0.00431     |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 623         |
|    iterations           | 144         |
|    time_elapsed         | 473         |
|    total_timesteps      | 294912      |
| train/                  |             |
|    approx_kl            | 0.022326307 |
|    clip_fraction        | 0.181       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.78       |
|    explained_variance   | 0.664       |
|    learning_rate        | 0.00194     |
|    loss                 | 0.0351      |
|    n_updates            | 1430        |
|    policy_gradient_loss | -0.00447    |
|    std                  | 0.615       |
|    value_loss           | 0.00158     |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 623         |
|    iterations           | 145         |
|    time_elapsed         | 476         |
|    total_timesteps      | 296960      |
| train/                  |             |
|    approx_kl            | 0.021045022 |
|    clip_fraction        | 0.183       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.8        |
|    explained_variance   | 0.793       |
|    learning_rate        | 0.00194     |
|    loss                 | -0.00608    |
|    n_updates            | 1440        |
|    policy_gradient_loss | 0.00498     |
|    std                  | 0.627       |
|    value_loss           | 0.000998    |
-----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 623        |
|    iterations           | 146        |
|    time_elapsed         | 479        |
|    total_timesteps      | 299008     |
| train/                  |            |
|    approx_kl            | 0.02480754 |
|    clip_fraction        | 0.184      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.83      |
|    explained_variance   | 0.751      |
|    learning_rate        | 0.00194    |
|    loss                 | -0.00628   |
|    n_updates            | 1450       |
|    policy_gradient_loss | -0.00673   |
|    std                  | 0.628      |
|    value_loss           | 0.000988   |
----------------------------------------
box reached target
Eval num_timesteps=300000, episode_reward=-0.87 +/- 0.26
Episode length: 300.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 300         |
|    mean_reward          | -0.87       |
| time/                   |             |
|    total_timesteps      | 300000      |
| train/                  |             |
|    approx_kl            | 0.023947747 |
|    clip_fraction        | 0.208       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.82       |
|    explained_variance   | 0.885       |
|    learning_rate        | 0.00194     |
|    loss                 | -0.0127     |
|    n_updates            | 1460        |
|    policy_gradient_loss | 0.00346     |
|    std                  | 0.635       |
|    value_loss           | 0.00703     |
-----------------------------------------
-------------------------------
| time/              |        |
|    fps             | 622    |
|    iterations      | 147    |
|    time_elapsed    | 483    |
|    total_timesteps | 301056 |
-------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 623        |
|    iterations           | 148        |
|    time_elapsed         | 486        |
|    total_timesteps      | 303104     |
| train/                  |            |
|    approx_kl            | 0.02545429 |
|    clip_fraction        | 0.214      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.78      |
|    explained_variance   | 0.952      |
|    learning_rate        | 0.00194    |
|    loss                 | 0.0698     |
|    n_updates            | 1470       |
|    policy_gradient_loss | 0.00049    |
|    std                  | 0.609      |
|    value_loss           | 0.0044     |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 623        |
|    iterations           | 149        |
|    time_elapsed         | 489        |
|    total_timesteps      | 305152     |
| train/                  |            |
|    approx_kl            | 0.02309384 |
|    clip_fraction        | 0.202      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.8       |
|    explained_variance   | 0.571      |
|    learning_rate        | 0.00194    |
|    loss                 | 0.0211     |
|    n_updates            | 1480       |
|    policy_gradient_loss | -0.000707  |
|    std                  | 0.623      |
|    value_loss           | 0.00106    |
----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 623         |
|    iterations           | 150         |
|    time_elapsed         | 492         |
|    total_timesteps      | 307200      |
| train/                  |             |
|    approx_kl            | 0.016424064 |
|    clip_fraction        | 0.187       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.85       |
|    explained_variance   | 0.955       |
|    learning_rate        | 0.00194     |
|    loss                 | -0.0324     |
|    n_updates            | 1490        |
|    policy_gradient_loss | 0.00264     |
|    std                  | 0.637       |
|    value_loss           | 0.00161     |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 623         |
|    iterations           | 151         |
|    time_elapsed         | 495         |
|    total_timesteps      | 309248      |
| train/                  |             |
|    approx_kl            | 0.016179245 |
|    clip_fraction        | 0.143       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.89       |
|    explained_variance   | 0.835       |
|    learning_rate        | 0.00194     |
|    loss                 | 0.0146      |
|    n_updates            | 1500        |
|    policy_gradient_loss | -0.00535    |
|    std                  | 0.657       |
|    value_loss           | 0.00325     |
-----------------------------------------
box reached target
box reached target
Eval num_timesteps=310000, episode_reward=1.59 +/- 3.18
Episode length: 255.20 +/- 61.81
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 255         |
|    mean_reward          | 1.59        |
| time/                   |             |
|    total_timesteps      | 310000      |
| train/                  |             |
|    approx_kl            | 0.023639088 |
|    clip_fraction        | 0.19        |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.89       |
|    explained_variance   | 0.923       |
|    learning_rate        | 0.00194     |
|    loss                 | 0.00847     |
|    n_updates            | 1510        |
|    policy_gradient_loss | 0.00863     |
|    std                  | 0.647       |
|    value_loss           | 0.000974    |
-----------------------------------------
New best mean reward!
-------------------------------
| time/              |        |
|    fps             | 623    |
|    iterations      | 152    |
|    time_elapsed    | 499    |
|    total_timesteps | 311296 |
-------------------------------
box reached target
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 623         |
|    iterations           | 153         |
|    time_elapsed         | 502         |
|    total_timesteps      | 313344      |
| train/                  |             |
|    approx_kl            | 0.019977842 |
|    clip_fraction        | 0.19        |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.95       |
|    explained_variance   | 0.679       |
|    learning_rate        | 0.00194     |
|    loss                 | 0.000326    |
|    n_updates            | 1520        |
|    policy_gradient_loss | 0.0019      |
|    std                  | 0.675       |
|    value_loss           | 0.0016      |
-----------------------------------------
box reached target
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 623         |
|    iterations           | 154         |
|    time_elapsed         | 505         |
|    total_timesteps      | 315392      |
| train/                  |             |
|    approx_kl            | 0.011545714 |
|    clip_fraction        | 0.144       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.95       |
|    explained_variance   | 0.913       |
|    learning_rate        | 0.00194     |
|    loss                 | -0.0162     |
|    n_updates            | 1530        |
|    policy_gradient_loss | -0.000627   |
|    std                  | 0.677       |
|    value_loss           | 0.00512     |
-----------------------------------------
box reached target
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 623         |
|    iterations           | 155         |
|    time_elapsed         | 508         |
|    total_timesteps      | 317440      |
| train/                  |             |
|    approx_kl            | 0.014963424 |
|    clip_fraction        | 0.183       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.97       |
|    explained_variance   | 0.897       |
|    learning_rate        | 0.00194     |
|    loss                 | -0.0121     |
|    n_updates            | 1540        |
|    policy_gradient_loss | -0.00221    |
|    std                  | 0.679       |
|    value_loss           | 0.00919     |
-----------------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 624        |
|    iterations           | 156        |
|    time_elapsed         | 511        |
|    total_timesteps      | 319488     |
| train/                  |            |
|    approx_kl            | 0.02383431 |
|    clip_fraction        | 0.208      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.96      |
|    explained_variance   | 0.958      |
|    learning_rate        | 0.00194    |
|    loss                 | -0.0265    |
|    n_updates            | 1550       |
|    policy_gradient_loss | -0.00151   |
|    std                  | 0.665      |
|    value_loss           | 0.00162    |
----------------------------------------
Eval num_timesteps=320000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 300         |
|    mean_reward          | -1          |
| time/                   |             |
|    total_timesteps      | 320000      |
| train/                  |             |
|    approx_kl            | 0.035909332 |
|    clip_fraction        | 0.19        |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.93       |
|    explained_variance   | 0.956       |
|    learning_rate        | 0.00194     |
|    loss                 | -0.00658    |
|    n_updates            | 1560        |
|    policy_gradient_loss | 0.0115      |
|    std                  | 0.653       |
|    value_loss           | 0.00172     |
-----------------------------------------
box reached target
-------------------------------
| time/              |        |
|    fps             | 623    |
|    iterations      | 157    |
|    time_elapsed    | 516    |
|    total_timesteps | 321536 |
-------------------------------
box reached target
box reached target
box reached target
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 623         |
|    iterations           | 158         |
|    time_elapsed         | 519         |
|    total_timesteps      | 323584      |
| train/                  |             |
|    approx_kl            | 0.019450806 |
|    clip_fraction        | 0.197       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.9        |
|    explained_variance   | 0.957       |
|    learning_rate        | 0.00194     |
|    loss                 | -0.00171    |
|    n_updates            | 1570        |
|    policy_gradient_loss | -0.00165    |
|    std                  | 0.642       |
|    value_loss           | 0.00217     |
-----------------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 623         |
|    iterations           | 159         |
|    time_elapsed         | 522         |
|    total_timesteps      | 325632      |
| train/                  |             |
|    approx_kl            | 0.021451091 |
|    clip_fraction        | 0.198       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.87       |
|    explained_variance   | 0.968       |
|    learning_rate        | 0.00194     |
|    loss                 | -0.018      |
|    n_updates            | 1580        |
|    policy_gradient_loss | -0.00137    |
|    std                  | 0.635       |
|    value_loss           | 0.00434     |
-----------------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 623         |
|    iterations           | 160         |
|    time_elapsed         | 525         |
|    total_timesteps      | 327680      |
| train/                  |             |
|    approx_kl            | 0.019752137 |
|    clip_fraction        | 0.191       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.92       |
|    explained_variance   | 0.927       |
|    learning_rate        | 0.00194     |
|    loss                 | -0.0381     |
|    n_updates            | 1590        |
|    policy_gradient_loss | -0.00536    |
|    std                  | 0.667       |
|    value_loss           | 0.00251     |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 623         |
|    iterations           | 161         |
|    time_elapsed         | 528         |
|    total_timesteps      | 329728      |
| train/                  |             |
|    approx_kl            | 0.016264426 |
|    clip_fraction        | 0.198       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.98       |
|    explained_variance   | 0.942       |
|    learning_rate        | 0.00194     |
|    loss                 | -0.0126     |
|    n_updates            | 1600        |
|    policy_gradient_loss | 0.00132     |
|    std                  | 0.69        |
|    value_loss           | 0.00206     |
-----------------------------------------
Eval num_timesteps=330000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 300         |
|    mean_reward          | -1          |
| time/                   |             |
|    total_timesteps      | 330000      |
| train/                  |             |
|    approx_kl            | 0.018375328 |
|    clip_fraction        | 0.182       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.05       |
|    explained_variance   | 0.837       |
|    learning_rate        | 0.00194     |
|    loss                 | 0.0159      |
|    n_updates            | 1610        |
|    policy_gradient_loss | -0.00045    |
|    std                  | 0.716       |
|    value_loss           | 0.000759    |
-----------------------------------------
box reached target
box reached target
-------------------------------
| time/              |        |
|    fps             | 622    |
|    iterations      | 162    |
|    time_elapsed    | 532    |
|    total_timesteps | 331776 |
-------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 623         |
|    iterations           | 163         |
|    time_elapsed         | 535         |
|    total_timesteps      | 333824      |
| train/                  |             |
|    approx_kl            | 0.021138564 |
|    clip_fraction        | 0.198       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.06       |
|    explained_variance   | 0.904       |
|    learning_rate        | 0.00194     |
|    loss                 | 0.0139      |
|    n_updates            | 1620        |
|    policy_gradient_loss | 0.000183    |
|    std                  | 0.713       |
|    value_loss           | 0.0105      |
-----------------------------------------
box reached target
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 623         |
|    iterations           | 164         |
|    time_elapsed         | 538         |
|    total_timesteps      | 335872      |
| train/                  |             |
|    approx_kl            | 0.018853668 |
|    clip_fraction        | 0.191       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.08       |
|    explained_variance   | 0.73        |
|    learning_rate        | 0.00193     |
|    loss                 | -0.0162     |
|    n_updates            | 1630        |
|    policy_gradient_loss | -0.00247    |
|    std                  | 0.723       |
|    value_loss           | 0.00103     |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 623         |
|    iterations           | 165         |
|    time_elapsed         | 541         |
|    total_timesteps      | 337920      |
| train/                  |             |
|    approx_kl            | 0.015811114 |
|    clip_fraction        | 0.173       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.11       |
|    explained_variance   | 0.961       |
|    learning_rate        | 0.00193     |
|    loss                 | 0.00356     |
|    n_updates            | 1640        |
|    policy_gradient_loss | 0.00533     |
|    std                  | 0.724       |
|    value_loss           | 0.00234     |
-----------------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 623         |
|    iterations           | 166         |
|    time_elapsed         | 544         |
|    total_timesteps      | 339968      |
| train/                  |             |
|    approx_kl            | 0.012734821 |
|    clip_fraction        | 0.165       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.13       |
|    explained_variance   | 0.804       |
|    learning_rate        | 0.00193     |
|    loss                 | 0.00527     |
|    n_updates            | 1650        |
|    policy_gradient_loss | 0.000379    |
|    std                  | 0.729       |
|    value_loss           | 0.00534     |
-----------------------------------------
Eval num_timesteps=340000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 300         |
|    mean_reward          | -1          |
| time/                   |             |
|    total_timesteps      | 340000      |
| train/                  |             |
|    approx_kl            | 0.017766751 |
|    clip_fraction        | 0.177       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.13       |
|    explained_variance   | 0.964       |
|    learning_rate        | 0.00193     |
|    loss                 | 0.0272      |
|    n_updates            | 1660        |
|    policy_gradient_loss | -0.00674    |
|    std                  | 0.727       |
|    value_loss           | 0.00131     |
-----------------------------------------
-------------------------------
| time/              |        |
|    fps             | 622    |
|    iterations      | 167    |
|    time_elapsed    | 549    |
|    total_timesteps | 342016 |
-------------------------------
box reached target
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 623         |
|    iterations           | 168         |
|    time_elapsed         | 552         |
|    total_timesteps      | 344064      |
| train/                  |             |
|    approx_kl            | 0.040052574 |
|    clip_fraction        | 0.184       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.13       |
|    explained_variance   | 0.752       |
|    learning_rate        | 0.00193     |
|    loss                 | 0.00507     |
|    n_updates            | 1670        |
|    policy_gradient_loss | -0.000107   |
|    std                  | 0.716       |
|    value_loss           | 0.000731    |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 623         |
|    iterations           | 169         |
|    time_elapsed         | 555         |
|    total_timesteps      | 346112      |
| train/                  |             |
|    approx_kl            | 0.014084101 |
|    clip_fraction        | 0.205       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.12       |
|    explained_variance   | 0.932       |
|    learning_rate        | 0.00193     |
|    loss                 | -0.00823    |
|    n_updates            | 1680        |
|    policy_gradient_loss | -0.00373    |
|    std                  | 0.722       |
|    value_loss           | 0.0026      |
-----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 623        |
|    iterations           | 170        |
|    time_elapsed         | 558        |
|    total_timesteps      | 348160     |
| train/                  |            |
|    approx_kl            | 0.01951807 |
|    clip_fraction        | 0.179      |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.12      |
|    explained_variance   | 0.916      |
|    learning_rate        | 0.00193    |
|    loss                 | -0.0138    |
|    n_updates            | 1690       |
|    policy_gradient_loss | -0.00248   |
|    std                  | 0.72       |
|    value_loss           | 0.00027    |
----------------------------------------
box reached target
Eval num_timesteps=350000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 300         |
|    mean_reward          | -1          |
| time/                   |             |
|    total_timesteps      | 350000      |
| train/                  |             |
|    approx_kl            | 0.016804915 |
|    clip_fraction        | 0.162       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.07       |
|    explained_variance   | 0.664       |
|    learning_rate        | 0.00193     |
|    loss                 | 0.0301      |
|    n_updates            | 1700        |
|    policy_gradient_loss | -0.000516   |
|    std                  | 0.705       |
|    value_loss           | 0.00585     |
-----------------------------------------
-------------------------------
| time/              |        |
|    fps             | 622    |
|    iterations      | 171    |
|    time_elapsed    | 562    |
|    total_timesteps | 350208 |
-------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 622         |
|    iterations           | 172         |
|    time_elapsed         | 565         |
|    total_timesteps      | 352256      |
| train/                  |             |
|    approx_kl            | 0.019037493 |
|    clip_fraction        | 0.185       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.1        |
|    explained_variance   | 0.724       |
|    learning_rate        | 0.00193     |
|    loss                 | -0.0255     |
|    n_updates            | 1710        |
|    policy_gradient_loss | -0.00313    |
|    std                  | 0.712       |
|    value_loss           | 0.0224      |
-----------------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 623         |
|    iterations           | 173         |
|    time_elapsed         | 568         |
|    total_timesteps      | 354304      |
| train/                  |             |
|    approx_kl            | 0.022194795 |
|    clip_fraction        | 0.203       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.12       |
|    explained_variance   | 0.786       |
|    learning_rate        | 0.00193     |
|    loss                 | -0.00733    |
|    n_updates            | 1720        |
|    policy_gradient_loss | -0.00269    |
|    std                  | 0.716       |
|    value_loss           | 0.00637     |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 623         |
|    iterations           | 174         |
|    time_elapsed         | 571         |
|    total_timesteps      | 356352      |
| train/                  |             |
|    approx_kl            | 0.018130982 |
|    clip_fraction        | 0.192       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.07       |
|    explained_variance   | 0.926       |
|    learning_rate        | 0.00193     |
|    loss                 | -0.01       |
|    n_updates            | 1730        |
|    policy_gradient_loss | -0.000684   |
|    std                  | 0.696       |
|    value_loss           | 0.00249     |
-----------------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 623         |
|    iterations           | 175         |
|    time_elapsed         | 574         |
|    total_timesteps      | 358400      |
| train/                  |             |
|    approx_kl            | 0.012042117 |
|    clip_fraction        | 0.138       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.08       |
|    explained_variance   | 0.689       |
|    learning_rate        | 0.00193     |
|    loss                 | 0.00575     |
|    n_updates            | 1740        |
|    policy_gradient_loss | 0.00405     |
|    std                  | 0.711       |
|    value_loss           | 0.00113     |
-----------------------------------------
box reached target
Eval num_timesteps=360000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 300         |
|    mean_reward          | -1          |
| time/                   |             |
|    total_timesteps      | 360000      |
| train/                  |             |
|    approx_kl            | 0.017245315 |
|    clip_fraction        | 0.199       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.06       |
|    explained_variance   | 0.913       |
|    learning_rate        | 0.00193     |
|    loss                 | 0.0122      |
|    n_updates            | 1750        |
|    policy_gradient_loss | 0.00579     |
|    std                  | 0.705       |
|    value_loss           | 0.00379     |
-----------------------------------------
-------------------------------
| time/              |        |
|    fps             | 622    |
|    iterations      | 176    |
|    time_elapsed    | 578    |
|    total_timesteps | 360448 |
-------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 622         |
|    iterations           | 177         |
|    time_elapsed         | 581         |
|    total_timesteps      | 362496      |
| train/                  |             |
|    approx_kl            | 0.025174096 |
|    clip_fraction        | 0.194       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.12       |
|    explained_variance   | 0.855       |
|    learning_rate        | 0.00193     |
|    loss                 | -0.00639    |
|    n_updates            | 1760        |
|    policy_gradient_loss | 0.0074      |
|    std                  | 0.725       |
|    value_loss           | 0.0039      |
-----------------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 623         |
|    iterations           | 178         |
|    time_elapsed         | 584         |
|    total_timesteps      | 364544      |
| train/                  |             |
|    approx_kl            | 0.016786784 |
|    clip_fraction        | 0.187       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.09       |
|    explained_variance   | 0.797       |
|    learning_rate        | 0.00193     |
|    loss                 | -0.0226     |
|    n_updates            | 1770        |
|    policy_gradient_loss | 0.000468    |
|    std                  | 0.7         |
|    value_loss           | 0.00376     |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 623         |
|    iterations           | 179         |
|    time_elapsed         | 588         |
|    total_timesteps      | 366592      |
| train/                  |             |
|    approx_kl            | 0.015955674 |
|    clip_fraction        | 0.166       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.09       |
|    explained_variance   | 0.919       |
|    learning_rate        | 0.00193     |
|    loss                 | -0.00945    |
|    n_updates            | 1780        |
|    policy_gradient_loss | 0.00267     |
|    std                  | 0.704       |
|    value_loss           | 0.0021      |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 623         |
|    iterations           | 180         |
|    time_elapsed         | 591         |
|    total_timesteps      | 368640      |
| train/                  |             |
|    approx_kl            | 0.014584475 |
|    clip_fraction        | 0.139       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.16       |
|    explained_variance   | 0.821       |
|    learning_rate        | 0.00193     |
|    loss                 | -0.0225     |
|    n_updates            | 1790        |
|    policy_gradient_loss | -0.000915   |
|    std                  | 0.733       |
|    value_loss           | 0.00624     |
-----------------------------------------
box reached target
Eval num_timesteps=370000, episode_reward=0.22 +/- 2.44
Episode length: 275.40 +/- 49.20
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 275         |
|    mean_reward          | 0.221       |
| time/                   |             |
|    total_timesteps      | 370000      |
| train/                  |             |
|    approx_kl            | 0.018658428 |
|    clip_fraction        | 0.153       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.22       |
|    explained_variance   | 0.873       |
|    learning_rate        | 0.00193     |
|    loss                 | -0.0222     |
|    n_updates            | 1800        |
|    policy_gradient_loss | 0.000732    |
|    std                  | 0.756       |
|    value_loss           | 0.00152     |
-----------------------------------------
box reached target
-------------------------------
| time/              |        |
|    fps             | 622    |
|    iterations      | 181    |
|    time_elapsed    | 595    |
|    total_timesteps | 370688 |
-------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 623         |
|    iterations           | 182         |
|    time_elapsed         | 598         |
|    total_timesteps      | 372736      |
| train/                  |             |
|    approx_kl            | 0.015833374 |
|    clip_fraction        | 0.171       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.22       |
|    explained_variance   | 0.842       |
|    learning_rate        | 0.00193     |
|    loss                 | 0.0147      |
|    n_updates            | 1810        |
|    policy_gradient_loss | -0.00126    |
|    std                  | 0.74        |
|    value_loss           | 0.00505     |
-----------------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 623         |
|    iterations           | 183         |
|    time_elapsed         | 601         |
|    total_timesteps      | 374784      |
| train/                  |             |
|    approx_kl            | 0.018848535 |
|    clip_fraction        | 0.189       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.17       |
|    explained_variance   | 0.807       |
|    learning_rate        | 0.00193     |
|    loss                 | 0.0249      |
|    n_updates            | 1820        |
|    policy_gradient_loss | -0.000322   |
|    std                  | 0.727       |
|    value_loss           | 0.00107     |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 623         |
|    iterations           | 184         |
|    time_elapsed         | 604         |
|    total_timesteps      | 376832      |
| train/                  |             |
|    approx_kl            | 0.014174072 |
|    clip_fraction        | 0.174       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.11       |
|    explained_variance   | 0.909       |
|    learning_rate        | 0.00193     |
|    loss                 | -0.0111     |
|    n_updates            | 1830        |
|    policy_gradient_loss | -0.00747    |
|    std                  | 0.713       |
|    value_loss           | 0.00649     |
-----------------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 623        |
|    iterations           | 185        |
|    time_elapsed         | 607        |
|    total_timesteps      | 378880     |
| train/                  |            |
|    approx_kl            | 0.01916328 |
|    clip_fraction        | 0.18       |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.14      |
|    explained_variance   | 0.78       |
|    learning_rate        | 0.00193    |
|    loss                 | -0.00909   |
|    n_updates            | 1840       |
|    policy_gradient_loss | -0.00573   |
|    std                  | 0.725      |
|    value_loss           | 0.000844   |
----------------------------------------
Eval num_timesteps=380000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 300         |
|    mean_reward          | -1          |
| time/                   |             |
|    total_timesteps      | 380000      |
| train/                  |             |
|    approx_kl            | 0.021833768 |
|    clip_fraction        | 0.185       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.15       |
|    explained_variance   | 0.934       |
|    learning_rate        | 0.00193     |
|    loss                 | 0.0318      |
|    n_updates            | 1850        |
|    policy_gradient_loss | -0.000849   |
|    std                  | 0.725       |
|    value_loss           | 0.00331     |
-----------------------------------------
box reached target
-------------------------------
| time/              |        |
|    fps             | 622    |
|    iterations      | 186    |
|    time_elapsed    | 611    |
|    total_timesteps | 380928 |
-------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 623         |
|    iterations           | 187         |
|    time_elapsed         | 614         |
|    total_timesteps      | 382976      |
| train/                  |             |
|    approx_kl            | 0.015505056 |
|    clip_fraction        | 0.204       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.17       |
|    explained_variance   | 0.93        |
|    learning_rate        | 0.00193     |
|    loss                 | -0.0191     |
|    n_updates            | 1860        |
|    policy_gradient_loss | 0.00411     |
|    std                  | 0.736       |
|    value_loss           | 0.00208     |
-----------------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 623         |
|    iterations           | 188         |
|    time_elapsed         | 617         |
|    total_timesteps      | 385024      |
| train/                  |             |
|    approx_kl            | 0.023425855 |
|    clip_fraction        | 0.169       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.18       |
|    explained_variance   | 0.963       |
|    learning_rate        | 0.00193     |
|    loss                 | 0.0142      |
|    n_updates            | 1870        |
|    policy_gradient_loss | 0.0099      |
|    std                  | 0.732       |
|    value_loss           | 0.00299     |
-----------------------------------------
box reached target
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 623         |
|    iterations           | 189         |
|    time_elapsed         | 620         |
|    total_timesteps      | 387072      |
| train/                  |             |
|    approx_kl            | 0.021809913 |
|    clip_fraction        | 0.169       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.2        |
|    explained_variance   | 0.902       |
|    learning_rate        | 0.00192     |
|    loss                 | -0.00935    |
|    n_updates            | 1880        |
|    policy_gradient_loss | 0.00137     |
|    std                  | 0.747       |
|    value_loss           | 0.00462     |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 623         |
|    iterations           | 190         |
|    time_elapsed         | 624         |
|    total_timesteps      | 389120      |
| train/                  |             |
|    approx_kl            | 0.014350153 |
|    clip_fraction        | 0.156       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.24       |
|    explained_variance   | 0.95        |
|    learning_rate        | 0.00192     |
|    loss                 | -0.0264     |
|    n_updates            | 1890        |
|    policy_gradient_loss | -0.000943   |
|    std                  | 0.772       |
|    value_loss           | 0.00648     |
-----------------------------------------
Eval num_timesteps=390000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 300          |
|    mean_reward          | -1           |
| time/                   |              |
|    total_timesteps      | 390000       |
| train/                  |              |
|    approx_kl            | 0.0154702095 |
|    clip_fraction        | 0.182        |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.3         |
|    explained_variance   | 0.874        |
|    learning_rate        | 0.00192      |
|    loss                 | 0.0192       |
|    n_updates            | 1900         |
|    policy_gradient_loss | 0.000864     |
|    std                  | 0.798        |
|    value_loss           | 0.00284      |
------------------------------------------
-------------------------------
| time/              |        |
|    fps             | 622    |
|    iterations      | 191    |
|    time_elapsed    | 628    |
|    total_timesteps | 391168 |
-------------------------------
box reached target
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 623         |
|    iterations           | 192         |
|    time_elapsed         | 631         |
|    total_timesteps      | 393216      |
| train/                  |             |
|    approx_kl            | 0.018778607 |
|    clip_fraction        | 0.183       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.38       |
|    explained_variance   | 0.895       |
|    learning_rate        | 0.00192     |
|    loss                 | -0.0241     |
|    n_updates            | 1910        |
|    policy_gradient_loss | -0.00335    |
|    std                  | 0.824       |
|    value_loss           | 0.00182     |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 623         |
|    iterations           | 193         |
|    time_elapsed         | 634         |
|    total_timesteps      | 395264      |
| train/                  |             |
|    approx_kl            | 0.021310499 |
|    clip_fraction        | 0.174       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.36       |
|    explained_variance   | 0.875       |
|    learning_rate        | 0.00192     |
|    loss                 | -0.0302     |
|    n_updates            | 1920        |
|    policy_gradient_loss | -0.00505    |
|    std                  | 0.813       |
|    value_loss           | 0.00905     |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 623         |
|    iterations           | 194         |
|    time_elapsed         | 637         |
|    total_timesteps      | 397312      |
| train/                  |             |
|    approx_kl            | 0.022331938 |
|    clip_fraction        | 0.188       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.36       |
|    explained_variance   | 0.926       |
|    learning_rate        | 0.00192     |
|    loss                 | -0.0223     |
|    n_updates            | 1930        |
|    policy_gradient_loss | -0.00839    |
|    std                  | 0.82        |
|    value_loss           | 0.00101     |
-----------------------------------------
box reached target
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 623         |
|    iterations           | 195         |
|    time_elapsed         | 640         |
|    total_timesteps      | 399360      |
| train/                  |             |
|    approx_kl            | 0.012322561 |
|    clip_fraction        | 0.134       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.37       |
|    explained_variance   | 0.774       |
|    learning_rate        | 0.00192     |
|    loss                 | -0.00909    |
|    n_updates            | 1940        |
|    policy_gradient_loss | -0.0042     |
|    std                  | 0.827       |
|    value_loss           | 0.000525    |
-----------------------------------------
box reached target
Eval num_timesteps=400000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 300         |
|    mean_reward          | -1          |
| time/                   |             |
|    total_timesteps      | 400000      |
| train/                  |             |
|    approx_kl            | 0.023010898 |
|    clip_fraction        | 0.225       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.34       |
|    explained_variance   | 0.863       |
|    learning_rate        | 0.00192     |
|    loss                 | -0.0131     |
|    n_updates            | 1950        |
|    policy_gradient_loss | -0.00109    |
|    std                  | 0.807       |
|    value_loss           | 0.00717     |
-----------------------------------------
box reached target
-------------------------------
| time/              |        |
|    fps             | 622    |
|    iterations      | 196    |
|    time_elapsed    | 644    |
|    total_timesteps | 401408 |
-------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 622         |
|    iterations           | 197         |
|    time_elapsed         | 647         |
|    total_timesteps      | 403456      |
| train/                  |             |
|    approx_kl            | 0.021335002 |
|    clip_fraction        | 0.173       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.39       |
|    explained_variance   | 0.958       |
|    learning_rate        | 0.00192     |
|    loss                 | 0.0118      |
|    n_updates            | 1960        |
|    policy_gradient_loss | 0.00423     |
|    std                  | 0.851       |
|    value_loss           | 0.00493     |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 623         |
|    iterations           | 198         |
|    time_elapsed         | 650         |
|    total_timesteps      | 405504      |
| train/                  |             |
|    approx_kl            | 0.019929051 |
|    clip_fraction        | 0.176       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.42       |
|    explained_variance   | 0.749       |
|    learning_rate        | 0.00192     |
|    loss                 | -0.0409     |
|    n_updates            | 1970        |
|    policy_gradient_loss | -0.000241   |
|    std                  | 0.849       |
|    value_loss           | 0.00376     |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 623         |
|    iterations           | 199         |
|    time_elapsed         | 653         |
|    total_timesteps      | 407552      |
| train/                  |             |
|    approx_kl            | 0.012461763 |
|    clip_fraction        | 0.158       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.45       |
|    explained_variance   | 0.738       |
|    learning_rate        | 0.00192     |
|    loss                 | -0.0116     |
|    n_updates            | 1980        |
|    policy_gradient_loss | -0.00625    |
|    std                  | 0.871       |
|    value_loss           | 0.000368    |
-----------------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 623         |
|    iterations           | 200         |
|    time_elapsed         | 656         |
|    total_timesteps      | 409600      |
| train/                  |             |
|    approx_kl            | 0.012610701 |
|    clip_fraction        | 0.152       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.48       |
|    explained_variance   | 0.889       |
|    learning_rate        | 0.00192     |
|    loss                 | 0.0358      |
|    n_updates            | 1990        |
|    policy_gradient_loss | -0.00496    |
|    std                  | 0.88        |
|    value_loss           | 0.000326    |
-----------------------------------------
box reached target
Eval num_timesteps=410000, episode_reward=0.26 +/- 2.52
Episode length: 281.00 +/- 38.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 281         |
|    mean_reward          | 0.261       |
| time/                   |             |
|    total_timesteps      | 410000      |
| train/                  |             |
|    approx_kl            | 0.014658114 |
|    clip_fraction        | 0.155       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.43       |
|    explained_variance   | 0.98        |
|    learning_rate        | 0.00192     |
|    loss                 | -0.00141    |
|    n_updates            | 2000        |
|    policy_gradient_loss | -0.00296    |
|    std                  | 0.862       |
|    value_loss           | 0.00102     |
-----------------------------------------
-------------------------------
| time/              |        |
|    fps             | 622    |
|    iterations      | 201    |
|    time_elapsed    | 660    |
|    total_timesteps | 411648 |
-------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 622         |
|    iterations           | 202         |
|    time_elapsed         | 664         |
|    total_timesteps      | 413696      |
| train/                  |             |
|    approx_kl            | 0.022534428 |
|    clip_fraction        | 0.18        |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.42       |
|    explained_variance   | 0.771       |
|    learning_rate        | 0.00192     |
|    loss                 | 0.173       |
|    n_updates            | 2010        |
|    policy_gradient_loss | -0.00231    |
|    std                  | 0.844       |
|    value_loss           | 0.000541    |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 623         |
|    iterations           | 203         |
|    time_elapsed         | 667         |
|    total_timesteps      | 415744      |
| train/                  |             |
|    approx_kl            | 0.016657077 |
|    clip_fraction        | 0.185       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.44       |
|    explained_variance   | 0.866       |
|    learning_rate        | 0.00192     |
|    loss                 | 0.0205      |
|    n_updates            | 2020        |
|    policy_gradient_loss | -0.00603    |
|    std                  | 0.853       |
|    value_loss           | 0.00117     |
-----------------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 623         |
|    iterations           | 204         |
|    time_elapsed         | 670         |
|    total_timesteps      | 417792      |
| train/                  |             |
|    approx_kl            | 0.011630477 |
|    clip_fraction        | 0.139       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.43       |
|    explained_variance   | 0.658       |
|    learning_rate        | 0.00192     |
|    loss                 | 0.00439     |
|    n_updates            | 2030        |
|    policy_gradient_loss | -0.000702   |
|    std                  | 0.843       |
|    value_loss           | 0.000957    |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 623         |
|    iterations           | 205         |
|    time_elapsed         | 673         |
|    total_timesteps      | 419840      |
| train/                  |             |
|    approx_kl            | 0.014716471 |
|    clip_fraction        | 0.168       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.38       |
|    explained_variance   | 0.974       |
|    learning_rate        | 0.00192     |
|    loss                 | 0.037       |
|    n_updates            | 2040        |
|    policy_gradient_loss | -0.00286    |
|    std                  | 0.816       |
|    value_loss           | 0.00156     |
-----------------------------------------
box reached target
Eval num_timesteps=420000, episode_reward=0.22 +/- 2.44
Episode length: 280.60 +/- 38.80
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 281        |
|    mean_reward          | 0.222      |
| time/                   |            |
|    total_timesteps      | 420000     |
| train/                  |            |
|    approx_kl            | 0.01267096 |
|    clip_fraction        | 0.148      |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.35      |
|    explained_variance   | 0.75       |
|    learning_rate        | 0.00192    |
|    loss                 | -0.0288    |
|    n_updates            | 2050       |
|    policy_gradient_loss | -0.00496   |
|    std                  | 0.807      |
|    value_loss           | 0.000381   |
----------------------------------------
box reached target
box reached target
-------------------------------
| time/              |        |
|    fps             | 622    |
|    iterations      | 206    |
|    time_elapsed    | 677    |
|    total_timesteps | 421888 |
-------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 623         |
|    iterations           | 207         |
|    time_elapsed         | 680         |
|    total_timesteps      | 423936      |
| train/                  |             |
|    approx_kl            | 0.024754707 |
|    clip_fraction        | 0.182       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.28       |
|    explained_variance   | 0.953       |
|    learning_rate        | 0.00192     |
|    loss                 | 0.0152      |
|    n_updates            | 2060        |
|    policy_gradient_loss | 0.00118     |
|    std                  | 0.78        |
|    value_loss           | 0.00415     |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 623         |
|    iterations           | 208         |
|    time_elapsed         | 683         |
|    total_timesteps      | 425984      |
| train/                  |             |
|    approx_kl            | 0.010506499 |
|    clip_fraction        | 0.178       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.27       |
|    explained_variance   | 0.791       |
|    learning_rate        | 0.00192     |
|    loss                 | 0.00118     |
|    n_updates            | 2070        |
|    policy_gradient_loss | 0.00145     |
|    std                  | 0.788       |
|    value_loss           | 0.000542    |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 623         |
|    iterations           | 209         |
|    time_elapsed         | 686         |
|    total_timesteps      | 428032      |
| train/                  |             |
|    approx_kl            | 0.016837807 |
|    clip_fraction        | 0.177       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.27       |
|    explained_variance   | 0.734       |
|    learning_rate        | 0.00192     |
|    loss                 | -0.00263    |
|    n_updates            | 2080        |
|    policy_gradient_loss | 0.00249     |
|    std                  | 0.778       |
|    value_loss           | 0.000703    |
-----------------------------------------
box reached target
Eval num_timesteps=430000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 300         |
|    mean_reward          | -1          |
| time/                   |             |
|    total_timesteps      | 430000      |
| train/                  |             |
|    approx_kl            | 0.012635943 |
|    clip_fraction        | 0.171       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.27       |
|    explained_variance   | 0.833       |
|    learning_rate        | 0.00192     |
|    loss                 | 0.0123      |
|    n_updates            | 2090        |
|    policy_gradient_loss | 0.00573     |
|    std                  | 0.777       |
|    value_loss           | 0.000846    |
-----------------------------------------
-------------------------------
| time/              |        |
|    fps             | 622    |
|    iterations      | 210    |
|    time_elapsed    | 690    |
|    total_timesteps | 430080 |
-------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 622         |
|    iterations           | 211         |
|    time_elapsed         | 693         |
|    total_timesteps      | 432128      |
| train/                  |             |
|    approx_kl            | 0.020786138 |
|    clip_fraction        | 0.198       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.27       |
|    explained_variance   | 0.971       |
|    learning_rate        | 0.00192     |
|    loss                 | 0.0031      |
|    n_updates            | 2100        |
|    policy_gradient_loss | -0.00163    |
|    std                  | 0.778       |
|    value_loss           | 0.00185     |
-----------------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 623         |
|    iterations           | 212         |
|    time_elapsed         | 696         |
|    total_timesteps      | 434176      |
| train/                  |             |
|    approx_kl            | 0.018167213 |
|    clip_fraction        | 0.166       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.29       |
|    explained_variance   | 0.725       |
|    learning_rate        | 0.00192     |
|    loss                 | 0.0359      |
|    n_updates            | 2110        |
|    policy_gradient_loss | 0.00183     |
|    std                  | 0.787       |
|    value_loss           | 0.0006      |
-----------------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 623         |
|    iterations           | 213         |
|    time_elapsed         | 699         |
|    total_timesteps      | 436224      |
| train/                  |             |
|    approx_kl            | 0.018171558 |
|    clip_fraction        | 0.175       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.26       |
|    explained_variance   | 0.914       |
|    learning_rate        | 0.00192     |
|    loss                 | 0.0315      |
|    n_updates            | 2120        |
|    policy_gradient_loss | -0.00168    |
|    std                  | 0.784       |
|    value_loss           | 0.00257     |
-----------------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 623         |
|    iterations           | 214         |
|    time_elapsed         | 703         |
|    total_timesteps      | 438272      |
| train/                  |             |
|    approx_kl            | 0.019323334 |
|    clip_fraction        | 0.189       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.22       |
|    explained_variance   | 0.647       |
|    learning_rate        | 0.00191     |
|    loss                 | 0.00445     |
|    n_updates            | 2130        |
|    policy_gradient_loss | -0.0016     |
|    std                  | 0.77        |
|    value_loss           | 0.00693     |
-----------------------------------------
box reached target
Eval num_timesteps=440000, episode_reward=-0.82 +/- 0.36
Episode length: 300.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 300         |
|    mean_reward          | -0.819      |
| time/                   |             |
|    total_timesteps      | 440000      |
| train/                  |             |
|    approx_kl            | 0.014593035 |
|    clip_fraction        | 0.158       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.17       |
|    explained_variance   | 0.756       |
|    learning_rate        | 0.00191     |
|    loss                 | 0.0322      |
|    n_updates            | 2140        |
|    policy_gradient_loss | 0.00272     |
|    std                  | 0.745       |
|    value_loss           | 0.0192      |
-----------------------------------------
-------------------------------
| time/              |        |
|    fps             | 622    |
|    iterations      | 215    |
|    time_elapsed    | 707    |
|    total_timesteps | 440320 |
-------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 622         |
|    iterations           | 216         |
|    time_elapsed         | 710         |
|    total_timesteps      | 442368      |
| train/                  |             |
|    approx_kl            | 0.030151047 |
|    clip_fraction        | 0.187       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.1        |
|    explained_variance   | 0.716       |
|    learning_rate        | 0.00191     |
|    loss                 | -0.00272    |
|    n_updates            | 2150        |
|    policy_gradient_loss | -0.00497    |
|    std                  | 0.717       |
|    value_loss           | 0.0239      |
-----------------------------------------
box reached target
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 623         |
|    iterations           | 217         |
|    time_elapsed         | 713         |
|    total_timesteps      | 444416      |
| train/                  |             |
|    approx_kl            | 0.013872762 |
|    clip_fraction        | 0.16        |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.08       |
|    explained_variance   | 0.783       |
|    learning_rate        | 0.00191     |
|    loss                 | 0.00635     |
|    n_updates            | 2160        |
|    policy_gradient_loss | 0.0035      |
|    std                  | 0.724       |
|    value_loss           | 0.0116      |
-----------------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 623         |
|    iterations           | 218         |
|    time_elapsed         | 716         |
|    total_timesteps      | 446464      |
| train/                  |             |
|    approx_kl            | 0.021738535 |
|    clip_fraction        | 0.187       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.04       |
|    explained_variance   | 0.911       |
|    learning_rate        | 0.00191     |
|    loss                 | 0.106       |
|    n_updates            | 2170        |
|    policy_gradient_loss | 0.00653     |
|    std                  | 0.698       |
|    value_loss           | 0.0066      |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 623         |
|    iterations           | 219         |
|    time_elapsed         | 719         |
|    total_timesteps      | 448512      |
| train/                  |             |
|    approx_kl            | 0.015637169 |
|    clip_fraction        | 0.161       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.06       |
|    explained_variance   | 0.833       |
|    learning_rate        | 0.00191     |
|    loss                 | 0.0224      |
|    n_updates            | 2180        |
|    policy_gradient_loss | 0.00185     |
|    std                  | 0.73        |
|    value_loss           | 0.0152      |
-----------------------------------------
box reached target
box reached target
Eval num_timesteps=450000, episode_reward=1.79 +/- 2.82
Episode length: 261.00 +/- 50.02
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 261       |
|    mean_reward          | 1.79      |
| time/                   |           |
|    total_timesteps      | 450000    |
| train/                  |           |
|    approx_kl            | 1.0668013 |
|    clip_fraction        | 0.368     |
|    clip_range           | 0.2       |
|    entropy_loss         | -2.06     |
|    explained_variance   | 0.841     |
|    learning_rate        | 0.00191   |
|    loss                 | -0.0496   |
|    n_updates            | 2190      |
|    policy_gradient_loss | -0.0268   |
|    std                  | 0.713     |
|    value_loss           | 0.0159    |
---------------------------------------
New best mean reward!
-------------------------------
| time/              |        |
|    fps             | 622    |
|    iterations      | 220    |
|    time_elapsed    | 723    |
|    total_timesteps | 450560 |
-------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 622         |
|    iterations           | 221         |
|    time_elapsed         | 726         |
|    total_timesteps      | 452608      |
| train/                  |             |
|    approx_kl            | 0.017040562 |
|    clip_fraction        | 0.171       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.03       |
|    explained_variance   | 0.819       |
|    learning_rate        | 0.00191     |
|    loss                 | 0.00441     |
|    n_updates            | 2200        |
|    policy_gradient_loss | 0.00118     |
|    std                  | 0.71        |
|    value_loss           | 0.000897    |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 623         |
|    iterations           | 222         |
|    time_elapsed         | 729         |
|    total_timesteps      | 454656      |
| train/                  |             |
|    approx_kl            | 0.034509897 |
|    clip_fraction        | 0.193       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.02       |
|    explained_variance   | 0.841       |
|    learning_rate        | 0.00191     |
|    loss                 | -0.00635    |
|    n_updates            | 2210        |
|    policy_gradient_loss | 0.00351     |
|    std                  | 0.711       |
|    value_loss           | 0.00278     |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 623         |
|    iterations           | 223         |
|    time_elapsed         | 732         |
|    total_timesteps      | 456704      |
| train/                  |             |
|    approx_kl            | 0.024026278 |
|    clip_fraction        | 0.211       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.03       |
|    explained_variance   | 0.731       |
|    learning_rate        | 0.00191     |
|    loss                 | -0.0165     |
|    n_updates            | 2220        |
|    policy_gradient_loss | -0.00487    |
|    std                  | 0.703       |
|    value_loss           | 0.00098     |
-----------------------------------------
box reached target
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 623         |
|    iterations           | 224         |
|    time_elapsed         | 735         |
|    total_timesteps      | 458752      |
| train/                  |             |
|    approx_kl            | 0.023719324 |
|    clip_fraction        | 0.174       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.04       |
|    explained_variance   | 0.751       |
|    learning_rate        | 0.00191     |
|    loss                 | -0.0287     |
|    n_updates            | 2230        |
|    policy_gradient_loss | 8.29e-05    |
|    std                  | 0.708       |
|    value_loss           | 0.00114     |
-----------------------------------------
box reached target
box reached target
Eval num_timesteps=460000, episode_reward=-0.78 +/- 0.43
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -0.783     |
| time/                   |            |
|    total_timesteps      | 460000     |
| train/                  |            |
|    approx_kl            | 0.02978119 |
|    clip_fraction        | 0.198      |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.05      |
|    explained_variance   | 0.898      |
|    learning_rate        | 0.00191    |
|    loss                 | -0.0278    |
|    n_updates            | 2240       |
|    policy_gradient_loss | 0.00164    |
|    std                  | 0.709      |
|    value_loss           | 0.00364    |
----------------------------------------
box reached target
-------------------------------
| time/              |        |
|    fps             | 622    |
|    iterations      | 225    |
|    time_elapsed    | 739    |
|    total_timesteps | 460800 |
-------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 622         |
|    iterations           | 226         |
|    time_elapsed         | 743         |
|    total_timesteps      | 462848      |
| train/                  |             |
|    approx_kl            | 0.031406753 |
|    clip_fraction        | 0.195       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2          |
|    explained_variance   | 0.951       |
|    learning_rate        | 0.00191     |
|    loss                 | -0.000271   |
|    n_updates            | 2250        |
|    policy_gradient_loss | -0.00303    |
|    std                  | 0.688       |
|    value_loss           | 0.00493     |
-----------------------------------------
box reached target
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 623         |
|    iterations           | 227         |
|    time_elapsed         | 746         |
|    total_timesteps      | 464896      |
| train/                  |             |
|    approx_kl            | 0.019988244 |
|    clip_fraction        | 0.188       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.04       |
|    explained_variance   | 0.791       |
|    learning_rate        | 0.00191     |
|    loss                 | 0.0241      |
|    n_updates            | 2260        |
|    policy_gradient_loss | 0.00339     |
|    std                  | 0.71        |
|    value_loss           | 0.00869     |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 623         |
|    iterations           | 228         |
|    time_elapsed         | 749         |
|    total_timesteps      | 466944      |
| train/                  |             |
|    approx_kl            | 0.020573985 |
|    clip_fraction        | 0.194       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.08       |
|    explained_variance   | 0.719       |
|    learning_rate        | 0.00191     |
|    loss                 | 0.0169      |
|    n_updates            | 2270        |
|    policy_gradient_loss | 0.00212     |
|    std                  | 0.714       |
|    value_loss           | 0.0376      |
-----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 623        |
|    iterations           | 229        |
|    time_elapsed         | 752        |
|    total_timesteps      | 468992     |
| train/                  |            |
|    approx_kl            | 0.07136874 |
|    clip_fraction        | 0.259      |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.07      |
|    explained_variance   | 0.892      |
|    learning_rate        | 0.00191    |
|    loss                 | -0.0413    |
|    n_updates            | 2280       |
|    policy_gradient_loss | -0.00395   |
|    std                  | 0.695      |
|    value_loss           | 0.00387    |
----------------------------------------
box reached target
Eval num_timesteps=470000, episode_reward=0.70 +/- 2.24
Episode length: 275.20 +/- 49.60
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 275        |
|    mean_reward          | 0.704      |
| time/                   |            |
|    total_timesteps      | 470000     |
| train/                  |            |
|    approx_kl            | 0.04003302 |
|    clip_fraction        | 0.214      |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.06      |
|    explained_variance   | 0.797      |
|    learning_rate        | 0.00191    |
|    loss                 | -0.0401    |
|    n_updates            | 2290       |
|    policy_gradient_loss | 0.00444    |
|    std                  | 0.708      |
|    value_loss           | 0.00425    |
----------------------------------------
-------------------------------
| time/              |        |
|    fps             | 622    |
|    iterations      | 230    |
|    time_elapsed    | 756    |
|    total_timesteps | 471040 |
-------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 231        |
|    time_elapsed         | 759        |
|    total_timesteps      | 473088     |
| train/                  |            |
|    approx_kl            | 0.02473389 |
|    clip_fraction        | 0.179      |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.04      |
|    explained_variance   | 0.457      |
|    learning_rate        | 0.00191    |
|    loss                 | -0.0227    |
|    n_updates            | 2300       |
|    policy_gradient_loss | 0.000589   |
|    std                  | 0.698      |
|    value_loss           | 0.0055     |
----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 623         |
|    iterations           | 232         |
|    time_elapsed         | 762         |
|    total_timesteps      | 475136      |
| train/                  |             |
|    approx_kl            | 0.019477118 |
|    clip_fraction        | 0.206       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.05       |
|    explained_variance   | 0.793       |
|    learning_rate        | 0.00191     |
|    loss                 | -0.0247     |
|    n_updates            | 2310        |
|    policy_gradient_loss | 0.00376     |
|    std                  | 0.708       |
|    value_loss           | 0.0042      |
-----------------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 623         |
|    iterations           | 233         |
|    time_elapsed         | 765         |
|    total_timesteps      | 477184      |
| train/                  |             |
|    approx_kl            | 0.028018367 |
|    clip_fraction        | 0.215       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.06       |
|    explained_variance   | 0.738       |
|    learning_rate        | 0.00191     |
|    loss                 | -0.0261     |
|    n_updates            | 2320        |
|    policy_gradient_loss | -0.00335    |
|    std                  | 0.708       |
|    value_loss           | 0.00125     |
-----------------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 623         |
|    iterations           | 234         |
|    time_elapsed         | 768         |
|    total_timesteps      | 479232      |
| train/                  |             |
|    approx_kl            | 0.024873184 |
|    clip_fraction        | 0.192       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.04       |
|    explained_variance   | 0.866       |
|    learning_rate        | 0.00191     |
|    loss                 | 0.0188      |
|    n_updates            | 2330        |
|    policy_gradient_loss | -0.000184   |
|    std                  | 0.694       |
|    value_loss           | 0.00445     |
-----------------------------------------
box reached target
Eval num_timesteps=480000, episode_reward=0.25 +/- 2.51
Episode length: 283.80 +/- 32.40
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 284        |
|    mean_reward          | 0.253      |
| time/                   |            |
|    total_timesteps      | 480000     |
| train/                  |            |
|    approx_kl            | 0.02242332 |
|    clip_fraction        | 0.215      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.98      |
|    explained_variance   | 0.316      |
|    learning_rate        | 0.00191    |
|    loss                 | 0.00745    |
|    n_updates            | 2340       |
|    policy_gradient_loss | 0.00716    |
|    std                  | 0.678      |
|    value_loss           | 0.0153     |
----------------------------------------
box reached target
-------------------------------
| time/              |        |
|    fps             | 622    |
|    iterations      | 235    |
|    time_elapsed    | 772    |
|    total_timesteps | 481280 |
-------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 622         |
|    iterations           | 236         |
|    time_elapsed         | 775         |
|    total_timesteps      | 483328      |
| train/                  |             |
|    approx_kl            | 0.025090594 |
|    clip_fraction        | 0.223       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.94       |
|    explained_variance   | 0.776       |
|    learning_rate        | 0.00191     |
|    loss                 | 0.0263      |
|    n_updates            | 2350        |
|    policy_gradient_loss | -0.000261   |
|    std                  | 0.68        |
|    value_loss           | 0.00688     |
-----------------------------------------
box reached target
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 623        |
|    iterations           | 237        |
|    time_elapsed         | 778        |
|    total_timesteps      | 485376     |
| train/                  |            |
|    approx_kl            | 0.02469062 |
|    clip_fraction        | 0.236      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.98      |
|    explained_variance   | 0.923      |
|    learning_rate        | 0.00191    |
|    loss                 | -0.0067    |
|    n_updates            | 2360       |
|    policy_gradient_loss | 0.00429    |
|    std                  | 0.691      |
|    value_loss           | 0.00367    |
----------------------------------------
box reached target
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 623         |
|    iterations           | 238         |
|    time_elapsed         | 782         |
|    total_timesteps      | 487424      |
| train/                  |             |
|    approx_kl            | 0.016096957 |
|    clip_fraction        | 0.186       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.96       |
|    explained_variance   | 0.798       |
|    learning_rate        | 0.00191     |
|    loss                 | 0.0163      |
|    n_updates            | 2370        |
|    policy_gradient_loss | 0.00294     |
|    std                  | 0.67        |
|    value_loss           | 0.0149      |
-----------------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 623         |
|    iterations           | 239         |
|    time_elapsed         | 785         |
|    total_timesteps      | 489472      |
| train/                  |             |
|    approx_kl            | 0.030318672 |
|    clip_fraction        | 0.196       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.98       |
|    explained_variance   | 0.902       |
|    learning_rate        | 0.0019      |
|    loss                 | 0.00023     |
|    n_updates            | 2380        |
|    policy_gradient_loss | -0.00509    |
|    std                  | 0.685       |
|    value_loss           | 0.0068      |
-----------------------------------------
box reached target
box reached target
box reached target
Eval num_timesteps=490000, episode_reward=0.23 +/- 2.47
Episode length: 273.40 +/- 53.20
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 273        |
|    mean_reward          | 0.235      |
| time/                   |            |
|    total_timesteps      | 490000     |
| train/                  |            |
|    approx_kl            | 0.02034032 |
|    clip_fraction        | 0.187      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.96      |
|    explained_variance   | 0.889      |
|    learning_rate        | 0.0019     |
|    loss                 | 0.036      |
|    n_updates            | 2390       |
|    policy_gradient_loss | 0.00172    |
|    std                  | 0.681      |
|    value_loss           | 0.00472    |
----------------------------------------
-------------------------------
| time/              |        |
|    fps             | 622    |
|    iterations      | 240    |
|    time_elapsed    | 789    |
|    total_timesteps | 491520 |
-------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 623        |
|    iterations           | 241        |
|    time_elapsed         | 792        |
|    total_timesteps      | 493568     |
| train/                  |            |
|    approx_kl            | 0.03299899 |
|    clip_fraction        | 0.237      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.94      |
|    explained_variance   | 0.821      |
|    learning_rate        | 0.0019     |
|    loss                 | 0.00919    |
|    n_updates            | 2400       |
|    policy_gradient_loss | 0.00192    |
|    std                  | 0.652      |
|    value_loss           | 0.0162     |
----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 623         |
|    iterations           | 242         |
|    time_elapsed         | 795         |
|    total_timesteps      | 495616      |
| train/                  |             |
|    approx_kl            | 0.022141807 |
|    clip_fraction        | 0.209       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.94       |
|    explained_variance   | 0.89        |
|    learning_rate        | 0.0019      |
|    loss                 | 0.0193      |
|    n_updates            | 2410        |
|    policy_gradient_loss | -0.00473    |
|    std                  | 0.668       |
|    value_loss           | 0.00669     |
-----------------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 623         |
|    iterations           | 243         |
|    time_elapsed         | 798         |
|    total_timesteps      | 497664      |
| train/                  |             |
|    approx_kl            | 0.020526787 |
|    clip_fraction        | 0.22        |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.98       |
|    explained_variance   | 0.844       |
|    learning_rate        | 0.0019      |
|    loss                 | -0.00446    |
|    n_updates            | 2420        |
|    policy_gradient_loss | -0.00206    |
|    std                  | 0.684       |
|    value_loss           | 0.00451     |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 623         |
|    iterations           | 244         |
|    time_elapsed         | 801         |
|    total_timesteps      | 499712      |
| train/                  |             |
|    approx_kl            | 0.019661196 |
|    clip_fraction        | 0.179       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2          |
|    explained_variance   | 0.838       |
|    learning_rate        | 0.0019      |
|    loss                 | -0.0203     |
|    n_updates            | 2430        |
|    policy_gradient_loss | -0.0032     |
|    std                  | 0.683       |
|    value_loss           | 0.00459     |
-----------------------------------------
Eval num_timesteps=500000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1         |
| time/                   |            |
|    total_timesteps      | 500000     |
| train/                  |            |
|    approx_kl            | 0.02931447 |
|    clip_fraction        | 0.231      |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.04      |
|    explained_variance   | 0.87       |
|    learning_rate        | 0.0019     |
|    loss                 | -0.0153    |
|    n_updates            | 2440       |
|    policy_gradient_loss | -0.00352   |
|    std                  | 0.702      |
|    value_loss           | 0.00201    |
----------------------------------------
box reached target
-------------------------------
| time/              |        |
|    fps             | 622    |
|    iterations      | 245    |
|    time_elapsed    | 805    |
|    total_timesteps | 501760 |
-------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 623         |
|    iterations           | 246         |
|    time_elapsed         | 808         |
|    total_timesteps      | 503808      |
| train/                  |             |
|    approx_kl            | 0.019598646 |
|    clip_fraction        | 0.181       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.08       |
|    explained_variance   | 0.839       |
|    learning_rate        | 0.0019      |
|    loss                 | -0.00558    |
|    n_updates            | 2450        |
|    policy_gradient_loss | -0.00182    |
|    std                  | 0.711       |
|    value_loss           | 0.00791     |
-----------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 623          |
|    iterations           | 247          |
|    time_elapsed         | 811          |
|    total_timesteps      | 505856       |
| train/                  |              |
|    approx_kl            | 0.0156048555 |
|    clip_fraction        | 0.179        |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.08        |
|    explained_variance   | 0.743        |
|    learning_rate        | 0.0019       |
|    loss                 | 0.0205       |
|    n_updates            | 2460         |
|    policy_gradient_loss | 5.93e-05     |
|    std                  | 0.706        |
|    value_loss           | 0.00182      |
------------------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 623         |
|    iterations           | 248         |
|    time_elapsed         | 814         |
|    total_timesteps      | 507904      |
| train/                  |             |
|    approx_kl            | 0.022724926 |
|    clip_fraction        | 0.192       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.05       |
|    explained_variance   | 0.787       |
|    learning_rate        | 0.0019      |
|    loss                 | -0.003      |
|    n_updates            | 2470        |
|    policy_gradient_loss | -0.00439    |
|    std                  | 0.688       |
|    value_loss           | 0.0023      |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 623         |
|    iterations           | 249         |
|    time_elapsed         | 817         |
|    total_timesteps      | 509952      |
| train/                  |             |
|    approx_kl            | 0.021280818 |
|    clip_fraction        | 0.193       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.02       |
|    explained_variance   | 0.95        |
|    learning_rate        | 0.0019      |
|    loss                 | -0.0157     |
|    n_updates            | 2480        |
|    policy_gradient_loss | 0.0007      |
|    std                  | 0.683       |
|    value_loss           | 0.00267     |
-----------------------------------------
box reached target
box reached target
Eval num_timesteps=510000, episode_reward=1.58 +/- 3.16
Episode length: 269.60 +/- 49.68
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 270         |
|    mean_reward          | 1.58        |
| time/                   |             |
|    total_timesteps      | 510000      |
| train/                  |             |
|    approx_kl            | 0.023373816 |
|    clip_fraction        | 0.192       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.01       |
|    explained_variance   | 0.791       |
|    learning_rate        | 0.0019      |
|    loss                 | 0.0278      |
|    n_updates            | 2490        |
|    policy_gradient_loss | 0.000574    |
|    std                  | 0.686       |
|    value_loss           | 0.00179     |
-----------------------------------------
box reached target
-------------------------------
| time/              |        |
|    fps             | 622    |
|    iterations      | 250    |
|    time_elapsed    | 821    |
|    total_timesteps | 512000 |
-------------------------------
box reached target
box reached target
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 623         |
|    iterations           | 251         |
|    time_elapsed         | 825         |
|    total_timesteps      | 514048      |
| train/                  |             |
|    approx_kl            | 0.019245597 |
|    clip_fraction        | 0.196       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.01       |
|    explained_variance   | 0.964       |
|    learning_rate        | 0.0019      |
|    loss                 | -0.02       |
|    n_updates            | 2500        |
|    policy_gradient_loss | -0.00404    |
|    std                  | 0.683       |
|    value_loss           | 0.00158     |
-----------------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 623         |
|    iterations           | 252         |
|    time_elapsed         | 828         |
|    total_timesteps      | 516096      |
| train/                  |             |
|    approx_kl            | 0.022658369 |
|    clip_fraction        | 0.188       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2          |
|    explained_variance   | 0.917       |
|    learning_rate        | 0.0019      |
|    loss                 | -0.0176     |
|    n_updates            | 2510        |
|    policy_gradient_loss | -0.000794   |
|    std                  | 0.679       |
|    value_loss           | 0.00859     |
-----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 623        |
|    iterations           | 253        |
|    time_elapsed         | 831        |
|    total_timesteps      | 518144     |
| train/                  |            |
|    approx_kl            | 0.04981973 |
|    clip_fraction        | 0.214      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.97      |
|    explained_variance   | 0.84       |
|    learning_rate        | 0.0019     |
|    loss                 | 0.00185    |
|    n_updates            | 2520       |
|    policy_gradient_loss | -0.00244   |
|    std                  | 0.662      |
|    value_loss           | 0.00622    |
----------------------------------------
box reached target
box reached target
Eval num_timesteps=520000, episode_reward=-0.79 +/- 0.42
Episode length: 300.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 300         |
|    mean_reward          | -0.788      |
| time/                   |             |
|    total_timesteps      | 520000      |
| train/                  |             |
|    approx_kl            | 0.019769683 |
|    clip_fraction        | 0.191       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.98       |
|    explained_variance   | 0.781       |
|    learning_rate        | 0.0019      |
|    loss                 | 0.0179      |
|    n_updates            | 2530        |
|    policy_gradient_loss | -0.000984   |
|    std                  | 0.672       |
|    value_loss           | 0.000804    |
-----------------------------------------
-------------------------------
| time/              |        |
|    fps             | 622    |
|    iterations      | 254    |
|    time_elapsed    | 835    |
|    total_timesteps | 520192 |
-------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 622       |
|    iterations           | 255       |
|    time_elapsed         | 838       |
|    total_timesteps      | 522240    |
| train/                  |           |
|    approx_kl            | 0.0540703 |
|    clip_fraction        | 0.242     |
|    clip_range           | 0.2       |
|    entropy_loss         | -1.93     |
|    explained_variance   | 0.86      |
|    learning_rate        | 0.0019    |
|    loss                 | 0.00681   |
|    n_updates            | 2540      |
|    policy_gradient_loss | 0.00644   |
|    std                  | 0.643     |
|    value_loss           | 0.0207    |
---------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 622         |
|    iterations           | 256         |
|    time_elapsed         | 841         |
|    total_timesteps      | 524288      |
| train/                  |             |
|    approx_kl            | 0.019628305 |
|    clip_fraction        | 0.2         |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.89       |
|    explained_variance   | 0.731       |
|    learning_rate        | 0.0019      |
|    loss                 | 0.0375      |
|    n_updates            | 2550        |
|    policy_gradient_loss | -0.00408    |
|    std                  | 0.646       |
|    value_loss           | 0.00186     |
-----------------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 623         |
|    iterations           | 257         |
|    time_elapsed         | 844         |
|    total_timesteps      | 526336      |
| train/                  |             |
|    approx_kl            | 0.017309317 |
|    clip_fraction        | 0.183       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.93       |
|    explained_variance   | 0.742       |
|    learning_rate        | 0.0019      |
|    loss                 | -0.0254     |
|    n_updates            | 2560        |
|    policy_gradient_loss | -0.00391    |
|    std                  | 0.655       |
|    value_loss           | 0.0075      |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 623         |
|    iterations           | 258         |
|    time_elapsed         | 847         |
|    total_timesteps      | 528384      |
| train/                  |             |
|    approx_kl            | 0.022260517 |
|    clip_fraction        | 0.192       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.94       |
|    explained_variance   | 0.859       |
|    learning_rate        | 0.0019      |
|    loss                 | -0.0101     |
|    n_updates            | 2570        |
|    policy_gradient_loss | 0.015       |
|    std                  | 0.648       |
|    value_loss           | 0.00641     |
-----------------------------------------
box reached target
box reached target
Eval num_timesteps=530000, episode_reward=0.86 +/- 2.29
Episode length: 278.00 +/- 44.00
--------------------------------------
| eval/                   |          |
|    mean_ep_length       | 278      |
|    mean_reward          | 0.859    |
| time/                   |          |
|    total_timesteps      | 530000   |
| train/                  |          |
|    approx_kl            | 0.018489 |
|    clip_fraction        | 0.186    |
|    clip_range           | 0.2      |
|    entropy_loss         | -1.88    |
|    explained_variance   | 0.81     |
|    learning_rate        | 0.0019   |
|    loss                 | 0.00694  |
|    n_updates            | 2580     |
|    policy_gradient_loss | -0.00217 |
|    std                  | 0.639    |
|    value_loss           | 0.00285  |
--------------------------------------
-------------------------------
| time/              |        |
|    fps             | 622    |
|    iterations      | 259    |
|    time_elapsed    | 851    |
|    total_timesteps | 530432 |
-------------------------------
box reached target
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 260        |
|    time_elapsed         | 854        |
|    total_timesteps      | 532480     |
| train/                  |            |
|    approx_kl            | 0.01758562 |
|    clip_fraction        | 0.179      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.89      |
|    explained_variance   | 0.864      |
|    learning_rate        | 0.0019     |
|    loss                 | -0.00173   |
|    n_updates            | 2590       |
|    policy_gradient_loss | 0.0107     |
|    std                  | 0.646      |
|    value_loss           | 0.0102     |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 623        |
|    iterations           | 261        |
|    time_elapsed         | 857        |
|    total_timesteps      | 534528     |
| train/                  |            |
|    approx_kl            | 0.02637408 |
|    clip_fraction        | 0.213      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.88      |
|    explained_variance   | 0.937      |
|    learning_rate        | 0.0019     |
|    loss                 | -0.0268    |
|    n_updates            | 2600       |
|    policy_gradient_loss | -0.00593   |
|    std                  | 0.631      |
|    value_loss           | 0.00717    |
----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 623         |
|    iterations           | 262         |
|    time_elapsed         | 861         |
|    total_timesteps      | 536576      |
| train/                  |             |
|    approx_kl            | 0.024847567 |
|    clip_fraction        | 0.206       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.92       |
|    explained_variance   | 0.845       |
|    learning_rate        | 0.0019      |
|    loss                 | 0.00686     |
|    n_updates            | 2610        |
|    policy_gradient_loss | 0.00586     |
|    std                  | 0.649       |
|    value_loss           | 0.000951    |
-----------------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 623         |
|    iterations           | 263         |
|    time_elapsed         | 864         |
|    total_timesteps      | 538624      |
| train/                  |             |
|    approx_kl            | 0.015381785 |
|    clip_fraction        | 0.184       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.97       |
|    explained_variance   | 0.832       |
|    learning_rate        | 0.0019      |
|    loss                 | 0.0365      |
|    n_updates            | 2620        |
|    policy_gradient_loss | 0.000348    |
|    std                  | 0.667       |
|    value_loss           | 0.00568     |
-----------------------------------------
Eval num_timesteps=540000, episode_reward=-0.70 +/- 0.60
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -0.701     |
| time/                   |            |
|    total_timesteps      | 540000     |
| train/                  |            |
|    approx_kl            | 0.02935857 |
|    clip_fraction        | 0.194      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.99      |
|    explained_variance   | 0.943      |
|    learning_rate        | 0.00189    |
|    loss                 | 0.0223     |
|    n_updates            | 2630       |
|    policy_gradient_loss | 0.0028     |
|    std                  | 0.667      |
|    value_loss           | 0.00417    |
----------------------------------------
-------------------------------
| time/              |        |
|    fps             | 622    |
|    iterations      | 264    |
|    time_elapsed    | 868    |
|    total_timesteps | 540672 |
-------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 622         |
|    iterations           | 265         |
|    time_elapsed         | 871         |
|    total_timesteps      | 542720      |
| train/                  |             |
|    approx_kl            | 0.030140046 |
|    clip_fraction        | 0.204       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.94       |
|    explained_variance   | 0.765       |
|    learning_rate        | 0.00189     |
|    loss                 | 0.051       |
|    n_updates            | 2640        |
|    policy_gradient_loss | 0.000465    |
|    std                  | 0.656       |
|    value_loss           | 0.00348     |
-----------------------------------------
box reached target
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 622         |
|    iterations           | 266         |
|    time_elapsed         | 874         |
|    total_timesteps      | 544768      |
| train/                  |             |
|    approx_kl            | 0.031614497 |
|    clip_fraction        | 0.237       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.98       |
|    explained_variance   | 0.902       |
|    learning_rate        | 0.00189     |
|    loss                 | 0.0301      |
|    n_updates            | 2650        |
|    policy_gradient_loss | 0.00807     |
|    std                  | 0.679       |
|    value_loss           | 0.00112     |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 623         |
|    iterations           | 267         |
|    time_elapsed         | 877         |
|    total_timesteps      | 546816      |
| train/                  |             |
|    approx_kl            | 0.047929622 |
|    clip_fraction        | 0.248       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.93       |
|    explained_variance   | 0.83        |
|    learning_rate        | 0.00189     |
|    loss                 | -0.0234     |
|    n_updates            | 2660        |
|    policy_gradient_loss | -0.00484    |
|    std                  | 0.64        |
|    value_loss           | 0.00823     |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 623         |
|    iterations           | 268         |
|    time_elapsed         | 880         |
|    total_timesteps      | 548864      |
| train/                  |             |
|    approx_kl            | 0.019413492 |
|    clip_fraction        | 0.197       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.89       |
|    explained_variance   | 0.836       |
|    learning_rate        | 0.00189     |
|    loss                 | -0.0295     |
|    n_updates            | 2670        |
|    policy_gradient_loss | 0.00336     |
|    std                  | 0.633       |
|    value_loss           | 0.00351     |
-----------------------------------------
Eval num_timesteps=550000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 300         |
|    mean_reward          | -1          |
| time/                   |             |
|    total_timesteps      | 550000      |
| train/                  |             |
|    approx_kl            | 0.012916913 |
|    clip_fraction        | 0.174       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.87       |
|    explained_variance   | 0.848       |
|    learning_rate        | 0.00189     |
|    loss                 | -0.0172     |
|    n_updates            | 2680        |
|    policy_gradient_loss | 9.36e-05    |
|    std                  | 0.635       |
|    value_loss           | 0.00197     |
-----------------------------------------
-------------------------------
| time/              |        |
|    fps             | 622    |
|    iterations      | 269    |
|    time_elapsed    | 884    |
|    total_timesteps | 550912 |
-------------------------------
box reached target
box reached target
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 622         |
|    iterations           | 270         |
|    time_elapsed         | 887         |
|    total_timesteps      | 552960      |
| train/                  |             |
|    approx_kl            | 0.021984786 |
|    clip_fraction        | 0.181       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.86       |
|    explained_variance   | 0.877       |
|    learning_rate        | 0.00189     |
|    loss                 | 0.059       |
|    n_updates            | 2690        |
|    policy_gradient_loss | 0.00384     |
|    std                  | 0.627       |
|    value_loss           | 0.0025      |
-----------------------------------------
box reached target
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 622         |
|    iterations           | 271         |
|    time_elapsed         | 890         |
|    total_timesteps      | 555008      |
| train/                  |             |
|    approx_kl            | 0.059381615 |
|    clip_fraction        | 0.23        |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.82       |
|    explained_variance   | 0.959       |
|    learning_rate        | 0.00189     |
|    loss                 | -0.031      |
|    n_updates            | 2700        |
|    policy_gradient_loss | -0.00538    |
|    std                  | 0.608       |
|    value_loss           | 0.00435     |
-----------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 623       |
|    iterations           | 272       |
|    time_elapsed         | 894       |
|    total_timesteps      | 557056    |
| train/                  |           |
|    approx_kl            | 0.0591743 |
|    clip_fraction        | 0.21      |
|    clip_range           | 0.2       |
|    entropy_loss         | -1.74     |
|    explained_variance   | 0.963     |
|    learning_rate        | 0.00189   |
|    loss                 | 0.00161   |
|    n_updates            | 2710      |
|    policy_gradient_loss | 0.00222   |
|    std                  | 0.592     |
|    value_loss           | 0.00252   |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 623        |
|    iterations           | 273        |
|    time_elapsed         | 897        |
|    total_timesteps      | 559104     |
| train/                  |            |
|    approx_kl            | 0.06041934 |
|    clip_fraction        | 0.226      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.76      |
|    explained_variance   | 0.948      |
|    learning_rate        | 0.00189    |
|    loss                 | -0.0114    |
|    n_updates            | 2720       |
|    policy_gradient_loss | -4.49e-05  |
|    std                  | 0.595      |
|    value_loss           | 0.00202    |
----------------------------------------
box reached target
box reached target
Eval num_timesteps=560000, episode_reward=1.50 +/- 3.06
Episode length: 246.20 +/- 66.16
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 246         |
|    mean_reward          | 1.5         |
| time/                   |             |
|    total_timesteps      | 560000      |
| train/                  |             |
|    approx_kl            | 0.041475162 |
|    clip_fraction        | 0.245       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.79       |
|    explained_variance   | 0.905       |
|    learning_rate        | 0.00189     |
|    loss                 | 0.0408      |
|    n_updates            | 2730        |
|    policy_gradient_loss | -0.00157    |
|    std                  | 0.613       |
|    value_loss           | 0.00202     |
-----------------------------------------
box reached target
box reached target
-------------------------------
| time/              |        |
|    fps             | 622    |
|    iterations      | 274    |
|    time_elapsed    | 901    |
|    total_timesteps | 561152 |
-------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 622         |
|    iterations           | 275         |
|    time_elapsed         | 904         |
|    total_timesteps      | 563200      |
| train/                  |             |
|    approx_kl            | 0.025351662 |
|    clip_fraction        | 0.195       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.79       |
|    explained_variance   | 0.77        |
|    learning_rate        | 0.00189     |
|    loss                 | 0.0112      |
|    n_updates            | 2740        |
|    policy_gradient_loss | 0.00161     |
|    std                  | 0.594       |
|    value_loss           | 0.0327      |
-----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 623        |
|    iterations           | 276        |
|    time_elapsed         | 907        |
|    total_timesteps      | 565248     |
| train/                  |            |
|    approx_kl            | 0.02590794 |
|    clip_fraction        | 0.243      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.73      |
|    explained_variance   | 0.835      |
|    learning_rate        | 0.00189    |
|    loss                 | -0.0284    |
|    n_updates            | 2750       |
|    policy_gradient_loss | 0.0039     |
|    std                  | 0.583      |
|    value_loss           | 0.000515   |
----------------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 623         |
|    iterations           | 277         |
|    time_elapsed         | 910         |
|    total_timesteps      | 567296      |
| train/                  |             |
|    approx_kl            | 0.021975845 |
|    clip_fraction        | 0.189       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.7        |
|    explained_variance   | 0.819       |
|    learning_rate        | 0.00189     |
|    loss                 | -0.0366     |
|    n_updates            | 2760        |
|    policy_gradient_loss | 0.00176     |
|    std                  | 0.578       |
|    value_loss           | 0.00964     |
-----------------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 623         |
|    iterations           | 278         |
|    time_elapsed         | 913         |
|    total_timesteps      | 569344      |
| train/                  |             |
|    approx_kl            | 0.036329802 |
|    clip_fraction        | 0.217       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.64       |
|    explained_variance   | 0.817       |
|    learning_rate        | 0.00189     |
|    loss                 | 0.0276      |
|    n_updates            | 2770        |
|    policy_gradient_loss | 0.00319     |
|    std                  | 0.556       |
|    value_loss           | 0.00401     |
-----------------------------------------
box reached target
Eval num_timesteps=570000, episode_reward=0.58 +/- 2.47
Episode length: 271.80 +/- 56.40
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 272         |
|    mean_reward          | 0.578       |
| time/                   |             |
|    total_timesteps      | 570000      |
| train/                  |             |
|    approx_kl            | 0.033362523 |
|    clip_fraction        | 0.227       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.58       |
|    explained_variance   | 0.68        |
|    learning_rate        | 0.00189     |
|    loss                 | -0.00307    |
|    n_updates            | 2780        |
|    policy_gradient_loss | -0.00715    |
|    std                  | 0.543       |
|    value_loss           | 0.0079      |
-----------------------------------------
box reached target
-------------------------------
| time/              |        |
|    fps             | 622    |
|    iterations      | 279    |
|    time_elapsed    | 917    |
|    total_timesteps | 571392 |
-------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 622         |
|    iterations           | 280         |
|    time_elapsed         | 920         |
|    total_timesteps      | 573440      |
| train/                  |             |
|    approx_kl            | 0.054031573 |
|    clip_fraction        | 0.271       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.59       |
|    explained_variance   | 0.876       |
|    learning_rate        | 0.00189     |
|    loss                 | -0.0105     |
|    n_updates            | 2790        |
|    policy_gradient_loss | -0.000706   |
|    std                  | 0.553       |
|    value_loss           | 0.00521     |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 623         |
|    iterations           | 281         |
|    time_elapsed         | 923         |
|    total_timesteps      | 575488      |
| train/                  |             |
|    approx_kl            | 0.022049177 |
|    clip_fraction        | 0.209       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.58       |
|    explained_variance   | 0.965       |
|    learning_rate        | 0.00189     |
|    loss                 | -0.0144     |
|    n_updates            | 2800        |
|    policy_gradient_loss | 0.0035      |
|    std                  | 0.543       |
|    value_loss           | 0.00177     |
-----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 623       |
|    iterations           | 282       |
|    time_elapsed         | 926       |
|    total_timesteps      | 577536    |
| train/                  |           |
|    approx_kl            | 0.0916405 |
|    clip_fraction        | 0.256     |
|    clip_range           | 0.2       |
|    entropy_loss         | -1.57     |
|    explained_variance   | 0.541     |
|    learning_rate        | 0.00189   |
|    loss                 | 0.0159    |
|    n_updates            | 2810      |
|    policy_gradient_loss | 0.00943   |
|    std                  | 0.531     |
|    value_loss           | 0.000962  |
---------------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 623         |
|    iterations           | 283         |
|    time_elapsed         | 929         |
|    total_timesteps      | 579584      |
| train/                  |             |
|    approx_kl            | 0.020528536 |
|    clip_fraction        | 0.193       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.57       |
|    explained_variance   | 0.793       |
|    learning_rate        | 0.00189     |
|    loss                 | -0.043      |
|    n_updates            | 2820        |
|    policy_gradient_loss | -0.00038    |
|    std                  | 0.545       |
|    value_loss           | 0.000867    |
-----------------------------------------
Eval num_timesteps=580000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1         |
| time/                   |            |
|    total_timesteps      | 580000     |
| train/                  |            |
|    approx_kl            | 0.03602656 |
|    clip_fraction        | 0.218      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.58      |
|    explained_variance   | 0.873      |
|    learning_rate        | 0.00189    |
|    loss                 | -0.0299    |
|    n_updates            | 2830       |
|    policy_gradient_loss | 0.00197    |
|    std                  | 0.541      |
|    value_loss           | 0.00545    |
----------------------------------------
-------------------------------
| time/              |        |
|    fps             | 622    |
|    iterations      | 284    |
|    time_elapsed    | 933    |
|    total_timesteps | 581632 |
-------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 622         |
|    iterations           | 285         |
|    time_elapsed         | 937         |
|    total_timesteps      | 583680      |
| train/                  |             |
|    approx_kl            | 0.025854826 |
|    clip_fraction        | 0.193       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.57       |
|    explained_variance   | 0.782       |
|    learning_rate        | 0.00189     |
|    loss                 | -0.0376     |
|    n_updates            | 2840        |
|    policy_gradient_loss | 0.00151     |
|    std                  | 0.533       |
|    value_loss           | 0.00148     |
-----------------------------------------
box reached target
box reached target
box reached target
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 623         |
|    iterations           | 286         |
|    time_elapsed         | 940         |
|    total_timesteps      | 585728      |
| train/                  |             |
|    approx_kl            | 0.030113973 |
|    clip_fraction        | 0.221       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.56       |
|    explained_variance   | 0.797       |
|    learning_rate        | 0.00189     |
|    loss                 | 0.012       |
|    n_updates            | 2850        |
|    policy_gradient_loss | -0.00133    |
|    std                  | 0.531       |
|    value_loss           | 0.0045      |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 623         |
|    iterations           | 287         |
|    time_elapsed         | 943         |
|    total_timesteps      | 587776      |
| train/                  |             |
|    approx_kl            | 0.023717647 |
|    clip_fraction        | 0.23        |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.59       |
|    explained_variance   | 0.96        |
|    learning_rate        | 0.00189     |
|    loss                 | 0.0489      |
|    n_updates            | 2860        |
|    policy_gradient_loss | 0.00315     |
|    std                  | 0.537       |
|    value_loss           | 0.00793     |
-----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 623        |
|    iterations           | 288        |
|    time_elapsed         | 946        |
|    total_timesteps      | 589824     |
| train/                  |            |
|    approx_kl            | 0.05998479 |
|    clip_fraction        | 0.259      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.61      |
|    explained_variance   | 0.703      |
|    learning_rate        | 0.00189    |
|    loss                 | 0.0544     |
|    n_updates            | 2870       |
|    policy_gradient_loss | 0.00437    |
|    std                  | 0.543      |
|    value_loss           | 0.00142    |
----------------------------------------
box reached target
Eval num_timesteps=590000, episode_reward=0.38 +/- 2.47
Episode length: 273.60 +/- 52.80
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 274         |
|    mean_reward          | 0.382       |
| time/                   |             |
|    total_timesteps      | 590000      |
| train/                  |             |
|    approx_kl            | 0.025431529 |
|    clip_fraction        | 0.221       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.63       |
|    explained_variance   | 0.967       |
|    learning_rate        | 0.00188     |
|    loss                 | -0.00312    |
|    n_updates            | 2880        |
|    policy_gradient_loss | -0.00163    |
|    std                  | 0.551       |
|    value_loss           | 0.00137     |
-----------------------------------------
-------------------------------
| time/              |        |
|    fps             | 622    |
|    iterations      | 289    |
|    time_elapsed    | 950    |
|    total_timesteps | 591872 |
-------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 622         |
|    iterations           | 290         |
|    time_elapsed         | 953         |
|    total_timesteps      | 593920      |
| train/                  |             |
|    approx_kl            | 0.020432573 |
|    clip_fraction        | 0.189       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.64       |
|    explained_variance   | 0.537       |
|    learning_rate        | 0.00188     |
|    loss                 | 0.0402      |
|    n_updates            | 2890        |
|    policy_gradient_loss | -0.00306    |
|    std                  | 0.545       |
|    value_loss           | 0.00109     |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 623         |
|    iterations           | 291         |
|    time_elapsed         | 956         |
|    total_timesteps      | 595968      |
| train/                  |             |
|    approx_kl            | 0.047759533 |
|    clip_fraction        | 0.257       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.61       |
|    explained_variance   | 0.824       |
|    learning_rate        | 0.00188     |
|    loss                 | -0.0126     |
|    n_updates            | 2900        |
|    policy_gradient_loss | -0.00529    |
|    std                  | 0.539       |
|    value_loss           | 0.000505    |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 623         |
|    iterations           | 292         |
|    time_elapsed         | 959         |
|    total_timesteps      | 598016      |
| train/                  |             |
|    approx_kl            | 0.023294628 |
|    clip_fraction        | 0.22        |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.58       |
|    explained_variance   | 0.84        |
|    learning_rate        | 0.00188     |
|    loss                 | -0.00846    |
|    n_updates            | 2910        |
|    policy_gradient_loss | -0.00065    |
|    std                  | 0.536       |
|    value_loss           | 0.000932    |
-----------------------------------------
Eval num_timesteps=600000, episode_reward=-0.70 +/- 0.60
Episode length: 300.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 300         |
|    mean_reward          | -0.701      |
| time/                   |             |
|    total_timesteps      | 600000      |
| train/                  |             |
|    approx_kl            | 0.024756666 |
|    clip_fraction        | 0.242       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.54       |
|    explained_variance   | 0.725       |
|    learning_rate        | 0.00188     |
|    loss                 | -0.0176     |
|    n_updates            | 2920        |
|    policy_gradient_loss | -0.000288   |
|    std                  | 0.521       |
|    value_loss           | 0.00106     |
-----------------------------------------
-------------------------------
| time/              |        |
|    fps             | 622    |
|    iterations      | 293    |
|    time_elapsed    | 963    |
|    total_timesteps | 600064 |
-------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 294        |
|    time_elapsed         | 966        |
|    total_timesteps      | 602112     |
| train/                  |            |
|    approx_kl            | 0.04546132 |
|    clip_fraction        | 0.254      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.52      |
|    explained_variance   | 0.721      |
|    learning_rate        | 0.00188    |
|    loss                 | 0.0755     |
|    n_updates            | 2930       |
|    policy_gradient_loss | -0.00347   |
|    std                  | 0.512      |
|    value_loss           | 0.000772   |
----------------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 622         |
|    iterations           | 295         |
|    time_elapsed         | 969         |
|    total_timesteps      | 604160      |
| train/                  |             |
|    approx_kl            | 0.033699732 |
|    clip_fraction        | 0.205       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.5        |
|    explained_variance   | 0.626       |
|    learning_rate        | 0.00188     |
|    loss                 | -0.00865    |
|    n_updates            | 2940        |
|    policy_gradient_loss | 0.00481     |
|    std                  | 0.511       |
|    value_loss           | 0.013       |
-----------------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 623        |
|    iterations           | 296        |
|    time_elapsed         | 972        |
|    total_timesteps      | 606208     |
| train/                  |            |
|    approx_kl            | 0.02074289 |
|    clip_fraction        | 0.218      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.51      |
|    explained_variance   | 0.78       |
|    learning_rate        | 0.00188    |
|    loss                 | 0.00987    |
|    n_updates            | 2950       |
|    policy_gradient_loss | 6.64e-06   |
|    std                  | 0.52       |
|    value_loss           | 0.0193     |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 623        |
|    iterations           | 297        |
|    time_elapsed         | 976        |
|    total_timesteps      | 608256     |
| train/                  |            |
|    approx_kl            | 0.04273628 |
|    clip_fraction        | 0.266      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.48      |
|    explained_variance   | 0.866      |
|    learning_rate        | 0.00188    |
|    loss                 | 0.0398     |
|    n_updates            | 2960       |
|    policy_gradient_loss | 0.00791    |
|    std                  | 0.5        |
|    value_loss           | 0.0147     |
----------------------------------------
Eval num_timesteps=610000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 300         |
|    mean_reward          | -1          |
| time/                   |             |
|    total_timesteps      | 610000      |
| train/                  |             |
|    approx_kl            | 0.024222568 |
|    clip_fraction        | 0.223       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.5        |
|    explained_variance   | 0.828       |
|    learning_rate        | 0.00188     |
|    loss                 | 0.0208      |
|    n_updates            | 2970        |
|    policy_gradient_loss | 0.0046      |
|    std                  | 0.516       |
|    value_loss           | 0.00235     |
-----------------------------------------
-------------------------------
| time/              |        |
|    fps             | 622    |
|    iterations      | 298    |
|    time_elapsed    | 980    |
|    total_timesteps | 610304 |
-------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 299        |
|    time_elapsed         | 983        |
|    total_timesteps      | 612352     |
| train/                  |            |
|    approx_kl            | 0.03921657 |
|    clip_fraction        | 0.242      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.58      |
|    explained_variance   | 0.743      |
|    learning_rate        | 0.00188    |
|    loss                 | -0.0206    |
|    n_updates            | 2980       |
|    policy_gradient_loss | -0.0049    |
|    std                  | 0.535      |
|    value_loss           | 0.00066    |
----------------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 622         |
|    iterations           | 300         |
|    time_elapsed         | 986         |
|    total_timesteps      | 614400      |
| train/                  |             |
|    approx_kl            | 0.026442416 |
|    clip_fraction        | 0.222       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.55       |
|    explained_variance   | 0.67        |
|    learning_rate        | 0.00188     |
|    loss                 | -0.0321     |
|    n_updates            | 2990        |
|    policy_gradient_loss | -0.00123    |
|    std                  | 0.522       |
|    value_loss           | 0.00297     |
-----------------------------------------
box reached target
box reached target
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 623         |
|    iterations           | 301         |
|    time_elapsed         | 989         |
|    total_timesteps      | 616448      |
| train/                  |             |
|    approx_kl            | 0.024509713 |
|    clip_fraction        | 0.225       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.53       |
|    explained_variance   | 0.874       |
|    learning_rate        | 0.00188     |
|    loss                 | -0.0361     |
|    n_updates            | 3000        |
|    policy_gradient_loss | 0.00261     |
|    std                  | 0.517       |
|    value_loss           | 0.00626     |
-----------------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 623         |
|    iterations           | 302         |
|    time_elapsed         | 992         |
|    total_timesteps      | 618496      |
| train/                  |             |
|    approx_kl            | 0.026748821 |
|    clip_fraction        | 0.193       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.5        |
|    explained_variance   | 0.963       |
|    learning_rate        | 0.00188     |
|    loss                 | 0.00751     |
|    n_updates            | 3010        |
|    policy_gradient_loss | -0.000626   |
|    std                  | 0.509       |
|    value_loss           | 0.00309     |
-----------------------------------------
box reached target
Eval num_timesteps=620000, episode_reward=0.30 +/- 2.61
Episode length: 285.00 +/- 30.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 285         |
|    mean_reward          | 0.305       |
| time/                   |             |
|    total_timesteps      | 620000      |
| train/                  |             |
|    approx_kl            | 0.026885152 |
|    clip_fraction        | 0.204       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.46       |
|    explained_variance   | 0.791       |
|    learning_rate        | 0.00188     |
|    loss                 | 0.051       |
|    n_updates            | 3020        |
|    policy_gradient_loss | 0.00347     |
|    std                  | 0.502       |
|    value_loss           | 0.0119      |
-----------------------------------------
box reached target
box reached target
-------------------------------
| time/              |        |
|    fps             | 622    |
|    iterations      | 303    |
|    time_elapsed    | 996    |
|    total_timesteps | 620544 |
-------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 622         |
|    iterations           | 304         |
|    time_elapsed         | 999         |
|    total_timesteps      | 622592      |
| train/                  |             |
|    approx_kl            | 0.057924062 |
|    clip_fraction        | 0.242       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.48       |
|    explained_variance   | 0.964       |
|    learning_rate        | 0.00188     |
|    loss                 | -0.0234     |
|    n_updates            | 3030        |
|    policy_gradient_loss | 0.00676     |
|    std                  | 0.511       |
|    value_loss           | 0.00373     |
-----------------------------------------
box reached target
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 622         |
|    iterations           | 305         |
|    time_elapsed         | 1002        |
|    total_timesteps      | 624640      |
| train/                  |             |
|    approx_kl            | 0.031205006 |
|    clip_fraction        | 0.191       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.53       |
|    explained_variance   | 0.897       |
|    learning_rate        | 0.00188     |
|    loss                 | -0.0201     |
|    n_updates            | 3040        |
|    policy_gradient_loss | -0.00337    |
|    std                  | 0.523       |
|    value_loss           | 0.00256     |
-----------------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 622         |
|    iterations           | 306         |
|    time_elapsed         | 1005        |
|    total_timesteps      | 626688      |
| train/                  |             |
|    approx_kl            | 0.029796408 |
|    clip_fraction        | 0.213       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.54       |
|    explained_variance   | 0.921       |
|    learning_rate        | 0.00188     |
|    loss                 | 0.0235      |
|    n_updates            | 3050        |
|    policy_gradient_loss | -0.000591   |
|    std                  | 0.522       |
|    value_loss           | 0.00822     |
-----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 623        |
|    iterations           | 307        |
|    time_elapsed         | 1009       |
|    total_timesteps      | 628736     |
| train/                  |            |
|    approx_kl            | 0.02702833 |
|    clip_fraction        | 0.216      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.48      |
|    explained_variance   | 0.734      |
|    learning_rate        | 0.00188    |
|    loss                 | 0.0211     |
|    n_updates            | 3060       |
|    policy_gradient_loss | 8.29e-05   |
|    std                  | 0.501      |
|    value_loss           | 0.0141     |
----------------------------------------
box reached target
Eval num_timesteps=630000, episode_reward=0.81 +/- 2.24
Episode length: 274.00 +/- 52.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 274        |
|    mean_reward          | 0.814      |
| time/                   |            |
|    total_timesteps      | 630000     |
| train/                  |            |
|    approx_kl            | 0.01817984 |
|    clip_fraction        | 0.211      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.47      |
|    explained_variance   | 0.83       |
|    learning_rate        | 0.00188    |
|    loss                 | -0.0287    |
|    n_updates            | 3070       |
|    policy_gradient_loss | -0.000766  |
|    std                  | 0.503      |
|    value_loss           | 0.0131     |
----------------------------------------
box reached target
box reached target
-------------------------------
| time/              |        |
|    fps             | 622    |
|    iterations      | 308    |
|    time_elapsed    | 1013   |
|    total_timesteps | 630784 |
-------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 622         |
|    iterations           | 309         |
|    time_elapsed         | 1016        |
|    total_timesteps      | 632832      |
| train/                  |             |
|    approx_kl            | 0.055835575 |
|    clip_fraction        | 0.26        |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.49       |
|    explained_variance   | 0.899       |
|    learning_rate        | 0.00188     |
|    loss                 | -0.00811    |
|    n_updates            | 3080        |
|    policy_gradient_loss | 0.00619     |
|    std                  | 0.506       |
|    value_loss           | 0.00714     |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 622         |
|    iterations           | 310         |
|    time_elapsed         | 1019        |
|    total_timesteps      | 634880      |
| train/                  |             |
|    approx_kl            | 0.023445617 |
|    clip_fraction        | 0.203       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.51       |
|    explained_variance   | 0.932       |
|    learning_rate        | 0.00188     |
|    loss                 | 0.015       |
|    n_updates            | 3090        |
|    policy_gradient_loss | -0.00141    |
|    std                  | 0.518       |
|    value_loss           | 0.0023      |
-----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 311        |
|    time_elapsed         | 1022       |
|    total_timesteps      | 636928     |
| train/                  |            |
|    approx_kl            | 0.02305954 |
|    clip_fraction        | 0.225      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.57      |
|    explained_variance   | 0.883      |
|    learning_rate        | 0.00188    |
|    loss                 | 0.105      |
|    n_updates            | 3100       |
|    policy_gradient_loss | 0.00849    |
|    std                  | 0.535      |
|    value_loss           | 0.00323    |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 623        |
|    iterations           | 312        |
|    time_elapsed         | 1025       |
|    total_timesteps      | 638976     |
| train/                  |            |
|    approx_kl            | 0.02658967 |
|    clip_fraction        | 0.211      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.62      |
|    explained_variance   | 0.818      |
|    learning_rate        | 0.00188    |
|    loss                 | -0.0247    |
|    n_updates            | 3110       |
|    policy_gradient_loss | -8.32e-05  |
|    std                  | 0.545      |
|    value_loss           | 0.00182    |
----------------------------------------
box reached target
Eval num_timesteps=640000, episode_reward=0.50 +/- 2.46
Episode length: 274.20 +/- 51.60
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 274        |
|    mean_reward          | 0.498      |
| time/                   |            |
|    total_timesteps      | 640000     |
| train/                  |            |
|    approx_kl            | 0.03440566 |
|    clip_fraction        | 0.204      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.61      |
|    explained_variance   | 0.951      |
|    learning_rate        | 0.00188    |
|    loss                 | 0.167      |
|    n_updates            | 3120       |
|    policy_gradient_loss | -0.00108   |
|    std                  | 0.539      |
|    value_loss           | 0.00412    |
----------------------------------------
-------------------------------
| time/              |        |
|    fps             | 622    |
|    iterations      | 313    |
|    time_elapsed    | 1029   |
|    total_timesteps | 641024 |
-------------------------------
box reached target
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 622         |
|    iterations           | 314         |
|    time_elapsed         | 1032        |
|    total_timesteps      | 643072      |
| train/                  |             |
|    approx_kl            | 0.019828446 |
|    clip_fraction        | 0.199       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.63       |
|    explained_variance   | 0.88        |
|    learning_rate        | 0.00188     |
|    loss                 | -0.00914    |
|    n_updates            | 3130        |
|    policy_gradient_loss | -0.00163    |
|    std                  | 0.553       |
|    value_loss           | 0.00361     |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 622         |
|    iterations           | 315         |
|    time_elapsed         | 1035        |
|    total_timesteps      | 645120      |
| train/                  |             |
|    approx_kl            | 0.025105672 |
|    clip_fraction        | 0.216       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.7        |
|    explained_variance   | 0.803       |
|    learning_rate        | 0.00187     |
|    loss                 | 0.0301      |
|    n_updates            | 3140        |
|    policy_gradient_loss | -0.00321    |
|    std                  | 0.566       |
|    value_loss           | 0.0233      |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 623         |
|    iterations           | 316         |
|    time_elapsed         | 1038        |
|    total_timesteps      | 647168      |
| train/                  |             |
|    approx_kl            | 0.030314453 |
|    clip_fraction        | 0.23        |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.73       |
|    explained_variance   | 0.912       |
|    learning_rate        | 0.00187     |
|    loss                 | 0.0543      |
|    n_updates            | 3150        |
|    policy_gradient_loss | 0.00254     |
|    std                  | 0.579       |
|    value_loss           | 0.00184     |
-----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 623        |
|    iterations           | 317        |
|    time_elapsed         | 1041       |
|    total_timesteps      | 649216     |
| train/                  |            |
|    approx_kl            | 0.01613421 |
|    clip_fraction        | 0.18       |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.78      |
|    explained_variance   | 0.844      |
|    learning_rate        | 0.00187    |
|    loss                 | 0.0527     |
|    n_updates            | 3160       |
|    policy_gradient_loss | 0.00038    |
|    std                  | 0.593      |
|    value_loss           | 0.00129    |
----------------------------------------
box reached target
box reached target
box reached target
Eval num_timesteps=650000, episode_reward=1.49 +/- 3.05
Episode length: 250.80 +/- 60.38
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 251         |
|    mean_reward          | 1.49        |
| time/                   |             |
|    total_timesteps      | 650000      |
| train/                  |             |
|    approx_kl            | 0.018411495 |
|    clip_fraction        | 0.194       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.78       |
|    explained_variance   | 0.887       |
|    learning_rate        | 0.00187     |
|    loss                 | -0.0295     |
|    n_updates            | 3170        |
|    policy_gradient_loss | 0.0058      |
|    std                  | 0.587       |
|    value_loss           | 0.00906     |
-----------------------------------------
-------------------------------
| time/              |        |
|    fps             | 622    |
|    iterations      | 318    |
|    time_elapsed    | 1045   |
|    total_timesteps | 651264 |
-------------------------------
box reached target
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 622         |
|    iterations           | 319         |
|    time_elapsed         | 1048        |
|    total_timesteps      | 653312      |
| train/                  |             |
|    approx_kl            | 0.023020681 |
|    clip_fraction        | 0.192       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.8        |
|    explained_variance   | 0.94        |
|    learning_rate        | 0.00187     |
|    loss                 | -0.00682    |
|    n_updates            | 3180        |
|    policy_gradient_loss | 0.00205     |
|    std                  | 0.599       |
|    value_loss           | 0.00384     |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 622         |
|    iterations           | 320         |
|    time_elapsed         | 1051        |
|    total_timesteps      | 655360      |
| train/                  |             |
|    approx_kl            | 0.028888945 |
|    clip_fraction        | 0.214       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.81       |
|    explained_variance   | 0.864       |
|    learning_rate        | 0.00187     |
|    loss                 | 0.058       |
|    n_updates            | 3190        |
|    policy_gradient_loss | 0.00179     |
|    std                  | 0.596       |
|    value_loss           | 0.00792     |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 623         |
|    iterations           | 321         |
|    time_elapsed         | 1055        |
|    total_timesteps      | 657408      |
| train/                  |             |
|    approx_kl            | 0.029716946 |
|    clip_fraction        | 0.168       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.84       |
|    explained_variance   | 0.876       |
|    learning_rate        | 0.00187     |
|    loss                 | -0.0084     |
|    n_updates            | 3200        |
|    policy_gradient_loss | -0.00523    |
|    std                  | 0.608       |
|    value_loss           | 0.00253     |
-----------------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 623         |
|    iterations           | 322         |
|    time_elapsed         | 1058        |
|    total_timesteps      | 659456      |
| train/                  |             |
|    approx_kl            | 0.026803857 |
|    clip_fraction        | 0.195       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.83       |
|    explained_variance   | 0.865       |
|    learning_rate        | 0.00187     |
|    loss                 | 0.022       |
|    n_updates            | 3210        |
|    policy_gradient_loss | -0.00402    |
|    std                  | 0.602       |
|    value_loss           | 0.00146     |
-----------------------------------------
box reached target
Eval num_timesteps=660000, episode_reward=0.44 +/- 2.43
Episode length: 277.60 +/- 44.80
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 278         |
|    mean_reward          | 0.441       |
| time/                   |             |
|    total_timesteps      | 660000      |
| train/                  |             |
|    approx_kl            | 0.023089401 |
|    clip_fraction        | 0.199       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.77       |
|    explained_variance   | 0.805       |
|    learning_rate        | 0.00187     |
|    loss                 | -0.025      |
|    n_updates            | 3220        |
|    policy_gradient_loss | -0.00078    |
|    std                  | 0.582       |
|    value_loss           | 0.00515     |
-----------------------------------------
box reached target
-------------------------------
| time/              |        |
|    fps             | 622    |
|    iterations      | 323    |
|    time_elapsed    | 1062   |
|    total_timesteps | 661504 |
-------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 622         |
|    iterations           | 324         |
|    time_elapsed         | 1065        |
|    total_timesteps      | 663552      |
| train/                  |             |
|    approx_kl            | 0.017676676 |
|    clip_fraction        | 0.199       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.75       |
|    explained_variance   | 0.767       |
|    learning_rate        | 0.00187     |
|    loss                 | -0.00231    |
|    n_updates            | 3230        |
|    policy_gradient_loss | 0.000455    |
|    std                  | 0.577       |
|    value_loss           | 0.0122      |
-----------------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 622         |
|    iterations           | 325         |
|    time_elapsed         | 1068        |
|    total_timesteps      | 665600      |
| train/                  |             |
|    approx_kl            | 0.025227645 |
|    clip_fraction        | 0.181       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.75       |
|    explained_variance   | 0.771       |
|    learning_rate        | 0.00187     |
|    loss                 | -0.0218     |
|    n_updates            | 3240        |
|    policy_gradient_loss | -0.00321    |
|    std                  | 0.579       |
|    value_loss           | 0.00117     |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 623         |
|    iterations           | 326         |
|    time_elapsed         | 1071        |
|    total_timesteps      | 667648      |
| train/                  |             |
|    approx_kl            | 0.019390736 |
|    clip_fraction        | 0.221       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.72       |
|    explained_variance   | 0.844       |
|    learning_rate        | 0.00187     |
|    loss                 | 0.0195      |
|    n_updates            | 3250        |
|    policy_gradient_loss | -0.000173   |
|    std                  | 0.573       |
|    value_loss           | 0.00392     |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 623         |
|    iterations           | 327         |
|    time_elapsed         | 1074        |
|    total_timesteps      | 669696      |
| train/                  |             |
|    approx_kl            | 0.035928898 |
|    clip_fraction        | 0.18        |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.7        |
|    explained_variance   | 0.808       |
|    learning_rate        | 0.00187     |
|    loss                 | 0.00963     |
|    n_updates            | 3260        |
|    policy_gradient_loss | 0.00344     |
|    std                  | 0.562       |
|    value_loss           | 0.00127     |
-----------------------------------------
box reached target
box reached target
Eval num_timesteps=670000, episode_reward=1.79 +/- 2.95
Episode length: 253.00 +/- 59.61
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 253         |
|    mean_reward          | 1.79        |
| time/                   |             |
|    total_timesteps      | 670000      |
| train/                  |             |
|    approx_kl            | 0.019006066 |
|    clip_fraction        | 0.193       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.73       |
|    explained_variance   | 0.71        |
|    learning_rate        | 0.00187     |
|    loss                 | 0.00531     |
|    n_updates            | 3270        |
|    policy_gradient_loss | 0.00412     |
|    std                  | 0.575       |
|    value_loss           | 0.00225     |
-----------------------------------------
box reached target
-------------------------------
| time/              |        |
|    fps             | 622    |
|    iterations      | 328    |
|    time_elapsed    | 1078   |
|    total_timesteps | 671744 |
-------------------------------
box reached target
box reached target
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 622         |
|    iterations           | 329         |
|    time_elapsed         | 1081        |
|    total_timesteps      | 673792      |
| train/                  |             |
|    approx_kl            | 0.023505777 |
|    clip_fraction        | 0.203       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.75       |
|    explained_variance   | 0.84        |
|    learning_rate        | 0.00187     |
|    loss                 | -0.00791    |
|    n_updates            | 3280        |
|    policy_gradient_loss | -0.000867   |
|    std                  | 0.584       |
|    value_loss           | 0.00761     |
-----------------------------------------
box reached target
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 623         |
|    iterations           | 330         |
|    time_elapsed         | 1084        |
|    total_timesteps      | 675840      |
| train/                  |             |
|    approx_kl            | 0.037030183 |
|    clip_fraction        | 0.244       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.69       |
|    explained_variance   | 0.952       |
|    learning_rate        | 0.00187     |
|    loss                 | -0.0267     |
|    n_updates            | 3290        |
|    policy_gradient_loss | 0.00267     |
|    std                  | 0.559       |
|    value_loss           | 0.0067      |
-----------------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 623         |
|    iterations           | 331         |
|    time_elapsed         | 1087        |
|    total_timesteps      | 677888      |
| train/                  |             |
|    approx_kl            | 0.032941975 |
|    clip_fraction        | 0.209       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.66       |
|    explained_variance   | 0.916       |
|    learning_rate        | 0.00187     |
|    loss                 | 0.0216      |
|    n_updates            | 3300        |
|    policy_gradient_loss | 0.00265     |
|    std                  | 0.557       |
|    value_loss           | 0.00685     |
-----------------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 623         |
|    iterations           | 332         |
|    time_elapsed         | 1090        |
|    total_timesteps      | 679936      |
| train/                  |             |
|    approx_kl            | 0.021220818 |
|    clip_fraction        | 0.197       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.7        |
|    explained_variance   | 0.955       |
|    learning_rate        | 0.00187     |
|    loss                 | 0.0391      |
|    n_updates            | 3310        |
|    policy_gradient_loss | 0.00504     |
|    std                  | 0.574       |
|    value_loss           | 0.00314     |
-----------------------------------------
box reached target
Eval num_timesteps=680000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 300         |
|    mean_reward          | -1          |
| time/                   |             |
|    total_timesteps      | 680000      |
| train/                  |             |
|    approx_kl            | 0.025565984 |
|    clip_fraction        | 0.208       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.73       |
|    explained_variance   | 0.805       |
|    learning_rate        | 0.00187     |
|    loss                 | 0.00398     |
|    n_updates            | 3320        |
|    policy_gradient_loss | -0.00098    |
|    std                  | 0.572       |
|    value_loss           | 0.01        |
-----------------------------------------
box reached target
-------------------------------
| time/              |        |
|    fps             | 622    |
|    iterations      | 333    |
|    time_elapsed    | 1095   |
|    total_timesteps | 681984 |
-------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 622       |
|    iterations           | 334       |
|    time_elapsed         | 1098      |
|    total_timesteps      | 684032    |
| train/                  |           |
|    approx_kl            | 0.0243543 |
|    clip_fraction        | 0.233     |
|    clip_range           | 0.2       |
|    entropy_loss         | -1.68     |
|    explained_variance   | 0.751     |
|    learning_rate        | 0.00187   |
|    loss                 | -0.0032   |
|    n_updates            | 3330      |
|    policy_gradient_loss | 0.00128   |
|    std                  | 0.563     |
|    value_loss           | 0.00834   |
---------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 623         |
|    iterations           | 335         |
|    time_elapsed         | 1101        |
|    total_timesteps      | 686080      |
| train/                  |             |
|    approx_kl            | 0.032456636 |
|    clip_fraction        | 0.224       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.71       |
|    explained_variance   | 0.945       |
|    learning_rate        | 0.00187     |
|    loss                 | -0.0081     |
|    n_updates            | 3340        |
|    policy_gradient_loss | -0.00129    |
|    std                  | 0.574       |
|    value_loss           | 0.00279     |
-----------------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 623         |
|    iterations           | 336         |
|    time_elapsed         | 1104        |
|    total_timesteps      | 688128      |
| train/                  |             |
|    approx_kl            | 0.036397193 |
|    clip_fraction        | 0.203       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.78       |
|    explained_variance   | 0.788       |
|    learning_rate        | 0.00187     |
|    loss                 | 0.0961      |
|    n_updates            | 3350        |
|    policy_gradient_loss | -0.00187    |
|    std                  | 0.594       |
|    value_loss           | 0.00228     |
-----------------------------------------
box reached target
box reached target
box reached target
box reached target
box reached target
Eval num_timesteps=690000, episode_reward=1.44 +/- 2.99
Episode length: 240.80 +/- 72.55
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 241         |
|    mean_reward          | 1.44        |
| time/                   |             |
|    total_timesteps      | 690000      |
| train/                  |             |
|    approx_kl            | 0.026435552 |
|    clip_fraction        | 0.216       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.86       |
|    explained_variance   | 0.85        |
|    learning_rate        | 0.00187     |
|    loss                 | -0.00457    |
|    n_updates            | 3360        |
|    policy_gradient_loss | -0.000293   |
|    std                  | 0.625       |
|    value_loss           | 0.0067      |
-----------------------------------------
-------------------------------
| time/              |        |
|    fps             | 622    |
|    iterations      | 337    |
|    time_elapsed    | 1108   |
|    total_timesteps | 690176 |
-------------------------------
box reached target
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 622         |
|    iterations           | 338         |
|    time_elapsed         | 1111        |
|    total_timesteps      | 692224      |
| train/                  |             |
|    approx_kl            | 0.030285478 |
|    clip_fraction        | 0.207       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.9        |
|    explained_variance   | 0.921       |
|    learning_rate        | 0.00187     |
|    loss                 | -0.0123     |
|    n_updates            | 3370        |
|    policy_gradient_loss | -0.00324    |
|    std                  | 0.627       |
|    value_loss           | 0.00799     |
-----------------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 622         |
|    iterations           | 339         |
|    time_elapsed         | 1114        |
|    total_timesteps      | 694272      |
| train/                  |             |
|    approx_kl            | 0.025626633 |
|    clip_fraction        | 0.206       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.92       |
|    explained_variance   | 0.953       |
|    learning_rate        | 0.00187     |
|    loss                 | -0.0179     |
|    n_updates            | 3380        |
|    policy_gradient_loss | -0.00287    |
|    std                  | 0.635       |
|    value_loss           | 0.00467     |
-----------------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 623         |
|    iterations           | 340         |
|    time_elapsed         | 1117        |
|    total_timesteps      | 696320      |
| train/                  |             |
|    approx_kl            | 0.036542036 |
|    clip_fraction        | 0.212       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.95       |
|    explained_variance   | 0.908       |
|    learning_rate        | 0.00186     |
|    loss                 | 0.0224      |
|    n_updates            | 3390        |
|    policy_gradient_loss | 0.00331     |
|    std                  | 0.645       |
|    value_loss           | 0.00269     |
-----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 623        |
|    iterations           | 341        |
|    time_elapsed         | 1120       |
|    total_timesteps      | 698368     |
| train/                  |            |
|    approx_kl            | 0.05523281 |
|    clip_fraction        | 0.239      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.95      |
|    explained_variance   | 0.974      |
|    learning_rate        | 0.00186    |
|    loss                 | 0.03       |
|    n_updates            | 3400       |
|    policy_gradient_loss | -0.00322   |
|    std                  | 0.633      |
|    value_loss           | 0.00127    |
----------------------------------------
box reached target
Eval num_timesteps=700000, episode_reward=0.22 +/- 2.45
Episode length: 269.40 +/- 61.20
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 269         |
|    mean_reward          | 0.224       |
| time/                   |             |
|    total_timesteps      | 700000      |
| train/                  |             |
|    approx_kl            | 0.017970353 |
|    clip_fraction        | 0.174       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.95       |
|    explained_variance   | 0.82        |
|    learning_rate        | 0.00186     |
|    loss                 | 0.00597     |
|    n_updates            | 3410        |
|    policy_gradient_loss | 0.00291     |
|    std                  | 0.647       |
|    value_loss           | 0.0017      |
-----------------------------------------
-------------------------------
| time/              |        |
|    fps             | 622    |
|    iterations      | 342    |
|    time_elapsed    | 1124   |
|    total_timesteps | 700416 |
-------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 622         |
|    iterations           | 343         |
|    time_elapsed         | 1127        |
|    total_timesteps      | 702464      |
| train/                  |             |
|    approx_kl            | 0.053686395 |
|    clip_fraction        | 0.226       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2          |
|    explained_variance   | 0.794       |
|    learning_rate        | 0.00186     |
|    loss                 | -0.0249     |
|    n_updates            | 3420        |
|    policy_gradient_loss | -0.00138    |
|    std                  | 0.651       |
|    value_loss           | 0.00288     |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 622         |
|    iterations           | 344         |
|    time_elapsed         | 1130        |
|    total_timesteps      | 704512      |
| train/                  |             |
|    approx_kl            | 0.028274262 |
|    clip_fraction        | 0.199       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.95       |
|    explained_variance   | 0.966       |
|    learning_rate        | 0.00186     |
|    loss                 | 0.0112      |
|    n_updates            | 3430        |
|    policy_gradient_loss | 0.000358    |
|    std                  | 0.641       |
|    value_loss           | 0.002       |
-----------------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 623        |
|    iterations           | 345        |
|    time_elapsed         | 1133       |
|    total_timesteps      | 706560     |
| train/                  |            |
|    approx_kl            | 0.02241883 |
|    clip_fraction        | 0.189      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.96      |
|    explained_variance   | 0.778      |
|    learning_rate        | 0.00186    |
|    loss                 | -0.0273    |
|    n_updates            | 3440       |
|    policy_gradient_loss | -0.00382   |
|    std                  | 0.647      |
|    value_loss           | 0.00151    |
----------------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 623         |
|    iterations           | 346         |
|    time_elapsed         | 1137        |
|    total_timesteps      | 708608      |
| train/                  |             |
|    approx_kl            | 0.021707222 |
|    clip_fraction        | 0.196       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.97       |
|    explained_variance   | 0.914       |
|    learning_rate        | 0.00186     |
|    loss                 | 0.00282     |
|    n_updates            | 3450        |
|    policy_gradient_loss | 0.00137     |
|    std                  | 0.653       |
|    value_loss           | 0.00608     |
-----------------------------------------
box reached target
box reached target
box reached target
Eval num_timesteps=710000, episode_reward=1.50 +/- 3.06
Episode length: 237.40 +/- 76.90
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 237         |
|    mean_reward          | 1.5         |
| time/                   |             |
|    total_timesteps      | 710000      |
| train/                  |             |
|    approx_kl            | 0.019239185 |
|    clip_fraction        | 0.18        |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.95       |
|    explained_variance   | 0.939       |
|    learning_rate        | 0.00186     |
|    loss                 | -7.39e-05   |
|    n_updates            | 3460        |
|    policy_gradient_loss | -0.00351    |
|    std                  | 0.637       |
|    value_loss           | 0.00239     |
-----------------------------------------
-------------------------------
| time/              |        |
|    fps             | 622    |
|    iterations      | 347    |
|    time_elapsed    | 1140   |
|    total_timesteps | 710656 |
-------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 622         |
|    iterations           | 348         |
|    time_elapsed         | 1144        |
|    total_timesteps      | 712704      |
| train/                  |             |
|    approx_kl            | 0.028601516 |
|    clip_fraction        | 0.218       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.95       |
|    explained_variance   | 0.823       |
|    learning_rate        | 0.00186     |
|    loss                 | 0.0598      |
|    n_updates            | 3470        |
|    policy_gradient_loss | 0.00764     |
|    std                  | 0.642       |
|    value_loss           | 0.00892     |
-----------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 623       |
|    iterations           | 349       |
|    time_elapsed         | 1147      |
|    total_timesteps      | 714752    |
| train/                  |           |
|    approx_kl            | 0.1599415 |
|    clip_fraction        | 0.225     |
|    clip_range           | 0.2       |
|    entropy_loss         | -1.92     |
|    explained_variance   | 0.59      |
|    learning_rate        | 0.00186   |
|    loss                 | 0.036     |
|    n_updates            | 3480      |
|    policy_gradient_loss | -0.0019   |
|    std                  | 0.628     |
|    value_loss           | 0.00161   |
---------------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 623         |
|    iterations           | 350         |
|    time_elapsed         | 1150        |
|    total_timesteps      | 716800      |
| train/                  |             |
|    approx_kl            | 0.061437473 |
|    clip_fraction        | 0.245       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.87       |
|    explained_variance   | 0.695       |
|    learning_rate        | 0.00186     |
|    loss                 | 0.0427      |
|    n_updates            | 3490        |
|    policy_gradient_loss | 0.00256     |
|    std                  | 0.612       |
|    value_loss           | 0.0058      |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 623         |
|    iterations           | 351         |
|    time_elapsed         | 1153        |
|    total_timesteps      | 718848      |
| train/                  |             |
|    approx_kl            | 0.021681845 |
|    clip_fraction        | 0.191       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.86       |
|    explained_variance   | 0.952       |
|    learning_rate        | 0.00186     |
|    loss                 | -0.00392    |
|    n_updates            | 3500        |
|    policy_gradient_loss | -0.00241    |
|    std                  | 0.613       |
|    value_loss           | 0.00296     |
-----------------------------------------
box reached target
Eval num_timesteps=720000, episode_reward=-0.46 +/- 0.67
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -0.462     |
| time/                   |            |
|    total_timesteps      | 720000     |
| train/                  |            |
|    approx_kl            | 0.11378856 |
|    clip_fraction        | 0.25       |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.87      |
|    explained_variance   | 0.761      |
|    learning_rate        | 0.00186    |
|    loss                 | 0.000899   |
|    n_updates            | 3510       |
|    policy_gradient_loss | -0.00127   |
|    std                  | 0.62       |
|    value_loss           | 0.00244    |
----------------------------------------
box reached target
-------------------------------
| time/              |        |
|    fps             | 622    |
|    iterations      | 352    |
|    time_elapsed    | 1157   |
|    total_timesteps | 720896 |
-------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 353        |
|    time_elapsed         | 1160       |
|    total_timesteps      | 722944     |
| train/                  |            |
|    approx_kl            | 0.02189604 |
|    clip_fraction        | 0.227      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.85      |
|    explained_variance   | 0.963      |
|    learning_rate        | 0.00186    |
|    loss                 | -0.0322    |
|    n_updates            | 3520       |
|    policy_gradient_loss | 0.0085     |
|    std                  | 0.609      |
|    value_loss           | 0.00487    |
----------------------------------------
box reached target
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 623         |
|    iterations           | 354         |
|    time_elapsed         | 1163        |
|    total_timesteps      | 724992      |
| train/                  |             |
|    approx_kl            | 0.039851233 |
|    clip_fraction        | 0.205       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.87       |
|    explained_variance   | 0.9         |
|    learning_rate        | 0.00186     |
|    loss                 | -0.0401     |
|    n_updates            | 3530        |
|    policy_gradient_loss | 0.000742    |
|    std                  | 0.62        |
|    value_loss           | 0.00181     |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 623         |
|    iterations           | 355         |
|    time_elapsed         | 1166        |
|    total_timesteps      | 727040      |
| train/                  |             |
|    approx_kl            | 0.022702195 |
|    clip_fraction        | 0.203       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.87       |
|    explained_variance   | 0.953       |
|    learning_rate        | 0.00186     |
|    loss                 | 0.00654     |
|    n_updates            | 3540        |
|    policy_gradient_loss | 0.00141     |
|    std                  | 0.625       |
|    value_loss           | 0.00326     |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 623         |
|    iterations           | 356         |
|    time_elapsed         | 1169        |
|    total_timesteps      | 729088      |
| train/                  |             |
|    approx_kl            | 0.036595084 |
|    clip_fraction        | 0.208       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.92       |
|    explained_variance   | 0.823       |
|    learning_rate        | 0.00186     |
|    loss                 | -0.0273     |
|    n_updates            | 3550        |
|    policy_gradient_loss | -0.00865    |
|    std                  | 0.633       |
|    value_loss           | 0.00156     |
-----------------------------------------
box reached target
Eval num_timesteps=730000, episode_reward=0.24 +/- 2.47
Episode length: 272.80 +/- 54.40
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 273        |
|    mean_reward          | 0.236      |
| time/                   |            |
|    total_timesteps      | 730000     |
| train/                  |            |
|    approx_kl            | 0.03892551 |
|    clip_fraction        | 0.23       |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.89      |
|    explained_variance   | 0.645      |
|    learning_rate        | 0.00186    |
|    loss                 | 0.00159    |
|    n_updates            | 3560       |
|    policy_gradient_loss | -0.00268   |
|    std                  | 0.627      |
|    value_loss           | 0.000614   |
----------------------------------------
-------------------------------
| time/              |        |
|    fps             | 622    |
|    iterations      | 357    |
|    time_elapsed    | 1173   |
|    total_timesteps | 731136 |
-------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 622         |
|    iterations           | 358         |
|    time_elapsed         | 1176        |
|    total_timesteps      | 733184      |
| train/                  |             |
|    approx_kl            | 0.020021576 |
|    clip_fraction        | 0.219       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.87       |
|    explained_variance   | 0.842       |
|    learning_rate        | 0.00186     |
|    loss                 | -0.00687    |
|    n_updates            | 3570        |
|    policy_gradient_loss | -0.00034    |
|    std                  | 0.619       |
|    value_loss           | 0.00193     |
-----------------------------------------
box reached target
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 623         |
|    iterations           | 359         |
|    time_elapsed         | 1179        |
|    total_timesteps      | 735232      |
| train/                  |             |
|    approx_kl            | 0.051906973 |
|    clip_fraction        | 0.228       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.9        |
|    explained_variance   | 0.729       |
|    learning_rate        | 0.00186     |
|    loss                 | -0.0206     |
|    n_updates            | 3580        |
|    policy_gradient_loss | -0.00667    |
|    std                  | 0.634       |
|    value_loss           | 0.000952    |
-----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 623        |
|    iterations           | 360        |
|    time_elapsed         | 1183       |
|    total_timesteps      | 737280     |
| train/                  |            |
|    approx_kl            | 0.02931362 |
|    clip_fraction        | 0.231      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.88      |
|    explained_variance   | 0.797      |
|    learning_rate        | 0.00186    |
|    loss                 | -0.00421   |
|    n_updates            | 3590       |
|    policy_gradient_loss | -0.00364   |
|    std                  | 0.614      |
|    value_loss           | 0.0158     |
----------------------------------------
box reached target
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 623         |
|    iterations           | 361         |
|    time_elapsed         | 1186        |
|    total_timesteps      | 739328      |
| train/                  |             |
|    approx_kl            | 0.068015136 |
|    clip_fraction        | 0.236       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.84       |
|    explained_variance   | 0.903       |
|    learning_rate        | 0.00186     |
|    loss                 | 0.0235      |
|    n_updates            | 3600        |
|    policy_gradient_loss | -0.00129    |
|    std                  | 0.609       |
|    value_loss           | 0.00363     |
-----------------------------------------
Eval num_timesteps=740000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 300         |
|    mean_reward          | -1          |
| time/                   |             |
|    total_timesteps      | 740000      |
| train/                  |             |
|    approx_kl            | 0.028863873 |
|    clip_fraction        | 0.215       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.83       |
|    explained_variance   | 0.962       |
|    learning_rate        | 0.00186     |
|    loss                 | 0.00332     |
|    n_updates            | 3610        |
|    policy_gradient_loss | 0.00101     |
|    std                  | 0.607       |
|    value_loss           | 0.0029      |
-----------------------------------------
box reached target
box reached target
-------------------------------
| time/              |        |
|    fps             | 622    |
|    iterations      | 362    |
|    time_elapsed    | 1190   |
|    total_timesteps | 741376 |
-------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 363        |
|    time_elapsed         | 1193       |
|    total_timesteps      | 743424     |
| train/                  |            |
|    approx_kl            | 0.05133476 |
|    clip_fraction        | 0.243      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.82      |
|    explained_variance   | 0.873      |
|    learning_rate        | 0.00186    |
|    loss                 | -0.015     |
|    n_updates            | 3620       |
|    policy_gradient_loss | 0.00217    |
|    std                  | 0.598      |
|    value_loss           | 0.00906    |
----------------------------------------
box reached target
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 623         |
|    iterations           | 364         |
|    time_elapsed         | 1196        |
|    total_timesteps      | 745472      |
| train/                  |             |
|    approx_kl            | 0.029212646 |
|    clip_fraction        | 0.193       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.81       |
|    explained_variance   | 0.853       |
|    learning_rate        | 0.00186     |
|    loss                 | -0.0224     |
|    n_updates            | 3630        |
|    policy_gradient_loss | 0.000174    |
|    std                  | 0.596       |
|    value_loss           | 0.00346     |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 623         |
|    iterations           | 365         |
|    time_elapsed         | 1199        |
|    total_timesteps      | 747520      |
| train/                  |             |
|    approx_kl            | 0.026088076 |
|    clip_fraction        | 0.216       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.77       |
|    explained_variance   | 0.819       |
|    learning_rate        | 0.00185     |
|    loss                 | 0.0132      |
|    n_updates            | 3640        |
|    policy_gradient_loss | 0.00381     |
|    std                  | 0.591       |
|    value_loss           | 0.0186      |
-----------------------------------------
box reached target
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 623         |
|    iterations           | 366         |
|    time_elapsed         | 1202        |
|    total_timesteps      | 749568      |
| train/                  |             |
|    approx_kl            | 0.025679907 |
|    clip_fraction        | 0.226       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.82       |
|    explained_variance   | 0.701       |
|    learning_rate        | 0.00185     |
|    loss                 | 0.0122      |
|    n_updates            | 3650        |
|    policy_gradient_loss | 0.00428     |
|    std                  | 0.61        |
|    value_loss           | 0.00182     |
-----------------------------------------
box reached target
Eval num_timesteps=750000, episode_reward=0.23 +/- 2.46
Episode length: 274.40 +/- 51.20
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 274         |
|    mean_reward          | 0.232       |
| time/                   |             |
|    total_timesteps      | 750000      |
| train/                  |             |
|    approx_kl            | 0.028731085 |
|    clip_fraction        | 0.248       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.83       |
|    explained_variance   | 0.831       |
|    learning_rate        | 0.00185     |
|    loss                 | 0.0375      |
|    n_updates            | 3660        |
|    policy_gradient_loss | 0.00115     |
|    std                  | 0.608       |
|    value_loss           | 0.0181      |
-----------------------------------------
-------------------------------
| time/              |        |
|    fps             | 622    |
|    iterations      | 367    |
|    time_elapsed    | 1206   |
|    total_timesteps | 751616 |
-------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 368        |
|    time_elapsed         | 1209       |
|    total_timesteps      | 753664     |
| train/                  |            |
|    approx_kl            | 0.02771793 |
|    clip_fraction        | 0.242      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.81      |
|    explained_variance   | 0.919      |
|    learning_rate        | 0.00185    |
|    loss                 | -0.0319    |
|    n_updates            | 3670       |
|    policy_gradient_loss | -0.00323   |
|    std                  | 0.603      |
|    value_loss           | 0.0024     |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 623        |
|    iterations           | 369        |
|    time_elapsed         | 1212       |
|    total_timesteps      | 755712     |
| train/                  |            |
|    approx_kl            | 0.03988954 |
|    clip_fraction        | 0.234      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.81      |
|    explained_variance   | 0.931      |
|    learning_rate        | 0.00185    |
|    loss                 | -0.0136    |
|    n_updates            | 3680       |
|    policy_gradient_loss | -0.00303   |
|    std                  | 0.613      |
|    value_loss           | 0.00274    |
----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 623       |
|    iterations           | 370       |
|    time_elapsed         | 1216      |
|    total_timesteps      | 757760    |
| train/                  |           |
|    approx_kl            | 0.0420114 |
|    clip_fraction        | 0.269     |
|    clip_range           | 0.2       |
|    entropy_loss         | -1.74     |
|    explained_variance   | 0.69      |
|    learning_rate        | 0.00185   |
|    loss                 | -0.0197   |
|    n_updates            | 3690      |
|    policy_gradient_loss | 0.00272   |
|    std                  | 0.577     |
|    value_loss           | 0.00465   |
---------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 623         |
|    iterations           | 371         |
|    time_elapsed         | 1219        |
|    total_timesteps      | 759808      |
| train/                  |             |
|    approx_kl            | 0.025688097 |
|    clip_fraction        | 0.204       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.72       |
|    explained_variance   | 0.798       |
|    learning_rate        | 0.00185     |
|    loss                 | -0.0128     |
|    n_updates            | 3700        |
|    policy_gradient_loss | 0.00181     |
|    std                  | 0.581       |
|    value_loss           | 0.0101      |
-----------------------------------------
Eval num_timesteps=760000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 300         |
|    mean_reward          | -1          |
| time/                   |             |
|    total_timesteps      | 760000      |
| train/                  |             |
|    approx_kl            | 0.045836516 |
|    clip_fraction        | 0.245       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.75       |
|    explained_variance   | 0.785       |
|    learning_rate        | 0.00185     |
|    loss                 | 0.012       |
|    n_updates            | 3710        |
|    policy_gradient_loss | 0.00471     |
|    std                  | 0.583       |
|    value_loss           | 0.00288     |
-----------------------------------------
box reached target
box reached target
-------------------------------
| time/              |        |
|    fps             | 622    |
|    iterations      | 372    |
|    time_elapsed    | 1223   |
|    total_timesteps | 761856 |
-------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 622         |
|    iterations           | 373         |
|    time_elapsed         | 1226        |
|    total_timesteps      | 763904      |
| train/                  |             |
|    approx_kl            | 0.029461104 |
|    clip_fraction        | 0.246       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.72       |
|    explained_variance   | 0.845       |
|    learning_rate        | 0.00185     |
|    loss                 | -0.00544    |
|    n_updates            | 3720        |
|    policy_gradient_loss | 0.00385     |
|    std                  | 0.583       |
|    value_loss           | 0.00789     |
-----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 623        |
|    iterations           | 374        |
|    time_elapsed         | 1229       |
|    total_timesteps      | 765952     |
| train/                  |            |
|    approx_kl            | 0.03276487 |
|    clip_fraction        | 0.259      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.74      |
|    explained_variance   | 0.912      |
|    learning_rate        | 0.00185    |
|    loss                 | 0.0139     |
|    n_updates            | 3730       |
|    policy_gradient_loss | 0.00977    |
|    std                  | 0.582      |
|    value_loss           | 0.00576    |
----------------------------------------
box reached target
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 623         |
|    iterations           | 375         |
|    time_elapsed         | 1232        |
|    total_timesteps      | 768000      |
| train/                  |             |
|    approx_kl            | 0.032229148 |
|    clip_fraction        | 0.258       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.76       |
|    explained_variance   | 0.782       |
|    learning_rate        | 0.00185     |
|    loss                 | -0.00718    |
|    n_updates            | 3740        |
|    policy_gradient_loss | -0.00215    |
|    std                  | 0.59        |
|    value_loss           | 0.00131     |
-----------------------------------------
box reached target
box reached target
box reached target
Eval num_timesteps=770000, episode_reward=1.82 +/- 2.93
Episode length: 252.20 +/- 60.56
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 252         |
|    mean_reward          | 1.82        |
| time/                   |             |
|    total_timesteps      | 770000      |
| train/                  |             |
|    approx_kl            | 0.015412039 |
|    clip_fraction        | 0.215       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.75       |
|    explained_variance   | 0.741       |
|    learning_rate        | 0.00185     |
|    loss                 | 0.0209      |
|    n_updates            | 3750        |
|    policy_gradient_loss | -0.00492    |
|    std                  | 0.587       |
|    value_loss           | 0.0141      |
-----------------------------------------
New best mean reward!
-------------------------------
| time/              |        |
|    fps             | 622    |
|    iterations      | 376    |
|    time_elapsed    | 1236   |
|    total_timesteps | 770048 |
-------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 622         |
|    iterations           | 377         |
|    time_elapsed         | 1239        |
|    total_timesteps      | 772096      |
| train/                  |             |
|    approx_kl            | 0.025599048 |
|    clip_fraction        | 0.242       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.78       |
|    explained_variance   | 0.963       |
|    learning_rate        | 0.00185     |
|    loss                 | -0.0171     |
|    n_updates            | 3760        |
|    policy_gradient_loss | 0.00106     |
|    std                  | 0.596       |
|    value_loss           | 0.00361     |
-----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 378        |
|    time_elapsed         | 1242       |
|    total_timesteps      | 774144     |
| train/                  |            |
|    approx_kl            | 0.03551384 |
|    clip_fraction        | 0.226      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.78      |
|    explained_variance   | 0.685      |
|    learning_rate        | 0.00185    |
|    loss                 | -0.00418   |
|    n_updates            | 3770       |
|    policy_gradient_loss | 0.00658    |
|    std                  | 0.6        |
|    value_loss           | 0.00223    |
----------------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 623        |
|    iterations           | 379        |
|    time_elapsed         | 1245       |
|    total_timesteps      | 776192     |
| train/                  |            |
|    approx_kl            | 0.02880565 |
|    clip_fraction        | 0.212      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.8       |
|    explained_variance   | 0.876      |
|    learning_rate        | 0.00185    |
|    loss                 | 0.0116     |
|    n_updates            | 3780       |
|    policy_gradient_loss | -0.000485  |
|    std                  | 0.601      |
|    value_loss           | 0.00455    |
----------------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 623         |
|    iterations           | 380         |
|    time_elapsed         | 1248        |
|    total_timesteps      | 778240      |
| train/                  |             |
|    approx_kl            | 0.025920272 |
|    clip_fraction        | 0.219       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.79       |
|    explained_variance   | 0.94        |
|    learning_rate        | 0.00185     |
|    loss                 | 0.0139      |
|    n_updates            | 3790        |
|    policy_gradient_loss | 0.00251     |
|    std                  | 0.594       |
|    value_loss           | 0.00516     |
-----------------------------------------
box reached target
box reached target
box reached target
box reached target
box reached target
Eval num_timesteps=780000, episode_reward=1.44 +/- 2.99
Episode length: 250.60 +/- 61.51
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 251         |
|    mean_reward          | 1.44        |
| time/                   |             |
|    total_timesteps      | 780000      |
| train/                  |             |
|    approx_kl            | 0.029896576 |
|    clip_fraction        | 0.195       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.77       |
|    explained_variance   | 0.936       |
|    learning_rate        | 0.00185     |
|    loss                 | -0.0178     |
|    n_updates            | 3800        |
|    policy_gradient_loss | -0.00027    |
|    std                  | 0.585       |
|    value_loss           | 0.00566     |
-----------------------------------------
-------------------------------
| time/              |        |
|    fps             | 622    |
|    iterations      | 381    |
|    time_elapsed    | 1252   |
|    total_timesteps | 780288 |
-------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 622       |
|    iterations           | 382       |
|    time_elapsed         | 1255      |
|    total_timesteps      | 782336    |
| train/                  |           |
|    approx_kl            | 0.0266798 |
|    clip_fraction        | 0.169     |
|    clip_range           | 0.2       |
|    entropy_loss         | -1.78     |
|    explained_variance   | 0.946     |
|    learning_rate        | 0.00185   |
|    loss                 | -0.0345   |
|    n_updates            | 3810      |
|    policy_gradient_loss | -0.000622 |
|    std                  | 0.596     |
|    value_loss           | 0.0133    |
---------------------------------------
box reached target
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 623         |
|    iterations           | 383         |
|    time_elapsed         | 1258        |
|    total_timesteps      | 784384      |
| train/                  |             |
|    approx_kl            | 0.030363679 |
|    clip_fraction        | 0.172       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.83       |
|    explained_variance   | 0.89        |
|    learning_rate        | 0.00185     |
|    loss                 | -0.00724    |
|    n_updates            | 3820        |
|    policy_gradient_loss | -0.0071     |
|    std                  | 0.612       |
|    value_loss           | 0.0143      |
-----------------------------------------
box reached target
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 623         |
|    iterations           | 384         |
|    time_elapsed         | 1262        |
|    total_timesteps      | 786432      |
| train/                  |             |
|    approx_kl            | 0.024044141 |
|    clip_fraction        | 0.243       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.86       |
|    explained_variance   | 0.977       |
|    learning_rate        | 0.00185     |
|    loss                 | 0.0177      |
|    n_updates            | 3830        |
|    policy_gradient_loss | -0.00239    |
|    std                  | 0.627       |
|    value_loss           | 0.00464     |
-----------------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 623         |
|    iterations           | 385         |
|    time_elapsed         | 1265        |
|    total_timesteps      | 788480      |
| train/                  |             |
|    approx_kl            | 0.074044086 |
|    clip_fraction        | 0.234       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.87       |
|    explained_variance   | 0.944       |
|    learning_rate        | 0.00185     |
|    loss                 | 0.000386    |
|    n_updates            | 3840        |
|    policy_gradient_loss | 0.00581     |
|    std                  | 0.627       |
|    value_loss           | 0.00479     |
-----------------------------------------
box reached target
box reached target
box reached target
Eval num_timesteps=790000, episode_reward=1.49 +/- 3.05
Episode length: 244.00 +/- 69.24
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 244         |
|    mean_reward          | 1.49        |
| time/                   |             |
|    total_timesteps      | 790000      |
| train/                  |             |
|    approx_kl            | 0.036830246 |
|    clip_fraction        | 0.284       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.85       |
|    explained_variance   | 0.918       |
|    learning_rate        | 0.00185     |
|    loss                 | -0.0304     |
|    n_updates            | 3850        |
|    policy_gradient_loss | -0.000303   |
|    std                  | 0.62        |
|    value_loss           | 0.0079      |
-----------------------------------------
-------------------------------
| time/              |        |
|    fps             | 622    |
|    iterations      | 386    |
|    time_elapsed    | 1269   |
|    total_timesteps | 790528 |
-------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 623        |
|    iterations           | 387        |
|    time_elapsed         | 1272       |
|    total_timesteps      | 792576     |
| train/                  |            |
|    approx_kl            | 0.02169634 |
|    clip_fraction        | 0.191      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.88      |
|    explained_variance   | 0.819      |
|    learning_rate        | 0.00185    |
|    loss                 | 0.018      |
|    n_updates            | 3860       |
|    policy_gradient_loss | 0.000734   |
|    std                  | 0.633      |
|    value_loss           | 0.0186     |
----------------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 623         |
|    iterations           | 388         |
|    time_elapsed         | 1275        |
|    total_timesteps      | 794624      |
| train/                  |             |
|    approx_kl            | 0.033109993 |
|    clip_fraction        | 0.218       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.88       |
|    explained_variance   | 0.922       |
|    learning_rate        | 0.00185     |
|    loss                 | 0.0135      |
|    n_updates            | 3870        |
|    policy_gradient_loss | -0.00474    |
|    std                  | 0.631       |
|    value_loss           | 0.00352     |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 623         |
|    iterations           | 389         |
|    time_elapsed         | 1278        |
|    total_timesteps      | 796672      |
| train/                  |             |
|    approx_kl            | 0.020960271 |
|    clip_fraction        | 0.19        |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.9        |
|    explained_variance   | 0.881       |
|    learning_rate        | 0.00185     |
|    loss                 | 0.00305     |
|    n_updates            | 3880        |
|    policy_gradient_loss | 0.00265     |
|    std                  | 0.637       |
|    value_loss           | 0.005       |
-----------------------------------------
box reached target
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 623        |
|    iterations           | 390        |
|    time_elapsed         | 1281       |
|    total_timesteps      | 798720     |
| train/                  |            |
|    approx_kl            | 0.02623368 |
|    clip_fraction        | 0.186      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.92      |
|    explained_variance   | 0.854      |
|    learning_rate        | 0.00184    |
|    loss                 | 0.0148     |
|    n_updates            | 3890       |
|    policy_gradient_loss | -0.00624   |
|    std                  | 0.644      |
|    value_loss           | 0.00301    |
----------------------------------------
box reached target
box reached target
Eval num_timesteps=800000, episode_reward=0.30 +/- 2.61
Episode length: 275.80 +/- 48.40
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 276         |
|    mean_reward          | 0.303       |
| time/                   |             |
|    total_timesteps      | 800000      |
| train/                  |             |
|    approx_kl            | 0.027208237 |
|    clip_fraction        | 0.21        |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.91       |
|    explained_variance   | 0.922       |
|    learning_rate        | 0.00184     |
|    loss                 | 0.0303      |
|    n_updates            | 3900        |
|    policy_gradient_loss | -0.0044     |
|    std                  | 0.629       |
|    value_loss           | 0.0121      |
-----------------------------------------
box reached target
-------------------------------
| time/              |        |
|    fps             | 622    |
|    iterations      | 391    |
|    time_elapsed    | 1285   |
|    total_timesteps | 800768 |
-------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 392        |
|    time_elapsed         | 1288       |
|    total_timesteps      | 802816     |
| train/                  |            |
|    approx_kl            | 0.04783926 |
|    clip_fraction        | 0.261      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.87      |
|    explained_variance   | 0.932      |
|    learning_rate        | 0.00184    |
|    loss                 | 0.0264     |
|    n_updates            | 3910       |
|    policy_gradient_loss | 0.000305   |
|    std                  | 0.614      |
|    value_loss           | 0.00707    |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 623        |
|    iterations           | 393        |
|    time_elapsed         | 1291       |
|    total_timesteps      | 804864     |
| train/                  |            |
|    approx_kl            | 0.04117479 |
|    clip_fraction        | 0.187      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.85      |
|    explained_variance   | 0.73       |
|    learning_rate        | 0.00184    |
|    loss                 | 0.0576     |
|    n_updates            | 3920       |
|    policy_gradient_loss | 0.00214    |
|    std                  | 0.609      |
|    value_loss           | 0.00157    |
----------------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 623         |
|    iterations           | 394         |
|    time_elapsed         | 1294        |
|    total_timesteps      | 806912      |
| train/                  |             |
|    approx_kl            | 0.023786524 |
|    clip_fraction        | 0.216       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.79       |
|    explained_variance   | 0.645       |
|    learning_rate        | 0.00184     |
|    loss                 | -0.0224     |
|    n_updates            | 3930        |
|    policy_gradient_loss | -0.00303    |
|    std                  | 0.582       |
|    value_loss           | 0.0126      |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 623         |
|    iterations           | 395         |
|    time_elapsed         | 1297        |
|    total_timesteps      | 808960      |
| train/                  |             |
|    approx_kl            | 0.031878978 |
|    clip_fraction        | 0.243       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.73       |
|    explained_variance   | 0.902       |
|    learning_rate        | 0.00184     |
|    loss                 | 0.00545     |
|    n_updates            | 3940        |
|    policy_gradient_loss | -0.0051     |
|    std                  | 0.576       |
|    value_loss           | 0.011       |
-----------------------------------------
box reached target
box reached target
Eval num_timesteps=810000, episode_reward=1.49 +/- 3.04
Episode length: 240.00 +/- 73.55
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 240         |
|    mean_reward          | 1.49        |
| time/                   |             |
|    total_timesteps      | 810000      |
| train/                  |             |
|    approx_kl            | 0.024384458 |
|    clip_fraction        | 0.226       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.68       |
|    explained_variance   | 0.899       |
|    learning_rate        | 0.00184     |
|    loss                 | 0.0108      |
|    n_updates            | 3950        |
|    policy_gradient_loss | 0.000849    |
|    std                  | 0.556       |
|    value_loss           | 0.00216     |
-----------------------------------------
-------------------------------
| time/              |        |
|    fps             | 622    |
|    iterations      | 396    |
|    time_elapsed    | 1301   |
|    total_timesteps | 811008 |
-------------------------------
box reached target
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 623         |
|    iterations           | 397         |
|    time_elapsed         | 1304        |
|    total_timesteps      | 813056      |
| train/                  |             |
|    approx_kl            | 0.029162025 |
|    clip_fraction        | 0.23        |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.68       |
|    explained_variance   | 0.899       |
|    learning_rate        | 0.00184     |
|    loss                 | -0.0115     |
|    n_updates            | 3960        |
|    policy_gradient_loss | -0.00471    |
|    std                  | 0.566       |
|    value_loss           | 0.00179     |
-----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 623       |
|    iterations           | 398       |
|    time_elapsed         | 1308      |
|    total_timesteps      | 815104    |
| train/                  |           |
|    approx_kl            | 0.0212689 |
|    clip_fraction        | 0.201     |
|    clip_range           | 0.2       |
|    entropy_loss         | -1.65     |
|    explained_variance   | 0.804     |
|    learning_rate        | 0.00184   |
|    loss                 | 0.049     |
|    n_updates            | 3970      |
|    policy_gradient_loss | 0.00189   |
|    std                  | 0.549     |
|    value_loss           | 0.016     |
---------------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 623         |
|    iterations           | 399         |
|    time_elapsed         | 1311        |
|    total_timesteps      | 817152      |
| train/                  |             |
|    approx_kl            | 0.041196678 |
|    clip_fraction        | 0.215       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.63       |
|    explained_variance   | 0.439       |
|    learning_rate        | 0.00184     |
|    loss                 | -0.0241     |
|    n_updates            | 3980        |
|    policy_gradient_loss | -0.00235    |
|    std                  | 0.548       |
|    value_loss           | 0.00109     |
-----------------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 623         |
|    iterations           | 400         |
|    time_elapsed         | 1314        |
|    total_timesteps      | 819200      |
| train/                  |             |
|    approx_kl            | 0.026502937 |
|    clip_fraction        | 0.201       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.6        |
|    explained_variance   | 0.92        |
|    learning_rate        | 0.00184     |
|    loss                 | 0.00966     |
|    n_updates            | 3990        |
|    policy_gradient_loss | -0.00545    |
|    std                  | 0.538       |
|    value_loss           | 0.00543     |
-----------------------------------------
box reached target
box reached target
box reached target
Eval num_timesteps=820000, episode_reward=0.36 +/- 2.48
Episode length: 271.00 +/- 58.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 271        |
|    mean_reward          | 0.364      |
| time/                   |            |
|    total_timesteps      | 820000     |
| train/                  |            |
|    approx_kl            | 0.02302707 |
|    clip_fraction        | 0.221      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.59      |
|    explained_variance   | 0.908      |
|    learning_rate        | 0.00184    |
|    loss                 | 0.00913    |
|    n_updates            | 4000       |
|    policy_gradient_loss | -0.00112   |
|    std                  | 0.538      |
|    value_loss           | 0.00294    |
----------------------------------------
box reached target
-------------------------------
| time/              |        |
|    fps             | 623    |
|    iterations      | 401    |
|    time_elapsed    | 1318   |
|    total_timesteps | 821248 |
-------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 623         |
|    iterations           | 402         |
|    time_elapsed         | 1321        |
|    total_timesteps      | 823296      |
| train/                  |             |
|    approx_kl            | 0.032980613 |
|    clip_fraction        | 0.241       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.61       |
|    explained_variance   | 0.937       |
|    learning_rate        | 0.00184     |
|    loss                 | 0.00586     |
|    n_updates            | 4010        |
|    policy_gradient_loss | -0.00124    |
|    std                  | 0.539       |
|    value_loss           | 0.0133      |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 623         |
|    iterations           | 403         |
|    time_elapsed         | 1324        |
|    total_timesteps      | 825344      |
| train/                  |             |
|    approx_kl            | 0.019739266 |
|    clip_fraction        | 0.205       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.6        |
|    explained_variance   | 0.82        |
|    learning_rate        | 0.00184     |
|    loss                 | -0.00864    |
|    n_updates            | 4020        |
|    policy_gradient_loss | 0.00198     |
|    std                  | 0.544       |
|    value_loss           | 0.00155     |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 623         |
|    iterations           | 404         |
|    time_elapsed         | 1327        |
|    total_timesteps      | 827392      |
| train/                  |             |
|    approx_kl            | 0.027412344 |
|    clip_fraction        | 0.199       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.65       |
|    explained_variance   | 0.813       |
|    learning_rate        | 0.00184     |
|    loss                 | -0.0298     |
|    n_updates            | 4030        |
|    policy_gradient_loss | -0.00261    |
|    std                  | 0.561       |
|    value_loss           | 0.00126     |
-----------------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 623         |
|    iterations           | 405         |
|    time_elapsed         | 1330        |
|    total_timesteps      | 829440      |
| train/                  |             |
|    approx_kl            | 0.032842204 |
|    clip_fraction        | 0.253       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.74       |
|    explained_variance   | 0.851       |
|    learning_rate        | 0.00184     |
|    loss                 | 0.0617      |
|    n_updates            | 4040        |
|    policy_gradient_loss | 0.00899     |
|    std                  | 0.584       |
|    value_loss           | 0.0045      |
-----------------------------------------
box reached target
Eval num_timesteps=830000, episode_reward=0.23 +/- 2.45
Episode length: 281.60 +/- 36.80
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 282         |
|    mean_reward          | 0.226       |
| time/                   |             |
|    total_timesteps      | 830000      |
| train/                  |             |
|    approx_kl            | 0.020057356 |
|    clip_fraction        | 0.201       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.8        |
|    explained_variance   | 0.951       |
|    learning_rate        | 0.00184     |
|    loss                 | -0.0119     |
|    n_updates            | 4050        |
|    policy_gradient_loss | 0.000258    |
|    std                  | 0.606       |
|    value_loss           | 0.00237     |
-----------------------------------------
box reached target
box reached target
box reached target
-------------------------------
| time/              |        |
|    fps             | 623    |
|    iterations      | 406    |
|    time_elapsed    | 1334   |
|    total_timesteps | 831488 |
-------------------------------
box reached target
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 623         |
|    iterations           | 407         |
|    time_elapsed         | 1337        |
|    total_timesteps      | 833536      |
| train/                  |             |
|    approx_kl            | 0.024748668 |
|    clip_fraction        | 0.201       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.86       |
|    explained_variance   | 0.961       |
|    learning_rate        | 0.00184     |
|    loss                 | 0.00894     |
|    n_updates            | 4060        |
|    policy_gradient_loss | -0.000804   |
|    std                  | 0.627       |
|    value_loss           | 0.00484     |
-----------------------------------------
box reached target
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 623         |
|    iterations           | 408         |
|    time_elapsed         | 1340        |
|    total_timesteps      | 835584      |
| train/                  |             |
|    approx_kl            | 0.025603477 |
|    clip_fraction        | 0.221       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.93       |
|    explained_variance   | 0.985       |
|    learning_rate        | 0.00184     |
|    loss                 | 0.0497      |
|    n_updates            | 4070        |
|    policy_gradient_loss | -0.00532    |
|    std                  | 0.646       |
|    value_loss           | 0.00217     |
-----------------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 623         |
|    iterations           | 409         |
|    time_elapsed         | 1343        |
|    total_timesteps      | 837632      |
| train/                  |             |
|    approx_kl            | 0.023359478 |
|    clip_fraction        | 0.212       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.94       |
|    explained_variance   | 0.895       |
|    learning_rate        | 0.00184     |
|    loss                 | 0.0207      |
|    n_updates            | 4080        |
|    policy_gradient_loss | 0.00223     |
|    std                  | 0.633       |
|    value_loss           | 0.0227      |
-----------------------------------------
box reached target
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 623         |
|    iterations           | 410         |
|    time_elapsed         | 1347        |
|    total_timesteps      | 839680      |
| train/                  |             |
|    approx_kl            | 0.022152362 |
|    clip_fraction        | 0.165       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.93       |
|    explained_variance   | 0.845       |
|    learning_rate        | 0.00184     |
|    loss                 | 0.0259      |
|    n_updates            | 4090        |
|    policy_gradient_loss | 0.00386     |
|    std                  | 0.632       |
|    value_loss           | 0.023       |
-----------------------------------------
box reached target
box reached target
Eval num_timesteps=840000, episode_reward=1.49 +/- 3.05
Episode length: 237.40 +/- 76.86
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 237         |
|    mean_reward          | 1.49        |
| time/                   |             |
|    total_timesteps      | 840000      |
| train/                  |             |
|    approx_kl            | 0.022998704 |
|    clip_fraction        | 0.205       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.91       |
|    explained_variance   | 0.952       |
|    learning_rate        | 0.00184     |
|    loss                 | 0.0098      |
|    n_updates            | 4100        |
|    policy_gradient_loss | 0.00268     |
|    std                  | 0.631       |
|    value_loss           | 0.00407     |
-----------------------------------------
box reached target
-------------------------------
| time/              |        |
|    fps             | 623    |
|    iterations      | 411    |
|    time_elapsed    | 1350   |
|    total_timesteps | 841728 |
-------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 623         |
|    iterations           | 412         |
|    time_elapsed         | 1354        |
|    total_timesteps      | 843776      |
| train/                  |             |
|    approx_kl            | 0.023856658 |
|    clip_fraction        | 0.206       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.91       |
|    explained_variance   | 0.829       |
|    learning_rate        | 0.00184     |
|    loss                 | 0.0259      |
|    n_updates            | 4110        |
|    policy_gradient_loss | -0.00212    |
|    std                  | 0.637       |
|    value_loss           | 0.0117      |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 623         |
|    iterations           | 413         |
|    time_elapsed         | 1357        |
|    total_timesteps      | 845824      |
| train/                  |             |
|    approx_kl            | 0.024986254 |
|    clip_fraction        | 0.199       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.92       |
|    explained_variance   | 0.698       |
|    learning_rate        | 0.00184     |
|    loss                 | 0.00865     |
|    n_updates            | 4120        |
|    policy_gradient_loss | 0.00196     |
|    std                  | 0.635       |
|    value_loss           | 0.0339      |
-----------------------------------------
box reached target
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 623        |
|    iterations           | 414        |
|    time_elapsed         | 1360       |
|    total_timesteps      | 847872     |
| train/                  |            |
|    approx_kl            | 0.04636111 |
|    clip_fraction        | 0.228      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.92      |
|    explained_variance   | 0.901      |
|    learning_rate        | 0.00184    |
|    loss                 | -0.0321    |
|    n_updates            | 4130       |
|    policy_gradient_loss | 0.0103     |
|    std                  | 0.636      |
|    value_loss           | 0.00467    |
----------------------------------------
box reached target
box reached target
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 623         |
|    iterations           | 415         |
|    time_elapsed         | 1363        |
|    total_timesteps      | 849920      |
| train/                  |             |
|    approx_kl            | 0.019003473 |
|    clip_fraction        | 0.184       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.93       |
|    explained_variance   | 0.917       |
|    learning_rate        | 0.00183     |
|    loss                 | 0.00955     |
|    n_updates            | 4140        |
|    policy_gradient_loss | 0.00208     |
|    std                  | 0.647       |
|    value_loss           | 0.0226      |
-----------------------------------------
Eval num_timesteps=850000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 300         |
|    mean_reward          | -1          |
| time/                   |             |
|    total_timesteps      | 850000      |
| train/                  |             |
|    approx_kl            | 0.026920225 |
|    clip_fraction        | 0.197       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.92       |
|    explained_variance   | 0.958       |
|    learning_rate        | 0.00183     |
|    loss                 | 0.011       |
|    n_updates            | 4150        |
|    policy_gradient_loss | 0.00151     |
|    std                  | 0.644       |
|    value_loss           | 0.011       |
-----------------------------------------
box reached target
-------------------------------
| time/              |        |
|    fps             | 623    |
|    iterations      | 416    |
|    time_elapsed    | 1367   |
|    total_timesteps | 851968 |
-------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 623         |
|    iterations           | 417         |
|    time_elapsed         | 1370        |
|    total_timesteps      | 854016      |
| train/                  |             |
|    approx_kl            | 0.035437085 |
|    clip_fraction        | 0.219       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.91       |
|    explained_variance   | 0.832       |
|    learning_rate        | 0.00183     |
|    loss                 | -0.0174     |
|    n_updates            | 4160        |
|    policy_gradient_loss | -0.00361    |
|    std                  | 0.639       |
|    value_loss           | 0.00429     |
-----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 623        |
|    iterations           | 418        |
|    time_elapsed         | 1373       |
|    total_timesteps      | 856064     |
| train/                  |            |
|    approx_kl            | 0.03298357 |
|    clip_fraction        | 0.216      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.9       |
|    explained_variance   | 0.902      |
|    learning_rate        | 0.00183    |
|    loss                 | -0.0178    |
|    n_updates            | 4170       |
|    policy_gradient_loss | 0.000721   |
|    std                  | 0.633      |
|    value_loss           | 0.00582    |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 623        |
|    iterations           | 419        |
|    time_elapsed         | 1376       |
|    total_timesteps      | 858112     |
| train/                  |            |
|    approx_kl            | 0.24474823 |
|    clip_fraction        | 0.217      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.89      |
|    explained_variance   | 0.904      |
|    learning_rate        | 0.00183    |
|    loss                 | -0.0224    |
|    n_updates            | 4180       |
|    policy_gradient_loss | 0.0129     |
|    std                  | 0.635      |
|    value_loss           | 0.00607    |
----------------------------------------
box reached target
Eval num_timesteps=860000, episode_reward=-0.71 +/- 0.57
Episode length: 300.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 300         |
|    mean_reward          | -0.715      |
| time/                   |             |
|    total_timesteps      | 860000      |
| train/                  |             |
|    approx_kl            | 0.044812486 |
|    clip_fraction        | 0.258       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.91       |
|    explained_variance   | 0.895       |
|    learning_rate        | 0.00183     |
|    loss                 | 0.00213     |
|    n_updates            | 4190        |
|    policy_gradient_loss | 0.000568    |
|    std                  | 0.645       |
|    value_loss           | 0.00882     |
-----------------------------------------
-------------------------------
| time/              |        |
|    fps             | 622    |
|    iterations      | 420    |
|    time_elapsed    | 1380   |
|    total_timesteps | 860160 |
-------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 623        |
|    iterations           | 421        |
|    time_elapsed         | 1383       |
|    total_timesteps      | 862208     |
| train/                  |            |
|    approx_kl            | 0.06993042 |
|    clip_fraction        | 0.247      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.88      |
|    explained_variance   | 0.915      |
|    learning_rate        | 0.00183    |
|    loss                 | -0.0317    |
|    n_updates            | 4200       |
|    policy_gradient_loss | -0.0011    |
|    std                  | 0.632      |
|    value_loss           | 0.0154     |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 623        |
|    iterations           | 422        |
|    time_elapsed         | 1387       |
|    total_timesteps      | 864256     |
| train/                  |            |
|    approx_kl            | 0.03792776 |
|    clip_fraction        | 0.199      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.9       |
|    explained_variance   | 0.823      |
|    learning_rate        | 0.00183    |
|    loss                 | -0.0318    |
|    n_updates            | 4210       |
|    policy_gradient_loss | -0.00801   |
|    std                  | 0.639      |
|    value_loss           | 0.00219    |
----------------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 623         |
|    iterations           | 423         |
|    time_elapsed         | 1390        |
|    total_timesteps      | 866304      |
| train/                  |             |
|    approx_kl            | 0.049179353 |
|    clip_fraction        | 0.22        |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.94       |
|    explained_variance   | 0.902       |
|    learning_rate        | 0.00183     |
|    loss                 | -0.0196     |
|    n_updates            | 4220        |
|    policy_gradient_loss | -0.000907   |
|    std                  | 0.658       |
|    value_loss           | 0.00641     |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 623         |
|    iterations           | 424         |
|    time_elapsed         | 1393        |
|    total_timesteps      | 868352      |
| train/                  |             |
|    approx_kl            | 0.020806018 |
|    clip_fraction        | 0.204       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.94       |
|    explained_variance   | 0.841       |
|    learning_rate        | 0.00183     |
|    loss                 | 0.0377      |
|    n_updates            | 4230        |
|    policy_gradient_loss | 0.00141     |
|    std                  | 0.654       |
|    value_loss           | 0.00598     |
-----------------------------------------
box reached target
box reached target
Eval num_timesteps=870000, episode_reward=-0.71 +/- 0.58
Episode length: 300.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 300         |
|    mean_reward          | -0.709      |
| time/                   |             |
|    total_timesteps      | 870000      |
| train/                  |             |
|    approx_kl            | 0.038307726 |
|    clip_fraction        | 0.255       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.96       |
|    explained_variance   | 0.84        |
|    learning_rate        | 0.00183     |
|    loss                 | -0.0321     |
|    n_updates            | 4240        |
|    policy_gradient_loss | -0.00703    |
|    std                  | 0.664       |
|    value_loss           | 0.00516     |
-----------------------------------------
-------------------------------
| time/              |        |
|    fps             | 622    |
|    iterations      | 425    |
|    time_elapsed    | 1397   |
|    total_timesteps | 870400 |
-------------------------------
box reached target
box reached target
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 622         |
|    iterations           | 426         |
|    time_elapsed         | 1400        |
|    total_timesteps      | 872448      |
| train/                  |             |
|    approx_kl            | 0.063075304 |
|    clip_fraction        | 0.249       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.95       |
|    explained_variance   | 0.945       |
|    learning_rate        | 0.00183     |
|    loss                 | 0.0484      |
|    n_updates            | 4250        |
|    policy_gradient_loss | -0.00398    |
|    std                  | 0.657       |
|    value_loss           | 0.00525     |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 623         |
|    iterations           | 427         |
|    time_elapsed         | 1403        |
|    total_timesteps      | 874496      |
| train/                  |             |
|    approx_kl            | 0.031544454 |
|    clip_fraction        | 0.273       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.91       |
|    explained_variance   | 0.903       |
|    learning_rate        | 0.00183     |
|    loss                 | 0.00308     |
|    n_updates            | 4260        |
|    policy_gradient_loss | 0.00252     |
|    std                  | 0.64        |
|    value_loss           | 0.00775     |
-----------------------------------------
box reached target
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 623         |
|    iterations           | 428         |
|    time_elapsed         | 1406        |
|    total_timesteps      | 876544      |
| train/                  |             |
|    approx_kl            | 0.046888497 |
|    clip_fraction        | 0.234       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.88       |
|    explained_variance   | 0.901       |
|    learning_rate        | 0.00183     |
|    loss                 | -0.0381     |
|    n_updates            | 4270        |
|    policy_gradient_loss | 0.0307      |
|    std                  | 0.639       |
|    value_loss           | 0.00706     |
-----------------------------------------
box reached target
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 623         |
|    iterations           | 429         |
|    time_elapsed         | 1409        |
|    total_timesteps      | 878592      |
| train/                  |             |
|    approx_kl            | 0.030846115 |
|    clip_fraction        | 0.236       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.86       |
|    explained_variance   | 0.948       |
|    learning_rate        | 0.00183     |
|    loss                 | -0.00904    |
|    n_updates            | 4280        |
|    policy_gradient_loss | -0.00188    |
|    std                  | 0.627       |
|    value_loss           | 0.00476     |
-----------------------------------------
box reached target
box reached target
Eval num_timesteps=880000, episode_reward=1.79 +/- 2.82
Episode length: 242.20 +/- 71.23
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 242         |
|    mean_reward          | 1.79        |
| time/                   |             |
|    total_timesteps      | 880000      |
| train/                  |             |
|    approx_kl            | 0.038821954 |
|    clip_fraction        | 0.239       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.81       |
|    explained_variance   | 0.974       |
|    learning_rate        | 0.00183     |
|    loss                 | 0.044       |
|    n_updates            | 4290        |
|    policy_gradient_loss | 0.00058     |
|    std                  | 0.613       |
|    value_loss           | 0.00298     |
-----------------------------------------
box reached target
-------------------------------
| time/              |        |
|    fps             | 622    |
|    iterations      | 430    |
|    time_elapsed    | 1413   |
|    total_timesteps | 880640 |
-------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 623         |
|    iterations           | 431         |
|    time_elapsed         | 1416        |
|    total_timesteps      | 882688      |
| train/                  |             |
|    approx_kl            | 0.058068827 |
|    clip_fraction        | 0.223       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.82       |
|    explained_variance   | 0.935       |
|    learning_rate        | 0.00183     |
|    loss                 | -0.0271     |
|    n_updates            | 4300        |
|    policy_gradient_loss | -0.00494    |
|    std                  | 0.622       |
|    value_loss           | 0.00315     |
-----------------------------------------
box reached target
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 623        |
|    iterations           | 432        |
|    time_elapsed         | 1419       |
|    total_timesteps      | 884736     |
| train/                  |            |
|    approx_kl            | 0.05515477 |
|    clip_fraction        | 0.253      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.8       |
|    explained_variance   | 0.64       |
|    learning_rate        | 0.00183    |
|    loss                 | 0.0698     |
|    n_updates            | 4310       |
|    policy_gradient_loss | -0.00555   |
|    std                  | 0.613      |
|    value_loss           | 0.00272    |
----------------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 623         |
|    iterations           | 433         |
|    time_elapsed         | 1422        |
|    total_timesteps      | 886784      |
| train/                  |             |
|    approx_kl            | 0.041521236 |
|    clip_fraction        | 0.246       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.77       |
|    explained_variance   | 0.953       |
|    learning_rate        | 0.00183     |
|    loss                 | -0.0146     |
|    n_updates            | 4320        |
|    policy_gradient_loss | -0.00394    |
|    std                  | 0.6         |
|    value_loss           | 0.00645     |
-----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 623        |
|    iterations           | 434        |
|    time_elapsed         | 1426       |
|    total_timesteps      | 888832     |
| train/                  |            |
|    approx_kl            | 0.03677758 |
|    clip_fraction        | 0.237      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.77      |
|    explained_variance   | 0.863      |
|    learning_rate        | 0.00183    |
|    loss                 | 0.031      |
|    n_updates            | 4330       |
|    policy_gradient_loss | 8.9e-05    |
|    std                  | 0.604      |
|    value_loss           | 0.00896    |
----------------------------------------
box reached target
box reached target
box reached target
box reached target
box reached target
Eval num_timesteps=890000, episode_reward=2.84 +/- 2.96
Episode length: 232.20 +/- 70.30
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 232         |
|    mean_reward          | 2.84        |
| time/                   |             |
|    total_timesteps      | 890000      |
| train/                  |             |
|    approx_kl            | 0.036687516 |
|    clip_fraction        | 0.248       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.75       |
|    explained_variance   | 0.983       |
|    learning_rate        | 0.00183     |
|    loss                 | 0.00548     |
|    n_updates            | 4340        |
|    policy_gradient_loss | 0.00211     |
|    std                  | 0.592       |
|    value_loss           | 0.00194     |
-----------------------------------------
New best mean reward!
-------------------------------
| time/              |        |
|    fps             | 623    |
|    iterations      | 435    |
|    time_elapsed    | 1429   |
|    total_timesteps | 890880 |
-------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 623         |
|    iterations           | 436         |
|    time_elapsed         | 1433        |
|    total_timesteps      | 892928      |
| train/                  |             |
|    approx_kl            | 0.034009766 |
|    clip_fraction        | 0.234       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.69       |
|    explained_variance   | 0.95        |
|    learning_rate        | 0.00183     |
|    loss                 | 0.0152      |
|    n_updates            | 4350        |
|    policy_gradient_loss | 4.63e-05    |
|    std                  | 0.572       |
|    value_loss           | 0.00741     |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 623         |
|    iterations           | 437         |
|    time_elapsed         | 1436        |
|    total_timesteps      | 894976      |
| train/                  |             |
|    approx_kl            | 0.046321638 |
|    clip_fraction        | 0.174       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.74       |
|    explained_variance   | 0.847       |
|    learning_rate        | 0.00183     |
|    loss                 | -0.00559    |
|    n_updates            | 4360        |
|    policy_gradient_loss | -0.002      |
|    std                  | 0.602       |
|    value_loss           | 0.00863     |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 623         |
|    iterations           | 438         |
|    time_elapsed         | 1439        |
|    total_timesteps      | 897024      |
| train/                  |             |
|    approx_kl            | 0.032999545 |
|    clip_fraction        | 0.244       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.76       |
|    explained_variance   | 0.639       |
|    learning_rate        | 0.00183     |
|    loss                 | -0.0155     |
|    n_updates            | 4370        |
|    policy_gradient_loss | -0.00335    |
|    std                  | 0.595       |
|    value_loss           | 0.00324     |
-----------------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 623         |
|    iterations           | 439         |
|    time_elapsed         | 1442        |
|    total_timesteps      | 899072      |
| train/                  |             |
|    approx_kl            | 0.061199114 |
|    clip_fraction        | 0.242       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.72       |
|    explained_variance   | 0.772       |
|    learning_rate        | 0.00183     |
|    loss                 | 0.0107      |
|    n_updates            | 4380        |
|    policy_gradient_loss | -0.0015     |
|    std                  | 0.582       |
|    value_loss           | 0.00305     |
-----------------------------------------
Eval num_timesteps=900000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 300         |
|    mean_reward          | -1          |
| time/                   |             |
|    total_timesteps      | 900000      |
| train/                  |             |
|    approx_kl            | 0.033995032 |
|    clip_fraction        | 0.204       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.71       |
|    explained_variance   | 0.97        |
|    learning_rate        | 0.00182     |
|    loss                 | -0.0279     |
|    n_updates            | 4390        |
|    policy_gradient_loss | -0.00511    |
|    std                  | 0.581       |
|    value_loss           | 0.00261     |
-----------------------------------------
-------------------------------
| time/              |        |
|    fps             | 622    |
|    iterations      | 440    |
|    time_elapsed    | 1446   |
|    total_timesteps | 901120 |
-------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 623        |
|    iterations           | 441        |
|    time_elapsed         | 1449       |
|    total_timesteps      | 903168     |
| train/                  |            |
|    approx_kl            | 0.11434883 |
|    clip_fraction        | 0.283      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.69      |
|    explained_variance   | 0.527      |
|    learning_rate        | 0.00182    |
|    loss                 | -0.0411    |
|    n_updates            | 4400       |
|    policy_gradient_loss | -0.00743   |
|    std                  | 0.573      |
|    value_loss           | 0.00182    |
----------------------------------------
box reached target
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 623         |
|    iterations           | 442         |
|    time_elapsed         | 1452        |
|    total_timesteps      | 905216      |
| train/                  |             |
|    approx_kl            | 0.035397924 |
|    clip_fraction        | 0.248       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.63       |
|    explained_variance   | 0.945       |
|    learning_rate        | 0.00182     |
|    loss                 | 0.000879    |
|    n_updates            | 4410        |
|    policy_gradient_loss | 0.00322     |
|    std                  | 0.557       |
|    value_loss           | 0.00351     |
-----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 623        |
|    iterations           | 443        |
|    time_elapsed         | 1455       |
|    total_timesteps      | 907264     |
| train/                  |            |
|    approx_kl            | 0.04836162 |
|    clip_fraction        | 0.266      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.57      |
|    explained_variance   | 0.769      |
|    learning_rate        | 0.00182    |
|    loss                 | -0.000533  |
|    n_updates            | 4420       |
|    policy_gradient_loss | -0.00161   |
|    std                  | 0.54       |
|    value_loss           | 0.0107     |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 623        |
|    iterations           | 444        |
|    time_elapsed         | 1458       |
|    total_timesteps      | 909312     |
| train/                  |            |
|    approx_kl            | 0.04139766 |
|    clip_fraction        | 0.259      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.54      |
|    explained_variance   | 0.77       |
|    learning_rate        | 0.00182    |
|    loss                 | -0.0486    |
|    n_updates            | 4430       |
|    policy_gradient_loss | -0.00022   |
|    std                  | 0.543      |
|    value_loss           | 0.00651    |
----------------------------------------
Eval num_timesteps=910000, episode_reward=-0.85 +/- 0.29
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -0.853     |
| time/                   |            |
|    total_timesteps      | 910000     |
| train/                  |            |
|    approx_kl            | 0.08887003 |
|    clip_fraction        | 0.308      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.57      |
|    explained_variance   | 0.827      |
|    learning_rate        | 0.00182    |
|    loss                 | -0.02      |
|    n_updates            | 4440       |
|    policy_gradient_loss | -0.00358   |
|    std                  | 0.551      |
|    value_loss           | 0.00243    |
----------------------------------------
-------------------------------
| time/              |        |
|    fps             | 622    |
|    iterations      | 445    |
|    time_elapsed    | 1462   |
|    total_timesteps | 911360 |
-------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 623        |
|    iterations           | 446        |
|    time_elapsed         | 1466       |
|    total_timesteps      | 913408     |
| train/                  |            |
|    approx_kl            | 0.03687116 |
|    clip_fraction        | 0.258      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.61      |
|    explained_variance   | 0.745      |
|    learning_rate        | 0.00182    |
|    loss                 | -0.0045    |
|    n_updates            | 4450       |
|    policy_gradient_loss | 0.00295    |
|    std                  | 0.565      |
|    value_loss           | 0.00121    |
----------------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 623         |
|    iterations           | 447         |
|    time_elapsed         | 1469        |
|    total_timesteps      | 915456      |
| train/                  |             |
|    approx_kl            | 0.035582446 |
|    clip_fraction        | 0.27        |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.57       |
|    explained_variance   | 0.916       |
|    learning_rate        | 0.00182     |
|    loss                 | -0.0018     |
|    n_updates            | 4460        |
|    policy_gradient_loss | 0.00142     |
|    std                  | 0.544       |
|    value_loss           | 0.00281     |
-----------------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 623        |
|    iterations           | 448        |
|    time_elapsed         | 1472       |
|    total_timesteps      | 917504     |
| train/                  |            |
|    approx_kl            | 0.04575675 |
|    clip_fraction        | 0.271      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.55      |
|    explained_variance   | 0.981      |
|    learning_rate        | 0.00182    |
|    loss                 | 0.000594   |
|    n_updates            | 4470       |
|    policy_gradient_loss | 0.00295    |
|    std                  | 0.541      |
|    value_loss           | 0.00117    |
----------------------------------------
box reached target
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 623        |
|    iterations           | 449        |
|    time_elapsed         | 1475       |
|    total_timesteps      | 919552     |
| train/                  |            |
|    approx_kl            | 0.05315271 |
|    clip_fraction        | 0.274      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.5       |
|    explained_variance   | 0.802      |
|    learning_rate        | 0.00182    |
|    loss                 | -0.00457   |
|    n_updates            | 4480       |
|    policy_gradient_loss | 0.00144    |
|    std                  | 0.521      |
|    value_loss           | 0.0466     |
----------------------------------------
box reached target
Eval num_timesteps=920000, episode_reward=0.26 +/- 2.52
Episode length: 285.40 +/- 29.20
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 285       |
|    mean_reward          | 0.262     |
| time/                   |           |
|    total_timesteps      | 920000    |
| train/                  |           |
|    approx_kl            | 0.0612419 |
|    clip_fraction        | 0.25      |
|    clip_range           | 0.2       |
|    entropy_loss         | -1.52     |
|    explained_variance   | 0.965     |
|    learning_rate        | 0.00182   |
|    loss                 | 0.0619    |
|    n_updates            | 4490      |
|    policy_gradient_loss | 0.00605   |
|    std                  | 0.53      |
|    value_loss           | 0.00482   |
---------------------------------------
-------------------------------
| time/              |        |
|    fps             | 622    |
|    iterations      | 450    |
|    time_elapsed    | 1479   |
|    total_timesteps | 921600 |
-------------------------------
box reached target
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 623         |
|    iterations           | 451         |
|    time_elapsed         | 1482        |
|    total_timesteps      | 923648      |
| train/                  |             |
|    approx_kl            | 0.038680878 |
|    clip_fraction        | 0.231       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.54       |
|    explained_variance   | 0.822       |
|    learning_rate        | 0.00182     |
|    loss                 | -0.00746    |
|    n_updates            | 4500        |
|    policy_gradient_loss | -0.00408    |
|    std                  | 0.536       |
|    value_loss           | 0.00242     |
-----------------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 623         |
|    iterations           | 452         |
|    time_elapsed         | 1485        |
|    total_timesteps      | 925696      |
| train/                  |             |
|    approx_kl            | 0.040073816 |
|    clip_fraction        | 0.232       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.54       |
|    explained_variance   | 0.901       |
|    learning_rate        | 0.00182     |
|    loss                 | -0.00808    |
|    n_updates            | 4510        |
|    policy_gradient_loss | -0.00294    |
|    std                  | 0.539       |
|    value_loss           | 0.0097      |
-----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 623        |
|    iterations           | 453        |
|    time_elapsed         | 1488       |
|    total_timesteps      | 927744     |
| train/                  |            |
|    approx_kl            | 0.10872117 |
|    clip_fraction        | 0.28       |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.58      |
|    explained_variance   | 0.938      |
|    learning_rate        | 0.00182    |
|    loss                 | -0.0403    |
|    n_updates            | 4520       |
|    policy_gradient_loss | -0.00568   |
|    std                  | 0.547      |
|    value_loss           | 0.00387    |
----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 623         |
|    iterations           | 454         |
|    time_elapsed         | 1491        |
|    total_timesteps      | 929792      |
| train/                  |             |
|    approx_kl            | 0.031461168 |
|    clip_fraction        | 0.222       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.6        |
|    explained_variance   | 0.94        |
|    learning_rate        | 0.00182     |
|    loss                 | -0.0291     |
|    n_updates            | 4530        |
|    policy_gradient_loss | -0.00727    |
|    std                  | 0.551       |
|    value_loss           | 0.00447     |
-----------------------------------------
box reached target
box reached target
Eval num_timesteps=930000, episode_reward=0.22 +/- 2.44
Episode length: 270.00 +/- 60.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 270         |
|    mean_reward          | 0.221       |
| time/                   |             |
|    total_timesteps      | 930000      |
| train/                  |             |
|    approx_kl            | 0.062090706 |
|    clip_fraction        | 0.265       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.53       |
|    explained_variance   | 0.896       |
|    learning_rate        | 0.00182     |
|    loss                 | -0.0207     |
|    n_updates            | 4540        |
|    policy_gradient_loss | -0.0021     |
|    std                  | 0.519       |
|    value_loss           | 0.0021      |
-----------------------------------------
box reached target
-------------------------------
| time/              |        |
|    fps             | 622    |
|    iterations      | 455    |
|    time_elapsed    | 1495   |
|    total_timesteps | 931840 |
-------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 623         |
|    iterations           | 456         |
|    time_elapsed         | 1498        |
|    total_timesteps      | 933888      |
| train/                  |             |
|    approx_kl            | 0.030902106 |
|    clip_fraction        | 0.217       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.48       |
|    explained_variance   | 0.939       |
|    learning_rate        | 0.00182     |
|    loss                 | -0.00235    |
|    n_updates            | 4550        |
|    policy_gradient_loss | -0.00221    |
|    std                  | 0.515       |
|    value_loss           | 0.00793     |
-----------------------------------------
box reached target
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 623         |
|    iterations           | 457         |
|    time_elapsed         | 1501        |
|    total_timesteps      | 935936      |
| train/                  |             |
|    approx_kl            | 0.050521314 |
|    clip_fraction        | 0.255       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.45       |
|    explained_variance   | 0.38        |
|    learning_rate        | 0.00182     |
|    loss                 | -0.0292     |
|    n_updates            | 4560        |
|    policy_gradient_loss | -0.0107     |
|    std                  | 0.504       |
|    value_loss           | 0.00148     |
-----------------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 623         |
|    iterations           | 458         |
|    time_elapsed         | 1505        |
|    total_timesteps      | 937984      |
| train/                  |             |
|    approx_kl            | 0.032359764 |
|    clip_fraction        | 0.28        |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.43       |
|    explained_variance   | 0.869       |
|    learning_rate        | 0.00182     |
|    loss                 | 0.012       |
|    n_updates            | 4570        |
|    policy_gradient_loss | 0.00326     |
|    std                  | 0.506       |
|    value_loss           | 0.0101      |
-----------------------------------------
box reached target
box reached target
box reached target
Eval num_timesteps=940000, episode_reward=1.61 +/- 2.96
Episode length: 242.60 +/- 70.36
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 243         |
|    mean_reward          | 1.61        |
| time/                   |             |
|    total_timesteps      | 940000      |
| train/                  |             |
|    approx_kl            | 0.025301008 |
|    clip_fraction        | 0.256       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.42       |
|    explained_variance   | 0.968       |
|    learning_rate        | 0.00182     |
|    loss                 | -0.00197    |
|    n_updates            | 4580        |
|    policy_gradient_loss | 0.000179    |
|    std                  | 0.501       |
|    value_loss           | 0.00189     |
-----------------------------------------
-------------------------------
| time/              |        |
|    fps             | 622    |
|    iterations      | 459    |
|    time_elapsed    | 1509   |
|    total_timesteps | 940032 |
-------------------------------
box reached target
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 623         |
|    iterations           | 460         |
|    time_elapsed         | 1512        |
|    total_timesteps      | 942080      |
| train/                  |             |
|    approx_kl            | 0.043775216 |
|    clip_fraction        | 0.26        |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.36       |
|    explained_variance   | 0.713       |
|    learning_rate        | 0.00182     |
|    loss                 | 0.0313      |
|    n_updates            | 4590        |
|    policy_gradient_loss | -0.000287   |
|    std                  | 0.484       |
|    value_loss           | 0.0139      |
-----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 623        |
|    iterations           | 461        |
|    time_elapsed         | 1515       |
|    total_timesteps      | 944128     |
| train/                  |            |
|    approx_kl            | 0.09356167 |
|    clip_fraction        | 0.297      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.28      |
|    explained_variance   | 0.728      |
|    learning_rate        | 0.00182    |
|    loss                 | -0.0138    |
|    n_updates            | 4600       |
|    policy_gradient_loss | -0.0017    |
|    std                  | 0.467      |
|    value_loss           | 0.0252     |
----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 623         |
|    iterations           | 462         |
|    time_elapsed         | 1518        |
|    total_timesteps      | 946176      |
| train/                  |             |
|    approx_kl            | 0.046109505 |
|    clip_fraction        | 0.228       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.26       |
|    explained_variance   | 0.568       |
|    learning_rate        | 0.00182     |
|    loss                 | -0.0198     |
|    n_updates            | 4610        |
|    policy_gradient_loss | -0.00582    |
|    std                  | 0.466       |
|    value_loss           | 0.00257     |
-----------------------------------------
box reached target
box reached target
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 623         |
|    iterations           | 463         |
|    time_elapsed         | 1521        |
|    total_timesteps      | 948224      |
| train/                  |             |
|    approx_kl            | 0.065460965 |
|    clip_fraction        | 0.274       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.27       |
|    explained_variance   | 0.856       |
|    learning_rate        | 0.00182     |
|    loss                 | -0.0102     |
|    n_updates            | 4620        |
|    policy_gradient_loss | -0.00119    |
|    std                  | 0.473       |
|    value_loss           | 0.00506     |
-----------------------------------------
Eval num_timesteps=950000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1         |
| time/                   |            |
|    total_timesteps      | 950000     |
| train/                  |            |
|    approx_kl            | 0.08574992 |
|    clip_fraction        | 0.269      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.31      |
|    explained_variance   | 0.981      |
|    learning_rate        | 0.00182    |
|    loss                 | -0.0206    |
|    n_updates            | 4630       |
|    policy_gradient_loss | -0.00669   |
|    std                  | 0.476      |
|    value_loss           | 0.00384    |
----------------------------------------
box reached target
-------------------------------
| time/              |        |
|    fps             | 622    |
|    iterations      | 464    |
|    time_elapsed    | 1525   |
|    total_timesteps | 950272 |
-------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 622       |
|    iterations           | 465       |
|    time_elapsed         | 1528      |
|    total_timesteps      | 952320    |
| train/                  |           |
|    approx_kl            | 0.0703072 |
|    clip_fraction        | 0.288     |
|    clip_range           | 0.2       |
|    entropy_loss         | -1.32     |
|    explained_variance   | 0.956     |
|    learning_rate        | 0.00181   |
|    loss                 | 0.00444   |
|    n_updates            | 4640      |
|    policy_gradient_loss | 0.00225   |
|    std                  | 0.479     |
|    value_loss           | 0.00334   |
---------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 623         |
|    iterations           | 466         |
|    time_elapsed         | 1531        |
|    total_timesteps      | 954368      |
| train/                  |             |
|    approx_kl            | 0.055297546 |
|    clip_fraction        | 0.28        |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.32       |
|    explained_variance   | 0.721       |
|    learning_rate        | 0.00181     |
|    loss                 | 0.0123      |
|    n_updates            | 4650        |
|    policy_gradient_loss | -0.00714    |
|    std                  | 0.479       |
|    value_loss           | 0.00104     |
-----------------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 623        |
|    iterations           | 467        |
|    time_elapsed         | 1534       |
|    total_timesteps      | 956416     |
| train/                  |            |
|    approx_kl            | 0.04352984 |
|    clip_fraction        | 0.258      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.33      |
|    explained_variance   | 0.636      |
|    learning_rate        | 0.00181    |
|    loss                 | -0.0105    |
|    n_updates            | 4660       |
|    policy_gradient_loss | -0.000929  |
|    std                  | 0.478      |
|    value_loss           | 0.00126    |
----------------------------------------
box reached target
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 623         |
|    iterations           | 468         |
|    time_elapsed         | 1537        |
|    total_timesteps      | 958464      |
| train/                  |             |
|    approx_kl            | 0.040300786 |
|    clip_fraction        | 0.285       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.32       |
|    explained_variance   | 0.888       |
|    learning_rate        | 0.00181     |
|    loss                 | 0.0278      |
|    n_updates            | 4670        |
|    policy_gradient_loss | 0.00343     |
|    std                  | 0.483       |
|    value_loss           | 0.0125      |
-----------------------------------------
Eval num_timesteps=960000, episode_reward=-0.80 +/- 0.38
Episode length: 300.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 300         |
|    mean_reward          | -0.804      |
| time/                   |             |
|    total_timesteps      | 960000      |
| train/                  |             |
|    approx_kl            | 0.064771146 |
|    clip_fraction        | 0.284       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.34       |
|    explained_variance   | 0.942       |
|    learning_rate        | 0.00181     |
|    loss                 | -0.0375     |
|    n_updates            | 4680        |
|    policy_gradient_loss | -0.000438   |
|    std                  | 0.482       |
|    value_loss           | 0.0106      |
-----------------------------------------
-------------------------------
| time/              |        |
|    fps             | 622    |
|    iterations      | 469    |
|    time_elapsed    | 1542   |
|    total_timesteps | 960512 |
-------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 470        |
|    time_elapsed         | 1545       |
|    total_timesteps      | 962560     |
| train/                  |            |
|    approx_kl            | 0.10114293 |
|    clip_fraction        | 0.288      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.35      |
|    explained_variance   | 0.884      |
|    learning_rate        | 0.00181    |
|    loss                 | -0.000276  |
|    n_updates            | 4690       |
|    policy_gradient_loss | -0.00155   |
|    std                  | 0.482      |
|    value_loss           | 0.00312    |
----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 623         |
|    iterations           | 471         |
|    time_elapsed         | 1548        |
|    total_timesteps      | 964608      |
| train/                  |             |
|    approx_kl            | 0.046490006 |
|    clip_fraction        | 0.253       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.36       |
|    explained_variance   | 0.73        |
|    learning_rate        | 0.00181     |
|    loss                 | 0.0208      |
|    n_updates            | 4700        |
|    policy_gradient_loss | 0.00181     |
|    std                  | 0.49        |
|    value_loss           | 0.0017      |
-----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 623        |
|    iterations           | 472        |
|    time_elapsed         | 1551       |
|    total_timesteps      | 966656     |
| train/                  |            |
|    approx_kl            | 0.17635438 |
|    clip_fraction        | 0.271      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.35      |
|    explained_variance   | 0.612      |
|    learning_rate        | 0.00181    |
|    loss                 | -0.0272    |
|    n_updates            | 4710       |
|    policy_gradient_loss | -0.00634   |
|    std                  | 0.483      |
|    value_loss           | 0.00498    |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 623        |
|    iterations           | 473        |
|    time_elapsed         | 1554       |
|    total_timesteps      | 968704     |
| train/                  |            |
|    approx_kl            | 0.12583238 |
|    clip_fraction        | 0.317      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.36      |
|    explained_variance   | 0.922      |
|    learning_rate        | 0.00181    |
|    loss                 | -0.00533   |
|    n_updates            | 4720       |
|    policy_gradient_loss | 0.00484    |
|    std                  | 0.485      |
|    value_loss           | 0.00419    |
----------------------------------------
box reached target
Eval num_timesteps=970000, episode_reward=0.24 +/- 2.48
Episode length: 268.40 +/- 63.20
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 268        |
|    mean_reward          | 0.241      |
| time/                   |            |
|    total_timesteps      | 970000     |
| train/                  |            |
|    approx_kl            | 0.07466015 |
|    clip_fraction        | 0.278      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.35      |
|    explained_variance   | 0.663      |
|    learning_rate        | 0.00181    |
|    loss                 | -0.0111    |
|    n_updates            | 4730       |
|    policy_gradient_loss | 0.00325    |
|    std                  | 0.485      |
|    value_loss           | 0.00637    |
----------------------------------------
-------------------------------
| time/              |        |
|    fps             | 622    |
|    iterations      | 474    |
|    time_elapsed    | 1558   |
|    total_timesteps | 970752 |
-------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 475        |
|    time_elapsed         | 1561       |
|    total_timesteps      | 972800     |
| train/                  |            |
|    approx_kl            | 0.05600614 |
|    clip_fraction        | 0.247      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.36      |
|    explained_variance   | 0.61       |
|    learning_rate        | 0.00181    |
|    loss                 | 0.0117     |
|    n_updates            | 4740       |
|    policy_gradient_loss | 0.00191    |
|    std                  | 0.489      |
|    value_loss           | 0.00271    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 623        |
|    iterations           | 476        |
|    time_elapsed         | 1564       |
|    total_timesteps      | 974848     |
| train/                  |            |
|    approx_kl            | 0.06557788 |
|    clip_fraction        | 0.262      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.39      |
|    explained_variance   | 0.639      |
|    learning_rate        | 0.00181    |
|    loss                 | -0.0101    |
|    n_updates            | 4750       |
|    policy_gradient_loss | -0.00372   |
|    std                  | 0.508      |
|    value_loss           | 0.00216    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 623        |
|    iterations           | 477        |
|    time_elapsed         | 1567       |
|    total_timesteps      | 976896     |
| train/                  |            |
|    approx_kl            | 0.05862883 |
|    clip_fraction        | 0.247      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.42      |
|    explained_variance   | 0.827      |
|    learning_rate        | 0.00181    |
|    loss                 | -0.0148    |
|    n_updates            | 4760       |
|    policy_gradient_loss | 0.00966    |
|    std                  | 0.498      |
|    value_loss           | 0.00376    |
----------------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 623         |
|    iterations           | 478         |
|    time_elapsed         | 1570        |
|    total_timesteps      | 978944      |
| train/                  |             |
|    approx_kl            | 0.047463737 |
|    clip_fraction        | 0.331       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.44       |
|    explained_variance   | 0.663       |
|    learning_rate        | 0.00181     |
|    loss                 | -0.029      |
|    n_updates            | 4770        |
|    policy_gradient_loss | -0.000763   |
|    std                  | 0.519       |
|    value_loss           | 0.00547     |
-----------------------------------------
box reached target
box reached target
Eval num_timesteps=980000, episode_reward=1.57 +/- 2.96
Episode length: 250.00 +/- 61.79
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 250        |
|    mean_reward          | 1.57       |
| time/                   |            |
|    total_timesteps      | 980000     |
| train/                  |            |
|    approx_kl            | 0.05586002 |
|    clip_fraction        | 0.313      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.42      |
|    explained_variance   | 0.535      |
|    learning_rate        | 0.00181    |
|    loss                 | 0.017      |
|    n_updates            | 4780       |
|    policy_gradient_loss | 0.0105     |
|    std                  | 0.501      |
|    value_loss           | 0.00925    |
----------------------------------------
-------------------------------
| time/              |        |
|    fps             | 622    |
|    iterations      | 479    |
|    time_elapsed    | 1574   |
|    total_timesteps | 980992 |
-------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 623         |
|    iterations           | 480         |
|    time_elapsed         | 1577        |
|    total_timesteps      | 983040      |
| train/                  |             |
|    approx_kl            | 0.061451524 |
|    clip_fraction        | 0.301       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.45       |
|    explained_variance   | 0.581       |
|    learning_rate        | 0.00181     |
|    loss                 | -0.0261     |
|    n_updates            | 4790        |
|    policy_gradient_loss | 0.00337     |
|    std                  | 0.517       |
|    value_loss           | 0.00194     |
-----------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 623       |
|    iterations           | 481       |
|    time_elapsed         | 1580      |
|    total_timesteps      | 985088    |
| train/                  |           |
|    approx_kl            | 0.0313496 |
|    clip_fraction        | 0.278     |
|    clip_range           | 0.2       |
|    entropy_loss         | -1.49     |
|    explained_variance   | 0.695     |
|    learning_rate        | 0.00181   |
|    loss                 | -0.00728  |
|    n_updates            | 4800      |
|    policy_gradient_loss | -0.00143  |
|    std                  | 0.531     |
|    value_loss           | 0.0103    |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 623        |
|    iterations           | 482        |
|    time_elapsed         | 1584       |
|    total_timesteps      | 987136     |
| train/                  |            |
|    approx_kl            | 0.13234319 |
|    clip_fraction        | 0.274      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.5       |
|    explained_variance   | 0.863      |
|    learning_rate        | 0.00181    |
|    loss                 | 0.0429     |
|    n_updates            | 4810       |
|    policy_gradient_loss | -0.00181   |
|    std                  | 0.526      |
|    value_loss           | 0.00354    |
----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 623         |
|    iterations           | 483         |
|    time_elapsed         | 1587        |
|    total_timesteps      | 989184      |
| train/                  |             |
|    approx_kl            | 0.031711936 |
|    clip_fraction        | 0.231       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.49       |
|    explained_variance   | 0.709       |
|    learning_rate        | 0.00181     |
|    loss                 | -0.048      |
|    n_updates            | 4820        |
|    policy_gradient_loss | 0.00133     |
|    std                  | 0.528       |
|    value_loss           | 0.00208     |
-----------------------------------------
box reached target
box reached target
box reached target
box reached target
Eval num_timesteps=990000, episode_reward=1.44 +/- 2.99
Episode length: 250.40 +/- 61.01
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 250        |
|    mean_reward          | 1.44       |
| time/                   |            |
|    total_timesteps      | 990000     |
| train/                  |            |
|    approx_kl            | 0.04769226 |
|    clip_fraction        | 0.266      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.48      |
|    explained_variance   | 0.481      |
|    learning_rate        | 0.00181    |
|    loss                 | -0.0532    |
|    n_updates            | 4830       |
|    policy_gradient_loss | -0.00603   |
|    std                  | 0.52       |
|    value_loss           | 0.00177    |
----------------------------------------
box reached target
-------------------------------
| time/              |        |
|    fps             | 623    |
|    iterations      | 484    |
|    time_elapsed    | 1591   |
|    total_timesteps | 991232 |
-------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 623         |
|    iterations           | 485         |
|    time_elapsed         | 1594        |
|    total_timesteps      | 993280      |
| train/                  |             |
|    approx_kl            | 0.069708705 |
|    clip_fraction        | 0.272       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.46       |
|    explained_variance   | 0.801       |
|    learning_rate        | 0.00181     |
|    loss                 | 0.0321      |
|    n_updates            | 4840        |
|    policy_gradient_loss | 0.00226     |
|    std                  | 0.512       |
|    value_loss           | 0.0136      |
-----------------------------------------
box reached target
box reached target
box reached target
box reached target
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 623         |
|    iterations           | 486         |
|    time_elapsed         | 1597        |
|    total_timesteps      | 995328      |
| train/                  |             |
|    approx_kl            | 0.039068863 |
|    clip_fraction        | 0.274       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.46       |
|    explained_variance   | 0.725       |
|    learning_rate        | 0.00181     |
|    loss                 | 0.0387      |
|    n_updates            | 4850        |
|    policy_gradient_loss | -0.000388   |
|    std                  | 0.52        |
|    value_loss           | 0.0046      |
-----------------------------------------
box reached target
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 623         |
|    iterations           | 487         |
|    time_elapsed         | 1600        |
|    total_timesteps      | 997376      |
| train/                  |             |
|    approx_kl            | 0.053398866 |
|    clip_fraction        | 0.293       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.46       |
|    explained_variance   | 0.705       |
|    learning_rate        | 0.00181     |
|    loss                 | -0.00359    |
|    n_updates            | 4860        |
|    policy_gradient_loss | 0.00367     |
|    std                  | 0.515       |
|    value_loss           | 0.0371      |
-----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 623        |
|    iterations           | 488        |
|    time_elapsed         | 1603       |
|    total_timesteps      | 999424     |
| train/                  |            |
|    approx_kl            | 0.10319634 |
|    clip_fraction        | 0.282      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.43      |
|    explained_variance   | 0.815      |
|    learning_rate        | 0.00181    |
|    loss                 | -0.00988   |
|    n_updates            | 4870       |
|    policy_gradient_loss | 0.00237    |
|    std                  | 0.517      |
|    value_loss           | 0.00569    |
----------------------------------------
box reached target
Eval num_timesteps=1000000, episode_reward=-1.08 +/- 0.16
Episode length: 300.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 300       |
|    mean_reward          | -1.08     |
| time/                   |           |
|    total_timesteps      | 1000000   |
| train/                  |           |
|    approx_kl            | 0.1383792 |
|    clip_fraction        | 0.288     |
|    clip_range           | 0.2       |
|    entropy_loss         | -1.5      |
|    explained_variance   | 0.885     |
|    learning_rate        | 0.00181   |
|    loss                 | 0.00015   |
|    n_updates            | 4880      |
|    policy_gradient_loss | -0.000511 |
|    std                  | 0.536     |
|    value_loss           | 0.0101    |
---------------------------------------
--------------------------------
| time/              |         |
|    fps             | 622     |
|    iterations      | 489     |
|    time_elapsed    | 1607    |
|    total_timesteps | 1001472 |
--------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 623         |
|    iterations           | 490         |
|    time_elapsed         | 1610        |
|    total_timesteps      | 1003520     |
| train/                  |             |
|    approx_kl            | 0.060696702 |
|    clip_fraction        | 0.276       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.5        |
|    explained_variance   | 0.794       |
|    learning_rate        | 0.0018      |
|    loss                 | 0.0034      |
|    n_updates            | 4890        |
|    policy_gradient_loss | 0.037       |
|    std                  | 0.538       |
|    value_loss           | 0.0116      |
-----------------------------------------
box reached target
box reached target
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 623         |
|    iterations           | 491         |
|    time_elapsed         | 1613        |
|    total_timesteps      | 1005568     |
| train/                  |             |
|    approx_kl            | 0.034980442 |
|    clip_fraction        | 0.297       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.48       |
|    explained_variance   | 0.806       |
|    learning_rate        | 0.0018      |
|    loss                 | 0.0338      |
|    n_updates            | 4900        |
|    policy_gradient_loss | 0.00117     |
|    std                  | 0.532       |
|    value_loss           | 0.011       |
-----------------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 623         |
|    iterations           | 492         |
|    time_elapsed         | 1616        |
|    total_timesteps      | 1007616     |
| train/                  |             |
|    approx_kl            | 0.038229935 |
|    clip_fraction        | 0.281       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.51       |
|    explained_variance   | 0.938       |
|    learning_rate        | 0.0018      |
|    loss                 | -0.000215   |
|    n_updates            | 4910        |
|    policy_gradient_loss | 0.00485     |
|    std                  | 0.54        |
|    value_loss           | 0.00644     |
-----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 623        |
|    iterations           | 493        |
|    time_elapsed         | 1619       |
|    total_timesteps      | 1009664    |
| train/                  |            |
|    approx_kl            | 0.03989424 |
|    clip_fraction        | 0.284      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.49      |
|    explained_variance   | 0.925      |
|    learning_rate        | 0.0018     |
|    loss                 | 0.022      |
|    n_updates            | 4920       |
|    policy_gradient_loss | -0.000141  |
|    std                  | 0.533      |
|    value_loss           | 0.00219    |
----------------------------------------
Eval num_timesteps=1010000, episode_reward=-0.84 +/- 0.31
Episode length: 300.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 300         |
|    mean_reward          | -0.843      |
| time/                   |             |
|    total_timesteps      | 1010000     |
| train/                  |             |
|    approx_kl            | 0.051660173 |
|    clip_fraction        | 0.26        |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.49       |
|    explained_variance   | 0.874       |
|    learning_rate        | 0.0018      |
|    loss                 | 0.00902     |
|    n_updates            | 4930        |
|    policy_gradient_loss | -0.00342    |
|    std                  | 0.532       |
|    value_loss           | 0.0078      |
-----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 622     |
|    iterations      | 494     |
|    time_elapsed    | 1624    |
|    total_timesteps | 1011712 |
--------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 623         |
|    iterations           | 495         |
|    time_elapsed         | 1627        |
|    total_timesteps      | 1013760     |
| train/                  |             |
|    approx_kl            | 0.049027428 |
|    clip_fraction        | 0.293       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.55       |
|    explained_variance   | 0.707       |
|    learning_rate        | 0.0018      |
|    loss                 | 0.05        |
|    n_updates            | 4940        |
|    policy_gradient_loss | 0.00199     |
|    std                  | 0.571       |
|    value_loss           | 0.00382     |
-----------------------------------------
box reached target
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 623         |
|    iterations           | 496         |
|    time_elapsed         | 1630        |
|    total_timesteps      | 1015808     |
| train/                  |             |
|    approx_kl            | 0.085433915 |
|    clip_fraction        | 0.287       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.64       |
|    explained_variance   | 0.586       |
|    learning_rate        | 0.0018      |
|    loss                 | -0.0116     |
|    n_updates            | 4950        |
|    policy_gradient_loss | -0.00801    |
|    std                  | 0.582       |
|    value_loss           | 0.00224     |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 623         |
|    iterations           | 497         |
|    time_elapsed         | 1633        |
|    total_timesteps      | 1017856     |
| train/                  |             |
|    approx_kl            | 0.061577566 |
|    clip_fraction        | 0.289       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.59       |
|    explained_variance   | 0.96        |
|    learning_rate        | 0.0018      |
|    loss                 | 0.0188      |
|    n_updates            | 4960        |
|    policy_gradient_loss | -0.00197    |
|    std                  | 0.57        |
|    value_loss           | 0.00569     |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 623         |
|    iterations           | 498         |
|    time_elapsed         | 1636        |
|    total_timesteps      | 1019904     |
| train/                  |             |
|    approx_kl            | 0.050141484 |
|    clip_fraction        | 0.237       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.57       |
|    explained_variance   | 0.508       |
|    learning_rate        | 0.0018      |
|    loss                 | 0.0834      |
|    n_updates            | 4970        |
|    policy_gradient_loss | -0.00405    |
|    std                  | 0.563       |
|    value_loss           | 0.00599     |
-----------------------------------------
Eval num_timesteps=1020000, episode_reward=-0.73 +/- 0.54
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -0.732     |
| time/                   |            |
|    total_timesteps      | 1020000    |
| train/                  |            |
|    approx_kl            | 0.08620459 |
|    clip_fraction        | 0.277      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.55      |
|    explained_variance   | 0.483      |
|    learning_rate        | 0.0018     |
|    loss                 | -0.0202    |
|    n_updates            | 4980       |
|    policy_gradient_loss | 0.00104    |
|    std                  | 0.557      |
|    value_loss           | 0.00401    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 622     |
|    iterations      | 499     |
|    time_elapsed    | 1640    |
|    total_timesteps | 1021952 |
--------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 623         |
|    iterations           | 500         |
|    time_elapsed         | 1643        |
|    total_timesteps      | 1024000     |
| train/                  |             |
|    approx_kl            | 0.038436055 |
|    clip_fraction        | 0.259       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.59       |
|    explained_variance   | 0.804       |
|    learning_rate        | 0.0018      |
|    loss                 | -0.0228     |
|    n_updates            | 4990        |
|    policy_gradient_loss | 0.00332     |
|    std                  | 0.573       |
|    value_loss           | 0.00346     |
-----------------------------------------
box reached target
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 623         |
|    iterations           | 501         |
|    time_elapsed         | 1646        |
|    total_timesteps      | 1026048     |
| train/                  |             |
|    approx_kl            | 0.035880238 |
|    clip_fraction        | 0.229       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.59       |
|    explained_variance   | 0.965       |
|    learning_rate        | 0.0018      |
|    loss                 | 0.0905      |
|    n_updates            | 5000        |
|    policy_gradient_loss | -0.00117    |
|    std                  | 0.571       |
|    value_loss           | 0.002       |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 623         |
|    iterations           | 502         |
|    time_elapsed         | 1649        |
|    total_timesteps      | 1028096     |
| train/                  |             |
|    approx_kl            | 0.053368893 |
|    clip_fraction        | 0.299       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.51       |
|    explained_variance   | 0.833       |
|    learning_rate        | 0.0018      |
|    loss                 | -0.00786    |
|    n_updates            | 5010        |
|    policy_gradient_loss | 0.0044      |
|    std                  | 0.543       |
|    value_loss           | 0.0231      |
-----------------------------------------
box reached target
box reached target
Eval num_timesteps=1030000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 300         |
|    mean_reward          | -1          |
| time/                   |             |
|    total_timesteps      | 1030000     |
| train/                  |             |
|    approx_kl            | 0.028661098 |
|    clip_fraction        | 0.242       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.49       |
|    explained_variance   | 0.725       |
|    learning_rate        | 0.0018      |
|    loss                 | -0.0135     |
|    n_updates            | 5020        |
|    policy_gradient_loss | 0.00247     |
|    std                  | 0.55        |
|    value_loss           | 0.00322     |
-----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 622     |
|    iterations      | 503     |
|    time_elapsed    | 1653    |
|    total_timesteps | 1030144 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 504        |
|    time_elapsed         | 1656       |
|    total_timesteps      | 1032192    |
| train/                  |            |
|    approx_kl            | 0.09076898 |
|    clip_fraction        | 0.296      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.43      |
|    explained_variance   | 0.805      |
|    learning_rate        | 0.0018     |
|    loss                 | 0.0186     |
|    n_updates            | 5030       |
|    policy_gradient_loss | -0.00125   |
|    std                  | 0.522      |
|    value_loss           | 0.00611    |
----------------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 623         |
|    iterations           | 505         |
|    time_elapsed         | 1660        |
|    total_timesteps      | 1034240     |
| train/                  |             |
|    approx_kl            | 0.060249977 |
|    clip_fraction        | 0.248       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.41       |
|    explained_variance   | 0.698       |
|    learning_rate        | 0.0018      |
|    loss                 | -0.0181     |
|    n_updates            | 5040        |
|    policy_gradient_loss | -0.00129    |
|    std                  | 0.531       |
|    value_loss           | 0.00205     |
-----------------------------------------
box reached target
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 623        |
|    iterations           | 506        |
|    time_elapsed         | 1663       |
|    total_timesteps      | 1036288    |
| train/                  |            |
|    approx_kl            | 0.10109444 |
|    clip_fraction        | 0.282      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.36      |
|    explained_variance   | 0.634      |
|    learning_rate        | 0.0018     |
|    loss                 | -0.00135   |
|    n_updates            | 5050       |
|    policy_gradient_loss | 0.00142    |
|    std                  | 0.516      |
|    value_loss           | 0.00691    |
----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 623         |
|    iterations           | 507         |
|    time_elapsed         | 1666        |
|    total_timesteps      | 1038336     |
| train/                  |             |
|    approx_kl            | 0.040303696 |
|    clip_fraction        | 0.281       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.31       |
|    explained_variance   | 0.889       |
|    learning_rate        | 0.0018      |
|    loss                 | 0.0456      |
|    n_updates            | 5060        |
|    policy_gradient_loss | 0.0015      |
|    std                  | 0.5         |
|    value_loss           | 0.00823     |
-----------------------------------------
box reached target
box reached target
Eval num_timesteps=1040000, episode_reward=0.23 +/- 2.46
Episode length: 272.00 +/- 56.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 272        |
|    mean_reward          | 0.229      |
| time/                   |            |
|    total_timesteps      | 1040000    |
| train/                  |            |
|    approx_kl            | 0.04772495 |
|    clip_fraction        | 0.273      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.27      |
|    explained_variance   | 0.57       |
|    learning_rate        | 0.0018     |
|    loss                 | 0.04       |
|    n_updates            | 5070       |
|    policy_gradient_loss | 0.00734    |
|    std                  | 0.489      |
|    value_loss           | 0.00263    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 622     |
|    iterations      | 508     |
|    time_elapsed    | 1670    |
|    total_timesteps | 1040384 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 509        |
|    time_elapsed         | 1673       |
|    total_timesteps      | 1042432    |
| train/                  |            |
|    approx_kl            | 0.04566661 |
|    clip_fraction        | 0.286      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.26      |
|    explained_variance   | 0.912      |
|    learning_rate        | 0.0018     |
|    loss                 | 0.0139     |
|    n_updates            | 5080       |
|    policy_gradient_loss | 0.00451    |
|    std                  | 0.497      |
|    value_loss           | 0.00559    |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 623        |
|    iterations           | 510        |
|    time_elapsed         | 1676       |
|    total_timesteps      | 1044480    |
| train/                  |            |
|    approx_kl            | 0.12482264 |
|    clip_fraction        | 0.267      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.3       |
|    explained_variance   | 0.769      |
|    learning_rate        | 0.0018     |
|    loss                 | -0.0278    |
|    n_updates            | 5090       |
|    policy_gradient_loss | 0.00463    |
|    std                  | 0.506      |
|    value_loss           | 0.00395    |
----------------------------------------
box reached target
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 623        |
|    iterations           | 511        |
|    time_elapsed         | 1679       |
|    total_timesteps      | 1046528    |
| train/                  |            |
|    approx_kl            | 0.04863084 |
|    clip_fraction        | 0.299      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.32      |
|    explained_variance   | 0.95       |
|    learning_rate        | 0.0018     |
|    loss                 | -0.0271    |
|    n_updates            | 5100       |
|    policy_gradient_loss | 0.00225    |
|    std                  | 0.505      |
|    value_loss           | 0.00471    |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 623        |
|    iterations           | 512        |
|    time_elapsed         | 1682       |
|    total_timesteps      | 1048576    |
| train/                  |            |
|    approx_kl            | 0.07501884 |
|    clip_fraction        | 0.304      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.33      |
|    explained_variance   | 0.613      |
|    learning_rate        | 0.0018     |
|    loss                 | -0.0188    |
|    n_updates            | 5110       |
|    policy_gradient_loss | 0.00175    |
|    std                  | 0.509      |
|    value_loss           | 0.0424     |
----------------------------------------
Eval num_timesteps=1050000, episode_reward=-0.36 +/- 0.79
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -0.361     |
| time/                   |            |
|    total_timesteps      | 1050000    |
| train/                  |            |
|    approx_kl            | 0.04861114 |
|    clip_fraction        | 0.317      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.33      |
|    explained_variance   | 0.624      |
|    learning_rate        | 0.0018     |
|    loss                 | -0.0162    |
|    n_updates            | 5120       |
|    policy_gradient_loss | 0.00662    |
|    std                  | 0.515      |
|    value_loss           | 0.0142     |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 622     |
|    iterations      | 513     |
|    time_elapsed    | 1686    |
|    total_timesteps | 1050624 |
--------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 622         |
|    iterations           | 514         |
|    time_elapsed         | 1689        |
|    total_timesteps      | 1052672     |
| train/                  |             |
|    approx_kl            | 0.023652604 |
|    clip_fraction        | 0.243       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.38       |
|    explained_variance   | 0.718       |
|    learning_rate        | 0.0018      |
|    loss                 | 0.0135      |
|    n_updates            | 5130        |
|    policy_gradient_loss | 0.00708     |
|    std                  | 0.518       |
|    value_loss           | 0.00726     |
-----------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 622       |
|    iterations           | 515       |
|    time_elapsed         | 1692      |
|    total_timesteps      | 1054720   |
| train/                  |           |
|    approx_kl            | 0.0810933 |
|    clip_fraction        | 0.3       |
|    clip_range           | 0.2       |
|    entropy_loss         | -1.37     |
|    explained_variance   | 0.897     |
|    learning_rate        | 0.00179   |
|    loss                 | -0.0255   |
|    n_updates            | 5140      |
|    policy_gradient_loss | 0.00235   |
|    std                  | 0.518     |
|    value_loss           | 0.00588   |
---------------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 623         |
|    iterations           | 516         |
|    time_elapsed         | 1696        |
|    total_timesteps      | 1056768     |
| train/                  |             |
|    approx_kl            | 0.038206883 |
|    clip_fraction        | 0.304       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.37       |
|    explained_variance   | 0.674       |
|    learning_rate        | 0.00179     |
|    loss                 | 0.0266      |
|    n_updates            | 5150        |
|    policy_gradient_loss | 0.00434     |
|    std                  | 0.517       |
|    value_loss           | 0.0108      |
-----------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 623       |
|    iterations           | 517       |
|    time_elapsed         | 1699      |
|    total_timesteps      | 1058816   |
| train/                  |           |
|    approx_kl            | 0.0982053 |
|    clip_fraction        | 0.303     |
|    clip_range           | 0.2       |
|    entropy_loss         | -1.34     |
|    explained_variance   | 0.722     |
|    learning_rate        | 0.00179   |
|    loss                 | -0.0427   |
|    n_updates            | 5160      |
|    policy_gradient_loss | -0.00206  |
|    std                  | 0.506     |
|    value_loss           | 0.0135    |
---------------------------------------
Eval num_timesteps=1060000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1         |
| time/                   |            |
|    total_timesteps      | 1060000    |
| train/                  |            |
|    approx_kl            | 0.11859166 |
|    clip_fraction        | 0.316      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.29      |
|    explained_variance   | 0.774      |
|    learning_rate        | 0.00179    |
|    loss                 | -0.00109   |
|    n_updates            | 5170       |
|    policy_gradient_loss | 0.00268    |
|    std                  | 0.502      |
|    value_loss           | 0.013      |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 622     |
|    iterations      | 518     |
|    time_elapsed    | 1703    |
|    total_timesteps | 1060864 |
--------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 519        |
|    time_elapsed         | 1706       |
|    total_timesteps      | 1062912    |
| train/                  |            |
|    approx_kl            | 0.14716412 |
|    clip_fraction        | 0.324      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.32      |
|    explained_variance   | 0.543      |
|    learning_rate        | 0.00179    |
|    loss                 | 0.0119     |
|    n_updates            | 5180       |
|    policy_gradient_loss | -0.00156   |
|    std                  | 0.506      |
|    value_loss           | 0.00502    |
----------------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 520        |
|    time_elapsed         | 1709       |
|    total_timesteps      | 1064960    |
| train/                  |            |
|    approx_kl            | 0.12230082 |
|    clip_fraction        | 0.296      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.35      |
|    explained_variance   | 0.91       |
|    learning_rate        | 0.00179    |
|    loss                 | -0.0437    |
|    n_updates            | 5190       |
|    policy_gradient_loss | -0.0117    |
|    std                  | 0.509      |
|    value_loss           | 0.00428    |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 623        |
|    iterations           | 521        |
|    time_elapsed         | 1712       |
|    total_timesteps      | 1067008    |
| train/                  |            |
|    approx_kl            | 0.07116922 |
|    clip_fraction        | 0.287      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.28      |
|    explained_variance   | 0.933      |
|    learning_rate        | 0.00179    |
|    loss                 | -0.00572   |
|    n_updates            | 5200       |
|    policy_gradient_loss | -0.00549   |
|    std                  | 0.489      |
|    value_loss           | 0.011      |
----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 623         |
|    iterations           | 522         |
|    time_elapsed         | 1715        |
|    total_timesteps      | 1069056     |
| train/                  |             |
|    approx_kl            | 0.054453872 |
|    clip_fraction        | 0.278       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.28       |
|    explained_variance   | 0.866       |
|    learning_rate        | 0.00179     |
|    loss                 | 0.0269      |
|    n_updates            | 5210        |
|    policy_gradient_loss | 0.00849     |
|    std                  | 0.49        |
|    value_loss           | 0.00551     |
-----------------------------------------
box reached target
box reached target
Eval num_timesteps=1070000, episode_reward=0.22 +/- 2.51
Episode length: 277.60 +/- 44.80
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 278        |
|    mean_reward          | 0.223      |
| time/                   |            |
|    total_timesteps      | 1070000    |
| train/                  |            |
|    approx_kl            | 0.07363427 |
|    clip_fraction        | 0.288      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.28      |
|    explained_variance   | 0.828      |
|    learning_rate        | 0.00179    |
|    loss                 | 0.00781    |
|    n_updates            | 5220       |
|    policy_gradient_loss | -0.000855  |
|    std                  | 0.486      |
|    value_loss           | 0.00453    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 622     |
|    iterations      | 523     |
|    time_elapsed    | 1719    |
|    total_timesteps | 1071104 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 524        |
|    time_elapsed         | 1722       |
|    total_timesteps      | 1073152    |
| train/                  |            |
|    approx_kl            | 0.13097166 |
|    clip_fraction        | 0.279      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.26      |
|    explained_variance   | 0.808      |
|    learning_rate        | 0.00179    |
|    loss                 | -0.0197    |
|    n_updates            | 5230       |
|    policy_gradient_loss | -0.0011    |
|    std                  | 0.475      |
|    value_loss           | 0.00412    |
----------------------------------------
box reached target
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 525        |
|    time_elapsed         | 1725       |
|    total_timesteps      | 1075200    |
| train/                  |            |
|    approx_kl            | 0.03750189 |
|    clip_fraction        | 0.252      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.25      |
|    explained_variance   | 0.673      |
|    learning_rate        | 0.00179    |
|    loss                 | -0.0364    |
|    n_updates            | 5240       |
|    policy_gradient_loss | -0.00409   |
|    std                  | 0.482      |
|    value_loss           | 0.0034     |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 623        |
|    iterations           | 526        |
|    time_elapsed         | 1729       |
|    total_timesteps      | 1077248    |
| train/                  |            |
|    approx_kl            | 0.12275349 |
|    clip_fraction        | 0.364      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.24      |
|    explained_variance   | 0.809      |
|    learning_rate        | 0.00179    |
|    loss                 | 0.0169     |
|    n_updates            | 5250       |
|    policy_gradient_loss | 0.00825    |
|    std                  | 0.483      |
|    value_loss           | 0.0136     |
----------------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 623         |
|    iterations           | 527         |
|    time_elapsed         | 1732        |
|    total_timesteps      | 1079296     |
| train/                  |             |
|    approx_kl            | 0.075535245 |
|    clip_fraction        | 0.33        |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.23       |
|    explained_variance   | 0.668       |
|    learning_rate        | 0.00179     |
|    loss                 | 0.00356     |
|    n_updates            | 5260        |
|    policy_gradient_loss | 0.00373     |
|    std                  | 0.474       |
|    value_loss           | 0.00496     |
-----------------------------------------
Eval num_timesteps=1080000, episode_reward=-0.57 +/- 0.58
Episode length: 300.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 300         |
|    mean_reward          | -0.573      |
| time/                   |             |
|    total_timesteps      | 1080000     |
| train/                  |             |
|    approx_kl            | 0.046303116 |
|    clip_fraction        | 0.297       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.25       |
|    explained_variance   | 0.834       |
|    learning_rate        | 0.00179     |
|    loss                 | 0.00418     |
|    n_updates            | 5270        |
|    policy_gradient_loss | 0.00241     |
|    std                  | 0.487       |
|    value_loss           | 0.00842     |
-----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 622     |
|    iterations      | 528     |
|    time_elapsed    | 1736    |
|    total_timesteps | 1081344 |
--------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 622         |
|    iterations           | 529         |
|    time_elapsed         | 1739        |
|    total_timesteps      | 1083392     |
| train/                  |             |
|    approx_kl            | 0.060566783 |
|    clip_fraction        | 0.255       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.26       |
|    explained_variance   | 0.506       |
|    learning_rate        | 0.00179     |
|    loss                 | 0.0119      |
|    n_updates            | 5280        |
|    policy_gradient_loss | 0.0138      |
|    std                  | 0.48        |
|    value_loss           | 0.00221     |
-----------------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 622         |
|    iterations           | 530         |
|    time_elapsed         | 1742        |
|    total_timesteps      | 1085440     |
| train/                  |             |
|    approx_kl            | 0.110405795 |
|    clip_fraction        | 0.249       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.22       |
|    explained_variance   | 0.944       |
|    learning_rate        | 0.00179     |
|    loss                 | 0.024       |
|    n_updates            | 5290        |
|    policy_gradient_loss | 0.00112     |
|    std                  | 0.474       |
|    value_loss           | 0.0029      |
-----------------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 623         |
|    iterations           | 531         |
|    time_elapsed         | 1745        |
|    total_timesteps      | 1087488     |
| train/                  |             |
|    approx_kl            | 0.052363295 |
|    clip_fraction        | 0.308       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.2        |
|    explained_variance   | 0.952       |
|    learning_rate        | 0.00179     |
|    loss                 | -0.0303     |
|    n_updates            | 5300        |
|    policy_gradient_loss | 0.00291     |
|    std                  | 0.47        |
|    value_loss           | 0.00285     |
-----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 623        |
|    iterations           | 532        |
|    time_elapsed         | 1748       |
|    total_timesteps      | 1089536    |
| train/                  |            |
|    approx_kl            | 0.12594864 |
|    clip_fraction        | 0.317      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.19      |
|    explained_variance   | 0.915      |
|    learning_rate        | 0.00179    |
|    loss                 | 0.000971   |
|    n_updates            | 5310       |
|    policy_gradient_loss | -0.000117  |
|    std                  | 0.464      |
|    value_loss           | 0.00579    |
----------------------------------------
box reached target
Eval num_timesteps=1090000, episode_reward=0.26 +/- 2.53
Episode length: 278.60 +/- 42.80
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 279        |
|    mean_reward          | 0.264      |
| time/                   |            |
|    total_timesteps      | 1090000    |
| train/                  |            |
|    approx_kl            | 0.14658263 |
|    clip_fraction        | 0.324      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.11      |
|    explained_variance   | 0.252      |
|    learning_rate        | 0.00179    |
|    loss                 | 0.055      |
|    n_updates            | 5320       |
|    policy_gradient_loss | -0.00283   |
|    std                  | 0.441      |
|    value_loss           | 0.00328    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 622     |
|    iterations      | 533     |
|    time_elapsed    | 1752    |
|    total_timesteps | 1091584 |
--------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 534        |
|    time_elapsed         | 1755       |
|    total_timesteps      | 1093632    |
| train/                  |            |
|    approx_kl            | 0.09120224 |
|    clip_fraction        | 0.296      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.06      |
|    explained_variance   | 0.834      |
|    learning_rate        | 0.00179    |
|    loss                 | -0.0179    |
|    n_updates            | 5330       |
|    policy_gradient_loss | 0.00281    |
|    std                  | 0.431      |
|    value_loss           | 0.00209    |
----------------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 622         |
|    iterations           | 535         |
|    time_elapsed         | 1758        |
|    total_timesteps      | 1095680     |
| train/                  |             |
|    approx_kl            | 0.053284697 |
|    clip_fraction        | 0.294       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.04       |
|    explained_variance   | 0.962       |
|    learning_rate        | 0.00179     |
|    loss                 | -0.0242     |
|    n_updates            | 5340        |
|    policy_gradient_loss | 0.00448     |
|    std                  | 0.432       |
|    value_loss           | 0.00231     |
-----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 623        |
|    iterations           | 536        |
|    time_elapsed         | 1761       |
|    total_timesteps      | 1097728    |
| train/                  |            |
|    approx_kl            | 0.07956201 |
|    clip_fraction        | 0.303      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.05      |
|    explained_variance   | 0.933      |
|    learning_rate        | 0.00179    |
|    loss                 | -0.0146    |
|    n_updates            | 5350       |
|    policy_gradient_loss | 0.00351    |
|    std                  | 0.43       |
|    value_loss           | 0.0037     |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 623        |
|    iterations           | 537        |
|    time_elapsed         | 1765       |
|    total_timesteps      | 1099776    |
| train/                  |            |
|    approx_kl            | 0.23688595 |
|    clip_fraction        | 0.341      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.05      |
|    explained_variance   | 0.858      |
|    learning_rate        | 0.00179    |
|    loss                 | -0.0271    |
|    n_updates            | 5360       |
|    policy_gradient_loss | 0.00275    |
|    std                  | 0.435      |
|    value_loss           | 0.00736    |
----------------------------------------
Eval num_timesteps=1100000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1         |
| time/                   |            |
|    total_timesteps      | 1100000    |
| train/                  |            |
|    approx_kl            | 0.12058604 |
|    clip_fraction        | 0.297      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.06      |
|    explained_variance   | 0.902      |
|    learning_rate        | 0.00179    |
|    loss                 | -0.0264    |
|    n_updates            | 5370       |
|    policy_gradient_loss | 0.000792   |
|    std                  | 0.442      |
|    value_loss           | 0.00768    |
----------------------------------------
box reached target
--------------------------------
| time/              |         |
|    fps             | 622     |
|    iterations      | 538     |
|    time_elapsed    | 1769    |
|    total_timesteps | 1101824 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 539        |
|    time_elapsed         | 1772       |
|    total_timesteps      | 1103872    |
| train/                  |            |
|    approx_kl            | 0.07397522 |
|    clip_fraction        | 0.288      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.08      |
|    explained_variance   | 0.922      |
|    learning_rate        | 0.00179    |
|    loss                 | -0.00202   |
|    n_updates            | 5380       |
|    policy_gradient_loss | 0.00379    |
|    std                  | 0.443      |
|    value_loss           | 0.0037     |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 540        |
|    time_elapsed         | 1775       |
|    total_timesteps      | 1105920    |
| train/                  |            |
|    approx_kl            | 0.06796385 |
|    clip_fraction        | 0.274      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.12      |
|    explained_variance   | 0.682      |
|    learning_rate        | 0.00178    |
|    loss                 | -0.00823   |
|    n_updates            | 5390       |
|    policy_gradient_loss | -0.002     |
|    std                  | 0.447      |
|    value_loss           | 0.00207    |
----------------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 622         |
|    iterations           | 541         |
|    time_elapsed         | 1778        |
|    total_timesteps      | 1107968     |
| train/                  |             |
|    approx_kl            | 0.100569054 |
|    clip_fraction        | 0.283       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.11       |
|    explained_variance   | 0.726       |
|    learning_rate        | 0.00178     |
|    loss                 | -0.0177     |
|    n_updates            | 5400        |
|    policy_gradient_loss | -0.0027     |
|    std                  | 0.448       |
|    value_loss           | 0.00263     |
-----------------------------------------
box reached target
Eval num_timesteps=1110000, episode_reward=0.21 +/- 2.42
Episode length: 271.80 +/- 56.40
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 272        |
|    mean_reward          | 0.208      |
| time/                   |            |
|    total_timesteps      | 1110000    |
| train/                  |            |
|    approx_kl            | 0.08997391 |
|    clip_fraction        | 0.319      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.1       |
|    explained_variance   | 0.826      |
|    learning_rate        | 0.00178    |
|    loss                 | 0.0175     |
|    n_updates            | 5410       |
|    policy_gradient_loss | 0.00011    |
|    std                  | 0.445      |
|    value_loss           | 0.00504    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 622     |
|    iterations      | 542     |
|    time_elapsed    | 1782    |
|    total_timesteps | 1110016 |
--------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 543        |
|    time_elapsed         | 1785       |
|    total_timesteps      | 1112064    |
| train/                  |            |
|    approx_kl            | 0.07894772 |
|    clip_fraction        | 0.31       |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.1       |
|    explained_variance   | 0.46       |
|    learning_rate        | 0.00178    |
|    loss                 | 0.0296     |
|    n_updates            | 5420       |
|    policy_gradient_loss | 0.00321    |
|    std                  | 0.451      |
|    value_loss           | 0.00196    |
----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 622         |
|    iterations           | 544         |
|    time_elapsed         | 1788        |
|    total_timesteps      | 1114112     |
| train/                  |             |
|    approx_kl            | 0.059906058 |
|    clip_fraction        | 0.296       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.11       |
|    explained_variance   | 0.916       |
|    learning_rate        | 0.00178     |
|    loss                 | 0.00889     |
|    n_updates            | 5430        |
|    policy_gradient_loss | -0.00546    |
|    std                  | 0.453       |
|    value_loss           | 0.00585     |
-----------------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 622         |
|    iterations           | 545         |
|    time_elapsed         | 1791        |
|    total_timesteps      | 1116160     |
| train/                  |             |
|    approx_kl            | 0.060656972 |
|    clip_fraction        | 0.316       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.16       |
|    explained_variance   | 0.814       |
|    learning_rate        | 0.00178     |
|    loss                 | 0.00541     |
|    n_updates            | 5440        |
|    policy_gradient_loss | 0.008       |
|    std                  | 0.468       |
|    value_loss           | 0.00707     |
-----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 623        |
|    iterations           | 546        |
|    time_elapsed         | 1794       |
|    total_timesteps      | 1118208    |
| train/                  |            |
|    approx_kl            | 0.54109716 |
|    clip_fraction        | 0.345      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.12      |
|    explained_variance   | 0.728      |
|    learning_rate        | 0.00178    |
|    loss                 | -0.0457    |
|    n_updates            | 5450       |
|    policy_gradient_loss | -0.0085    |
|    std                  | 0.446      |
|    value_loss           | 0.00802    |
----------------------------------------
box reached target
box reached target
Eval num_timesteps=1120000, episode_reward=0.41 +/- 2.42
Episode length: 283.60 +/- 32.80
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 284        |
|    mean_reward          | 0.406      |
| time/                   |            |
|    total_timesteps      | 1120000    |
| train/                  |            |
|    approx_kl            | 0.14070715 |
|    clip_fraction        | 0.311      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.13      |
|    explained_variance   | 0.858      |
|    learning_rate        | 0.00178    |
|    loss                 | -0.0395    |
|    n_updates            | 5460       |
|    policy_gradient_loss | 0.000537   |
|    std                  | 0.459      |
|    value_loss           | 0.0035     |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 622     |
|    iterations      | 547     |
|    time_elapsed    | 1798    |
|    total_timesteps | 1120256 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 548        |
|    time_elapsed         | 1801       |
|    total_timesteps      | 1122304    |
| train/                  |            |
|    approx_kl            | 0.09746462 |
|    clip_fraction        | 0.339      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.14      |
|    explained_variance   | 0.888      |
|    learning_rate        | 0.00178    |
|    loss                 | -0.00599   |
|    n_updates            | 5470       |
|    policy_gradient_loss | 0.00699    |
|    std                  | 0.456      |
|    value_loss           | 0.00397    |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 549        |
|    time_elapsed         | 1805       |
|    total_timesteps      | 1124352    |
| train/                  |            |
|    approx_kl            | 0.05126109 |
|    clip_fraction        | 0.308      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.13      |
|    explained_variance   | 0.804      |
|    learning_rate        | 0.00178    |
|    loss                 | 0.0185     |
|    n_updates            | 5480       |
|    policy_gradient_loss | 0.012      |
|    std                  | 0.45       |
|    value_loss           | 0.00753    |
----------------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 550        |
|    time_elapsed         | 1808       |
|    total_timesteps      | 1126400    |
| train/                  |            |
|    approx_kl            | 0.11858305 |
|    clip_fraction        | 0.318      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.1       |
|    explained_variance   | 0.762      |
|    learning_rate        | 0.00178    |
|    loss                 | 0.0476     |
|    n_updates            | 5490       |
|    policy_gradient_loss | 0.00111    |
|    std                  | 0.445      |
|    value_loss           | 0.00655    |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 551        |
|    time_elapsed         | 1811       |
|    total_timesteps      | 1128448    |
| train/                  |            |
|    approx_kl            | 0.07473417 |
|    clip_fraction        | 0.298      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.08      |
|    explained_variance   | 0.951      |
|    learning_rate        | 0.00178    |
|    loss                 | -0.012     |
|    n_updates            | 5500       |
|    policy_gradient_loss | -0.0019    |
|    std                  | 0.444      |
|    value_loss           | 0.00443    |
----------------------------------------
box reached target
Eval num_timesteps=1130000, episode_reward=0.41 +/- 2.35
Episode length: 273.80 +/- 52.40
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 274         |
|    mean_reward          | 0.415       |
| time/                   |             |
|    total_timesteps      | 1130000     |
| train/                  |             |
|    approx_kl            | 0.071576506 |
|    clip_fraction        | 0.309       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.05       |
|    explained_variance   | 0.852       |
|    learning_rate        | 0.00178     |
|    loss                 | 0.0319      |
|    n_updates            | 5510        |
|    policy_gradient_loss | 0.00465     |
|    std                  | 0.438       |
|    value_loss           | 0.00867     |
-----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 622     |
|    iterations      | 552     |
|    time_elapsed    | 1815    |
|    total_timesteps | 1130496 |
--------------------------------
box reached target
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 622       |
|    iterations           | 553       |
|    time_elapsed         | 1818      |
|    total_timesteps      | 1132544   |
| train/                  |           |
|    approx_kl            | 0.1777066 |
|    clip_fraction        | 0.323     |
|    clip_range           | 0.2       |
|    entropy_loss         | -1.05     |
|    explained_variance   | 0.432     |
|    learning_rate        | 0.00178   |
|    loss                 | -0.0176   |
|    n_updates            | 5520      |
|    policy_gradient_loss | 0.000244  |
|    std                  | 0.434     |
|    value_loss           | 0.00161   |
---------------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 622         |
|    iterations           | 554         |
|    time_elapsed         | 1821        |
|    total_timesteps      | 1134592     |
| train/                  |             |
|    approx_kl            | 0.057962753 |
|    clip_fraction        | 0.287       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.05       |
|    explained_variance   | 0.897       |
|    learning_rate        | 0.00178     |
|    loss                 | 0.0274      |
|    n_updates            | 5530        |
|    policy_gradient_loss | 0.00502     |
|    std                  | 0.437       |
|    value_loss           | 0.00831     |
-----------------------------------------
box reached target
--------------------------------------
| time/                   |          |
|    fps                  | 622      |
|    iterations           | 555      |
|    time_elapsed         | 1824     |
|    total_timesteps      | 1136640  |
| train/                  |          |
|    approx_kl            | 0.127531 |
|    clip_fraction        | 0.334    |
|    clip_range           | 0.2      |
|    entropy_loss         | -1.06    |
|    explained_variance   | 0.52     |
|    learning_rate        | 0.00178  |
|    loss                 | 0.0147   |
|    n_updates            | 5540     |
|    policy_gradient_loss | 0.00352  |
|    std                  | 0.436    |
|    value_loss           | 0.0205   |
--------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 556        |
|    time_elapsed         | 1827       |
|    total_timesteps      | 1138688    |
| train/                  |            |
|    approx_kl            | 0.11732267 |
|    clip_fraction        | 0.335      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.01      |
|    explained_variance   | 0.929      |
|    learning_rate        | 0.00178    |
|    loss                 | 0.0376     |
|    n_updates            | 5550       |
|    policy_gradient_loss | 0.00286    |
|    std                  | 0.419      |
|    value_loss           | 0.00501    |
----------------------------------------
box reached target
box reached target
box reached target
box reached target
Eval num_timesteps=1140000, episode_reward=0.52 +/- 2.39
Episode length: 272.20 +/- 55.60
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 272        |
|    mean_reward          | 0.523      |
| time/                   |            |
|    total_timesteps      | 1140000    |
| train/                  |            |
|    approx_kl            | 0.10140905 |
|    clip_fraction        | 0.324      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.01      |
|    explained_variance   | 0.915      |
|    learning_rate        | 0.00178    |
|    loss                 | -0.00487   |
|    n_updates            | 5560       |
|    policy_gradient_loss | 0.00319    |
|    std                  | 0.421      |
|    value_loss           | 0.00347    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 622     |
|    iterations      | 557     |
|    time_elapsed    | 1831    |
|    total_timesteps | 1140736 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 558        |
|    time_elapsed         | 1834       |
|    total_timesteps      | 1142784    |
| train/                  |            |
|    approx_kl            | 0.09794937 |
|    clip_fraction        | 0.315      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.983     |
|    explained_variance   | 0.866      |
|    learning_rate        | 0.00178    |
|    loss                 | -0.0393    |
|    n_updates            | 5570       |
|    policy_gradient_loss | 0.000485   |
|    std                  | 0.416      |
|    value_loss           | 0.014      |
----------------------------------------
box reached target
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 622         |
|    iterations           | 559         |
|    time_elapsed         | 1837        |
|    total_timesteps      | 1144832     |
| train/                  |             |
|    approx_kl            | 0.064319104 |
|    clip_fraction        | 0.333       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.993      |
|    explained_variance   | 0.601       |
|    learning_rate        | 0.00178     |
|    loss                 | -0.0217     |
|    n_updates            | 5580        |
|    policy_gradient_loss | 0.001       |
|    std                  | 0.421       |
|    value_loss           | 0.00218     |
-----------------------------------------
box reached target
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 622       |
|    iterations           | 560       |
|    time_elapsed         | 1841      |
|    total_timesteps      | 1146880   |
| train/                  |           |
|    approx_kl            | 0.0660627 |
|    clip_fraction        | 0.306     |
|    clip_range           | 0.2       |
|    entropy_loss         | -1.03     |
|    explained_variance   | 0.891     |
|    learning_rate        | 0.00178   |
|    loss                 | -0.00212  |
|    n_updates            | 5590      |
|    policy_gradient_loss | 0.00464   |
|    std                  | 0.428     |
|    value_loss           | 0.00764   |
---------------------------------------
box reached target
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 622         |
|    iterations           | 561         |
|    time_elapsed         | 1844        |
|    total_timesteps      | 1148928     |
| train/                  |             |
|    approx_kl            | 0.061708882 |
|    clip_fraction        | 0.332       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.05       |
|    explained_variance   | 0.936       |
|    learning_rate        | 0.00178     |
|    loss                 | -0.0224     |
|    n_updates            | 5600        |
|    policy_gradient_loss | 0.0055      |
|    std                  | 0.44        |
|    value_loss           | 0.00755     |
-----------------------------------------
box reached target
box reached target
Eval num_timesteps=1150000, episode_reward=0.22 +/- 2.44
Episode length: 270.00 +/- 60.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 270         |
|    mean_reward          | 0.22        |
| time/                   |             |
|    total_timesteps      | 1150000     |
| train/                  |             |
|    approx_kl            | 0.056020655 |
|    clip_fraction        | 0.285       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.05       |
|    explained_variance   | 0.966       |
|    learning_rate        | 0.00178     |
|    loss                 | -0.0368     |
|    n_updates            | 5610        |
|    policy_gradient_loss | -0.0108     |
|    std                  | 0.433       |
|    value_loss           | 0.00276     |
-----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 622     |
|    iterations      | 562     |
|    time_elapsed    | 1848    |
|    total_timesteps | 1150976 |
--------------------------------
box reached target
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 563        |
|    time_elapsed         | 1851       |
|    total_timesteps      | 1153024    |
| train/                  |            |
|    approx_kl            | 0.06963526 |
|    clip_fraction        | 0.324      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.05      |
|    explained_variance   | 0.938      |
|    learning_rate        | 0.00178    |
|    loss                 | -0.00173   |
|    n_updates            | 5620       |
|    policy_gradient_loss | 0.00511    |
|    std                  | 0.43       |
|    value_loss           | 0.00613    |
----------------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 564        |
|    time_elapsed         | 1854       |
|    total_timesteps      | 1155072    |
| train/                  |            |
|    approx_kl            | 0.07627873 |
|    clip_fraction        | 0.291      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.04      |
|    explained_variance   | 0.809      |
|    learning_rate        | 0.00178    |
|    loss                 | 0.0172     |
|    n_updates            | 5630       |
|    policy_gradient_loss | 0.00421    |
|    std                  | 0.436      |
|    value_loss           | 0.0184     |
----------------------------------------
box reached target
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 622         |
|    iterations           | 565         |
|    time_elapsed         | 1857        |
|    total_timesteps      | 1157120     |
| train/                  |             |
|    approx_kl            | 0.037955813 |
|    clip_fraction        | 0.282       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.04       |
|    explained_variance   | 0.89        |
|    learning_rate        | 0.00177     |
|    loss                 | -0.028      |
|    n_updates            | 5640        |
|    policy_gradient_loss | 0.00539     |
|    std                  | 0.433       |
|    value_loss           | 0.00853     |
-----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 566        |
|    time_elapsed         | 1860       |
|    total_timesteps      | 1159168    |
| train/                  |            |
|    approx_kl            | 0.07780106 |
|    clip_fraction        | 0.335      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.986     |
|    explained_variance   | 0.864      |
|    learning_rate        | 0.00177    |
|    loss                 | -0.014     |
|    n_updates            | 5650       |
|    policy_gradient_loss | 0.000695   |
|    std                  | 0.421      |
|    value_loss           | 0.0104     |
----------------------------------------
box reached target
box reached target
Eval num_timesteps=1160000, episode_reward=0.21 +/- 2.42
Episode length: 272.60 +/- 54.80
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 273         |
|    mean_reward          | 0.211       |
| time/                   |             |
|    total_timesteps      | 1160000     |
| train/                  |             |
|    approx_kl            | 0.056755204 |
|    clip_fraction        | 0.284       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.988      |
|    explained_variance   | 0.644       |
|    learning_rate        | 0.00177     |
|    loss                 | 0.0307      |
|    n_updates            | 5660        |
|    policy_gradient_loss | 0.00741     |
|    std                  | 0.432       |
|    value_loss           | 0.00171     |
-----------------------------------------
box reached target
box reached target
--------------------------------
| time/              |         |
|    fps             | 622     |
|    iterations      | 567     |
|    time_elapsed    | 1864    |
|    total_timesteps | 1161216 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 568        |
|    time_elapsed         | 1867       |
|    total_timesteps      | 1163264    |
| train/                  |            |
|    approx_kl            | 0.06472153 |
|    clip_fraction        | 0.301      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.02      |
|    explained_variance   | 0.851      |
|    learning_rate        | 0.00177    |
|    loss                 | 0.0753     |
|    n_updates            | 5670       |
|    policy_gradient_loss | 0.0123     |
|    std                  | 0.433      |
|    value_loss           | 0.0202     |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 569        |
|    time_elapsed         | 1870       |
|    total_timesteps      | 1165312    |
| train/                  |            |
|    approx_kl            | 0.07605079 |
|    clip_fraction        | 0.316      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.06      |
|    explained_variance   | 0.779      |
|    learning_rate        | 0.00177    |
|    loss                 | -0.019     |
|    n_updates            | 5680       |
|    policy_gradient_loss | -0.00558   |
|    std                  | 0.446      |
|    value_loss           | 0.00287    |
----------------------------------------
box reached target
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 622         |
|    iterations           | 570         |
|    time_elapsed         | 1873        |
|    total_timesteps      | 1167360     |
| train/                  |             |
|    approx_kl            | 0.088359416 |
|    clip_fraction        | 0.338       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.08       |
|    explained_variance   | 0.867       |
|    learning_rate        | 0.00177     |
|    loss                 | 0.0265      |
|    n_updates            | 5690        |
|    policy_gradient_loss | 0.0154      |
|    std                  | 0.445       |
|    value_loss           | 0.00653     |
-----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 571        |
|    time_elapsed         | 1877       |
|    total_timesteps      | 1169408    |
| train/                  |            |
|    approx_kl            | 0.09644818 |
|    clip_fraction        | 0.344      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.05      |
|    explained_variance   | 0.844      |
|    learning_rate        | 0.00177    |
|    loss                 | -0.0143    |
|    n_updates            | 5700       |
|    policy_gradient_loss | 0.00527    |
|    std                  | 0.432      |
|    value_loss           | 0.0154     |
----------------------------------------
Eval num_timesteps=1170000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1         |
| time/                   |            |
|    total_timesteps      | 1170000    |
| train/                  |            |
|    approx_kl            | 0.20151392 |
|    clip_fraction        | 0.327      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.992     |
|    explained_variance   | 0.831      |
|    learning_rate        | 0.00177    |
|    loss                 | -0.0187    |
|    n_updates            | 5710       |
|    policy_gradient_loss | -0.00454   |
|    std                  | 0.421      |
|    value_loss           | 0.00361    |
----------------------------------------
box reached target
--------------------------------
| time/              |         |
|    fps             | 622     |
|    iterations      | 572     |
|    time_elapsed    | 1881    |
|    total_timesteps | 1171456 |
--------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 622       |
|    iterations           | 573       |
|    time_elapsed         | 1884      |
|    total_timesteps      | 1173504   |
| train/                  |           |
|    approx_kl            | 0.1741722 |
|    clip_fraction        | 0.354     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.971    |
|    explained_variance   | 0.966     |
|    learning_rate        | 0.00177   |
|    loss                 | -0.0276   |
|    n_updates            | 5720      |
|    policy_gradient_loss | 0.0091    |
|    std                  | 0.412     |
|    value_loss           | 0.00157   |
---------------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 622         |
|    iterations           | 574         |
|    time_elapsed         | 1887        |
|    total_timesteps      | 1175552     |
| train/                  |             |
|    approx_kl            | 0.091731176 |
|    clip_fraction        | 0.321       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.991      |
|    explained_variance   | 0.818       |
|    learning_rate        | 0.00177     |
|    loss                 | -0.0553     |
|    n_updates            | 5730        |
|    policy_gradient_loss | 0.00154     |
|    std                  | 0.424       |
|    value_loss           | 0.00228     |
-----------------------------------------
box reached target
box reached target
box reached target
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 575        |
|    time_elapsed         | 1890       |
|    total_timesteps      | 1177600    |
| train/                  |            |
|    approx_kl            | 0.04777076 |
|    clip_fraction        | 0.324      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1         |
|    explained_variance   | 0.66       |
|    learning_rate        | 0.00177    |
|    loss                 | 0.0482     |
|    n_updates            | 5740       |
|    policy_gradient_loss | 0.00884    |
|    std                  | 0.429      |
|    value_loss           | 0.0436     |
----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 622         |
|    iterations           | 576         |
|    time_elapsed         | 1893        |
|    total_timesteps      | 1179648     |
| train/                  |             |
|    approx_kl            | 0.070672385 |
|    clip_fraction        | 0.344       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.01       |
|    explained_variance   | 0.793       |
|    learning_rate        | 0.00177     |
|    loss                 | -0.023      |
|    n_updates            | 5750        |
|    policy_gradient_loss | 0.00866     |
|    std                  | 0.423       |
|    value_loss           | 0.0506      |
-----------------------------------------
box reached target
Eval num_timesteps=1180000, episode_reward=0.26 +/- 2.52
Episode length: 272.20 +/- 55.60
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 272        |
|    mean_reward          | 0.262      |
| time/                   |            |
|    total_timesteps      | 1180000    |
| train/                  |            |
|    approx_kl            | 0.17894799 |
|    clip_fraction        | 0.246      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.03      |
|    explained_variance   | 0.399      |
|    learning_rate        | 0.00177    |
|    loss                 | -0.0449    |
|    n_updates            | 5760       |
|    policy_gradient_loss | -0.00426   |
|    std                  | 0.422      |
|    value_loss           | 0.0158     |
----------------------------------------
box reached target
--------------------------------
| time/              |         |
|    fps             | 622     |
|    iterations      | 577     |
|    time_elapsed    | 1897    |
|    total_timesteps | 1181696 |
--------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 622       |
|    iterations           | 578       |
|    time_elapsed         | 1900      |
|    total_timesteps      | 1183744   |
| train/                  |           |
|    approx_kl            | 0.1177336 |
|    clip_fraction        | 0.308     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.989    |
|    explained_variance   | 0.703     |
|    learning_rate        | 0.00177   |
|    loss                 | 0.0293    |
|    n_updates            | 5770      |
|    policy_gradient_loss | 0.00264   |
|    std                  | 0.415     |
|    value_loss           | 0.0146    |
---------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 579        |
|    time_elapsed         | 1903       |
|    total_timesteps      | 1185792    |
| train/                  |            |
|    approx_kl            | 0.04646099 |
|    clip_fraction        | 0.275      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.938     |
|    explained_variance   | 0.677      |
|    learning_rate        | 0.00177    |
|    loss                 | -0.00625   |
|    n_updates            | 5780       |
|    policy_gradient_loss | 0.00237    |
|    std                  | 0.41       |
|    value_loss           | 0.0288     |
----------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 622       |
|    iterations           | 580       |
|    time_elapsed         | 1906      |
|    total_timesteps      | 1187840   |
| train/                  |           |
|    approx_kl            | 0.1574342 |
|    clip_fraction        | 0.302     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.931    |
|    explained_variance   | 0.911     |
|    learning_rate        | 0.00177   |
|    loss                 | -0.0358   |
|    n_updates            | 5790      |
|    policy_gradient_loss | -0.00423  |
|    std                  | 0.409     |
|    value_loss           | 0.00704   |
---------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 581        |
|    time_elapsed         | 1910       |
|    total_timesteps      | 1189888    |
| train/                  |            |
|    approx_kl            | 0.07263038 |
|    clip_fraction        | 0.32       |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.963     |
|    explained_variance   | 0.684      |
|    learning_rate        | 0.00177    |
|    loss                 | -0.00865   |
|    n_updates            | 5800       |
|    policy_gradient_loss | 0.00211    |
|    std                  | 0.423      |
|    value_loss           | 0.0192     |
----------------------------------------
box reached target
Eval num_timesteps=1190000, episode_reward=0.42 +/- 2.46
Episode length: 276.40 +/- 47.20
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 276        |
|    mean_reward          | 0.423      |
| time/                   |            |
|    total_timesteps      | 1190000    |
| train/                  |            |
|    approx_kl            | 0.12174575 |
|    clip_fraction        | 0.318      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.996     |
|    explained_variance   | 0.816      |
|    learning_rate        | 0.00177    |
|    loss                 | 0.0172     |
|    n_updates            | 5810       |
|    policy_gradient_loss | -0.00331   |
|    std                  | 0.43       |
|    value_loss           | 0.0128     |
----------------------------------------
box reached target
box reached target
box reached target
box reached target
--------------------------------
| time/              |         |
|    fps             | 622     |
|    iterations      | 582     |
|    time_elapsed    | 1914    |
|    total_timesteps | 1191936 |
--------------------------------
box reached target
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 622         |
|    iterations           | 583         |
|    time_elapsed         | 1917        |
|    total_timesteps      | 1193984     |
| train/                  |             |
|    approx_kl            | 0.043346718 |
|    clip_fraction        | 0.297       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.01       |
|    explained_variance   | 0.919       |
|    learning_rate        | 0.00177     |
|    loss                 | -0.0286     |
|    n_updates            | 5820        |
|    policy_gradient_loss | 0.00835     |
|    std                  | 0.43        |
|    value_loss           | 0.0112      |
-----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 584        |
|    time_elapsed         | 1920       |
|    total_timesteps      | 1196032    |
| train/                  |            |
|    approx_kl            | 0.07951375 |
|    clip_fraction        | 0.301      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.974     |
|    explained_variance   | 0.943      |
|    learning_rate        | 0.00177    |
|    loss                 | -0.0165    |
|    n_updates            | 5830       |
|    policy_gradient_loss | 0.00898    |
|    std                  | 0.423      |
|    value_loss           | 0.00587    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 585        |
|    time_elapsed         | 1923       |
|    total_timesteps      | 1198080    |
| train/                  |            |
|    approx_kl            | 0.07965934 |
|    clip_fraction        | 0.296      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.934     |
|    explained_variance   | 0.902      |
|    learning_rate        | 0.00177    |
|    loss                 | 0.00481    |
|    n_updates            | 5840       |
|    policy_gradient_loss | 0.00352    |
|    std                  | 0.413      |
|    value_loss           | 0.00573    |
----------------------------------------
box reached target
box reached target
box reached target
box reached target
Eval num_timesteps=1200000, episode_reward=1.57 +/- 3.15
Episode length: 273.20 +/- 32.85
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 273         |
|    mean_reward          | 1.57        |
| time/                   |             |
|    total_timesteps      | 1200000     |
| train/                  |             |
|    approx_kl            | 0.114772834 |
|    clip_fraction        | 0.338       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.9        |
|    explained_variance   | 0.55        |
|    learning_rate        | 0.00177     |
|    loss                 | -0.024      |
|    n_updates            | 5850        |
|    policy_gradient_loss | -0.00422    |
|    std                  | 0.401       |
|    value_loss           | 0.00236     |
-----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 622     |
|    iterations      | 586     |
|    time_elapsed    | 1927    |
|    total_timesteps | 1200128 |
--------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 622         |
|    iterations           | 587         |
|    time_elapsed         | 1930        |
|    total_timesteps      | 1202176     |
| train/                  |             |
|    approx_kl            | 0.101727545 |
|    clip_fraction        | 0.36        |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.84       |
|    explained_variance   | 0.707       |
|    learning_rate        | 0.00177     |
|    loss                 | -0.0312     |
|    n_updates            | 5860        |
|    policy_gradient_loss | 0.00821     |
|    std                  | 0.39        |
|    value_loss           | 0.0267      |
-----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 588        |
|    time_elapsed         | 1933       |
|    total_timesteps      | 1204224    |
| train/                  |            |
|    approx_kl            | 0.13320081 |
|    clip_fraction        | 0.348      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.789     |
|    explained_variance   | 0.216      |
|    learning_rate        | 0.00177    |
|    loss                 | 0.00259    |
|    n_updates            | 5870       |
|    policy_gradient_loss | 0.00565    |
|    std                  | 0.382      |
|    value_loss           | 0.00731    |
----------------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 589        |
|    time_elapsed         | 1936       |
|    total_timesteps      | 1206272    |
| train/                  |            |
|    approx_kl            | 0.07672466 |
|    clip_fraction        | 0.285      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.787     |
|    explained_variance   | 0.777      |
|    learning_rate        | 0.00177    |
|    loss                 | -0.00774   |
|    n_updates            | 5880       |
|    policy_gradient_loss | 0.00271    |
|    std                  | 0.387      |
|    value_loss           | 0.0107     |
----------------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 590        |
|    time_elapsed         | 1939       |
|    total_timesteps      | 1208320    |
| train/                  |            |
|    approx_kl            | 0.10766119 |
|    clip_fraction        | 0.32       |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.793     |
|    explained_variance   | 0.832      |
|    learning_rate        | 0.00176    |
|    loss                 | 0.0769     |
|    n_updates            | 5890       |
|    policy_gradient_loss | 0.0075     |
|    std                  | 0.387      |
|    value_loss           | 0.0187     |
----------------------------------------
box reached target
Eval num_timesteps=1210000, episode_reward=0.22 +/- 2.44
Episode length: 271.60 +/- 56.80
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 272       |
|    mean_reward          | 0.222     |
| time/                   |           |
|    total_timesteps      | 1210000   |
| train/                  |           |
|    approx_kl            | 0.1732447 |
|    clip_fraction        | 0.381     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.776    |
|    explained_variance   | 0.902     |
|    learning_rate        | 0.00176   |
|    loss                 | -0.0309   |
|    n_updates            | 5900      |
|    policy_gradient_loss | 0.00981   |
|    std                  | 0.378     |
|    value_loss           | 0.00942   |
---------------------------------------
--------------------------------
| time/              |         |
|    fps             | 622     |
|    iterations      | 591     |
|    time_elapsed    | 1943    |
|    total_timesteps | 1210368 |
--------------------------------
box reached target
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 592        |
|    time_elapsed         | 1946       |
|    total_timesteps      | 1212416    |
| train/                  |            |
|    approx_kl            | 0.14592357 |
|    clip_fraction        | 0.349      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.82      |
|    explained_variance   | 0.495      |
|    learning_rate        | 0.00176    |
|    loss                 | -0.011     |
|    n_updates            | 5910       |
|    policy_gradient_loss | -0.00346   |
|    std                  | 0.397      |
|    value_loss           | 0.00584    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 593        |
|    time_elapsed         | 1949       |
|    total_timesteps      | 1214464    |
| train/                  |            |
|    approx_kl            | 0.06814853 |
|    clip_fraction        | 0.339      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.864     |
|    explained_variance   | 0.934      |
|    learning_rate        | 0.00176    |
|    loss                 | 0.0741     |
|    n_updates            | 5920       |
|    policy_gradient_loss | 0.0047     |
|    std                  | 0.401      |
|    value_loss           | 0.00898    |
----------------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 594        |
|    time_elapsed         | 1953       |
|    total_timesteps      | 1216512    |
| train/                  |            |
|    approx_kl            | 0.07834932 |
|    clip_fraction        | 0.307      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.886     |
|    explained_variance   | 0.656      |
|    learning_rate        | 0.00176    |
|    loss                 | -0.0397    |
|    n_updates            | 5930       |
|    policy_gradient_loss | 0.00247    |
|    std                  | 0.408      |
|    value_loss           | 0.00649    |
----------------------------------------
box reached target
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 622       |
|    iterations           | 595       |
|    time_elapsed         | 1956      |
|    total_timesteps      | 1218560   |
| train/                  |           |
|    approx_kl            | 0.0579055 |
|    clip_fraction        | 0.361     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.912    |
|    explained_variance   | 0.879     |
|    learning_rate        | 0.00176   |
|    loss                 | -0.0138   |
|    n_updates            | 5940      |
|    policy_gradient_loss | 0.00482   |
|    std                  | 0.414     |
|    value_loss           | 0.00891   |
---------------------------------------
box reached target
box reached target
Eval num_timesteps=1220000, episode_reward=0.24 +/- 2.48
Episode length: 276.00 +/- 48.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 276         |
|    mean_reward          | 0.241       |
| time/                   |             |
|    total_timesteps      | 1220000     |
| train/                  |             |
|    approx_kl            | 0.074137434 |
|    clip_fraction        | 0.345       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.931      |
|    explained_variance   | 0.963       |
|    learning_rate        | 0.00176     |
|    loss                 | -0.0128     |
|    n_updates            | 5950        |
|    policy_gradient_loss | 0.00377     |
|    std                  | 0.416       |
|    value_loss           | 0.00437     |
-----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 622     |
|    iterations      | 596     |
|    time_elapsed    | 1960    |
|    total_timesteps | 1220608 |
--------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 622         |
|    iterations           | 597         |
|    time_elapsed         | 1963        |
|    total_timesteps      | 1222656     |
| train/                  |             |
|    approx_kl            | 0.117577605 |
|    clip_fraction        | 0.388       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.917      |
|    explained_variance   | 0.623       |
|    learning_rate        | 0.00176     |
|    loss                 | 0.0567      |
|    n_updates            | 5960        |
|    policy_gradient_loss | 0.00677     |
|    std                  | 0.417       |
|    value_loss           | 0.0203      |
-----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 598        |
|    time_elapsed         | 1966       |
|    total_timesteps      | 1224704    |
| train/                  |            |
|    approx_kl            | 0.13438748 |
|    clip_fraction        | 0.316      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.906     |
|    explained_variance   | 0.655      |
|    learning_rate        | 0.00176    |
|    loss                 | 0.034      |
|    n_updates            | 5970       |
|    policy_gradient_loss | -0.00378   |
|    std                  | 0.414      |
|    value_loss           | 0.00436    |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 599        |
|    time_elapsed         | 1969       |
|    total_timesteps      | 1226752    |
| train/                  |            |
|    approx_kl            | 0.09276027 |
|    clip_fraction        | 0.315      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.943     |
|    explained_variance   | 0.815      |
|    learning_rate        | 0.00176    |
|    loss                 | 0.00564    |
|    n_updates            | 5980       |
|    policy_gradient_loss | 0.0051     |
|    std                  | 0.429      |
|    value_loss           | 0.00366    |
----------------------------------------
box reached target
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 622       |
|    iterations           | 600       |
|    time_elapsed         | 1972      |
|    total_timesteps      | 1228800   |
| train/                  |           |
|    approx_kl            | 0.1333057 |
|    clip_fraction        | 0.34      |
|    clip_range           | 0.2       |
|    entropy_loss         | -1.04     |
|    explained_variance   | 0.896     |
|    learning_rate        | 0.00176   |
|    loss                 | -0.0375   |
|    n_updates            | 5990      |
|    policy_gradient_loss | 0.0047    |
|    std                  | 0.454     |
|    value_loss           | 0.00543   |
---------------------------------------
box reached target
Eval num_timesteps=1230000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1         |
| time/                   |            |
|    total_timesteps      | 1230000    |
| train/                  |            |
|    approx_kl            | 0.07755911 |
|    clip_fraction        | 0.316      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.05      |
|    explained_variance   | 0.943      |
|    learning_rate        | 0.00176    |
|    loss                 | -0.0287    |
|    n_updates            | 6000       |
|    policy_gradient_loss | -0.00421   |
|    std                  | 0.439      |
|    value_loss           | 0.00599    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 622     |
|    iterations      | 601     |
|    time_elapsed    | 1976    |
|    total_timesteps | 1230848 |
--------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 622         |
|    iterations           | 602         |
|    time_elapsed         | 1979        |
|    total_timesteps      | 1232896     |
| train/                  |             |
|    approx_kl            | 0.043664377 |
|    clip_fraction        | 0.27        |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.04       |
|    explained_variance   | 0.91        |
|    learning_rate        | 0.00176     |
|    loss                 | 0.156       |
|    n_updates            | 6010        |
|    policy_gradient_loss | 0.00206     |
|    std                  | 0.443       |
|    value_loss           | 0.00791     |
-----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 603        |
|    time_elapsed         | 1982       |
|    total_timesteps      | 1234944    |
| train/                  |            |
|    approx_kl            | 0.19028017 |
|    clip_fraction        | 0.328      |
|    clip_range           | 0.2        |
|    entropy_loss         | -1         |
|    explained_variance   | 0.528      |
|    learning_rate        | 0.00176    |
|    loss                 | 0.00574    |
|    n_updates            | 6020       |
|    policy_gradient_loss | 0.00396    |
|    std                  | 0.425      |
|    value_loss           | 0.00328    |
----------------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 622         |
|    iterations           | 604         |
|    time_elapsed         | 1985        |
|    total_timesteps      | 1236992     |
| train/                  |             |
|    approx_kl            | 0.112880155 |
|    clip_fraction        | 0.362       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.964      |
|    explained_variance   | 0.302       |
|    learning_rate        | 0.00176     |
|    loss                 | -0.0212     |
|    n_updates            | 6030        |
|    policy_gradient_loss | 0.00738     |
|    std                  | 0.419       |
|    value_loss           | 0.00301     |
-----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 605        |
|    time_elapsed         | 1989       |
|    total_timesteps      | 1239040    |
| train/                  |            |
|    approx_kl            | 0.08382825 |
|    clip_fraction        | 0.296      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.975     |
|    explained_variance   | 0.927      |
|    learning_rate        | 0.00176    |
|    loss                 | -0.021     |
|    n_updates            | 6040       |
|    policy_gradient_loss | -0.00235   |
|    std                  | 0.421      |
|    value_loss           | 0.00406    |
----------------------------------------
Eval num_timesteps=1240000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1         |
| time/                   |            |
|    total_timesteps      | 1240000    |
| train/                  |            |
|    approx_kl            | 0.12223549 |
|    clip_fraction        | 0.273      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.998     |
|    explained_variance   | 0.969      |
|    learning_rate        | 0.00176    |
|    loss                 | 0.0239     |
|    n_updates            | 6050       |
|    policy_gradient_loss | 0.00509    |
|    std                  | 0.427      |
|    value_loss           | 0.00321    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 622     |
|    iterations      | 606     |
|    time_elapsed    | 1993    |
|    total_timesteps | 1241088 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 607        |
|    time_elapsed         | 1996       |
|    total_timesteps      | 1243136    |
| train/                  |            |
|    approx_kl            | 0.11874282 |
|    clip_fraction        | 0.276      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.986     |
|    explained_variance   | 0.243      |
|    learning_rate        | 0.00176    |
|    loss                 | 0.0101     |
|    n_updates            | 6060       |
|    policy_gradient_loss | -3.52e-05  |
|    std                  | 0.417      |
|    value_loss           | 0.00178    |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 608        |
|    time_elapsed         | 1999       |
|    total_timesteps      | 1245184    |
| train/                  |            |
|    approx_kl            | 0.10626245 |
|    clip_fraction        | 0.276      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.998     |
|    explained_variance   | 0.881      |
|    learning_rate        | 0.00176    |
|    loss                 | 0.0299     |
|    n_updates            | 6070       |
|    policy_gradient_loss | 0.00534    |
|    std                  | 0.432      |
|    value_loss           | 0.011      |
----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 622         |
|    iterations           | 609         |
|    time_elapsed         | 2002        |
|    total_timesteps      | 1247232     |
| train/                  |             |
|    approx_kl            | 0.067070164 |
|    clip_fraction        | 0.35        |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.03       |
|    explained_variance   | 0.926       |
|    learning_rate        | 0.00176     |
|    loss                 | -0.012      |
|    n_updates            | 6080        |
|    policy_gradient_loss | 0.00416     |
|    std                  | 0.424       |
|    value_loss           | 0.00288     |
-----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 622       |
|    iterations           | 610       |
|    time_elapsed         | 2005      |
|    total_timesteps      | 1249280   |
| train/                  |           |
|    approx_kl            | 0.0516868 |
|    clip_fraction        | 0.282     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.985    |
|    explained_variance   | 0.468     |
|    learning_rate        | 0.00176   |
|    loss                 | 0.0165    |
|    n_updates            | 6090      |
|    policy_gradient_loss | 0.00212   |
|    std                  | 0.421     |
|    value_loss           | 0.00191   |
---------------------------------------
box reached target
Eval num_timesteps=1250000, episode_reward=0.28 +/- 2.56
Episode length: 282.40 +/- 35.20
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 282       |
|    mean_reward          | 0.281     |
| time/                   |           |
|    total_timesteps      | 1250000   |
| train/                  |           |
|    approx_kl            | 0.3469943 |
|    clip_fraction        | 0.338     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.96     |
|    explained_variance   | 0.548     |
|    learning_rate        | 0.00176   |
|    loss                 | -0.00556  |
|    n_updates            | 6100      |
|    policy_gradient_loss | 0.00477   |
|    std                  | 0.409     |
|    value_loss           | 0.00134   |
---------------------------------------
--------------------------------
| time/              |         |
|    fps             | 622     |
|    iterations      | 611     |
|    time_elapsed    | 2009    |
|    total_timesteps | 1251328 |
--------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 612        |
|    time_elapsed         | 2012       |
|    total_timesteps      | 1253376    |
| train/                  |            |
|    approx_kl            | 0.07156958 |
|    clip_fraction        | 0.311      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.894     |
|    explained_variance   | 0.7        |
|    learning_rate        | 0.00176    |
|    loss                 | 0.0128     |
|    n_updates            | 6110       |
|    policy_gradient_loss | -0.00632   |
|    std                  | 0.404      |
|    value_loss           | 0.00347    |
----------------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 613        |
|    time_elapsed         | 2015       |
|    total_timesteps      | 1255424    |
| train/                  |            |
|    approx_kl            | 0.08176418 |
|    clip_fraction        | 0.322      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.91      |
|    explained_variance   | 0.599      |
|    learning_rate        | 0.00176    |
|    loss                 | -0.0444    |
|    n_updates            | 6120       |
|    policy_gradient_loss | 0.0019     |
|    std                  | 0.402      |
|    value_loss           | 0.02       |
----------------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 614        |
|    time_elapsed         | 2018       |
|    total_timesteps      | 1257472    |
| train/                  |            |
|    approx_kl            | 0.11837603 |
|    clip_fraction        | 0.339      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.881     |
|    explained_variance   | 0.77       |
|    learning_rate        | 0.00176    |
|    loss                 | -0.0354    |
|    n_updates            | 6130       |
|    policy_gradient_loss | 0.0026     |
|    std                  | 0.397      |
|    value_loss           | 0.0105     |
----------------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 615        |
|    time_elapsed         | 2021       |
|    total_timesteps      | 1259520    |
| train/                  |            |
|    approx_kl            | 0.14634681 |
|    clip_fraction        | 0.323      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.843     |
|    explained_variance   | 0.92       |
|    learning_rate        | 0.00175    |
|    loss                 | 0.0509     |
|    n_updates            | 6140       |
|    policy_gradient_loss | 0.00593    |
|    std                  | 0.389      |
|    value_loss           | 0.00558    |
----------------------------------------
box reached target
Eval num_timesteps=1260000, episode_reward=0.23 +/- 2.46
Episode length: 271.40 +/- 57.20
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 271        |
|    mean_reward          | 0.229      |
| time/                   |            |
|    total_timesteps      | 1260000    |
| train/                  |            |
|    approx_kl            | 0.24152894 |
|    clip_fraction        | 0.37       |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.797     |
|    explained_variance   | 0.953      |
|    learning_rate        | 0.00175    |
|    loss                 | -0.029     |
|    n_updates            | 6150       |
|    policy_gradient_loss | 0.000758   |
|    std                  | 0.38       |
|    value_loss           | 0.00321    |
----------------------------------------
box reached target
--------------------------------
| time/              |         |
|    fps             | 622     |
|    iterations      | 616     |
|    time_elapsed    | 2025    |
|    total_timesteps | 1261568 |
--------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 622       |
|    iterations           | 617       |
|    time_elapsed         | 2029      |
|    total_timesteps      | 1263616   |
| train/                  |           |
|    approx_kl            | 0.0899293 |
|    clip_fraction        | 0.327     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.826    |
|    explained_variance   | 0.973     |
|    learning_rate        | 0.00175   |
|    loss                 | -0.0119   |
|    n_updates            | 6160      |
|    policy_gradient_loss | 0.00318   |
|    std                  | 0.393     |
|    value_loss           | 0.00295   |
---------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 622         |
|    iterations           | 618         |
|    time_elapsed         | 2032        |
|    total_timesteps      | 1265664     |
| train/                  |             |
|    approx_kl            | 0.033040434 |
|    clip_fraction        | 0.294       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.895      |
|    explained_variance   | 0.824       |
|    learning_rate        | 0.00175     |
|    loss                 | -0.0155     |
|    n_updates            | 6170        |
|    policy_gradient_loss | 0.000883    |
|    std                  | 0.404       |
|    value_loss           | 0.00729     |
-----------------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 619        |
|    time_elapsed         | 2035       |
|    total_timesteps      | 1267712    |
| train/                  |            |
|    approx_kl            | 0.19404796 |
|    clip_fraction        | 0.379      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.928     |
|    explained_variance   | 0.493      |
|    learning_rate        | 0.00175    |
|    loss                 | -0.0391    |
|    n_updates            | 6180       |
|    policy_gradient_loss | 0.00396    |
|    std                  | 0.398      |
|    value_loss           | 0.00504    |
----------------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 620        |
|    time_elapsed         | 2038       |
|    total_timesteps      | 1269760    |
| train/                  |            |
|    approx_kl            | 0.09676287 |
|    clip_fraction        | 0.324      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.899     |
|    explained_variance   | 0.922      |
|    learning_rate        | 0.00175    |
|    loss                 | 0.0391     |
|    n_updates            | 6190       |
|    policy_gradient_loss | 0.00997    |
|    std                  | 0.396      |
|    value_loss           | 0.00451    |
----------------------------------------
box reached target
box reached target
Eval num_timesteps=1270000, episode_reward=0.55 +/- 2.41
Episode length: 277.60 +/- 44.80
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 278        |
|    mean_reward          | 0.547      |
| time/                   |            |
|    total_timesteps      | 1270000    |
| train/                  |            |
|    approx_kl            | 0.09643236 |
|    clip_fraction        | 0.341      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.853     |
|    explained_variance   | 0.947      |
|    learning_rate        | 0.00175    |
|    loss                 | -0.00962   |
|    n_updates            | 6200       |
|    policy_gradient_loss | 0.000468   |
|    std                  | 0.387      |
|    value_loss           | 0.00413    |
----------------------------------------
box reached target
--------------------------------
| time/              |         |
|    fps             | 622     |
|    iterations      | 621     |
|    time_elapsed    | 2042    |
|    total_timesteps | 1271808 |
--------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 622         |
|    iterations           | 622         |
|    time_elapsed         | 2045        |
|    total_timesteps      | 1273856     |
| train/                  |             |
|    approx_kl            | 0.097186975 |
|    clip_fraction        | 0.38        |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.795      |
|    explained_variance   | 0.913       |
|    learning_rate        | 0.00175     |
|    loss                 | -0.00826    |
|    n_updates            | 6210        |
|    policy_gradient_loss | 0.00906     |
|    std                  | 0.378       |
|    value_loss           | 0.00688     |
-----------------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 623        |
|    time_elapsed         | 2048       |
|    total_timesteps      | 1275904    |
| train/                  |            |
|    approx_kl            | 0.24863882 |
|    clip_fraction        | 0.364      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.809     |
|    explained_variance   | 0.631      |
|    learning_rate        | 0.00175    |
|    loss                 | -0.0043    |
|    n_updates            | 6220       |
|    policy_gradient_loss | 0.0112     |
|    std                  | 0.384      |
|    value_loss           | 0.00157    |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 624        |
|    time_elapsed         | 2051       |
|    total_timesteps      | 1277952    |
| train/                  |            |
|    approx_kl            | 0.05607118 |
|    clip_fraction        | 0.321      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.792     |
|    explained_variance   | 0.911      |
|    learning_rate        | 0.00175    |
|    loss                 | 0.05       |
|    n_updates            | 6230       |
|    policy_gradient_loss | 0.00543    |
|    std                  | 0.378      |
|    value_loss           | 0.00983    |
----------------------------------------
box reached target
Eval num_timesteps=1280000, episode_reward=-0.54 +/- 0.61
Episode length: 300.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 300         |
|    mean_reward          | -0.54       |
| time/                   |             |
|    total_timesteps      | 1280000     |
| train/                  |             |
|    approx_kl            | 0.085566536 |
|    clip_fraction        | 0.328       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.779      |
|    explained_variance   | 0.933       |
|    learning_rate        | 0.00175     |
|    loss                 | 0.0966      |
|    n_updates            | 6240        |
|    policy_gradient_loss | 0.00299     |
|    std                  | 0.377       |
|    value_loss           | 0.0033      |
-----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 622     |
|    iterations      | 625     |
|    time_elapsed    | 2055    |
|    total_timesteps | 1280000 |
--------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 622         |
|    iterations           | 626         |
|    time_elapsed         | 2058        |
|    total_timesteps      | 1282048     |
| train/                  |             |
|    approx_kl            | 0.105814666 |
|    clip_fraction        | 0.328       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.781      |
|    explained_variance   | 0.966       |
|    learning_rate        | 0.00175     |
|    loss                 | -0.000825   |
|    n_updates            | 6250        |
|    policy_gradient_loss | 0.0107      |
|    std                  | 0.378       |
|    value_loss           | 0.00227     |
-----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 627        |
|    time_elapsed         | 2061       |
|    total_timesteps      | 1284096    |
| train/                  |            |
|    approx_kl            | 0.15449318 |
|    clip_fraction        | 0.303      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.784     |
|    explained_variance   | 0.797      |
|    learning_rate        | 0.00175    |
|    loss                 | 0.0155     |
|    n_updates            | 6260       |
|    policy_gradient_loss | 0.00728    |
|    std                  | 0.382      |
|    value_loss           | 0.00325    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 628        |
|    time_elapsed         | 2065       |
|    total_timesteps      | 1286144    |
| train/                  |            |
|    approx_kl            | 0.06445339 |
|    clip_fraction        | 0.3        |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.785     |
|    explained_variance   | 0.964      |
|    learning_rate        | 0.00175    |
|    loss                 | -0.0254    |
|    n_updates            | 6270       |
|    policy_gradient_loss | 0.00154    |
|    std                  | 0.378      |
|    value_loss           | 0.0037     |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 629        |
|    time_elapsed         | 2068       |
|    total_timesteps      | 1288192    |
| train/                  |            |
|    approx_kl            | 0.07495598 |
|    clip_fraction        | 0.324      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.794     |
|    explained_variance   | 0.815      |
|    learning_rate        | 0.00175    |
|    loss                 | -0.0127    |
|    n_updates            | 6280       |
|    policy_gradient_loss | 0.00793    |
|    std                  | 0.379      |
|    value_loss           | 0.00264    |
----------------------------------------
box reached target
box reached target
box reached target
box reached target
Eval num_timesteps=1290000, episode_reward=0.58 +/- 2.50
Episode length: 288.20 +/- 23.60
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 288        |
|    mean_reward          | 0.583      |
| time/                   |            |
|    total_timesteps      | 1290000    |
| train/                  |            |
|    approx_kl            | 0.08126623 |
|    clip_fraction        | 0.343      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.841     |
|    explained_variance   | 0.785      |
|    learning_rate        | 0.00175    |
|    loss                 | 0.0344     |
|    n_updates            | 6290       |
|    policy_gradient_loss | 0.00107    |
|    std                  | 0.384      |
|    value_loss           | 0.00348    |
----------------------------------------
box reached target
--------------------------------
| time/              |         |
|    fps             | 622     |
|    iterations      | 630     |
|    time_elapsed    | 2072    |
|    total_timesteps | 1290240 |
--------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 622         |
|    iterations           | 631         |
|    time_elapsed         | 2075        |
|    total_timesteps      | 1292288     |
| train/                  |             |
|    approx_kl            | 0.074341536 |
|    clip_fraction        | 0.347       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.798      |
|    explained_variance   | 0.886       |
|    learning_rate        | 0.00175     |
|    loss                 | 0.0045      |
|    n_updates            | 6300        |
|    policy_gradient_loss | 0.00574     |
|    std                  | 0.374       |
|    value_loss           | 0.029       |
-----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 632        |
|    time_elapsed         | 2078       |
|    total_timesteps      | 1294336    |
| train/                  |            |
|    approx_kl            | 0.11907773 |
|    clip_fraction        | 0.323      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.759     |
|    explained_variance   | 0.815      |
|    learning_rate        | 0.00175    |
|    loss                 | -0.000787  |
|    n_updates            | 6310       |
|    policy_gradient_loss | 0.00885    |
|    std                  | 0.371      |
|    value_loss           | 0.0156     |
----------------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 633        |
|    time_elapsed         | 2081       |
|    total_timesteps      | 1296384    |
| train/                  |            |
|    approx_kl            | 0.12147607 |
|    clip_fraction        | 0.305      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.733     |
|    explained_variance   | 0.83       |
|    learning_rate        | 0.00175    |
|    loss                 | 0.014      |
|    n_updates            | 6320       |
|    policy_gradient_loss | 0.00707    |
|    std                  | 0.364      |
|    value_loss           | 0.00773    |
----------------------------------------
box reached target
box reached target
box reached target
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 634        |
|    time_elapsed         | 2084       |
|    total_timesteps      | 1298432    |
| train/                  |            |
|    approx_kl            | 0.12671752 |
|    clip_fraction        | 0.345      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.757     |
|    explained_variance   | 0.941      |
|    learning_rate        | 0.00175    |
|    loss                 | -0.0168    |
|    n_updates            | 6330       |
|    policy_gradient_loss | 0.00776    |
|    std                  | 0.372      |
|    value_loss           | 0.00684    |
----------------------------------------
Eval num_timesteps=1300000, episode_reward=-0.80 +/- 0.40
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -0.802     |
| time/                   |            |
|    total_timesteps      | 1300000    |
| train/                  |            |
|    approx_kl            | 0.08191399 |
|    clip_fraction        | 0.349      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.707     |
|    explained_variance   | 0.878      |
|    learning_rate        | 0.00175    |
|    loss                 | -0.0543    |
|    n_updates            | 6340       |
|    policy_gradient_loss | -0.00268   |
|    std                  | 0.355      |
|    value_loss           | 0.0272     |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 622     |
|    iterations      | 635     |
|    time_elapsed    | 2088    |
|    total_timesteps | 1300480 |
--------------------------------
box reached target
box reached target
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 622       |
|    iterations           | 636       |
|    time_elapsed         | 2091      |
|    total_timesteps      | 1302528   |
| train/                  |           |
|    approx_kl            | 0.5050793 |
|    clip_fraction        | 0.417     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.735    |
|    explained_variance   | 0.245     |
|    learning_rate        | 0.00175   |
|    loss                 | 0.00493   |
|    n_updates            | 6350      |
|    policy_gradient_loss | 0.018     |
|    std                  | 0.362     |
|    value_loss           | 0.00222   |
---------------------------------------
box reached target
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 622       |
|    iterations           | 637       |
|    time_elapsed         | 2094      |
|    total_timesteps      | 1304576   |
| train/                  |           |
|    approx_kl            | 0.0972829 |
|    clip_fraction        | 0.33      |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.725    |
|    explained_variance   | 0.89      |
|    learning_rate        | 0.00175   |
|    loss                 | 0.00539   |
|    n_updates            | 6360      |
|    policy_gradient_loss | 0.00127   |
|    std                  | 0.353     |
|    value_loss           | 0.0336    |
---------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 622         |
|    iterations           | 638         |
|    time_elapsed         | 2098        |
|    total_timesteps      | 1306624     |
| train/                  |             |
|    approx_kl            | 0.110877916 |
|    clip_fraction        | 0.361       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.668      |
|    explained_variance   | 0.896       |
|    learning_rate        | 0.00175     |
|    loss                 | -0.00846    |
|    n_updates            | 6370        |
|    policy_gradient_loss | 0.00985     |
|    std                  | 0.344       |
|    value_loss           | 0.0137      |
-----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 639        |
|    time_elapsed         | 2101       |
|    total_timesteps      | 1308672    |
| train/                  |            |
|    approx_kl            | 0.22870332 |
|    clip_fraction        | 0.336      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.67      |
|    explained_variance   | 0.905      |
|    learning_rate        | 0.00175    |
|    loss                 | 0.0143     |
|    n_updates            | 6380       |
|    policy_gradient_loss | -0.00281   |
|    std                  | 0.347      |
|    value_loss           | 0.0021     |
----------------------------------------
box reached target
box reached target
Eval num_timesteps=1310000, episode_reward=0.23 +/- 2.46
Episode length: 272.60 +/- 54.80
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 273        |
|    mean_reward          | 0.228      |
| time/                   |            |
|    total_timesteps      | 1310000    |
| train/                  |            |
|    approx_kl            | 0.08654833 |
|    clip_fraction        | 0.341      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.715     |
|    explained_variance   | 0.924      |
|    learning_rate        | 0.00174    |
|    loss                 | -0.0232    |
|    n_updates            | 6390       |
|    policy_gradient_loss | 0.00916    |
|    std                  | 0.358      |
|    value_loss           | 0.00505    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 622     |
|    iterations      | 640     |
|    time_elapsed    | 2105    |
|    total_timesteps | 1310720 |
--------------------------------
box reached target
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 641        |
|    time_elapsed         | 2108       |
|    total_timesteps      | 1312768    |
| train/                  |            |
|    approx_kl            | 0.12119975 |
|    clip_fraction        | 0.306      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.687     |
|    explained_variance   | 0.863      |
|    learning_rate        | 0.00174    |
|    loss                 | 0.0054     |
|    n_updates            | 6400       |
|    policy_gradient_loss | 0.00354    |
|    std                  | 0.349      |
|    value_loss           | 0.00707    |
----------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 622       |
|    iterations           | 642       |
|    time_elapsed         | 2111      |
|    total_timesteps      | 1314816   |
| train/                  |           |
|    approx_kl            | 0.5208797 |
|    clip_fraction        | 0.379     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.72     |
|    explained_variance   | 0.976     |
|    learning_rate        | 0.00174   |
|    loss                 | -0.0241   |
|    n_updates            | 6410      |
|    policy_gradient_loss | 0.0129    |
|    std                  | 0.355     |
|    value_loss           | 0.00308   |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 643        |
|    time_elapsed         | 2114       |
|    total_timesteps      | 1316864    |
| train/                  |            |
|    approx_kl            | 0.12788147 |
|    clip_fraction        | 0.351      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.659     |
|    explained_variance   | 0.98       |
|    learning_rate        | 0.00174    |
|    loss                 | -0.0283    |
|    n_updates            | 6420       |
|    policy_gradient_loss | -0.00316   |
|    std                  | 0.343      |
|    value_loss           | 0.00136    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 644        |
|    time_elapsed         | 2117       |
|    total_timesteps      | 1318912    |
| train/                  |            |
|    approx_kl            | 0.09750069 |
|    clip_fraction        | 0.294      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.631     |
|    explained_variance   | 0.498      |
|    learning_rate        | 0.00174    |
|    loss                 | -0.00714   |
|    n_updates            | 6430       |
|    policy_gradient_loss | 0.0117     |
|    std                  | 0.34       |
|    value_loss           | 0.000971   |
----------------------------------------
Eval num_timesteps=1320000, episode_reward=-0.70 +/- 0.60
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -0.699     |
| time/                   |            |
|    total_timesteps      | 1320000    |
| train/                  |            |
|    approx_kl            | 0.07727694 |
|    clip_fraction        | 0.326      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.596     |
|    explained_variance   | 0.385      |
|    learning_rate        | 0.00174    |
|    loss                 | 0.0098     |
|    n_updates            | 6440       |
|    policy_gradient_loss | 0.0082     |
|    std                  | 0.338      |
|    value_loss           | 0.00244    |
----------------------------------------
box reached target
--------------------------------
| time/              |         |
|    fps             | 622     |
|    iterations      | 645     |
|    time_elapsed    | 2121    |
|    total_timesteps | 1320960 |
--------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 646        |
|    time_elapsed         | 2124       |
|    total_timesteps      | 1323008    |
| train/                  |            |
|    approx_kl            | 0.11703238 |
|    clip_fraction        | 0.34       |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.626     |
|    explained_variance   | 0.945      |
|    learning_rate        | 0.00174    |
|    loss                 | 0.0448     |
|    n_updates            | 6450       |
|    policy_gradient_loss | 0.00317    |
|    std                  | 0.343      |
|    value_loss           | 0.0049     |
----------------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 647        |
|    time_elapsed         | 2127       |
|    total_timesteps      | 1325056    |
| train/                  |            |
|    approx_kl            | 0.22845943 |
|    clip_fraction        | 0.409      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.64      |
|    explained_variance   | 0.899      |
|    learning_rate        | 0.00174    |
|    loss                 | -0.0039    |
|    n_updates            | 6460       |
|    policy_gradient_loss | 0.00764    |
|    std                  | 0.342      |
|    value_loss           | 0.00644    |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 648        |
|    time_elapsed         | 2130       |
|    total_timesteps      | 1327104    |
| train/                  |            |
|    approx_kl            | 0.08035432 |
|    clip_fraction        | 0.346      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.581     |
|    explained_variance   | 0.824      |
|    learning_rate        | 0.00174    |
|    loss                 | 0.00136    |
|    n_updates            | 6470       |
|    policy_gradient_loss | 0.0148     |
|    std                  | 0.328      |
|    value_loss           | 0.0124     |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 649        |
|    time_elapsed         | 2134       |
|    total_timesteps      | 1329152    |
| train/                  |            |
|    approx_kl            | 0.07916796 |
|    clip_fraction        | 0.295      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.541     |
|    explained_variance   | 0.92       |
|    learning_rate        | 0.00174    |
|    loss                 | -0.0169    |
|    n_updates            | 6480       |
|    policy_gradient_loss | 0.00652    |
|    std                  | 0.323      |
|    value_loss           | 0.00618    |
----------------------------------------
Eval num_timesteps=1330000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1         |
| time/                   |            |
|    total_timesteps      | 1330000    |
| train/                  |            |
|    approx_kl            | 0.15011713 |
|    clip_fraction        | 0.32       |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.556     |
|    explained_variance   | 0.114      |
|    learning_rate        | 0.00174    |
|    loss                 | 0.0149     |
|    n_updates            | 6490       |
|    policy_gradient_loss | 0.0152     |
|    std                  | 0.324      |
|    value_loss           | 0.0023     |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 622     |
|    iterations      | 650     |
|    time_elapsed    | 2138    |
|    total_timesteps | 1331200 |
--------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 651        |
|    time_elapsed         | 2141       |
|    total_timesteps      | 1333248    |
| train/                  |            |
|    approx_kl            | 0.04596846 |
|    clip_fraction        | 0.298      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.525     |
|    explained_variance   | 0.592      |
|    learning_rate        | 0.00174    |
|    loss                 | -0.0113    |
|    n_updates            | 6500       |
|    policy_gradient_loss | 0.00385    |
|    std                  | 0.318      |
|    value_loss           | 0.00485    |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 652        |
|    time_elapsed         | 2144       |
|    total_timesteps      | 1335296    |
| train/                  |            |
|    approx_kl            | 0.08662351 |
|    clip_fraction        | 0.371      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.571     |
|    explained_variance   | 0.941      |
|    learning_rate        | 0.00174    |
|    loss                 | -0.0152    |
|    n_updates            | 6510       |
|    policy_gradient_loss | -0.00292   |
|    std                  | 0.334      |
|    value_loss           | 0.0054     |
----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 622       |
|    iterations           | 653       |
|    time_elapsed         | 2147      |
|    total_timesteps      | 1337344   |
| train/                  |           |
|    approx_kl            | 0.0956202 |
|    clip_fraction        | 0.317     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.568    |
|    explained_variance   | 0.961     |
|    learning_rate        | 0.00174   |
|    loss                 | 0.0425    |
|    n_updates            | 6520      |
|    policy_gradient_loss | 0.000367  |
|    std                  | 0.325     |
|    value_loss           | 0.00209   |
---------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 654        |
|    time_elapsed         | 2150       |
|    total_timesteps      | 1339392    |
| train/                  |            |
|    approx_kl            | 0.08732852 |
|    clip_fraction        | 0.333      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.533     |
|    explained_variance   | 0.748      |
|    learning_rate        | 0.00174    |
|    loss                 | 0.0124     |
|    n_updates            | 6530       |
|    policy_gradient_loss | -0.00628   |
|    std                  | 0.322      |
|    value_loss           | 0.00227    |
----------------------------------------
box reached target
Eval num_timesteps=1340000, episode_reward=0.25 +/- 2.49
Episode length: 271.40 +/- 57.20
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 271        |
|    mean_reward          | 0.245      |
| time/                   |            |
|    total_timesteps      | 1340000    |
| train/                  |            |
|    approx_kl            | 0.13262108 |
|    clip_fraction        | 0.367      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.57      |
|    explained_variance   | 0.958      |
|    learning_rate        | 0.00174    |
|    loss                 | -0.0182    |
|    n_updates            | 6540       |
|    policy_gradient_loss | 0.00294    |
|    std                  | 0.327      |
|    value_loss           | 0.00293    |
----------------------------------------
box reached target
--------------------------------
| time/              |         |
|    fps             | 622     |
|    iterations      | 655     |
|    time_elapsed    | 2154    |
|    total_timesteps | 1341440 |
--------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 656        |
|    time_elapsed         | 2157       |
|    total_timesteps      | 1343488    |
| train/                  |            |
|    approx_kl            | 0.36106646 |
|    clip_fraction        | 0.415      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.532     |
|    explained_variance   | 0.748      |
|    learning_rate        | 0.00174    |
|    loss                 | -0.0194    |
|    n_updates            | 6550       |
|    policy_gradient_loss | 0.00575    |
|    std                  | 0.319      |
|    value_loss           | 0.0227     |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 657        |
|    time_elapsed         | 2160       |
|    total_timesteps      | 1345536    |
| train/                  |            |
|    approx_kl            | 0.12619698 |
|    clip_fraction        | 0.375      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.516     |
|    explained_variance   | 0.388      |
|    learning_rate        | 0.00174    |
|    loss                 | -0.023     |
|    n_updates            | 6560       |
|    policy_gradient_loss | 0.0147     |
|    std                  | 0.317      |
|    value_loss           | 0.0144     |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 658        |
|    time_elapsed         | 2163       |
|    total_timesteps      | 1347584    |
| train/                  |            |
|    approx_kl            | 0.20375907 |
|    clip_fraction        | 0.387      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.453     |
|    explained_variance   | 0.629      |
|    learning_rate        | 0.00174    |
|    loss                 | -0.0289    |
|    n_updates            | 6570       |
|    policy_gradient_loss | 0.0246     |
|    std                  | 0.307      |
|    value_loss           | 0.00839    |
----------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 622       |
|    iterations           | 659       |
|    time_elapsed         | 2167      |
|    total_timesteps      | 1349632   |
| train/                  |           |
|    approx_kl            | 0.1537521 |
|    clip_fraction        | 0.347     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.475    |
|    explained_variance   | 0.648     |
|    learning_rate        | 0.00174   |
|    loss                 | 0.0186    |
|    n_updates            | 6580      |
|    policy_gradient_loss | 0.0104    |
|    std                  | 0.314     |
|    value_loss           | 0.00173   |
---------------------------------------
Eval num_timesteps=1350000, episode_reward=-0.73 +/- 0.54
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -0.732     |
| time/                   |            |
|    total_timesteps      | 1350000    |
| train/                  |            |
|    approx_kl            | 0.09703067 |
|    clip_fraction        | 0.327      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.495     |
|    explained_variance   | 0.902      |
|    learning_rate        | 0.00174    |
|    loss                 | -0.0148    |
|    n_updates            | 6590       |
|    policy_gradient_loss | 0.00584    |
|    std                  | 0.311      |
|    value_loss           | 0.00206    |
----------------------------------------
box reached target
--------------------------------
| time/              |         |
|    fps             | 622     |
|    iterations      | 660     |
|    time_elapsed    | 2171    |
|    total_timesteps | 1351680 |
--------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 661        |
|    time_elapsed         | 2174       |
|    total_timesteps      | 1353728    |
| train/                  |            |
|    approx_kl            | 0.11413445 |
|    clip_fraction        | 0.382      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.478     |
|    explained_variance   | 0.851      |
|    learning_rate        | 0.00174    |
|    loss                 | 0.0556     |
|    n_updates            | 6600       |
|    policy_gradient_loss | 0.0109     |
|    std                  | 0.312      |
|    value_loss           | 0.00978    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 662        |
|    time_elapsed         | 2177       |
|    total_timesteps      | 1355776    |
| train/                  |            |
|    approx_kl            | 0.08801417 |
|    clip_fraction        | 0.333      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.504     |
|    explained_variance   | 0.488      |
|    learning_rate        | 0.00174    |
|    loss                 | 0.0355     |
|    n_updates            | 6610       |
|    policy_gradient_loss | 0.01       |
|    std                  | 0.309      |
|    value_loss           | 0.0087     |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 663        |
|    time_elapsed         | 2180       |
|    total_timesteps      | 1357824    |
| train/                  |            |
|    approx_kl            | 0.35942262 |
|    clip_fraction        | 0.356      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.499     |
|    explained_variance   | 0.82       |
|    learning_rate        | 0.00174    |
|    loss                 | 0.0487     |
|    n_updates            | 6620       |
|    policy_gradient_loss | 0.0151     |
|    std                  | 0.318      |
|    value_loss           | 0.00251    |
----------------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 664        |
|    time_elapsed         | 2183       |
|    total_timesteps      | 1359872    |
| train/                  |            |
|    approx_kl            | 0.19764483 |
|    clip_fraction        | 0.414      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.51      |
|    explained_variance   | 0.579      |
|    learning_rate        | 0.00174    |
|    loss                 | -0.0347    |
|    n_updates            | 6630       |
|    policy_gradient_loss | -0.00117   |
|    std                  | 0.31       |
|    value_loss           | 0.0207     |
----------------------------------------
box reached target
Eval num_timesteps=1360000, episode_reward=0.50 +/- 2.41
Episode length: 268.40 +/- 63.20
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 268         |
|    mean_reward          | 0.503       |
| time/                   |             |
|    total_timesteps      | 1360000     |
| train/                  |             |
|    approx_kl            | 0.054153793 |
|    clip_fraction        | 0.348       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.522      |
|    explained_variance   | 0.733       |
|    learning_rate        | 0.00173     |
|    loss                 | -0.0177     |
|    n_updates            | 6640        |
|    policy_gradient_loss | 0.0187      |
|    std                  | 0.321       |
|    value_loss           | 0.00721     |
-----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 622     |
|    iterations      | 665     |
|    time_elapsed    | 2187    |
|    total_timesteps | 1361920 |
--------------------------------
box reached target
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 666        |
|    time_elapsed         | 2190       |
|    total_timesteps      | 1363968    |
| train/                  |            |
|    approx_kl            | 0.10371095 |
|    clip_fraction        | 0.361      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.557     |
|    explained_variance   | 0.666      |
|    learning_rate        | 0.00173    |
|    loss                 | -0.0247    |
|    n_updates            | 6650       |
|    policy_gradient_loss | -0.000502  |
|    std                  | 0.321      |
|    value_loss           | 0.00129    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 667        |
|    time_elapsed         | 2193       |
|    total_timesteps      | 1366016    |
| train/                  |            |
|    approx_kl            | 0.09174913 |
|    clip_fraction        | 0.356      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.497     |
|    explained_variance   | 0.79       |
|    learning_rate        | 0.00173    |
|    loss                 | 0.00906    |
|    n_updates            | 6660       |
|    policy_gradient_loss | 0.0016     |
|    std                  | 0.311      |
|    value_loss           | 0.0114     |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 668        |
|    time_elapsed         | 2196       |
|    total_timesteps      | 1368064    |
| train/                  |            |
|    approx_kl            | 0.10718089 |
|    clip_fraction        | 0.335      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.462     |
|    explained_variance   | 0.682      |
|    learning_rate        | 0.00173    |
|    loss                 | -0.0471    |
|    n_updates            | 6670       |
|    policy_gradient_loss | 0.00905    |
|    std                  | 0.304      |
|    value_loss           | 0.00137    |
----------------------------------------
Eval num_timesteps=1370000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1         |
| time/                   |            |
|    total_timesteps      | 1370000    |
| train/                  |            |
|    approx_kl            | 0.17794278 |
|    clip_fraction        | 0.4        |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.451     |
|    explained_variance   | 0.921      |
|    learning_rate        | 0.00173    |
|    loss                 | 0.00403    |
|    n_updates            | 6680       |
|    policy_gradient_loss | 0.0097     |
|    std                  | 0.308      |
|    value_loss           | 0.00206    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 622     |
|    iterations      | 669     |
|    time_elapsed    | 2200    |
|    total_timesteps | 1370112 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 670        |
|    time_elapsed         | 2203       |
|    total_timesteps      | 1372160    |
| train/                  |            |
|    approx_kl            | 0.22142008 |
|    clip_fraction        | 0.383      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.456     |
|    explained_variance   | 0.615      |
|    learning_rate        | 0.00173    |
|    loss                 | -0.0314    |
|    n_updates            | 6690       |
|    policy_gradient_loss | 0.00426    |
|    std                  | 0.304      |
|    value_loss           | 0.00283    |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 671        |
|    time_elapsed         | 2207       |
|    total_timesteps      | 1374208    |
| train/                  |            |
|    approx_kl            | 0.09424277 |
|    clip_fraction        | 0.372      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.539     |
|    explained_variance   | 0.417      |
|    learning_rate        | 0.00173    |
|    loss                 | 0.0246     |
|    n_updates            | 6700       |
|    policy_gradient_loss | -0.00384   |
|    std                  | 0.325      |
|    value_loss           | 0.00808    |
----------------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 672        |
|    time_elapsed         | 2210       |
|    total_timesteps      | 1376256    |
| train/                  |            |
|    approx_kl            | 0.14485529 |
|    clip_fraction        | 0.41       |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.534     |
|    explained_variance   | 0.688      |
|    learning_rate        | 0.00173    |
|    loss                 | 0.0379     |
|    n_updates            | 6710       |
|    policy_gradient_loss | 0.0012     |
|    std                  | 0.313      |
|    value_loss           | 0.0177     |
----------------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 622         |
|    iterations           | 673         |
|    time_elapsed         | 2213        |
|    total_timesteps      | 1378304     |
| train/                  |             |
|    approx_kl            | 0.085089274 |
|    clip_fraction        | 0.319       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.612      |
|    explained_variance   | 0.784       |
|    learning_rate        | 0.00173     |
|    loss                 | 0.049       |
|    n_updates            | 6720        |
|    policy_gradient_loss | 0.0056      |
|    std                  | 0.335       |
|    value_loss           | 0.0383      |
-----------------------------------------
box reached target
box reached target
Eval num_timesteps=1380000, episode_reward=-0.68 +/- 0.65
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -0.676     |
| time/                   |            |
|    total_timesteps      | 1380000    |
| train/                  |            |
|    approx_kl            | 0.07178043 |
|    clip_fraction        | 0.323      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.682     |
|    explained_variance   | 0.85       |
|    learning_rate        | 0.00173    |
|    loss                 | 0.0328     |
|    n_updates            | 6730       |
|    policy_gradient_loss | 0.00569    |
|    std                  | 0.345      |
|    value_loss           | 0.0136     |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 622     |
|    iterations      | 674     |
|    time_elapsed    | 2217    |
|    total_timesteps | 1380352 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 675        |
|    time_elapsed         | 2220       |
|    total_timesteps      | 1382400    |
| train/                  |            |
|    approx_kl            | 0.07474683 |
|    clip_fraction        | 0.357      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.716     |
|    explained_variance   | 0.708      |
|    learning_rate        | 0.00173    |
|    loss                 | 0.013      |
|    n_updates            | 6740       |
|    policy_gradient_loss | 0.00369    |
|    std                  | 0.347      |
|    value_loss           | 0.0261     |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 676        |
|    time_elapsed         | 2223       |
|    total_timesteps      | 1384448    |
| train/                  |            |
|    approx_kl            | 0.07655661 |
|    clip_fraction        | 0.318      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.733     |
|    explained_variance   | 0.709      |
|    learning_rate        | 0.00173    |
|    loss                 | 0.0243     |
|    n_updates            | 6750       |
|    policy_gradient_loss | -0.00195   |
|    std                  | 0.35       |
|    value_loss           | 0.00496    |
----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 622         |
|    iterations           | 677         |
|    time_elapsed         | 2226        |
|    total_timesteps      | 1386496     |
| train/                  |             |
|    approx_kl            | 0.110695906 |
|    clip_fraction        | 0.298       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.734      |
|    explained_variance   | 0.604       |
|    learning_rate        | 0.00173     |
|    loss                 | 0.00819     |
|    n_updates            | 6760        |
|    policy_gradient_loss | 0.0149      |
|    std                  | 0.351       |
|    value_loss           | 0.00158     |
-----------------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 678        |
|    time_elapsed         | 2229       |
|    total_timesteps      | 1388544    |
| train/                  |            |
|    approx_kl            | 0.12567261 |
|    clip_fraction        | 0.318      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.776     |
|    explained_variance   | 0.181      |
|    learning_rate        | 0.00173    |
|    loss                 | -0.0296    |
|    n_updates            | 6770       |
|    policy_gradient_loss | 0.00401    |
|    std                  | 0.363      |
|    value_loss           | 0.00237    |
----------------------------------------
box reached target
box reached target
box reached target
Eval num_timesteps=1390000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1         |
| time/                   |            |
|    total_timesteps      | 1390000    |
| train/                  |            |
|    approx_kl            | 0.19021834 |
|    clip_fraction        | 0.397      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.763     |
|    explained_variance   | 0.841      |
|    learning_rate        | 0.00173    |
|    loss                 | 0.0622     |
|    n_updates            | 6780       |
|    policy_gradient_loss | -0.00133   |
|    std                  | 0.351      |
|    value_loss           | 0.00581    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 622     |
|    iterations      | 679     |
|    time_elapsed    | 2233    |
|    total_timesteps | 1390592 |
--------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 680        |
|    time_elapsed         | 2236       |
|    total_timesteps      | 1392640    |
| train/                  |            |
|    approx_kl            | 0.15175474 |
|    clip_fraction        | 0.379      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.748     |
|    explained_variance   | 0.798      |
|    learning_rate        | 0.00173    |
|    loss                 | 0.00221    |
|    n_updates            | 6790       |
|    policy_gradient_loss | 0.00501    |
|    std                  | 0.35       |
|    value_loss           | 0.0174     |
----------------------------------------
box reached target
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 681        |
|    time_elapsed         | 2240       |
|    total_timesteps      | 1394688    |
| train/                  |            |
|    approx_kl            | 0.17333677 |
|    clip_fraction        | 0.428      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.788     |
|    explained_variance   | 0.777      |
|    learning_rate        | 0.00173    |
|    loss                 | 0.255      |
|    n_updates            | 6800       |
|    policy_gradient_loss | 0.016      |
|    std                  | 0.36       |
|    value_loss           | 0.0204     |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 682        |
|    time_elapsed         | 2243       |
|    total_timesteps      | 1396736    |
| train/                  |            |
|    approx_kl            | 0.08302295 |
|    clip_fraction        | 0.347      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.803     |
|    explained_variance   | 0.892      |
|    learning_rate        | 0.00173    |
|    loss                 | 0.0364     |
|    n_updates            | 6810       |
|    policy_gradient_loss | 0.0106     |
|    std                  | 0.361      |
|    value_loss           | 0.0225     |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 683        |
|    time_elapsed         | 2246       |
|    total_timesteps      | 1398784    |
| train/                  |            |
|    approx_kl            | 0.11481006 |
|    clip_fraction        | 0.331      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.803     |
|    explained_variance   | 0.922      |
|    learning_rate        | 0.00173    |
|    loss                 | -0.022     |
|    n_updates            | 6820       |
|    policy_gradient_loss | -0.00598   |
|    std                  | 0.36       |
|    value_loss           | 0.00365    |
----------------------------------------
box reached target
box reached target
Eval num_timesteps=1400000, episode_reward=0.58 +/- 2.37
Episode length: 280.20 +/- 39.60
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 280        |
|    mean_reward          | 0.583      |
| time/                   |            |
|    total_timesteps      | 1400000    |
| train/                  |            |
|    approx_kl            | 0.30228463 |
|    clip_fraction        | 0.34       |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.79      |
|    explained_variance   | 0.813      |
|    learning_rate        | 0.00173    |
|    loss                 | -0.0241    |
|    n_updates            | 6830       |
|    policy_gradient_loss | 0.00183    |
|    std                  | 0.355      |
|    value_loss           | 0.00846    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 622     |
|    iterations      | 684     |
|    time_elapsed    | 2250    |
|    total_timesteps | 1400832 |
--------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 622         |
|    iterations           | 685         |
|    time_elapsed         | 2253        |
|    total_timesteps      | 1402880     |
| train/                  |             |
|    approx_kl            | 0.072986975 |
|    clip_fraction        | 0.361       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.791      |
|    explained_variance   | 0.631       |
|    learning_rate        | 0.00173     |
|    loss                 | -0.0141     |
|    n_updates            | 6840        |
|    policy_gradient_loss | 0.0137      |
|    std                  | 0.362       |
|    value_loss           | 0.012       |
-----------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 622       |
|    iterations           | 686       |
|    time_elapsed         | 2256      |
|    total_timesteps      | 1404928   |
| train/                  |           |
|    approx_kl            | 0.0985579 |
|    clip_fraction        | 0.369     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.863    |
|    explained_variance   | 0.35      |
|    learning_rate        | 0.00173   |
|    loss                 | -0.0221   |
|    n_updates            | 6850      |
|    policy_gradient_loss | 0.00342   |
|    std                  | 0.372     |
|    value_loss           | 0.00286   |
---------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 687        |
|    time_elapsed         | 2259       |
|    total_timesteps      | 1406976    |
| train/                  |            |
|    approx_kl            | 0.11691362 |
|    clip_fraction        | 0.38       |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.866     |
|    explained_variance   | 0.819      |
|    learning_rate        | 0.00173    |
|    loss                 | 0.00277    |
|    n_updates            | 6860       |
|    policy_gradient_loss | 0.0107     |
|    std                  | 0.371      |
|    value_loss           | 0.00562    |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 688        |
|    time_elapsed         | 2262       |
|    total_timesteps      | 1409024    |
| train/                  |            |
|    approx_kl            | 0.13291141 |
|    clip_fraction        | 0.341      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.84      |
|    explained_variance   | 0.816      |
|    learning_rate        | 0.00173    |
|    loss                 | -0.00633   |
|    n_updates            | 6870       |
|    policy_gradient_loss | -0.00294   |
|    std                  | 0.364      |
|    value_loss           | 0.00573    |
----------------------------------------
Eval num_timesteps=1410000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1         |
| time/                   |            |
|    total_timesteps      | 1410000    |
| train/                  |            |
|    approx_kl            | 0.28923988 |
|    clip_fraction        | 0.342      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.781     |
|    explained_variance   | 0.556      |
|    learning_rate        | 0.00173    |
|    loss                 | -0.0131    |
|    n_updates            | 6880       |
|    policy_gradient_loss | 0.0104     |
|    std                  | 0.349      |
|    value_loss           | 0.014      |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 622     |
|    iterations      | 689     |
|    time_elapsed    | 2266    |
|    total_timesteps | 1411072 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 690        |
|    time_elapsed         | 2269       |
|    total_timesteps      | 1413120    |
| train/                  |            |
|    approx_kl            | 0.07734751 |
|    clip_fraction        | 0.32       |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.746     |
|    explained_variance   | 0.19       |
|    learning_rate        | 0.00172    |
|    loss                 | -0.00267   |
|    n_updates            | 6890       |
|    policy_gradient_loss | 0.00479    |
|    std                  | 0.348      |
|    value_loss           | 0.00253    |
----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 622         |
|    iterations           | 691         |
|    time_elapsed         | 2273        |
|    total_timesteps      | 1415168     |
| train/                  |             |
|    approx_kl            | 0.093935765 |
|    clip_fraction        | 0.287       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.718      |
|    explained_variance   | 0.318       |
|    learning_rate        | 0.00172     |
|    loss                 | 0.0289      |
|    n_updates            | 6900        |
|    policy_gradient_loss | -0.00505    |
|    std                  | 0.343       |
|    value_loss           | 0.00125     |
-----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 692        |
|    time_elapsed         | 2276       |
|    total_timesteps      | 1417216    |
| train/                  |            |
|    approx_kl            | 0.13926816 |
|    clip_fraction        | 0.296      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.679     |
|    explained_variance   | 0.0754     |
|    learning_rate        | 0.00172    |
|    loss                 | -0.0197    |
|    n_updates            | 6910       |
|    policy_gradient_loss | 0.0046     |
|    std                  | 0.338      |
|    value_loss           | 0.00119    |
----------------------------------------
box reached target
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 622         |
|    iterations           | 693         |
|    time_elapsed         | 2279        |
|    total_timesteps      | 1419264     |
| train/                  |             |
|    approx_kl            | 0.060499825 |
|    clip_fraction        | 0.342       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.685      |
|    explained_variance   | 0.839       |
|    learning_rate        | 0.00172     |
|    loss                 | 0.0513      |
|    n_updates            | 6920        |
|    policy_gradient_loss | 0.00936     |
|    std                  | 0.342       |
|    value_loss           | 0.0104      |
-----------------------------------------
box reached target
Eval num_timesteps=1420000, episode_reward=-0.76 +/- 0.47
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -0.763     |
| time/                   |            |
|    total_timesteps      | 1420000    |
| train/                  |            |
|    approx_kl            | 0.07930175 |
|    clip_fraction        | 0.304      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.706     |
|    explained_variance   | 0.61       |
|    learning_rate        | 0.00172    |
|    loss                 | -0.0271    |
|    n_updates            | 6930       |
|    policy_gradient_loss | 0.00282    |
|    std                  | 0.35       |
|    value_loss           | 0.0145     |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 622     |
|    iterations      | 694     |
|    time_elapsed    | 2283    |
|    total_timesteps | 1421312 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 695        |
|    time_elapsed         | 2286       |
|    total_timesteps      | 1423360    |
| train/                  |            |
|    approx_kl            | 0.09216127 |
|    clip_fraction        | 0.371      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.743     |
|    explained_variance   | 0.66       |
|    learning_rate        | 0.00172    |
|    loss                 | -0.00883   |
|    n_updates            | 6940       |
|    policy_gradient_loss | 0.00933    |
|    std                  | 0.348      |
|    value_loss           | 0.0123     |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 696        |
|    time_elapsed         | 2289       |
|    total_timesteps      | 1425408    |
| train/                  |            |
|    approx_kl            | 0.16886836 |
|    clip_fraction        | 0.373      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.749     |
|    explained_variance   | 0.437      |
|    learning_rate        | 0.00172    |
|    loss                 | 0.0568     |
|    n_updates            | 6950       |
|    policy_gradient_loss | 0.00334    |
|    std                  | 0.35       |
|    value_loss           | 0.00261    |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 697        |
|    time_elapsed         | 2292       |
|    total_timesteps      | 1427456    |
| train/                  |            |
|    approx_kl            | 0.56170374 |
|    clip_fraction        | 0.4        |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.711     |
|    explained_variance   | 0.837      |
|    learning_rate        | 0.00172    |
|    loss                 | -0.057     |
|    n_updates            | 6960       |
|    policy_gradient_loss | -0.0167    |
|    std                  | 0.337      |
|    value_loss           | 0.00927    |
----------------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 698        |
|    time_elapsed         | 2295       |
|    total_timesteps      | 1429504    |
| train/                  |            |
|    approx_kl            | 0.07963866 |
|    clip_fraction        | 0.37       |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.645     |
|    explained_variance   | 0.802      |
|    learning_rate        | 0.00172    |
|    loss                 | 0.0242     |
|    n_updates            | 6970       |
|    policy_gradient_loss | 0.0223     |
|    std                  | 0.334      |
|    value_loss           | 0.00797    |
----------------------------------------
box reached target
Eval num_timesteps=1430000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1         |
| time/                   |            |
|    total_timesteps      | 1430000    |
| train/                  |            |
|    approx_kl            | 0.05332844 |
|    clip_fraction        | 0.336      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.601     |
|    explained_variance   | 0.793      |
|    learning_rate        | 0.00172    |
|    loss                 | -0.00759   |
|    n_updates            | 6980       |
|    policy_gradient_loss | 0.00697    |
|    std                  | 0.324      |
|    value_loss           | 0.0151     |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 622     |
|    iterations      | 699     |
|    time_elapsed    | 2299    |
|    total_timesteps | 1431552 |
--------------------------------
box reached target
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 622         |
|    iterations           | 700         |
|    time_elapsed         | 2302        |
|    total_timesteps      | 1433600     |
| train/                  |             |
|    approx_kl            | 0.101200715 |
|    clip_fraction        | 0.37        |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.612      |
|    explained_variance   | 0.903       |
|    learning_rate        | 0.00172     |
|    loss                 | 0.0274      |
|    n_updates            | 6990        |
|    policy_gradient_loss | 0.0128      |
|    std                  | 0.329       |
|    value_loss           | 0.0084      |
-----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 701        |
|    time_elapsed         | 2306       |
|    total_timesteps      | 1435648    |
| train/                  |            |
|    approx_kl            | 0.07572499 |
|    clip_fraction        | 0.35       |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.605     |
|    explained_variance   | 0.972      |
|    learning_rate        | 0.00172    |
|    loss                 | 0.0102     |
|    n_updates            | 7000       |
|    policy_gradient_loss | 0.0109     |
|    std                  | 0.323      |
|    value_loss           | 0.00491    |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 702        |
|    time_elapsed         | 2309       |
|    total_timesteps      | 1437696    |
| train/                  |            |
|    approx_kl            | 0.09420003 |
|    clip_fraction        | 0.328      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.568     |
|    explained_variance   | 0.768      |
|    learning_rate        | 0.00172    |
|    loss                 | -0.00303   |
|    n_updates            | 7010       |
|    policy_gradient_loss | 0.0104     |
|    std                  | 0.321      |
|    value_loss           | 0.0127     |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 703        |
|    time_elapsed         | 2312       |
|    total_timesteps      | 1439744    |
| train/                  |            |
|    approx_kl            | 0.17017347 |
|    clip_fraction        | 0.369      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.528     |
|    explained_variance   | 0.885      |
|    learning_rate        | 0.00172    |
|    loss                 | 0.0725     |
|    n_updates            | 7020       |
|    policy_gradient_loss | 0.00874    |
|    std                  | 0.314      |
|    value_loss           | 0.00393    |
----------------------------------------
box reached target
box reached target
Eval num_timesteps=1440000, episode_reward=1.62 +/- 2.92
Episode length: 245.80 +/- 66.71
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 246        |
|    mean_reward          | 1.62       |
| time/                   |            |
|    total_timesteps      | 1440000    |
| train/                  |            |
|    approx_kl            | 0.07980297 |
|    clip_fraction        | 0.364      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.569     |
|    explained_variance   | 0.777      |
|    learning_rate        | 0.00172    |
|    loss                 | -0.034     |
|    n_updates            | 7030       |
|    policy_gradient_loss | 0.0115     |
|    std                  | 0.322      |
|    value_loss           | 0.00734    |
----------------------------------------
box reached target
--------------------------------
| time/              |         |
|    fps             | 622     |
|    iterations      | 704     |
|    time_elapsed    | 2316    |
|    total_timesteps | 1441792 |
--------------------------------
box reached target
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 705        |
|    time_elapsed         | 2319       |
|    total_timesteps      | 1443840    |
| train/                  |            |
|    approx_kl            | 0.14898166 |
|    clip_fraction        | 0.371      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.575     |
|    explained_variance   | 0.852      |
|    learning_rate        | 0.00172    |
|    loss                 | 0.0311     |
|    n_updates            | 7040       |
|    policy_gradient_loss | 0.00599    |
|    std                  | 0.322      |
|    value_loss           | 0.00769    |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 706        |
|    time_elapsed         | 2322       |
|    total_timesteps      | 1445888    |
| train/                  |            |
|    approx_kl            | 0.10208343 |
|    clip_fraction        | 0.38       |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.638     |
|    explained_variance   | 0.967      |
|    learning_rate        | 0.00172    |
|    loss                 | 0.0573     |
|    n_updates            | 7050       |
|    policy_gradient_loss | 0.0206     |
|    std                  | 0.338      |
|    value_loss           | 0.00699    |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 707        |
|    time_elapsed         | 2325       |
|    total_timesteps      | 1447936    |
| train/                  |            |
|    approx_kl            | 0.10054685 |
|    clip_fraction        | 0.334      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.651     |
|    explained_variance   | 0.932      |
|    learning_rate        | 0.00172    |
|    loss                 | 0.0781     |
|    n_updates            | 7060       |
|    policy_gradient_loss | 0.00319    |
|    std                  | 0.33       |
|    value_loss           | 0.00528    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 708        |
|    time_elapsed         | 2328       |
|    total_timesteps      | 1449984    |
| train/                  |            |
|    approx_kl            | 0.13911012 |
|    clip_fraction        | 0.369      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.62      |
|    explained_variance   | 0.897      |
|    learning_rate        | 0.00172    |
|    loss                 | 0.0131     |
|    n_updates            | 7070       |
|    policy_gradient_loss | 0.016      |
|    std                  | 0.331      |
|    value_loss           | 0.00449    |
----------------------------------------
box reached target
Eval num_timesteps=1450000, episode_reward=0.45 +/- 2.55
Episode length: 276.60 +/- 46.80
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 277        |
|    mean_reward          | 0.447      |
| time/                   |            |
|    total_timesteps      | 1450000    |
| train/                  |            |
|    approx_kl            | 0.06502954 |
|    clip_fraction        | 0.294      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.634     |
|    explained_variance   | 0.566      |
|    learning_rate        | 0.00172    |
|    loss                 | 0.0352     |
|    n_updates            | 7080       |
|    policy_gradient_loss | 0.00422    |
|    std                  | 0.335      |
|    value_loss           | 0.00309    |
----------------------------------------
box reached target
--------------------------------
| time/              |         |
|    fps             | 622     |
|    iterations      | 709     |
|    time_elapsed    | 2332    |
|    total_timesteps | 1452032 |
--------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 710        |
|    time_elapsed         | 2335       |
|    total_timesteps      | 1454080    |
| train/                  |            |
|    approx_kl            | 0.32880354 |
|    clip_fraction        | 0.412      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.616     |
|    explained_variance   | 0.871      |
|    learning_rate        | 0.00172    |
|    loss                 | -0.0283    |
|    n_updates            | 7090       |
|    policy_gradient_loss | 0.00528    |
|    std                  | 0.318      |
|    value_loss           | 0.0114     |
----------------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 711        |
|    time_elapsed         | 2338       |
|    total_timesteps      | 1456128    |
| train/                  |            |
|    approx_kl            | 0.22388314 |
|    clip_fraction        | 0.356      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.499     |
|    explained_variance   | 0.84       |
|    learning_rate        | 0.00172    |
|    loss                 | 0.000278   |
|    n_updates            | 7100       |
|    policy_gradient_loss | 0.0108     |
|    std                  | 0.303      |
|    value_loss           | 0.00896    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 712        |
|    time_elapsed         | 2341       |
|    total_timesteps      | 1458176    |
| train/                  |            |
|    approx_kl            | 0.06343733 |
|    clip_fraction        | 0.328      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.486     |
|    explained_variance   | 0.882      |
|    learning_rate        | 0.00172    |
|    loss                 | -0.028     |
|    n_updates            | 7110       |
|    policy_gradient_loss | 0.00444    |
|    std                  | 0.313      |
|    value_loss           | 0.0079     |
----------------------------------------
box reached target
box reached target
box reached target
box reached target
Eval num_timesteps=1460000, episode_reward=0.22 +/- 2.43
Episode length: 273.00 +/- 54.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 273        |
|    mean_reward          | 0.216      |
| time/                   |            |
|    total_timesteps      | 1460000    |
| train/                  |            |
|    approx_kl            | 0.17293566 |
|    clip_fraction        | 0.342      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.546     |
|    explained_variance   | 0.775      |
|    learning_rate        | 0.00172    |
|    loss                 | 0.00832    |
|    n_updates            | 7120       |
|    policy_gradient_loss | 0.00373    |
|    std                  | 0.318      |
|    value_loss           | 0.00393    |
----------------------------------------
box reached target
--------------------------------
| time/              |         |
|    fps             | 622     |
|    iterations      | 713     |
|    time_elapsed    | 2345    |
|    total_timesteps | 1460224 |
--------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 714        |
|    time_elapsed         | 2348       |
|    total_timesteps      | 1462272    |
| train/                  |            |
|    approx_kl            | 0.09548327 |
|    clip_fraction        | 0.378      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.501     |
|    explained_variance   | 0.927      |
|    learning_rate        | 0.00172    |
|    loss                 | 0.0358     |
|    n_updates            | 7130       |
|    policy_gradient_loss | 0.000814   |
|    std                  | 0.307      |
|    value_loss           | 0.0104     |
----------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 622       |
|    iterations           | 715       |
|    time_elapsed         | 2352      |
|    total_timesteps      | 1464320   |
| train/                  |           |
|    approx_kl            | 0.3849336 |
|    clip_fraction        | 0.402     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.497    |
|    explained_variance   | 0.865     |
|    learning_rate        | 0.00171   |
|    loss                 | 0.00109   |
|    n_updates            | 7140      |
|    policy_gradient_loss | 0.00976   |
|    std                  | 0.308     |
|    value_loss           | 0.01      |
---------------------------------------
--------------------------------------
| time/                   |          |
|    fps                  | 622      |
|    iterations           | 716      |
|    time_elapsed         | 2355     |
|    total_timesteps      | 1466368  |
| train/                  |          |
|    approx_kl            | 0.143235 |
|    clip_fraction        | 0.379    |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.52    |
|    explained_variance   | 0.79     |
|    learning_rate        | 0.00171  |
|    loss                 | -0.034   |
|    n_updates            | 7150     |
|    policy_gradient_loss | 0.0113   |
|    std                  | 0.315    |
|    value_loss           | 0.0215   |
--------------------------------------
box reached target
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 717        |
|    time_elapsed         | 2358       |
|    total_timesteps      | 1468416    |
| train/                  |            |
|    approx_kl            | 0.08811184 |
|    clip_fraction        | 0.373      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.57      |
|    explained_variance   | 0.678      |
|    learning_rate        | 0.00171    |
|    loss                 | -0.0322    |
|    n_updates            | 7160       |
|    policy_gradient_loss | 0.0122     |
|    std                  | 0.325      |
|    value_loss           | 0.00864    |
----------------------------------------
box reached target
box reached target
box reached target
Eval num_timesteps=1470000, episode_reward=0.23 +/- 2.46
Episode length: 277.60 +/- 44.80
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 278        |
|    mean_reward          | 0.23       |
| time/                   |            |
|    total_timesteps      | 1470000    |
| train/                  |            |
|    approx_kl            | 0.23510204 |
|    clip_fraction        | 0.4        |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.594     |
|    explained_variance   | 0.866      |
|    learning_rate        | 0.00171    |
|    loss                 | 0.00548    |
|    n_updates            | 7170       |
|    policy_gradient_loss | 0.000923   |
|    std                  | 0.323      |
|    value_loss           | 0.0235     |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 622     |
|    iterations      | 718     |
|    time_elapsed    | 2362    |
|    total_timesteps | 1470464 |
--------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 622       |
|    iterations           | 719       |
|    time_elapsed         | 2365      |
|    total_timesteps      | 1472512   |
| train/                  |           |
|    approx_kl            | 0.1954646 |
|    clip_fraction        | 0.382     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.594    |
|    explained_variance   | 0.964     |
|    learning_rate        | 0.00171   |
|    loss                 | -0.0141   |
|    n_updates            | 7180      |
|    policy_gradient_loss | 0.0074    |
|    std                  | 0.325     |
|    value_loss           | 0.00757   |
---------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 622       |
|    iterations           | 720       |
|    time_elapsed         | 2368      |
|    total_timesteps      | 1474560   |
| train/                  |           |
|    approx_kl            | 0.1348551 |
|    clip_fraction        | 0.333     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.622    |
|    explained_variance   | 0.876     |
|    learning_rate        | 0.00171   |
|    loss                 | 0.00636   |
|    n_updates            | 7190      |
|    policy_gradient_loss | 0.00436   |
|    std                  | 0.332     |
|    value_loss           | 0.0108    |
---------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 721        |
|    time_elapsed         | 2371       |
|    total_timesteps      | 1476608    |
| train/                  |            |
|    approx_kl            | 0.17304283 |
|    clip_fraction        | 0.332      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.675     |
|    explained_variance   | 0.607      |
|    learning_rate        | 0.00171    |
|    loss                 | 0.0251     |
|    n_updates            | 7200       |
|    policy_gradient_loss | 0.00131    |
|    std                  | 0.34       |
|    value_loss           | 0.00224    |
----------------------------------------
--------------------------------------
| time/                   |          |
|    fps                  | 622      |
|    iterations           | 722      |
|    time_elapsed         | 2374     |
|    total_timesteps      | 1478656  |
| train/                  |          |
|    approx_kl            | 0.266026 |
|    clip_fraction        | 0.397    |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.665   |
|    explained_variance   | 0.899    |
|    learning_rate        | 0.00171  |
|    loss                 | -0.00444 |
|    n_updates            | 7210     |
|    policy_gradient_loss | 0.0279   |
|    std                  | 0.331    |
|    value_loss           | 0.0124   |
--------------------------------------
box reached target
box reached target
box reached target
Eval num_timesteps=1480000, episode_reward=1.55 +/- 3.13
Episode length: 257.60 +/- 53.03
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 258        |
|    mean_reward          | 1.55       |
| time/                   |            |
|    total_timesteps      | 1480000    |
| train/                  |            |
|    approx_kl            | 0.11561249 |
|    clip_fraction        | 0.345      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.623     |
|    explained_variance   | 0.774      |
|    learning_rate        | 0.00171    |
|    loss                 | 0.0243     |
|    n_updates            | 7220       |
|    policy_gradient_loss | 0.0296     |
|    std                  | 0.328      |
|    value_loss           | 0.00633    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 622     |
|    iterations      | 723     |
|    time_elapsed    | 2378    |
|    total_timesteps | 1480704 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 724        |
|    time_elapsed         | 2381       |
|    total_timesteps      | 1482752    |
| train/                  |            |
|    approx_kl            | 0.15554574 |
|    clip_fraction        | 0.376      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.611     |
|    explained_variance   | 0.953      |
|    learning_rate        | 0.00171    |
|    loss                 | -0.0349    |
|    n_updates            | 7230       |
|    policy_gradient_loss | -0.000836  |
|    std                  | 0.326      |
|    value_loss           | 0.00405    |
----------------------------------------
box reached target
box reached target
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 622       |
|    iterations           | 725       |
|    time_elapsed         | 2384      |
|    total_timesteps      | 1484800   |
| train/                  |           |
|    approx_kl            | 0.2831751 |
|    clip_fraction        | 0.374     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.669    |
|    explained_variance   | 0.627     |
|    learning_rate        | 0.00171   |
|    loss                 | -0.0436   |
|    n_updates            | 7240      |
|    policy_gradient_loss | 0.000659  |
|    std                  | 0.341     |
|    value_loss           | 0.0024    |
---------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 726        |
|    time_elapsed         | 2387       |
|    total_timesteps      | 1486848    |
| train/                  |            |
|    approx_kl            | 0.15459648 |
|    clip_fraction        | 0.397      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.633     |
|    explained_variance   | 0.724      |
|    learning_rate        | 0.00171    |
|    loss                 | 0.00466    |
|    n_updates            | 7250       |
|    policy_gradient_loss | 0.00042    |
|    std                  | 0.328      |
|    value_loss           | 0.0217     |
----------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 622       |
|    iterations           | 727       |
|    time_elapsed         | 2391      |
|    total_timesteps      | 1488896   |
| train/                  |           |
|    approx_kl            | 0.2844398 |
|    clip_fraction        | 0.411     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.627    |
|    explained_variance   | 0.732     |
|    learning_rate        | 0.00171   |
|    loss                 | -0.00734  |
|    n_updates            | 7260      |
|    policy_gradient_loss | 0.00248   |
|    std                  | 0.329     |
|    value_loss           | 0.00957   |
---------------------------------------
box reached target
box reached target
Eval num_timesteps=1490000, episode_reward=0.58 +/- 2.54
Episode length: 288.00 +/- 24.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 288        |
|    mean_reward          | 0.577      |
| time/                   |            |
|    total_timesteps      | 1490000    |
| train/                  |            |
|    approx_kl            | 0.09110142 |
|    clip_fraction        | 0.345      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.635     |
|    explained_variance   | 0.738      |
|    learning_rate        | 0.00171    |
|    loss                 | 0.000355   |
|    n_updates            | 7270       |
|    policy_gradient_loss | 0.00524    |
|    std                  | 0.331      |
|    value_loss           | 0.00733    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 622     |
|    iterations      | 728     |
|    time_elapsed    | 2395    |
|    total_timesteps | 1490944 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 729        |
|    time_elapsed         | 2398       |
|    total_timesteps      | 1492992    |
| train/                  |            |
|    approx_kl            | 0.42509258 |
|    clip_fraction        | 0.399      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.647     |
|    explained_variance   | 0.808      |
|    learning_rate        | 0.00171    |
|    loss                 | 0.0143     |
|    n_updates            | 7280       |
|    policy_gradient_loss | 0.00715    |
|    std                  | 0.327      |
|    value_loss           | 0.00437    |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 730        |
|    time_elapsed         | 2401       |
|    total_timesteps      | 1495040    |
| train/                  |            |
|    approx_kl            | 0.64358294 |
|    clip_fraction        | 0.381      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.538     |
|    explained_variance   | 0.84       |
|    learning_rate        | 0.00171    |
|    loss                 | -0.0438    |
|    n_updates            | 7290       |
|    policy_gradient_loss | -0.0114    |
|    std                  | 0.31       |
|    value_loss           | 0.00763    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 731        |
|    time_elapsed         | 2404       |
|    total_timesteps      | 1497088    |
| train/                  |            |
|    approx_kl            | 0.13000083 |
|    clip_fraction        | 0.416      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.51      |
|    explained_variance   | 0.894      |
|    learning_rate        | 0.00171    |
|    loss                 | 0.0138     |
|    n_updates            | 7300       |
|    policy_gradient_loss | 0.00202    |
|    std                  | 0.311      |
|    value_loss           | 0.00753    |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 732        |
|    time_elapsed         | 2407       |
|    total_timesteps      | 1499136    |
| train/                  |            |
|    approx_kl            | 0.18566465 |
|    clip_fraction        | 0.395      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.515     |
|    explained_variance   | 0.776      |
|    learning_rate        | 0.00171    |
|    loss                 | 0.0276     |
|    n_updates            | 7310       |
|    policy_gradient_loss | 0.0216     |
|    std                  | 0.312      |
|    value_loss           | 0.00592    |
----------------------------------------
box reached target
Eval num_timesteps=1500000, episode_reward=0.53 +/- 2.35
Episode length: 271.40 +/- 57.20
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 271        |
|    mean_reward          | 0.527      |
| time/                   |            |
|    total_timesteps      | 1500000    |
| train/                  |            |
|    approx_kl            | 0.20575564 |
|    clip_fraction        | 0.364      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.562     |
|    explained_variance   | 0.488      |
|    learning_rate        | 0.00171    |
|    loss                 | -0.00824   |
|    n_updates            | 7320       |
|    policy_gradient_loss | 0.0279     |
|    std                  | 0.322      |
|    value_loss           | 0.0115     |
----------------------------------------
box reached target
box reached target
--------------------------------
| time/              |         |
|    fps             | 622     |
|    iterations      | 733     |
|    time_elapsed    | 2411    |
|    total_timesteps | 1501184 |
--------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 734        |
|    time_elapsed         | 2414       |
|    total_timesteps      | 1503232    |
| train/                  |            |
|    approx_kl            | 0.13677019 |
|    clip_fraction        | 0.392      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.586     |
|    explained_variance   | 0.895      |
|    learning_rate        | 0.00171    |
|    loss                 | -0.0407    |
|    n_updates            | 7330       |
|    policy_gradient_loss | 0.00443    |
|    std                  | 0.325      |
|    value_loss           | 0.00998    |
----------------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 735        |
|    time_elapsed         | 2417       |
|    total_timesteps      | 1505280    |
| train/                  |            |
|    approx_kl            | 0.23645806 |
|    clip_fraction        | 0.383      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.593     |
|    explained_variance   | 0.951      |
|    learning_rate        | 0.00171    |
|    loss                 | -0.0247    |
|    n_updates            | 7340       |
|    policy_gradient_loss | 0.0261     |
|    std                  | 0.322      |
|    value_loss           | 0.00856    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 736        |
|    time_elapsed         | 2420       |
|    total_timesteps      | 1507328    |
| train/                  |            |
|    approx_kl            | 0.05787792 |
|    clip_fraction        | 0.36       |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.6       |
|    explained_variance   | 0.819      |
|    learning_rate        | 0.00171    |
|    loss                 | 0.0412     |
|    n_updates            | 7350       |
|    policy_gradient_loss | 0.00485    |
|    std                  | 0.325      |
|    value_loss           | 0.0167     |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 737        |
|    time_elapsed         | 2424       |
|    total_timesteps      | 1509376    |
| train/                  |            |
|    approx_kl            | 0.07608671 |
|    clip_fraction        | 0.336      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.601     |
|    explained_variance   | 0.487      |
|    learning_rate        | 0.00171    |
|    loss                 | -0.0356    |
|    n_updates            | 7360       |
|    policy_gradient_loss | 0.00994    |
|    std                  | 0.329      |
|    value_loss           | 0.00193    |
----------------------------------------
box reached target
Eval num_timesteps=1510000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 300       |
|    mean_reward          | -1        |
| time/                   |           |
|    total_timesteps      | 1510000   |
| train/                  |           |
|    approx_kl            | 0.5655686 |
|    clip_fraction        | 0.391     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.628    |
|    explained_variance   | 0.853     |
|    learning_rate        | 0.00171   |
|    loss                 | -0.0336   |
|    n_updates            | 7370      |
|    policy_gradient_loss | -0.00596  |
|    std                  | 0.329     |
|    value_loss           | 0.00618   |
---------------------------------------
--------------------------------
| time/              |         |
|    fps             | 622     |
|    iterations      | 738     |
|    time_elapsed    | 2428    |
|    total_timesteps | 1511424 |
--------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 739        |
|    time_elapsed         | 2431       |
|    total_timesteps      | 1513472    |
| train/                  |            |
|    approx_kl            | 0.21004157 |
|    clip_fraction        | 0.326      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.594     |
|    explained_variance   | 0.689      |
|    learning_rate        | 0.00171    |
|    loss                 | 0.0327     |
|    n_updates            | 7380       |
|    policy_gradient_loss | -0.00071   |
|    std                  | 0.319      |
|    value_loss           | 0.00505    |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 740        |
|    time_elapsed         | 2434       |
|    total_timesteps      | 1515520    |
| train/                  |            |
|    approx_kl            | 0.11380537 |
|    clip_fraction        | 0.397      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.545     |
|    explained_variance   | 0.612      |
|    learning_rate        | 0.0017     |
|    loss                 | 0.0102     |
|    n_updates            | 7390       |
|    policy_gradient_loss | 0.0136     |
|    std                  | 0.315      |
|    value_loss           | 0.0201     |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 741        |
|    time_elapsed         | 2437       |
|    total_timesteps      | 1517568    |
| train/                  |            |
|    approx_kl            | 0.14902985 |
|    clip_fraction        | 0.382      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.486     |
|    explained_variance   | 0.848      |
|    learning_rate        | 0.0017     |
|    loss                 | 0.0112     |
|    n_updates            | 7400       |
|    policy_gradient_loss | 0.00324    |
|    std                  | 0.301      |
|    value_loss           | 0.0063     |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 742        |
|    time_elapsed         | 2440       |
|    total_timesteps      | 1519616    |
| train/                  |            |
|    approx_kl            | 0.15734705 |
|    clip_fraction        | 0.337      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.463     |
|    explained_variance   | 0.515      |
|    learning_rate        | 0.0017     |
|    loss                 | -0.0363    |
|    n_updates            | 7410       |
|    policy_gradient_loss | 0.0172     |
|    std                  | 0.304      |
|    value_loss           | 0.0107     |
----------------------------------------
Eval num_timesteps=1520000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1         |
| time/                   |            |
|    total_timesteps      | 1520000    |
| train/                  |            |
|    approx_kl            | 0.14766696 |
|    clip_fraction        | 0.385      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.493     |
|    explained_variance   | 0.625      |
|    learning_rate        | 0.0017     |
|    loss                 | -0.00384   |
|    n_updates            | 7420       |
|    policy_gradient_loss | 0.00613    |
|    std                  | 0.307      |
|    value_loss           | 0.00378    |
----------------------------------------
box reached target
--------------------------------
| time/              |         |
|    fps             | 622     |
|    iterations      | 743     |
|    time_elapsed    | 2444    |
|    total_timesteps | 1521664 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 744        |
|    time_elapsed         | 2447       |
|    total_timesteps      | 1523712    |
| train/                  |            |
|    approx_kl            | 0.12233421 |
|    clip_fraction        | 0.358      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.455     |
|    explained_variance   | 0.24       |
|    learning_rate        | 0.0017     |
|    loss                 | 0.00535    |
|    n_updates            | 7430       |
|    policy_gradient_loss | 0.00634    |
|    std                  | 0.299      |
|    value_loss           | 0.0462     |
----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 622       |
|    iterations           | 745       |
|    time_elapsed         | 2450      |
|    total_timesteps      | 1525760   |
| train/                  |           |
|    approx_kl            | 0.3559091 |
|    clip_fraction        | 0.36      |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.429    |
|    explained_variance   | 0.671     |
|    learning_rate        | 0.0017    |
|    loss                 | 0.00696   |
|    n_updates            | 7440      |
|    policy_gradient_loss | -8.28e-06 |
|    std                  | 0.299     |
|    value_loss           | 0.0137    |
---------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 622         |
|    iterations           | 746         |
|    time_elapsed         | 2453        |
|    total_timesteps      | 1527808     |
| train/                  |             |
|    approx_kl            | 0.068367556 |
|    clip_fraction        | 0.303       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.462      |
|    explained_variance   | 0.419       |
|    learning_rate        | 0.0017      |
|    loss                 | -0.0417     |
|    n_updates            | 7450        |
|    policy_gradient_loss | 0.00123     |
|    std                  | 0.306       |
|    value_loss           | 0.00641     |
-----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 622       |
|    iterations           | 747       |
|    time_elapsed         | 2457      |
|    total_timesteps      | 1529856   |
| train/                  |           |
|    approx_kl            | 0.1236265 |
|    clip_fraction        | 0.37      |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.495    |
|    explained_variance   | 0.529     |
|    learning_rate        | 0.0017    |
|    loss                 | 0.0363    |
|    n_updates            | 7460      |
|    policy_gradient_loss | 0.0264    |
|    std                  | 0.311     |
|    value_loss           | 0.0053    |
---------------------------------------
box reached target
Eval num_timesteps=1530000, episode_reward=0.53 +/- 2.35
Episode length: 273.00 +/- 54.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 273        |
|    mean_reward          | 0.533      |
| time/                   |            |
|    total_timesteps      | 1530000    |
| train/                  |            |
|    approx_kl            | 0.13269666 |
|    clip_fraction        | 0.331      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.492     |
|    explained_variance   | 0.303      |
|    learning_rate        | 0.0017     |
|    loss                 | -0.0122    |
|    n_updates            | 7470       |
|    policy_gradient_loss | 0.00521    |
|    std                  | 0.307      |
|    value_loss           | 0.00245    |
----------------------------------------
box reached target
--------------------------------
| time/              |         |
|    fps             | 622     |
|    iterations      | 748     |
|    time_elapsed    | 2461    |
|    total_timesteps | 1531904 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 749        |
|    time_elapsed         | 2464       |
|    total_timesteps      | 1533952    |
| train/                  |            |
|    approx_kl            | 0.10122239 |
|    clip_fraction        | 0.35       |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.478     |
|    explained_variance   | 0.886      |
|    learning_rate        | 0.0017     |
|    loss                 | -0.00807   |
|    n_updates            | 7480       |
|    policy_gradient_loss | 0.00619    |
|    std                  | 0.306      |
|    value_loss           | 0.00624    |
----------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 622       |
|    iterations           | 750       |
|    time_elapsed         | 2467      |
|    total_timesteps      | 1536000   |
| train/                  |           |
|    approx_kl            | 0.3060248 |
|    clip_fraction        | 0.363     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.505    |
|    explained_variance   | 0.466     |
|    learning_rate        | 0.0017    |
|    loss                 | -0.0442   |
|    n_updates            | 7490      |
|    policy_gradient_loss | 0.0128    |
|    std                  | 0.31      |
|    value_loss           | 0.00282   |
---------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 751        |
|    time_elapsed         | 2470       |
|    total_timesteps      | 1538048    |
| train/                  |            |
|    approx_kl            | 0.15635139 |
|    clip_fraction        | 0.357      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.496     |
|    explained_variance   | 0.93       |
|    learning_rate        | 0.0017     |
|    loss                 | -0.0151    |
|    n_updates            | 7500       |
|    policy_gradient_loss | 0.00144    |
|    std                  | 0.31       |
|    value_loss           | 0.00601    |
----------------------------------------
box reached target
Eval num_timesteps=1540000, episode_reward=-0.85 +/- 0.29
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -0.854     |
| time/                   |            |
|    total_timesteps      | 1540000    |
| train/                  |            |
|    approx_kl            | 0.19948396 |
|    clip_fraction        | 0.394      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.477     |
|    explained_variance   | 0.812      |
|    learning_rate        | 0.0017     |
|    loss                 | 0.00872    |
|    n_updates            | 7510       |
|    policy_gradient_loss | 0.0126     |
|    std                  | 0.304      |
|    value_loss           | 0.0121     |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 622     |
|    iterations      | 752     |
|    time_elapsed    | 2474    |
|    total_timesteps | 1540096 |
--------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 622         |
|    iterations           | 753         |
|    time_elapsed         | 2477        |
|    total_timesteps      | 1542144     |
| train/                  |             |
|    approx_kl            | 0.107638106 |
|    clip_fraction        | 0.407       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.434      |
|    explained_variance   | 0.452       |
|    learning_rate        | 0.0017      |
|    loss                 | -0.00488    |
|    n_updates            | 7520        |
|    policy_gradient_loss | 0.00787     |
|    std                  | 0.298       |
|    value_loss           | 0.0645      |
-----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 754        |
|    time_elapsed         | 2480       |
|    total_timesteps      | 1544192    |
| train/                  |            |
|    approx_kl            | 0.09212293 |
|    clip_fraction        | 0.39       |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.447     |
|    explained_variance   | 0.236      |
|    learning_rate        | 0.0017     |
|    loss                 | -0.0117    |
|    n_updates            | 7530       |
|    policy_gradient_loss | 0.00468    |
|    std                  | 0.302      |
|    value_loss           | 0.00464    |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 755        |
|    time_elapsed         | 2483       |
|    total_timesteps      | 1546240    |
| train/                  |            |
|    approx_kl            | 0.16424066 |
|    clip_fraction        | 0.329      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.399     |
|    explained_variance   | 0.423      |
|    learning_rate        | 0.0017     |
|    loss                 | 0.00136    |
|    n_updates            | 7540       |
|    policy_gradient_loss | -0.00245   |
|    std                  | 0.293      |
|    value_loss           | 0.00341    |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 756        |
|    time_elapsed         | 2486       |
|    total_timesteps      | 1548288    |
| train/                  |            |
|    approx_kl            | 0.18125728 |
|    clip_fraction        | 0.366      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.41      |
|    explained_variance   | 0.219      |
|    learning_rate        | 0.0017     |
|    loss                 | 0.0388     |
|    n_updates            | 7550       |
|    policy_gradient_loss | 0.0287     |
|    std                  | 0.295      |
|    value_loss           | 0.00586    |
----------------------------------------
box reached target
box reached target
Eval num_timesteps=1550000, episode_reward=0.54 +/- 2.44
Episode length: 280.80 +/- 38.40
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 281        |
|    mean_reward          | 0.541      |
| time/                   |            |
|    total_timesteps      | 1550000    |
| train/                  |            |
|    approx_kl            | 0.30746928 |
|    clip_fraction        | 0.38       |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.403     |
|    explained_variance   | 0.659      |
|    learning_rate        | 0.0017     |
|    loss                 | 0.0256     |
|    n_updates            | 7560       |
|    policy_gradient_loss | 0.00821    |
|    std                  | 0.294      |
|    value_loss           | 0.0121     |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 622     |
|    iterations      | 757     |
|    time_elapsed    | 2490    |
|    total_timesteps | 1550336 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 758        |
|    time_elapsed         | 2493       |
|    total_timesteps      | 1552384    |
| train/                  |            |
|    approx_kl            | 0.19328526 |
|    clip_fraction        | 0.388      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.435     |
|    explained_variance   | 0.384      |
|    learning_rate        | 0.0017     |
|    loss                 | 0.0389     |
|    n_updates            | 7570       |
|    policy_gradient_loss | 0.00626    |
|    std                  | 0.298      |
|    value_loss           | 0.0605     |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 759        |
|    time_elapsed         | 2497       |
|    total_timesteps      | 1554432    |
| train/                  |            |
|    approx_kl            | 0.14515851 |
|    clip_fraction        | 0.339      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.403     |
|    explained_variance   | 0.602      |
|    learning_rate        | 0.0017     |
|    loss                 | -0.0313    |
|    n_updates            | 7580       |
|    policy_gradient_loss | 0.00432    |
|    std                  | 0.294      |
|    value_loss           | 0.0114     |
----------------------------------------
box reached target
box reached target
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 622       |
|    iterations           | 760       |
|    time_elapsed         | 2500      |
|    total_timesteps      | 1556480   |
| train/                  |           |
|    approx_kl            | 0.8157444 |
|    clip_fraction        | 0.436     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.375    |
|    explained_variance   | 0.239     |
|    learning_rate        | 0.0017    |
|    loss                 | -0.0393   |
|    n_updates            | 7590      |
|    policy_gradient_loss | -0.0144   |
|    std                  | 0.288     |
|    value_loss           | 0.0195    |
---------------------------------------
box reached target
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 761        |
|    time_elapsed         | 2503       |
|    total_timesteps      | 1558528    |
| train/                  |            |
|    approx_kl            | 0.13554962 |
|    clip_fraction        | 0.394      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.366     |
|    explained_variance   | 0.241      |
|    learning_rate        | 0.0017     |
|    loss                 | 0.0043     |
|    n_updates            | 7600       |
|    policy_gradient_loss | 0.0112     |
|    std                  | 0.289      |
|    value_loss           | 0.0732     |
----------------------------------------
box reached target
Eval num_timesteps=1560000, episode_reward=-0.75 +/- 0.51
Episode length: 300.00 +/- 0.00
--------------------------------------
| eval/                   |          |
|    mean_ep_length       | 300      |
|    mean_reward          | -0.745   |
| time/                   |          |
|    total_timesteps      | 1560000  |
| train/                  |          |
|    approx_kl            | 0.301434 |
|    clip_fraction        | 0.421    |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.323   |
|    explained_variance   | 0.634    |
|    learning_rate        | 0.0017   |
|    loss                 | -0.0349  |
|    n_updates            | 7610     |
|    policy_gradient_loss | 0.00798  |
|    std                  | 0.279    |
|    value_loss           | 0.019    |
--------------------------------------
--------------------------------
| time/              |         |
|    fps             | 622     |
|    iterations      | 762     |
|    time_elapsed    | 2507    |
|    total_timesteps | 1560576 |
--------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 763        |
|    time_elapsed         | 2510       |
|    total_timesteps      | 1562624    |
| train/                  |            |
|    approx_kl            | 0.38989052 |
|    clip_fraction        | 0.392      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.281     |
|    explained_variance   | 0.659      |
|    learning_rate        | 0.0017     |
|    loss                 | -0.00519   |
|    n_updates            | 7620       |
|    policy_gradient_loss | -0.00631   |
|    std                  | 0.274      |
|    value_loss           | 0.0235     |
----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 622       |
|    iterations           | 764       |
|    time_elapsed         | 2513      |
|    total_timesteps      | 1564672   |
| train/                  |           |
|    approx_kl            | 0.1309894 |
|    clip_fraction        | 0.387     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.256    |
|    explained_variance   | 0.256     |
|    learning_rate        | 0.0017    |
|    loss                 | 0.00148   |
|    n_updates            | 7630      |
|    policy_gradient_loss | 0.00899   |
|    std                  | 0.275     |
|    value_loss           | 0.0216    |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 765        |
|    time_elapsed         | 2516       |
|    total_timesteps      | 1566720    |
| train/                  |            |
|    approx_kl            | 0.29377508 |
|    clip_fraction        | 0.366      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.304     |
|    explained_variance   | 0.701      |
|    learning_rate        | 0.00169    |
|    loss                 | 0.0496     |
|    n_updates            | 7640       |
|    policy_gradient_loss | -7.14e-05  |
|    std                  | 0.283      |
|    value_loss           | 0.0113     |
----------------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 766        |
|    time_elapsed         | 2519       |
|    total_timesteps      | 1568768    |
| train/                  |            |
|    approx_kl            | 0.12388864 |
|    clip_fraction        | 0.325      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.3       |
|    explained_variance   | 0.443      |
|    learning_rate        | 0.00169    |
|    loss                 | -0.0648    |
|    n_updates            | 7650       |
|    policy_gradient_loss | 0.000313   |
|    std                  | 0.278      |
|    value_loss           | 0.00576    |
----------------------------------------
Eval num_timesteps=1570000, episode_reward=-0.46 +/- 0.55
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -0.459     |
| time/                   |            |
|    total_timesteps      | 1570000    |
| train/                  |            |
|    approx_kl            | 0.24960218 |
|    clip_fraction        | 0.439      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.24      |
|    explained_variance   | 0.735      |
|    learning_rate        | 0.00169    |
|    loss                 | -0.0198    |
|    n_updates            | 7660       |
|    policy_gradient_loss | 0.00751    |
|    std                  | 0.27       |
|    value_loss           | 0.0123     |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 622     |
|    iterations      | 767     |
|    time_elapsed    | 2523    |
|    total_timesteps | 1570816 |
--------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 768        |
|    time_elapsed         | 2527       |
|    total_timesteps      | 1572864    |
| train/                  |            |
|    approx_kl            | 0.07836139 |
|    clip_fraction        | 0.355      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.269     |
|    explained_variance   | 0.849      |
|    learning_rate        | 0.00169    |
|    loss                 | 0.00997    |
|    n_updates            | 7670       |
|    policy_gradient_loss | 0.00962    |
|    std                  | 0.28       |
|    value_loss           | 0.00319    |
----------------------------------------
--------------------------------------
| time/                   |          |
|    fps                  | 622      |
|    iterations           | 769      |
|    time_elapsed         | 2530     |
|    total_timesteps      | 1574912  |
| train/                  |          |
|    approx_kl            | 0.188107 |
|    clip_fraction        | 0.418    |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.301   |
|    explained_variance   | 0.735    |
|    learning_rate        | 0.00169  |
|    loss                 | 0.0279   |
|    n_updates            | 7680     |
|    policy_gradient_loss | 0.0166   |
|    std                  | 0.279    |
|    value_loss           | 0.00795  |
--------------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 770        |
|    time_elapsed         | 2533       |
|    total_timesteps      | 1576960    |
| train/                  |            |
|    approx_kl            | 0.08037366 |
|    clip_fraction        | 0.369      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.274     |
|    explained_variance   | 0.189      |
|    learning_rate        | 0.00169    |
|    loss                 | -0.0192    |
|    n_updates            | 7690       |
|    policy_gradient_loss | 0.0192     |
|    std                  | 0.276      |
|    value_loss           | 0.00332    |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 771        |
|    time_elapsed         | 2536       |
|    total_timesteps      | 1579008    |
| train/                  |            |
|    approx_kl            | 0.26260614 |
|    clip_fraction        | 0.359      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.27      |
|    explained_variance   | 0.895      |
|    learning_rate        | 0.00169    |
|    loss                 | -0.0394    |
|    n_updates            | 7700       |
|    policy_gradient_loss | 0.00485    |
|    std                  | 0.276      |
|    value_loss           | 0.0101     |
----------------------------------------
Eval num_timesteps=1580000, episode_reward=-0.83 +/- 0.33
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -0.83      |
| time/                   |            |
|    total_timesteps      | 1580000    |
| train/                  |            |
|    approx_kl            | 0.33529246 |
|    clip_fraction        | 0.401      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.283     |
|    explained_variance   | 0.896      |
|    learning_rate        | 0.00169    |
|    loss                 | -0.0355    |
|    n_updates            | 7710       |
|    policy_gradient_loss | 0.00425    |
|    std                  | 0.278      |
|    value_loss           | 0.00714    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 622     |
|    iterations      | 772     |
|    time_elapsed    | 2540    |
|    total_timesteps | 1581056 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 773        |
|    time_elapsed         | 2543       |
|    total_timesteps      | 1583104    |
| train/                  |            |
|    approx_kl            | 0.20133433 |
|    clip_fraction        | 0.367      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.311     |
|    explained_variance   | 0.73       |
|    learning_rate        | 0.00169    |
|    loss                 | 0.0293     |
|    n_updates            | 7720       |
|    policy_gradient_loss | -0.00172   |
|    std                  | 0.283      |
|    value_loss           | 0.00934    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 774        |
|    time_elapsed         | 2546       |
|    total_timesteps      | 1585152    |
| train/                  |            |
|    approx_kl            | 0.08998094 |
|    clip_fraction        | 0.33       |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.308     |
|    explained_variance   | 0.81       |
|    learning_rate        | 0.00169    |
|    loss                 | 0.045      |
|    n_updates            | 7730       |
|    policy_gradient_loss | 0.00719    |
|    std                  | 0.283      |
|    value_loss           | 0.00477    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 775        |
|    time_elapsed         | 2549       |
|    total_timesteps      | 1587200    |
| train/                  |            |
|    approx_kl            | 0.31863183 |
|    clip_fraction        | 0.368      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.327     |
|    explained_variance   | 0.728      |
|    learning_rate        | 0.00169    |
|    loss                 | -0.0136    |
|    n_updates            | 7740       |
|    policy_gradient_loss | -0.00195   |
|    std                  | 0.284      |
|    value_loss           | 0.00167    |
----------------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 776        |
|    time_elapsed         | 2552       |
|    total_timesteps      | 1589248    |
| train/                  |            |
|    approx_kl            | 0.28253686 |
|    clip_fraction        | 0.357      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.342     |
|    explained_variance   | 0.34       |
|    learning_rate        | 0.00169    |
|    loss                 | -0.00211   |
|    n_updates            | 7750       |
|    policy_gradient_loss | -0.000453  |
|    std                  | 0.287      |
|    value_loss           | 0.0028     |
----------------------------------------
box reached target
box reached target
box reached target
Eval num_timesteps=1590000, episode_reward=1.49 +/- 3.05
Episode length: 252.00 +/- 60.56
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 252        |
|    mean_reward          | 1.49       |
| time/                   |            |
|    total_timesteps      | 1590000    |
| train/                  |            |
|    approx_kl            | 0.31544212 |
|    clip_fraction        | 0.418      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.333     |
|    explained_variance   | 0.897      |
|    learning_rate        | 0.00169    |
|    loss                 | -0.00841   |
|    n_updates            | 7760       |
|    policy_gradient_loss | 0.0166     |
|    std                  | 0.285      |
|    value_loss           | 0.0142     |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 622     |
|    iterations      | 777     |
|    time_elapsed    | 2556    |
|    total_timesteps | 1591296 |
--------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 778        |
|    time_elapsed         | 2559       |
|    total_timesteps      | 1593344    |
| train/                  |            |
|    approx_kl            | 0.14368865 |
|    clip_fraction        | 0.425      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.331     |
|    explained_variance   | 0.296      |
|    learning_rate        | 0.00169    |
|    loss                 | -0.0186    |
|    n_updates            | 7770       |
|    policy_gradient_loss | 0.0393     |
|    std                  | 0.287      |
|    value_loss           | 0.0204     |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 779        |
|    time_elapsed         | 2562       |
|    total_timesteps      | 1595392    |
| train/                  |            |
|    approx_kl            | 0.12220691 |
|    clip_fraction        | 0.365      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.294     |
|    explained_variance   | 0.896      |
|    learning_rate        | 0.00169    |
|    loss                 | 0.0127     |
|    n_updates            | 7780       |
|    policy_gradient_loss | 0.00674    |
|    std                  | 0.279      |
|    value_loss           | 0.00725    |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 780        |
|    time_elapsed         | 2566       |
|    total_timesteps      | 1597440    |
| train/                  |            |
|    approx_kl            | 0.12427321 |
|    clip_fraction        | 0.432      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.298     |
|    explained_variance   | 0.814      |
|    learning_rate        | 0.00169    |
|    loss                 | -0.0165    |
|    n_updates            | 7790       |
|    policy_gradient_loss | 0.0165     |
|    std                  | 0.285      |
|    value_loss           | 0.0239     |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 781        |
|    time_elapsed         | 2569       |
|    total_timesteps      | 1599488    |
| train/                  |            |
|    approx_kl            | 0.15366995 |
|    clip_fraction        | 0.385      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.358     |
|    explained_variance   | 0.894      |
|    learning_rate        | 0.00169    |
|    loss                 | 0.0739     |
|    n_updates            | 7800       |
|    policy_gradient_loss | 0.00906    |
|    std                  | 0.291      |
|    value_loss           | 0.00548    |
----------------------------------------
Eval num_timesteps=1600000, episode_reward=-0.75 +/- 0.50
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -0.752     |
| time/                   |            |
|    total_timesteps      | 1600000    |
| train/                  |            |
|    approx_kl            | 0.11846419 |
|    clip_fraction        | 0.387      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.39      |
|    explained_variance   | 0.916      |
|    learning_rate        | 0.00169    |
|    loss                 | -6.03e-05  |
|    n_updates            | 7810       |
|    policy_gradient_loss | 0.0196     |
|    std                  | 0.299      |
|    value_loss           | 0.00575    |
----------------------------------------
box reached target
--------------------------------
| time/              |         |
|    fps             | 622     |
|    iterations      | 782     |
|    time_elapsed    | 2573    |
|    total_timesteps | 1601536 |
--------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 622       |
|    iterations           | 783       |
|    time_elapsed         | 2576      |
|    total_timesteps      | 1603584   |
| train/                  |           |
|    approx_kl            | 0.1408689 |
|    clip_fraction        | 0.358     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.411    |
|    explained_variance   | 0.898     |
|    learning_rate        | 0.00169   |
|    loss                 | 0.0255    |
|    n_updates            | 7820      |
|    policy_gradient_loss | -0.00249  |
|    std                  | 0.296     |
|    value_loss           | 0.0059    |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 784        |
|    time_elapsed         | 2579       |
|    total_timesteps      | 1605632    |
| train/                  |            |
|    approx_kl            | 0.31988427 |
|    clip_fraction        | 0.36       |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.378     |
|    explained_variance   | 0.548      |
|    learning_rate        | 0.00169    |
|    loss                 | -0.0374    |
|    n_updates            | 7830       |
|    policy_gradient_loss | 0.00606    |
|    std                  | 0.288      |
|    value_loss           | 0.00421    |
----------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 622       |
|    iterations           | 785       |
|    time_elapsed         | 2582      |
|    total_timesteps      | 1607680   |
| train/                  |           |
|    approx_kl            | 0.5705987 |
|    clip_fraction        | 0.386     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.312    |
|    explained_variance   | 0.404     |
|    learning_rate        | 0.00169   |
|    loss                 | -0.02     |
|    n_updates            | 7840      |
|    policy_gradient_loss | 0.0168    |
|    std                  | 0.279     |
|    value_loss           | 0.00225   |
---------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 622       |
|    iterations           | 786       |
|    time_elapsed         | 2585      |
|    total_timesteps      | 1609728   |
| train/                  |           |
|    approx_kl            | 0.2112923 |
|    clip_fraction        | 0.412     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.279    |
|    explained_variance   | 0.872     |
|    learning_rate        | 0.00169   |
|    loss                 | 0.0623    |
|    n_updates            | 7850      |
|    policy_gradient_loss | 0.0303    |
|    std                  | 0.28      |
|    value_loss           | 0.00578   |
---------------------------------------
box reached target
box reached target
Eval num_timesteps=1610000, episode_reward=0.28 +/- 2.56
Episode length: 280.80 +/- 38.40
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 281        |
|    mean_reward          | 0.28       |
| time/                   |            |
|    total_timesteps      | 1610000    |
| train/                  |            |
|    approx_kl            | 0.26441467 |
|    clip_fraction        | 0.399      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.297     |
|    explained_variance   | 0.658      |
|    learning_rate        | 0.00169    |
|    loss                 | -0.0628    |
|    n_updates            | 7860       |
|    policy_gradient_loss | -0.0028    |
|    std                  | 0.276      |
|    value_loss           | 0.00278    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 622     |
|    iterations      | 787     |
|    time_elapsed    | 2589    |
|    total_timesteps | 1611776 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 788        |
|    time_elapsed         | 2592       |
|    total_timesteps      | 1613824    |
| train/                  |            |
|    approx_kl            | 0.31316888 |
|    clip_fraction        | 0.436      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.279     |
|    explained_variance   | 0.827      |
|    learning_rate        | 0.00169    |
|    loss                 | -0.0158    |
|    n_updates            | 7870       |
|    policy_gradient_loss | 0.0203     |
|    std                  | 0.281      |
|    value_loss           | 0.0128     |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 789        |
|    time_elapsed         | 2595       |
|    total_timesteps      | 1615872    |
| train/                  |            |
|    approx_kl            | 0.20550174 |
|    clip_fraction        | 0.371      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.332     |
|    explained_variance   | 0.593      |
|    learning_rate        | 0.00169    |
|    loss                 | 0.00903    |
|    n_updates            | 7880       |
|    policy_gradient_loss | -0.00339   |
|    std                  | 0.281      |
|    value_loss           | 0.00425    |
----------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 622       |
|    iterations           | 790       |
|    time_elapsed         | 2599      |
|    total_timesteps      | 1617920   |
| train/                  |           |
|    approx_kl            | 2.3602557 |
|    clip_fraction        | 0.423     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.287    |
|    explained_variance   | 0.654     |
|    learning_rate        | 0.00168   |
|    loss                 | -0.0276   |
|    n_updates            | 7890      |
|    policy_gradient_loss | 0.00849   |
|    std                  | 0.274     |
|    value_loss           | 0.0027    |
---------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 791        |
|    time_elapsed         | 2602       |
|    total_timesteps      | 1619968    |
| train/                  |            |
|    approx_kl            | 0.31590927 |
|    clip_fraction        | 0.39       |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.243     |
|    explained_variance   | 0.909      |
|    learning_rate        | 0.00168    |
|    loss                 | 0.0352     |
|    n_updates            | 7900       |
|    policy_gradient_loss | -0.00315   |
|    std                  | 0.27       |
|    value_loss           | 0.00703    |
----------------------------------------
box reached target
Eval num_timesteps=1620000, episode_reward=0.24 +/- 2.52
Episode length: 267.80 +/- 64.40
--------------------------------------
| eval/                   |          |
|    mean_ep_length       | 268      |
|    mean_reward          | 0.24     |
| time/                   |          |
|    total_timesteps      | 1620000  |
| train/                  |          |
|    approx_kl            | 0.182458 |
|    clip_fraction        | 0.406    |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.204   |
|    explained_variance   | 0.331    |
|    learning_rate        | 0.00168  |
|    loss                 | 0.0206   |
|    n_updates            | 7910     |
|    policy_gradient_loss | 0.00647  |
|    std                  | 0.265    |
|    value_loss           | 0.0782   |
--------------------------------------
--------------------------------
| time/              |         |
|    fps             | 622     |
|    iterations      | 792     |
|    time_elapsed    | 2606    |
|    total_timesteps | 1622016 |
--------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 793        |
|    time_elapsed         | 2609       |
|    total_timesteps      | 1624064    |
| train/                  |            |
|    approx_kl            | 0.09208222 |
|    clip_fraction        | 0.402      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.195     |
|    explained_variance   | 0.674      |
|    learning_rate        | 0.00168    |
|    loss                 | -0.0369    |
|    n_updates            | 7920       |
|    policy_gradient_loss | 0.00553    |
|    std                  | 0.268      |
|    value_loss           | 0.00545    |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 794        |
|    time_elapsed         | 2612       |
|    total_timesteps      | 1626112    |
| train/                  |            |
|    approx_kl            | 0.12200205 |
|    clip_fraction        | 0.384      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.21      |
|    explained_variance   | 0.939      |
|    learning_rate        | 0.00168    |
|    loss                 | -0.00588   |
|    n_updates            | 7930       |
|    policy_gradient_loss | 0.00359    |
|    std                  | 0.27       |
|    value_loss           | 0.00436    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 795        |
|    time_elapsed         | 2615       |
|    total_timesteps      | 1628160    |
| train/                  |            |
|    approx_kl            | 0.19544734 |
|    clip_fraction        | 0.421      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.202     |
|    explained_variance   | 0.954      |
|    learning_rate        | 0.00168    |
|    loss                 | 0.345      |
|    n_updates            | 7940       |
|    policy_gradient_loss | 0.0272     |
|    std                  | 0.265      |
|    value_loss           | 0.0034     |
----------------------------------------
box reached target
Eval num_timesteps=1630000, episode_reward=-1.07 +/- 0.14
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1.07      |
| time/                   |            |
|    total_timesteps      | 1630000    |
| train/                  |            |
|    approx_kl            | 0.21038125 |
|    clip_fraction        | 0.37       |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.164     |
|    explained_variance   | 0.629      |
|    learning_rate        | 0.00168    |
|    loss                 | 0.045      |
|    n_updates            | 7950       |
|    policy_gradient_loss | 0.00264    |
|    std                  | 0.258      |
|    value_loss           | 0.00286    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 622     |
|    iterations      | 796     |
|    time_elapsed    | 2619    |
|    total_timesteps | 1630208 |
--------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 797        |
|    time_elapsed         | 2622       |
|    total_timesteps      | 1632256    |
| train/                  |            |
|    approx_kl            | 0.25430417 |
|    clip_fraction        | 0.445      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.149     |
|    explained_variance   | 0.783      |
|    learning_rate        | 0.00168    |
|    loss                 | -0.00561   |
|    n_updates            | 7960       |
|    policy_gradient_loss | -0.00236   |
|    std                  | 0.259      |
|    value_loss           | 0.0102     |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 798        |
|    time_elapsed         | 2625       |
|    total_timesteps      | 1634304    |
| train/                  |            |
|    approx_kl            | 0.26466995 |
|    clip_fraction        | 0.448      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.104     |
|    explained_variance   | 0.829      |
|    learning_rate        | 0.00168    |
|    loss                 | 0.0605     |
|    n_updates            | 7970       |
|    policy_gradient_loss | 0.0212     |
|    std                  | 0.253      |
|    value_loss           | 0.0138     |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 799        |
|    time_elapsed         | 2628       |
|    total_timesteps      | 1636352    |
| train/                  |            |
|    approx_kl            | 0.18726164 |
|    clip_fraction        | 0.423      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.151     |
|    explained_variance   | 0.616      |
|    learning_rate        | 0.00168    |
|    loss                 | 0.00551    |
|    n_updates            | 7980       |
|    policy_gradient_loss | 0.013      |
|    std                  | 0.264      |
|    value_loss           | 0.00542    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 800        |
|    time_elapsed         | 2631       |
|    total_timesteps      | 1638400    |
| train/                  |            |
|    approx_kl            | 0.27440614 |
|    clip_fraction        | 0.367      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.189     |
|    explained_variance   | 0.571      |
|    learning_rate        | 0.00168    |
|    loss                 | 0.0363     |
|    n_updates            | 7990       |
|    policy_gradient_loss | 0.0138     |
|    std                  | 0.267      |
|    value_loss           | 0.0027     |
----------------------------------------
box reached target
box reached target
Eval num_timesteps=1640000, episode_reward=0.22 +/- 2.49
Episode length: 269.80 +/- 60.40
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 270       |
|    mean_reward          | 0.218     |
| time/                   |           |
|    total_timesteps      | 1640000   |
| train/                  |           |
|    approx_kl            | 0.1597515 |
|    clip_fraction        | 0.356     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.184    |
|    explained_variance   | 0.689     |
|    learning_rate        | 0.00168   |
|    loss                 | -0.0161   |
|    n_updates            | 8000      |
|    policy_gradient_loss | -0.00206  |
|    std                  | 0.262     |
|    value_loss           | 0.00338   |
---------------------------------------
--------------------------------
| time/              |         |
|    fps             | 622     |
|    iterations      | 801     |
|    time_elapsed    | 2635    |
|    total_timesteps | 1640448 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 802        |
|    time_elapsed         | 2639       |
|    total_timesteps      | 1642496    |
| train/                  |            |
|    approx_kl            | 0.23789725 |
|    clip_fraction        | 0.414      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.163     |
|    explained_variance   | 0.813      |
|    learning_rate        | 0.00168    |
|    loss                 | -0.00995   |
|    n_updates            | 8010       |
|    policy_gradient_loss | 0.0114     |
|    std                  | 0.256      |
|    value_loss           | 0.0122     |
----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 622       |
|    iterations           | 803       |
|    time_elapsed         | 2642      |
|    total_timesteps      | 1644544   |
| train/                  |           |
|    approx_kl            | 0.3026664 |
|    clip_fraction        | 0.365     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.134    |
|    explained_variance   | 0.501     |
|    learning_rate        | 0.00168   |
|    loss                 | -0.0203   |
|    n_updates            | 8020      |
|    policy_gradient_loss | 0.0138    |
|    std                  | 0.257     |
|    value_loss           | 0.00215   |
---------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 804        |
|    time_elapsed         | 2645       |
|    total_timesteps      | 1646592    |
| train/                  |            |
|    approx_kl            | 0.16675542 |
|    clip_fraction        | 0.408      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.109     |
|    explained_variance   | 0.169      |
|    learning_rate        | 0.00168    |
|    loss                 | -0.0442    |
|    n_updates            | 8030       |
|    policy_gradient_loss | 0.00364    |
|    std                  | 0.25       |
|    value_loss           | 0.00204    |
----------------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 805        |
|    time_elapsed         | 2648       |
|    total_timesteps      | 1648640    |
| train/                  |            |
|    approx_kl            | 0.22763078 |
|    clip_fraction        | 0.392      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.0666    |
|    explained_variance   | 0.921      |
|    learning_rate        | 0.00168    |
|    loss                 | 0.013      |
|    n_updates            | 8040       |
|    policy_gradient_loss | 0.00216    |
|    std                  | 0.249      |
|    value_loss           | 0.00536    |
----------------------------------------
box reached target
Eval num_timesteps=1650000, episode_reward=0.21 +/- 2.50
Episode length: 270.00 +/- 60.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 270        |
|    mean_reward          | 0.212      |
| time/                   |            |
|    total_timesteps      | 1650000    |
| train/                  |            |
|    approx_kl            | 0.31879464 |
|    clip_fraction        | 0.431      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.068     |
|    explained_variance   | 0.898      |
|    learning_rate        | 0.00168    |
|    loss                 | 0.0244     |
|    n_updates            | 8050       |
|    policy_gradient_loss | 0.0115     |
|    std                  | 0.247      |
|    value_loss           | 0.013      |
----------------------------------------
box reached target
--------------------------------
| time/              |         |
|    fps             | 622     |
|    iterations      | 806     |
|    time_elapsed    | 2652    |
|    total_timesteps | 1650688 |
--------------------------------
box reached target
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 622       |
|    iterations           | 807       |
|    time_elapsed         | 2655      |
|    total_timesteps      | 1652736   |
| train/                  |           |
|    approx_kl            | 0.3134841 |
|    clip_fraction        | 0.465     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0142   |
|    explained_variance   | 0.183     |
|    learning_rate        | 0.00168   |
|    loss                 | 0.0259    |
|    n_updates            | 8060      |
|    policy_gradient_loss | 0.0103    |
|    std                  | 0.241     |
|    value_loss           | 0.0281    |
---------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 808        |
|    time_elapsed         | 2658       |
|    total_timesteps      | 1654784    |
| train/                  |            |
|    approx_kl            | 0.19745971 |
|    clip_fraction        | 0.429      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.00448    |
|    explained_variance   | 0.698      |
|    learning_rate        | 0.00168    |
|    loss                 | -0.0329    |
|    n_updates            | 8070       |
|    policy_gradient_loss | 0.373      |
|    std                  | 0.239      |
|    value_loss           | 0.0264     |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 809        |
|    time_elapsed         | 2661       |
|    total_timesteps      | 1656832    |
| train/                  |            |
|    approx_kl            | 0.13638672 |
|    clip_fraction        | 0.416      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.00907    |
|    explained_variance   | 0.763      |
|    learning_rate        | 0.00168    |
|    loss                 | 0.0716     |
|    n_updates            | 8080       |
|    policy_gradient_loss | 0.0163     |
|    std                  | 0.24       |
|    value_loss           | 0.0221     |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 810        |
|    time_elapsed         | 2664       |
|    total_timesteps      | 1658880    |
| train/                  |            |
|    approx_kl            | 0.12262836 |
|    clip_fraction        | 0.391      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.0443    |
|    explained_variance   | 0.813      |
|    learning_rate        | 0.00168    |
|    loss                 | 0.072      |
|    n_updates            | 8090       |
|    policy_gradient_loss | 0.0162     |
|    std                  | 0.25       |
|    value_loss           | 0.00647    |
----------------------------------------
box reached target
Eval num_timesteps=1660000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1         |
| time/                   |            |
|    total_timesteps      | 1660000    |
| train/                  |            |
|    approx_kl            | 0.28167492 |
|    clip_fraction        | 0.386      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.039     |
|    explained_variance   | 0.497      |
|    learning_rate        | 0.00168    |
|    loss                 | 0.00979    |
|    n_updates            | 8100       |
|    policy_gradient_loss | -0.00378   |
|    std                  | 0.244      |
|    value_loss           | 0.00294    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 622     |
|    iterations      | 811     |
|    time_elapsed    | 2668    |
|    total_timesteps | 1660928 |
--------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 812        |
|    time_elapsed         | 2671       |
|    total_timesteps      | 1662976    |
| train/                  |            |
|    approx_kl            | 0.18993223 |
|    clip_fraction        | 0.377      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.0143    |
|    explained_variance   | 0.94       |
|    learning_rate        | 0.00168    |
|    loss                 | -0.0391    |
|    n_updates            | 8110       |
|    policy_gradient_loss | 0.00801    |
|    std                  | 0.24       |
|    value_loss           | 0.00492    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 813        |
|    time_elapsed         | 2675       |
|    total_timesteps      | 1665024    |
| train/                  |            |
|    approx_kl            | 0.36777872 |
|    clip_fraction        | 0.407      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.0265     |
|    explained_variance   | 0.896      |
|    learning_rate        | 0.00168    |
|    loss                 | 0.024      |
|    n_updates            | 8120       |
|    policy_gradient_loss | 0.00803    |
|    std                  | 0.235      |
|    value_loss           | 0.00646    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 814        |
|    time_elapsed         | 2678       |
|    total_timesteps      | 1667072    |
| train/                  |            |
|    approx_kl            | 0.19024725 |
|    clip_fraction        | 0.447      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.0356    |
|    explained_variance   | 0.704      |
|    learning_rate        | 0.00168    |
|    loss                 | -0.0236    |
|    n_updates            | 8130       |
|    policy_gradient_loss | 0.0281     |
|    std                  | 0.249      |
|    value_loss           | 0.0181     |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 815        |
|    time_elapsed         | 2681       |
|    total_timesteps      | 1669120    |
| train/                  |            |
|    approx_kl            | 0.17929913 |
|    clip_fraction        | 0.389      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.0891    |
|    explained_variance   | 0.593      |
|    learning_rate        | 0.00167    |
|    loss                 | -0.0312    |
|    n_updates            | 8140       |
|    policy_gradient_loss | 0.00757    |
|    std                  | 0.252      |
|    value_loss           | 0.00514    |
----------------------------------------
Eval num_timesteps=1670000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1         |
| time/                   |            |
|    total_timesteps      | 1670000    |
| train/                  |            |
|    approx_kl            | 0.49884707 |
|    clip_fraction        | 0.444      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.0979    |
|    explained_variance   | 0.921      |
|    learning_rate        | 0.00167    |
|    loss                 | 0.0141     |
|    n_updates            | 8150       |
|    policy_gradient_loss | 0.00406    |
|    std                  | 0.251      |
|    value_loss           | 0.00432    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 622     |
|    iterations      | 816     |
|    time_elapsed    | 2685    |
|    total_timesteps | 1671168 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 817        |
|    time_elapsed         | 2688       |
|    total_timesteps      | 1673216    |
| train/                  |            |
|    approx_kl            | 0.10265393 |
|    clip_fraction        | 0.404      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.0796    |
|    explained_variance   | 0.555      |
|    learning_rate        | 0.00167    |
|    loss                 | 0.0778     |
|    n_updates            | 8160       |
|    policy_gradient_loss | 0.00872    |
|    std                  | 0.251      |
|    value_loss           | 0.00419    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 818        |
|    time_elapsed         | 2691       |
|    total_timesteps      | 1675264    |
| train/                  |            |
|    approx_kl            | 0.16363463 |
|    clip_fraction        | 0.4        |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.0751    |
|    explained_variance   | 0.664      |
|    learning_rate        | 0.00167    |
|    loss                 | -0.00438   |
|    n_updates            | 8170       |
|    policy_gradient_loss | 0.0188     |
|    std                  | 0.252      |
|    value_loss           | 0.00493    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 819        |
|    time_elapsed         | 2694       |
|    total_timesteps      | 1677312    |
| train/                  |            |
|    approx_kl            | 0.31908157 |
|    clip_fraction        | 0.4        |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.052     |
|    explained_variance   | -0.612     |
|    learning_rate        | 0.00167    |
|    loss                 | -0.0147    |
|    n_updates            | 8180       |
|    policy_gradient_loss | 0.0211     |
|    std                  | 0.243      |
|    value_loss           | 0.00173    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 820        |
|    time_elapsed         | 2697       |
|    total_timesteps      | 1679360    |
| train/                  |            |
|    approx_kl            | 0.31690344 |
|    clip_fraction        | 0.399      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.01       |
|    explained_variance   | 0.128      |
|    learning_rate        | 0.00167    |
|    loss                 | -0.0516    |
|    n_updates            | 8190       |
|    policy_gradient_loss | 0.000834   |
|    std                  | 0.234      |
|    value_loss           | 0.00357    |
----------------------------------------
Eval num_timesteps=1680000, episode_reward=-0.37 +/- 0.78
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -0.365     |
| time/                   |            |
|    total_timesteps      | 1680000    |
| train/                  |            |
|    approx_kl            | 0.41450176 |
|    clip_fraction        | 0.42       |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.126      |
|    explained_variance   | 0.0548     |
|    learning_rate        | 0.00167    |
|    loss                 | 0.00658    |
|    n_updates            | 8200       |
|    policy_gradient_loss | -0.00289   |
|    std                  | 0.223      |
|    value_loss           | 0.00277    |
----------------------------------------
box reached target
--------------------------------
| time/              |         |
|    fps             | 622     |
|    iterations      | 821     |
|    time_elapsed    | 2701    |
|    total_timesteps | 1681408 |
--------------------------------
box reached target
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 822        |
|    time_elapsed         | 2705       |
|    total_timesteps      | 1683456    |
| train/                  |            |
|    approx_kl            | 0.34026426 |
|    clip_fraction        | 0.503      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.153      |
|    explained_variance   | 0.471      |
|    learning_rate        | 0.00167    |
|    loss                 | 0.018      |
|    n_updates            | 8210       |
|    policy_gradient_loss | 0.0131     |
|    std                  | 0.221      |
|    value_loss           | 0.0515     |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 823        |
|    time_elapsed         | 2708       |
|    total_timesteps      | 1685504    |
| train/                  |            |
|    approx_kl            | 0.23154262 |
|    clip_fraction        | 0.463      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.161      |
|    explained_variance   | 0.445      |
|    learning_rate        | 0.00167    |
|    loss                 | 0.0182     |
|    n_updates            | 8220       |
|    policy_gradient_loss | 0.025      |
|    std                  | 0.224      |
|    value_loss           | 0.0247     |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 824        |
|    time_elapsed         | 2711       |
|    total_timesteps      | 1687552    |
| train/                  |            |
|    approx_kl            | 0.51042724 |
|    clip_fraction        | 0.434      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.186      |
|    explained_variance   | 0.786      |
|    learning_rate        | 0.00167    |
|    loss                 | 0.0291     |
|    n_updates            | 8230       |
|    policy_gradient_loss | 0.0141     |
|    std                  | 0.218      |
|    value_loss           | 0.0159     |
----------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 622       |
|    iterations           | 825       |
|    time_elapsed         | 2714      |
|    total_timesteps      | 1689600   |
| train/                  |           |
|    approx_kl            | 0.2603842 |
|    clip_fraction        | 0.464     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.236     |
|    explained_variance   | 0.894     |
|    learning_rate        | 0.00167   |
|    loss                 | -0.0176   |
|    n_updates            | 8240      |
|    policy_gradient_loss | 0.0103    |
|    std                  | 0.213     |
|    value_loss           | 0.00748   |
---------------------------------------
box reached target
box reached target
box reached target
Eval num_timesteps=1690000, episode_reward=2.81 +/- 2.93
Episode length: 226.20 +/- 60.80
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 226        |
|    mean_reward          | 2.81       |
| time/                   |            |
|    total_timesteps      | 1690000    |
| train/                  |            |
|    approx_kl            | 0.48099875 |
|    clip_fraction        | 0.441      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.208      |
|    explained_variance   | 0.889      |
|    learning_rate        | 0.00167    |
|    loss                 | 0.0297     |
|    n_updates            | 8250       |
|    policy_gradient_loss | 0.0181     |
|    std                  | 0.221      |
|    value_loss           | 0.0115     |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 622     |
|    iterations      | 826     |
|    time_elapsed    | 2718    |
|    total_timesteps | 1691648 |
--------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 827        |
|    time_elapsed         | 2721       |
|    total_timesteps      | 1693696    |
| train/                  |            |
|    approx_kl            | 0.27499652 |
|    clip_fraction        | 0.496      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.104      |
|    explained_variance   | 0.648      |
|    learning_rate        | 0.00167    |
|    loss                 | 0.015      |
|    n_updates            | 8260       |
|    policy_gradient_loss | 0.0261     |
|    std                  | 0.233      |
|    value_loss           | 0.00739    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 828        |
|    time_elapsed         | 2724       |
|    total_timesteps      | 1695744    |
| train/                  |            |
|    approx_kl            | 0.34109712 |
|    clip_fraction        | 0.421      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.127      |
|    explained_variance   | 0.94       |
|    learning_rate        | 0.00167    |
|    loss                 | -0.0145    |
|    n_updates            | 8270       |
|    policy_gradient_loss | 0.0136     |
|    std                  | 0.226      |
|    value_loss           | 0.0042     |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 829        |
|    time_elapsed         | 2727       |
|    total_timesteps      | 1697792    |
| train/                  |            |
|    approx_kl            | 0.36632833 |
|    clip_fraction        | 0.34       |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.109      |
|    explained_variance   | 0.392      |
|    learning_rate        | 0.00167    |
|    loss                 | -0.00145   |
|    n_updates            | 8280       |
|    policy_gradient_loss | 0.007      |
|    std                  | 0.226      |
|    value_loss           | 0.00199    |
----------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 622       |
|    iterations           | 830       |
|    time_elapsed         | 2730      |
|    total_timesteps      | 1699840   |
| train/                  |           |
|    approx_kl            | 0.2194601 |
|    clip_fraction        | 0.405     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.12      |
|    explained_variance   | 0.78      |
|    learning_rate        | 0.00167   |
|    loss                 | -0.011    |
|    n_updates            | 8290      |
|    policy_gradient_loss | 0.0152    |
|    std                  | 0.227     |
|    value_loss           | 0.0163    |
---------------------------------------
Eval num_timesteps=1700000, episode_reward=-0.96 +/- 0.08
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -0.958     |
| time/                   |            |
|    total_timesteps      | 1700000    |
| train/                  |            |
|    approx_kl            | 0.15584357 |
|    clip_fraction        | 0.396      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.0961     |
|    explained_variance   | 0.874      |
|    learning_rate        | 0.00167    |
|    loss                 | -0.0115    |
|    n_updates            | 8300       |
|    policy_gradient_loss | 0.0146     |
|    std                  | 0.231      |
|    value_loss           | 0.0119     |
----------------------------------------
box reached target
--------------------------------
| time/              |         |
|    fps             | 622     |
|    iterations      | 831     |
|    time_elapsed    | 2734    |
|    total_timesteps | 1701888 |
--------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 832        |
|    time_elapsed         | 2737       |
|    total_timesteps      | 1703936    |
| train/                  |            |
|    approx_kl            | 0.27571964 |
|    clip_fraction        | 0.424      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.115      |
|    explained_variance   | 0.826      |
|    learning_rate        | 0.00167    |
|    loss                 | 0.00956    |
|    n_updates            | 8310       |
|    policy_gradient_loss | 0.00603    |
|    std                  | 0.228      |
|    value_loss           | 0.00711    |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 833        |
|    time_elapsed         | 2741       |
|    total_timesteps      | 1705984    |
| train/                  |            |
|    approx_kl            | 0.38478646 |
|    clip_fraction        | 0.453      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.099      |
|    explained_variance   | 0.869      |
|    learning_rate        | 0.00167    |
|    loss                 | 0.0313     |
|    n_updates            | 8320       |
|    policy_gradient_loss | 0.0155     |
|    std                  | 0.235      |
|    value_loss           | 0.00648    |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 834        |
|    time_elapsed         | 2744       |
|    total_timesteps      | 1708032    |
| train/                  |            |
|    approx_kl            | 0.30049002 |
|    clip_fraction        | 0.445      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.0238     |
|    explained_variance   | 0.796      |
|    learning_rate        | 0.00167    |
|    loss                 | -0.0591    |
|    n_updates            | 8330       |
|    policy_gradient_loss | 0.0109     |
|    std                  | 0.241      |
|    value_loss           | 0.01       |
----------------------------------------
box reached target
box reached target
box reached target
Eval num_timesteps=1710000, episode_reward=2.15 +/- 2.67
Episode length: 254.60 +/- 55.61
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 255        |
|    mean_reward          | 2.15       |
| time/                   |            |
|    total_timesteps      | 1710000    |
| train/                  |            |
|    approx_kl            | 0.13093647 |
|    clip_fraction        | 0.436      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.0231     |
|    explained_variance   | 0.689      |
|    learning_rate        | 0.00167    |
|    loss                 | 0.0949     |
|    n_updates            | 8340       |
|    policy_gradient_loss | 0.0187     |
|    std                  | 0.237      |
|    value_loss           | 0.00647    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 622     |
|    iterations      | 835     |
|    time_elapsed    | 2748    |
|    total_timesteps | 1710080 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 836        |
|    time_elapsed         | 2751       |
|    total_timesteps      | 1712128    |
| train/                  |            |
|    approx_kl            | 0.13941175 |
|    clip_fraction        | 0.411      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.00556    |
|    explained_variance   | 0.667      |
|    learning_rate        | 0.00167    |
|    loss                 | -0.0344    |
|    n_updates            | 8350       |
|    policy_gradient_loss | 0.015      |
|    std                  | 0.247      |
|    value_loss           | 0.0236     |
----------------------------------------
box reached target
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 622       |
|    iterations           | 837       |
|    time_elapsed         | 2754      |
|    total_timesteps      | 1714176   |
| train/                  |           |
|    approx_kl            | 0.5855062 |
|    clip_fraction        | 0.417     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0577   |
|    explained_variance   | 0.33      |
|    learning_rate        | 0.00167   |
|    loss                 | 0.00572   |
|    n_updates            | 8360      |
|    policy_gradient_loss | 0.0148    |
|    std                  | 0.245     |
|    value_loss           | 0.00226   |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 838        |
|    time_elapsed         | 2757       |
|    total_timesteps      | 1716224    |
| train/                  |            |
|    approx_kl            | 0.17400816 |
|    clip_fraction        | 0.438      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.0138    |
|    explained_variance   | 0.836      |
|    learning_rate        | 0.00167    |
|    loss                 | -0.0154    |
|    n_updates            | 8370       |
|    policy_gradient_loss | 0.0105     |
|    std                  | 0.243      |
|    value_loss           | 0.0219     |
----------------------------------------
box reached target
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 839        |
|    time_elapsed         | 2760       |
|    total_timesteps      | 1718272    |
| train/                  |            |
|    approx_kl            | 0.59462404 |
|    clip_fraction        | 0.436      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.018     |
|    explained_variance   | 0.539      |
|    learning_rate        | 0.00167    |
|    loss                 | -0.000984  |
|    n_updates            | 8380       |
|    policy_gradient_loss | 0.00673    |
|    std                  | 0.242      |
|    value_loss           | 0.00247    |
----------------------------------------
box reached target
box reached target
box reached target
Eval num_timesteps=1720000, episode_reward=2.74 +/- 3.06
Episode length: 227.80 +/- 64.01
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 228        |
|    mean_reward          | 2.74       |
| time/                   |            |
|    total_timesteps      | 1720000    |
| train/                  |            |
|    approx_kl            | 0.64767194 |
|    clip_fraction        | 0.505      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.0864     |
|    explained_variance   | 0.803      |
|    learning_rate        | 0.00166    |
|    loss                 | 0.112      |
|    n_updates            | 8390       |
|    policy_gradient_loss | 0.00441    |
|    std                  | 0.227      |
|    value_loss           | 0.0127     |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 622     |
|    iterations      | 840     |
|    time_elapsed    | 2764    |
|    total_timesteps | 1720320 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 841        |
|    time_elapsed         | 2767       |
|    total_timesteps      | 1722368    |
| train/                  |            |
|    approx_kl            | 0.24837792 |
|    clip_fraction        | 0.443      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.103      |
|    explained_variance   | 0.713      |
|    learning_rate        | 0.00166    |
|    loss                 | 0.22       |
|    n_updates            | 8400       |
|    policy_gradient_loss | 0.0276     |
|    std                  | 0.234      |
|    value_loss           | 0.0197     |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 842        |
|    time_elapsed         | 2770       |
|    total_timesteps      | 1724416    |
| train/                  |            |
|    approx_kl            | 0.23656243 |
|    clip_fraction        | 0.431      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.0432     |
|    explained_variance   | 0.744      |
|    learning_rate        | 0.00166    |
|    loss                 | 0.071      |
|    n_updates            | 8410       |
|    policy_gradient_loss | 0.0201     |
|    std                  | 0.236      |
|    value_loss           | 0.0122     |
----------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 622       |
|    iterations           | 843       |
|    time_elapsed         | 2773      |
|    total_timesteps      | 1726464   |
| train/                  |           |
|    approx_kl            | 0.4087726 |
|    clip_fraction        | 0.405     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.0355    |
|    explained_variance   | 0.593     |
|    learning_rate        | 0.00166   |
|    loss                 | 0.0138    |
|    n_updates            | 8420      |
|    policy_gradient_loss | 0.0232    |
|    std                  | 0.236     |
|    value_loss           | 0.0115    |
---------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 622       |
|    iterations           | 844       |
|    time_elapsed         | 2776      |
|    total_timesteps      | 1728512   |
| train/                  |           |
|    approx_kl            | 0.4509274 |
|    clip_fraction        | 0.486     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.0362    |
|    explained_variance   | 0.508     |
|    learning_rate        | 0.00166   |
|    loss                 | 0.116     |
|    n_updates            | 8430      |
|    policy_gradient_loss | 0.018     |
|    std                  | 0.238     |
|    value_loss           | 0.0219    |
---------------------------------------
box reached target
box reached target
box reached target
box reached target
Eval num_timesteps=1730000, episode_reward=1.63 +/- 2.89
Episode length: 260.20 +/- 52.42
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 260        |
|    mean_reward          | 1.63       |
| time/                   |            |
|    total_timesteps      | 1730000    |
| train/                  |            |
|    approx_kl            | 0.23294342 |
|    clip_fraction        | 0.413      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.0236     |
|    explained_variance   | 0.726      |
|    learning_rate        | 0.00166    |
|    loss                 | -0.00753   |
|    n_updates            | 8440       |
|    policy_gradient_loss | 0.00192    |
|    std                  | 0.236      |
|    value_loss           | 0.00428    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 622     |
|    iterations      | 845     |
|    time_elapsed    | 2780    |
|    total_timesteps | 1730560 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 846        |
|    time_elapsed         | 2783       |
|    total_timesteps      | 1732608    |
| train/                  |            |
|    approx_kl            | 0.20879345 |
|    clip_fraction        | 0.393      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.0544     |
|    explained_variance   | 0.797      |
|    learning_rate        | 0.00166    |
|    loss                 | -0.00654   |
|    n_updates            | 8450       |
|    policy_gradient_loss | 0.00717    |
|    std                  | 0.236      |
|    value_loss           | 0.0205     |
----------------------------------------
box reached target
box reached target
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 847        |
|    time_elapsed         | 2786       |
|    total_timesteps      | 1734656    |
| train/                  |            |
|    approx_kl            | 0.19329709 |
|    clip_fraction        | 0.414      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.0506     |
|    explained_variance   | 0.604      |
|    learning_rate        | 0.00166    |
|    loss                 | 0.0616     |
|    n_updates            | 8460       |
|    policy_gradient_loss | 0.0106     |
|    std                  | 0.234      |
|    value_loss           | 0.00535    |
----------------------------------------
box reached target
box reached target
box reached target
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 622       |
|    iterations           | 848       |
|    time_elapsed         | 2790      |
|    total_timesteps      | 1736704   |
| train/                  |           |
|    approx_kl            | 0.3103524 |
|    clip_fraction        | 0.477     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.105     |
|    explained_variance   | 0.474     |
|    learning_rate        | 0.00166   |
|    loss                 | -0.00176  |
|    n_updates            | 8470      |
|    policy_gradient_loss | 0.0123    |
|    std                  | 0.225     |
|    value_loss           | 0.149     |
---------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 849        |
|    time_elapsed         | 2793       |
|    total_timesteps      | 1738752    |
| train/                  |            |
|    approx_kl            | 0.12256012 |
|    clip_fraction        | 0.37       |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.117      |
|    explained_variance   | 0.77       |
|    learning_rate        | 0.00166    |
|    loss                 | -0.000134  |
|    n_updates            | 8480       |
|    policy_gradient_loss | 0.0109     |
|    std                  | 0.23       |
|    value_loss           | 0.0828     |
----------------------------------------
Eval num_timesteps=1740000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1         |
| time/                   |            |
|    total_timesteps      | 1740000    |
| train/                  |            |
|    approx_kl            | 0.20693517 |
|    clip_fraction        | 0.463      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.0706     |
|    explained_variance   | 0.463      |
|    learning_rate        | 0.00166    |
|    loss                 | 0.0025     |
|    n_updates            | 8490       |
|    policy_gradient_loss | 0.0283     |
|    std                  | 0.233      |
|    value_loss           | 0.0225     |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 622     |
|    iterations      | 850     |
|    time_elapsed    | 2797    |
|    total_timesteps | 1740800 |
--------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 851        |
|    time_elapsed         | 2800       |
|    total_timesteps      | 1742848    |
| train/                  |            |
|    approx_kl            | 0.14677933 |
|    clip_fraction        | 0.36       |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.0721     |
|    explained_variance   | 0.631      |
|    learning_rate        | 0.00166    |
|    loss                 | 0.00974    |
|    n_updates            | 8500       |
|    policy_gradient_loss | 0.0137     |
|    std                  | 0.234      |
|    value_loss           | 0.0148     |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 852        |
|    time_elapsed         | 2803       |
|    total_timesteps      | 1744896    |
| train/                  |            |
|    approx_kl            | 0.25409925 |
|    clip_fraction        | 0.472      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.077      |
|    explained_variance   | 0.682      |
|    learning_rate        | 0.00166    |
|    loss                 | 0.0522     |
|    n_updates            | 8510       |
|    policy_gradient_loss | 0.0144     |
|    std                  | 0.232      |
|    value_loss           | 0.0227     |
----------------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 853        |
|    time_elapsed         | 2806       |
|    total_timesteps      | 1746944    |
| train/                  |            |
|    approx_kl            | 0.16743743 |
|    clip_fraction        | 0.413      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.0314     |
|    explained_variance   | 0.811      |
|    learning_rate        | 0.00166    |
|    loss                 | -0.00189   |
|    n_updates            | 8520       |
|    policy_gradient_loss | 0.00722    |
|    std                  | 0.239      |
|    value_loss           | 0.04       |
----------------------------------------
box reached target
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 854        |
|    time_elapsed         | 2809       |
|    total_timesteps      | 1748992    |
| train/                  |            |
|    approx_kl            | 0.57560456 |
|    clip_fraction        | 0.47       |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.0184     |
|    explained_variance   | 0.725      |
|    learning_rate        | 0.00166    |
|    loss                 | -0.0308    |
|    n_updates            | 8530       |
|    policy_gradient_loss | 0.012      |
|    std                  | 0.239      |
|    value_loss           | 0.0215     |
----------------------------------------
box reached target
box reached target
box reached target
Eval num_timesteps=1750000, episode_reward=1.74 +/- 2.90
Episode length: 255.60 +/- 54.56
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 256        |
|    mean_reward          | 1.74       |
| time/                   |            |
|    total_timesteps      | 1750000    |
| train/                  |            |
|    approx_kl            | 0.39504945 |
|    clip_fraction        | 0.424      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.0196    |
|    explained_variance   | 0.912      |
|    learning_rate        | 0.00166    |
|    loss                 | -0.0205    |
|    n_updates            | 8540       |
|    policy_gradient_loss | 0.0099     |
|    std                  | 0.245      |
|    value_loss           | 0.0137     |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 622     |
|    iterations      | 855     |
|    time_elapsed    | 2813    |
|    total_timesteps | 1751040 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 856        |
|    time_elapsed         | 2816       |
|    total_timesteps      | 1753088    |
| train/                  |            |
|    approx_kl            | 0.23700188 |
|    clip_fraction        | 0.413      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.00604    |
|    explained_variance   | 0.757      |
|    learning_rate        | 0.00166    |
|    loss                 | 0.0186     |
|    n_updates            | 8550       |
|    policy_gradient_loss | 0.00973    |
|    std                  | 0.238      |
|    value_loss           | 0.0171     |
----------------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 857        |
|    time_elapsed         | 2819       |
|    total_timesteps      | 1755136    |
| train/                  |            |
|    approx_kl            | 0.43231547 |
|    clip_fraction        | 0.425      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.0186     |
|    explained_variance   | 0.791      |
|    learning_rate        | 0.00166    |
|    loss                 | -0.0274    |
|    n_updates            | 8560       |
|    policy_gradient_loss | -0.00133   |
|    std                  | 0.237      |
|    value_loss           | 0.00614    |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 858        |
|    time_elapsed         | 2822       |
|    total_timesteps      | 1757184    |
| train/                  |            |
|    approx_kl            | 0.18603477 |
|    clip_fraction        | 0.448      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.02       |
|    explained_variance   | 0.821      |
|    learning_rate        | 0.00166    |
|    loss                 | 0.0147     |
|    n_updates            | 8570       |
|    policy_gradient_loss | 0.0151     |
|    std                  | 0.24       |
|    value_loss           | 0.028      |
----------------------------------------
box reached target
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 859        |
|    time_elapsed         | 2826       |
|    total_timesteps      | 1759232    |
| train/                  |            |
|    approx_kl            | 0.46285576 |
|    clip_fraction        | 0.477      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.00925    |
|    explained_variance   | 0.619      |
|    learning_rate        | 0.00166    |
|    loss                 | 0.00478    |
|    n_updates            | 8580       |
|    policy_gradient_loss | 0.0195     |
|    std                  | 0.241      |
|    value_loss           | 0.0232     |
----------------------------------------
box reached target
Eval num_timesteps=1760000, episode_reward=0.25 +/- 2.50
Episode length: 277.00 +/- 46.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 277        |
|    mean_reward          | 0.249      |
| time/                   |            |
|    total_timesteps      | 1760000    |
| train/                  |            |
|    approx_kl            | 0.27394432 |
|    clip_fraction        | 0.407      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.000946  |
|    explained_variance   | 0.615      |
|    learning_rate        | 0.00166    |
|    loss                 | 0.0163     |
|    n_updates            | 8590       |
|    policy_gradient_loss | 0.0192     |
|    std                  | 0.243      |
|    value_loss           | 0.0391     |
----------------------------------------
box reached target
box reached target
--------------------------------
| time/              |         |
|    fps             | 622     |
|    iterations      | 860     |
|    time_elapsed    | 2830    |
|    total_timesteps | 1761280 |
--------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 861        |
|    time_elapsed         | 2833       |
|    total_timesteps      | 1763328    |
| train/                  |            |
|    approx_kl            | 0.15845227 |
|    clip_fraction        | 0.428      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.0227    |
|    explained_variance   | 0.941      |
|    learning_rate        | 0.00166    |
|    loss                 | 0.0166     |
|    n_updates            | 8600       |
|    policy_gradient_loss | 0.0123     |
|    std                  | 0.247      |
|    value_loss           | 0.0142     |
----------------------------------------
box reached target
box reached target
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 862        |
|    time_elapsed         | 2836       |
|    total_timesteps      | 1765376    |
| train/                  |            |
|    approx_kl            | 0.21115066 |
|    clip_fraction        | 0.442      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.086     |
|    explained_variance   | 0.8        |
|    learning_rate        | 0.00166    |
|    loss                 | -0.0282    |
|    n_updates            | 8610       |
|    policy_gradient_loss | 0.0168     |
|    std                  | 0.255      |
|    value_loss           | 0.0168     |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 863        |
|    time_elapsed         | 2839       |
|    total_timesteps      | 1767424    |
| train/                  |            |
|    approx_kl            | 0.16292003 |
|    clip_fraction        | 0.407      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.108     |
|    explained_variance   | 0.675      |
|    learning_rate        | 0.00166    |
|    loss                 | 0.0269     |
|    n_updates            | 8620       |
|    policy_gradient_loss | 0.014      |
|    std                  | 0.252      |
|    value_loss           | 0.0444     |
----------------------------------------
box reached target
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 864        |
|    time_elapsed         | 2842       |
|    total_timesteps      | 1769472    |
| train/                  |            |
|    approx_kl            | 0.20464677 |
|    clip_fraction        | 0.433      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.127     |
|    explained_variance   | 0.792      |
|    learning_rate        | 0.00166    |
|    loss                 | -0.00257   |
|    n_updates            | 8630       |
|    policy_gradient_loss | 0.0146     |
|    std                  | 0.261      |
|    value_loss           | 0.0226     |
----------------------------------------
box reached target
Eval num_timesteps=1770000, episode_reward=0.21 +/- 2.56
Episode length: 273.40 +/- 53.20
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 273        |
|    mean_reward          | 0.213      |
| time/                   |            |
|    total_timesteps      | 1770000    |
| train/                  |            |
|    approx_kl            | 0.15460388 |
|    clip_fraction        | 0.406      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.154     |
|    explained_variance   | 0.903      |
|    learning_rate        | 0.00165    |
|    loss                 | -0.0376    |
|    n_updates            | 8640       |
|    policy_gradient_loss | 0.0132     |
|    std                  | 0.261      |
|    value_loss           | 0.015      |
----------------------------------------
box reached target
box reached target
--------------------------------
| time/              |         |
|    fps             | 622     |
|    iterations      | 865     |
|    time_elapsed    | 2846    |
|    total_timesteps | 1771520 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 866        |
|    time_elapsed         | 2849       |
|    total_timesteps      | 1773568    |
| train/                  |            |
|    approx_kl            | 0.20172992 |
|    clip_fraction        | 0.423      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.0845    |
|    explained_variance   | 0.413      |
|    learning_rate        | 0.00165    |
|    loss                 | -0.00225   |
|    n_updates            | 8650       |
|    policy_gradient_loss | 0.00435    |
|    std                  | 0.247      |
|    value_loss           | 0.0386     |
----------------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 867        |
|    time_elapsed         | 2852       |
|    total_timesteps      | 1775616    |
| train/                  |            |
|    approx_kl            | 0.27961627 |
|    clip_fraction        | 0.428      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.0525    |
|    explained_variance   | 0.866      |
|    learning_rate        | 0.00165    |
|    loss                 | 0.151      |
|    n_updates            | 8660       |
|    policy_gradient_loss | 0.0141     |
|    std                  | 0.249      |
|    value_loss           | 0.00818    |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 868        |
|    time_elapsed         | 2855       |
|    total_timesteps      | 1777664    |
| train/                  |            |
|    approx_kl            | 0.09905933 |
|    clip_fraction        | 0.351      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.0622    |
|    explained_variance   | 0.92       |
|    learning_rate        | 0.00165    |
|    loss                 | 0.102      |
|    n_updates            | 8670       |
|    policy_gradient_loss | 0.00932    |
|    std                  | 0.251      |
|    value_loss           | 0.015      |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 869        |
|    time_elapsed         | 2858       |
|    total_timesteps      | 1779712    |
| train/                  |            |
|    approx_kl            | 0.13043198 |
|    clip_fraction        | 0.404      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.13      |
|    explained_variance   | 0.737      |
|    learning_rate        | 0.00165    |
|    loss                 | -0.0225    |
|    n_updates            | 8680       |
|    policy_gradient_loss | 0.0167     |
|    std                  | 0.262      |
|    value_loss           | 0.0165     |
----------------------------------------
box reached target
box reached target
box reached target
Eval num_timesteps=1780000, episode_reward=2.75 +/- 3.07
Episode length: 233.40 +/- 57.35
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 233       |
|    mean_reward          | 2.75      |
| time/                   |           |
|    total_timesteps      | 1780000   |
| train/                  |           |
|    approx_kl            | 0.2170707 |
|    clip_fraction        | 0.398     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.192    |
|    explained_variance   | 0.515     |
|    learning_rate        | 0.00165   |
|    loss                 | -0.0272   |
|    n_updates            | 8690      |
|    policy_gradient_loss | 0.0123    |
|    std                  | 0.266     |
|    value_loss           | 0.00456   |
---------------------------------------
box reached target
box reached target
--------------------------------
| time/              |         |
|    fps             | 622     |
|    iterations      | 870     |
|    time_elapsed    | 2862    |
|    total_timesteps | 1781760 |
--------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 622       |
|    iterations           | 871       |
|    time_elapsed         | 2865      |
|    total_timesteps      | 1783808   |
| train/                  |           |
|    approx_kl            | 0.1718161 |
|    clip_fraction        | 0.382     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.186    |
|    explained_variance   | 0.888     |
|    learning_rate        | 0.00165   |
|    loss                 | -0.00851  |
|    n_updates            | 8700      |
|    policy_gradient_loss | 0.0186    |
|    std                  | 0.265     |
|    value_loss           | 0.0122    |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 872        |
|    time_elapsed         | 2868       |
|    total_timesteps      | 1785856    |
| train/                  |            |
|    approx_kl            | 0.23799697 |
|    clip_fraction        | 0.418      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.2       |
|    explained_variance   | 0.771      |
|    learning_rate        | 0.00165    |
|    loss                 | -0.0333    |
|    n_updates            | 8710       |
|    policy_gradient_loss | 0.021      |
|    std                  | 0.271      |
|    value_loss           | 0.0119     |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 873        |
|    time_elapsed         | 2872       |
|    total_timesteps      | 1787904    |
| train/                  |            |
|    approx_kl            | 0.12701786 |
|    clip_fraction        | 0.378      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.231     |
|    explained_variance   | 0.715      |
|    learning_rate        | 0.00165    |
|    loss                 | 0.000731   |
|    n_updates            | 8720       |
|    policy_gradient_loss | 0.0106     |
|    std                  | 0.275      |
|    value_loss           | 0.0133     |
----------------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 874        |
|    time_elapsed         | 2875       |
|    total_timesteps      | 1789952    |
| train/                  |            |
|    approx_kl            | 0.37363687 |
|    clip_fraction        | 0.414      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.22      |
|    explained_variance   | 0.804      |
|    learning_rate        | 0.00165    |
|    loss                 | -0.0224    |
|    n_updates            | 8730       |
|    policy_gradient_loss | 0.00203    |
|    std                  | 0.267      |
|    value_loss           | 0.00831    |
----------------------------------------
box reached target
Eval num_timesteps=1790000, episode_reward=0.48 +/- 2.55
Episode length: 293.20 +/- 13.60
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 293       |
|    mean_reward          | 0.485     |
| time/                   |           |
|    total_timesteps      | 1790000   |
| train/                  |           |
|    approx_kl            | 0.2515951 |
|    clip_fraction        | 0.413     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.278    |
|    explained_variance   | 0.909     |
|    learning_rate        | 0.00165   |
|    loss                 | -0.0169   |
|    n_updates            | 8740      |
|    policy_gradient_loss | 0.00533   |
|    std                  | 0.281     |
|    value_loss           | 0.0101    |
---------------------------------------
box reached target
box reached target
--------------------------------
| time/              |         |
|    fps             | 622     |
|    iterations      | 875     |
|    time_elapsed    | 2879    |
|    total_timesteps | 1792000 |
--------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 622       |
|    iterations           | 876       |
|    time_elapsed         | 2882      |
|    total_timesteps      | 1794048   |
| train/                  |           |
|    approx_kl            | 0.0969137 |
|    clip_fraction        | 0.369     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.323    |
|    explained_variance   | 0.902     |
|    learning_rate        | 0.00165   |
|    loss                 | 0.0601    |
|    n_updates            | 8750      |
|    policy_gradient_loss | 0.0134    |
|    std                  | 0.285     |
|    value_loss           | 0.0158    |
---------------------------------------
box reached target
box reached target
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 622       |
|    iterations           | 877       |
|    time_elapsed         | 2885      |
|    total_timesteps      | 1796096   |
| train/                  |           |
|    approx_kl            | 0.1384462 |
|    clip_fraction        | 0.383     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.336    |
|    explained_variance   | 0.894     |
|    learning_rate        | 0.00165   |
|    loss                 | -0.0103   |
|    n_updates            | 8760      |
|    policy_gradient_loss | 0.0126    |
|    std                  | 0.286     |
|    value_loss           | 0.00774   |
---------------------------------------
box reached target
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 878        |
|    time_elapsed         | 2888       |
|    total_timesteps      | 1798144    |
| train/                  |            |
|    approx_kl            | 0.21797094 |
|    clip_fraction        | 0.436      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.328     |
|    explained_variance   | 0.74       |
|    learning_rate        | 0.00165    |
|    loss                 | 0.0162     |
|    n_updates            | 8770       |
|    policy_gradient_loss | 0.017      |
|    std                  | 0.285      |
|    value_loss           | 0.0228     |
----------------------------------------
box reached target
box reached target
box reached target
Eval num_timesteps=1800000, episode_reward=1.62 +/- 3.20
Episode length: 275.40 +/- 32.10
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 275        |
|    mean_reward          | 1.62       |
| time/                   |            |
|    total_timesteps      | 1800000    |
| train/                  |            |
|    approx_kl            | 0.13111797 |
|    clip_fraction        | 0.376      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.332     |
|    explained_variance   | 0.893      |
|    learning_rate        | 0.00165    |
|    loss                 | 0.017      |
|    n_updates            | 8780       |
|    policy_gradient_loss | 0.00414    |
|    std                  | 0.288      |
|    value_loss           | 0.028      |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 622     |
|    iterations      | 879     |
|    time_elapsed    | 2892    |
|    total_timesteps | 1800192 |
--------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 622       |
|    iterations           | 880       |
|    time_elapsed         | 2895      |
|    total_timesteps      | 1802240   |
| train/                  |           |
|    approx_kl            | 0.0729883 |
|    clip_fraction        | 0.372     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.36     |
|    explained_variance   | 0.832     |
|    learning_rate        | 0.00165   |
|    loss                 | -0.000668 |
|    n_updates            | 8790      |
|    policy_gradient_loss | 0.0047    |
|    std                  | 0.29      |
|    value_loss           | 0.0234    |
---------------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 881        |
|    time_elapsed         | 2898       |
|    total_timesteps      | 1804288    |
| train/                  |            |
|    approx_kl            | 0.09459752 |
|    clip_fraction        | 0.373      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.356     |
|    explained_variance   | 0.578      |
|    learning_rate        | 0.00165    |
|    loss                 | -0.00314   |
|    n_updates            | 8800       |
|    policy_gradient_loss | 0.00329    |
|    std                  | 0.287      |
|    value_loss           | 0.0109     |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 882        |
|    time_elapsed         | 2901       |
|    total_timesteps      | 1806336    |
| train/                  |            |
|    approx_kl            | 0.09987871 |
|    clip_fraction        | 0.357      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.317     |
|    explained_variance   | 0.894      |
|    learning_rate        | 0.00165    |
|    loss                 | 0.0109     |
|    n_updates            | 8810       |
|    policy_gradient_loss | -0.00423   |
|    std                  | 0.281      |
|    value_loss           | 0.0117     |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 883        |
|    time_elapsed         | 2904       |
|    total_timesteps      | 1808384    |
| train/                  |            |
|    approx_kl            | 0.14897746 |
|    clip_fraction        | 0.407      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.311     |
|    explained_variance   | 0.843      |
|    learning_rate        | 0.00165    |
|    loss                 | 0.0138     |
|    n_updates            | 8820       |
|    policy_gradient_loss | 0.000136   |
|    std                  | 0.283      |
|    value_loss           | 0.0115     |
----------------------------------------
box reached target
box reached target
Eval num_timesteps=1810000, episode_reward=-0.74 +/- 0.52
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -0.741     |
| time/                   |            |
|    total_timesteps      | 1810000    |
| train/                  |            |
|    approx_kl            | 0.07726535 |
|    clip_fraction        | 0.399      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.338     |
|    explained_variance   | 0.616      |
|    learning_rate        | 0.00165    |
|    loss                 | 0.0198     |
|    n_updates            | 8830       |
|    policy_gradient_loss | 0.0116     |
|    std                  | 0.291      |
|    value_loss           | 0.043      |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 622     |
|    iterations      | 884     |
|    time_elapsed    | 2908    |
|    total_timesteps | 1810432 |
--------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 622       |
|    iterations           | 885       |
|    time_elapsed         | 2911      |
|    total_timesteps      | 1812480   |
| train/                  |           |
|    approx_kl            | 0.3000266 |
|    clip_fraction        | 0.409     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.362    |
|    explained_variance   | 0.853     |
|    learning_rate        | 0.00165   |
|    loss                 | -0.0211   |
|    n_updates            | 8840      |
|    policy_gradient_loss | 0.00341   |
|    std                  | 0.286     |
|    value_loss           | 0.0257    |
---------------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 622         |
|    iterations           | 886         |
|    time_elapsed         | 2914        |
|    total_timesteps      | 1814528     |
| train/                  |             |
|    approx_kl            | 0.105933905 |
|    clip_fraction        | 0.341       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.326      |
|    explained_variance   | 0.646       |
|    learning_rate        | 0.00165     |
|    loss                 | 0.0166      |
|    n_updates            | 8850        |
|    policy_gradient_loss | 0.00986     |
|    std                  | 0.287       |
|    value_loss           | 0.0114      |
-----------------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 887        |
|    time_elapsed         | 2917       |
|    total_timesteps      | 1816576    |
| train/                  |            |
|    approx_kl            | 0.13429175 |
|    clip_fraction        | 0.388      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.373     |
|    explained_variance   | 0.886      |
|    learning_rate        | 0.00165    |
|    loss                 | 0.0501     |
|    n_updates            | 8860       |
|    policy_gradient_loss | 0.00487    |
|    std                  | 0.293      |
|    value_loss           | 0.0112     |
----------------------------------------
box reached target
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 888        |
|    time_elapsed         | 2920       |
|    total_timesteps      | 1818624    |
| train/                  |            |
|    approx_kl            | 0.34992868 |
|    clip_fraction        | 0.444      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.399     |
|    explained_variance   | 0.966      |
|    learning_rate        | 0.00165    |
|    loss                 | -0.0456    |
|    n_updates            | 8870       |
|    policy_gradient_loss | 0.00843    |
|    std                  | 0.291      |
|    value_loss           | 0.0058     |
----------------------------------------
box reached target
box reached target
Eval num_timesteps=1820000, episode_reward=0.75 +/- 2.33
Episode length: 270.00 +/- 60.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 270        |
|    mean_reward          | 0.748      |
| time/                   |            |
|    total_timesteps      | 1820000    |
| train/                  |            |
|    approx_kl            | 0.40304232 |
|    clip_fraction        | 0.388      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.305     |
|    explained_variance   | 0.783      |
|    learning_rate        | 0.00165    |
|    loss                 | 0.00738    |
|    n_updates            | 8880       |
|    policy_gradient_loss | -0.00233   |
|    std                  | 0.276      |
|    value_loss           | 0.0338     |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 622     |
|    iterations      | 889     |
|    time_elapsed    | 2924    |
|    total_timesteps | 1820672 |
--------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 622       |
|    iterations           | 890       |
|    time_elapsed         | 2927      |
|    total_timesteps      | 1822720   |
| train/                  |           |
|    approx_kl            | 0.3169512 |
|    clip_fraction        | 0.37      |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.273    |
|    explained_variance   | 0.964     |
|    learning_rate        | 0.00164   |
|    loss                 | 0.00183   |
|    n_updates            | 8890      |
|    policy_gradient_loss | 0.00403   |
|    std                  | 0.273     |
|    value_loss           | 0.00566   |
---------------------------------------
box reached target
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 891        |
|    time_elapsed         | 2930       |
|    total_timesteps      | 1824768    |
| train/                  |            |
|    approx_kl            | 0.14333633 |
|    clip_fraction        | 0.376      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.249     |
|    explained_variance   | 0.906      |
|    learning_rate        | 0.00164    |
|    loss                 | 0.0544     |
|    n_updates            | 8900       |
|    policy_gradient_loss | 0.00488    |
|    std                  | 0.273      |
|    value_loss           | 0.0125     |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 892        |
|    time_elapsed         | 2933       |
|    total_timesteps      | 1826816    |
| train/                  |            |
|    approx_kl            | 0.16363963 |
|    clip_fraction        | 0.373      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.22      |
|    explained_variance   | 0.808      |
|    learning_rate        | 0.00164    |
|    loss                 | -0.043     |
|    n_updates            | 8910       |
|    policy_gradient_loss | -0.000186  |
|    std                  | 0.265      |
|    value_loss           | 0.0513     |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 893        |
|    time_elapsed         | 2937       |
|    total_timesteps      | 1828864    |
| train/                  |            |
|    approx_kl            | 0.24164039 |
|    clip_fraction        | 0.353      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.192     |
|    explained_variance   | 0.948      |
|    learning_rate        | 0.00164    |
|    loss                 | 0.0266     |
|    n_updates            | 8920       |
|    policy_gradient_loss | 0.00556    |
|    std                  | 0.266      |
|    value_loss           | 0.00749    |
----------------------------------------
box reached target
box reached target
box reached target
Eval num_timesteps=1830000, episode_reward=2.73 +/- 3.05
Episode length: 226.60 +/- 60.30
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 227        |
|    mean_reward          | 2.73       |
| time/                   |            |
|    total_timesteps      | 1830000    |
| train/                  |            |
|    approx_kl            | 0.20503941 |
|    clip_fraction        | 0.398      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.229     |
|    explained_variance   | 0.659      |
|    learning_rate        | 0.00164    |
|    loss                 | -0.00982   |
|    n_updates            | 8930       |
|    policy_gradient_loss | 0.0166     |
|    std                  | 0.274      |
|    value_loss           | 0.00739    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 622     |
|    iterations      | 894     |
|    time_elapsed    | 2940    |
|    total_timesteps | 1830912 |
--------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 895        |
|    time_elapsed         | 2943       |
|    total_timesteps      | 1832960    |
| train/                  |            |
|    approx_kl            | 0.22805747 |
|    clip_fraction        | 0.371      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.261     |
|    explained_variance   | 0.428      |
|    learning_rate        | 0.00164    |
|    loss                 | 0.00484    |
|    n_updates            | 8940       |
|    policy_gradient_loss | 0.00599    |
|    std                  | 0.276      |
|    value_loss           | 0.00325    |
----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 622       |
|    iterations           | 896       |
|    time_elapsed         | 2946      |
|    total_timesteps      | 1835008   |
| train/                  |           |
|    approx_kl            | 2.4827514 |
|    clip_fraction        | 0.446     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.248    |
|    explained_variance   | 0.858     |
|    learning_rate        | 0.00164   |
|    loss                 | 0.0372    |
|    n_updates            | 8950      |
|    policy_gradient_loss | 0.0438    |
|    std                  | 0.272     |
|    value_loss           | 0.0337    |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 897        |
|    time_elapsed         | 2950       |
|    total_timesteps      | 1837056    |
| train/                  |            |
|    approx_kl            | 0.13643081 |
|    clip_fraction        | 0.402      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.271     |
|    explained_variance   | 0.64       |
|    learning_rate        | 0.00164    |
|    loss                 | 0.0217     |
|    n_updates            | 8960       |
|    policy_gradient_loss | 0.00863    |
|    std                  | 0.278      |
|    value_loss           | 0.0112     |
----------------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 898        |
|    time_elapsed         | 2953       |
|    total_timesteps      | 1839104    |
| train/                  |            |
|    approx_kl            | 0.26577982 |
|    clip_fraction        | 0.385      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.272     |
|    explained_variance   | 0.828      |
|    learning_rate        | 0.00164    |
|    loss                 | -0.0674    |
|    n_updates            | 8970       |
|    policy_gradient_loss | -0.00763   |
|    std                  | 0.275      |
|    value_loss           | 0.00176    |
----------------------------------------
box reached target
Eval num_timesteps=1840000, episode_reward=0.40 +/- 2.35
Episode length: 273.60 +/- 52.80
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 274        |
|    mean_reward          | 0.402      |
| time/                   |            |
|    total_timesteps      | 1840000    |
| train/                  |            |
|    approx_kl            | 0.32282752 |
|    clip_fraction        | 0.434      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.191     |
|    explained_variance   | 0.851      |
|    learning_rate        | 0.00164    |
|    loss                 | 0.0355     |
|    n_updates            | 8980       |
|    policy_gradient_loss | 0.00851    |
|    std                  | 0.259      |
|    value_loss           | 0.0329     |
----------------------------------------
box reached target
--------------------------------
| time/              |         |
|    fps             | 622     |
|    iterations      | 899     |
|    time_elapsed    | 2957    |
|    total_timesteps | 1841152 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 900        |
|    time_elapsed         | 2960       |
|    total_timesteps      | 1843200    |
| train/                  |            |
|    approx_kl            | 0.27735624 |
|    clip_fraction        | 0.445      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.19      |
|    explained_variance   | 0.838      |
|    learning_rate        | 0.00164    |
|    loss                 | -0.0131    |
|    n_updates            | 8990       |
|    policy_gradient_loss | 0.0131     |
|    std                  | 0.266      |
|    value_loss           | 0.012      |
----------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 622       |
|    iterations           | 901       |
|    time_elapsed         | 2963      |
|    total_timesteps      | 1845248   |
| train/                  |           |
|    approx_kl            | 0.6492832 |
|    clip_fraction        | 0.401     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.177    |
|    explained_variance   | 0.856     |
|    learning_rate        | 0.00164   |
|    loss                 | 0.0313    |
|    n_updates            | 9000      |
|    policy_gradient_loss | -0.00537  |
|    std                  | 0.259     |
|    value_loss           | 0.00754   |
---------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 902        |
|    time_elapsed         | 2966       |
|    total_timesteps      | 1847296    |
| train/                  |            |
|    approx_kl            | 0.26274768 |
|    clip_fraction        | 0.428      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.0775    |
|    explained_variance   | 0.0747     |
|    learning_rate        | 0.00164    |
|    loss                 | 0.0598     |
|    n_updates            | 9010       |
|    policy_gradient_loss | 0.00446    |
|    std                  | 0.248      |
|    value_loss           | 0.0399     |
----------------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 903        |
|    time_elapsed         | 2969       |
|    total_timesteps      | 1849344    |
| train/                  |            |
|    approx_kl            | 0.28998083 |
|    clip_fraction        | 0.466      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.0429    |
|    explained_variance   | 0.893      |
|    learning_rate        | 0.00164    |
|    loss                 | -0.0119    |
|    n_updates            | 9020       |
|    policy_gradient_loss | 0.0186     |
|    std                  | 0.241      |
|    value_loss           | 0.00932    |
----------------------------------------
box reached target
Eval num_timesteps=1850000, episode_reward=0.25 +/- 2.50
Episode length: 273.00 +/- 54.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 273        |
|    mean_reward          | 0.25       |
| time/                   |            |
|    total_timesteps      | 1850000    |
| train/                  |            |
|    approx_kl            | 0.13373137 |
|    clip_fraction        | 0.41       |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.031     |
|    explained_variance   | 0.689      |
|    learning_rate        | 0.00164    |
|    loss                 | -0.047     |
|    n_updates            | 9030       |
|    policy_gradient_loss | 0.0111     |
|    std                  | 0.249      |
|    value_loss           | 0.0373     |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 622     |
|    iterations      | 904     |
|    time_elapsed    | 2973    |
|    total_timesteps | 1851392 |
--------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 905        |
|    time_elapsed         | 2976       |
|    total_timesteps      | 1853440    |
| train/                  |            |
|    approx_kl            | 0.20477125 |
|    clip_fraction        | 0.43       |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.0243    |
|    explained_variance   | 0.752      |
|    learning_rate        | 0.00164    |
|    loss                 | -0.00473   |
|    n_updates            | 9040       |
|    policy_gradient_loss | 0.00485    |
|    std                  | 0.241      |
|    value_loss           | 0.00699    |
----------------------------------------
box reached target
--------------------------------------
| time/                   |          |
|    fps                  | 622      |
|    iterations           | 906      |
|    time_elapsed         | 2979     |
|    total_timesteps      | 1855488  |
| train/                  |          |
|    approx_kl            | 0.140342 |
|    clip_fraction        | 0.422    |
|    clip_range           | 0.2      |
|    entropy_loss         | 0.00364  |
|    explained_variance   | 0.658    |
|    learning_rate        | 0.00164  |
|    loss                 | 0.0117   |
|    n_updates            | 9050     |
|    policy_gradient_loss | 0.0141   |
|    std                  | 0.242    |
|    value_loss           | 0.0426   |
--------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 907        |
|    time_elapsed         | 2982       |
|    total_timesteps      | 1857536    |
| train/                  |            |
|    approx_kl            | 0.22153199 |
|    clip_fraction        | 0.39       |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.0306    |
|    explained_variance   | 0.875      |
|    learning_rate        | 0.00164    |
|    loss                 | 0.0402     |
|    n_updates            | 9060       |
|    policy_gradient_loss | 0.00697    |
|    std                  | 0.246      |
|    value_loss           | 0.0106     |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 908        |
|    time_elapsed         | 2985       |
|    total_timesteps      | 1859584    |
| train/                  |            |
|    approx_kl            | 0.19539794 |
|    clip_fraction        | 0.452      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.0557    |
|    explained_variance   | 0.588      |
|    learning_rate        | 0.00164    |
|    loss                 | 0.0419     |
|    n_updates            | 9070       |
|    policy_gradient_loss | 0.0222     |
|    std                  | 0.247      |
|    value_loss           | 0.0164     |
----------------------------------------
Eval num_timesteps=1860000, episode_reward=-1.01 +/- 0.02
Episode length: 300.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 300       |
|    mean_reward          | -1.01     |
| time/                   |           |
|    total_timesteps      | 1860000   |
| train/                  |           |
|    approx_kl            | 0.5947403 |
|    clip_fraction        | 0.476     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0682   |
|    explained_variance   | 0.586     |
|    learning_rate        | 0.00164   |
|    loss                 | -0.0316   |
|    n_updates            | 9080      |
|    policy_gradient_loss | 0.0045    |
|    std                  | 0.252     |
|    value_loss           | 0.00941   |
---------------------------------------
box reached target
--------------------------------
| time/              |         |
|    fps             | 622     |
|    iterations      | 909     |
|    time_elapsed    | 2989    |
|    total_timesteps | 1861632 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 910        |
|    time_elapsed         | 2992       |
|    total_timesteps      | 1863680    |
| train/                  |            |
|    approx_kl            | 0.12030306 |
|    clip_fraction        | 0.415      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.0709    |
|    explained_variance   | 0.748      |
|    learning_rate        | 0.00164    |
|    loss                 | 0.0673     |
|    n_updates            | 9090       |
|    policy_gradient_loss | 0.015      |
|    std                  | 0.25       |
|    value_loss           | 0.0219     |
----------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 622       |
|    iterations           | 911       |
|    time_elapsed         | 2995      |
|    total_timesteps      | 1865728   |
| train/                  |           |
|    approx_kl            | 1.1420316 |
|    clip_fraction        | 0.396     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0739   |
|    explained_variance   | 0.735     |
|    learning_rate        | 0.00164   |
|    loss                 | -0.0338   |
|    n_updates            | 9100      |
|    policy_gradient_loss | 0.00838   |
|    std                  | 0.248     |
|    value_loss           | 0.00989   |
---------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 622       |
|    iterations           | 912       |
|    time_elapsed         | 2998      |
|    total_timesteps      | 1867776   |
| train/                  |           |
|    approx_kl            | 0.1446965 |
|    clip_fraction        | 0.422     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0701   |
|    explained_variance   | 0.835     |
|    learning_rate        | 0.00164   |
|    loss                 | -0.017    |
|    n_updates            | 9110      |
|    policy_gradient_loss | 0.0197    |
|    std                  | 0.251     |
|    value_loss           | 0.0132    |
---------------------------------------
box reached target
box reached target
box reached target
--------------------------------------
| time/                   |          |
|    fps                  | 622      |
|    iterations           | 913      |
|    time_elapsed         | 3001     |
|    total_timesteps      | 1869824  |
| train/                  |          |
|    approx_kl            | 0.280715 |
|    clip_fraction        | 0.433    |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0786  |
|    explained_variance   | 0.739    |
|    learning_rate        | 0.00164  |
|    loss                 | 0.0315   |
|    n_updates            | 9120     |
|    policy_gradient_loss | 0.0126   |
|    std                  | 0.249    |
|    value_loss           | 0.0164   |
--------------------------------------
box reached target
Eval num_timesteps=1870000, episode_reward=0.24 +/- 2.47
Episode length: 272.40 +/- 55.20
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 272       |
|    mean_reward          | 0.235     |
| time/                   |           |
|    total_timesteps      | 1870000   |
| train/                  |           |
|    approx_kl            | 0.7891977 |
|    clip_fraction        | 0.425     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0465   |
|    explained_variance   | 0.759     |
|    learning_rate        | 0.00164   |
|    loss                 | -0.00903  |
|    n_updates            | 9130      |
|    policy_gradient_loss | 0.00762   |
|    std                  | 0.241     |
|    value_loss           | 0.0228    |
---------------------------------------
box reached target
--------------------------------
| time/              |         |
|    fps             | 622     |
|    iterations      | 914     |
|    time_elapsed    | 3005    |
|    total_timesteps | 1871872 |
--------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 915        |
|    time_elapsed         | 3008       |
|    total_timesteps      | 1873920    |
| train/                  |            |
|    approx_kl            | 0.21717158 |
|    clip_fraction        | 0.465      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.0181    |
|    explained_variance   | 0.634      |
|    learning_rate        | 0.00163    |
|    loss                 | 0.0851     |
|    n_updates            | 9140       |
|    policy_gradient_loss | 0.0125     |
|    std                  | 0.245      |
|    value_loss           | 0.0284     |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 916        |
|    time_elapsed         | 3011       |
|    total_timesteps      | 1875968    |
| train/                  |            |
|    approx_kl            | 0.69362855 |
|    clip_fraction        | 0.463      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.047     |
|    explained_variance   | 0.527      |
|    learning_rate        | 0.00163    |
|    loss                 | -0.0044    |
|    n_updates            | 9150       |
|    policy_gradient_loss | 0.00801    |
|    std                  | 0.242      |
|    value_loss           | 0.0331     |
----------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 622       |
|    iterations           | 917       |
|    time_elapsed         | 3014      |
|    total_timesteps      | 1878016   |
| train/                  |           |
|    approx_kl            | 0.2825122 |
|    clip_fraction        | 0.448     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0125   |
|    explained_variance   | 0.717     |
|    learning_rate        | 0.00163   |
|    loss                 | -0.00232  |
|    n_updates            | 9160      |
|    policy_gradient_loss | 0.0121    |
|    std                  | 0.242     |
|    value_loss           | 0.00506   |
---------------------------------------
box reached target
box reached target
box reached target
Eval num_timesteps=1880000, episode_reward=1.46 +/- 3.01
Episode length: 244.40 +/- 68.17
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 244       |
|    mean_reward          | 1.46      |
| time/                   |           |
|    total_timesteps      | 1880000   |
| train/                  |           |
|    approx_kl            | 0.2951243 |
|    clip_fraction        | 0.437     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.00518   |
|    explained_variance   | 0.723     |
|    learning_rate        | 0.00163   |
|    loss                 | 0.0477    |
|    n_updates            | 9170      |
|    policy_gradient_loss | 0.0221    |
|    std                  | 0.241     |
|    value_loss           | 0.0238    |
---------------------------------------
--------------------------------
| time/              |         |
|    fps             | 622     |
|    iterations      | 918     |
|    time_elapsed    | 3018    |
|    total_timesteps | 1880064 |
--------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 919        |
|    time_elapsed         | 3021       |
|    total_timesteps      | 1882112    |
| train/                  |            |
|    approx_kl            | 0.19167773 |
|    clip_fraction        | 0.416      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.00403    |
|    explained_variance   | 0.792      |
|    learning_rate        | 0.00163    |
|    loss                 | 0.0292     |
|    n_updates            | 9180       |
|    policy_gradient_loss | -0.00537   |
|    std                  | 0.236      |
|    value_loss           | 0.00846    |
----------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 622       |
|    iterations           | 920       |
|    time_elapsed         | 3024      |
|    total_timesteps      | 1884160   |
| train/                  |           |
|    approx_kl            | 0.4189675 |
|    clip_fraction        | 0.444     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.0529    |
|    explained_variance   | 0.502     |
|    learning_rate        | 0.00163   |
|    loss                 | 0.0211    |
|    n_updates            | 9190      |
|    policy_gradient_loss | 0.0281    |
|    std                  | 0.233     |
|    value_loss           | 0.00976   |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 921        |
|    time_elapsed         | 3027       |
|    total_timesteps      | 1886208    |
| train/                  |            |
|    approx_kl            | 0.18683991 |
|    clip_fraction        | 0.412      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.078      |
|    explained_variance   | 0.853      |
|    learning_rate        | 0.00163    |
|    loss                 | -0.00265   |
|    n_updates            | 9200       |
|    policy_gradient_loss | -6.34e-05  |
|    std                  | 0.232      |
|    value_loss           | 0.00827    |
----------------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 922        |
|    time_elapsed         | 3031       |
|    total_timesteps      | 1888256    |
| train/                  |            |
|    approx_kl            | 0.14119568 |
|    clip_fraction        | 0.375      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.0404     |
|    explained_variance   | -0.505     |
|    learning_rate        | 0.00163    |
|    loss                 | 0.0335     |
|    n_updates            | 9210       |
|    policy_gradient_loss | 0.0102     |
|    std                  | 0.236      |
|    value_loss           | 0.00536    |
----------------------------------------
box reached target
Eval num_timesteps=1890000, episode_reward=0.64 +/- 2.32
Episode length: 274.00 +/- 52.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 274         |
|    mean_reward          | 0.637       |
| time/                   |             |
|    total_timesteps      | 1890000     |
| train/                  |             |
|    approx_kl            | 0.104334846 |
|    clip_fraction        | 0.369       |
|    clip_range           | 0.2         |
|    entropy_loss         | 0.025       |
|    explained_variance   | 0.638       |
|    learning_rate        | 0.00163     |
|    loss                 | -0.00494    |
|    n_updates            | 9220        |
|    policy_gradient_loss | 0.00943     |
|    std                  | 0.24        |
|    value_loss           | 0.0804      |
-----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 622     |
|    iterations      | 923     |
|    time_elapsed    | 3035    |
|    total_timesteps | 1890304 |
--------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 622       |
|    iterations           | 924       |
|    time_elapsed         | 3038      |
|    total_timesteps      | 1892352   |
| train/                  |           |
|    approx_kl            | 0.3652467 |
|    clip_fraction        | 0.362     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.0394    |
|    explained_variance   | 0.512     |
|    learning_rate        | 0.00163   |
|    loss                 | -0.00372  |
|    n_updates            | 9230      |
|    policy_gradient_loss | -0.00147  |
|    std                  | 0.234     |
|    value_loss           | 0.0583    |
---------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 622       |
|    iterations           | 925       |
|    time_elapsed         | 3041      |
|    total_timesteps      | 1894400   |
| train/                  |           |
|    approx_kl            | 0.1625215 |
|    clip_fraction        | 0.44      |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.0669    |
|    explained_variance   | 0.763     |
|    learning_rate        | 0.00163   |
|    loss                 | 0.0288    |
|    n_updates            | 9240      |
|    policy_gradient_loss | 0.0245    |
|    std                  | 0.234     |
|    value_loss           | 0.0233    |
---------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 622       |
|    iterations           | 926       |
|    time_elapsed         | 3044      |
|    total_timesteps      | 1896448   |
| train/                  |           |
|    approx_kl            | 0.4789811 |
|    clip_fraction        | 0.425     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.0349    |
|    explained_variance   | 0.847     |
|    learning_rate        | 0.00163   |
|    loss                 | 0.0108    |
|    n_updates            | 9250      |
|    policy_gradient_loss | 0.00686   |
|    std                  | 0.238     |
|    value_loss           | 0.00859   |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 623        |
|    iterations           | 927        |
|    time_elapsed         | 3047       |
|    total_timesteps      | 1898496    |
| train/                  |            |
|    approx_kl            | 0.35291404 |
|    clip_fraction        | 0.412      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.0243     |
|    explained_variance   | 0.687      |
|    learning_rate        | 0.00163    |
|    loss                 | 0.0174     |
|    n_updates            | 9260       |
|    policy_gradient_loss | 0.000861   |
|    std                  | 0.239      |
|    value_loss           | 0.0109     |
----------------------------------------
Eval num_timesteps=1900000, episode_reward=-0.72 +/- 0.57
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -0.715     |
| time/                   |            |
|    total_timesteps      | 1900000    |
| train/                  |            |
|    approx_kl            | 0.38968223 |
|    clip_fraction        | 0.416      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.0142     |
|    explained_variance   | 0.582      |
|    learning_rate        | 0.00163    |
|    loss                 | 0.0383     |
|    n_updates            | 9270       |
|    policy_gradient_loss | 0.0125     |
|    std                  | 0.242      |
|    value_loss           | 0.00458    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 622     |
|    iterations      | 928     |
|    time_elapsed    | 3051    |
|    total_timesteps | 1900544 |
--------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 622       |
|    iterations           | 929       |
|    time_elapsed         | 3054      |
|    total_timesteps      | 1902592   |
| train/                  |           |
|    approx_kl            | 1.9253767 |
|    clip_fraction        | 0.453     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.0527    |
|    explained_variance   | 0.756     |
|    learning_rate        | 0.00163   |
|    loss                 | -0.0338   |
|    n_updates            | 9280      |
|    policy_gradient_loss | -0.0177   |
|    std                  | 0.234     |
|    value_loss           | 0.00701   |
---------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 622       |
|    iterations           | 930       |
|    time_elapsed         | 3057      |
|    total_timesteps      | 1904640   |
| train/                  |           |
|    approx_kl            | 0.7140987 |
|    clip_fraction        | 0.533     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.109     |
|    explained_variance   | 0.771     |
|    learning_rate        | 0.00163   |
|    loss                 | -0.014    |
|    n_updates            | 9290      |
|    policy_gradient_loss | 0.00403   |
|    std                  | 0.226     |
|    value_loss           | 0.00832   |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 623        |
|    iterations           | 931        |
|    time_elapsed         | 3060       |
|    total_timesteps      | 1906688    |
| train/                  |            |
|    approx_kl            | 0.40338305 |
|    clip_fraction        | 0.482      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.117      |
|    explained_variance   | 0.772      |
|    learning_rate        | 0.00163    |
|    loss                 | -0.0393    |
|    n_updates            | 9300       |
|    policy_gradient_loss | 0.0111     |
|    std                  | 0.228      |
|    value_loss           | 0.00618    |
----------------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 623        |
|    iterations           | 932        |
|    time_elapsed         | 3063       |
|    total_timesteps      | 1908736    |
| train/                  |            |
|    approx_kl            | 0.66934633 |
|    clip_fraction        | 0.456      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.109      |
|    explained_variance   | 0.736      |
|    learning_rate        | 0.00163    |
|    loss                 | -0.0537    |
|    n_updates            | 9310       |
|    policy_gradient_loss | 0.011      |
|    std                  | 0.228      |
|    value_loss           | 0.0108     |
----------------------------------------
box reached target
Eval num_timesteps=1910000, episode_reward=-0.66 +/- 0.46
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -0.655     |
| time/                   |            |
|    total_timesteps      | 1910000    |
| train/                  |            |
|    approx_kl            | 0.47810954 |
|    clip_fraction        | 0.481      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.0791     |
|    explained_variance   | 0.517      |
|    learning_rate        | 0.00163    |
|    loss                 | 0.0478     |
|    n_updates            | 9320       |
|    policy_gradient_loss | 0.0143     |
|    std                  | 0.233      |
|    value_loss           | 0.0581     |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 622     |
|    iterations      | 933     |
|    time_elapsed    | 3067    |
|    total_timesteps | 1910784 |
--------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 622        |
|    iterations           | 934        |
|    time_elapsed         | 3070       |
|    total_timesteps      | 1912832    |
| train/                  |            |
|    approx_kl            | 0.08768168 |
|    clip_fraction        | 0.364      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.0354     |
|    explained_variance   | 0.596      |
|    learning_rate        | 0.00163    |
|    loss                 | 0.0473     |
|    n_updates            | 9330       |
|    policy_gradient_loss | 0.0275     |
|    std                  | 0.239      |
|    value_loss           | 0.0463     |
----------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 622       |
|    iterations           | 935       |
|    time_elapsed         | 3073      |
|    total_timesteps      | 1914880   |
| train/                  |           |
|    approx_kl            | 0.4211058 |
|    clip_fraction        | 0.432     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.0594    |
|    explained_variance   | 0.835     |
|    learning_rate        | 0.00163   |
|    loss                 | 0.0631    |
|    n_updates            | 9340      |
|    policy_gradient_loss | 0.00796   |
|    std                  | 0.23      |
|    value_loss           | 0.0218    |
---------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 623       |
|    iterations           | 936       |
|    time_elapsed         | 3076      |
|    total_timesteps      | 1916928   |
| train/                  |           |
|    approx_kl            | 0.1674686 |
|    clip_fraction        | 0.415     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.096     |
|    explained_variance   | 0.879     |
|    learning_rate        | 0.00163   |
|    loss                 | 0.0819    |
|    n_updates            | 9350      |
|    policy_gradient_loss | 0.0214    |
|    std                  | 0.23      |
|    value_loss           | 0.0165    |
---------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 623       |
|    iterations           | 937       |
|    time_elapsed         | 3079      |
|    total_timesteps      | 1918976   |
| train/                  |           |
|    approx_kl            | 1.2352915 |
|    clip_fraction        | 0.51      |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.118     |
|    explained_variance   | 0.893     |
|    learning_rate        | 0.00163   |
|    loss                 | 0.00251   |
|    n_updates            | 9360      |
|    policy_gradient_loss | 0.0221    |
|    std                  | 0.223     |
|    value_loss           | 0.00953   |
---------------------------------------
box reached target
box reached target
box reached target
Eval num_timesteps=1920000, episode_reward=2.96 +/- 2.77
Episode length: 215.60 +/- 69.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 216       |
|    mean_reward          | 2.96      |
| time/                   |           |
|    total_timesteps      | 1920000   |
| train/                  |           |
|    approx_kl            | 0.3775707 |
|    clip_fraction        | 0.453     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.188     |
|    explained_variance   | 0.411     |
|    learning_rate        | 0.00163   |
|    loss                 | -0.0183   |
|    n_updates            | 9370      |
|    policy_gradient_loss | 0.0105    |
|    std                  | 0.219     |
|    value_loss           | 0.00409   |
---------------------------------------
New best mean reward!
box reached target
--------------------------------
| time/              |         |
|    fps             | 622     |
|    iterations      | 938     |
|    time_elapsed    | 3083    |
|    total_timesteps | 1921024 |
--------------------------------
--------------------------------------
| time/                   |          |
|    fps                  | 623      |
|    iterations           | 939      |
|    time_elapsed         | 3086     |
|    total_timesteps      | 1923072  |
| train/                  |          |
|    approx_kl            | 0.95977  |
|    clip_fraction        | 0.52     |
|    clip_range           | 0.2      |
|    entropy_loss         | 0.22     |
|    explained_variance   | 0.888    |
|    learning_rate        | 0.00163  |
|    loss                 | 0.0108   |
|    n_updates            | 9380     |
|    policy_gradient_loss | 0.00592  |
|    std                  | 0.214    |
|    value_loss           | 0.0215   |
--------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 623        |
|    iterations           | 940        |
|    time_elapsed         | 3089       |
|    total_timesteps      | 1925120    |
| train/                  |            |
|    approx_kl            | 0.38978836 |
|    clip_fraction        | 0.481      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.193      |
|    explained_variance   | 0.771      |
|    learning_rate        | 0.00163    |
|    loss                 | 0.0851     |
|    n_updates            | 9390       |
|    policy_gradient_loss | 0.0066     |
|    std                  | 0.219      |
|    value_loss           | 0.0142     |
----------------------------------------
box reached target
box reached target
box reached target
--------------------------------------
| time/                   |          |
|    fps                  | 623      |
|    iterations           | 941      |
|    time_elapsed         | 3092     |
|    total_timesteps      | 1927168  |
| train/                  |          |
|    approx_kl            | 0.47239  |
|    clip_fraction        | 0.485    |
|    clip_range           | 0.2      |
|    entropy_loss         | 0.198    |
|    explained_variance   | 0.777    |
|    learning_rate        | 0.00162  |
|    loss                 | -0.026   |
|    n_updates            | 9400     |
|    policy_gradient_loss | 0.00411  |
|    std                  | 0.215    |
|    value_loss           | 0.00885  |
--------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 623        |
|    iterations           | 942        |
|    time_elapsed         | 3095       |
|    total_timesteps      | 1929216    |
| train/                  |            |
|    approx_kl            | 0.35618186 |
|    clip_fraction        | 0.454      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.193      |
|    explained_variance   | 0.782      |
|    learning_rate        | 0.00162    |
|    loss                 | 0.0736     |
|    n_updates            | 9410       |
|    policy_gradient_loss | 0.0101     |
|    std                  | 0.22       |
|    value_loss           | 0.0527     |
----------------------------------------
box reached target
box reached target
Eval num_timesteps=1930000, episode_reward=0.22 +/- 2.43
Episode length: 273.40 +/- 53.20
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 273       |
|    mean_reward          | 0.216     |
| time/                   |           |
|    total_timesteps      | 1930000   |
| train/                  |           |
|    approx_kl            | 0.1662292 |
|    clip_fraction        | 0.43      |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.172     |
|    explained_variance   | 0.725     |
|    learning_rate        | 0.00162   |
|    loss                 | 0.0316    |
|    n_updates            | 9420      |
|    policy_gradient_loss | 0.0204    |
|    std                  | 0.219     |
|    value_loss           | 0.0181    |
---------------------------------------
--------------------------------
| time/              |         |
|    fps             | 623     |
|    iterations      | 943     |
|    time_elapsed    | 3099    |
|    total_timesteps | 1931264 |
--------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 623        |
|    iterations           | 944        |
|    time_elapsed         | 3102       |
|    total_timesteps      | 1933312    |
| train/                  |            |
|    approx_kl            | 0.30948004 |
|    clip_fraction        | 0.483      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.176      |
|    explained_variance   | 0.657      |
|    learning_rate        | 0.00162    |
|    loss                 | -0.0265    |
|    n_updates            | 9430       |
|    policy_gradient_loss | 0.0171     |
|    std                  | 0.22       |
|    value_loss           | 0.0737     |
----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 623       |
|    iterations           | 945       |
|    time_elapsed         | 3105      |
|    total_timesteps      | 1935360   |
| train/                  |           |
|    approx_kl            | 0.7379401 |
|    clip_fraction        | 0.503     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.208     |
|    explained_variance   | 0.684     |
|    learning_rate        | 0.00162   |
|    loss                 | -0.00017  |
|    n_updates            | 9440      |
|    policy_gradient_loss | 0.0049    |
|    std                  | 0.214     |
|    value_loss           | 0.0557    |
---------------------------------------
box reached target
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 623        |
|    iterations           | 946        |
|    time_elapsed         | 3109       |
|    total_timesteps      | 1937408    |
| train/                  |            |
|    approx_kl            | 0.43576297 |
|    clip_fraction        | 0.45       |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.264      |
|    explained_variance   | 0.707      |
|    learning_rate        | 0.00162    |
|    loss                 | -0.0126    |
|    n_updates            | 9450       |
|    policy_gradient_loss | 0.00319    |
|    std                  | 0.21       |
|    value_loss           | 0.00958    |
----------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 623       |
|    iterations           | 947       |
|    time_elapsed         | 3112      |
|    total_timesteps      | 1939456   |
| train/                  |           |
|    approx_kl            | 0.8455311 |
|    clip_fraction        | 0.521     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.273     |
|    explained_variance   | 0.286     |
|    learning_rate        | 0.00162   |
|    loss                 | 0.0824    |
|    n_updates            | 9460      |
|    policy_gradient_loss | 0.0183    |
|    std                  | 0.213     |
|    value_loss           | 0.0699    |
---------------------------------------
box reached target
Eval num_timesteps=1940000, episode_reward=0.51 +/- 2.37
Episode length: 273.20 +/- 53.60
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 273        |
|    mean_reward          | 0.505      |
| time/                   |            |
|    total_timesteps      | 1940000    |
| train/                  |            |
|    approx_kl            | 0.51118237 |
|    clip_fraction        | 0.493      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.227      |
|    explained_variance   | 0.708      |
|    learning_rate        | 0.00162    |
|    loss                 | -0.0394    |
|    n_updates            | 9470       |
|    policy_gradient_loss | 0.0284     |
|    std                  | 0.214      |
|    value_loss           | 0.0271     |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 623     |
|    iterations      | 948     |
|    time_elapsed    | 3116    |
|    total_timesteps | 1941504 |
--------------------------------
box reached target
box reached target
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 623       |
|    iterations           | 949       |
|    time_elapsed         | 3119      |
|    total_timesteps      | 1943552   |
| train/                  |           |
|    approx_kl            | 0.5453425 |
|    clip_fraction        | 0.469     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.205     |
|    explained_variance   | 0.718     |
|    learning_rate        | 0.00162   |
|    loss                 | 0.0219    |
|    n_updates            | 9480      |
|    policy_gradient_loss | 0.0218    |
|    std                  | 0.214     |
|    value_loss           | 0.0162    |
---------------------------------------
box reached target
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 623       |
|    iterations           | 950       |
|    time_elapsed         | 3122      |
|    total_timesteps      | 1945600   |
| train/                  |           |
|    approx_kl            | 0.3209613 |
|    clip_fraction        | 0.436     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.185     |
|    explained_variance   | 0.737     |
|    learning_rate        | 0.00162   |
|    loss                 | -0.0136   |
|    n_updates            | 9490      |
|    policy_gradient_loss | 0.0108    |
|    std                  | 0.222     |
|    value_loss           | 0.0727    |
---------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 623        |
|    iterations           | 951        |
|    time_elapsed         | 3125       |
|    total_timesteps      | 1947648    |
| train/                  |            |
|    approx_kl            | 0.41281638 |
|    clip_fraction        | 0.493      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.153      |
|    explained_variance   | 0.829      |
|    learning_rate        | 0.00162    |
|    loss                 | 0.0191     |
|    n_updates            | 9500       |
|    policy_gradient_loss | 0.0311     |
|    std                  | 0.226      |
|    value_loss           | 0.027      |
----------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 623       |
|    iterations           | 952       |
|    time_elapsed         | 3128      |
|    total_timesteps      | 1949696   |
| train/                  |           |
|    approx_kl            | 1.0983642 |
|    clip_fraction        | 0.452     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.121     |
|    explained_variance   | 0.432     |
|    learning_rate        | 0.00162   |
|    loss                 | 0.0152    |
|    n_updates            | 9510      |
|    policy_gradient_loss | 0.0382    |
|    std                  | 0.224     |
|    value_loss           | 0.0378    |
---------------------------------------
box reached target
Eval num_timesteps=1950000, episode_reward=0.57 +/- 2.44
Episode length: 273.20 +/- 53.60
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 273       |
|    mean_reward          | 0.573     |
| time/                   |           |
|    total_timesteps      | 1950000   |
| train/                  |           |
|    approx_kl            | 0.3816245 |
|    clip_fraction        | 0.474     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.123     |
|    explained_variance   | 0.586     |
|    learning_rate        | 0.00162   |
|    loss                 | 0.0514    |
|    n_updates            | 9520      |
|    policy_gradient_loss | 0.0146    |
|    std                  | 0.228     |
|    value_loss           | 0.036     |
---------------------------------------
--------------------------------
| time/              |         |
|    fps             | 623     |
|    iterations      | 953     |
|    time_elapsed    | 3132    |
|    total_timesteps | 1951744 |
--------------------------------
box reached target
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 623        |
|    iterations           | 954        |
|    time_elapsed         | 3135       |
|    total_timesteps      | 1953792    |
| train/                  |            |
|    approx_kl            | 0.12745276 |
|    clip_fraction        | 0.44       |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.0533     |
|    explained_variance   | 0.674      |
|    learning_rate        | 0.00162    |
|    loss                 | -0.00974   |
|    n_updates            | 9530       |
|    policy_gradient_loss | 0.0185     |
|    std                  | 0.237      |
|    value_loss           | 0.00906    |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 623        |
|    iterations           | 955        |
|    time_elapsed         | 3138       |
|    total_timesteps      | 1955840    |
| train/                  |            |
|    approx_kl            | 0.20534518 |
|    clip_fraction        | 0.455      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.0452     |
|    explained_variance   | 0.734      |
|    learning_rate        | 0.00162    |
|    loss                 | -0.00521   |
|    n_updates            | 9540       |
|    policy_gradient_loss | 0.0217     |
|    std                  | 0.237      |
|    value_loss           | 0.0321     |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 623        |
|    iterations           | 956        |
|    time_elapsed         | 3141       |
|    total_timesteps      | 1957888    |
| train/                  |            |
|    approx_kl            | 0.20727488 |
|    clip_fraction        | 0.44       |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.0427     |
|    explained_variance   | 0.773      |
|    learning_rate        | 0.00162    |
|    loss                 | -0.0278    |
|    n_updates            | 9550       |
|    policy_gradient_loss | 0.0073     |
|    std                  | 0.235      |
|    value_loss           | 0.0122     |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 623        |
|    iterations           | 957        |
|    time_elapsed         | 3144       |
|    total_timesteps      | 1959936    |
| train/                  |            |
|    approx_kl            | 0.19723886 |
|    clip_fraction        | 0.465      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.0296     |
|    explained_variance   | 0.854      |
|    learning_rate        | 0.00162    |
|    loss                 | 0.0378     |
|    n_updates            | 9560       |
|    policy_gradient_loss | 0.0221     |
|    std                  | 0.234      |
|    value_loss           | 0.00861    |
----------------------------------------
box reached target
Eval num_timesteps=1960000, episode_reward=0.26 +/- 2.51
Episode length: 279.00 +/- 42.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 279        |
|    mean_reward          | 0.257      |
| time/                   |            |
|    total_timesteps      | 1960000    |
| train/                  |            |
|    approx_kl            | 0.25631154 |
|    clip_fraction        | 0.447      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.015      |
|    explained_variance   | 0.532      |
|    learning_rate        | 0.00162    |
|    loss                 | -0.0232    |
|    n_updates            | 9570       |
|    policy_gradient_loss | 0.0174     |
|    std                  | 0.242      |
|    value_loss           | 0.0279     |
----------------------------------------
box reached target
box reached target
box reached target
box reached target
--------------------------------
| time/              |         |
|    fps             | 623     |
|    iterations      | 958     |
|    time_elapsed    | 3148    |
|    total_timesteps | 1961984 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 623        |
|    iterations           | 959        |
|    time_elapsed         | 3151       |
|    total_timesteps      | 1964032    |
| train/                  |            |
|    approx_kl            | 0.25752288 |
|    clip_fraction        | 0.429      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.0225    |
|    explained_variance   | 0.87       |
|    learning_rate        | 0.00162    |
|    loss                 | 0.0222     |
|    n_updates            | 9580       |
|    policy_gradient_loss | 0.00356    |
|    std                  | 0.242      |
|    value_loss           | 0.0263     |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 623        |
|    iterations           | 960        |
|    time_elapsed         | 3154       |
|    total_timesteps      | 1966080    |
| train/                  |            |
|    approx_kl            | 0.29796305 |
|    clip_fraction        | 0.377      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.077     |
|    explained_variance   | 0.713      |
|    learning_rate        | 0.00162    |
|    loss                 | -0.0309    |
|    n_updates            | 9590       |
|    policy_gradient_loss | 0.0248     |
|    std                  | 0.254      |
|    value_loss           | 0.00936    |
----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 623       |
|    iterations           | 961       |
|    time_elapsed         | 3157      |
|    total_timesteps      | 1968128   |
| train/                  |           |
|    approx_kl            | 0.3214755 |
|    clip_fraction        | 0.447     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0863   |
|    explained_variance   | 0.219     |
|    learning_rate        | 0.00162   |
|    loss                 | 0.0113    |
|    n_updates            | 9600      |
|    policy_gradient_loss | 0.0202    |
|    std                  | 0.248     |
|    value_loss           | 0.00701   |
---------------------------------------
box reached target
Eval num_timesteps=1970000, episode_reward=0.23 +/- 2.46
Episode length: 273.80 +/- 52.40
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 274        |
|    mean_reward          | 0.23       |
| time/                   |            |
|    total_timesteps      | 1970000    |
| train/                  |            |
|    approx_kl            | 0.54472804 |
|    clip_fraction        | 0.474      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.092     |
|    explained_variance   | 0.422      |
|    learning_rate        | 0.00162    |
|    loss                 | 0.149      |
|    n_updates            | 9610       |
|    policy_gradient_loss | 0.0235     |
|    std                  | 0.252      |
|    value_loss           | 0.00469    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 623     |
|    iterations      | 962     |
|    time_elapsed    | 3161    |
|    total_timesteps | 1970176 |
--------------------------------
box reached target
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 623        |
|    iterations           | 963        |
|    time_elapsed         | 3164       |
|    total_timesteps      | 1972224    |
| train/                  |            |
|    approx_kl            | 0.24561518 |
|    clip_fraction        | 0.474      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.102     |
|    explained_variance   | 0.735      |
|    learning_rate        | 0.00162    |
|    loss                 | 0.0153     |
|    n_updates            | 9620       |
|    policy_gradient_loss | 0.0134     |
|    std                  | 0.248      |
|    value_loss           | 0.00844    |
----------------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 623        |
|    iterations           | 964        |
|    time_elapsed         | 3167       |
|    total_timesteps      | 1974272    |
| train/                  |            |
|    approx_kl            | 0.27558348 |
|    clip_fraction        | 0.45       |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.043     |
|    explained_variance   | 0.835      |
|    learning_rate        | 0.00162    |
|    loss                 | 0.0343     |
|    n_updates            | 9630       |
|    policy_gradient_loss | 0.00209    |
|    std                  | 0.245      |
|    value_loss           | 0.0244     |
----------------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 623        |
|    iterations           | 965        |
|    time_elapsed         | 3170       |
|    total_timesteps      | 1976320    |
| train/                  |            |
|    approx_kl            | 0.36738425 |
|    clip_fraction        | 0.431      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.00968   |
|    explained_variance   | 0.479      |
|    learning_rate        | 0.00162    |
|    loss                 | 0.0455     |
|    n_updates            | 9640       |
|    policy_gradient_loss | 0.0222     |
|    std                  | 0.24       |
|    value_loss           | 0.0334     |
----------------------------------------
box reached target
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 623       |
|    iterations           | 966       |
|    time_elapsed         | 3173      |
|    total_timesteps      | 1978368   |
| train/                  |           |
|    approx_kl            | 0.3097313 |
|    clip_fraction        | 0.444     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.0119    |
|    explained_variance   | 0.899     |
|    learning_rate        | 0.00161   |
|    loss                 | -0.0253   |
|    n_updates            | 9650      |
|    policy_gradient_loss | 0.0211    |
|    std                  | 0.24      |
|    value_loss           | 0.0113    |
---------------------------------------
Eval num_timesteps=1980000, episode_reward=-1.03 +/- 0.06
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1.03      |
| time/                   |            |
|    total_timesteps      | 1980000    |
| train/                  |            |
|    approx_kl            | 0.28747597 |
|    clip_fraction        | 0.484      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.00627   |
|    explained_variance   | 0.665      |
|    learning_rate        | 0.00161    |
|    loss                 | 0.0359     |
|    n_updates            | 9660       |
|    policy_gradient_loss | 0.00912    |
|    std                  | 0.242      |
|    value_loss           | 0.0369     |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 623     |
|    iterations      | 967     |
|    time_elapsed    | 3177    |
|    total_timesteps | 1980416 |
--------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 623       |
|    iterations           | 968       |
|    time_elapsed         | 3180      |
|    total_timesteps      | 1982464   |
| train/                  |           |
|    approx_kl            | 0.2608875 |
|    clip_fraction        | 0.444     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00128  |
|    explained_variance   | 0.724     |
|    learning_rate        | 0.00161   |
|    loss                 | 0.019     |
|    n_updates            | 9670      |
|    policy_gradient_loss | 0.0148    |
|    std                  | 0.24      |
|    value_loss           | 0.0138    |
---------------------------------------
box reached target
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 623        |
|    iterations           | 969        |
|    time_elapsed         | 3183       |
|    total_timesteps      | 1984512    |
| train/                  |            |
|    approx_kl            | 0.21671085 |
|    clip_fraction        | 0.39       |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.0247     |
|    explained_variance   | 0.66       |
|    learning_rate        | 0.00161    |
|    loss                 | 0.0134     |
|    n_updates            | 9680       |
|    policy_gradient_loss | -0.000106  |
|    std                  | 0.238      |
|    value_loss           | 0.00944    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 623        |
|    iterations           | 970        |
|    time_elapsed         | 3186       |
|    total_timesteps      | 1986560    |
| train/                  |            |
|    approx_kl            | 0.35351515 |
|    clip_fraction        | 0.488      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.00785    |
|    explained_variance   | 0.426      |
|    learning_rate        | 0.00161    |
|    loss                 | 0.00718    |
|    n_updates            | 9690       |
|    policy_gradient_loss | 0.0282     |
|    std                  | 0.24       |
|    value_loss           | 0.0752     |
----------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 623       |
|    iterations           | 971       |
|    time_elapsed         | 3190      |
|    total_timesteps      | 1988608   |
| train/                  |           |
|    approx_kl            | 0.7553644 |
|    clip_fraction        | 0.477     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.021    |
|    explained_variance   | -0.117    |
|    learning_rate        | 0.00161   |
|    loss                 | 0.0238    |
|    n_updates            | 9700      |
|    policy_gradient_loss | 0.0175    |
|    std                  | 0.243     |
|    value_loss           | 0.0051    |
---------------------------------------
box reached target
box reached target
Eval num_timesteps=1990000, episode_reward=0.26 +/- 2.52
Episode length: 283.60 +/- 32.80
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 284        |
|    mean_reward          | 0.261      |
| time/                   |            |
|    total_timesteps      | 1990000    |
| train/                  |            |
|    approx_kl            | 0.32570177 |
|    clip_fraction        | 0.444      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.0462    |
|    explained_variance   | 0.649      |
|    learning_rate        | 0.00161    |
|    loss                 | 0.0504     |
|    n_updates            | 9710       |
|    policy_gradient_loss | 0.0101     |
|    std                  | 0.25       |
|    value_loss           | 0.0175     |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 623     |
|    iterations      | 972     |
|    time_elapsed    | 3193    |
|    total_timesteps | 1990656 |
--------------------------------
box reached target
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 623        |
|    iterations           | 973        |
|    time_elapsed         | 3197       |
|    total_timesteps      | 1992704    |
| train/                  |            |
|    approx_kl            | 0.16777077 |
|    clip_fraction        | 0.424      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.0645    |
|    explained_variance   | 0.753      |
|    learning_rate        | 0.00161    |
|    loss                 | -0.0142    |
|    n_updates            | 9720       |
|    policy_gradient_loss | 0.015      |
|    std                  | 0.247      |
|    value_loss           | 0.00881    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 623        |
|    iterations           | 974        |
|    time_elapsed         | 3200       |
|    total_timesteps      | 1994752    |
| train/                  |            |
|    approx_kl            | 0.24437188 |
|    clip_fraction        | 0.422      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.0389    |
|    explained_variance   | 0.903      |
|    learning_rate        | 0.00161    |
|    loss                 | -0.0352    |
|    n_updates            | 9730       |
|    policy_gradient_loss | 0.00759    |
|    std                  | 0.245      |
|    value_loss           | 0.0146     |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 623        |
|    iterations           | 975        |
|    time_elapsed         | 3203       |
|    total_timesteps      | 1996800    |
| train/                  |            |
|    approx_kl            | 0.44845492 |
|    clip_fraction        | 0.392      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.0091     |
|    explained_variance   | 0.815      |
|    learning_rate        | 0.00161    |
|    loss                 | -0.0516    |
|    n_updates            | 9740       |
|    policy_gradient_loss | 0.0168     |
|    std                  | 0.237      |
|    value_loss           | 0.00315    |
----------------------------------------
box reached target
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 623        |
|    iterations           | 976        |
|    time_elapsed         | 3206       |
|    total_timesteps      | 1998848    |
| train/                  |            |
|    approx_kl            | 0.34541953 |
|    clip_fraction        | 0.433      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.0212    |
|    explained_variance   | 0.603      |
|    learning_rate        | 0.00161    |
|    loss                 | 0.0195     |
|    n_updates            | 9750       |
|    policy_gradient_loss | 0.0243     |
|    std                  | 0.246      |
|    value_loss           | 0.0148     |
----------------------------------------
Eval num_timesteps=2000000, episode_reward=-0.83 +/- 0.34
Episode length: 300.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 300       |
|    mean_reward          | -0.832    |
| time/                   |           |
|    total_timesteps      | 2000000   |
| train/                  |           |
|    approx_kl            | 0.6143795 |
|    clip_fraction        | 0.506     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0502   |
|    explained_variance   | 0.878     |
|    learning_rate        | 0.00161   |
|    loss                 | -0.024    |
|    n_updates            | 9760      |
|    policy_gradient_loss | 0.0238    |
|    std                  | 0.249     |
|    value_loss           | 0.0243    |
---------------------------------------
--------------------------------
| time/              |         |
|    fps             | 623     |
|    iterations      | 977     |
|    time_elapsed    | 3210    |
|    total_timesteps | 2000896 |
--------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 623        |
|    iterations           | 978        |
|    time_elapsed         | 3213       |
|    total_timesteps      | 2002944    |
| train/                  |            |
|    approx_kl            | 0.33439183 |
|    clip_fraction        | 0.467      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.0516    |
|    explained_variance   | 0.199      |
|    learning_rate        | 0.00161    |
|    loss                 | -0.0283    |
|    n_updates            | 9770       |
|    policy_gradient_loss | 0.012      |
|    std                  | 0.245      |
|    value_loss           | 0.00295    |
----------------------------------------
box reached target
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 623       |
|    iterations           | 979       |
|    time_elapsed         | 3216      |
|    total_timesteps      | 2004992   |
| train/                  |           |
|    approx_kl            | 0.2925872 |
|    clip_fraction        | 0.42      |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0241   |
|    explained_variance   | 0.94      |
|    learning_rate        | 0.00161   |
|    loss                 | -0.0538   |
|    n_updates            | 9780      |
|    policy_gradient_loss | 0.00827   |
|    std                  | 0.242     |
|    value_loss           | 0.00834   |
---------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 623       |
|    iterations           | 980       |
|    time_elapsed         | 3219      |
|    total_timesteps      | 2007040   |
| train/                  |           |
|    approx_kl            | 0.5680975 |
|    clip_fraction        | 0.46      |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.0247    |
|    explained_variance   | 0.84      |
|    learning_rate        | 0.00161   |
|    loss                 | 0.0424    |
|    n_updates            | 9790      |
|    policy_gradient_loss | -0.00051  |
|    std                  | 0.235     |
|    value_loss           | 0.0106    |
---------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 623        |
|    iterations           | 981        |
|    time_elapsed         | 3222       |
|    total_timesteps      | 2009088    |
| train/                  |            |
|    approx_kl            | 0.15584558 |
|    clip_fraction        | 0.409      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.0407     |
|    explained_variance   | 0.781      |
|    learning_rate        | 0.00161    |
|    loss                 | 0.0576     |
|    n_updates            | 9800       |
|    policy_gradient_loss | 0.0127     |
|    std                  | 0.239      |
|    value_loss           | 0.0118     |
----------------------------------------
box reached target
Eval num_timesteps=2010000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1         |
| time/                   |            |
|    total_timesteps      | 2010000    |
| train/                  |            |
|    approx_kl            | 0.39336574 |
|    clip_fraction        | 0.444      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.0338     |
|    explained_variance   | 0.742      |
|    learning_rate        | 0.00161    |
|    loss                 | -0.0329    |
|    n_updates            | 9810       |
|    policy_gradient_loss | 0.0133     |
|    std                  | 0.235      |
|    value_loss           | 0.0438     |
----------------------------------------
box reached target
--------------------------------
| time/              |         |
|    fps             | 623     |
|    iterations      | 982     |
|    time_elapsed    | 3226    |
|    total_timesteps | 2011136 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 623        |
|    iterations           | 983        |
|    time_elapsed         | 3229       |
|    total_timesteps      | 2013184    |
| train/                  |            |
|    approx_kl            | 0.32055497 |
|    clip_fraction        | 0.455      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.0467     |
|    explained_variance   | 0.819      |
|    learning_rate        | 0.00161    |
|    loss                 | -0.0159    |
|    n_updates            | 9820       |
|    policy_gradient_loss | 0.0153     |
|    std                  | 0.235      |
|    value_loss           | 0.0398     |
----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 623       |
|    iterations           | 984       |
|    time_elapsed         | 3232      |
|    total_timesteps      | 2015232   |
| train/                  |           |
|    approx_kl            | 0.5097378 |
|    clip_fraction        | 0.464     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.0393    |
|    explained_variance   | 0.664     |
|    learning_rate        | 0.00161   |
|    loss                 | -0.0316   |
|    n_updates            | 9830      |
|    policy_gradient_loss | 0.00643   |
|    std                  | 0.235     |
|    value_loss           | 0.0262    |
---------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 623        |
|    iterations           | 985        |
|    time_elapsed         | 3235       |
|    total_timesteps      | 2017280    |
| train/                  |            |
|    approx_kl            | 0.28342184 |
|    clip_fraction        | 0.404      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.0572     |
|    explained_variance   | 0.666      |
|    learning_rate        | 0.00161    |
|    loss                 | 0.0162     |
|    n_updates            | 9840       |
|    policy_gradient_loss | 0.0077     |
|    std                  | 0.233      |
|    value_loss           | 0.00956    |
----------------------------------------
box reached target
box reached target
box reached target
box reached target
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 623       |
|    iterations           | 986       |
|    time_elapsed         | 3238      |
|    total_timesteps      | 2019328   |
| train/                  |           |
|    approx_kl            | 0.4787807 |
|    clip_fraction        | 0.47      |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.0646    |
|    explained_variance   | 0.801     |
|    learning_rate        | 0.00161   |
|    loss                 | -0.0446   |
|    n_updates            | 9850      |
|    policy_gradient_loss | 0.00382   |
|    std                  | 0.236     |
|    value_loss           | 0.0194    |
---------------------------------------
box reached target
Eval num_timesteps=2020000, episode_reward=-0.89 +/- 0.39
Episode length: 300.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 300       |
|    mean_reward          | -0.892    |
| time/                   |           |
|    total_timesteps      | 2020000   |
| train/                  |           |
|    approx_kl            | 3.2629058 |
|    clip_fraction        | 0.564     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.0866    |
|    explained_variance   | 0.855     |
|    learning_rate        | 0.00161   |
|    loss                 | -0.0279   |
|    n_updates            | 9860      |
|    policy_gradient_loss | 0.0103    |
|    std                  | 0.227     |
|    value_loss           | 0.0366    |
---------------------------------------
box reached target
--------------------------------
| time/              |         |
|    fps             | 623     |
|    iterations      | 987     |
|    time_elapsed    | 3242    |
|    total_timesteps | 2021376 |
--------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 623       |
|    iterations           | 988       |
|    time_elapsed         | 3245      |
|    total_timesteps      | 2023424   |
| train/                  |           |
|    approx_kl            | 0.5203542 |
|    clip_fraction        | 0.475     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.0754    |
|    explained_variance   | 0.867     |
|    learning_rate        | 0.00161   |
|    loss                 | 0.0692    |
|    n_updates            | 9870      |
|    policy_gradient_loss | 0.0139    |
|    std                  | 0.233     |
|    value_loss           | 0.015     |
---------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 623       |
|    iterations           | 989       |
|    time_elapsed         | 3248      |
|    total_timesteps      | 2025472   |
| train/                  |           |
|    approx_kl            | 0.7684893 |
|    clip_fraction        | 0.478     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.0804    |
|    explained_variance   | 0.765     |
|    learning_rate        | 0.00161   |
|    loss                 | -0.0199   |
|    n_updates            | 9880      |
|    policy_gradient_loss | 0.00774   |
|    std                  | 0.232     |
|    value_loss           | 0.0172    |
---------------------------------------
box reached target
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 623        |
|    iterations           | 990        |
|    time_elapsed         | 3251       |
|    total_timesteps      | 2027520    |
| train/                  |            |
|    approx_kl            | 0.17868897 |
|    clip_fraction        | 0.409      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.0624     |
|    explained_variance   | 0.88       |
|    learning_rate        | 0.00161    |
|    loss                 | -0.0245    |
|    n_updates            | 9890       |
|    policy_gradient_loss | 0.0245     |
|    std                  | 0.236      |
|    value_loss           | 0.00772    |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 623        |
|    iterations           | 991        |
|    time_elapsed         | 3254       |
|    total_timesteps      | 2029568    |
| train/                  |            |
|    approx_kl            | 0.46503145 |
|    clip_fraction        | 0.468      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.0721     |
|    explained_variance   | 0.784      |
|    learning_rate        | 0.0016     |
|    loss                 | -0.000781  |
|    n_updates            | 9900       |
|    policy_gradient_loss | 0.00196    |
|    std                  | 0.23       |
|    value_loss           | 0.0337     |
----------------------------------------
box reached target
Eval num_timesteps=2030000, episode_reward=0.20 +/- 2.40
Episode length: 276.20 +/- 47.60
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 276       |
|    mean_reward          | 0.202     |
| time/                   |           |
|    total_timesteps      | 2030000   |
| train/                  |           |
|    approx_kl            | 0.5990655 |
|    clip_fraction        | 0.434     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.107     |
|    explained_variance   | 0.749     |
|    learning_rate        | 0.0016    |
|    loss                 | 0.0488    |
|    n_updates            | 9910      |
|    policy_gradient_loss | 0.0165    |
|    std                  | 0.228     |
|    value_loss           | 0.0233    |
---------------------------------------
box reached target
--------------------------------
| time/              |         |
|    fps             | 623     |
|    iterations      | 992     |
|    time_elapsed    | 3258    |
|    total_timesteps | 2031616 |
--------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 623        |
|    iterations           | 993        |
|    time_elapsed         | 3261       |
|    total_timesteps      | 2033664    |
| train/                  |            |
|    approx_kl            | 0.55300343 |
|    clip_fraction        | 0.473      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.132      |
|    explained_variance   | 0.731      |
|    learning_rate        | 0.0016     |
|    loss                 | 0.0102     |
|    n_updates            | 9920       |
|    policy_gradient_loss | 0.0254     |
|    std                  | 0.225      |
|    value_loss           | 0.0322     |
----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 623       |
|    iterations           | 994       |
|    time_elapsed         | 3264      |
|    total_timesteps      | 2035712   |
| train/                  |           |
|    approx_kl            | 0.6177202 |
|    clip_fraction        | 0.48      |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.144     |
|    explained_variance   | 0.79      |
|    learning_rate        | 0.0016    |
|    loss                 | -0.0119   |
|    n_updates            | 9930      |
|    policy_gradient_loss | 0.0151    |
|    std                  | 0.222     |
|    value_loss           | 0.0179    |
---------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 623       |
|    iterations           | 995       |
|    time_elapsed         | 3267      |
|    total_timesteps      | 2037760   |
| train/                  |           |
|    approx_kl            | 0.5491753 |
|    clip_fraction        | 0.438     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.154     |
|    explained_variance   | 0.607     |
|    learning_rate        | 0.0016    |
|    loss                 | -0.0706   |
|    n_updates            | 9940      |
|    policy_gradient_loss | 0.0173    |
|    std                  | 0.223     |
|    value_loss           | 0.0233    |
---------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 623       |
|    iterations           | 996       |
|    time_elapsed         | 3271      |
|    total_timesteps      | 2039808   |
| train/                  |           |
|    approx_kl            | 0.5520061 |
|    clip_fraction        | 0.449     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.174     |
|    explained_variance   | 0.31      |
|    learning_rate        | 0.0016    |
|    loss                 | 0.0287    |
|    n_updates            | 9950      |
|    policy_gradient_loss | 0.023     |
|    std                  | 0.222     |
|    value_loss           | 0.00969   |
---------------------------------------
box reached target
Eval num_timesteps=2040000, episode_reward=0.30 +/- 2.58
Episode length: 283.60 +/- 32.80
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 284       |
|    mean_reward          | 0.295     |
| time/                   |           |
|    total_timesteps      | 2040000   |
| train/                  |           |
|    approx_kl            | 0.8327191 |
|    clip_fraction        | 0.506     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.154     |
|    explained_variance   | 0.753     |
|    learning_rate        | 0.0016    |
|    loss                 | 0.0432    |
|    n_updates            | 9960      |
|    policy_gradient_loss | 0.0175    |
|    std                  | 0.221     |
|    value_loss           | 0.00946   |
---------------------------------------
box reached target
box reached target
--------------------------------
| time/              |         |
|    fps             | 623     |
|    iterations      | 997     |
|    time_elapsed    | 3274    |
|    total_timesteps | 2041856 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 623        |
|    iterations           | 998        |
|    time_elapsed         | 3278       |
|    total_timesteps      | 2043904    |
| train/                  |            |
|    approx_kl            | 0.41705906 |
|    clip_fraction        | 0.482      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.169      |
|    explained_variance   | 0.617      |
|    learning_rate        | 0.0016     |
|    loss                 | -0.0438    |
|    n_updates            | 9970       |
|    policy_gradient_loss | 0.0155     |
|    std                  | 0.223      |
|    value_loss           | 0.0331     |
----------------------------------------
box reached target
box reached target
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 623       |
|    iterations           | 999       |
|    time_elapsed         | 3281      |
|    total_timesteps      | 2045952   |
| train/                  |           |
|    approx_kl            | 0.4705497 |
|    clip_fraction        | 0.473     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.163     |
|    explained_variance   | 0.685     |
|    learning_rate        | 0.0016    |
|    loss                 | 0.00975   |
|    n_updates            | 9980      |
|    policy_gradient_loss | 0.0281    |
|    std                  | 0.222     |
|    value_loss           | 0.0188    |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 623        |
|    iterations           | 1000       |
|    time_elapsed         | 3284       |
|    total_timesteps      | 2048000    |
| train/                  |            |
|    approx_kl            | 0.43298256 |
|    clip_fraction        | 0.48       |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.117      |
|    explained_variance   | 0.741      |
|    learning_rate        | 0.0016     |
|    loss                 | 0.0078     |
|    n_updates            | 9990       |
|    policy_gradient_loss | 0.0426     |
|    std                  | 0.232      |
|    value_loss           | 0.0289     |
----------------------------------------
Eval num_timesteps=2050000, episode_reward=-0.78 +/- 0.43
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -0.785     |
| time/                   |            |
|    total_timesteps      | 2050000    |
| train/                  |            |
|    approx_kl            | 0.61950624 |
|    clip_fraction        | 0.449      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.0691     |
|    explained_variance   | 0.832      |
|    learning_rate        | 0.0016     |
|    loss                 | 0.0231     |
|    n_updates            | 10000      |
|    policy_gradient_loss | 0.00356    |
|    std                  | 0.232      |
|    value_loss           | 0.00551    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 623     |
|    iterations      | 1001    |
|    time_elapsed    | 3288    |
|    total_timesteps | 2050048 |
--------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 623        |
|    iterations           | 1002       |
|    time_elapsed         | 3291       |
|    total_timesteps      | 2052096    |
| train/                  |            |
|    approx_kl            | 0.35291484 |
|    clip_fraction        | 0.465      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.0742     |
|    explained_variance   | 0.384      |
|    learning_rate        | 0.0016     |
|    loss                 | -0.0229    |
|    n_updates            | 10010      |
|    policy_gradient_loss | 0.0139     |
|    std                  | 0.23       |
|    value_loss           | 0.0106     |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 623        |
|    iterations           | 1003       |
|    time_elapsed         | 3294       |
|    total_timesteps      | 2054144    |
| train/                  |            |
|    approx_kl            | 0.42846572 |
|    clip_fraction        | 0.468      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.101      |
|    explained_variance   | 0.461      |
|    learning_rate        | 0.0016     |
|    loss                 | 0.0325     |
|    n_updates            | 10020      |
|    policy_gradient_loss | 0.0136     |
|    std                  | 0.228      |
|    value_loss           | 0.014      |
----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 623       |
|    iterations           | 1004      |
|    time_elapsed         | 3297      |
|    total_timesteps      | 2056192   |
| train/                  |           |
|    approx_kl            | 0.5577823 |
|    clip_fraction        | 0.479     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.118     |
|    explained_variance   | 0.632     |
|    learning_rate        | 0.0016    |
|    loss                 | 0.198     |
|    n_updates            | 10030     |
|    policy_gradient_loss | 0.012     |
|    std                  | 0.225     |
|    value_loss           | 0.011     |
---------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 623        |
|    iterations           | 1005       |
|    time_elapsed         | 3300       |
|    total_timesteps      | 2058240    |
| train/                  |            |
|    approx_kl            | 0.49872896 |
|    clip_fraction        | 0.444      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.105      |
|    explained_variance   | 0.466      |
|    learning_rate        | 0.0016     |
|    loss                 | 0.0351     |
|    n_updates            | 10040      |
|    policy_gradient_loss | 0.00587    |
|    std                  | 0.228      |
|    value_loss           | 0.0103     |
----------------------------------------
Eval num_timesteps=2060000, episode_reward=-0.93 +/- 0.29
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -0.931     |
| time/                   |            |
|    total_timesteps      | 2060000    |
| train/                  |            |
|    approx_kl            | 0.38513872 |
|    clip_fraction        | 0.5        |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.128      |
|    explained_variance   | 0.0721     |
|    learning_rate        | 0.0016     |
|    loss                 | 0.112      |
|    n_updates            | 10050      |
|    policy_gradient_loss | 0.0103     |
|    std                  | 0.225      |
|    value_loss           | 0.091      |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 623     |
|    iterations      | 1006    |
|    time_elapsed    | 3304    |
|    total_timesteps | 2060288 |
--------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 623        |
|    iterations           | 1007       |
|    time_elapsed         | 3307       |
|    total_timesteps      | 2062336    |
| train/                  |            |
|    approx_kl            | 0.63568974 |
|    clip_fraction        | 0.535      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.173      |
|    explained_variance   | 0.749      |
|    learning_rate        | 0.0016     |
|    loss                 | 0.0977     |
|    n_updates            | 10060      |
|    policy_gradient_loss | 0.0234     |
|    std                  | 0.217      |
|    value_loss           | 0.00674    |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 623        |
|    iterations           | 1008       |
|    time_elapsed         | 3310       |
|    total_timesteps      | 2064384    |
| train/                  |            |
|    approx_kl            | 0.33495182 |
|    clip_fraction        | 0.499      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.227      |
|    explained_variance   | 0.14       |
|    learning_rate        | 0.0016     |
|    loss                 | 0.0295     |
|    n_updates            | 10070      |
|    policy_gradient_loss | 0.0212     |
|    std                  | 0.213      |
|    value_loss           | 0.0282     |
----------------------------------------
box reached target
box reached target
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 623       |
|    iterations           | 1009      |
|    time_elapsed         | 3313      |
|    total_timesteps      | 2066432   |
| train/                  |           |
|    approx_kl            | 0.5186254 |
|    clip_fraction        | 0.479     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.282     |
|    explained_variance   | 0.162     |
|    learning_rate        | 0.0016    |
|    loss                 | -0.0421   |
|    n_updates            | 10080     |
|    policy_gradient_loss | 0.0247    |
|    std                  | 0.206     |
|    value_loss           | 0.0832    |
---------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 623       |
|    iterations           | 1010      |
|    time_elapsed         | 3316      |
|    total_timesteps      | 2068480   |
| train/                  |           |
|    approx_kl            | 0.6216917 |
|    clip_fraction        | 0.558     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.306     |
|    explained_variance   | 0.483     |
|    learning_rate        | 0.0016    |
|    loss                 | 0.104     |
|    n_updates            | 10090     |
|    policy_gradient_loss | 0.0275    |
|    std                  | 0.207     |
|    value_loss           | 0.0556    |
---------------------------------------
box reached target
Eval num_timesteps=2070000, episode_reward=0.51 +/- 2.36
Episode length: 273.40 +/- 53.20
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 273        |
|    mean_reward          | 0.509      |
| time/                   |            |
|    total_timesteps      | 2070000    |
| train/                  |            |
|    approx_kl            | 0.20138499 |
|    clip_fraction        | 0.476      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.271      |
|    explained_variance   | 0.422      |
|    learning_rate        | 0.0016     |
|    loss                 | -0.0277    |
|    n_updates            | 10100      |
|    policy_gradient_loss | 0.0325     |
|    std                  | 0.213      |
|    value_loss           | 0.00678    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 623     |
|    iterations      | 1011    |
|    time_elapsed    | 3320    |
|    total_timesteps | 2070528 |
--------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 623        |
|    iterations           | 1012       |
|    time_elapsed         | 3323       |
|    total_timesteps      | 2072576    |
| train/                  |            |
|    approx_kl            | 0.24777015 |
|    clip_fraction        | 0.453      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.251      |
|    explained_variance   | 0.458      |
|    learning_rate        | 0.0016     |
|    loss                 | -0.0202    |
|    n_updates            | 10110      |
|    policy_gradient_loss | 0.00323    |
|    std                  | 0.208      |
|    value_loss           | 0.0178     |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 623        |
|    iterations           | 1013       |
|    time_elapsed         | 3326       |
|    total_timesteps      | 2074624    |
| train/                  |            |
|    approx_kl            | 0.18998909 |
|    clip_fraction        | 0.448      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.294      |
|    explained_variance   | 0.753      |
|    learning_rate        | 0.0016     |
|    loss                 | 0.0528     |
|    n_updates            | 10120      |
|    policy_gradient_loss | 0.0157     |
|    std                  | 0.209      |
|    value_loss           | 0.0164     |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 623        |
|    iterations           | 1014       |
|    time_elapsed         | 3329       |
|    total_timesteps      | 2076672    |
| train/                  |            |
|    approx_kl            | 0.20585153 |
|    clip_fraction        | 0.48       |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.248      |
|    explained_variance   | 0.479      |
|    learning_rate        | 0.0016     |
|    loss                 | 0.0428     |
|    n_updates            | 10130      |
|    policy_gradient_loss | 0.0141     |
|    std                  | 0.214      |
|    value_loss           | 0.0572     |
----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 623       |
|    iterations           | 1015      |
|    time_elapsed         | 3332      |
|    total_timesteps      | 2078720   |
| train/                  |           |
|    approx_kl            | 1.5208561 |
|    clip_fraction        | 0.595     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.235     |
|    explained_variance   | 0.403     |
|    learning_rate        | 0.0016    |
|    loss                 | 0.0396    |
|    n_updates            | 10140     |
|    policy_gradient_loss | 0.0212    |
|    std                  | 0.209     |
|    value_loss           | 0.0424    |
---------------------------------------
box reached target
Eval num_timesteps=2080000, episode_reward=-0.90 +/- 0.36
Episode length: 300.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 300       |
|    mean_reward          | -0.9      |
| time/                   |           |
|    total_timesteps      | 2080000   |
| train/                  |           |
|    approx_kl            | 0.8134204 |
|    clip_fraction        | 0.467     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.282     |
|    explained_variance   | 0.646     |
|    learning_rate        | 0.00159   |
|    loss                 | -0.0453   |
|    n_updates            | 10150     |
|    policy_gradient_loss | 0.0146    |
|    std                  | 0.208     |
|    value_loss           | 0.00985   |
---------------------------------------
--------------------------------
| time/              |         |
|    fps             | 623     |
|    iterations      | 1016    |
|    time_elapsed    | 3336    |
|    total_timesteps | 2080768 |
--------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 623       |
|    iterations           | 1017      |
|    time_elapsed         | 3339      |
|    total_timesteps      | 2082816   |
| train/                  |           |
|    approx_kl            | 0.2446523 |
|    clip_fraction        | 0.435     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.303     |
|    explained_variance   | 0.414     |
|    learning_rate        | 0.00159   |
|    loss                 | 0.00943   |
|    n_updates            | 10160     |
|    policy_gradient_loss | 0.0154    |
|    std                  | 0.209     |
|    value_loss           | 0.029     |
---------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 623       |
|    iterations           | 1018      |
|    time_elapsed         | 3342      |
|    total_timesteps      | 2084864   |
| train/                  |           |
|    approx_kl            | 1.7495043 |
|    clip_fraction        | 0.589     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.335     |
|    explained_variance   | 0.552     |
|    learning_rate        | 0.00159   |
|    loss                 | 0.00798   |
|    n_updates            | 10170     |
|    policy_gradient_loss | 0.0651    |
|    std                  | 0.2       |
|    value_loss           | 0.0271    |
---------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 623       |
|    iterations           | 1019      |
|    time_elapsed         | 3345      |
|    total_timesteps      | 2086912   |
| train/                  |           |
|    approx_kl            | 1.3089627 |
|    clip_fraction        | 0.546     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.388     |
|    explained_variance   | 0.607     |
|    learning_rate        | 0.00159   |
|    loss                 | 0.0192    |
|    n_updates            | 10180     |
|    policy_gradient_loss | 0.0022    |
|    std                  | 0.195     |
|    value_loss           | 0.0114    |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 623        |
|    iterations           | 1020       |
|    time_elapsed         | 3348       |
|    total_timesteps      | 2088960    |
| train/                  |            |
|    approx_kl            | 0.54790527 |
|    clip_fraction        | 0.562      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.427      |
|    explained_variance   | 0.689      |
|    learning_rate        | 0.00159    |
|    loss                 | 0.0408     |
|    n_updates            | 10190      |
|    policy_gradient_loss | 0.018      |
|    std                  | 0.194      |
|    value_loss           | 0.00553    |
----------------------------------------
box reached target
Eval num_timesteps=2090000, episode_reward=0.56 +/- 2.35
Episode length: 278.20 +/- 43.60
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 278       |
|    mean_reward          | 0.562     |
| time/                   |           |
|    total_timesteps      | 2090000   |
| train/                  |           |
|    approx_kl            | 0.7007741 |
|    clip_fraction        | 0.499     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.413     |
|    explained_variance   | -0.346    |
|    learning_rate        | 0.00159   |
|    loss                 | -0.0167   |
|    n_updates            | 10200     |
|    policy_gradient_loss | 0.0177    |
|    std                  | 0.197     |
|    value_loss           | 0.00406   |
---------------------------------------
--------------------------------
| time/              |         |
|    fps             | 623     |
|    iterations      | 1021    |
|    time_elapsed    | 3352    |
|    total_timesteps | 2091008 |
--------------------------------
box reached target
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 623       |
|    iterations           | 1022      |
|    time_elapsed         | 3355      |
|    total_timesteps      | 2093056   |
| train/                  |           |
|    approx_kl            | 0.3612925 |
|    clip_fraction        | 0.521     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.34      |
|    explained_variance   | 0.694     |
|    learning_rate        | 0.00159   |
|    loss                 | -0.00772  |
|    n_updates            | 10210     |
|    policy_gradient_loss | 0.0342    |
|    std                  | 0.205     |
|    value_loss           | 0.00867   |
---------------------------------------
box reached target
--------------------------------------
| time/                   |          |
|    fps                  | 623      |
|    iterations           | 1023     |
|    time_elapsed         | 3358     |
|    total_timesteps      | 2095104  |
| train/                  |          |
|    approx_kl            | 8.738371 |
|    clip_fraction        | 0.619    |
|    clip_range           | 0.2      |
|    entropy_loss         | 0.316    |
|    explained_variance   | 0.827    |
|    learning_rate        | 0.00159  |
|    loss                 | 0.0794   |
|    n_updates            | 10220    |
|    policy_gradient_loss | 0.0306   |
|    std                  | 0.207    |
|    value_loss           | 0.0207   |
--------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 623        |
|    iterations           | 1024       |
|    time_elapsed         | 3361       |
|    total_timesteps      | 2097152    |
| train/                  |            |
|    approx_kl            | 0.17203246 |
|    clip_fraction        | 0.43       |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.283      |
|    explained_variance   | 0.559      |
|    learning_rate        | 0.00159    |
|    loss                 | -0.0394    |
|    n_updates            | 10230      |
|    policy_gradient_loss | 0.0263     |
|    std                  | 0.213      |
|    value_loss           | 0.0193     |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 623        |
|    iterations           | 1025       |
|    time_elapsed         | 3364       |
|    total_timesteps      | 2099200    |
| train/                  |            |
|    approx_kl            | 0.22534478 |
|    clip_fraction        | 0.448      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.244      |
|    explained_variance   | 0.752      |
|    learning_rate        | 0.00159    |
|    loss                 | 0.105      |
|    n_updates            | 10240      |
|    policy_gradient_loss | 0.00805    |
|    std                  | 0.212      |
|    value_loss           | 0.0119     |
----------------------------------------
box reached target
Eval num_timesteps=2100000, episode_reward=-1.05 +/- 0.09
Episode length: 300.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 300       |
|    mean_reward          | -1.05     |
| time/                   |           |
|    total_timesteps      | 2100000   |
| train/                  |           |
|    approx_kl            | 0.4085678 |
|    clip_fraction        | 0.557     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.211     |
|    explained_variance   | 0.534     |
|    learning_rate        | 0.00159   |
|    loss                 | 0.0493    |
|    n_updates            | 10250     |
|    policy_gradient_loss | 0.0279    |
|    std                  | 0.214     |
|    value_loss           | 0.00948   |
---------------------------------------
box reached target
--------------------------------
| time/              |         |
|    fps             | 623     |
|    iterations      | 1026    |
|    time_elapsed    | 3368    |
|    total_timesteps | 2101248 |
--------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 623        |
|    iterations           | 1027       |
|    time_elapsed         | 3371       |
|    total_timesteps      | 2103296    |
| train/                  |            |
|    approx_kl            | 0.32308733 |
|    clip_fraction        | 0.479      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.212      |
|    explained_variance   | 0.762      |
|    learning_rate        | 0.00159    |
|    loss                 | 0.00908    |
|    n_updates            | 10260      |
|    policy_gradient_loss | 0.027      |
|    std                  | 0.218      |
|    value_loss           | 0.0113     |
----------------------------------------
box reached target
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 623        |
|    iterations           | 1028       |
|    time_elapsed         | 3375       |
|    total_timesteps      | 2105344    |
| train/                  |            |
|    approx_kl            | 0.35303694 |
|    clip_fraction        | 0.515      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.191      |
|    explained_variance   | 0.503      |
|    learning_rate        | 0.00159    |
|    loss                 | 0.0088     |
|    n_updates            | 10270      |
|    policy_gradient_loss | 0.0209     |
|    std                  | 0.218      |
|    value_loss           | 0.111      |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 623        |
|    iterations           | 1029       |
|    time_elapsed         | 3378       |
|    total_timesteps      | 2107392    |
| train/                  |            |
|    approx_kl            | 0.36615086 |
|    clip_fraction        | 0.484      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.2        |
|    explained_variance   | 0.654      |
|    learning_rate        | 0.00159    |
|    loss                 | -0.0209    |
|    n_updates            | 10280      |
|    policy_gradient_loss | 0.0282     |
|    std                  | 0.218      |
|    value_loss           | 0.0885     |
----------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 623       |
|    iterations           | 1030      |
|    time_elapsed         | 3381      |
|    total_timesteps      | 2109440   |
| train/                  |           |
|    approx_kl            | 0.3213824 |
|    clip_fraction        | 0.46      |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.161     |
|    explained_variance   | 0.659     |
|    learning_rate        | 0.00159   |
|    loss                 | 0.0727    |
|    n_updates            | 10290     |
|    policy_gradient_loss | 0.0196    |
|    std                  | 0.224     |
|    value_loss           | 0.0111    |
---------------------------------------
box reached target
box reached target
Eval num_timesteps=2110000, episode_reward=1.53 +/- 2.86
Episode length: 250.80 +/- 60.38
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 251        |
|    mean_reward          | 1.53       |
| time/                   |            |
|    total_timesteps      | 2110000    |
| train/                  |            |
|    approx_kl            | 0.39476314 |
|    clip_fraction        | 0.405      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.144      |
|    explained_variance   | 0.708      |
|    learning_rate        | 0.00159    |
|    loss                 | 0.0505     |
|    n_updates            | 10300      |
|    policy_gradient_loss | 0.00931    |
|    std                  | 0.225      |
|    value_loss           | 0.0167     |
----------------------------------------
box reached target
--------------------------------
| time/              |         |
|    fps             | 623     |
|    iterations      | 1031    |
|    time_elapsed    | 3384    |
|    total_timesteps | 2111488 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 623        |
|    iterations           | 1032       |
|    time_elapsed         | 3387       |
|    total_timesteps      | 2113536    |
| train/                  |            |
|    approx_kl            | 0.22871459 |
|    clip_fraction        | 0.462      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.158      |
|    explained_variance   | 0.774      |
|    learning_rate        | 0.00159    |
|    loss                 | 0.0251     |
|    n_updates            | 10310      |
|    policy_gradient_loss | 0.00938    |
|    std                  | 0.223      |
|    value_loss           | 0.0114     |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 623        |
|    iterations           | 1033       |
|    time_elapsed         | 3391       |
|    total_timesteps      | 2115584    |
| train/                  |            |
|    approx_kl            | 0.29956532 |
|    clip_fraction        | 0.42       |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.125      |
|    explained_variance   | 0.645      |
|    learning_rate        | 0.00159    |
|    loss                 | -0.0417    |
|    n_updates            | 10320      |
|    policy_gradient_loss | 0.0157     |
|    std                  | 0.227      |
|    value_loss           | 0.0128     |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 623        |
|    iterations           | 1034       |
|    time_elapsed         | 3394       |
|    total_timesteps      | 2117632    |
| train/                  |            |
|    approx_kl            | 0.26125324 |
|    clip_fraction        | 0.422      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.0998     |
|    explained_variance   | 0.682      |
|    learning_rate        | 0.00159    |
|    loss                 | -0.0277    |
|    n_updates            | 10330      |
|    policy_gradient_loss | 0.00387    |
|    std                  | 0.23       |
|    value_loss           | 0.00424    |
----------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 623       |
|    iterations           | 1035      |
|    time_elapsed         | 3397      |
|    total_timesteps      | 2119680   |
| train/                  |           |
|    approx_kl            | 0.7313653 |
|    clip_fraction        | 0.46      |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.0882    |
|    explained_variance   | 0.234     |
|    learning_rate        | 0.00159   |
|    loss                 | 0.0188    |
|    n_updates            | 10340     |
|    policy_gradient_loss | 0.00498   |
|    std                  | 0.229     |
|    value_loss           | 0.0267    |
---------------------------------------
box reached target
box reached target
Eval num_timesteps=2120000, episode_reward=1.46 +/- 3.08
Episode length: 259.00 +/- 51.56
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 259        |
|    mean_reward          | 1.46       |
| time/                   |            |
|    total_timesteps      | 2120000    |
| train/                  |            |
|    approx_kl            | 0.21445791 |
|    clip_fraction        | 0.438      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.0621     |
|    explained_variance   | 0.854      |
|    learning_rate        | 0.00159    |
|    loss                 | -0.00913   |
|    n_updates            | 10350      |
|    policy_gradient_loss | 0.012      |
|    std                  | 0.234      |
|    value_loss           | 0.0152     |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 623     |
|    iterations      | 1036    |
|    time_elapsed    | 3400    |
|    total_timesteps | 2121728 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 623        |
|    iterations           | 1037       |
|    time_elapsed         | 3403       |
|    total_timesteps      | 2123776    |
| train/                  |            |
|    approx_kl            | 0.46684173 |
|    clip_fraction        | 0.457      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.0657     |
|    explained_variance   | 0.667      |
|    learning_rate        | 0.00159    |
|    loss                 | 0.0172     |
|    n_updates            | 10360      |
|    policy_gradient_loss | 0.00838    |
|    std                  | 0.231      |
|    value_loss           | 0.00497    |
----------------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 623        |
|    iterations           | 1038       |
|    time_elapsed         | 3407       |
|    total_timesteps      | 2125824    |
| train/                  |            |
|    approx_kl            | 0.30714744 |
|    clip_fraction        | 0.386      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.0782     |
|    explained_variance   | 0.652      |
|    learning_rate        | 0.00159    |
|    loss                 | -0.0107    |
|    n_updates            | 10370      |
|    policy_gradient_loss | -0.00344   |
|    std                  | 0.229      |
|    value_loss           | 0.00287    |
----------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 623       |
|    iterations           | 1039      |
|    time_elapsed         | 3410      |
|    total_timesteps      | 2127872   |
| train/                  |           |
|    approx_kl            | 0.5531938 |
|    clip_fraction        | 0.45      |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.137     |
|    explained_variance   | 0.4       |
|    learning_rate        | 0.00159   |
|    loss                 | 0.00366   |
|    n_updates            | 10380     |
|    policy_gradient_loss | 0.0137    |
|    std                  | 0.22      |
|    value_loss           | 0.0359    |
---------------------------------------
box reached target
box reached target
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 624       |
|    iterations           | 1040      |
|    time_elapsed         | 3413      |
|    total_timesteps      | 2129920   |
| train/                  |           |
|    approx_kl            | 0.4079526 |
|    clip_fraction        | 0.486     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.123     |
|    explained_variance   | 0.584     |
|    learning_rate        | 0.00159   |
|    loss                 | -0.0508   |
|    n_updates            | 10390     |
|    policy_gradient_loss | 0.0266    |
|    std                  | 0.231     |
|    value_loss           | 0.0227    |
---------------------------------------
Eval num_timesteps=2130000, episode_reward=-0.94 +/- 0.13
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -0.937     |
| time/                   |            |
|    total_timesteps      | 2130000    |
| train/                  |            |
|    approx_kl            | 0.21891782 |
|    clip_fraction        | 0.418      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.0743     |
|    explained_variance   | 0.891      |
|    learning_rate        | 0.00158    |
|    loss                 | 0.0378     |
|    n_updates            | 10400      |
|    policy_gradient_loss | 0.0221     |
|    std                  | 0.234      |
|    value_loss           | 0.0218     |
----------------------------------------
box reached target
box reached target
--------------------------------
| time/              |         |
|    fps             | 623     |
|    iterations      | 1041    |
|    time_elapsed    | 3417    |
|    total_timesteps | 2131968 |
--------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 623        |
|    iterations           | 1042       |
|    time_elapsed         | 3420       |
|    total_timesteps      | 2134016    |
| train/                  |            |
|    approx_kl            | 0.46138635 |
|    clip_fraction        | 0.475      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.104      |
|    explained_variance   | 0.713      |
|    learning_rate        | 0.00158    |
|    loss                 | -0.0044    |
|    n_updates            | 10410      |
|    policy_gradient_loss | 0.0049     |
|    std                  | 0.225      |
|    value_loss           | 0.0422     |
----------------------------------------
box reached target
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 623        |
|    iterations           | 1043       |
|    time_elapsed         | 3423       |
|    total_timesteps      | 2136064    |
| train/                  |            |
|    approx_kl            | 0.30359018 |
|    clip_fraction        | 0.422      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.112      |
|    explained_variance   | 0.842      |
|    learning_rate        | 0.00158    |
|    loss                 | -0.00326   |
|    n_updates            | 10420      |
|    policy_gradient_loss | 0.00352    |
|    std                  | 0.229      |
|    value_loss           | 0.0434     |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 624        |
|    iterations           | 1044       |
|    time_elapsed         | 3426       |
|    total_timesteps      | 2138112    |
| train/                  |            |
|    approx_kl            | 0.28294647 |
|    clip_fraction        | 0.447      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.141      |
|    explained_variance   | 0.675      |
|    learning_rate        | 0.00158    |
|    loss                 | 0.0349     |
|    n_updates            | 10430      |
|    policy_gradient_loss | 0.000568   |
|    std                  | 0.222      |
|    value_loss           | 0.0874     |
----------------------------------------
box reached target
box reached target
Eval num_timesteps=2140000, episode_reward=0.24 +/- 2.49
Episode length: 274.00 +/- 52.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 274        |
|    mean_reward          | 0.243      |
| time/                   |            |
|    total_timesteps      | 2140000    |
| train/                  |            |
|    approx_kl            | 0.30195957 |
|    clip_fraction        | 0.43       |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.1        |
|    explained_variance   | 0.791      |
|    learning_rate        | 0.00158    |
|    loss                 | -0.00424   |
|    n_updates            | 10440      |
|    policy_gradient_loss | 0.013      |
|    std                  | 0.231      |
|    value_loss           | 0.00899    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 623     |
|    iterations      | 1045    |
|    time_elapsed    | 3430    |
|    total_timesteps | 2140160 |
--------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 623       |
|    iterations           | 1046      |
|    time_elapsed         | 3433      |
|    total_timesteps      | 2142208   |
| train/                  |           |
|    approx_kl            | 2.5800638 |
|    clip_fraction        | 0.488     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.117     |
|    explained_variance   | 0.785     |
|    learning_rate        | 0.00158   |
|    loss                 | 0.00717   |
|    n_updates            | 10450     |
|    policy_gradient_loss | 0.0425    |
|    std                  | 0.224     |
|    value_loss           | 0.0279    |
---------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 624       |
|    iterations           | 1047      |
|    time_elapsed         | 3436      |
|    total_timesteps      | 2144256   |
| train/                  |           |
|    approx_kl            | 0.7991321 |
|    clip_fraction        | 0.5       |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.183     |
|    explained_variance   | 0.737     |
|    learning_rate        | 0.00158   |
|    loss                 | 0.0249    |
|    n_updates            | 10460     |
|    policy_gradient_loss | 0.0665    |
|    std                  | 0.217     |
|    value_loss           | 0.0174    |
---------------------------------------
box reached target
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 624       |
|    iterations           | 1048      |
|    time_elapsed         | 3439      |
|    total_timesteps      | 2146304   |
| train/                  |           |
|    approx_kl            | 1.1395113 |
|    clip_fraction        | 0.494     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.293     |
|    explained_variance   | 0.61      |
|    learning_rate        | 0.00158   |
|    loss                 | 0.01      |
|    n_updates            | 10470     |
|    policy_gradient_loss | 0.0235    |
|    std                  | 0.203     |
|    value_loss           | 0.135     |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 624        |
|    iterations           | 1049       |
|    time_elapsed         | 3442       |
|    total_timesteps      | 2148352    |
| train/                  |            |
|    approx_kl            | 0.36679453 |
|    clip_fraction        | 0.494      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.283      |
|    explained_variance   | 0.867      |
|    learning_rate        | 0.00158    |
|    loss                 | 0.0359     |
|    n_updates            | 10480      |
|    policy_gradient_loss | 0.0206     |
|    std                  | 0.212      |
|    value_loss           | 0.04       |
----------------------------------------
box reached target
box reached target
Eval num_timesteps=2150000, episode_reward=0.73 +/- 2.44
Episode length: 277.00 +/- 46.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 277       |
|    mean_reward          | 0.726     |
| time/                   |           |
|    total_timesteps      | 2150000   |
| train/                  |           |
|    approx_kl            | 0.2367129 |
|    clip_fraction        | 0.483     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.25      |
|    explained_variance   | 0.713     |
|    learning_rate        | 0.00158   |
|    loss                 | 0.0263    |
|    n_updates            | 10490     |
|    policy_gradient_loss | 0.00748   |
|    std                  | 0.212     |
|    value_loss           | 0.00912   |
---------------------------------------
--------------------------------
| time/              |         |
|    fps             | 623     |
|    iterations      | 1050    |
|    time_elapsed    | 3446    |
|    total_timesteps | 2150400 |
--------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 624        |
|    iterations           | 1051       |
|    time_elapsed         | 3449       |
|    total_timesteps      | 2152448    |
| train/                  |            |
|    approx_kl            | 0.31053716 |
|    clip_fraction        | 0.505      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.219      |
|    explained_variance   | 0.609      |
|    learning_rate        | 0.00158    |
|    loss                 | 0.0944     |
|    n_updates            | 10500      |
|    policy_gradient_loss | 0.00549    |
|    std                  | 0.216      |
|    value_loss           | 0.0192     |
----------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 624       |
|    iterations           | 1052      |
|    time_elapsed         | 3452      |
|    total_timesteps      | 2154496   |
| train/                  |           |
|    approx_kl            | 0.3611757 |
|    clip_fraction        | 0.493     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.231     |
|    explained_variance   | 0.36      |
|    learning_rate        | 0.00158   |
|    loss                 | 0.116     |
|    n_updates            | 10510     |
|    policy_gradient_loss | 0.0139    |
|    std                  | 0.212     |
|    value_loss           | 0.0746    |
---------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 624       |
|    iterations           | 1053      |
|    time_elapsed         | 3455      |
|    total_timesteps      | 2156544   |
| train/                  |           |
|    approx_kl            | 1.0923913 |
|    clip_fraction        | 0.44      |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.299     |
|    explained_variance   | 0.521     |
|    learning_rate        | 0.00158   |
|    loss                 | -0.0168   |
|    n_updates            | 10520     |
|    policy_gradient_loss | -0.00258  |
|    std                  | 0.204     |
|    value_loss           | 0.0152    |
---------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 624       |
|    iterations           | 1054      |
|    time_elapsed         | 3458      |
|    total_timesteps      | 2158592   |
| train/                  |           |
|    approx_kl            | 0.5069746 |
|    clip_fraction        | 0.456     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.362     |
|    explained_variance   | 0.496     |
|    learning_rate        | 0.00158   |
|    loss                 | -0.00912  |
|    n_updates            | 10530     |
|    policy_gradient_loss | 0.0129    |
|    std                  | 0.199     |
|    value_loss           | 0.0399    |
---------------------------------------
box reached target
Eval num_timesteps=2160000, episode_reward=-1.11 +/- 0.18
Episode length: 300.00 +/- 0.00
--------------------------------------
| eval/                   |          |
|    mean_ep_length       | 300      |
|    mean_reward          | -1.11    |
| time/                   |          |
|    total_timesteps      | 2160000  |
| train/                  |          |
|    approx_kl            | 0.817158 |
|    clip_fraction        | 0.488    |
|    clip_range           | 0.2      |
|    entropy_loss         | 0.342    |
|    explained_variance   | 0.523    |
|    learning_rate        | 0.00158  |
|    loss                 | -0.0146  |
|    n_updates            | 10540    |
|    policy_gradient_loss | 0.0293   |
|    std                  | 0.204    |
|    value_loss           | 0.00619  |
--------------------------------------
--------------------------------
| time/              |         |
|    fps             | 624     |
|    iterations      | 1055    |
|    time_elapsed    | 3462    |
|    total_timesteps | 2160640 |
--------------------------------
--------------------------------------
| time/                   |          |
|    fps                  | 624      |
|    iterations           | 1056     |
|    time_elapsed         | 3465     |
|    total_timesteps      | 2162688  |
| train/                  |          |
|    approx_kl            | 0.271824 |
|    clip_fraction        | 0.474    |
|    clip_range           | 0.2      |
|    entropy_loss         | 0.342    |
|    explained_variance   | 0.406    |
|    learning_rate        | 0.00158  |
|    loss                 | 0.00948  |
|    n_updates            | 10550    |
|    policy_gradient_loss | 0.0175   |
|    std                  | 0.203    |
|    value_loss           | 0.0362   |
--------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 624        |
|    iterations           | 1057       |
|    time_elapsed         | 3468       |
|    total_timesteps      | 2164736    |
| train/                  |            |
|    approx_kl            | 0.31266445 |
|    clip_fraction        | 0.49       |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.347      |
|    explained_variance   | 0.599      |
|    learning_rate        | 0.00158    |
|    loss                 | 0.113      |
|    n_updates            | 10560      |
|    policy_gradient_loss | 0.0121     |
|    std                  | 0.203      |
|    value_loss           | 0.0138     |
----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 624       |
|    iterations           | 1058      |
|    time_elapsed         | 3471      |
|    total_timesteps      | 2166784   |
| train/                  |           |
|    approx_kl            | 0.3484631 |
|    clip_fraction        | 0.484     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.34      |
|    explained_variance   | 0.0752    |
|    learning_rate        | 0.00158   |
|    loss                 | -0.0209   |
|    n_updates            | 10570     |
|    policy_gradient_loss | 0.00741   |
|    std                  | 0.206     |
|    value_loss           | 0.0305    |
---------------------------------------
box reached target
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 624       |
|    iterations           | 1059      |
|    time_elapsed         | 3474      |
|    total_timesteps      | 2168832   |
| train/                  |           |
|    approx_kl            | 0.2658168 |
|    clip_fraction        | 0.464     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.313     |
|    explained_variance   | 0.537     |
|    learning_rate        | 0.00158   |
|    loss                 | -0.0275   |
|    n_updates            | 10580     |
|    policy_gradient_loss | 0.0319    |
|    std                  | 0.206     |
|    value_loss           | 0.00641   |
---------------------------------------
box reached target
Eval num_timesteps=2170000, episode_reward=0.21 +/- 2.41
Episode length: 273.00 +/- 54.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 273       |
|    mean_reward          | 0.206     |
| time/                   |           |
|    total_timesteps      | 2170000   |
| train/                  |           |
|    approx_kl            | 0.4336462 |
|    clip_fraction        | 0.503     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.321     |
|    explained_variance   | 0.36      |
|    learning_rate        | 0.00158   |
|    loss                 | 0.0174    |
|    n_updates            | 10590     |
|    policy_gradient_loss | 0.0363    |
|    std                  | 0.206     |
|    value_loss           | 0.0258    |
---------------------------------------
--------------------------------
| time/              |         |
|    fps             | 624     |
|    iterations      | 1060    |
|    time_elapsed    | 3478    |
|    total_timesteps | 2170880 |
--------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 624        |
|    iterations           | 1061       |
|    time_elapsed         | 3481       |
|    total_timesteps      | 2172928    |
| train/                  |            |
|    approx_kl            | 0.58158123 |
|    clip_fraction        | 0.452      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.314      |
|    explained_variance   | 0.449      |
|    learning_rate        | 0.00158    |
|    loss                 | 0.0466     |
|    n_updates            | 10600      |
|    policy_gradient_loss | 0.0147     |
|    std                  | 0.206      |
|    value_loss           | 0.00528    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 624        |
|    iterations           | 1062       |
|    time_elapsed         | 3484       |
|    total_timesteps      | 2174976    |
| train/                  |            |
|    approx_kl            | 0.43965733 |
|    clip_fraction        | 0.482      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.271      |
|    explained_variance   | 0.883      |
|    learning_rate        | 0.00158    |
|    loss                 | 0.0254     |
|    n_updates            | 10610      |
|    policy_gradient_loss | 0.0184     |
|    std                  | 0.213      |
|    value_loss           | 0.0207     |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 624        |
|    iterations           | 1063       |
|    time_elapsed         | 3487       |
|    total_timesteps      | 2177024    |
| train/                  |            |
|    approx_kl            | 0.30103415 |
|    clip_fraction        | 0.464      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.229      |
|    explained_variance   | 0.53       |
|    learning_rate        | 0.00158    |
|    loss                 | 0.0187     |
|    n_updates            | 10620      |
|    policy_gradient_loss | 0.0095     |
|    std                  | 0.214      |
|    value_loss           | 0.01       |
----------------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 624        |
|    iterations           | 1064       |
|    time_elapsed         | 3490       |
|    total_timesteps      | 2179072    |
| train/                  |            |
|    approx_kl            | 0.50471085 |
|    clip_fraction        | 0.522      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.224      |
|    explained_variance   | 0.636      |
|    learning_rate        | 0.00158    |
|    loss                 | 0.0156     |
|    n_updates            | 10630      |
|    policy_gradient_loss | 0.0375     |
|    std                  | 0.216      |
|    value_loss           | 0.0324     |
----------------------------------------
box reached target
box reached target
box reached target
Eval num_timesteps=2180000, episode_reward=-0.85 +/- 0.31
Episode length: 300.00 +/- 0.00
--------------------------------------
| eval/                   |          |
|    mean_ep_length       | 300      |
|    mean_reward          | -0.85    |
| time/                   |          |
|    total_timesteps      | 2180000  |
| train/                  |          |
|    approx_kl            | 0.474586 |
|    clip_fraction        | 0.501    |
|    clip_range           | 0.2      |
|    entropy_loss         | 0.205    |
|    explained_variance   | 0.688    |
|    learning_rate        | 0.00158  |
|    loss                 | -0.0137  |
|    n_updates            | 10640    |
|    policy_gradient_loss | 0.0155   |
|    std                  | 0.219    |
|    value_loss           | 0.0469   |
--------------------------------------
box reached target
--------------------------------
| time/              |         |
|    fps             | 624     |
|    iterations      | 1065    |
|    time_elapsed    | 3494    |
|    total_timesteps | 2181120 |
--------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 624       |
|    iterations           | 1066      |
|    time_elapsed         | 3497      |
|    total_timesteps      | 2183168   |
| train/                  |           |
|    approx_kl            | 0.2257304 |
|    clip_fraction        | 0.47      |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.179     |
|    explained_variance   | 0.686     |
|    learning_rate        | 0.00157   |
|    loss                 | 0.0304    |
|    n_updates            | 10650     |
|    policy_gradient_loss | 0.0227    |
|    std                  | 0.221     |
|    value_loss           | 0.0625    |
---------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 624        |
|    iterations           | 1067       |
|    time_elapsed         | 3500       |
|    total_timesteps      | 2185216    |
| train/                  |            |
|    approx_kl            | 0.46018443 |
|    clip_fraction        | 0.417      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.246      |
|    explained_variance   | 0.532      |
|    learning_rate        | 0.00157    |
|    loss                 | 0.013      |
|    n_updates            | 10660      |
|    policy_gradient_loss | 0.0073     |
|    std                  | 0.21       |
|    value_loss           | 0.011      |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 624        |
|    iterations           | 1068       |
|    time_elapsed         | 3503       |
|    total_timesteps      | 2187264    |
| train/                  |            |
|    approx_kl            | 0.66995114 |
|    clip_fraction        | 0.489      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.276      |
|    explained_variance   | 0.72       |
|    learning_rate        | 0.00157    |
|    loss                 | 0.000968   |
|    n_updates            | 10670      |
|    policy_gradient_loss | 0.00754    |
|    std                  | 0.211      |
|    value_loss           | 0.0118     |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 624        |
|    iterations           | 1069       |
|    time_elapsed         | 3506       |
|    total_timesteps      | 2189312    |
| train/                  |            |
|    approx_kl            | 0.38147438 |
|    clip_fraction        | 0.446      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.24       |
|    explained_variance   | 0.738      |
|    learning_rate        | 0.00157    |
|    loss                 | -0.0546    |
|    n_updates            | 10680      |
|    policy_gradient_loss | 0.00859    |
|    std                  | 0.214      |
|    value_loss           | 0.00613    |
----------------------------------------
box reached target
Eval num_timesteps=2190000, episode_reward=-0.82 +/- 0.36
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -0.821     |
| time/                   |            |
|    total_timesteps      | 2190000    |
| train/                  |            |
|    approx_kl            | 0.31861287 |
|    clip_fraction        | 0.455      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.224      |
|    explained_variance   | 0.898      |
|    learning_rate        | 0.00157    |
|    loss                 | 0.0174     |
|    n_updates            | 10690      |
|    policy_gradient_loss | 0.0085     |
|    std                  | 0.216      |
|    value_loss           | 0.00219    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 624     |
|    iterations      | 1070    |
|    time_elapsed    | 3510    |
|    total_timesteps | 2191360 |
--------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 624       |
|    iterations           | 1071      |
|    time_elapsed         | 3514      |
|    total_timesteps      | 2193408   |
| train/                  |           |
|    approx_kl            | 1.7863915 |
|    clip_fraction        | 0.529     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.246     |
|    explained_variance   | 0.809     |
|    learning_rate        | 0.00157   |
|    loss                 | -0.054    |
|    n_updates            | 10700     |
|    policy_gradient_loss | 0.0252    |
|    std                  | 0.21      |
|    value_loss           | 0.0118    |
---------------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 624        |
|    iterations           | 1072       |
|    time_elapsed         | 3517       |
|    total_timesteps      | 2195456    |
| train/                  |            |
|    approx_kl            | 0.30777526 |
|    clip_fraction        | 0.459      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.238      |
|    explained_variance   | 0.556      |
|    learning_rate        | 0.00157    |
|    loss                 | 0.0276     |
|    n_updates            | 10710      |
|    policy_gradient_loss | 0.014      |
|    std                  | 0.216      |
|    value_loss           | 0.00405    |
----------------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 624        |
|    iterations           | 1073       |
|    time_elapsed         | 3520       |
|    total_timesteps      | 2197504    |
| train/                  |            |
|    approx_kl            | 0.80109084 |
|    clip_fraction        | 0.501      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.256      |
|    explained_variance   | 0.66       |
|    learning_rate        | 0.00157    |
|    loss                 | 0.141      |
|    n_updates            | 10720      |
|    policy_gradient_loss | 0.0166     |
|    std                  | 0.212      |
|    value_loss           | 0.115      |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 624        |
|    iterations           | 1074       |
|    time_elapsed         | 3523       |
|    total_timesteps      | 2199552    |
| train/                  |            |
|    approx_kl            | 0.37324044 |
|    clip_fraction        | 0.465      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.256      |
|    explained_variance   | 0.773      |
|    learning_rate        | 0.00157    |
|    loss                 | -0.0448    |
|    n_updates            | 10730      |
|    policy_gradient_loss | 0.0206     |
|    std                  | 0.211      |
|    value_loss           | 0.015      |
----------------------------------------
Eval num_timesteps=2200000, episode_reward=-0.57 +/- 0.57
Episode length: 300.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 300       |
|    mean_reward          | -0.568    |
| time/                   |           |
|    total_timesteps      | 2200000   |
| train/                  |           |
|    approx_kl            | 1.0734795 |
|    clip_fraction        | 0.48      |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.243     |
|    explained_variance   | 0.81      |
|    learning_rate        | 0.00157   |
|    loss                 | -0.00691  |
|    n_updates            | 10740     |
|    policy_gradient_loss | 0.0312    |
|    std                  | 0.212     |
|    value_loss           | 0.0146    |
---------------------------------------
box reached target
--------------------------------
| time/              |         |
|    fps             | 624     |
|    iterations      | 1075    |
|    time_elapsed    | 3527    |
|    total_timesteps | 2201600 |
--------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 624       |
|    iterations           | 1076      |
|    time_elapsed         | 3530      |
|    total_timesteps      | 2203648   |
| train/                  |           |
|    approx_kl            | 0.5736497 |
|    clip_fraction        | 0.484     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.244     |
|    explained_variance   | 0.815     |
|    learning_rate        | 0.00157   |
|    loss                 | 0.0827    |
|    n_updates            | 10750     |
|    policy_gradient_loss | 0.0106    |
|    std                  | 0.212     |
|    value_loss           | 0.0221    |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 624        |
|    iterations           | 1077       |
|    time_elapsed         | 3533       |
|    total_timesteps      | 2205696    |
| train/                  |            |
|    approx_kl            | 0.41343018 |
|    clip_fraction        | 0.48       |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.27       |
|    explained_variance   | 0.512      |
|    learning_rate        | 0.00157    |
|    loss                 | 0.0337     |
|    n_updates            | 10760      |
|    policy_gradient_loss | 0.0155     |
|    std                  | 0.205      |
|    value_loss           | 0.0217     |
----------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 624       |
|    iterations           | 1078      |
|    time_elapsed         | 3536      |
|    total_timesteps      | 2207744   |
| train/                  |           |
|    approx_kl            | 0.7808832 |
|    clip_fraction        | 0.476     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.362     |
|    explained_variance   | 0.805     |
|    learning_rate        | 0.00157   |
|    loss                 | 0.0172    |
|    n_updates            | 10770     |
|    policy_gradient_loss | 0.00523   |
|    std                  | 0.198     |
|    value_loss           | 0.028     |
---------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 624       |
|    iterations           | 1079      |
|    time_elapsed         | 3539      |
|    total_timesteps      | 2209792   |
| train/                  |           |
|    approx_kl            | 0.8894385 |
|    clip_fraction        | 0.581     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.439     |
|    explained_variance   | 0.717     |
|    learning_rate        | 0.00157   |
|    loss                 | 0.0202    |
|    n_updates            | 10780     |
|    policy_gradient_loss | 0.0168    |
|    std                  | 0.189     |
|    value_loss           | 0.0194    |
---------------------------------------
box reached target
Eval num_timesteps=2210000, episode_reward=0.18 +/- 2.57
Episode length: 273.00 +/- 54.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 273       |
|    mean_reward          | 0.178     |
| time/                   |           |
|    total_timesteps      | 2210000   |
| train/                  |           |
|    approx_kl            | 0.3895546 |
|    clip_fraction        | 0.509     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.471     |
|    explained_variance   | 0.569     |
|    learning_rate        | 0.00157   |
|    loss                 | -0.00138  |
|    n_updates            | 10790     |
|    policy_gradient_loss | 0.00756   |
|    std                  | 0.188     |
|    value_loss           | 0.0206    |
---------------------------------------
--------------------------------
| time/              |         |
|    fps             | 624     |
|    iterations      | 1080    |
|    time_elapsed    | 3543    |
|    total_timesteps | 2211840 |
--------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 624       |
|    iterations           | 1081      |
|    time_elapsed         | 3546      |
|    total_timesteps      | 2213888   |
| train/                  |           |
|    approx_kl            | 0.2080952 |
|    clip_fraction        | 0.517     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.451     |
|    explained_variance   | 0.717     |
|    learning_rate        | 0.00157   |
|    loss                 | 0.0325    |
|    n_updates            | 10800     |
|    policy_gradient_loss | 0.0287    |
|    std                  | 0.196     |
|    value_loss           | 0.0118    |
---------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 624       |
|    iterations           | 1082      |
|    time_elapsed         | 3549      |
|    total_timesteps      | 2215936   |
| train/                  |           |
|    approx_kl            | 0.4238464 |
|    clip_fraction        | 0.538     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.46      |
|    explained_variance   | 0.663     |
|    learning_rate        | 0.00157   |
|    loss                 | 0.00833   |
|    n_updates            | 10810     |
|    policy_gradient_loss | 0.023     |
|    std                  | 0.189     |
|    value_loss           | 0.0186    |
---------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 624        |
|    iterations           | 1083       |
|    time_elapsed         | 3552       |
|    total_timesteps      | 2217984    |
| train/                  |            |
|    approx_kl            | 0.58155936 |
|    clip_fraction        | 0.529      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.517      |
|    explained_variance   | 0.406      |
|    learning_rate        | 0.00157    |
|    loss                 | 0.0974     |
|    n_updates            | 10820      |
|    policy_gradient_loss | 0.0172     |
|    std                  | 0.182      |
|    value_loss           | 0.124      |
----------------------------------------
Eval num_timesteps=2220000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
--------------------------------------
| eval/                   |          |
|    mean_ep_length       | 300      |
|    mean_reward          | -1       |
| time/                   |          |
|    total_timesteps      | 2220000  |
| train/                  |          |
|    approx_kl            | 1.104201 |
|    clip_fraction        | 0.523    |
|    clip_range           | 0.2      |
|    entropy_loss         | 0.535    |
|    explained_variance   | 0.556    |
|    learning_rate        | 0.00157  |
|    loss                 | -0.00298 |
|    n_updates            | 10830    |
|    policy_gradient_loss | 0.0228   |
|    std                  | 0.185    |
|    value_loss           | 0.00843  |
--------------------------------------
--------------------------------
| time/              |         |
|    fps             | 624     |
|    iterations      | 1084    |
|    time_elapsed    | 3556    |
|    total_timesteps | 2220032 |
--------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 624       |
|    iterations           | 1085      |
|    time_elapsed         | 3559      |
|    total_timesteps      | 2222080   |
| train/                  |           |
|    approx_kl            | 2.2383814 |
|    clip_fraction        | 0.585     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.547     |
|    explained_variance   | 0.829     |
|    learning_rate        | 0.00157   |
|    loss                 | -0.0274   |
|    n_updates            | 10840     |
|    policy_gradient_loss | 0.0177    |
|    std                  | 0.184     |
|    value_loss           | 0.00904   |
---------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 624       |
|    iterations           | 1086      |
|    time_elapsed         | 3562      |
|    total_timesteps      | 2224128   |
| train/                  |           |
|    approx_kl            | 0.5232884 |
|    clip_fraction        | 0.555     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.565     |
|    explained_variance   | 0.393     |
|    learning_rate        | 0.00157   |
|    loss                 | 0.189     |
|    n_updates            | 10850     |
|    policy_gradient_loss | 0.0134    |
|    std                  | 0.181     |
|    value_loss           | 0.0156    |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 624        |
|    iterations           | 1087       |
|    time_elapsed         | 3565       |
|    total_timesteps      | 2226176    |
| train/                  |            |
|    approx_kl            | 0.59040666 |
|    clip_fraction        | 0.575      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.579      |
|    explained_variance   | 0.61       |
|    learning_rate        | 0.00157    |
|    loss                 | 0.0441     |
|    n_updates            | 10860      |
|    policy_gradient_loss | 0.0318     |
|    std                  | 0.181      |
|    value_loss           | 0.00118    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 624        |
|    iterations           | 1088       |
|    time_elapsed         | 3568       |
|    total_timesteps      | 2228224    |
| train/                  |            |
|    approx_kl            | 0.91648847 |
|    clip_fraction        | 0.575      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.619      |
|    explained_variance   | 0.742      |
|    learning_rate        | 0.00157    |
|    loss                 | -0.0297    |
|    n_updates            | 10870      |
|    policy_gradient_loss | 0.0146     |
|    std                  | 0.176      |
|    value_loss           | 0.008      |
----------------------------------------
box reached target
box reached target
Eval num_timesteps=2230000, episode_reward=-0.75 +/- 0.50
Episode length: 300.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 300       |
|    mean_reward          | -0.749    |
| time/                   |           |
|    total_timesteps      | 2230000   |
| train/                  |           |
|    approx_kl            | 1.3348706 |
|    clip_fraction        | 0.456     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.609     |
|    explained_variance   | 0.795     |
|    learning_rate        | 0.00157   |
|    loss                 | -0.00361  |
|    n_updates            | 10880     |
|    policy_gradient_loss | 0.00104   |
|    std                  | 0.178     |
|    value_loss           | 0.00612   |
---------------------------------------
--------------------------------
| time/              |         |
|    fps             | 624     |
|    iterations      | 1089    |
|    time_elapsed    | 3572    |
|    total_timesteps | 2230272 |
--------------------------------
box reached target
box reached target
--------------------------------------
| time/                   |          |
|    fps                  | 624      |
|    iterations           | 1090     |
|    time_elapsed         | 3575     |
|    total_timesteps      | 2232320  |
| train/                  |          |
|    approx_kl            | 0.651376 |
|    clip_fraction        | 0.59     |
|    clip_range           | 0.2      |
|    entropy_loss         | 0.563    |
|    explained_variance   | 0.308    |
|    learning_rate        | 0.00157  |
|    loss                 | 0.0711   |
|    n_updates            | 10890    |
|    policy_gradient_loss | 0.0425   |
|    std                  | 0.186    |
|    value_loss           | 0.116    |
--------------------------------------
box reached target
--------------------------------------
| time/                   |          |
|    fps                  | 624      |
|    iterations           | 1091     |
|    time_elapsed         | 3578     |
|    total_timesteps      | 2234368  |
| train/                  |          |
|    approx_kl            | 2.596312 |
|    clip_fraction        | 0.638    |
|    clip_range           | 0.2      |
|    entropy_loss         | 0.603    |
|    explained_variance   | 0.488    |
|    learning_rate        | 0.00156  |
|    loss                 | -0.0312  |
|    n_updates            | 10900    |
|    policy_gradient_loss | 0.0156   |
|    std                  | 0.178    |
|    value_loss           | 0.0279   |
--------------------------------------
box reached target
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 624       |
|    iterations           | 1092      |
|    time_elapsed         | 3581      |
|    total_timesteps      | 2236416   |
| train/                  |           |
|    approx_kl            | 0.7017725 |
|    clip_fraction        | 0.527     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.624     |
|    explained_variance   | 0.239     |
|    learning_rate        | 0.00156   |
|    loss                 | 0.00243   |
|    n_updates            | 10910     |
|    policy_gradient_loss | 0.0129    |
|    std                  | 0.177     |
|    value_loss           | 0.023     |
---------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 624       |
|    iterations           | 1093      |
|    time_elapsed         | 3584      |
|    total_timesteps      | 2238464   |
| train/                  |           |
|    approx_kl            | 0.8767592 |
|    clip_fraction        | 0.563     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.635     |
|    explained_variance   | 0.744     |
|    learning_rate        | 0.00156   |
|    loss                 | -0.0205   |
|    n_updates            | 10920     |
|    policy_gradient_loss | 0.0484    |
|    std                  | 0.174     |
|    value_loss           | 0.0186    |
---------------------------------------
box reached target
box reached target
Eval num_timesteps=2240000, episode_reward=1.50 +/- 3.06
Episode length: 254.00 +/- 57.48
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 254       |
|    mean_reward          | 1.5       |
| time/                   |           |
|    total_timesteps      | 2240000   |
| train/                  |           |
|    approx_kl            | 1.1869793 |
|    clip_fraction        | 0.568     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.684     |
|    explained_variance   | 0.768     |
|    learning_rate        | 0.00156   |
|    loss                 | 0.0377    |
|    n_updates            | 10930     |
|    policy_gradient_loss | 0.0402    |
|    std                  | 0.168     |
|    value_loss           | 0.0198    |
---------------------------------------
box reached target
--------------------------------
| time/              |         |
|    fps             | 624     |
|    iterations      | 1094    |
|    time_elapsed    | 3588    |
|    total_timesteps | 2240512 |
--------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 624       |
|    iterations           | 1095      |
|    time_elapsed         | 3591      |
|    total_timesteps      | 2242560   |
| train/                  |           |
|    approx_kl            | 2.2045498 |
|    clip_fraction        | 0.59      |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.713     |
|    explained_variance   | 0.929     |
|    learning_rate        | 0.00156   |
|    loss                 | 0.00655   |
|    n_updates            | 10940     |
|    policy_gradient_loss | 0.0357    |
|    std                  | 0.169     |
|    value_loss           | 0.00872   |
---------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 624       |
|    iterations           | 1096      |
|    time_elapsed         | 3594      |
|    total_timesteps      | 2244608   |
| train/                  |           |
|    approx_kl            | 1.4273291 |
|    clip_fraction        | 0.547     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.757     |
|    explained_variance   | 0.7       |
|    learning_rate        | 0.00156   |
|    loss                 | 0.0918    |
|    n_updates            | 10950     |
|    policy_gradient_loss | 0.0226    |
|    std                  | 0.162     |
|    value_loss           | 0.0377    |
---------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 624       |
|    iterations           | 1097      |
|    time_elapsed         | 3597      |
|    total_timesteps      | 2246656   |
| train/                  |           |
|    approx_kl            | 1.1767423 |
|    clip_fraction        | 0.562     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.814     |
|    explained_variance   | 0.708     |
|    learning_rate        | 0.00156   |
|    loss                 | -0.00543  |
|    n_updates            | 10960     |
|    policy_gradient_loss | 0.0183    |
|    std                  | 0.159     |
|    value_loss           | 0.0087    |
---------------------------------------
box reached target
--------------------------------------
| time/                   |          |
|    fps                  | 624      |
|    iterations           | 1098     |
|    time_elapsed         | 3600     |
|    total_timesteps      | 2248704  |
| train/                  |          |
|    approx_kl            | 5.536661 |
|    clip_fraction        | 0.578    |
|    clip_range           | 0.2      |
|    entropy_loss         | 0.836    |
|    explained_variance   | 0.711    |
|    learning_rate        | 0.00156  |
|    loss                 | 0.0113   |
|    n_updates            | 10970    |
|    policy_gradient_loss | 0.0225   |
|    std                  | 0.159    |
|    value_loss           | 0.00442  |
--------------------------------------
box reached target
box reached target
box reached target
box reached target
Eval num_timesteps=2250000, episode_reward=1.43 +/- 2.97
Episode length: 249.80 +/- 61.78
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 250       |
|    mean_reward          | 1.43      |
| time/                   |           |
|    total_timesteps      | 2250000   |
| train/                  |           |
|    approx_kl            | 3.4661186 |
|    clip_fraction        | 0.574     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.846     |
|    explained_variance   | 0.905     |
|    learning_rate        | 0.00156   |
|    loss                 | 0.000572  |
|    n_updates            | 10980     |
|    policy_gradient_loss | 0.0237    |
|    std                  | 0.155     |
|    value_loss           | 0.0114    |
---------------------------------------
--------------------------------
| time/              |         |
|    fps             | 624     |
|    iterations      | 1099    |
|    time_elapsed    | 3604    |
|    total_timesteps | 2250752 |
--------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 624        |
|    iterations           | 1100       |
|    time_elapsed         | 3607       |
|    total_timesteps      | 2252800    |
| train/                  |            |
|    approx_kl            | 0.91707504 |
|    clip_fraction        | 0.62       |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.835      |
|    explained_variance   | 0.16       |
|    learning_rate        | 0.00156    |
|    loss                 | 0.0581     |
|    n_updates            | 10990      |
|    policy_gradient_loss | 0.0403     |
|    std                  | 0.16       |
|    value_loss           | 0.0791     |
----------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 624       |
|    iterations           | 1101      |
|    time_elapsed         | 3610      |
|    total_timesteps      | 2254848   |
| train/                  |           |
|    approx_kl            | 0.7571715 |
|    clip_fraction        | 0.577     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.856     |
|    explained_variance   | 0.302     |
|    learning_rate        | 0.00156   |
|    loss                 | -0.0404   |
|    n_updates            | 11000     |
|    policy_gradient_loss | 0.0163    |
|    std                  | 0.157     |
|    value_loss           | 0.00906   |
---------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 624       |
|    iterations           | 1102      |
|    time_elapsed         | 3613      |
|    total_timesteps      | 2256896   |
| train/                  |           |
|    approx_kl            | 1.2014788 |
|    clip_fraction        | 0.592     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.846     |
|    explained_variance   | 0.473     |
|    learning_rate        | 0.00156   |
|    loss                 | 0.00916   |
|    n_updates            | 11010     |
|    policy_gradient_loss | 0.0592    |
|    std                  | 0.155     |
|    value_loss           | 0.0206    |
---------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 624       |
|    iterations           | 1103      |
|    time_elapsed         | 3616      |
|    total_timesteps      | 2258944   |
| train/                  |           |
|    approx_kl            | 1.7597485 |
|    clip_fraction        | 0.522     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.834     |
|    explained_variance   | 0.209     |
|    learning_rate        | 0.00156   |
|    loss                 | 0.0016    |
|    n_updates            | 11020     |
|    policy_gradient_loss | 0.0353    |
|    std                  | 0.161     |
|    value_loss           | 0.00153   |
---------------------------------------
box reached target
box reached target
Eval num_timesteps=2260000, episode_reward=0.37 +/- 2.41
Episode length: 273.60 +/- 52.80
--------------------------------------
| eval/                   |          |
|    mean_ep_length       | 274      |
|    mean_reward          | 0.372    |
| time/                   |          |
|    total_timesteps      | 2260000  |
| train/                  |          |
|    approx_kl            | 0.520848 |
|    clip_fraction        | 0.49     |
|    clip_range           | 0.2      |
|    entropy_loss         | 0.838    |
|    explained_variance   | 0.817    |
|    learning_rate        | 0.00156  |
|    loss                 | 0.0258   |
|    n_updates            | 11030    |
|    policy_gradient_loss | 0.00533  |
|    std                  | 0.156    |
|    value_loss           | 0.0098   |
--------------------------------------
--------------------------------
| time/              |         |
|    fps             | 624     |
|    iterations      | 1104    |
|    time_elapsed    | 3620    |
|    total_timesteps | 2260992 |
--------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 624       |
|    iterations           | 1105      |
|    time_elapsed         | 3623      |
|    total_timesteps      | 2263040   |
| train/                  |           |
|    approx_kl            | 2.4011672 |
|    clip_fraction        | 0.526     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.91      |
|    explained_variance   | 0.866     |
|    learning_rate        | 0.00156   |
|    loss                 | -0.0265   |
|    n_updates            | 11040     |
|    policy_gradient_loss | 0.00507   |
|    std                  | 0.149     |
|    value_loss           | 0.0291    |
---------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 624       |
|    iterations           | 1106      |
|    time_elapsed         | 3626      |
|    total_timesteps      | 2265088   |
| train/                  |           |
|    approx_kl            | 3.0918875 |
|    clip_fraction        | 0.593     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.971     |
|    explained_variance   | 0.333     |
|    learning_rate        | 0.00156   |
|    loss                 | 0.0134    |
|    n_updates            | 11050     |
|    policy_gradient_loss | 0.022     |
|    std                  | 0.146     |
|    value_loss           | 0.00226   |
---------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 624       |
|    iterations           | 1107      |
|    time_elapsed         | 3629      |
|    total_timesteps      | 2267136   |
| train/                  |           |
|    approx_kl            | 3.9188972 |
|    clip_fraction        | 0.612     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.07      |
|    explained_variance   | 0.757     |
|    learning_rate        | 0.00156   |
|    loss                 | -0.0301   |
|    n_updates            | 11060     |
|    policy_gradient_loss | -0.00282  |
|    std                  | 0.139     |
|    value_loss           | 0.00952   |
---------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 624       |
|    iterations           | 1108      |
|    time_elapsed         | 3632      |
|    total_timesteps      | 2269184   |
| train/                  |           |
|    approx_kl            | 6.9293876 |
|    clip_fraction        | 0.622     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.14      |
|    explained_variance   | 0.466     |
|    learning_rate        | 0.00156   |
|    loss                 | 0.00533   |
|    n_updates            | 11070     |
|    policy_gradient_loss | 0.0044    |
|    std                  | 0.134     |
|    value_loss           | 0.0016    |
---------------------------------------
box reached target
box reached target
Eval num_timesteps=2270000, episode_reward=0.40 +/- 2.38
Episode length: 271.40 +/- 57.20
--------------------------------------
| eval/                   |          |
|    mean_ep_length       | 271      |
|    mean_reward          | 0.398    |
| time/                   |          |
|    total_timesteps      | 2270000  |
| train/                  |          |
|    approx_kl            | 1.040531 |
|    clip_fraction        | 0.639    |
|    clip_range           | 0.2      |
|    entropy_loss         | 1.14     |
|    explained_variance   | 0.958    |
|    learning_rate        | 0.00156  |
|    loss                 | 0.0233   |
|    n_updates            | 11080    |
|    policy_gradient_loss | 0.0631   |
|    std                  | 0.14     |
|    value_loss           | 0.00616  |
--------------------------------------
--------------------------------
| time/              |         |
|    fps             | 624     |
|    iterations      | 1109    |
|    time_elapsed    | 3636    |
|    total_timesteps | 2271232 |
--------------------------------
box reached target
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 624       |
|    iterations           | 1110      |
|    time_elapsed         | 3639      |
|    total_timesteps      | 2273280   |
| train/                  |           |
|    approx_kl            | 1.5250497 |
|    clip_fraction        | 0.546     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.13      |
|    explained_variance   | 0.832     |
|    learning_rate        | 0.00156   |
|    loss                 | -0.0325   |
|    n_updates            | 11090     |
|    policy_gradient_loss | 0.0105    |
|    std                  | 0.137     |
|    value_loss           | 0.0153    |
---------------------------------------
box reached target
--------------------------------------
| time/                   |          |
|    fps                  | 624      |
|    iterations           | 1111     |
|    time_elapsed         | 3642     |
|    total_timesteps      | 2275328  |
| train/                  |          |
|    approx_kl            | 1.507375 |
|    clip_fraction        | 0.579    |
|    clip_range           | 0.2      |
|    entropy_loss         | 1.11     |
|    explained_variance   | 0.765    |
|    learning_rate        | 0.00156  |
|    loss                 | 0.101    |
|    n_updates            | 11100    |
|    policy_gradient_loss | 0.0547   |
|    std                  | 0.14     |
|    value_loss           | 0.0377   |
--------------------------------------
box reached target
box reached target
box reached target
box reached target
box reached target
box reached target
--------------------------------------
| time/                   |          |
|    fps                  | 624      |
|    iterations           | 1112     |
|    time_elapsed         | 3645     |
|    total_timesteps      | 2277376  |
| train/                  |          |
|    approx_kl            | 2.032906 |
|    clip_fraction        | 0.589    |
|    clip_range           | 0.2      |
|    entropy_loss         | 1.06     |
|    explained_variance   | 0.217    |
|    learning_rate        | 0.00156  |
|    loss                 | 0.00499  |
|    n_updates            | 11110    |
|    policy_gradient_loss | 0.0235   |
|    std                  | 0.14     |
|    value_loss           | 0.0191   |
--------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 624       |
|    iterations           | 1113      |
|    time_elapsed         | 3648      |
|    total_timesteps      | 2279424   |
| train/                  |           |
|    approx_kl            | 2.0110645 |
|    clip_fraction        | 0.633     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.06      |
|    explained_variance   | 0.854     |
|    learning_rate        | 0.00156   |
|    loss                 | 0.00402   |
|    n_updates            | 11120     |
|    policy_gradient_loss | 0.0361    |
|    std                  | 0.144     |
|    value_loss           | 0.052     |
---------------------------------------
box reached target
box reached target
Eval num_timesteps=2280000, episode_reward=0.13 +/- 2.60
Episode length: 278.60 +/- 42.80
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 279       |
|    mean_reward          | 0.129     |
| time/                   |           |
|    total_timesteps      | 2280000   |
| train/                  |           |
|    approx_kl            | 1.4445913 |
|    clip_fraction        | 0.55      |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.05      |
|    explained_variance   | 0.479     |
|    learning_rate        | 0.00156   |
|    loss                 | -0.0289   |
|    n_updates            | 11130     |
|    policy_gradient_loss | 0.0101    |
|    std                  | 0.142     |
|    value_loss           | 0.0236    |
---------------------------------------
--------------------------------
| time/              |         |
|    fps             | 624     |
|    iterations      | 1114    |
|    time_elapsed    | 3652    |
|    total_timesteps | 2281472 |
--------------------------------
--------------------------------------
| time/                   |          |
|    fps                  | 624      |
|    iterations           | 1115     |
|    time_elapsed         | 3655     |
|    total_timesteps      | 2283520  |
| train/                  |          |
|    approx_kl            | 1.439134 |
|    clip_fraction        | 0.623    |
|    clip_range           | 0.2      |
|    entropy_loss         | 1.06     |
|    explained_variance   | 0.549    |
|    learning_rate        | 0.00156  |
|    loss                 | 0.041    |
|    n_updates            | 11140    |
|    policy_gradient_loss | 0.0258   |
|    std                  | 0.142    |
|    value_loss           | 0.0242   |
--------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 624        |
|    iterations           | 1116       |
|    time_elapsed         | 3658       |
|    total_timesteps      | 2285568    |
| train/                  |            |
|    approx_kl            | 0.82397294 |
|    clip_fraction        | 0.517      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.06       |
|    explained_variance   | 0.847      |
|    learning_rate        | 0.00155    |
|    loss                 | -0.0315    |
|    n_updates            | 11150      |
|    policy_gradient_loss | 0.0178     |
|    std                  | 0.143      |
|    value_loss           | 0.00757    |
----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 624       |
|    iterations           | 1117      |
|    time_elapsed         | 3661      |
|    total_timesteps      | 2287616   |
| train/                  |           |
|    approx_kl            | 3.3439097 |
|    clip_fraction        | 0.601     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.04      |
|    explained_variance   | 0.241     |
|    learning_rate        | 0.00155   |
|    loss                 | 0.0332    |
|    n_updates            | 11160     |
|    policy_gradient_loss | 0.051     |
|    std                  | 0.143     |
|    value_loss           | 0.0182    |
---------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 624       |
|    iterations           | 1118      |
|    time_elapsed         | 3664      |
|    total_timesteps      | 2289664   |
| train/                  |           |
|    approx_kl            | 1.3255808 |
|    clip_fraction        | 0.569     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.09      |
|    explained_variance   | 0.482     |
|    learning_rate        | 0.00155   |
|    loss                 | 0.00651   |
|    n_updates            | 11170     |
|    policy_gradient_loss | 0.0125    |
|    std                  | 0.139     |
|    value_loss           | 0.0103    |
---------------------------------------
box reached target
box reached target
Eval num_timesteps=2290000, episode_reward=1.75 +/- 2.87
Episode length: 247.40 +/- 64.46
--------------------------------------
| eval/                   |          |
|    mean_ep_length       | 247      |
|    mean_reward          | 1.75     |
| time/                   |          |
|    total_timesteps      | 2290000  |
| train/                  |          |
|    approx_kl            | 6.5246   |
|    clip_fraction        | 0.707    |
|    clip_range           | 0.2      |
|    entropy_loss         | 1.12     |
|    explained_variance   | 0.437    |
|    learning_rate        | 0.00155  |
|    loss                 | 0.00548  |
|    n_updates            | 11180    |
|    policy_gradient_loss | 0.0525   |
|    std                  | 0.138    |
|    value_loss           | 0.0273   |
--------------------------------------
--------------------------------
| time/              |         |
|    fps             | 624     |
|    iterations      | 1119    |
|    time_elapsed    | 3668    |
|    total_timesteps | 2291712 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 624        |
|    iterations           | 1120       |
|    time_elapsed         | 3671       |
|    total_timesteps      | 2293760    |
| train/                  |            |
|    approx_kl            | 0.95448583 |
|    clip_fraction        | 0.669      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.07       |
|    explained_variance   | 0.591      |
|    learning_rate        | 0.00155    |
|    loss                 | 0.05       |
|    n_updates            | 11190      |
|    policy_gradient_loss | 0.0521     |
|    std                  | 0.142      |
|    value_loss           | 0.0203     |
----------------------------------------
--------------------------------------
| time/                   |          |
|    fps                  | 624      |
|    iterations           | 1121     |
|    time_elapsed         | 3674     |
|    total_timesteps      | 2295808  |
| train/                  |          |
|    approx_kl            | 1.269443 |
|    clip_fraction        | 0.589    |
|    clip_range           | 0.2      |
|    entropy_loss         | 1.06     |
|    explained_variance   | 0.178    |
|    learning_rate        | 0.00155  |
|    loss                 | 0.106    |
|    n_updates            | 11200    |
|    policy_gradient_loss | 0.0282   |
|    std                  | 0.142    |
|    value_loss           | 0.00469  |
--------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 624       |
|    iterations           | 1122      |
|    time_elapsed         | 3677      |
|    total_timesteps      | 2297856   |
| train/                  |           |
|    approx_kl            | 0.8574504 |
|    clip_fraction        | 0.615     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.02      |
|    explained_variance   | 0.756     |
|    learning_rate        | 0.00155   |
|    loss                 | 0.071     |
|    n_updates            | 11210     |
|    policy_gradient_loss | 0.0287    |
|    std                  | 0.147     |
|    value_loss           | 0.00588   |
---------------------------------------
box reached target
box reached target
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 624       |
|    iterations           | 1123      |
|    time_elapsed         | 3680      |
|    total_timesteps      | 2299904   |
| train/                  |           |
|    approx_kl            | 3.8507347 |
|    clip_fraction        | 0.632     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.01      |
|    explained_variance   | 0.735     |
|    learning_rate        | 0.00155   |
|    loss                 | 0.0385    |
|    n_updates            | 11220     |
|    policy_gradient_loss | 0.0222    |
|    std                  | 0.146     |
|    value_loss           | 0.00228   |
---------------------------------------
box reached target
Eval num_timesteps=2300000, episode_reward=0.26 +/- 2.55
Episode length: 274.00 +/- 52.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 274       |
|    mean_reward          | 0.265     |
| time/                   |           |
|    total_timesteps      | 2300000   |
| train/                  |           |
|    approx_kl            | 0.7602092 |
|    clip_fraction        | 0.591     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.945     |
|    explained_variance   | 0.536     |
|    learning_rate        | 0.00155   |
|    loss                 | 0.0407    |
|    n_updates            | 11230     |
|    policy_gradient_loss | 0.0478    |
|    std                  | 0.153     |
|    value_loss           | 0.0208    |
---------------------------------------
box reached target
--------------------------------
| time/              |         |
|    fps             | 624     |
|    iterations      | 1124    |
|    time_elapsed    | 3684    |
|    total_timesteps | 2301952 |
--------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 624       |
|    iterations           | 1125      |
|    time_elapsed         | 3687      |
|    total_timesteps      | 2304000   |
| train/                  |           |
|    approx_kl            | 1.9312532 |
|    clip_fraction        | 0.601     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.909     |
|    explained_variance   | 0.797     |
|    learning_rate        | 0.00155   |
|    loss                 | 0.0241    |
|    n_updates            | 11240     |
|    policy_gradient_loss | 0.0132    |
|    std                  | 0.151     |
|    value_loss           | 0.0222    |
---------------------------------------
box reached target
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 624        |
|    iterations           | 1126       |
|    time_elapsed         | 3690       |
|    total_timesteps      | 2306048    |
| train/                  |            |
|    approx_kl            | 0.47314975 |
|    clip_fraction        | 0.553      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.863      |
|    explained_variance   | 0.651      |
|    learning_rate        | 0.00155    |
|    loss                 | 0.115      |
|    n_updates            | 11250      |
|    policy_gradient_loss | 0.0409     |
|    std                  | 0.158      |
|    value_loss           | 0.0128     |
----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 624       |
|    iterations           | 1127      |
|    time_elapsed         | 3693      |
|    total_timesteps      | 2308096   |
| train/                  |           |
|    approx_kl            | 0.7063533 |
|    clip_fraction        | 0.618     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.819     |
|    explained_variance   | 0.675     |
|    learning_rate        | 0.00155   |
|    loss                 | 0.0667    |
|    n_updates            | 11260     |
|    policy_gradient_loss | 0.0343    |
|    std                  | 0.158     |
|    value_loss           | 0.0318    |
---------------------------------------
box reached target
Eval num_timesteps=2310000, episode_reward=0.55 +/- 2.35
Episode length: 281.00 +/- 38.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 281       |
|    mean_reward          | 0.546     |
| time/                   |           |
|    total_timesteps      | 2310000   |
| train/                  |           |
|    approx_kl            | 0.2476373 |
|    clip_fraction        | 0.493     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.835     |
|    explained_variance   | 0.735     |
|    learning_rate        | 0.00155   |
|    loss                 | 0.148     |
|    n_updates            | 11270     |
|    policy_gradient_loss | 0.0273    |
|    std                  | 0.158     |
|    value_loss           | 0.00821   |
---------------------------------------
--------------------------------
| time/              |         |
|    fps             | 624     |
|    iterations      | 1128    |
|    time_elapsed    | 3697    |
|    total_timesteps | 2310144 |
--------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 624       |
|    iterations           | 1129      |
|    time_elapsed         | 3700      |
|    total_timesteps      | 2312192   |
| train/                  |           |
|    approx_kl            | 1.0063715 |
|    clip_fraction        | 0.534     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.878     |
|    explained_variance   | 0.805     |
|    learning_rate        | 0.00155   |
|    loss                 | -0.000147 |
|    n_updates            | 11280     |
|    policy_gradient_loss | 0.0217    |
|    std                  | 0.151     |
|    value_loss           | 0.00892   |
---------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 624       |
|    iterations           | 1130      |
|    time_elapsed         | 3703      |
|    total_timesteps      | 2314240   |
| train/                  |           |
|    approx_kl            | 1.0818055 |
|    clip_fraction        | 0.636     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.86      |
|    explained_variance   | 0.782     |
|    learning_rate        | 0.00155   |
|    loss                 | -0.00599  |
|    n_updates            | 11290     |
|    policy_gradient_loss | 0.0572    |
|    std                  | 0.159     |
|    value_loss           | 0.0102    |
---------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 624       |
|    iterations           | 1131      |
|    time_elapsed         | 3706      |
|    total_timesteps      | 2316288   |
| train/                  |           |
|    approx_kl            | 1.0284181 |
|    clip_fraction        | 0.543     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.809     |
|    explained_variance   | 0.0667    |
|    learning_rate        | 0.00155   |
|    loss                 | 0.0605    |
|    n_updates            | 11300     |
|    policy_gradient_loss | 0.0189    |
|    std                  | 0.161     |
|    value_loss           | 0.106     |
---------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 624       |
|    iterations           | 1132      |
|    time_elapsed         | 3709      |
|    total_timesteps      | 2318336   |
| train/                  |           |
|    approx_kl            | 2.8873262 |
|    clip_fraction        | 0.602     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.838     |
|    explained_variance   | 0.135     |
|    learning_rate        | 0.00155   |
|    loss                 | 0.0454    |
|    n_updates            | 11310     |
|    policy_gradient_loss | 0.0209    |
|    std                  | 0.157     |
|    value_loss           | 0.0682    |
---------------------------------------
box reached target
box reached target
box reached target
Eval num_timesteps=2320000, episode_reward=0.36 +/- 2.42
Episode length: 278.40 +/- 43.20
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 278       |
|    mean_reward          | 0.356     |
| time/                   |           |
|    total_timesteps      | 2320000   |
| train/                  |           |
|    approx_kl            | 0.5847362 |
|    clip_fraction        | 0.519     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.784     |
|    explained_variance   | 0.765     |
|    learning_rate        | 0.00155   |
|    loss                 | -0.0279   |
|    n_updates            | 11320     |
|    policy_gradient_loss | 0.034     |
|    std                  | 0.165     |
|    value_loss           | 0.0153    |
---------------------------------------
--------------------------------
| time/              |         |
|    fps             | 624     |
|    iterations      | 1133    |
|    time_elapsed    | 3713    |
|    total_timesteps | 2320384 |
--------------------------------
--------------------------------------
| time/                   |          |
|    fps                  | 624      |
|    iterations           | 1134     |
|    time_elapsed         | 3716     |
|    total_timesteps      | 2322432  |
| train/                  |          |
|    approx_kl            | 8.90103  |
|    clip_fraction        | 0.669    |
|    clip_range           | 0.2      |
|    entropy_loss         | 0.748    |
|    explained_variance   | 0.783    |
|    learning_rate        | 0.00155  |
|    loss                 | 0.101    |
|    n_updates            | 11330    |
|    policy_gradient_loss | 0.0474   |
|    std                  | 0.166    |
|    value_loss           | 0.0131   |
--------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 624       |
|    iterations           | 1135      |
|    time_elapsed         | 3719      |
|    total_timesteps      | 2324480   |
| train/                  |           |
|    approx_kl            | 1.0103871 |
|    clip_fraction        | 0.545     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.759     |
|    explained_variance   | 0.761     |
|    learning_rate        | 0.00155   |
|    loss                 | -0.0149   |
|    n_updates            | 11340     |
|    policy_gradient_loss | 0.0508    |
|    std                  | 0.162     |
|    value_loss           | 0.00911   |
---------------------------------------
--------------------------------------
| time/                   |          |
|    fps                  | 624      |
|    iterations           | 1136     |
|    time_elapsed         | 3722     |
|    total_timesteps      | 2326528  |
| train/                  |          |
|    approx_kl            | 2.039431 |
|    clip_fraction        | 0.558    |
|    clip_range           | 0.2      |
|    entropy_loss         | 0.835    |
|    explained_variance   | 0.754    |
|    learning_rate        | 0.00155  |
|    loss                 | -0.0374  |
|    n_updates            | 11350    |
|    policy_gradient_loss | 0.0106   |
|    std                  | 0.155    |
|    value_loss           | 0.0157   |
--------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 625       |
|    iterations           | 1137      |
|    time_elapsed         | 3725      |
|    total_timesteps      | 2328576   |
| train/                  |           |
|    approx_kl            | 2.9407043 |
|    clip_fraction        | 0.653     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.912     |
|    explained_variance   | 0.732     |
|    learning_rate        | 0.00155   |
|    loss                 | -0.0191   |
|    n_updates            | 11360     |
|    policy_gradient_loss | 0.0116    |
|    std                  | 0.152     |
|    value_loss           | 0.00959   |
---------------------------------------
box reached target
Eval num_timesteps=2330000, episode_reward=0.69 +/- 2.36
Episode length: 274.40 +/- 51.20
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 274       |
|    mean_reward          | 0.688     |
| time/                   |           |
|    total_timesteps      | 2330000   |
| train/                  |           |
|    approx_kl            | 2.4552693 |
|    clip_fraction        | 0.644     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.922     |
|    explained_variance   | 0.643     |
|    learning_rate        | 0.00155   |
|    loss                 | 0.025     |
|    n_updates            | 11370     |
|    policy_gradient_loss | 0.0618    |
|    std                  | 0.151     |
|    value_loss           | 0.0117    |
---------------------------------------
--------------------------------
| time/              |         |
|    fps             | 624     |
|    iterations      | 1138    |
|    time_elapsed    | 3729    |
|    total_timesteps | 2330624 |
--------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 624       |
|    iterations           | 1139      |
|    time_elapsed         | 3732      |
|    total_timesteps      | 2332672   |
| train/                  |           |
|    approx_kl            | 1.6966724 |
|    clip_fraction        | 0.605     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.837     |
|    explained_variance   | 0.562     |
|    learning_rate        | 0.00155   |
|    loss                 | 0.0295    |
|    n_updates            | 11380     |
|    policy_gradient_loss | 0.0803    |
|    std                  | 0.161     |
|    value_loss           | 0.014     |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 625        |
|    iterations           | 1140       |
|    time_elapsed         | 3735       |
|    total_timesteps      | 2334720    |
| train/                  |            |
|    approx_kl            | 0.78705066 |
|    clip_fraction        | 0.562      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.743      |
|    explained_variance   | 0.326      |
|    learning_rate        | 0.00155    |
|    loss                 | 0.0241     |
|    n_updates            | 11390      |
|    policy_gradient_loss | 0.102      |
|    std                  | 0.168      |
|    value_loss           | 0.00584    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 625        |
|    iterations           | 1141       |
|    time_elapsed         | 3738       |
|    total_timesteps      | 2336768    |
| train/                  |            |
|    approx_kl            | 0.47859973 |
|    clip_fraction        | 0.499      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.74       |
|    explained_variance   | 0.581      |
|    learning_rate        | 0.00154    |
|    loss                 | 0.0698     |
|    n_updates            | 11400      |
|    policy_gradient_loss | 0.0246     |
|    std                  | 0.166      |
|    value_loss           | 0.00336    |
----------------------------------------
box reached target
--------------------------------------
| time/                   |          |
|    fps                  | 625      |
|    iterations           | 1142     |
|    time_elapsed         | 3741     |
|    total_timesteps      | 2338816  |
| train/                  |          |
|    approx_kl            | 3.72991  |
|    clip_fraction        | 0.523    |
|    clip_range           | 0.2      |
|    entropy_loss         | 0.749    |
|    explained_variance   | 0.78     |
|    learning_rate        | 0.00154  |
|    loss                 | -0.00622 |
|    n_updates            | 11410    |
|    policy_gradient_loss | -0.00187 |
|    std                  | 0.164    |
|    value_loss           | 0.00234  |
--------------------------------------
box reached target
box reached target
box reached target
Eval num_timesteps=2340000, episode_reward=1.51 +/- 2.97
Episode length: 247.80 +/- 64.78
--------------------------------------
| eval/                   |          |
|    mean_ep_length       | 248      |
|    mean_reward          | 1.51     |
| time/                   |          |
|    total_timesteps      | 2340000  |
| train/                  |          |
|    approx_kl            | 5.449432 |
|    clip_fraction        | 0.606    |
|    clip_range           | 0.2      |
|    entropy_loss         | 0.807    |
|    explained_variance   | 0.0247   |
|    learning_rate        | 0.00154  |
|    loss                 | -0.00589 |
|    n_updates            | 11420    |
|    policy_gradient_loss | 0.0371   |
|    std                  | 0.16     |
|    value_loss           | 0.0639   |
--------------------------------------
box reached target
--------------------------------
| time/              |         |
|    fps             | 624     |
|    iterations      | 1143    |
|    time_elapsed    | 3745    |
|    total_timesteps | 2340864 |
--------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 625        |
|    iterations           | 1144       |
|    time_elapsed         | 3748       |
|    total_timesteps      | 2342912    |
| train/                  |            |
|    approx_kl            | 0.35291046 |
|    clip_fraction        | 0.536      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.784      |
|    explained_variance   | 0.617      |
|    learning_rate        | 0.00154    |
|    loss                 | 0.0342     |
|    n_updates            | 11430      |
|    policy_gradient_loss | 0.0377     |
|    std                  | 0.164      |
|    value_loss           | 0.0189     |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 625        |
|    iterations           | 1145       |
|    time_elapsed         | 3751       |
|    total_timesteps      | 2344960    |
| train/                  |            |
|    approx_kl            | 0.33494627 |
|    clip_fraction        | 0.539      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.699      |
|    explained_variance   | 0.564      |
|    learning_rate        | 0.00154    |
|    loss                 | 0.0773     |
|    n_updates            | 11440      |
|    policy_gradient_loss | 0.06       |
|    std                  | 0.174      |
|    value_loss           | 0.0352     |
----------------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 625        |
|    iterations           | 1146       |
|    time_elapsed         | 3754       |
|    total_timesteps      | 2347008    |
| train/                  |            |
|    approx_kl            | 0.87233174 |
|    clip_fraction        | 0.483      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.694      |
|    explained_variance   | 0.548      |
|    learning_rate        | 0.00154    |
|    loss                 | -0.0106    |
|    n_updates            | 11450      |
|    policy_gradient_loss | 0.014      |
|    std                  | 0.168      |
|    value_loss           | 0.0341     |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 625        |
|    iterations           | 1147       |
|    time_elapsed         | 3757       |
|    total_timesteps      | 2349056    |
| train/                  |            |
|    approx_kl            | 0.67503357 |
|    clip_fraction        | 0.546      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.695      |
|    explained_variance   | 0.771      |
|    learning_rate        | 0.00154    |
|    loss                 | 0.11       |
|    n_updates            | 11460      |
|    policy_gradient_loss | 0.0467     |
|    std                  | 0.171      |
|    value_loss           | 0.0383     |
----------------------------------------
box reached target
box reached target
box reached target
box reached target
Eval num_timesteps=2350000, episode_reward=1.65 +/- 2.87
Episode length: 256.80 +/- 53.09
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 257        |
|    mean_reward          | 1.65       |
| time/                   |            |
|    total_timesteps      | 2350000    |
| train/                  |            |
|    approx_kl            | 0.56022966 |
|    clip_fraction        | 0.633      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.607      |
|    explained_variance   | 0.862      |
|    learning_rate        | 0.00154    |
|    loss                 | 0.1        |
|    n_updates            | 11470      |
|    policy_gradient_loss | 0.0584     |
|    std                  | 0.181      |
|    value_loss           | 0.0176     |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 625     |
|    iterations      | 1148    |
|    time_elapsed    | 3761    |
|    total_timesteps | 2351104 |
--------------------------------
box reached target
--------------------------------------
| time/                   |          |
|    fps                  | 625      |
|    iterations           | 1149     |
|    time_elapsed         | 3764     |
|    total_timesteps      | 2353152  |
| train/                  |          |
|    approx_kl            | 2.95851  |
|    clip_fraction        | 0.63     |
|    clip_range           | 0.2      |
|    entropy_loss         | 0.567    |
|    explained_variance   | 0.815    |
|    learning_rate        | 0.00154  |
|    loss                 | -0.00723 |
|    n_updates            | 11480    |
|    policy_gradient_loss | 0.0162   |
|    std                  | 0.182    |
|    value_loss           | 0.0129   |
--------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 625        |
|    iterations           | 1150       |
|    time_elapsed         | 3767       |
|    total_timesteps      | 2355200    |
| train/                  |            |
|    approx_kl            | 0.93421996 |
|    clip_fraction        | 0.553      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.573      |
|    explained_variance   | 0.738      |
|    learning_rate        | 0.00154    |
|    loss                 | 0.0134     |
|    n_updates            | 11490      |
|    policy_gradient_loss | 0.00763    |
|    std                  | 0.177      |
|    value_loss           | 0.0432     |
----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 625       |
|    iterations           | 1151      |
|    time_elapsed         | 3770      |
|    total_timesteps      | 2357248   |
| train/                  |           |
|    approx_kl            | 0.4568593 |
|    clip_fraction        | 0.48      |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.614     |
|    explained_variance   | 0.725     |
|    learning_rate        | 0.00154   |
|    loss                 | -0.03     |
|    n_updates            | 11500     |
|    policy_gradient_loss | 0.0224    |
|    std                  | 0.176     |
|    value_loss           | 0.013     |
---------------------------------------
box reached target
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 625        |
|    iterations           | 1152       |
|    time_elapsed         | 3773       |
|    total_timesteps      | 2359296    |
| train/                  |            |
|    approx_kl            | 0.31613305 |
|    clip_fraction        | 0.521      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.605      |
|    explained_variance   | 0.698      |
|    learning_rate        | 0.00154    |
|    loss                 | 0.0446     |
|    n_updates            | 11510      |
|    policy_gradient_loss | 0.0274     |
|    std                  | 0.178      |
|    value_loss           | 0.0179     |
----------------------------------------
Eval num_timesteps=2360000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 300       |
|    mean_reward          | -1        |
| time/                   |           |
|    total_timesteps      | 2360000   |
| train/                  |           |
|    approx_kl            | 0.8312723 |
|    clip_fraction        | 0.53      |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.628     |
|    explained_variance   | 0.624     |
|    learning_rate        | 0.00154   |
|    loss                 | 0.0312    |
|    n_updates            | 11520     |
|    policy_gradient_loss | 0.00873   |
|    std                  | 0.175     |
|    value_loss           | 0.119     |
---------------------------------------
--------------------------------
| time/              |         |
|    fps             | 625     |
|    iterations      | 1153    |
|    time_elapsed    | 3777    |
|    total_timesteps | 2361344 |
--------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 625       |
|    iterations           | 1154      |
|    time_elapsed         | 3780      |
|    total_timesteps      | 2363392   |
| train/                  |           |
|    approx_kl            | 1.3773379 |
|    clip_fraction        | 0.53      |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.677     |
|    explained_variance   | 0.609     |
|    learning_rate        | 0.00154   |
|    loss                 | -0.0292   |
|    n_updates            | 11530     |
|    policy_gradient_loss | 0.0101    |
|    std                  | 0.171     |
|    value_loss           | 0.0147    |
---------------------------------------
box reached target
--------------------------------------
| time/                   |          |
|    fps                  | 625      |
|    iterations           | 1155     |
|    time_elapsed         | 3783     |
|    total_timesteps      | 2365440  |
| train/                  |          |
|    approx_kl            | 1.217128 |
|    clip_fraction        | 0.543    |
|    clip_range           | 0.2      |
|    entropy_loss         | 0.717    |
|    explained_variance   | 0.746    |
|    learning_rate        | 0.00154  |
|    loss                 | 0.00439  |
|    n_updates            | 11540    |
|    policy_gradient_loss | 0.0118   |
|    std                  | 0.166    |
|    value_loss           | 0.00847  |
--------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 625        |
|    iterations           | 1156       |
|    time_elapsed         | 3786       |
|    total_timesteps      | 2367488    |
| train/                  |            |
|    approx_kl            | 0.73295593 |
|    clip_fraction        | 0.512      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.753      |
|    explained_variance   | 0.801      |
|    learning_rate        | 0.00154    |
|    loss                 | 0.0143     |
|    n_updates            | 11550      |
|    policy_gradient_loss | 0.0034     |
|    std                  | 0.165      |
|    value_loss           | 0.0109     |
----------------------------------------
box reached target
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 625       |
|    iterations           | 1157      |
|    time_elapsed         | 3789      |
|    total_timesteps      | 2369536   |
| train/                  |           |
|    approx_kl            | 1.0902953 |
|    clip_fraction        | 0.536     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.761     |
|    explained_variance   | 0.639     |
|    learning_rate        | 0.00154   |
|    loss                 | -0.0312   |
|    n_updates            | 11560     |
|    policy_gradient_loss | 0.017     |
|    std                  | 0.164     |
|    value_loss           | 0.00364   |
---------------------------------------
box reached target
Eval num_timesteps=2370000, episode_reward=0.46 +/- 2.41
Episode length: 270.80 +/- 58.40
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 271       |
|    mean_reward          | 0.464     |
| time/                   |           |
|    total_timesteps      | 2370000   |
| train/                  |           |
|    approx_kl            | 0.5579715 |
|    clip_fraction        | 0.586     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.721     |
|    explained_variance   | 0.591     |
|    learning_rate        | 0.00154   |
|    loss                 | 0.0374    |
|    n_updates            | 11570     |
|    policy_gradient_loss | 0.0337    |
|    std                  | 0.171     |
|    value_loss           | 0.0159    |
---------------------------------------
box reached target
--------------------------------
| time/              |         |
|    fps             | 625     |
|    iterations      | 1158    |
|    time_elapsed    | 3793    |
|    total_timesteps | 2371584 |
--------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 625       |
|    iterations           | 1159      |
|    time_elapsed         | 3796      |
|    total_timesteps      | 2373632   |
| train/                  |           |
|    approx_kl            | 1.6998527 |
|    clip_fraction        | 0.568     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.659     |
|    explained_variance   | 0.51      |
|    learning_rate        | 0.00154   |
|    loss                 | -0.00149  |
|    n_updates            | 11580     |
|    policy_gradient_loss | 0.0343    |
|    std                  | 0.17      |
|    value_loss           | 0.0268    |
---------------------------------------
box reached target
box reached target
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 625       |
|    iterations           | 1160      |
|    time_elapsed         | 3799      |
|    total_timesteps      | 2375680   |
| train/                  |           |
|    approx_kl            | 1.1524236 |
|    clip_fraction        | 0.523     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.667     |
|    explained_variance   | 0.218     |
|    learning_rate        | 0.00154   |
|    loss                 | 0.0138    |
|    n_updates            | 11590     |
|    policy_gradient_loss | 0.0199    |
|    std                  | 0.174     |
|    value_loss           | 0.00813   |
---------------------------------------
--------------------------------------
| time/                   |          |
|    fps                  | 625      |
|    iterations           | 1161     |
|    time_elapsed         | 3802     |
|    total_timesteps      | 2377728  |
| train/                  |          |
|    approx_kl            | 1.898329 |
|    clip_fraction        | 0.614    |
|    clip_range           | 0.2      |
|    entropy_loss         | 0.667    |
|    explained_variance   | 0.751    |
|    learning_rate        | 0.00154  |
|    loss                 | 0.0374   |
|    n_updates            | 11600    |
|    policy_gradient_loss | 0.0217   |
|    std                  | 0.172    |
|    value_loss           | 0.0324   |
--------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 625       |
|    iterations           | 1162      |
|    time_elapsed         | 3805      |
|    total_timesteps      | 2379776   |
| train/                  |           |
|    approx_kl            | 1.6487929 |
|    clip_fraction        | 0.505     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.695     |
|    explained_variance   | 0.474     |
|    learning_rate        | 0.00154   |
|    loss                 | -0.011    |
|    n_updates            | 11610     |
|    policy_gradient_loss | 0.00657   |
|    std                  | 0.168     |
|    value_loss           | 0.00849   |
---------------------------------------
Eval num_timesteps=2380000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 300       |
|    mean_reward          | -1        |
| time/                   |           |
|    total_timesteps      | 2380000   |
| train/                  |           |
|    approx_kl            | 0.5131676 |
|    clip_fraction        | 0.552     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.705     |
|    explained_variance   | 0.6       |
|    learning_rate        | 0.00154   |
|    loss                 | 0.013     |
|    n_updates            | 11620     |
|    policy_gradient_loss | 0.021     |
|    std                  | 0.168     |
|    value_loss           | 0.0482    |
---------------------------------------
--------------------------------
| time/              |         |
|    fps             | 625     |
|    iterations      | 1163    |
|    time_elapsed    | 3809    |
|    total_timesteps | 2381824 |
--------------------------------
--------------------------------------
| time/                   |          |
|    fps                  | 625      |
|    iterations           | 1164     |
|    time_elapsed         | 3812     |
|    total_timesteps      | 2383872  |
| train/                  |          |
|    approx_kl            | 0.483195 |
|    clip_fraction        | 0.599    |
|    clip_range           | 0.2      |
|    entropy_loss         | 0.656    |
|    explained_variance   | 0.054    |
|    learning_rate        | 0.00154  |
|    loss                 | -0.0205  |
|    n_updates            | 11630    |
|    policy_gradient_loss | 0.0414   |
|    std                  | 0.173    |
|    value_loss           | 0.00729  |
--------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 625        |
|    iterations           | 1165       |
|    time_elapsed         | 3815       |
|    total_timesteps      | 2385920    |
| train/                  |            |
|    approx_kl            | 0.70673335 |
|    clip_fraction        | 0.545      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.621      |
|    explained_variance   | 0.901      |
|    learning_rate        | 0.00154    |
|    loss                 | -0.0271    |
|    n_updates            | 11640      |
|    policy_gradient_loss | 0.0336     |
|    std                  | 0.18       |
|    value_loss           | 0.00899    |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 625        |
|    iterations           | 1166       |
|    time_elapsed         | 3818       |
|    total_timesteps      | 2387968    |
| train/                  |            |
|    approx_kl            | 0.24273019 |
|    clip_fraction        | 0.49       |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.479      |
|    explained_variance   | -0.299     |
|    learning_rate        | 0.00153    |
|    loss                 | -0.0031    |
|    n_updates            | 11650      |
|    policy_gradient_loss | 0.02       |
|    std                  | 0.191      |
|    value_loss           | 0.00609    |
----------------------------------------
box reached target
Eval num_timesteps=2390000, episode_reward=-0.68 +/- 0.64
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -0.678     |
| time/                   |            |
|    total_timesteps      | 2390000    |
| train/                  |            |
|    approx_kl            | 0.50486284 |
|    clip_fraction        | 0.503      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.489      |
|    explained_variance   | 0.85       |
|    learning_rate        | 0.00153    |
|    loss                 | 0.0775     |
|    n_updates            | 11660      |
|    policy_gradient_loss | 0.0106     |
|    std                  | 0.186      |
|    value_loss           | 0.00976    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 625     |
|    iterations      | 1167    |
|    time_elapsed    | 3822    |
|    total_timesteps | 2390016 |
--------------------------------
box reached target
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 625       |
|    iterations           | 1168      |
|    time_elapsed         | 3825      |
|    total_timesteps      | 2392064   |
| train/                  |           |
|    approx_kl            | 0.4469813 |
|    clip_fraction        | 0.546     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.494     |
|    explained_variance   | 0.281     |
|    learning_rate        | 0.00153   |
|    loss                 | 0.0319    |
|    n_updates            | 11670     |
|    policy_gradient_loss | 0.0524    |
|    std                  | 0.188     |
|    value_loss           | 0.0516    |
---------------------------------------
box reached target
box reached target
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 625       |
|    iterations           | 1169      |
|    time_elapsed         | 3828      |
|    total_timesteps      | 2394112   |
| train/                  |           |
|    approx_kl            | 1.3894157 |
|    clip_fraction        | 0.49      |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.519     |
|    explained_variance   | 0.689     |
|    learning_rate        | 0.00153   |
|    loss                 | 0.0213    |
|    n_updates            | 11680     |
|    policy_gradient_loss | 0.00809   |
|    std                  | 0.18      |
|    value_loss           | 0.045     |
---------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 625       |
|    iterations           | 1170      |
|    time_elapsed         | 3831      |
|    total_timesteps      | 2396160   |
| train/                  |           |
|    approx_kl            | 1.8482745 |
|    clip_fraction        | 0.574     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.632     |
|    explained_variance   | 0.735     |
|    learning_rate        | 0.00153   |
|    loss                 | -0.0139   |
|    n_updates            | 11690     |
|    policy_gradient_loss | 0.0114    |
|    std                  | 0.172     |
|    value_loss           | 0.0547    |
---------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 625       |
|    iterations           | 1171      |
|    time_elapsed         | 3834      |
|    total_timesteps      | 2398208   |
| train/                  |           |
|    approx_kl            | 0.7757096 |
|    clip_fraction        | 0.533     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.693     |
|    explained_variance   | 0.757     |
|    learning_rate        | 0.00153   |
|    loss                 | 0.0814    |
|    n_updates            | 11700     |
|    policy_gradient_loss | 0.0184    |
|    std                  | 0.171     |
|    value_loss           | 0.0385    |
---------------------------------------
box reached target
box reached target
Eval num_timesteps=2400000, episode_reward=-0.81 +/- 0.30
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -0.807     |
| time/                   |            |
|    total_timesteps      | 2400000    |
| train/                  |            |
|    approx_kl            | 0.61689854 |
|    clip_fraction        | 0.506      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.698      |
|    explained_variance   | 0.618      |
|    learning_rate        | 0.00153    |
|    loss                 | 0.00258    |
|    n_updates            | 11710      |
|    policy_gradient_loss | 0.0109     |
|    std                  | 0.169      |
|    value_loss           | 0.00949    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 625     |
|    iterations      | 1172    |
|    time_elapsed    | 3838    |
|    total_timesteps | 2400256 |
--------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 625        |
|    iterations           | 1173       |
|    time_elapsed         | 3841       |
|    total_timesteps      | 2402304    |
| train/                  |            |
|    approx_kl            | 0.63272846 |
|    clip_fraction        | 0.527      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.716      |
|    explained_variance   | 0.914      |
|    learning_rate        | 0.00153    |
|    loss                 | -0.0458    |
|    n_updates            | 11720      |
|    policy_gradient_loss | 0.014      |
|    std                  | 0.168      |
|    value_loss           | 0.0208     |
----------------------------------------
box reached target
box reached target
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 625        |
|    iterations           | 1174       |
|    time_elapsed         | 3844       |
|    total_timesteps      | 2404352    |
| train/                  |            |
|    approx_kl            | 0.49112278 |
|    clip_fraction        | 0.522      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.703      |
|    explained_variance   | 0.855      |
|    learning_rate        | 0.00153    |
|    loss                 | 0.155      |
|    n_updates            | 11730      |
|    policy_gradient_loss | 0.0216     |
|    std                  | 0.17       |
|    value_loss           | 0.0129     |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 625        |
|    iterations           | 1175       |
|    time_elapsed         | 3847       |
|    total_timesteps      | 2406400    |
| train/                  |            |
|    approx_kl            | 0.49672318 |
|    clip_fraction        | 0.522      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.666      |
|    explained_variance   | 0.678      |
|    learning_rate        | 0.00153    |
|    loss                 | 0.0351     |
|    n_updates            | 11740      |
|    policy_gradient_loss | 0.0363     |
|    std                  | 0.175      |
|    value_loss           | 0.051      |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 625        |
|    iterations           | 1176       |
|    time_elapsed         | 3850       |
|    total_timesteps      | 2408448    |
| train/                  |            |
|    approx_kl            | 0.22889131 |
|    clip_fraction        | 0.528      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.557      |
|    explained_variance   | 0.709      |
|    learning_rate        | 0.00153    |
|    loss                 | 0.118      |
|    n_updates            | 11750      |
|    policy_gradient_loss | 0.0457     |
|    std                  | 0.186      |
|    value_loss           | 0.0186     |
----------------------------------------
box reached target
Eval num_timesteps=2410000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 300       |
|    mean_reward          | -1        |
| time/                   |           |
|    total_timesteps      | 2410000   |
| train/                  |           |
|    approx_kl            | 1.3262568 |
|    clip_fraction        | 0.59      |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.486     |
|    explained_variance   | 0.687     |
|    learning_rate        | 0.00153   |
|    loss                 | 0.0357    |
|    n_updates            | 11760     |
|    policy_gradient_loss | 0.0338    |
|    std                  | 0.193     |
|    value_loss           | 0.0328    |
---------------------------------------
--------------------------------
| time/              |         |
|    fps             | 625     |
|    iterations      | 1177    |
|    time_elapsed    | 3854    |
|    total_timesteps | 2410496 |
--------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 625        |
|    iterations           | 1178       |
|    time_elapsed         | 3857       |
|    total_timesteps      | 2412544    |
| train/                  |            |
|    approx_kl            | 0.59509426 |
|    clip_fraction        | 0.497      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.436      |
|    explained_variance   | 0.736      |
|    learning_rate        | 0.00153    |
|    loss                 | -0.0436    |
|    n_updates            | 11770      |
|    policy_gradient_loss | 0.013      |
|    std                  | 0.194      |
|    value_loss           | 0.0254     |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 625        |
|    iterations           | 1179       |
|    time_elapsed         | 3861       |
|    total_timesteps      | 2414592    |
| train/                  |            |
|    approx_kl            | 0.31034723 |
|    clip_fraction        | 0.482      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.4        |
|    explained_variance   | 0.871      |
|    learning_rate        | 0.00153    |
|    loss                 | 0.165      |
|    n_updates            | 11780      |
|    policy_gradient_loss | 0.0232     |
|    std                  | 0.2        |
|    value_loss           | 0.0138     |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 625        |
|    iterations           | 1180       |
|    time_elapsed         | 3864       |
|    total_timesteps      | 2416640    |
| train/                  |            |
|    approx_kl            | 0.49238074 |
|    clip_fraction        | 0.474      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.345      |
|    explained_variance   | 0.845      |
|    learning_rate        | 0.00153    |
|    loss                 | -0.0382    |
|    n_updates            | 11790      |
|    policy_gradient_loss | 0.0046     |
|    std                  | 0.203      |
|    value_loss           | 0.013      |
----------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 625       |
|    iterations           | 1181      |
|    time_elapsed         | 3867      |
|    total_timesteps      | 2418688   |
| train/                  |           |
|    approx_kl            | 0.2556399 |
|    clip_fraction        | 0.45      |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.332     |
|    explained_variance   | 0.774     |
|    learning_rate        | 0.00153   |
|    loss                 | 0.0208    |
|    n_updates            | 11800     |
|    policy_gradient_loss | 0.0272    |
|    std                  | 0.204     |
|    value_loss           | 0.0103    |
---------------------------------------
box reached target
box reached target
box reached target
Eval num_timesteps=2420000, episode_reward=2.92 +/- 2.78
Episode length: 224.80 +/- 62.02
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 225        |
|    mean_reward          | 2.92       |
| time/                   |            |
|    total_timesteps      | 2420000    |
| train/                  |            |
|    approx_kl            | 0.21533719 |
|    clip_fraction        | 0.423      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.338      |
|    explained_variance   | 0.642      |
|    learning_rate        | 0.00153    |
|    loss                 | 0.0143     |
|    n_updates            | 11810      |
|    policy_gradient_loss | 0.0151     |
|    std                  | 0.202      |
|    value_loss           | 0.0332     |
----------------------------------------
box reached target
--------------------------------
| time/              |         |
|    fps             | 625     |
|    iterations      | 1182    |
|    time_elapsed    | 3870    |
|    total_timesteps | 2420736 |
--------------------------------
box reached target
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 625        |
|    iterations           | 1183       |
|    time_elapsed         | 3873       |
|    total_timesteps      | 2422784    |
| train/                  |            |
|    approx_kl            | 0.14623973 |
|    clip_fraction        | 0.387      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.365      |
|    explained_variance   | 0.611      |
|    learning_rate        | 0.00153    |
|    loss                 | -0.0123    |
|    n_updates            | 11820      |
|    policy_gradient_loss | 0.0161     |
|    std                  | 0.199      |
|    value_loss           | 0.0166     |
----------------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 625        |
|    iterations           | 1184       |
|    time_elapsed         | 3876       |
|    total_timesteps      | 2424832    |
| train/                  |            |
|    approx_kl            | 0.95621485 |
|    clip_fraction        | 0.541      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.401      |
|    explained_variance   | 0.706      |
|    learning_rate        | 0.00153    |
|    loss                 | -0.00923   |
|    n_updates            | 11830      |
|    policy_gradient_loss | 0.0269     |
|    std                  | 0.196      |
|    value_loss           | 0.027      |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 625        |
|    iterations           | 1185       |
|    time_elapsed         | 3879       |
|    total_timesteps      | 2426880    |
| train/                  |            |
|    approx_kl            | 0.71175784 |
|    clip_fraction        | 0.492      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.432      |
|    explained_variance   | 0.725      |
|    learning_rate        | 0.00153    |
|    loss                 | 0.0103     |
|    n_updates            | 11840      |
|    policy_gradient_loss | 0.0196     |
|    std                  | 0.192      |
|    value_loss           | 0.0188     |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 625        |
|    iterations           | 1186       |
|    time_elapsed         | 3882       |
|    total_timesteps      | 2428928    |
| train/                  |            |
|    approx_kl            | 0.60238546 |
|    clip_fraction        | 0.51       |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.45       |
|    explained_variance   | 0.679      |
|    learning_rate        | 0.00153    |
|    loss                 | -0.029     |
|    n_updates            | 11850      |
|    policy_gradient_loss | 0.0168     |
|    std                  | 0.19       |
|    value_loss           | 0.00964    |
----------------------------------------
box reached target
Eval num_timesteps=2430000, episode_reward=0.26 +/- 2.57
Episode length: 282.60 +/- 34.80
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 283       |
|    mean_reward          | 0.255     |
| time/                   |           |
|    total_timesteps      | 2430000   |
| train/                  |           |
|    approx_kl            | 0.5716154 |
|    clip_fraction        | 0.509     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.471     |
|    explained_variance   | 0.635     |
|    learning_rate        | 0.00153   |
|    loss                 | -0.0193   |
|    n_updates            | 11860     |
|    policy_gradient_loss | 0.02      |
|    std                  | 0.191     |
|    value_loss           | 0.00955   |
---------------------------------------
box reached target
--------------------------------
| time/              |         |
|    fps             | 625     |
|    iterations      | 1187    |
|    time_elapsed    | 3886    |
|    total_timesteps | 2430976 |
--------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 625       |
|    iterations           | 1188      |
|    time_elapsed         | 3889      |
|    total_timesteps      | 2433024   |
| train/                  |           |
|    approx_kl            | 0.5348484 |
|    clip_fraction        | 0.495     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.478     |
|    explained_variance   | 0.342     |
|    learning_rate        | 0.00153   |
|    loss                 | 0.00392   |
|    n_updates            | 11870     |
|    policy_gradient_loss | 0.018     |
|    std                  | 0.187     |
|    value_loss           | 0.0194    |
---------------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 625        |
|    iterations           | 1189       |
|    time_elapsed         | 3892       |
|    total_timesteps      | 2435072    |
| train/                  |            |
|    approx_kl            | 0.40943426 |
|    clip_fraction        | 0.504      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.513      |
|    explained_variance   | 0.784      |
|    learning_rate        | 0.00153    |
|    loss                 | 0.04       |
|    n_updates            | 11880      |
|    policy_gradient_loss | 0.0196     |
|    std                  | 0.185      |
|    value_loss           | 0.00945    |
----------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 625       |
|    iterations           | 1190      |
|    time_elapsed         | 3896      |
|    total_timesteps      | 2437120   |
| train/                  |           |
|    approx_kl            | 0.7457521 |
|    clip_fraction        | 0.482     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.515     |
|    explained_variance   | 0.526     |
|    learning_rate        | 0.00153   |
|    loss                 | 0.0221    |
|    n_updates            | 11890     |
|    policy_gradient_loss | 0.0116    |
|    std                  | 0.188     |
|    value_loss           | 0.0182    |
---------------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 625        |
|    iterations           | 1191       |
|    time_elapsed         | 3899       |
|    total_timesteps      | 2439168    |
| train/                  |            |
|    approx_kl            | 0.79236615 |
|    clip_fraction        | 0.511      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.473      |
|    explained_variance   | 0.245      |
|    learning_rate        | 0.00152    |
|    loss                 | 0.0548     |
|    n_updates            | 11900      |
|    policy_gradient_loss | 0.0119     |
|    std                  | 0.189      |
|    value_loss           | 0.033      |
----------------------------------------
box reached target
Eval num_timesteps=2440000, episode_reward=0.51 +/- 2.38
Episode length: 284.80 +/- 30.40
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 285        |
|    mean_reward          | 0.512      |
| time/                   |            |
|    total_timesteps      | 2440000    |
| train/                  |            |
|    approx_kl            | 0.33064866 |
|    clip_fraction        | 0.515      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.475      |
|    explained_variance   | 0.645      |
|    learning_rate        | 0.00152    |
|    loss                 | 0.0692     |
|    n_updates            | 11910      |
|    policy_gradient_loss | 0.0223     |
|    std                  | 0.191      |
|    value_loss           | 0.043      |
----------------------------------------
box reached target
box reached target
box reached target
--------------------------------
| time/              |         |
|    fps             | 625     |
|    iterations      | 1192    |
|    time_elapsed    | 3902    |
|    total_timesteps | 2441216 |
--------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 625       |
|    iterations           | 1193      |
|    time_elapsed         | 3905      |
|    total_timesteps      | 2443264   |
| train/                  |           |
|    approx_kl            | 0.8648503 |
|    clip_fraction        | 0.454     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.486     |
|    explained_variance   | 0.852     |
|    learning_rate        | 0.00152   |
|    loss                 | 0.0376    |
|    n_updates            | 11920     |
|    policy_gradient_loss | 0.0324    |
|    std                  | 0.188     |
|    value_loss           | 0.0258    |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 625        |
|    iterations           | 1194       |
|    time_elapsed         | 3909       |
|    total_timesteps      | 2445312    |
| train/                  |            |
|    approx_kl            | 0.42112255 |
|    clip_fraction        | 0.479      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.467      |
|    explained_variance   | 0.749      |
|    learning_rate        | 0.00152    |
|    loss                 | 0.0113     |
|    n_updates            | 11930      |
|    policy_gradient_loss | 0.0232     |
|    std                  | 0.194      |
|    value_loss           | 0.0107     |
----------------------------------------
box reached target
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 625        |
|    iterations           | 1195       |
|    time_elapsed         | 3912       |
|    total_timesteps      | 2447360    |
| train/                  |            |
|    approx_kl            | 0.90345216 |
|    clip_fraction        | 0.521      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.437      |
|    explained_variance   | 0.7        |
|    learning_rate        | 0.00152    |
|    loss                 | 0.00382    |
|    n_updates            | 11940      |
|    policy_gradient_loss | 0.00969    |
|    std                  | 0.191      |
|    value_loss           | 0.031      |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 625        |
|    iterations           | 1196       |
|    time_elapsed         | 3915       |
|    total_timesteps      | 2449408    |
| train/                  |            |
|    approx_kl            | 0.24502514 |
|    clip_fraction        | 0.458      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.425      |
|    explained_variance   | 0.714      |
|    learning_rate        | 0.00152    |
|    loss                 | 0.0263     |
|    n_updates            | 11950      |
|    policy_gradient_loss | 0.00888    |
|    std                  | 0.198      |
|    value_loss           | 0.0279     |
----------------------------------------
box reached target
Eval num_timesteps=2450000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 300       |
|    mean_reward          | -1        |
| time/                   |           |
|    total_timesteps      | 2450000   |
| train/                  |           |
|    approx_kl            | 0.5502755 |
|    clip_fraction        | 0.456     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.457     |
|    explained_variance   | 0.735     |
|    learning_rate        | 0.00152   |
|    loss                 | -0.038    |
|    n_updates            | 11960     |
|    policy_gradient_loss | 0.000652  |
|    std                  | 0.192     |
|    value_loss           | 0.0182    |
---------------------------------------
box reached target
--------------------------------
| time/              |         |
|    fps             | 625     |
|    iterations      | 1197    |
|    time_elapsed    | 3919    |
|    total_timesteps | 2451456 |
--------------------------------
box reached target
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 625       |
|    iterations           | 1198      |
|    time_elapsed         | 3922      |
|    total_timesteps      | 2453504   |
| train/                  |           |
|    approx_kl            | 0.3825732 |
|    clip_fraction        | 0.495     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.459     |
|    explained_variance   | 0.66      |
|    learning_rate        | 0.00152   |
|    loss                 | 0.141     |
|    n_updates            | 11970     |
|    policy_gradient_loss | 0.0187    |
|    std                  | 0.193     |
|    value_loss           | 0.0198    |
---------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 625       |
|    iterations           | 1199      |
|    time_elapsed         | 3925      |
|    total_timesteps      | 2455552   |
| train/                  |           |
|    approx_kl            | 0.3840941 |
|    clip_fraction        | 0.449     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.432     |
|    explained_variance   | 0.87      |
|    learning_rate        | 0.00152   |
|    loss                 | 0.011     |
|    n_updates            | 11980     |
|    policy_gradient_loss | 0.01      |
|    std                  | 0.194     |
|    value_loss           | 0.0146    |
---------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 625       |
|    iterations           | 1200      |
|    time_elapsed         | 3928      |
|    total_timesteps      | 2457600   |
| train/                  |           |
|    approx_kl            | 0.7074803 |
|    clip_fraction        | 0.521     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.437     |
|    explained_variance   | 0.737     |
|    learning_rate        | 0.00152   |
|    loss                 | -0.0444   |
|    n_updates            | 11990     |
|    policy_gradient_loss | 0.00875   |
|    std                  | 0.194     |
|    value_loss           | 0.0129    |
---------------------------------------
box reached target
box reached target
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 625       |
|    iterations           | 1201      |
|    time_elapsed         | 3931      |
|    total_timesteps      | 2459648   |
| train/                  |           |
|    approx_kl            | 1.3374661 |
|    clip_fraction        | 0.484     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.398     |
|    explained_variance   | 0.488     |
|    learning_rate        | 0.00152   |
|    loss                 | -0.00288  |
|    n_updates            | 12000     |
|    policy_gradient_loss | 0.0206    |
|    std                  | 0.198     |
|    value_loss           | 0.02      |
---------------------------------------
box reached target
box reached target
Eval num_timesteps=2460000, episode_reward=1.52 +/- 3.08
Episode length: 262.80 +/- 49.85
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 263        |
|    mean_reward          | 1.52       |
| time/                   |            |
|    total_timesteps      | 2460000    |
| train/                  |            |
|    approx_kl            | 0.46814865 |
|    clip_fraction        | 0.493      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.415      |
|    explained_variance   | 0.895      |
|    learning_rate        | 0.00152    |
|    loss                 | -0.0175    |
|    n_updates            | 12010      |
|    policy_gradient_loss | 0.0243     |
|    std                  | 0.196      |
|    value_loss           | 0.0249     |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 625     |
|    iterations      | 1202    |
|    time_elapsed    | 3935    |
|    total_timesteps | 2461696 |
--------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 625       |
|    iterations           | 1203      |
|    time_elapsed         | 3938      |
|    total_timesteps      | 2463744   |
| train/                  |           |
|    approx_kl            | 0.5382847 |
|    clip_fraction        | 0.504     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.373     |
|    explained_variance   | 0.769     |
|    learning_rate        | 0.00152   |
|    loss                 | -0.0123   |
|    n_updates            | 12020     |
|    policy_gradient_loss | 0.348     |
|    std                  | 0.197     |
|    value_loss           | 0.00924   |
---------------------------------------
box reached target
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 625        |
|    iterations           | 1204       |
|    time_elapsed         | 3941       |
|    total_timesteps      | 2465792    |
| train/                  |            |
|    approx_kl            | 0.61472803 |
|    clip_fraction        | 0.482      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.404      |
|    explained_variance   | 0.9        |
|    learning_rate        | 0.00152    |
|    loss                 | 0.00382    |
|    n_updates            | 12030      |
|    policy_gradient_loss | 0.0111     |
|    std                  | 0.198      |
|    value_loss           | 0.0163     |
----------------------------------------
box reached target
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 625       |
|    iterations           | 1205      |
|    time_elapsed         | 3944      |
|    total_timesteps      | 2467840   |
| train/                  |           |
|    approx_kl            | 0.6381577 |
|    clip_fraction        | 0.506     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.361     |
|    explained_variance   | 0.831     |
|    learning_rate        | 0.00152   |
|    loss                 | 0.0991    |
|    n_updates            | 12040     |
|    policy_gradient_loss | 0.033     |
|    std                  | 0.204     |
|    value_loss           | 0.0368    |
---------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 625        |
|    iterations           | 1206       |
|    time_elapsed         | 3947       |
|    total_timesteps      | 2469888    |
| train/                  |            |
|    approx_kl            | 0.28689092 |
|    clip_fraction        | 0.46       |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.36       |
|    explained_variance   | 0.94       |
|    learning_rate        | 0.00152    |
|    loss                 | 0.000504   |
|    n_updates            | 12050      |
|    policy_gradient_loss | 0.0164     |
|    std                  | 0.201      |
|    value_loss           | 0.00883    |
----------------------------------------
Eval num_timesteps=2470000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 300       |
|    mean_reward          | -1        |
| time/                   |           |
|    total_timesteps      | 2470000   |
| train/                  |           |
|    approx_kl            | 0.4396776 |
|    clip_fraction        | 0.481     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.357     |
|    explained_variance   | 0.68      |
|    learning_rate        | 0.00152   |
|    loss                 | 0.0482    |
|    n_updates            | 12060     |
|    policy_gradient_loss | 0.0173    |
|    std                  | 0.203     |
|    value_loss           | 0.0157    |
---------------------------------------
box reached target
box reached target
--------------------------------
| time/              |         |
|    fps             | 625     |
|    iterations      | 1207    |
|    time_elapsed    | 3951    |
|    total_timesteps | 2471936 |
--------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 625       |
|    iterations           | 1208      |
|    time_elapsed         | 3954      |
|    total_timesteps      | 2473984   |
| train/                  |           |
|    approx_kl            | 1.1527215 |
|    clip_fraction        | 0.467     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.357     |
|    explained_variance   | 0.899     |
|    learning_rate        | 0.00152   |
|    loss                 | -0.0384   |
|    n_updates            | 12070     |
|    policy_gradient_loss | 0.00454   |
|    std                  | 0.2       |
|    value_loss           | 0.0121    |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 625        |
|    iterations           | 1209       |
|    time_elapsed         | 3957       |
|    total_timesteps      | 2476032    |
| train/                  |            |
|    approx_kl            | 0.49098563 |
|    clip_fraction        | 0.476      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.345      |
|    explained_variance   | 0.855      |
|    learning_rate        | 0.00152    |
|    loss                 | 0.0278     |
|    n_updates            | 12080      |
|    policy_gradient_loss | 0.0152     |
|    std                  | 0.206      |
|    value_loss           | 0.00977    |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 625        |
|    iterations           | 1210       |
|    time_elapsed         | 3960       |
|    total_timesteps      | 2478080    |
| train/                  |            |
|    approx_kl            | 0.96238244 |
|    clip_fraction        | 0.423      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.358      |
|    explained_variance   | 0.77       |
|    learning_rate        | 0.00152    |
|    loss                 | -0.0146    |
|    n_updates            | 12090      |
|    policy_gradient_loss | 0.0276     |
|    std                  | 0.2        |
|    value_loss           | 0.00856    |
----------------------------------------
box reached target
box reached target
box reached target
Eval num_timesteps=2480000, episode_reward=1.45 +/- 3.00
Episode length: 245.40 +/- 67.27
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 245       |
|    mean_reward          | 1.45      |
| time/                   |           |
|    total_timesteps      | 2480000   |
| train/                  |           |
|    approx_kl            | 0.7924412 |
|    clip_fraction        | 0.534     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.355     |
|    explained_variance   | 0.882     |
|    learning_rate        | 0.00152   |
|    loss                 | 0.0352    |
|    n_updates            | 12100     |
|    policy_gradient_loss | 0.0161    |
|    std                  | 0.202     |
|    value_loss           | 0.00912   |
---------------------------------------
--------------------------------
| time/              |         |
|    fps             | 625     |
|    iterations      | 1211    |
|    time_elapsed    | 3964    |
|    total_timesteps | 2480128 |
--------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 625       |
|    iterations           | 1212      |
|    time_elapsed         | 3967      |
|    total_timesteps      | 2482176   |
| train/                  |           |
|    approx_kl            | 0.7918472 |
|    clip_fraction        | 0.521     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.363     |
|    explained_variance   | 0.781     |
|    learning_rate        | 0.00152   |
|    loss                 | 0.0092    |
|    n_updates            | 12110     |
|    policy_gradient_loss | 0.067     |
|    std                  | 0.201     |
|    value_loss           | 0.0149    |
---------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 625       |
|    iterations           | 1213      |
|    time_elapsed         | 3970      |
|    total_timesteps      | 2484224   |
| train/                  |           |
|    approx_kl            | 0.9540258 |
|    clip_fraction        | 0.461     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.4       |
|    explained_variance   | 0.624     |
|    learning_rate        | 0.00152   |
|    loss                 | 0.0259    |
|    n_updates            | 12120     |
|    policy_gradient_loss | 0.0034    |
|    std                  | 0.196     |
|    value_loss           | 0.0274    |
---------------------------------------
box reached target
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 625       |
|    iterations           | 1214      |
|    time_elapsed         | 3973      |
|    total_timesteps      | 2486272   |
| train/                  |           |
|    approx_kl            | 0.4958409 |
|    clip_fraction        | 0.492     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.431     |
|    explained_variance   | 0.664     |
|    learning_rate        | 0.00152   |
|    loss                 | 0.0182    |
|    n_updates            | 12130     |
|    policy_gradient_loss | 0.038     |
|    std                  | 0.195     |
|    value_loss           | 0.0103    |
---------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 625        |
|    iterations           | 1215       |
|    time_elapsed         | 3976       |
|    total_timesteps      | 2488320    |
| train/                  |            |
|    approx_kl            | 0.46436426 |
|    clip_fraction        | 0.478      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.396      |
|    explained_variance   | 0.843      |
|    learning_rate        | 0.00152    |
|    loss                 | -0.0126    |
|    n_updates            | 12140      |
|    policy_gradient_loss | 0.0405     |
|    std                  | 0.203      |
|    value_loss           | 0.0171     |
----------------------------------------
box reached target
Eval num_timesteps=2490000, episode_reward=0.20 +/- 2.46
Episode length: 277.00 +/- 46.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 277        |
|    mean_reward          | 0.204      |
| time/                   |            |
|    total_timesteps      | 2490000    |
| train/                  |            |
|    approx_kl            | 0.26173252 |
|    clip_fraction        | 0.466      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.321      |
|    explained_variance   | 0.851      |
|    learning_rate        | 0.00151    |
|    loss                 | 0.0393     |
|    n_updates            | 12150      |
|    policy_gradient_loss | 0.0225     |
|    std                  | 0.207      |
|    value_loss           | 0.00556    |
----------------------------------------
box reached target
--------------------------------
| time/              |         |
|    fps             | 625     |
|    iterations      | 1216    |
|    time_elapsed    | 3980    |
|    total_timesteps | 2490368 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 625        |
|    iterations           | 1217       |
|    time_elapsed         | 3983       |
|    total_timesteps      | 2492416    |
| train/                  |            |
|    approx_kl            | 0.48277688 |
|    clip_fraction        | 0.499      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.254      |
|    explained_variance   | 0.7        |
|    learning_rate        | 0.00151    |
|    loss                 | -0.0116    |
|    n_updates            | 12160      |
|    policy_gradient_loss | 0.0207     |
|    std                  | 0.216      |
|    value_loss           | 0.0284     |
----------------------------------------
box reached target
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 625       |
|    iterations           | 1218      |
|    time_elapsed         | 3986      |
|    total_timesteps      | 2494464   |
| train/                  |           |
|    approx_kl            | 0.5420927 |
|    clip_fraction        | 0.45      |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.215     |
|    explained_variance   | 0.649     |
|    learning_rate        | 0.00151   |
|    loss                 | 0.0155    |
|    n_updates            | 12170     |
|    policy_gradient_loss | -0.00181  |
|    std                  | 0.214     |
|    value_loss           | 0.00823   |
---------------------------------------
box reached target
box reached target
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 625       |
|    iterations           | 1219      |
|    time_elapsed         | 3989      |
|    total_timesteps      | 2496512   |
| train/                  |           |
|    approx_kl            | 0.3746399 |
|    clip_fraction        | 0.447     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.241     |
|    explained_variance   | 0.502     |
|    learning_rate        | 0.00151   |
|    loss                 | 0.0567    |
|    n_updates            | 12180     |
|    policy_gradient_loss | 0.0104    |
|    std                  | 0.216     |
|    value_loss           | 0.0206    |
---------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 625       |
|    iterations           | 1220      |
|    time_elapsed         | 3992      |
|    total_timesteps      | 2498560   |
| train/                  |           |
|    approx_kl            | 0.7020335 |
|    clip_fraction        | 0.478     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.245     |
|    explained_variance   | 0.9       |
|    learning_rate        | 0.00151   |
|    loss                 | 0.00275   |
|    n_updates            | 12190     |
|    policy_gradient_loss | 0.0212    |
|    std                  | 0.212     |
|    value_loss           | 0.0165    |
---------------------------------------
box reached target
box reached target
box reached target
Eval num_timesteps=2500000, episode_reward=1.73 +/- 2.76
Episode length: 262.80 +/- 45.56
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 263        |
|    mean_reward          | 1.73       |
| time/                   |            |
|    total_timesteps      | 2500000    |
| train/                  |            |
|    approx_kl            | 0.28418714 |
|    clip_fraction        | 0.455      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.22       |
|    explained_variance   | 0.916      |
|    learning_rate        | 0.00151    |
|    loss                 | -0.0444    |
|    n_updates            | 12200      |
|    policy_gradient_loss | 0.00543    |
|    std                  | 0.218      |
|    value_loss           | 0.00756    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 625     |
|    iterations      | 1221    |
|    time_elapsed    | 3996    |
|    total_timesteps | 2500608 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 625        |
|    iterations           | 1222       |
|    time_elapsed         | 3999       |
|    total_timesteps      | 2502656    |
| train/                  |            |
|    approx_kl            | 0.72550464 |
|    clip_fraction        | 0.389      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.22       |
|    explained_variance   | 0.896      |
|    learning_rate        | 0.00151    |
|    loss                 | 0.0147     |
|    n_updates            | 12210      |
|    policy_gradient_loss | 0.00212    |
|    std                  | 0.213      |
|    value_loss           | 0.00521    |
----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 625       |
|    iterations           | 1223      |
|    time_elapsed         | 4002      |
|    total_timesteps      | 2504704   |
| train/                  |           |
|    approx_kl            | 0.3812024 |
|    clip_fraction        | 0.45      |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.222     |
|    explained_variance   | 0.74      |
|    learning_rate        | 0.00151   |
|    loss                 | -0.0422   |
|    n_updates            | 12220     |
|    policy_gradient_loss | 0.0208    |
|    std                  | 0.215     |
|    value_loss           | 0.00317   |
---------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 625       |
|    iterations           | 1224      |
|    time_elapsed         | 4005      |
|    total_timesteps      | 2506752   |
| train/                  |           |
|    approx_kl            | 1.0982971 |
|    clip_fraction        | 0.511     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.253     |
|    explained_variance   | 0.803     |
|    learning_rate        | 0.00151   |
|    loss                 | -0.0222   |
|    n_updates            | 12230     |
|    policy_gradient_loss | 0.000277  |
|    std                  | 0.209     |
|    value_loss           | 0.0209    |
---------------------------------------
box reached target
box reached target
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 625        |
|    iterations           | 1225       |
|    time_elapsed         | 4008       |
|    total_timesteps      | 2508800    |
| train/                  |            |
|    approx_kl            | 0.45779175 |
|    clip_fraction        | 0.501      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.239      |
|    explained_variance   | 0.799      |
|    learning_rate        | 0.00151    |
|    loss                 | -0.0177    |
|    n_updates            | 12240      |
|    policy_gradient_loss | 0.019      |
|    std                  | 0.217      |
|    value_loss           | 0.0455     |
----------------------------------------
Eval num_timesteps=2510000, episode_reward=-1.02 +/- 0.11
Episode length: 300.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 300       |
|    mean_reward          | -1.02     |
| time/                   |           |
|    total_timesteps      | 2510000   |
| train/                  |           |
|    approx_kl            | 0.4023465 |
|    clip_fraction        | 0.508     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.183     |
|    explained_variance   | 0.765     |
|    learning_rate        | 0.00151   |
|    loss                 | -0.0219   |
|    n_updates            | 12250     |
|    policy_gradient_loss | 0.0337    |
|    std                  | 0.221     |
|    value_loss           | 0.0467    |
---------------------------------------
--------------------------------
| time/              |         |
|    fps             | 625     |
|    iterations      | 1226    |
|    time_elapsed    | 4012    |
|    total_timesteps | 2510848 |
--------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 625        |
|    iterations           | 1227       |
|    time_elapsed         | 4015       |
|    total_timesteps      | 2512896    |
| train/                  |            |
|    approx_kl            | 0.48699662 |
|    clip_fraction        | 0.441      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.188      |
|    explained_variance   | 0.51       |
|    learning_rate        | 0.00151    |
|    loss                 | -0.0138    |
|    n_updates            | 12260      |
|    policy_gradient_loss | 0.00744    |
|    std                  | 0.218      |
|    value_loss           | 0.0057     |
----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 625       |
|    iterations           | 1228      |
|    time_elapsed         | 4018      |
|    total_timesteps      | 2514944   |
| train/                  |           |
|    approx_kl            | 0.5053679 |
|    clip_fraction        | 0.474     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.221     |
|    explained_variance   | 0.527     |
|    learning_rate        | 0.00151   |
|    loss                 | -0.00826  |
|    n_updates            | 12270     |
|    policy_gradient_loss | 0.0337    |
|    std                  | 0.216     |
|    value_loss           | 0.0214    |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 625        |
|    iterations           | 1229       |
|    time_elapsed         | 4021       |
|    total_timesteps      | 2516992    |
| train/                  |            |
|    approx_kl            | 0.34384272 |
|    clip_fraction        | 0.46       |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.231      |
|    explained_variance   | 0.697      |
|    learning_rate        | 0.00151    |
|    loss                 | 0.0343     |
|    n_updates            | 12280      |
|    policy_gradient_loss | 0.0107     |
|    std                  | 0.216      |
|    value_loss           | 0.00913    |
----------------------------------------
box reached target
--------------------------------------
| time/                   |          |
|    fps                  | 625      |
|    iterations           | 1230     |
|    time_elapsed         | 4024     |
|    total_timesteps      | 2519040  |
| train/                  |          |
|    approx_kl            | 0.270996 |
|    clip_fraction        | 0.437    |
|    clip_range           | 0.2      |
|    entropy_loss         | 0.25     |
|    explained_variance   | -0.129   |
|    learning_rate        | 0.00151  |
|    loss                 | -0.0233  |
|    n_updates            | 12290    |
|    policy_gradient_loss | 0.0129   |
|    std                  | 0.216    |
|    value_loss           | 0.00508  |
--------------------------------------
Eval num_timesteps=2520000, episode_reward=-0.97 +/- 0.05
Episode length: 300.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 300       |
|    mean_reward          | -0.973    |
| time/                   |           |
|    total_timesteps      | 2520000   |
| train/                  |           |
|    approx_kl            | 0.2556638 |
|    clip_fraction        | 0.444     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.182     |
|    explained_variance   | 0.36      |
|    learning_rate        | 0.00151   |
|    loss                 | -0.018    |
|    n_updates            | 12300     |
|    policy_gradient_loss | 0.0406    |
|    std                  | 0.221     |
|    value_loss           | 0.0197    |
---------------------------------------
--------------------------------
| time/              |         |
|    fps             | 625     |
|    iterations      | 1231    |
|    time_elapsed    | 4028    |
|    total_timesteps | 2521088 |
--------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 625        |
|    iterations           | 1232       |
|    time_elapsed         | 4031       |
|    total_timesteps      | 2523136    |
| train/                  |            |
|    approx_kl            | 0.18164667 |
|    clip_fraction        | 0.402      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.13       |
|    explained_variance   | -0.0705    |
|    learning_rate        | 0.00151    |
|    loss                 | -0.0157    |
|    n_updates            | 12310      |
|    policy_gradient_loss | 0.0253     |
|    std                  | 0.23       |
|    value_loss           | 0.00453    |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 625        |
|    iterations           | 1233       |
|    time_elapsed         | 4034       |
|    total_timesteps      | 2525184    |
| train/                  |            |
|    approx_kl            | 0.61156243 |
|    clip_fraction        | 0.436      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.0747     |
|    explained_variance   | 0.549      |
|    learning_rate        | 0.00151    |
|    loss                 | -0.0561    |
|    n_updates            | 12320      |
|    policy_gradient_loss | 0.00638    |
|    std                  | 0.233      |
|    value_loss           | 0.0347     |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 625        |
|    iterations           | 1234       |
|    time_elapsed         | 4037       |
|    total_timesteps      | 2527232    |
| train/                  |            |
|    approx_kl            | 0.24544755 |
|    clip_fraction        | 0.451      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.0256     |
|    explained_variance   | 0.897      |
|    learning_rate        | 0.00151    |
|    loss                 | 0.00411    |
|    n_updates            | 12330      |
|    policy_gradient_loss | 0.0284     |
|    std                  | 0.242      |
|    value_loss           | 0.00858    |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 625        |
|    iterations           | 1235       |
|    time_elapsed         | 4040       |
|    total_timesteps      | 2529280    |
| train/                  |            |
|    approx_kl            | 0.26939243 |
|    clip_fraction        | 0.459      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.0214     |
|    explained_variance   | 0.268      |
|    learning_rate        | 0.00151    |
|    loss                 | -0.0409    |
|    n_updates            | 12340      |
|    policy_gradient_loss | 0.00122    |
|    std                  | 0.236      |
|    value_loss           | 0.00596    |
----------------------------------------
box reached target
Eval num_timesteps=2530000, episode_reward=0.29 +/- 2.57
Episode length: 277.20 +/- 45.60
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 277        |
|    mean_reward          | 0.285      |
| time/                   |            |
|    total_timesteps      | 2530000    |
| train/                  |            |
|    approx_kl            | 0.23746938 |
|    clip_fraction        | 0.459      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.0391     |
|    explained_variance   | 0.112      |
|    learning_rate        | 0.00151    |
|    loss                 | -0.0207    |
|    n_updates            | 12350      |
|    policy_gradient_loss | 0.0127     |
|    std                  | 0.238      |
|    value_loss           | 0.0265     |
----------------------------------------
box reached target
--------------------------------
| time/              |         |
|    fps             | 625     |
|    iterations      | 1236    |
|    time_elapsed    | 4044    |
|    total_timesteps | 2531328 |
--------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 625       |
|    iterations           | 1237      |
|    time_elapsed         | 4047      |
|    total_timesteps      | 2533376   |
| train/                  |           |
|    approx_kl            | 0.2332477 |
|    clip_fraction        | 0.418     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.027     |
|    explained_variance   | 0.672     |
|    learning_rate        | 0.00151   |
|    loss                 | -0.0266   |
|    n_updates            | 12360     |
|    policy_gradient_loss | 0.00378   |
|    std                  | 0.239     |
|    value_loss           | 0.0366    |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 625        |
|    iterations           | 1238       |
|    time_elapsed         | 4050       |
|    total_timesteps      | 2535424    |
| train/                  |            |
|    approx_kl            | 0.32282138 |
|    clip_fraction        | 0.338      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.0292     |
|    explained_variance   | 0.372      |
|    learning_rate        | 0.00151    |
|    loss                 | -0.000661  |
|    n_updates            | 12370      |
|    policy_gradient_loss | 0.00263    |
|    std                  | 0.24       |
|    value_loss           | 0.00448    |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 625        |
|    iterations           | 1239       |
|    time_elapsed         | 4053       |
|    total_timesteps      | 2537472    |
| train/                  |            |
|    approx_kl            | 0.18914519 |
|    clip_fraction        | 0.413      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.0148     |
|    explained_variance   | 0.73       |
|    learning_rate        | 0.00151    |
|    loss                 | 0.0151     |
|    n_updates            | 12380      |
|    policy_gradient_loss | 0.0109     |
|    std                  | 0.242      |
|    value_loss           | 0.00257    |
----------------------------------------
box reached target
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 626       |
|    iterations           | 1240      |
|    time_elapsed         | 4056      |
|    total_timesteps      | 2539520   |
| train/                  |           |
|    approx_kl            | 0.6331357 |
|    clip_fraction        | 0.443     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00684  |
|    explained_variance   | 0.927     |
|    learning_rate        | 0.00151   |
|    loss                 | -0.00174  |
|    n_updates            | 12390     |
|    policy_gradient_loss | 0.0163    |
|    std                  | 0.241     |
|    value_loss           | 0.0155    |
---------------------------------------
box reached target
Eval num_timesteps=2540000, episode_reward=0.72 +/- 2.38
Episode length: 269.80 +/- 60.40
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 270        |
|    mean_reward          | 0.719      |
| time/                   |            |
|    total_timesteps      | 2540000    |
| train/                  |            |
|    approx_kl            | 0.41077575 |
|    clip_fraction        | 0.444      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.0414     |
|    explained_variance   | 0.617      |
|    learning_rate        | 0.0015     |
|    loss                 | -0.0411    |
|    n_updates            | 12400      |
|    policy_gradient_loss | 0.00833    |
|    std                  | 0.234      |
|    value_loss           | 0.0212     |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 625     |
|    iterations      | 1241    |
|    time_elapsed    | 4060    |
|    total_timesteps | 2541568 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 625        |
|    iterations           | 1242       |
|    time_elapsed         | 4063       |
|    total_timesteps      | 2543616    |
| train/                  |            |
|    approx_kl            | 0.23349819 |
|    clip_fraction        | 0.431      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.0734     |
|    explained_variance   | 0.684      |
|    learning_rate        | 0.0015     |
|    loss                 | 0.00633    |
|    n_updates            | 12410      |
|    policy_gradient_loss | 0.0162     |
|    std                  | 0.231      |
|    value_loss           | 0.0159     |
----------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 626       |
|    iterations           | 1243      |
|    time_elapsed         | 4066      |
|    total_timesteps      | 2545664   |
| train/                  |           |
|    approx_kl            | 0.2522229 |
|    clip_fraction        | 0.41      |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.112     |
|    explained_variance   | 0.572     |
|    learning_rate        | 0.0015    |
|    loss                 | 0.0188    |
|    n_updates            | 12420     |
|    policy_gradient_loss | 0.00593   |
|    std                  | 0.228     |
|    value_loss           | 0.00479   |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 626        |
|    iterations           | 1244       |
|    time_elapsed         | 4069       |
|    total_timesteps      | 2547712    |
| train/                  |            |
|    approx_kl            | 0.33111572 |
|    clip_fraction        | 0.428      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.122      |
|    explained_variance   | 0.603      |
|    learning_rate        | 0.0015     |
|    loss                 | 0.0104     |
|    n_updates            | 12430      |
|    policy_gradient_loss | 0.00905    |
|    std                  | 0.227      |
|    value_loss           | 0.029      |
----------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 626       |
|    iterations           | 1245      |
|    time_elapsed         | 4072      |
|    total_timesteps      | 2549760   |
| train/                  |           |
|    approx_kl            | 0.5269568 |
|    clip_fraction        | 0.471     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.0841    |
|    explained_variance   | 0.692     |
|    learning_rate        | 0.0015    |
|    loss                 | -0.0125   |
|    n_updates            | 12440     |
|    policy_gradient_loss | 0.0129    |
|    std                  | 0.234     |
|    value_loss           | 0.00529   |
---------------------------------------
box reached target
Eval num_timesteps=2550000, episode_reward=0.52 +/- 2.39
Episode length: 274.00 +/- 52.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 274        |
|    mean_reward          | 0.525      |
| time/                   |            |
|    total_timesteps      | 2550000    |
| train/                  |            |
|    approx_kl            | 0.20098457 |
|    clip_fraction        | 0.419      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.0723     |
|    explained_variance   | 0.437      |
|    learning_rate        | 0.0015     |
|    loss                 | 0.027      |
|    n_updates            | 12450      |
|    policy_gradient_loss | 0.0163     |
|    std                  | 0.232      |
|    value_loss           | 0.0124     |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 625     |
|    iterations      | 1246    |
|    time_elapsed    | 4076    |
|    total_timesteps | 2551808 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 626        |
|    iterations           | 1247       |
|    time_elapsed         | 4079       |
|    total_timesteps      | 2553856    |
| train/                  |            |
|    approx_kl            | 0.35268748 |
|    clip_fraction        | 0.415      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.0353     |
|    explained_variance   | 0.502      |
|    learning_rate        | 0.0015     |
|    loss                 | -0.00688   |
|    n_updates            | 12460      |
|    policy_gradient_loss | 0.0139     |
|    std                  | 0.238      |
|    value_loss           | 0.00451    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 626        |
|    iterations           | 1248       |
|    time_elapsed         | 4082       |
|    total_timesteps      | 2555904    |
| train/                  |            |
|    approx_kl            | 0.54545885 |
|    clip_fraction        | 0.442      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.0437     |
|    explained_variance   | 0.225      |
|    learning_rate        | 0.0015     |
|    loss                 | -0.000554  |
|    n_updates            | 12470      |
|    policy_gradient_loss | 0.00186    |
|    std                  | 0.235      |
|    value_loss           | 0.0109     |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 626        |
|    iterations           | 1249       |
|    time_elapsed         | 4085       |
|    total_timesteps      | 2557952    |
| train/                  |            |
|    approx_kl            | 0.29246634 |
|    clip_fraction        | 0.461      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.0601     |
|    explained_variance   | 0.628      |
|    learning_rate        | 0.0015     |
|    loss                 | 0.0865     |
|    n_updates            | 12480      |
|    policy_gradient_loss | 0.0332     |
|    std                  | 0.237      |
|    value_loss           | 0.00479    |
----------------------------------------
Eval num_timesteps=2560000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1         |
| time/                   |            |
|    total_timesteps      | 2560000    |
| train/                  |            |
|    approx_kl            | 0.21656747 |
|    clip_fraction        | 0.489      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.0725     |
|    explained_variance   | 0.831      |
|    learning_rate        | 0.0015     |
|    loss                 | 0.0254     |
|    n_updates            | 12490      |
|    policy_gradient_loss | 0.0138     |
|    std                  | 0.232      |
|    value_loss           | 0.00946    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 625     |
|    iterations      | 1250    |
|    time_elapsed    | 4089    |
|    total_timesteps | 2560000 |
--------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 626        |
|    iterations           | 1251       |
|    time_elapsed         | 4092       |
|    total_timesteps      | 2562048    |
| train/                  |            |
|    approx_kl            | 0.41841704 |
|    clip_fraction        | 0.42       |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.0842     |
|    explained_variance   | 0.631      |
|    learning_rate        | 0.0015     |
|    loss                 | -0.0335    |
|    n_updates            | 12500      |
|    policy_gradient_loss | 0.00799    |
|    std                  | 0.23       |
|    value_loss           | 0.00266    |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 626        |
|    iterations           | 1252       |
|    time_elapsed         | 4095       |
|    total_timesteps      | 2564096    |
| train/                  |            |
|    approx_kl            | 0.23240052 |
|    clip_fraction        | 0.464      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.151      |
|    explained_variance   | 0.592      |
|    learning_rate        | 0.0015     |
|    loss                 | 0.0681     |
|    n_updates            | 12510      |
|    policy_gradient_loss | 0.0177     |
|    std                  | 0.224      |
|    value_loss           | 0.0391     |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 626        |
|    iterations           | 1253       |
|    time_elapsed         | 4098       |
|    total_timesteps      | 2566144    |
| train/                  |            |
|    approx_kl            | 0.34648424 |
|    clip_fraction        | 0.43       |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.211      |
|    explained_variance   | 0.802      |
|    learning_rate        | 0.0015     |
|    loss                 | -0.0111    |
|    n_updates            | 12520      |
|    policy_gradient_loss | 0.0106     |
|    std                  | 0.216      |
|    value_loss           | 0.011      |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 626        |
|    iterations           | 1254       |
|    time_elapsed         | 4101       |
|    total_timesteps      | 2568192    |
| train/                  |            |
|    approx_kl            | 0.34829476 |
|    clip_fraction        | 0.491      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.261      |
|    explained_variance   | 0.633      |
|    learning_rate        | 0.0015     |
|    loss                 | -0.0242    |
|    n_updates            | 12530      |
|    policy_gradient_loss | 0.0319     |
|    std                  | 0.213      |
|    value_loss           | 0.00891    |
----------------------------------------
Eval num_timesteps=2570000, episode_reward=-0.41 +/- 0.73
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -0.413     |
| time/                   |            |
|    total_timesteps      | 2570000    |
| train/                  |            |
|    approx_kl            | 0.31089768 |
|    clip_fraction        | 0.463      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.298      |
|    explained_variance   | 0.907      |
|    learning_rate        | 0.0015     |
|    loss                 | 0.0189     |
|    n_updates            | 12540      |
|    policy_gradient_loss | 0.0102     |
|    std                  | 0.21       |
|    value_loss           | 0.00773    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 626     |
|    iterations      | 1255    |
|    time_elapsed    | 4105    |
|    total_timesteps | 2570240 |
--------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 626       |
|    iterations           | 1256      |
|    time_elapsed         | 4108      |
|    total_timesteps      | 2572288   |
| train/                  |           |
|    approx_kl            | 0.6201383 |
|    clip_fraction        | 0.5       |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.269     |
|    explained_variance   | 0.585     |
|    learning_rate        | 0.0015    |
|    loss                 | -0.00296  |
|    n_updates            | 12550     |
|    policy_gradient_loss | 0.0237    |
|    std                  | 0.213     |
|    value_loss           | 0.00262   |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 626        |
|    iterations           | 1257       |
|    time_elapsed         | 4111       |
|    total_timesteps      | 2574336    |
| train/                  |            |
|    approx_kl            | 0.18719684 |
|    clip_fraction        | 0.479      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.18       |
|    explained_variance   | 0.845      |
|    learning_rate        | 0.0015     |
|    loss                 | 0.0169     |
|    n_updates            | 12560      |
|    policy_gradient_loss | 0.0234     |
|    std                  | 0.227      |
|    value_loss           | 0.0161     |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 626        |
|    iterations           | 1258       |
|    time_elapsed         | 4114       |
|    total_timesteps      | 2576384    |
| train/                  |            |
|    approx_kl            | 0.25386927 |
|    clip_fraction        | 0.412      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.159      |
|    explained_variance   | 0.811      |
|    learning_rate        | 0.0015     |
|    loss                 | 0.0227     |
|    n_updates            | 12570      |
|    policy_gradient_loss | 0.0167     |
|    std                  | 0.223      |
|    value_loss           | 0.00575    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 626        |
|    iterations           | 1259       |
|    time_elapsed         | 4117       |
|    total_timesteps      | 2578432    |
| train/                  |            |
|    approx_kl            | 0.12846924 |
|    clip_fraction        | 0.389      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.16       |
|    explained_variance   | 0.869      |
|    learning_rate        | 0.0015     |
|    loss                 | -0.0137    |
|    n_updates            | 12580      |
|    policy_gradient_loss | 0.0153     |
|    std                  | 0.226      |
|    value_loss           | 0.0224     |
----------------------------------------
box reached target
Eval num_timesteps=2580000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1         |
| time/                   |            |
|    total_timesteps      | 2580000    |
| train/                  |            |
|    approx_kl            | 0.23735517 |
|    clip_fraction        | 0.428      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.112      |
|    explained_variance   | 0.786      |
|    learning_rate        | 0.0015     |
|    loss                 | -0.0404    |
|    n_updates            | 12590      |
|    policy_gradient_loss | 0.0122     |
|    std                  | 0.232      |
|    value_loss           | 0.0119     |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 626     |
|    iterations      | 1260    |
|    time_elapsed    | 4121    |
|    total_timesteps | 2580480 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 626        |
|    iterations           | 1261       |
|    time_elapsed         | 4124       |
|    total_timesteps      | 2582528    |
| train/                  |            |
|    approx_kl            | 0.26906523 |
|    clip_fraction        | 0.464      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.0584     |
|    explained_variance   | 0.936      |
|    learning_rate        | 0.0015     |
|    loss                 | -0.0391    |
|    n_updates            | 12600      |
|    policy_gradient_loss | 0.00774    |
|    std                  | 0.237      |
|    value_loss           | 0.00637    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 626        |
|    iterations           | 1262       |
|    time_elapsed         | 4127       |
|    total_timesteps      | 2584576    |
| train/                  |            |
|    approx_kl            | 0.41764545 |
|    clip_fraction        | 0.473      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.0818     |
|    explained_variance   | 0.17       |
|    learning_rate        | 0.0015     |
|    loss                 | 0.0607     |
|    n_updates            | 12610      |
|    policy_gradient_loss | 0.0173     |
|    std                  | 0.233      |
|    value_loss           | 0.00151    |
----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 626       |
|    iterations           | 1263      |
|    time_elapsed         | 4130      |
|    total_timesteps      | 2586624   |
| train/                  |           |
|    approx_kl            | 1.1066705 |
|    clip_fraction        | 0.497     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.136     |
|    explained_variance   | 0.542     |
|    learning_rate        | 0.0015    |
|    loss                 | -0.0342   |
|    n_updates            | 12620     |
|    policy_gradient_loss | 0.00256   |
|    std                  | 0.222     |
|    value_loss           | 0.00302   |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 626        |
|    iterations           | 1264       |
|    time_elapsed         | 4133       |
|    total_timesteps      | 2588672    |
| train/                  |            |
|    approx_kl            | 0.09920366 |
|    clip_fraction        | 0.379      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.146      |
|    explained_variance   | 0.877      |
|    learning_rate        | 0.0015     |
|    loss                 | 0.0347     |
|    n_updates            | 12630      |
|    policy_gradient_loss | 0.0173     |
|    std                  | 0.232      |
|    value_loss           | 0.00722    |
----------------------------------------
Eval num_timesteps=2590000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 300       |
|    mean_reward          | -1        |
| time/                   |           |
|    total_timesteps      | 2590000   |
| train/                  |           |
|    approx_kl            | 0.7273616 |
|    clip_fraction        | 0.456     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.0999    |
|    explained_variance   | 0.874     |
|    learning_rate        | 0.0015    |
|    loss                 | -0.0173   |
|    n_updates            | 12640     |
|    policy_gradient_loss | 0.0131    |
|    std                  | 0.227     |
|    value_loss           | 0.00294   |
---------------------------------------
--------------------------------
| time/              |         |
|    fps             | 626     |
|    iterations      | 1265    |
|    time_elapsed    | 4137    |
|    total_timesteps | 2590720 |
--------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 626        |
|    iterations           | 1266       |
|    time_elapsed         | 4140       |
|    total_timesteps      | 2592768    |
| train/                  |            |
|    approx_kl            | 0.44558558 |
|    clip_fraction        | 0.452      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.116      |
|    explained_variance   | 0.807      |
|    learning_rate        | 0.00149    |
|    loss                 | -0.0433    |
|    n_updates            | 12650      |
|    policy_gradient_loss | 0.0239     |
|    std                  | 0.23       |
|    value_loss           | 0.0045     |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 626        |
|    iterations           | 1267       |
|    time_elapsed         | 4143       |
|    total_timesteps      | 2594816    |
| train/                  |            |
|    approx_kl            | 0.17130253 |
|    clip_fraction        | 0.431      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.11       |
|    explained_variance   | 0.909      |
|    learning_rate        | 0.00149    |
|    loss                 | -0.00448   |
|    n_updates            | 12660      |
|    policy_gradient_loss | 0.0162     |
|    std                  | 0.231      |
|    value_loss           | 0.0115     |
----------------------------------------
--------------------------------------
| time/                   |          |
|    fps                  | 626      |
|    iterations           | 1268     |
|    time_elapsed         | 4146     |
|    total_timesteps      | 2596864  |
| train/                  |          |
|    approx_kl            | 0.156739 |
|    clip_fraction        | 0.403    |
|    clip_range           | 0.2      |
|    entropy_loss         | 0.0313   |
|    explained_variance   | 0.837    |
|    learning_rate        | 0.00149  |
|    loss                 | -0.0214  |
|    n_updates            | 12670    |
|    policy_gradient_loss | 0.0112   |
|    std                  | 0.245    |
|    value_loss           | 0.0073   |
--------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 626        |
|    iterations           | 1269       |
|    time_elapsed         | 4149       |
|    total_timesteps      | 2598912    |
| train/                  |            |
|    approx_kl            | 0.14278308 |
|    clip_fraction        | 0.412      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.00324   |
|    explained_variance   | 0.739      |
|    learning_rate        | 0.00149    |
|    loss                 | 0.0501     |
|    n_updates            | 12680      |
|    policy_gradient_loss | 0.015      |
|    std                  | 0.246      |
|    value_loss           | 0.00257    |
----------------------------------------
box reached target
Eval num_timesteps=2600000, episode_reward=0.21 +/- 2.47
Episode length: 270.60 +/- 58.80
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 271        |
|    mean_reward          | 0.208      |
| time/                   |            |
|    total_timesteps      | 2600000    |
| train/                  |            |
|    approx_kl            | 0.33010265 |
|    clip_fraction        | 0.434      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.0517    |
|    explained_variance   | 0.796      |
|    learning_rate        | 0.00149    |
|    loss                 | 0.0616     |
|    n_updates            | 12690      |
|    policy_gradient_loss | 0.0222     |
|    std                  | 0.252      |
|    value_loss           | 0.0105     |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 626     |
|    iterations      | 1270    |
|    time_elapsed    | 4153    |
|    total_timesteps | 2600960 |
--------------------------------
box reached target
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 626       |
|    iterations           | 1271      |
|    time_elapsed         | 4156      |
|    total_timesteps      | 2603008   |
| train/                  |           |
|    approx_kl            | 0.3008759 |
|    clip_fraction        | 0.437     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0935   |
|    explained_variance   | 0.787     |
|    learning_rate        | 0.00149   |
|    loss                 | -0.00722  |
|    n_updates            | 12700     |
|    policy_gradient_loss | 0.0145    |
|    std                  | 0.256     |
|    value_loss           | 0.00128   |
---------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 626       |
|    iterations           | 1272      |
|    time_elapsed         | 4159      |
|    total_timesteps      | 2605056   |
| train/                  |           |
|    approx_kl            | 0.2903617 |
|    clip_fraction        | 0.422     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0631   |
|    explained_variance   | 0.479     |
|    learning_rate        | 0.00149   |
|    loss                 | -0.0296   |
|    n_updates            | 12710     |
|    policy_gradient_loss | 0.0128    |
|    std                  | 0.251     |
|    value_loss           | 0.0109    |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 626        |
|    iterations           | 1273       |
|    time_elapsed         | 4162       |
|    total_timesteps      | 2607104    |
| train/                  |            |
|    approx_kl            | 0.17114207 |
|    clip_fraction        | 0.401      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.0167    |
|    explained_variance   | 0.801      |
|    learning_rate        | 0.00149    |
|    loss                 | 0.164      |
|    n_updates            | 12720      |
|    policy_gradient_loss | 0.0102     |
|    std                  | 0.25       |
|    value_loss           | 0.00675    |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 626        |
|    iterations           | 1274       |
|    time_elapsed         | 4165       |
|    total_timesteps      | 2609152    |
| train/                  |            |
|    approx_kl            | 0.24843907 |
|    clip_fraction        | 0.44       |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.0725    |
|    explained_variance   | 0.911      |
|    learning_rate        | 0.00149    |
|    loss                 | 0.0378     |
|    n_updates            | 12730      |
|    policy_gradient_loss | 0.0298     |
|    std                  | 0.256      |
|    value_loss           | 0.0048     |
----------------------------------------
Eval num_timesteps=2610000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 300       |
|    mean_reward          | -1        |
| time/                   |           |
|    total_timesteps      | 2610000   |
| train/                  |           |
|    approx_kl            | 0.3166787 |
|    clip_fraction        | 0.459     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0693   |
|    explained_variance   | 0.669     |
|    learning_rate        | 0.00149   |
|    loss                 | -0.0312   |
|    n_updates            | 12740     |
|    policy_gradient_loss | 0.0114    |
|    std                  | 0.255     |
|    value_loss           | 0.00987   |
---------------------------------------
--------------------------------
| time/              |         |
|    fps             | 626     |
|    iterations      | 1275    |
|    time_elapsed    | 4169    |
|    total_timesteps | 2611200 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 626        |
|    iterations           | 1276       |
|    time_elapsed         | 4172       |
|    total_timesteps      | 2613248    |
| train/                  |            |
|    approx_kl            | 0.20833907 |
|    clip_fraction        | 0.392      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.0748    |
|    explained_variance   | -0.0904    |
|    learning_rate        | 0.00149    |
|    loss                 | -0.022     |
|    n_updates            | 12750      |
|    policy_gradient_loss | 0.00405    |
|    std                  | 0.252      |
|    value_loss           | 0.00406    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 626        |
|    iterations           | 1277       |
|    time_elapsed         | 4175       |
|    total_timesteps      | 2615296    |
| train/                  |            |
|    approx_kl            | 0.12078084 |
|    clip_fraction        | 0.357      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.0933    |
|    explained_variance   | 0.783      |
|    learning_rate        | 0.00149    |
|    loss                 | -0.0229    |
|    n_updates            | 12760      |
|    policy_gradient_loss | 0.000273   |
|    std                  | 0.256      |
|    value_loss           | 0.00855    |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 626        |
|    iterations           | 1278       |
|    time_elapsed         | 4179       |
|    total_timesteps      | 2617344    |
| train/                  |            |
|    approx_kl            | 0.16825584 |
|    clip_fraction        | 0.384      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.145     |
|    explained_variance   | 0.803      |
|    learning_rate        | 0.00149    |
|    loss                 | -0.024     |
|    n_updates            | 12770      |
|    policy_gradient_loss | -0.00179   |
|    std                  | 0.266      |
|    value_loss           | 0.00582    |
----------------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 626        |
|    iterations           | 1279       |
|    time_elapsed         | 4182       |
|    total_timesteps      | 2619392    |
| train/                  |            |
|    approx_kl            | 0.21159859 |
|    clip_fraction        | 0.48       |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.174     |
|    explained_variance   | 0.763      |
|    learning_rate        | 0.00149    |
|    loss                 | 0.122      |
|    n_updates            | 12780      |
|    policy_gradient_loss | 0.0121     |
|    std                  | 0.265      |
|    value_loss           | 0.00723    |
----------------------------------------
box reached target
box reached target
Eval num_timesteps=2620000, episode_reward=0.21 +/- 2.42
Episode length: 275.00 +/- 50.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 275        |
|    mean_reward          | 0.209      |
| time/                   |            |
|    total_timesteps      | 2620000    |
| train/                  |            |
|    approx_kl            | 0.38996089 |
|    clip_fraction        | 0.496      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.085     |
|    explained_variance   | 0.696      |
|    learning_rate        | 0.00149    |
|    loss                 | -0.079     |
|    n_updates            | 12790      |
|    policy_gradient_loss | 0.00406    |
|    std                  | 0.25       |
|    value_loss           | 0.0136     |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 626     |
|    iterations      | 1280    |
|    time_elapsed    | 4185    |
|    total_timesteps | 2621440 |
--------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 626       |
|    iterations           | 1281      |
|    time_elapsed         | 4188      |
|    total_timesteps      | 2623488   |
| train/                  |           |
|    approx_kl            | 0.2773996 |
|    clip_fraction        | 0.421     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0497   |
|    explained_variance   | 0.679     |
|    learning_rate        | 0.00149   |
|    loss                 | 0.0466    |
|    n_updates            | 12800     |
|    policy_gradient_loss | 0.00298   |
|    std                  | 0.251     |
|    value_loss           | 0.0105    |
---------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 626        |
|    iterations           | 1282       |
|    time_elapsed         | 4192       |
|    total_timesteps      | 2625536    |
| train/                  |            |
|    approx_kl            | 0.07313909 |
|    clip_fraction        | 0.355      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.0573    |
|    explained_variance   | 0.827      |
|    learning_rate        | 0.00149    |
|    loss                 | 0.00295    |
|    n_updates            | 12810      |
|    policy_gradient_loss | 0.0205     |
|    std                  | 0.252      |
|    value_loss           | 0.0131     |
----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 626       |
|    iterations           | 1283      |
|    time_elapsed         | 4195      |
|    total_timesteps      | 2627584   |
| train/                  |           |
|    approx_kl            | 0.1308904 |
|    clip_fraction        | 0.405     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0762   |
|    explained_variance   | 0.896     |
|    learning_rate        | 0.00149   |
|    loss                 | 0.0249    |
|    n_updates            | 12820     |
|    policy_gradient_loss | 0.0176    |
|    std                  | 0.254     |
|    value_loss           | 0.00848   |
---------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 626       |
|    iterations           | 1284      |
|    time_elapsed         | 4198      |
|    total_timesteps      | 2629632   |
| train/                  |           |
|    approx_kl            | 0.3869414 |
|    clip_fraction        | 0.478     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.065    |
|    explained_variance   | 0.545     |
|    learning_rate        | 0.00149   |
|    loss                 | 0.0531    |
|    n_updates            | 12830     |
|    policy_gradient_loss | 0.0172    |
|    std                  | 0.246     |
|    value_loss           | 0.00303   |
---------------------------------------
Eval num_timesteps=2630000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1         |
| time/                   |            |
|    total_timesteps      | 2630000    |
| train/                  |            |
|    approx_kl            | 0.07966111 |
|    clip_fraction        | 0.373      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.0631    |
|    explained_variance   | 0.854      |
|    learning_rate        | 0.00149    |
|    loss                 | 0.0633     |
|    n_updates            | 12840      |
|    policy_gradient_loss | 0.0146     |
|    std                  | 0.253      |
|    value_loss           | 0.00643    |
----------------------------------------
box reached target
--------------------------------
| time/              |         |
|    fps             | 626     |
|    iterations      | 1285    |
|    time_elapsed    | 4202    |
|    total_timesteps | 2631680 |
--------------------------------
--------------------------------------
| time/                   |          |
|    fps                  | 626      |
|    iterations           | 1286     |
|    time_elapsed         | 4205     |
|    total_timesteps      | 2633728  |
| train/                  |          |
|    approx_kl            | 0.085977 |
|    clip_fraction        | 0.461    |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.169   |
|    explained_variance   | 0.947    |
|    learning_rate        | 0.00149  |
|    loss                 | -0.0108  |
|    n_updates            | 12850    |
|    policy_gradient_loss | 0.0172   |
|    std                  | 0.266    |
|    value_loss           | 0.00549  |
--------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 626        |
|    iterations           | 1287       |
|    time_elapsed         | 4208       |
|    total_timesteps      | 2635776    |
| train/                  |            |
|    approx_kl            | 0.09488079 |
|    clip_fraction        | 0.366      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.208     |
|    explained_variance   | 0.842      |
|    learning_rate        | 0.00149    |
|    loss                 | 0.0344     |
|    n_updates            | 12860      |
|    policy_gradient_loss | 0.0126     |
|    std                  | 0.268      |
|    value_loss           | 0.00563    |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 626        |
|    iterations           | 1288       |
|    time_elapsed         | 4211       |
|    total_timesteps      | 2637824    |
| train/                  |            |
|    approx_kl            | 0.19787417 |
|    clip_fraction        | 0.419      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.182     |
|    explained_variance   | 0.865      |
|    learning_rate        | 0.00149    |
|    loss                 | -0.0274    |
|    n_updates            | 12870      |
|    policy_gradient_loss | 0.00914    |
|    std                  | 0.267      |
|    value_loss           | 0.0106     |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 626        |
|    iterations           | 1289       |
|    time_elapsed         | 4214       |
|    total_timesteps      | 2639872    |
| train/                  |            |
|    approx_kl            | 0.09442523 |
|    clip_fraction        | 0.393      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.166     |
|    explained_variance   | 0.771      |
|    learning_rate        | 0.00149    |
|    loss                 | 0.0611     |
|    n_updates            | 12880      |
|    policy_gradient_loss | 0.00986    |
|    std                  | 0.26       |
|    value_loss           | 0.0164     |
----------------------------------------
Eval num_timesteps=2640000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1         |
| time/                   |            |
|    total_timesteps      | 2640000    |
| train/                  |            |
|    approx_kl            | 0.31914026 |
|    clip_fraction        | 0.493      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.112     |
|    explained_variance   | 0.737      |
|    learning_rate        | 0.00149    |
|    loss                 | -0.0414    |
|    n_updates            | 12890      |
|    policy_gradient_loss | 0.00893    |
|    std                  | 0.254      |
|    value_loss           | 0.00499    |
----------------------------------------
box reached target
--------------------------------
| time/              |         |
|    fps             | 626     |
|    iterations      | 1290    |
|    time_elapsed    | 4218    |
|    total_timesteps | 2641920 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 626        |
|    iterations           | 1291       |
|    time_elapsed         | 4221       |
|    total_timesteps      | 2643968    |
| train/                  |            |
|    approx_kl            | 0.22753362 |
|    clip_fraction        | 0.447      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.0498    |
|    explained_variance   | 0.759      |
|    learning_rate        | 0.00148    |
|    loss                 | -0.0186    |
|    n_updates            | 12900      |
|    policy_gradient_loss | 0.0137     |
|    std                  | 0.252      |
|    value_loss           | 0.00527    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 626        |
|    iterations           | 1292       |
|    time_elapsed         | 4224       |
|    total_timesteps      | 2646016    |
| train/                  |            |
|    approx_kl            | 0.17026919 |
|    clip_fraction        | 0.393      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.00279   |
|    explained_variance   | 0.861      |
|    learning_rate        | 0.00148    |
|    loss                 | -0.0431    |
|    n_updates            | 12910      |
|    policy_gradient_loss | 0.0138     |
|    std                  | 0.245      |
|    value_loss           | 0.00629    |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 626        |
|    iterations           | 1293       |
|    time_elapsed         | 4227       |
|    total_timesteps      | 2648064    |
| train/                  |            |
|    approx_kl            | 0.25966993 |
|    clip_fraction        | 0.439      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.076     |
|    explained_variance   | 0.83       |
|    learning_rate        | 0.00148    |
|    loss                 | 0.0533     |
|    n_updates            | 12920      |
|    policy_gradient_loss | 0.0144     |
|    std                  | 0.258      |
|    value_loss           | 0.00194    |
----------------------------------------
box reached target
box reached target
box reached target
Eval num_timesteps=2650000, episode_reward=0.36 +/- 2.72
Episode length: 290.20 +/- 19.60
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 290        |
|    mean_reward          | 0.358      |
| time/                   |            |
|    total_timesteps      | 2650000    |
| train/                  |            |
|    approx_kl            | 0.37193954 |
|    clip_fraction        | 0.509      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.0584    |
|    explained_variance   | 0.925      |
|    learning_rate        | 0.00148    |
|    loss                 | 0.00127    |
|    n_updates            | 12930      |
|    policy_gradient_loss | 0.0165     |
|    std                  | 0.247      |
|    value_loss           | 0.0129     |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 626     |
|    iterations      | 1294    |
|    time_elapsed    | 4231    |
|    total_timesteps | 2650112 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 626        |
|    iterations           | 1295       |
|    time_elapsed         | 4234       |
|    total_timesteps      | 2652160    |
| train/                  |            |
|    approx_kl            | 0.08877343 |
|    clip_fraction        | 0.353      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.0272    |
|    explained_variance   | 0.926      |
|    learning_rate        | 0.00148    |
|    loss                 | 0.0205     |
|    n_updates            | 12940      |
|    policy_gradient_loss | 0.0103     |
|    std                  | 0.251      |
|    value_loss           | 0.0156     |
----------------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 626         |
|    iterations           | 1296        |
|    time_elapsed         | 4237        |
|    total_timesteps      | 2654208     |
| train/                  |             |
|    approx_kl            | 0.105522156 |
|    clip_fraction        | 0.452       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0785     |
|    explained_variance   | -0.548      |
|    learning_rate        | 0.00148     |
|    loss                 | 0.015       |
|    n_updates            | 12950       |
|    policy_gradient_loss | 0.0331      |
|    std                  | 0.255       |
|    value_loss           | 0.00211     |
-----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 626        |
|    iterations           | 1297       |
|    time_elapsed         | 4240       |
|    total_timesteps      | 2656256    |
| train/                  |            |
|    approx_kl            | 0.18800458 |
|    clip_fraction        | 0.411      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.0596    |
|    explained_variance   | 0.946      |
|    learning_rate        | 0.00148    |
|    loss                 | -0.0219    |
|    n_updates            | 12960      |
|    policy_gradient_loss | 0.0186     |
|    std                  | 0.25       |
|    value_loss           | 0.00453    |
----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 626       |
|    iterations           | 1298      |
|    time_elapsed         | 4243      |
|    total_timesteps      | 2658304   |
| train/                  |           |
|    approx_kl            | 0.0588175 |
|    clip_fraction        | 0.381     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0447   |
|    explained_variance   | 0.683     |
|    learning_rate        | 0.00148   |
|    loss                 | -0.021    |
|    n_updates            | 12970     |
|    policy_gradient_loss | 0.0094    |
|    std                  | 0.248     |
|    value_loss           | 0.00339   |
---------------------------------------
Eval num_timesteps=2660000, episode_reward=-0.74 +/- 0.52
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -0.741     |
| time/                   |            |
|    total_timesteps      | 2660000    |
| train/                  |            |
|    approx_kl            | 0.14702985 |
|    clip_fraction        | 0.369      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.0303    |
|    explained_variance   | 0.832      |
|    learning_rate        | 0.00148    |
|    loss                 | 0.0446     |
|    n_updates            | 12980      |
|    policy_gradient_loss | 0.00627    |
|    std                  | 0.246      |
|    value_loss           | 0.00584    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 626     |
|    iterations      | 1299    |
|    time_elapsed    | 4247    |
|    total_timesteps | 2660352 |
--------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 626        |
|    iterations           | 1300       |
|    time_elapsed         | 4250       |
|    total_timesteps      | 2662400    |
| train/                  |            |
|    approx_kl            | 0.22746804 |
|    clip_fraction        | 0.466      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.106     |
|    explained_variance   | 0.458      |
|    learning_rate        | 0.00148    |
|    loss                 | -0.0119    |
|    n_updates            | 12990      |
|    policy_gradient_loss | 0.0142     |
|    std                  | 0.262      |
|    value_loss           | 0.00203    |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 626        |
|    iterations           | 1301       |
|    time_elapsed         | 4253       |
|    total_timesteps      | 2664448    |
| train/                  |            |
|    approx_kl            | 0.40644807 |
|    clip_fraction        | 0.45       |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.143     |
|    explained_variance   | 0.886      |
|    learning_rate        | 0.00148    |
|    loss                 | -0.0012    |
|    n_updates            | 13000      |
|    policy_gradient_loss | 0.00638    |
|    std                  | 0.26       |
|    value_loss           | 0.00685    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 626        |
|    iterations           | 1302       |
|    time_elapsed         | 4256       |
|    total_timesteps      | 2666496    |
| train/                  |            |
|    approx_kl            | 0.27543256 |
|    clip_fraction        | 0.411      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.155     |
|    explained_variance   | 0.837      |
|    learning_rate        | 0.00148    |
|    loss                 | 0.0224     |
|    n_updates            | 13010      |
|    policy_gradient_loss | 0.017      |
|    std                  | 0.268      |
|    value_loss           | 0.015      |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 626        |
|    iterations           | 1303       |
|    time_elapsed         | 4259       |
|    total_timesteps      | 2668544    |
| train/                  |            |
|    approx_kl            | 0.10418904 |
|    clip_fraction        | 0.366      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.239     |
|    explained_variance   | 0.857      |
|    learning_rate        | 0.00148    |
|    loss                 | -0.0291    |
|    n_updates            | 13020      |
|    policy_gradient_loss | 0.0112     |
|    std                  | 0.278      |
|    value_loss           | 0.00321    |
----------------------------------------
Eval num_timesteps=2670000, episode_reward=-0.40 +/- 0.74
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -0.397     |
| time/                   |            |
|    total_timesteps      | 2670000    |
| train/                  |            |
|    approx_kl            | 0.22812128 |
|    clip_fraction        | 0.428      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.253     |
|    explained_variance   | 0.89       |
|    learning_rate        | 0.00148    |
|    loss                 | -0.0348    |
|    n_updates            | 13030      |
|    policy_gradient_loss | 0.00611    |
|    std                  | 0.276      |
|    value_loss           | 0.00778    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 626     |
|    iterations      | 1304    |
|    time_elapsed    | 4263    |
|    total_timesteps | 2670592 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 626        |
|    iterations           | 1305       |
|    time_elapsed         | 4266       |
|    total_timesteps      | 2672640    |
| train/                  |            |
|    approx_kl            | 0.16305324 |
|    clip_fraction        | 0.432      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.245     |
|    explained_variance   | 0.714      |
|    learning_rate        | 0.00148    |
|    loss                 | 0.0145     |
|    n_updates            | 13040      |
|    policy_gradient_loss | 0.0174     |
|    std                  | 0.276      |
|    value_loss           | 0.00219    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 626        |
|    iterations           | 1306       |
|    time_elapsed         | 4269       |
|    total_timesteps      | 2674688    |
| train/                  |            |
|    approx_kl            | 0.27336615 |
|    clip_fraction        | 0.405      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.212     |
|    explained_variance   | 0.733      |
|    learning_rate        | 0.00148    |
|    loss                 | 0.0637     |
|    n_updates            | 13050      |
|    policy_gradient_loss | 0.00374    |
|    std                  | 0.267      |
|    value_loss           | 0.000689   |
----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 626       |
|    iterations           | 1307      |
|    time_elapsed         | 4272      |
|    total_timesteps      | 2676736   |
| train/                  |           |
|    approx_kl            | 0.1333594 |
|    clip_fraction        | 0.42      |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.215    |
|    explained_variance   | 0.852     |
|    learning_rate        | 0.00148   |
|    loss                 | 0.00992   |
|    n_updates            | 13060     |
|    policy_gradient_loss | 0.0258    |
|    std                  | 0.275     |
|    value_loss           | 0.00292   |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 626        |
|    iterations           | 1308       |
|    time_elapsed         | 4275       |
|    total_timesteps      | 2678784    |
| train/                  |            |
|    approx_kl            | 0.22670385 |
|    clip_fraction        | 0.411      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.265     |
|    explained_variance   | 0.605      |
|    learning_rate        | 0.00148    |
|    loss                 | -0.00695   |
|    n_updates            | 13070      |
|    policy_gradient_loss | 0.0182     |
|    std                  | 0.279      |
|    value_loss           | 0.00217    |
----------------------------------------
box reached target
box reached target
Eval num_timesteps=2680000, episode_reward=-0.82 +/- 0.37
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -0.815     |
| time/                   |            |
|    total_timesteps      | 2680000    |
| train/                  |            |
|    approx_kl            | 0.11696933 |
|    clip_fraction        | 0.403      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.264     |
|    explained_variance   | 0.812      |
|    learning_rate        | 0.00148    |
|    loss                 | -0.00618   |
|    n_updates            | 13080      |
|    policy_gradient_loss | 0.00944    |
|    std                  | 0.278      |
|    value_loss           | 0.0069     |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 626     |
|    iterations      | 1309    |
|    time_elapsed    | 4279    |
|    total_timesteps | 2680832 |
--------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 626        |
|    iterations           | 1310       |
|    time_elapsed         | 4282       |
|    total_timesteps      | 2682880    |
| train/                  |            |
|    approx_kl            | 0.12941156 |
|    clip_fraction        | 0.364      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.272     |
|    explained_variance   | 0.799      |
|    learning_rate        | 0.00148    |
|    loss                 | 0.042      |
|    n_updates            | 13090      |
|    policy_gradient_loss | 0.00854    |
|    std                  | 0.28       |
|    value_loss           | 0.0183     |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 626        |
|    iterations           | 1311       |
|    time_elapsed         | 4285       |
|    total_timesteps      | 2684928    |
| train/                  |            |
|    approx_kl            | 0.34038073 |
|    clip_fraction        | 0.413      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.257     |
|    explained_variance   | 0.887      |
|    learning_rate        | 0.00148    |
|    loss                 | 0.00279    |
|    n_updates            | 13100      |
|    policy_gradient_loss | 0.00608    |
|    std                  | 0.281      |
|    value_loss           | 0.00702    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 626        |
|    iterations           | 1312       |
|    time_elapsed         | 4288       |
|    total_timesteps      | 2686976    |
| train/                  |            |
|    approx_kl            | 0.27791792 |
|    clip_fraction        | 0.482      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.234     |
|    explained_variance   | 0.354      |
|    learning_rate        | 0.00148    |
|    loss                 | -0.0125    |
|    n_updates            | 13110      |
|    policy_gradient_loss | 0.0195     |
|    std                  | 0.271      |
|    value_loss           | 0.0491     |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 626        |
|    iterations           | 1313       |
|    time_elapsed         | 4291       |
|    total_timesteps      | 2689024    |
| train/                  |            |
|    approx_kl            | 0.19595659 |
|    clip_fraction        | 0.36       |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.145     |
|    explained_variance   | 0.745      |
|    learning_rate        | 0.00148    |
|    loss                 | 0.0136     |
|    n_updates            | 13120      |
|    policy_gradient_loss | 0.017      |
|    std                  | 0.26       |
|    value_loss           | 0.0149     |
----------------------------------------
Eval num_timesteps=2690000, episode_reward=-0.99 +/- 0.01
Episode length: 300.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 300       |
|    mean_reward          | -0.994    |
| time/                   |           |
|    total_timesteps      | 2690000   |
| train/                  |           |
|    approx_kl            | 0.1331751 |
|    clip_fraction        | 0.374     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0904   |
|    explained_variance   | 0.847     |
|    learning_rate        | 0.00148   |
|    loss                 | 0.00713   |
|    n_updates            | 13130     |
|    policy_gradient_loss | 0.0168    |
|    std                  | 0.255     |
|    value_loss           | 0.00298   |
---------------------------------------
--------------------------------
| time/              |         |
|    fps             | 626     |
|    iterations      | 1314    |
|    time_elapsed    | 4295    |
|    total_timesteps | 2691072 |
--------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 626       |
|    iterations           | 1315      |
|    time_elapsed         | 4298      |
|    total_timesteps      | 2693120   |
| train/                  |           |
|    approx_kl            | 0.4774872 |
|    clip_fraction        | 0.34      |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0864   |
|    explained_variance   | 0.745     |
|    learning_rate        | 0.00148   |
|    loss                 | 0.00398   |
|    n_updates            | 13140     |
|    policy_gradient_loss | -0.000348 |
|    std                  | 0.252     |
|    value_loss           | 0.00573   |
---------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 626       |
|    iterations           | 1316      |
|    time_elapsed         | 4301      |
|    total_timesteps      | 2695168   |
| train/                  |           |
|    approx_kl            | 1.5063365 |
|    clip_fraction        | 0.516     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0739   |
|    explained_variance   | 0.673     |
|    learning_rate        | 0.00147   |
|    loss                 | 0.0606    |
|    n_updates            | 13150     |
|    policy_gradient_loss | 0.118     |
|    std                  | 0.253     |
|    value_loss           | 0.0384    |
---------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 626       |
|    iterations           | 1317      |
|    time_elapsed         | 4304      |
|    total_timesteps      | 2697216   |
| train/                  |           |
|    approx_kl            | 0.1308445 |
|    clip_fraction        | 0.377     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0706   |
|    explained_variance   | 0.675     |
|    learning_rate        | 0.00147   |
|    loss                 | -0.00868  |
|    n_updates            | 13160     |
|    policy_gradient_loss | 0.0118    |
|    std                  | 0.252     |
|    value_loss           | 0.00385   |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 626        |
|    iterations           | 1318       |
|    time_elapsed         | 4307       |
|    total_timesteps      | 2699264    |
| train/                  |            |
|    approx_kl            | 0.10558155 |
|    clip_fraction        | 0.377      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.0889    |
|    explained_variance   | 0.8        |
|    learning_rate        | 0.00147    |
|    loss                 | -0.00398   |
|    n_updates            | 13170      |
|    policy_gradient_loss | 0.00938    |
|    std                  | 0.254      |
|    value_loss           | 0.00493    |
----------------------------------------
Eval num_timesteps=2700000, episode_reward=-0.69 +/- 0.63
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -0.685     |
| time/                   |            |
|    total_timesteps      | 2700000    |
| train/                  |            |
|    approx_kl            | 0.11523927 |
|    clip_fraction        | 0.435      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.11      |
|    explained_variance   | 0.697      |
|    learning_rate        | 0.00147    |
|    loss                 | -0.0341    |
|    n_updates            | 13180      |
|    policy_gradient_loss | 0.015      |
|    std                  | 0.258      |
|    value_loss           | 0.00741    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 626     |
|    iterations      | 1319    |
|    time_elapsed    | 4311    |
|    total_timesteps | 2701312 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 626        |
|    iterations           | 1320       |
|    time_elapsed         | 4314       |
|    total_timesteps      | 2703360    |
| train/                  |            |
|    approx_kl            | 0.16337663 |
|    clip_fraction        | 0.437      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.147     |
|    explained_variance   | 0.736      |
|    learning_rate        | 0.00147    |
|    loss                 | -0.0318    |
|    n_updates            | 13190      |
|    policy_gradient_loss | 0.0191     |
|    std                  | 0.262      |
|    value_loss           | 0.00785    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 626        |
|    iterations           | 1321       |
|    time_elapsed         | 4317       |
|    total_timesteps      | 2705408    |
| train/                  |            |
|    approx_kl            | 0.20183712 |
|    clip_fraction        | 0.396      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.136     |
|    explained_variance   | 0.65       |
|    learning_rate        | 0.00147    |
|    loss                 | 0.0581     |
|    n_updates            | 13200      |
|    policy_gradient_loss | -0.00257   |
|    std                  | 0.257      |
|    value_loss           | 0.00178    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 626        |
|    iterations           | 1322       |
|    time_elapsed         | 4320       |
|    total_timesteps      | 2707456    |
| train/                  |            |
|    approx_kl            | 0.35645714 |
|    clip_fraction        | 0.44       |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.0987    |
|    explained_variance   | 0.717      |
|    learning_rate        | 0.00147    |
|    loss                 | 0.0011     |
|    n_updates            | 13210      |
|    policy_gradient_loss | -0.000667  |
|    std                  | 0.251      |
|    value_loss           | 0.00483    |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 626        |
|    iterations           | 1323       |
|    time_elapsed         | 4323       |
|    total_timesteps      | 2709504    |
| train/                  |            |
|    approx_kl            | 0.34599906 |
|    clip_fraction        | 0.399      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.0377    |
|    explained_variance   | 0.537      |
|    learning_rate        | 0.00147    |
|    loss                 | -0.0317    |
|    n_updates            | 13220      |
|    policy_gradient_loss | 0.00549    |
|    std                  | 0.245      |
|    value_loss           | 0.00305    |
----------------------------------------
box reached target
Eval num_timesteps=2710000, episode_reward=0.37 +/- 2.43
Episode length: 274.20 +/- 51.60
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 274         |
|    mean_reward          | 0.367       |
| time/                   |             |
|    total_timesteps      | 2710000     |
| train/                  |             |
|    approx_kl            | 0.107306406 |
|    clip_fraction        | 0.385       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0322     |
|    explained_variance   | 0.374       |
|    learning_rate        | 0.00147     |
|    loss                 | 0.0127      |
|    n_updates            | 13230       |
|    policy_gradient_loss | 0.00697     |
|    std                  | 0.25        |
|    value_loss           | 0.0163      |
-----------------------------------------
box reached target
box reached target
--------------------------------
| time/              |         |
|    fps             | 626     |
|    iterations      | 1324    |
|    time_elapsed    | 4327    |
|    total_timesteps | 2711552 |
--------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 626       |
|    iterations           | 1325      |
|    time_elapsed         | 4330      |
|    total_timesteps      | 2713600   |
| train/                  |           |
|    approx_kl            | 0.5252362 |
|    clip_fraction        | 0.477     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0575   |
|    explained_variance   | 0.641     |
|    learning_rate        | 0.00147   |
|    loss                 | -0.0109   |
|    n_updates            | 13240     |
|    policy_gradient_loss | 0.025     |
|    std                  | 0.253     |
|    value_loss           | 0.0209    |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 626        |
|    iterations           | 1326       |
|    time_elapsed         | 4333       |
|    total_timesteps      | 2715648    |
| train/                  |            |
|    approx_kl            | 0.42271274 |
|    clip_fraction        | 0.449      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.0409    |
|    explained_variance   | 0.609      |
|    learning_rate        | 0.00147    |
|    loss                 | 0.00507    |
|    n_updates            | 13250      |
|    policy_gradient_loss | 0.00555    |
|    std                  | 0.245      |
|    value_loss           | 0.00574    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 626        |
|    iterations           | 1327       |
|    time_elapsed         | 4336       |
|    total_timesteps      | 2717696    |
| train/                  |            |
|    approx_kl            | 0.61335236 |
|    clip_fraction        | 0.45       |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.0102     |
|    explained_variance   | 0.719      |
|    learning_rate        | 0.00147    |
|    loss                 | -0.0425    |
|    n_updates            | 13260      |
|    policy_gradient_loss | 0.0099     |
|    std                  | 0.241      |
|    value_loss           | 0.0035     |
----------------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 626        |
|    iterations           | 1328       |
|    time_elapsed         | 4339       |
|    total_timesteps      | 2719744    |
| train/                  |            |
|    approx_kl            | 0.18603487 |
|    clip_fraction        | 0.424      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.0142     |
|    explained_variance   | 0.764      |
|    learning_rate        | 0.00147    |
|    loss                 | 0.0194     |
|    n_updates            | 13270      |
|    policy_gradient_loss | 0.00455    |
|    std                  | 0.244      |
|    value_loss           | 0.00301    |
----------------------------------------
box reached target
Eval num_timesteps=2720000, episode_reward=0.53 +/- 2.32
Episode length: 277.40 +/- 45.20
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 277        |
|    mean_reward          | 0.53       |
| time/                   |            |
|    total_timesteps      | 2720000    |
| train/                  |            |
|    approx_kl            | 0.26758134 |
|    clip_fraction        | 0.497      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.0453     |
|    explained_variance   | 0.886      |
|    learning_rate        | 0.00147    |
|    loss                 | -0.0349    |
|    n_updates            | 13280      |
|    policy_gradient_loss | 0.00535    |
|    std                  | 0.234      |
|    value_loss           | 0.00707    |
----------------------------------------
box reached target
--------------------------------
| time/              |         |
|    fps             | 626     |
|    iterations      | 1329    |
|    time_elapsed    | 4343    |
|    total_timesteps | 2721792 |
--------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 626        |
|    iterations           | 1330       |
|    time_elapsed         | 4346       |
|    total_timesteps      | 2723840    |
| train/                  |            |
|    approx_kl            | 0.33965272 |
|    clip_fraction        | 0.461      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.0431     |
|    explained_variance   | 0.737      |
|    learning_rate        | 0.00147    |
|    loss                 | 0.031      |
|    n_updates            | 13290      |
|    policy_gradient_loss | 0.0134     |
|    std                  | 0.241      |
|    value_loss           | 0.00882    |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 626        |
|    iterations           | 1331       |
|    time_elapsed         | 4349       |
|    total_timesteps      | 2725888    |
| train/                  |            |
|    approx_kl            | 0.20338362 |
|    clip_fraction        | 0.472      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.0127     |
|    explained_variance   | 0.879      |
|    learning_rate        | 0.00147    |
|    loss                 | 0.0445     |
|    n_updates            | 13300      |
|    policy_gradient_loss | 0.0179     |
|    std                  | 0.245      |
|    value_loss           | 0.0121     |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 626        |
|    iterations           | 1332       |
|    time_elapsed         | 4352       |
|    total_timesteps      | 2727936    |
| train/                  |            |
|    approx_kl            | 0.12458764 |
|    clip_fraction        | 0.422      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.0362    |
|    explained_variance   | 0.748      |
|    learning_rate        | 0.00147    |
|    loss                 | 0.0126     |
|    n_updates            | 13310      |
|    policy_gradient_loss | 0.0235     |
|    std                  | 0.247      |
|    value_loss           | 0.0314     |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 626        |
|    iterations           | 1333       |
|    time_elapsed         | 4355       |
|    total_timesteps      | 2729984    |
| train/                  |            |
|    approx_kl            | 0.10958603 |
|    clip_fraction        | 0.411      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.0142    |
|    explained_variance   | 0.704      |
|    learning_rate        | 0.00147    |
|    loss                 | 0.0186     |
|    n_updates            | 13320      |
|    policy_gradient_loss | 0.0145     |
|    std                  | 0.248      |
|    value_loss           | 0.0147     |
----------------------------------------
Eval num_timesteps=2730000, episode_reward=-0.16 +/- 0.69
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -0.164     |
| time/                   |            |
|    total_timesteps      | 2730000    |
| train/                  |            |
|    approx_kl            | 0.13501778 |
|    clip_fraction        | 0.409      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.0646    |
|    explained_variance   | 0.919      |
|    learning_rate        | 0.00147    |
|    loss                 | 0.0563     |
|    n_updates            | 13330      |
|    policy_gradient_loss | 0.0186     |
|    std                  | 0.254      |
|    value_loss           | 0.00569    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 626     |
|    iterations      | 1334    |
|    time_elapsed    | 4359    |
|    total_timesteps | 2732032 |
--------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 626        |
|    iterations           | 1335       |
|    time_elapsed         | 4362       |
|    total_timesteps      | 2734080    |
| train/                  |            |
|    approx_kl            | 0.14888611 |
|    clip_fraction        | 0.388      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.102     |
|    explained_variance   | 0.544      |
|    learning_rate        | 0.00147    |
|    loss                 | -0.0323    |
|    n_updates            | 13340      |
|    policy_gradient_loss | 0.00275    |
|    std                  | 0.256      |
|    value_loss           | 0.0125     |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 626        |
|    iterations           | 1336       |
|    time_elapsed         | 4365       |
|    total_timesteps      | 2736128    |
| train/                  |            |
|    approx_kl            | 0.08586166 |
|    clip_fraction        | 0.365      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.134     |
|    explained_variance   | 0.877      |
|    learning_rate        | 0.00147    |
|    loss                 | -0.00959   |
|    n_updates            | 13350      |
|    policy_gradient_loss | 0.00345    |
|    std                  | 0.263      |
|    value_loss           | 0.0103     |
----------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 626       |
|    iterations           | 1337      |
|    time_elapsed         | 4368      |
|    total_timesteps      | 2738176   |
| train/                  |           |
|    approx_kl            | 0.6218497 |
|    clip_fraction        | 0.433     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.135    |
|    explained_variance   | 0.637     |
|    learning_rate        | 0.00147   |
|    loss                 | -0.0318   |
|    n_updates            | 13360     |
|    policy_gradient_loss | 0.000468  |
|    std                  | 0.261     |
|    value_loss           | 0.00226   |
---------------------------------------
box reached target
box reached target
box reached target
Eval num_timesteps=2740000, episode_reward=0.47 +/- 2.38
Episode length: 273.00 +/- 54.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 273        |
|    mean_reward          | 0.465      |
| time/                   |            |
|    total_timesteps      | 2740000    |
| train/                  |            |
|    approx_kl            | 0.27343363 |
|    clip_fraction        | 0.4        |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.108     |
|    explained_variance   | 0.937      |
|    learning_rate        | 0.00147    |
|    loss                 | 0.0507     |
|    n_updates            | 13370      |
|    policy_gradient_loss | 0.0137     |
|    std                  | 0.257      |
|    value_loss           | 0.00718    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 626     |
|    iterations      | 1338    |
|    time_elapsed    | 4372    |
|    total_timesteps | 2740224 |
--------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 626       |
|    iterations           | 1339      |
|    time_elapsed         | 4375      |
|    total_timesteps      | 2742272   |
| train/                  |           |
|    approx_kl            | 0.4795425 |
|    clip_fraction        | 0.451     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0734   |
|    explained_variance   | 0.632     |
|    learning_rate        | 0.00147   |
|    loss                 | 0.053     |
|    n_updates            | 13380     |
|    policy_gradient_loss | 0.01      |
|    std                  | 0.253     |
|    value_loss           | 0.0298    |
---------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 626        |
|    iterations           | 1340       |
|    time_elapsed         | 4378       |
|    total_timesteps      | 2744320    |
| train/                  |            |
|    approx_kl            | 0.14521556 |
|    clip_fraction        | 0.44       |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.11      |
|    explained_variance   | 0.8        |
|    learning_rate        | 0.00147    |
|    loss                 | -0.00306   |
|    n_updates            | 13390      |
|    policy_gradient_loss | 0.0179     |
|    std                  | 0.261      |
|    value_loss           | 0.00705    |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 626        |
|    iterations           | 1341       |
|    time_elapsed         | 4381       |
|    total_timesteps      | 2746368    |
| train/                  |            |
|    approx_kl            | 0.15003416 |
|    clip_fraction        | 0.401      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.168     |
|    explained_variance   | 0.702      |
|    learning_rate        | 0.00146    |
|    loss                 | 0.0407     |
|    n_updates            | 13400      |
|    policy_gradient_loss | 0.0292     |
|    std                  | 0.272      |
|    value_loss           | 0.0281     |
----------------------------------------
box reached target
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 626        |
|    iterations           | 1342       |
|    time_elapsed         | 4384       |
|    total_timesteps      | 2748416    |
| train/                  |            |
|    approx_kl            | 0.08999956 |
|    clip_fraction        | 0.381      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.267     |
|    explained_variance   | 0.898      |
|    learning_rate        | 0.00146    |
|    loss                 | 0.0569     |
|    n_updates            | 13410      |
|    policy_gradient_loss | 0.00818    |
|    std                  | 0.282      |
|    value_loss           | 0.0187     |
----------------------------------------
box reached target
box reached target
Eval num_timesteps=2750000, episode_reward=0.65 +/- 2.30
Episode length: 276.80 +/- 46.40
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 277        |
|    mean_reward          | 0.646      |
| time/                   |            |
|    total_timesteps      | 2750000    |
| train/                  |            |
|    approx_kl            | 0.13562424 |
|    clip_fraction        | 0.42       |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.297     |
|    explained_variance   | 0.848      |
|    learning_rate        | 0.00146    |
|    loss                 | 0.0118     |
|    n_updates            | 13420      |
|    policy_gradient_loss | 0.0119     |
|    std                  | 0.281      |
|    value_loss           | 0.0213     |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 626     |
|    iterations      | 1343    |
|    time_elapsed    | 4388    |
|    total_timesteps | 2750464 |
--------------------------------
box reached target
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 626       |
|    iterations           | 1344      |
|    time_elapsed         | 4391      |
|    total_timesteps      | 2752512   |
| train/                  |           |
|    approx_kl            | 0.1574252 |
|    clip_fraction        | 0.39      |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.304    |
|    explained_variance   | 0.898     |
|    learning_rate        | 0.00146   |
|    loss                 | 0.0241    |
|    n_updates            | 13430     |
|    policy_gradient_loss | 0.0128    |
|    std                  | 0.282     |
|    value_loss           | 0.00992   |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 626        |
|    iterations           | 1345       |
|    time_elapsed         | 4394       |
|    total_timesteps      | 2754560    |
| train/                  |            |
|    approx_kl            | 0.11470355 |
|    clip_fraction        | 0.361      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.329     |
|    explained_variance   | 0.945      |
|    learning_rate        | 0.00146    |
|    loss                 | -0.076     |
|    n_updates            | 13440      |
|    policy_gradient_loss | -0.00112   |
|    std                  | 0.288      |
|    value_loss           | 0.0126     |
----------------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 626        |
|    iterations           | 1346       |
|    time_elapsed         | 4397       |
|    total_timesteps      | 2756608    |
| train/                  |            |
|    approx_kl            | 0.06725841 |
|    clip_fraction        | 0.331      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.409     |
|    explained_variance   | 0.84       |
|    learning_rate        | 0.00146    |
|    loss                 | -0.00603   |
|    n_updates            | 13450      |
|    policy_gradient_loss | 0.00372    |
|    std                  | 0.302      |
|    value_loss           | 0.00763    |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 626        |
|    iterations           | 1347       |
|    time_elapsed         | 4400       |
|    total_timesteps      | 2758656    |
| train/                  |            |
|    approx_kl            | 0.15017594 |
|    clip_fraction        | 0.406      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.421     |
|    explained_variance   | 0.762      |
|    learning_rate        | 0.00146    |
|    loss                 | 0.00148    |
|    n_updates            | 13460      |
|    policy_gradient_loss | 0.0189     |
|    std                  | 0.3        |
|    value_loss           | 0.0208     |
----------------------------------------
Eval num_timesteps=2760000, episode_reward=-1.04 +/- 0.08
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1.04      |
| time/                   |            |
|    total_timesteps      | 2760000    |
| train/                  |            |
|    approx_kl            | 0.11452322 |
|    clip_fraction        | 0.378      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.356     |
|    explained_variance   | 0.755      |
|    learning_rate        | 0.00146    |
|    loss                 | -0.0345    |
|    n_updates            | 13470      |
|    policy_gradient_loss | 0.000464   |
|    std                  | 0.285      |
|    value_loss           | 0.0199     |
----------------------------------------
box reached target
--------------------------------
| time/              |         |
|    fps             | 626     |
|    iterations      | 1348    |
|    time_elapsed    | 4404    |
|    total_timesteps | 2760704 |
--------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 626        |
|    iterations           | 1349       |
|    time_elapsed         | 4407       |
|    total_timesteps      | 2762752    |
| train/                  |            |
|    approx_kl            | 0.12534639 |
|    clip_fraction        | 0.384      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.35      |
|    explained_variance   | 0.887      |
|    learning_rate        | 0.00146    |
|    loss                 | -0.0234    |
|    n_updates            | 13480      |
|    policy_gradient_loss | -0.0021    |
|    std                  | 0.29       |
|    value_loss           | 0.017      |
----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 626       |
|    iterations           | 1350      |
|    time_elapsed         | 4411      |
|    total_timesteps      | 2764800   |
| train/                  |           |
|    approx_kl            | 0.2779853 |
|    clip_fraction        | 0.383     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.372    |
|    explained_variance   | 0.889     |
|    learning_rate        | 0.00146   |
|    loss                 | 0.0272    |
|    n_updates            | 13490     |
|    policy_gradient_loss | 0.00367   |
|    std                  | 0.292     |
|    value_loss           | 0.00941   |
---------------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 626        |
|    iterations           | 1351       |
|    time_elapsed         | 4414       |
|    total_timesteps      | 2766848    |
| train/                  |            |
|    approx_kl            | 0.47282445 |
|    clip_fraction        | 0.397      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.344     |
|    explained_variance   | 0.74       |
|    learning_rate        | 0.00146    |
|    loss                 | -0.0461    |
|    n_updates            | 13500      |
|    policy_gradient_loss | -0.00764   |
|    std                  | 0.284      |
|    value_loss           | 0.00409    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 626        |
|    iterations           | 1352       |
|    time_elapsed         | 4417       |
|    total_timesteps      | 2768896    |
| train/                  |            |
|    approx_kl            | 0.14953026 |
|    clip_fraction        | 0.436      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.324     |
|    explained_variance   | 0.723      |
|    learning_rate        | 0.00146    |
|    loss                 | -0.00886   |
|    n_updates            | 13510      |
|    policy_gradient_loss | 0.0191     |
|    std                  | 0.287      |
|    value_loss           | 0.0549     |
----------------------------------------
box reached target
box reached target
Eval num_timesteps=2770000, episode_reward=1.73 +/- 2.83
Episode length: 252.00 +/- 60.56
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 252        |
|    mean_reward          | 1.73       |
| time/                   |            |
|    total_timesteps      | 2770000    |
| train/                  |            |
|    approx_kl            | 0.13466707 |
|    clip_fraction        | 0.386      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.365     |
|    explained_variance   | 0.746      |
|    learning_rate        | 0.00146    |
|    loss                 | 0.0256     |
|    n_updates            | 13520      |
|    policy_gradient_loss | 0.00854    |
|    std                  | 0.296      |
|    value_loss           | 0.00737    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 626     |
|    iterations      | 1353    |
|    time_elapsed    | 4420    |
|    total_timesteps | 2770944 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 626        |
|    iterations           | 1354       |
|    time_elapsed         | 4423       |
|    total_timesteps      | 2772992    |
| train/                  |            |
|    approx_kl            | 0.10501227 |
|    clip_fraction        | 0.354      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.401     |
|    explained_variance   | 0.843      |
|    learning_rate        | 0.00146    |
|    loss                 | 0.0885     |
|    n_updates            | 13530      |
|    policy_gradient_loss | 0.0051     |
|    std                  | 0.301      |
|    value_loss           | 0.00519    |
----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 626       |
|    iterations           | 1355      |
|    time_elapsed         | 4426      |
|    total_timesteps      | 2775040   |
| train/                  |           |
|    approx_kl            | 1.6566069 |
|    clip_fraction        | 0.395     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.416    |
|    explained_variance   | 0.748     |
|    learning_rate        | 0.00146   |
|    loss                 | -0.0376   |
|    n_updates            | 13540     |
|    policy_gradient_loss | -0.00021  |
|    std                  | 0.303     |
|    value_loss           | 0.00309   |
---------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 626        |
|    iterations           | 1356       |
|    time_elapsed         | 4430       |
|    total_timesteps      | 2777088    |
| train/                  |            |
|    approx_kl            | 0.14799368 |
|    clip_fraction        | 0.356      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.419     |
|    explained_variance   | 0.75       |
|    learning_rate        | 0.00146    |
|    loss                 | -0.00213   |
|    n_updates            | 13550      |
|    policy_gradient_loss | -0.00148   |
|    std                  | 0.305      |
|    value_loss           | 0.00528    |
----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 626         |
|    iterations           | 1357        |
|    time_elapsed         | 4433        |
|    total_timesteps      | 2779136     |
| train/                  |             |
|    approx_kl            | 0.090255976 |
|    clip_fraction        | 0.369       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.414      |
|    explained_variance   | 0.682       |
|    learning_rate        | 0.00146     |
|    loss                 | -0.0185     |
|    n_updates            | 13560       |
|    policy_gradient_loss | 0.00347     |
|    std                  | 0.301       |
|    value_loss           | 0.0153      |
-----------------------------------------
box reached target
Eval num_timesteps=2780000, episode_reward=0.25 +/- 2.51
Episode length: 275.20 +/- 49.60
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 275        |
|    mean_reward          | 0.254      |
| time/                   |            |
|    total_timesteps      | 2780000    |
| train/                  |            |
|    approx_kl            | 0.29112667 |
|    clip_fraction        | 0.385      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.429     |
|    explained_variance   | 0.814      |
|    learning_rate        | 0.00146    |
|    loss                 | -0.032     |
|    n_updates            | 13570      |
|    policy_gradient_loss | -0.00439   |
|    std                  | 0.303      |
|    value_loss           | 0.00602    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 626     |
|    iterations      | 1358    |
|    time_elapsed    | 4436    |
|    total_timesteps | 2781184 |
--------------------------------
box reached target
--------------------------------------
| time/                   |          |
|    fps                  | 626      |
|    iterations           | 1359     |
|    time_elapsed         | 4439     |
|    total_timesteps      | 2783232  |
| train/                  |          |
|    approx_kl            | 0.102744 |
|    clip_fraction        | 0.421    |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.455   |
|    explained_variance   | 0.708    |
|    learning_rate        | 0.00146  |
|    loss                 | 0.0103   |
|    n_updates            | 13580    |
|    policy_gradient_loss | 0.012    |
|    std                  | 0.313    |
|    value_loss           | 0.0137   |
--------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 626        |
|    iterations           | 1360       |
|    time_elapsed         | 4442       |
|    total_timesteps      | 2785280    |
| train/                  |            |
|    approx_kl            | 0.23149766 |
|    clip_fraction        | 0.378      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.482     |
|    explained_variance   | 0.763      |
|    learning_rate        | 0.00146    |
|    loss                 | -0.00505   |
|    n_updates            | 13590      |
|    policy_gradient_loss | -0.00484   |
|    std                  | 0.309      |
|    value_loss           | 0.0272     |
----------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 626       |
|    iterations           | 1361      |
|    time_elapsed         | 4446      |
|    total_timesteps      | 2787328   |
| train/                  |           |
|    approx_kl            | 2.0587437 |
|    clip_fraction        | 0.456     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.458    |
|    explained_variance   | 0.534     |
|    learning_rate        | 0.00146   |
|    loss                 | -0.01     |
|    n_updates            | 13600     |
|    policy_gradient_loss | 0.0404    |
|    std                  | 0.303     |
|    value_loss           | 0.00401   |
---------------------------------------
box reached target
box reached target
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 626       |
|    iterations           | 1362      |
|    time_elapsed         | 4449      |
|    total_timesteps      | 2789376   |
| train/                  |           |
|    approx_kl            | 0.1188131 |
|    clip_fraction        | 0.383     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.445    |
|    explained_variance   | 0.708     |
|    learning_rate        | 0.00146   |
|    loss                 | -0.0112   |
|    n_updates            | 13610     |
|    policy_gradient_loss | 0.0248    |
|    std                  | 0.307     |
|    value_loss           | 0.0155    |
---------------------------------------
box reached target
Eval num_timesteps=2790000, episode_reward=0.26 +/- 2.52
Episode length: 281.40 +/- 37.20
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 281         |
|    mean_reward          | 0.258       |
| time/                   |             |
|    total_timesteps      | 2790000     |
| train/                  |             |
|    approx_kl            | 0.121680886 |
|    clip_fraction        | 0.377       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.446      |
|    explained_variance   | 0.751       |
|    learning_rate        | 0.00146     |
|    loss                 | 0.0204      |
|    n_updates            | 13620       |
|    policy_gradient_loss | 0.00619     |
|    std                  | 0.306       |
|    value_loss           | 0.0384      |
-----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 626     |
|    iterations      | 1363    |
|    time_elapsed    | 4453    |
|    total_timesteps | 2791424 |
--------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 626       |
|    iterations           | 1364      |
|    time_elapsed         | 4456      |
|    total_timesteps      | 2793472   |
| train/                  |           |
|    approx_kl            | 0.3178559 |
|    clip_fraction        | 0.337     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.449    |
|    explained_variance   | 0.589     |
|    learning_rate        | 0.00146   |
|    loss                 | -0.0224   |
|    n_updates            | 13630     |
|    policy_gradient_loss | -0.0121   |
|    std                  | 0.304     |
|    value_loss           | 0.0117    |
---------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 626        |
|    iterations           | 1365       |
|    time_elapsed         | 4459       |
|    total_timesteps      | 2795520    |
| train/                  |            |
|    approx_kl            | 0.39250594 |
|    clip_fraction        | 0.375      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.443     |
|    explained_variance   | 0.72       |
|    learning_rate        | 0.00146    |
|    loss                 | -0.00924   |
|    n_updates            | 13640      |
|    policy_gradient_loss | 0.0475     |
|    std                  | 0.3        |
|    value_loss           | 0.00411    |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 626        |
|    iterations           | 1366       |
|    time_elapsed         | 4462       |
|    total_timesteps      | 2797568    |
| train/                  |            |
|    approx_kl            | 0.06710363 |
|    clip_fraction        | 0.366      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.397     |
|    explained_variance   | 0.799      |
|    learning_rate        | 0.00145    |
|    loss                 | 0.0143     |
|    n_updates            | 13650      |
|    policy_gradient_loss | 0.0229     |
|    std                  | 0.293      |
|    value_loss           | 0.0376     |
----------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 626       |
|    iterations           | 1367      |
|    time_elapsed         | 4465      |
|    total_timesteps      | 2799616   |
| train/                  |           |
|    approx_kl            | 0.1307409 |
|    clip_fraction        | 0.362     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.361    |
|    explained_variance   | 0.735     |
|    learning_rate        | 0.00145   |
|    loss                 | 0.0683    |
|    n_updates            | 13660     |
|    policy_gradient_loss | 0.00892   |
|    std                  | 0.292     |
|    value_loss           | 0.0263    |
---------------------------------------
box reached target
box reached target
Eval num_timesteps=2800000, episode_reward=1.44 +/- 2.99
Episode length: 245.40 +/- 66.96
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 245        |
|    mean_reward          | 1.44       |
| time/                   |            |
|    total_timesteps      | 2800000    |
| train/                  |            |
|    approx_kl            | 0.16535172 |
|    clip_fraction        | 0.398      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.391     |
|    explained_variance   | 0.691      |
|    learning_rate        | 0.00145    |
|    loss                 | 0.0335     |
|    n_updates            | 13670      |
|    policy_gradient_loss | 0.013      |
|    std                  | 0.299      |
|    value_loss           | 0.00793    |
----------------------------------------
box reached target
box reached target
--------------------------------
| time/              |         |
|    fps             | 626     |
|    iterations      | 1368    |
|    time_elapsed    | 4468    |
|    total_timesteps | 2801664 |
--------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 626        |
|    iterations           | 1369       |
|    time_elapsed         | 4471       |
|    total_timesteps      | 2803712    |
| train/                  |            |
|    approx_kl            | 0.25673646 |
|    clip_fraction        | 0.422      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.419     |
|    explained_variance   | 0.778      |
|    learning_rate        | 0.00145    |
|    loss                 | 0.024      |
|    n_updates            | 13680      |
|    policy_gradient_loss | 0.0109     |
|    std                  | 0.297      |
|    value_loss           | 0.023      |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 626        |
|    iterations           | 1370       |
|    time_elapsed         | 4475       |
|    total_timesteps      | 2805760    |
| train/                  |            |
|    approx_kl            | 0.11168829 |
|    clip_fraction        | 0.39       |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.376     |
|    explained_variance   | 0.91       |
|    learning_rate        | 0.00145    |
|    loss                 | 0.414      |
|    n_updates            | 13690      |
|    policy_gradient_loss | 0.0128     |
|    std                  | 0.293      |
|    value_loss           | 0.00706    |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 627        |
|    iterations           | 1371       |
|    time_elapsed         | 4478       |
|    total_timesteps      | 2807808    |
| train/                  |            |
|    approx_kl            | 0.11516111 |
|    clip_fraction        | 0.348      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.379     |
|    explained_variance   | 0.9        |
|    learning_rate        | 0.00145    |
|    loss                 | -0.0192    |
|    n_updates            | 13700      |
|    policy_gradient_loss | -0.00325   |
|    std                  | 0.294      |
|    value_loss           | 0.00848    |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 627        |
|    iterations           | 1372       |
|    time_elapsed         | 4481       |
|    total_timesteps      | 2809856    |
| train/                  |            |
|    approx_kl            | 0.17525125 |
|    clip_fraction        | 0.387      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.344     |
|    explained_variance   | 0.673      |
|    learning_rate        | 0.00145    |
|    loss                 | 0.0195     |
|    n_updates            | 13710      |
|    policy_gradient_loss | 0.00537    |
|    std                  | 0.286      |
|    value_loss           | 0.062      |
----------------------------------------
Eval num_timesteps=2810000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1         |
| time/                   |            |
|    total_timesteps      | 2810000    |
| train/                  |            |
|    approx_kl            | 0.37249294 |
|    clip_fraction        | 0.413      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.357     |
|    explained_variance   | 0.803      |
|    learning_rate        | 0.00145    |
|    loss                 | 0.0407     |
|    n_updates            | 13720      |
|    policy_gradient_loss | 0.0171     |
|    std                  | 0.292      |
|    value_loss           | 0.00809    |
----------------------------------------
box reached target
box reached target
--------------------------------
| time/              |         |
|    fps             | 626     |
|    iterations      | 1373    |
|    time_elapsed    | 4485    |
|    total_timesteps | 2811904 |
--------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 626        |
|    iterations           | 1374       |
|    time_elapsed         | 4488       |
|    total_timesteps      | 2813952    |
| train/                  |            |
|    approx_kl            | 0.24494505 |
|    clip_fraction        | 0.456      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.375     |
|    explained_variance   | 0.843      |
|    learning_rate        | 0.00145    |
|    loss                 | -0.0403    |
|    n_updates            | 13730      |
|    policy_gradient_loss | 0.00636    |
|    std                  | 0.294      |
|    value_loss           | 0.0229     |
----------------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 627        |
|    iterations           | 1375       |
|    time_elapsed         | 4491       |
|    total_timesteps      | 2816000    |
| train/                  |            |
|    approx_kl            | 0.45211005 |
|    clip_fraction        | 0.439      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.367     |
|    explained_variance   | 0.682      |
|    learning_rate        | 0.00145    |
|    loss                 | 0.00544    |
|    n_updates            | 13740      |
|    policy_gradient_loss | 0.00985    |
|    std                  | 0.288      |
|    value_loss           | 0.0182     |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 627        |
|    iterations           | 1376       |
|    time_elapsed         | 4494       |
|    total_timesteps      | 2818048    |
| train/                  |            |
|    approx_kl            | 0.09179309 |
|    clip_fraction        | 0.378      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.355     |
|    explained_variance   | 0.788      |
|    learning_rate        | 0.00145    |
|    loss                 | -0.0219    |
|    n_updates            | 13750      |
|    policy_gradient_loss | 0.00949    |
|    std                  | 0.294      |
|    value_loss           | 0.0284     |
----------------------------------------
Eval num_timesteps=2820000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1         |
| time/                   |            |
|    total_timesteps      | 2820000    |
| train/                  |            |
|    approx_kl            | 0.12635921 |
|    clip_fraction        | 0.353      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.368     |
|    explained_variance   | 0.755      |
|    learning_rate        | 0.00145    |
|    loss                 | -0.00335   |
|    n_updates            | 13760      |
|    policy_gradient_loss | 0.0112     |
|    std                  | 0.292      |
|    value_loss           | 0.00974    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 626     |
|    iterations      | 1377    |
|    time_elapsed    | 4498    |
|    total_timesteps | 2820096 |
--------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 626       |
|    iterations           | 1378      |
|    time_elapsed         | 4501      |
|    total_timesteps      | 2822144   |
| train/                  |           |
|    approx_kl            | 0.4477819 |
|    clip_fraction        | 0.438     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.347    |
|    explained_variance   | 0.706     |
|    learning_rate        | 0.00145   |
|    loss                 | -0.0198   |
|    n_updates            | 13770     |
|    policy_gradient_loss | 0.00238   |
|    std                  | 0.284     |
|    value_loss           | 0.0419    |
---------------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 627        |
|    iterations           | 1379       |
|    time_elapsed         | 4504       |
|    total_timesteps      | 2824192    |
| train/                  |            |
|    approx_kl            | 0.32230672 |
|    clip_fraction        | 0.463      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.307     |
|    explained_variance   | 0.781      |
|    learning_rate        | 0.00145    |
|    loss                 | 0.00257    |
|    n_updates            | 13780      |
|    policy_gradient_loss | 0.00927    |
|    std                  | 0.282      |
|    value_loss           | 0.0298     |
----------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 627       |
|    iterations           | 1380      |
|    time_elapsed         | 4507      |
|    total_timesteps      | 2826240   |
| train/                  |           |
|    approx_kl            | 0.2685733 |
|    clip_fraction        | 0.448     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.295    |
|    explained_variance   | 0.801     |
|    learning_rate        | 0.00145   |
|    loss                 | -0.0143   |
|    n_updates            | 13790     |
|    policy_gradient_loss | 0.00337   |
|    std                  | 0.28      |
|    value_loss           | 0.0308    |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 627        |
|    iterations           | 1381       |
|    time_elapsed         | 4510       |
|    total_timesteps      | 2828288    |
| train/                  |            |
|    approx_kl            | 0.18043876 |
|    clip_fraction        | 0.375      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.321     |
|    explained_variance   | 0.839      |
|    learning_rate        | 0.00145    |
|    loss                 | -0.0415    |
|    n_updates            | 13800      |
|    policy_gradient_loss | 0.0101     |
|    std                  | 0.284      |
|    value_loss           | 0.023      |
----------------------------------------
box reached target
Eval num_timesteps=2830000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 300       |
|    mean_reward          | -1        |
| time/                   |           |
|    total_timesteps      | 2830000   |
| train/                  |           |
|    approx_kl            | 0.2526657 |
|    clip_fraction        | 0.409     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.345    |
|    explained_variance   | 0.701     |
|    learning_rate        | 0.00145   |
|    loss                 | -0.028    |
|    n_updates            | 13810     |
|    policy_gradient_loss | 0.0146    |
|    std                  | 0.287     |
|    value_loss           | 0.00479   |
---------------------------------------
--------------------------------
| time/              |         |
|    fps             | 626     |
|    iterations      | 1382    |
|    time_elapsed    | 4514    |
|    total_timesteps | 2830336 |
--------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 627        |
|    iterations           | 1383       |
|    time_elapsed         | 4517       |
|    total_timesteps      | 2832384    |
| train/                  |            |
|    approx_kl            | 0.24439636 |
|    clip_fraction        | 0.451      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.32      |
|    explained_variance   | 0.602      |
|    learning_rate        | 0.00145    |
|    loss                 | 0.00147    |
|    n_updates            | 13820      |
|    policy_gradient_loss | 0.00189    |
|    std                  | 0.285      |
|    value_loss           | 0.0305     |
----------------------------------------
box reached target
box reached target
box reached target
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 627        |
|    iterations           | 1384       |
|    time_elapsed         | 4520       |
|    total_timesteps      | 2834432    |
| train/                  |            |
|    approx_kl            | 0.16456538 |
|    clip_fraction        | 0.44       |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.295     |
|    explained_variance   | 0.909      |
|    learning_rate        | 0.00145    |
|    loss                 | -0.0574    |
|    n_updates            | 13830      |
|    policy_gradient_loss | 0.00765    |
|    std                  | 0.282      |
|    value_loss           | 0.0153     |
----------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 627       |
|    iterations           | 1385      |
|    time_elapsed         | 4523      |
|    total_timesteps      | 2836480   |
| train/                  |           |
|    approx_kl            | 0.1427859 |
|    clip_fraction        | 0.411     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.301    |
|    explained_variance   | 0.715     |
|    learning_rate        | 0.00145   |
|    loss                 | 0.0203    |
|    n_updates            | 13840     |
|    policy_gradient_loss | 0.0183    |
|    std                  | 0.285     |
|    value_loss           | 0.0451    |
---------------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 627        |
|    iterations           | 1386       |
|    time_elapsed         | 4526       |
|    total_timesteps      | 2838528    |
| train/                  |            |
|    approx_kl            | 0.40614787 |
|    clip_fraction        | 0.443      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.283     |
|    explained_variance   | 0.717      |
|    learning_rate        | 0.00145    |
|    loss                 | -0.0147    |
|    n_updates            | 13850      |
|    policy_gradient_loss | 0.0163     |
|    std                  | 0.281      |
|    value_loss           | 0.0357     |
----------------------------------------
box reached target
box reached target
Eval num_timesteps=2840000, episode_reward=-0.79 +/- 0.41
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -0.795     |
| time/                   |            |
|    total_timesteps      | 2840000    |
| train/                  |            |
|    approx_kl            | 0.13092211 |
|    clip_fraction        | 0.376      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.275     |
|    explained_variance   | 0.921      |
|    learning_rate        | 0.00145    |
|    loss                 | -0.00254   |
|    n_updates            | 13860      |
|    policy_gradient_loss | 0.0035     |
|    std                  | 0.282      |
|    value_loss           | 0.00778    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 626     |
|    iterations      | 1387    |
|    time_elapsed    | 4530    |
|    total_timesteps | 2840576 |
--------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 627       |
|    iterations           | 1388      |
|    time_elapsed         | 4533      |
|    total_timesteps      | 2842624   |
| train/                  |           |
|    approx_kl            | 0.9582614 |
|    clip_fraction        | 0.46      |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.273    |
|    explained_variance   | 0.742     |
|    learning_rate        | 0.00145   |
|    loss                 | -0.0465   |
|    n_updates            | 13870     |
|    policy_gradient_loss | -0.00675  |
|    std                  | 0.28      |
|    value_loss           | 0.0233    |
---------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 627        |
|    iterations           | 1389       |
|    time_elapsed         | 4536       |
|    total_timesteps      | 2844672    |
| train/                  |            |
|    approx_kl            | 0.26523176 |
|    clip_fraction        | 0.397      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.269     |
|    explained_variance   | 0.78       |
|    learning_rate        | 0.00145    |
|    loss                 | -0.00896   |
|    n_updates            | 13880      |
|    policy_gradient_loss | 0.0115     |
|    std                  | 0.284      |
|    value_loss           | 0.00628    |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 627        |
|    iterations           | 1390       |
|    time_elapsed         | 4539       |
|    total_timesteps      | 2846720    |
| train/                  |            |
|    approx_kl            | 0.11457573 |
|    clip_fraction        | 0.356      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.345     |
|    explained_variance   | 0.912      |
|    learning_rate        | 0.00145    |
|    loss                 | -0.0275    |
|    n_updates            | 13890      |
|    policy_gradient_loss | 0.00119    |
|    std                  | 0.294      |
|    value_loss           | 0.00727    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 627        |
|    iterations           | 1391       |
|    time_elapsed         | 4542       |
|    total_timesteps      | 2848768    |
| train/                  |            |
|    approx_kl            | 0.23353666 |
|    clip_fraction        | 0.427      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.352     |
|    explained_variance   | 0.645      |
|    learning_rate        | 0.00144    |
|    loss                 | 0.0131     |
|    n_updates            | 13900      |
|    policy_gradient_loss | 0.00508    |
|    std                  | 0.289      |
|    value_loss           | 0.0451     |
----------------------------------------
box reached target
box reached target
Eval num_timesteps=2850000, episode_reward=0.21 +/- 2.43
Episode length: 274.00 +/- 52.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 274       |
|    mean_reward          | 0.213     |
| time/                   |           |
|    total_timesteps      | 2850000   |
| train/                  |           |
|    approx_kl            | 2.4979029 |
|    clip_fraction        | 0.5       |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.32     |
|    explained_variance   | 0.66      |
|    learning_rate        | 0.00144   |
|    loss                 | -0.0195   |
|    n_updates            | 13910     |
|    policy_gradient_loss | 0.0482    |
|    std                  | 0.284     |
|    value_loss           | 0.0106    |
---------------------------------------
box reached target
--------------------------------
| time/              |         |
|    fps             | 627     |
|    iterations      | 1392    |
|    time_elapsed    | 4546    |
|    total_timesteps | 2850816 |
--------------------------------
box reached target
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 627       |
|    iterations           | 1393      |
|    time_elapsed         | 4549      |
|    total_timesteps      | 2852864   |
| train/                  |           |
|    approx_kl            | 0.2033551 |
|    clip_fraction        | 0.393     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.338    |
|    explained_variance   | 0.724     |
|    learning_rate        | 0.00144   |
|    loss                 | -0.03     |
|    n_updates            | 13920     |
|    policy_gradient_loss | 0.00206   |
|    std                  | 0.292     |
|    value_loss           | 0.0243    |
---------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 627       |
|    iterations           | 1394      |
|    time_elapsed         | 4552      |
|    total_timesteps      | 2854912   |
| train/                  |           |
|    approx_kl            | 1.2368083 |
|    clip_fraction        | 0.511     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.34     |
|    explained_variance   | 0.851     |
|    learning_rate        | 0.00144   |
|    loss                 | -2.94e-05 |
|    n_updates            | 13930     |
|    policy_gradient_loss | 0.00941   |
|    std                  | 0.288     |
|    value_loss           | 0.0131    |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 627        |
|    iterations           | 1395       |
|    time_elapsed         | 4555       |
|    total_timesteps      | 2856960    |
| train/                  |            |
|    approx_kl            | 0.10284973 |
|    clip_fraction        | 0.426      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.361     |
|    explained_variance   | 0.715      |
|    learning_rate        | 0.00144    |
|    loss                 | -0.0308    |
|    n_updates            | 13940      |
|    policy_gradient_loss | 0.0184     |
|    std                  | 0.294      |
|    value_loss           | 0.0307     |
----------------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 627        |
|    iterations           | 1396       |
|    time_elapsed         | 4558       |
|    total_timesteps      | 2859008    |
| train/                  |            |
|    approx_kl            | 0.18227482 |
|    clip_fraction        | 0.377      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.457     |
|    explained_variance   | 0.824      |
|    learning_rate        | 0.00144    |
|    loss                 | -0.00646   |
|    n_updates            | 13950      |
|    policy_gradient_loss | 0.0184     |
|    std                  | 0.31       |
|    value_loss           | 0.0119     |
----------------------------------------
box reached target
Eval num_timesteps=2860000, episode_reward=0.30 +/- 2.59
Episode length: 276.40 +/- 47.20
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 276       |
|    mean_reward          | 0.296     |
| time/                   |           |
|    total_timesteps      | 2860000   |
| train/                  |           |
|    approx_kl            | 0.2419706 |
|    clip_fraction        | 0.409     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.466    |
|    explained_variance   | 0.696     |
|    learning_rate        | 0.00144   |
|    loss                 | 0.0944    |
|    n_updates            | 13960     |
|    policy_gradient_loss | 0.0118    |
|    std                  | 0.31      |
|    value_loss           | 0.0261    |
---------------------------------------
--------------------------------
| time/              |         |
|    fps             | 627     |
|    iterations      | 1397    |
|    time_elapsed    | 4562    |
|    total_timesteps | 2861056 |
--------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 627        |
|    iterations           | 1398       |
|    time_elapsed         | 4565       |
|    total_timesteps      | 2863104    |
| train/                  |            |
|    approx_kl            | 0.26520786 |
|    clip_fraction        | 0.42       |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.518     |
|    explained_variance   | 0.788      |
|    learning_rate        | 0.00144    |
|    loss                 | -0.0234    |
|    n_updates            | 13970      |
|    policy_gradient_loss | -0.00542   |
|    std                  | 0.313      |
|    value_loss           | 0.0035     |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 627        |
|    iterations           | 1399       |
|    time_elapsed         | 4568       |
|    total_timesteps      | 2865152    |
| train/                  |            |
|    approx_kl            | 0.09546649 |
|    clip_fraction        | 0.362      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.55      |
|    explained_variance   | 0.764      |
|    learning_rate        | 0.00144    |
|    loss                 | 0.00677    |
|    n_updates            | 13980      |
|    policy_gradient_loss | 0.00608    |
|    std                  | 0.325      |
|    value_loss           | 0.0335     |
----------------------------------------
box reached target
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 627        |
|    iterations           | 1400       |
|    time_elapsed         | 4571       |
|    total_timesteps      | 2867200    |
| train/                  |            |
|    approx_kl            | 0.19622065 |
|    clip_fraction        | 0.431      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.61      |
|    explained_variance   | 0.52       |
|    learning_rate        | 0.00144    |
|    loss                 | -0.0161    |
|    n_updates            | 13990      |
|    policy_gradient_loss | 0.0187     |
|    std                  | 0.329      |
|    value_loss           | 0.0472     |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 627        |
|    iterations           | 1401       |
|    time_elapsed         | 4574       |
|    total_timesteps      | 2869248    |
| train/                  |            |
|    approx_kl            | 0.09339192 |
|    clip_fraction        | 0.37       |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.615     |
|    explained_variance   | 0.805      |
|    learning_rate        | 0.00144    |
|    loss                 | -0.00853   |
|    n_updates            | 14000      |
|    policy_gradient_loss | 0.0136     |
|    std                  | 0.333      |
|    value_loss           | 0.0239     |
----------------------------------------
box reached target
box reached target
box reached target
Eval num_timesteps=2870000, episode_reward=0.35 +/- 2.44
Episode length: 285.40 +/- 29.20
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 285        |
|    mean_reward          | 0.345      |
| time/                   |            |
|    total_timesteps      | 2870000    |
| train/                  |            |
|    approx_kl            | 0.30981684 |
|    clip_fraction        | 0.422      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.594     |
|    explained_variance   | 0.708      |
|    learning_rate        | 0.00144    |
|    loss                 | -0.0165    |
|    n_updates            | 14010      |
|    policy_gradient_loss | -0.00219   |
|    std                  | 0.324      |
|    value_loss           | 0.0134     |
----------------------------------------
box reached target
--------------------------------
| time/              |         |
|    fps             | 627     |
|    iterations      | 1402    |
|    time_elapsed    | 4578    |
|    total_timesteps | 2871296 |
--------------------------------
box reached target
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 627        |
|    iterations           | 1403       |
|    time_elapsed         | 4581       |
|    total_timesteps      | 2873344    |
| train/                  |            |
|    approx_kl            | 0.19272788 |
|    clip_fraction        | 0.428      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.538     |
|    explained_variance   | 0.639      |
|    learning_rate        | 0.00144    |
|    loss                 | 0.00467    |
|    n_updates            | 14020      |
|    policy_gradient_loss | 0.00608    |
|    std                  | 0.312      |
|    value_loss           | 0.0412     |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 627        |
|    iterations           | 1404       |
|    time_elapsed         | 4584       |
|    total_timesteps      | 2875392    |
| train/                  |            |
|    approx_kl            | 0.22800359 |
|    clip_fraction        | 0.484      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.527     |
|    explained_variance   | 0.833      |
|    learning_rate        | 0.00144    |
|    loss                 | 0.025      |
|    n_updates            | 14030      |
|    policy_gradient_loss | 0.0184     |
|    std                  | 0.318      |
|    value_loss           | 0.036      |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 627        |
|    iterations           | 1405       |
|    time_elapsed         | 4587       |
|    total_timesteps      | 2877440    |
| train/                  |            |
|    approx_kl            | 0.07236737 |
|    clip_fraction        | 0.321      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.526     |
|    explained_variance   | 0.784      |
|    learning_rate        | 0.00144    |
|    loss                 | 0.0943     |
|    n_updates            | 14040      |
|    policy_gradient_loss | 0.00502    |
|    std                  | 0.316      |
|    value_loss           | 0.0174     |
----------------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 627        |
|    iterations           | 1406       |
|    time_elapsed         | 4590       |
|    total_timesteps      | 2879488    |
| train/                  |            |
|    approx_kl            | 0.14454618 |
|    clip_fraction        | 0.41       |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.488     |
|    explained_variance   | 0.771      |
|    learning_rate        | 0.00144    |
|    loss                 | 0.00676    |
|    n_updates            | 14050      |
|    policy_gradient_loss | 0.00511    |
|    std                  | 0.31       |
|    value_loss           | 0.0173     |
----------------------------------------
Eval num_timesteps=2880000, episode_reward=-0.85 +/- 0.22
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -0.854     |
| time/                   |            |
|    total_timesteps      | 2880000    |
| train/                  |            |
|    approx_kl            | 0.13575864 |
|    clip_fraction        | 0.368      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.47      |
|    explained_variance   | 0.618      |
|    learning_rate        | 0.00144    |
|    loss                 | 0.0204     |
|    n_updates            | 14060      |
|    policy_gradient_loss | 0.00781    |
|    std                  | 0.305      |
|    value_loss           | 0.0168     |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 627     |
|    iterations      | 1407    |
|    time_elapsed    | 4594    |
|    total_timesteps | 2881536 |
--------------------------------
box reached target
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 627         |
|    iterations           | 1408        |
|    time_elapsed         | 4597        |
|    total_timesteps      | 2883584     |
| train/                  |             |
|    approx_kl            | 0.097363606 |
|    clip_fraction        | 0.393       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.501      |
|    explained_variance   | 0.436       |
|    learning_rate        | 0.00144     |
|    loss                 | -0.0035     |
|    n_updates            | 14070       |
|    policy_gradient_loss | 0.00564     |
|    std                  | 0.315       |
|    value_loss           | 0.012       |
-----------------------------------------
box reached target
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 627        |
|    iterations           | 1409       |
|    time_elapsed         | 4600       |
|    total_timesteps      | 2885632    |
| train/                  |            |
|    approx_kl            | 0.16084474 |
|    clip_fraction        | 0.398      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.504     |
|    explained_variance   | 0.725      |
|    learning_rate        | 0.00144    |
|    loss                 | 0.0877     |
|    n_updates            | 14080      |
|    policy_gradient_loss | 0.00334    |
|    std                  | 0.308      |
|    value_loss           | 0.0476     |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 627        |
|    iterations           | 1410       |
|    time_elapsed         | 4603       |
|    total_timesteps      | 2887680    |
| train/                  |            |
|    approx_kl            | 0.14134641 |
|    clip_fraction        | 0.374      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.47      |
|    explained_variance   | 0.836      |
|    learning_rate        | 0.00144    |
|    loss                 | 0.103      |
|    n_updates            | 14090      |
|    policy_gradient_loss | 0.0214     |
|    std                  | 0.306      |
|    value_loss           | 0.0213     |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 627        |
|    iterations           | 1411       |
|    time_elapsed         | 4606       |
|    total_timesteps      | 2889728    |
| train/                  |            |
|    approx_kl            | 0.23156476 |
|    clip_fraction        | 0.384      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.422     |
|    explained_variance   | 0.775      |
|    learning_rate        | 0.00144    |
|    loss                 | 0.0219     |
|    n_updates            | 14100      |
|    policy_gradient_loss | 0.00709    |
|    std                  | 0.294      |
|    value_loss           | 0.00554    |
----------------------------------------
box reached target
box reached target
Eval num_timesteps=2890000, episode_reward=1.50 +/- 3.06
Episode length: 258.20 +/- 51.27
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 258        |
|    mean_reward          | 1.5        |
| time/                   |            |
|    total_timesteps      | 2890000    |
| train/                  |            |
|    approx_kl            | 0.13921228 |
|    clip_fraction        | 0.41       |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.397     |
|    explained_variance   | 0.481      |
|    learning_rate        | 0.00144    |
|    loss                 | 0.0276     |
|    n_updates            | 14110      |
|    policy_gradient_loss | 0.0103     |
|    std                  | 0.299      |
|    value_loss           | 0.00522    |
----------------------------------------
box reached target
--------------------------------
| time/              |         |
|    fps             | 627     |
|    iterations      | 1412    |
|    time_elapsed    | 4610    |
|    total_timesteps | 2891776 |
--------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 627        |
|    iterations           | 1413       |
|    time_elapsed         | 4613       |
|    total_timesteps      | 2893824    |
| train/                  |            |
|    approx_kl            | 0.27391994 |
|    clip_fraction        | 0.415      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.448     |
|    explained_variance   | 0.56       |
|    learning_rate        | 0.00144    |
|    loss                 | -0.0292    |
|    n_updates            | 14120      |
|    policy_gradient_loss | 0.00245    |
|    std                  | 0.303      |
|    value_loss           | 0.0159     |
----------------------------------------
box reached target
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 627         |
|    iterations           | 1414        |
|    time_elapsed         | 4616        |
|    total_timesteps      | 2895872     |
| train/                  |             |
|    approx_kl            | 0.080186844 |
|    clip_fraction        | 0.334       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.476      |
|    explained_variance   | 0.825       |
|    learning_rate        | 0.00144     |
|    loss                 | -0.0175     |
|    n_updates            | 14130       |
|    policy_gradient_loss | 0.00157     |
|    std                  | 0.308       |
|    value_loss           | 0.0125      |
-----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 627        |
|    iterations           | 1415       |
|    time_elapsed         | 4619       |
|    total_timesteps      | 2897920    |
| train/                  |            |
|    approx_kl            | 0.13079754 |
|    clip_fraction        | 0.375      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.461     |
|    explained_variance   | 0.901      |
|    learning_rate        | 0.00144    |
|    loss                 | -0.033     |
|    n_updates            | 14140      |
|    policy_gradient_loss | 0.00054    |
|    std                  | 0.307      |
|    value_loss           | 0.00927    |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 627        |
|    iterations           | 1416       |
|    time_elapsed         | 4622       |
|    total_timesteps      | 2899968    |
| train/                  |            |
|    approx_kl            | 0.25437656 |
|    clip_fraction        | 0.415      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.547     |
|    explained_variance   | 0.566      |
|    learning_rate        | 0.00143    |
|    loss                 | 0.041      |
|    n_updates            | 14150      |
|    policy_gradient_loss | 0.0152     |
|    std                  | 0.327      |
|    value_loss           | 0.0247     |
----------------------------------------
box reached target
Eval num_timesteps=2900000, episode_reward=0.27 +/- 2.54
Episode length: 274.40 +/- 51.20
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 274        |
|    mean_reward          | 0.269      |
| time/                   |            |
|    total_timesteps      | 2900000    |
| train/                  |            |
|    approx_kl            | 0.09975837 |
|    clip_fraction        | 0.386      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.589     |
|    explained_variance   | 0.492      |
|    learning_rate        | 0.00143    |
|    loss                 | -0.0261    |
|    n_updates            | 14160      |
|    policy_gradient_loss | 0.00248    |
|    std                  | 0.327      |
|    value_loss           | 0.0133     |
----------------------------------------
box reached target
--------------------------------
| time/              |         |
|    fps             | 627     |
|    iterations      | 1417    |
|    time_elapsed    | 4626    |
|    total_timesteps | 2902016 |
--------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 627        |
|    iterations           | 1418       |
|    time_elapsed         | 4629       |
|    total_timesteps      | 2904064    |
| train/                  |            |
|    approx_kl            | 0.07437761 |
|    clip_fraction        | 0.338      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.595     |
|    explained_variance   | 0.647      |
|    learning_rate        | 0.00143    |
|    loss                 | -0.0309    |
|    n_updates            | 14170      |
|    policy_gradient_loss | 0.00876    |
|    std                  | 0.323      |
|    value_loss           | 0.0182     |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 627        |
|    iterations           | 1419       |
|    time_elapsed         | 4632       |
|    total_timesteps      | 2906112    |
| train/                  |            |
|    approx_kl            | 0.25749087 |
|    clip_fraction        | 0.414      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.565     |
|    explained_variance   | 0.707      |
|    learning_rate        | 0.00143    |
|    loss                 | -0.00402   |
|    n_updates            | 14180      |
|    policy_gradient_loss | 0.00249    |
|    std                  | 0.319      |
|    value_loss           | 0.00851    |
----------------------------------------
box reached target
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 627        |
|    iterations           | 1420       |
|    time_elapsed         | 4635       |
|    total_timesteps      | 2908160    |
| train/                  |            |
|    approx_kl            | 0.24272625 |
|    clip_fraction        | 0.413      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.574     |
|    explained_variance   | 0.764      |
|    learning_rate        | 0.00143    |
|    loss                 | -0.0179    |
|    n_updates            | 14190      |
|    policy_gradient_loss | 0.00809    |
|    std                  | 0.322      |
|    value_loss           | 0.0112     |
----------------------------------------
box reached target
box reached target
Eval num_timesteps=2910000, episode_reward=0.50 +/- 2.44
Episode length: 280.40 +/- 39.20
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 280        |
|    mean_reward          | 0.5        |
| time/                   |            |
|    total_timesteps      | 2910000    |
| train/                  |            |
|    approx_kl            | 0.23959832 |
|    clip_fraction        | 0.379      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.509     |
|    explained_variance   | 0.865      |
|    learning_rate        | 0.00143    |
|    loss                 | -0.0375    |
|    n_updates            | 14200      |
|    policy_gradient_loss | -0.00174   |
|    std                  | 0.305      |
|    value_loss           | 0.0131     |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 627     |
|    iterations      | 1421    |
|    time_elapsed    | 4639    |
|    total_timesteps | 2910208 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 627        |
|    iterations           | 1422       |
|    time_elapsed         | 4642       |
|    total_timesteps      | 2912256    |
| train/                  |            |
|    approx_kl            | 0.10539922 |
|    clip_fraction        | 0.353      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.478     |
|    explained_variance   | 0.965      |
|    learning_rate        | 0.00143    |
|    loss                 | -0.02      |
|    n_updates            | 14210      |
|    policy_gradient_loss | 0.004      |
|    std                  | 0.308      |
|    value_loss           | 0.00306    |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 627        |
|    iterations           | 1423       |
|    time_elapsed         | 4645       |
|    total_timesteps      | 2914304    |
| train/                  |            |
|    approx_kl            | 0.23617211 |
|    clip_fraction        | 0.402      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.49      |
|    explained_variance   | 0.799      |
|    learning_rate        | 0.00143    |
|    loss                 | -0.0283    |
|    n_updates            | 14220      |
|    policy_gradient_loss | 0.0209     |
|    std                  | 0.312      |
|    value_loss           | 0.0146     |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 627        |
|    iterations           | 1424       |
|    time_elapsed         | 4648       |
|    total_timesteps      | 2916352    |
| train/                  |            |
|    approx_kl            | 0.12702447 |
|    clip_fraction        | 0.361      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.496     |
|    explained_variance   | 0.739      |
|    learning_rate        | 0.00143    |
|    loss                 | -0.00506   |
|    n_updates            | 14230      |
|    policy_gradient_loss | 0.0105     |
|    std                  | 0.31       |
|    value_loss           | 0.0383     |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 627        |
|    iterations           | 1425       |
|    time_elapsed         | 4651       |
|    total_timesteps      | 2918400    |
| train/                  |            |
|    approx_kl            | 0.13640162 |
|    clip_fraction        | 0.425      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.5       |
|    explained_variance   | 0.737      |
|    learning_rate        | 0.00143    |
|    loss                 | -0.00282   |
|    n_updates            | 14240      |
|    policy_gradient_loss | 0.0357     |
|    std                  | 0.309      |
|    value_loss           | 0.0151     |
----------------------------------------
box reached target
box reached target
Eval num_timesteps=2920000, episode_reward=1.47 +/- 3.02
Episode length: 244.80 +/- 68.67
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 245       |
|    mean_reward          | 1.47      |
| time/                   |           |
|    total_timesteps      | 2920000   |
| train/                  |           |
|    approx_kl            | 0.1263667 |
|    clip_fraction        | 0.379     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.434    |
|    explained_variance   | 0.522     |
|    learning_rate        | 0.00143   |
|    loss                 | -0.000176 |
|    n_updates            | 14250     |
|    policy_gradient_loss | 0.0047    |
|    std                  | 0.297     |
|    value_loss           | 0.0269    |
---------------------------------------
--------------------------------
| time/              |         |
|    fps             | 627     |
|    iterations      | 1426    |
|    time_elapsed    | 4655    |
|    total_timesteps | 2920448 |
--------------------------------
box reached target
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 627       |
|    iterations           | 1427      |
|    time_elapsed         | 4658      |
|    total_timesteps      | 2922496   |
| train/                  |           |
|    approx_kl            | 0.3053263 |
|    clip_fraction        | 0.356     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.38     |
|    explained_variance   | 0.693     |
|    learning_rate        | 0.00143   |
|    loss                 | 0.0126    |
|    n_updates            | 14260     |
|    policy_gradient_loss | 0.0036    |
|    std                  | 0.29      |
|    value_loss           | 0.00875   |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 627        |
|    iterations           | 1428       |
|    time_elapsed         | 4661       |
|    total_timesteps      | 2924544    |
| train/                  |            |
|    approx_kl            | 0.16435292 |
|    clip_fraction        | 0.404      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.326     |
|    explained_variance   | 0.415      |
|    learning_rate        | 0.00143    |
|    loss                 | 0.00476    |
|    n_updates            | 14270      |
|    policy_gradient_loss | 0.00398    |
|    std                  | 0.284      |
|    value_loss           | 0.0806     |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 627        |
|    iterations           | 1429       |
|    time_elapsed         | 4664       |
|    total_timesteps      | 2926592    |
| train/                  |            |
|    approx_kl            | 0.08493184 |
|    clip_fraction        | 0.385      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.31      |
|    explained_variance   | 0.733      |
|    learning_rate        | 0.00143    |
|    loss                 | -0.0139    |
|    n_updates            | 14280      |
|    policy_gradient_loss | 0.0166     |
|    std                  | 0.283      |
|    value_loss           | 0.0119     |
----------------------------------------
--------------------------------------
| time/                   |          |
|    fps                  | 627      |
|    iterations           | 1430     |
|    time_elapsed         | 4667     |
|    total_timesteps      | 2928640  |
| train/                  |          |
|    approx_kl            | 0.630242 |
|    clip_fraction        | 0.459    |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.305   |
|    explained_variance   | 0.678    |
|    learning_rate        | 0.00143  |
|    loss                 | -0.0399  |
|    n_updates            | 14290    |
|    policy_gradient_loss | 0.0177   |
|    std                  | 0.283    |
|    value_loss           | 0.0101   |
--------------------------------------
Eval num_timesteps=2930000, episode_reward=-0.68 +/- 0.57
Episode length: 300.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 300       |
|    mean_reward          | -0.675    |
| time/                   |           |
|    total_timesteps      | 2930000   |
| train/                  |           |
|    approx_kl            | 0.3090251 |
|    clip_fraction        | 0.398     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.268    |
|    explained_variance   | 0.756     |
|    learning_rate        | 0.00143   |
|    loss                 | 0.0633    |
|    n_updates            | 14300     |
|    policy_gradient_loss | 0.00748   |
|    std                  | 0.278     |
|    value_loss           | 0.0073    |
---------------------------------------
--------------------------------
| time/              |         |
|    fps             | 627     |
|    iterations      | 1431    |
|    time_elapsed    | 4671    |
|    total_timesteps | 2930688 |
--------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 627        |
|    iterations           | 1432       |
|    time_elapsed         | 4674       |
|    total_timesteps      | 2932736    |
| train/                  |            |
|    approx_kl            | 0.15462533 |
|    clip_fraction        | 0.376      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.299     |
|    explained_variance   | 0.758      |
|    learning_rate        | 0.00143    |
|    loss                 | -0.00362   |
|    n_updates            | 14310      |
|    policy_gradient_loss | 0.00924    |
|    std                  | 0.283      |
|    value_loss           | 0.00749    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 627        |
|    iterations           | 1433       |
|    time_elapsed         | 4677       |
|    total_timesteps      | 2934784    |
| train/                  |            |
|    approx_kl            | 0.19536775 |
|    clip_fraction        | 0.447      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.349     |
|    explained_variance   | -0.0994    |
|    learning_rate        | 0.00143    |
|    loss                 | -0.0235    |
|    n_updates            | 14320      |
|    policy_gradient_loss | 0.00721    |
|    std                  | 0.296      |
|    value_loss           | 0.0205     |
----------------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 627         |
|    iterations           | 1434        |
|    time_elapsed         | 4680        |
|    total_timesteps      | 2936832     |
| train/                  |             |
|    approx_kl            | 0.116812974 |
|    clip_fraction        | 0.421       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.376      |
|    explained_variance   | 0.782       |
|    learning_rate        | 0.00143     |
|    loss                 | 0.011       |
|    n_updates            | 14330       |
|    policy_gradient_loss | 0.015       |
|    std                  | 0.293       |
|    value_loss           | 0.00872     |
-----------------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 627        |
|    iterations           | 1435       |
|    time_elapsed         | 4683       |
|    total_timesteps      | 2938880    |
| train/                  |            |
|    approx_kl            | 0.36186063 |
|    clip_fraction        | 0.429      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.374     |
|    explained_variance   | 0.501      |
|    learning_rate        | 0.00143    |
|    loss                 | -0.0123    |
|    n_updates            | 14340      |
|    policy_gradient_loss | 0.00349    |
|    std                  | 0.297      |
|    value_loss           | 0.021      |
----------------------------------------
Eval num_timesteps=2940000, episode_reward=-1.03 +/- 0.14
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1.03      |
| time/                   |            |
|    total_timesteps      | 2940000    |
| train/                  |            |
|    approx_kl            | 0.11840801 |
|    clip_fraction        | 0.375      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.388     |
|    explained_variance   | 0.73       |
|    learning_rate        | 0.00143    |
|    loss                 | 0.0744     |
|    n_updates            | 14350      |
|    policy_gradient_loss | 0.00984    |
|    std                  | 0.292      |
|    value_loss           | 0.0101     |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 627     |
|    iterations      | 1436    |
|    time_elapsed    | 4687    |
|    total_timesteps | 2940928 |
--------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 627        |
|    iterations           | 1437       |
|    time_elapsed         | 4690       |
|    total_timesteps      | 2942976    |
| train/                  |            |
|    approx_kl            | 0.44085324 |
|    clip_fraction        | 0.512      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.382     |
|    explained_variance   | 0.0942     |
|    learning_rate        | 0.00143    |
|    loss                 | 0.0773     |
|    n_updates            | 14360      |
|    policy_gradient_loss | 0.032      |
|    std                  | 0.299      |
|    value_loss           | 0.00288    |
----------------------------------------
box reached target
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 627         |
|    iterations           | 1438        |
|    time_elapsed         | 4694        |
|    total_timesteps      | 2945024     |
| train/                  |             |
|    approx_kl            | 0.115502805 |
|    clip_fraction        | 0.419       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.417      |
|    explained_variance   | 0.747       |
|    learning_rate        | 0.00143     |
|    loss                 | 0.0319      |
|    n_updates            | 14370       |
|    policy_gradient_loss | 0.0184      |
|    std                  | 0.297       |
|    value_loss           | 0.00797     |
-----------------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 627         |
|    iterations           | 1439        |
|    time_elapsed         | 4697        |
|    total_timesteps      | 2947072     |
| train/                  |             |
|    approx_kl            | 0.100610085 |
|    clip_fraction        | 0.375       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.415      |
|    explained_variance   | 0.754       |
|    learning_rate        | 0.00143     |
|    loss                 | 0.0247      |
|    n_updates            | 14380       |
|    policy_gradient_loss | 0.00962     |
|    std                  | 0.299       |
|    value_loss           | 0.0176      |
-----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 627        |
|    iterations           | 1440       |
|    time_elapsed         | 4700       |
|    total_timesteps      | 2949120    |
| train/                  |            |
|    approx_kl            | 0.06841687 |
|    clip_fraction        | 0.348      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.451     |
|    explained_variance   | 0.817      |
|    learning_rate        | 0.00143    |
|    loss                 | 0.0344     |
|    n_updates            | 14390      |
|    policy_gradient_loss | 0.0152     |
|    std                  | 0.305      |
|    value_loss           | 0.00812    |
----------------------------------------
box reached target
box reached target
box reached target
Eval num_timesteps=2950000, episode_reward=1.43 +/- 3.00
Episode length: 245.20 +/- 67.16
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 245       |
|    mean_reward          | 1.43      |
| time/                   |           |
|    total_timesteps      | 2950000   |
| train/                  |           |
|    approx_kl            | 0.1775415 |
|    clip_fraction        | 0.395     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.473    |
|    explained_variance   | 0.842     |
|    learning_rate        | 0.00142   |
|    loss                 | -0.0121   |
|    n_updates            | 14400     |
|    policy_gradient_loss | 0.00409   |
|    std                  | 0.307     |
|    value_loss           | 0.00424   |
---------------------------------------
box reached target
--------------------------------
| time/              |         |
|    fps             | 627     |
|    iterations      | 1441    |
|    time_elapsed    | 4703    |
|    total_timesteps | 2951168 |
--------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 627        |
|    iterations           | 1442       |
|    time_elapsed         | 4706       |
|    total_timesteps      | 2953216    |
| train/                  |            |
|    approx_kl            | 0.15208271 |
|    clip_fraction        | 0.38       |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.471     |
|    explained_variance   | 0.876      |
|    learning_rate        | 0.00142    |
|    loss                 | 0.00648    |
|    n_updates            | 14410      |
|    policy_gradient_loss | 0.00407    |
|    std                  | 0.309      |
|    value_loss           | 0.00893    |
----------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 627       |
|    iterations           | 1443      |
|    time_elapsed         | 4709      |
|    total_timesteps      | 2955264   |
| train/                  |           |
|    approx_kl            | 0.3974719 |
|    clip_fraction        | 0.453     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.551    |
|    explained_variance   | 0.873     |
|    learning_rate        | 0.00142   |
|    loss                 | -0.0207   |
|    n_updates            | 14420     |
|    policy_gradient_loss | 0.0153    |
|    std                  | 0.322     |
|    value_loss           | 0.0139    |
---------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 627       |
|    iterations           | 1444      |
|    time_elapsed         | 4713      |
|    total_timesteps      | 2957312   |
| train/                  |           |
|    approx_kl            | 0.4783931 |
|    clip_fraction        | 0.364     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.625    |
|    explained_variance   | 0.725     |
|    learning_rate        | 0.00142   |
|    loss                 | -0.00202  |
|    n_updates            | 14430     |
|    policy_gradient_loss | 0.0238    |
|    std                  | 0.335     |
|    value_loss           | 0.014     |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 627        |
|    iterations           | 1445       |
|    time_elapsed         | 4716       |
|    total_timesteps      | 2959360    |
| train/                  |            |
|    approx_kl            | 0.09312908 |
|    clip_fraction        | 0.367      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.667     |
|    explained_variance   | 0.572      |
|    learning_rate        | 0.00142    |
|    loss                 | 0.018      |
|    n_updates            | 14440      |
|    policy_gradient_loss | 0.00433    |
|    std                  | 0.34       |
|    value_loss           | 0.0116     |
----------------------------------------
box reached target
Eval num_timesteps=2960000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1         |
| time/                   |            |
|    total_timesteps      | 2960000    |
| train/                  |            |
|    approx_kl            | 0.11568994 |
|    clip_fraction        | 0.343      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.705     |
|    explained_variance   | 0.682      |
|    learning_rate        | 0.00142    |
|    loss                 | 0.0113     |
|    n_updates            | 14450      |
|    policy_gradient_loss | 0.00516    |
|    std                  | 0.34       |
|    value_loss           | 0.00833    |
----------------------------------------
box reached target
--------------------------------
| time/              |         |
|    fps             | 627     |
|    iterations      | 1446    |
|    time_elapsed    | 4720    |
|    total_timesteps | 2961408 |
--------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 627        |
|    iterations           | 1447       |
|    time_elapsed         | 4723       |
|    total_timesteps      | 2963456    |
| train/                  |            |
|    approx_kl            | 0.08951028 |
|    clip_fraction        | 0.374      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.637     |
|    explained_variance   | 0.888      |
|    learning_rate        | 0.00142    |
|    loss                 | -0.0183    |
|    n_updates            | 14460      |
|    policy_gradient_loss | 0.00729    |
|    std                  | 0.327      |
|    value_loss           | 0.00879    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 627        |
|    iterations           | 1448       |
|    time_elapsed         | 4726       |
|    total_timesteps      | 2965504    |
| train/                  |            |
|    approx_kl            | 0.43538982 |
|    clip_fraction        | 0.384      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.575     |
|    explained_variance   | 0.838      |
|    learning_rate        | 0.00142    |
|    loss                 | -0.00733   |
|    n_updates            | 14470      |
|    policy_gradient_loss | 0.0116     |
|    std                  | 0.318      |
|    value_loss           | 0.00939    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 627        |
|    iterations           | 1449       |
|    time_elapsed         | 4729       |
|    total_timesteps      | 2967552    |
| train/                  |            |
|    approx_kl            | 0.13615763 |
|    clip_fraction        | 0.418      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.619     |
|    explained_variance   | 0.548      |
|    learning_rate        | 0.00142    |
|    loss                 | -0.013     |
|    n_updates            | 14480      |
|    policy_gradient_loss | 0.000672   |
|    std                  | 0.332      |
|    value_loss           | 0.00934    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 627        |
|    iterations           | 1450       |
|    time_elapsed         | 4732       |
|    total_timesteps      | 2969600    |
| train/                  |            |
|    approx_kl            | 0.11373438 |
|    clip_fraction        | 0.356      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.622     |
|    explained_variance   | 0.273      |
|    learning_rate        | 0.00142    |
|    loss                 | 0.018      |
|    n_updates            | 14490      |
|    policy_gradient_loss | 0.00315    |
|    std                  | 0.329      |
|    value_loss           | 0.00115    |
----------------------------------------
Eval num_timesteps=2970000, episode_reward=-0.84 +/- 0.22
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -0.841     |
| time/                   |            |
|    total_timesteps      | 2970000    |
| train/                  |            |
|    approx_kl            | 0.13519253 |
|    clip_fraction        | 0.337      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.628     |
|    explained_variance   | 0.766      |
|    learning_rate        | 0.00142    |
|    loss                 | -0.0154    |
|    n_updates            | 14500      |
|    policy_gradient_loss | 0.00423    |
|    std                  | 0.331      |
|    value_loss           | 0.00627    |
----------------------------------------
box reached target
box reached target
--------------------------------
| time/              |         |
|    fps             | 627     |
|    iterations      | 1451    |
|    time_elapsed    | 4736    |
|    total_timesteps | 2971648 |
--------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 627         |
|    iterations           | 1452        |
|    time_elapsed         | 4739        |
|    total_timesteps      | 2973696     |
| train/                  |             |
|    approx_kl            | 0.121171184 |
|    clip_fraction        | 0.359       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.634      |
|    explained_variance   | 0.932       |
|    learning_rate        | 0.00142     |
|    loss                 | -0.0264     |
|    n_updates            | 14510       |
|    policy_gradient_loss | 0.00546     |
|    std                  | 0.329       |
|    value_loss           | 0.00947     |
-----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 627        |
|    iterations           | 1453       |
|    time_elapsed         | 4742       |
|    total_timesteps      | 2975744    |
| train/                  |            |
|    approx_kl            | 0.28353184 |
|    clip_fraction        | 0.342      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.619     |
|    explained_variance   | 0.708      |
|    learning_rate        | 0.00142    |
|    loss                 | -0.0502    |
|    n_updates            | 14520      |
|    policy_gradient_loss | -0.0071    |
|    std                  | 0.327      |
|    value_loss           | 0.0192     |
----------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 627       |
|    iterations           | 1454      |
|    time_elapsed         | 4745      |
|    total_timesteps      | 2977792   |
| train/                  |           |
|    approx_kl            | 0.1524468 |
|    clip_fraction        | 0.358     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.651    |
|    explained_variance   | 0.617     |
|    learning_rate        | 0.00142   |
|    loss                 | 0.179     |
|    n_updates            | 14530     |
|    policy_gradient_loss | 0.00197   |
|    std                  | 0.332     |
|    value_loss           | 0.00518   |
---------------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 627        |
|    iterations           | 1455       |
|    time_elapsed         | 4748       |
|    total_timesteps      | 2979840    |
| train/                  |            |
|    approx_kl            | 0.16407625 |
|    clip_fraction        | 0.37       |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.618     |
|    explained_variance   | 0.873      |
|    learning_rate        | 0.00142    |
|    loss                 | -0.0458    |
|    n_updates            | 14540      |
|    policy_gradient_loss | 0.00424    |
|    std                  | 0.327      |
|    value_loss           | 0.00383    |
----------------------------------------
Eval num_timesteps=2980000, episode_reward=-0.57 +/- 0.52
Episode length: 300.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 300         |
|    mean_reward          | -0.573      |
| time/                   |             |
|    total_timesteps      | 2980000     |
| train/                  |             |
|    approx_kl            | 0.101959266 |
|    clip_fraction        | 0.381       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.631      |
|    explained_variance   | 0.916       |
|    learning_rate        | 0.00142     |
|    loss                 | 0.0336      |
|    n_updates            | 14550       |
|    policy_gradient_loss | 0.00405     |
|    std                  | 0.331       |
|    value_loss           | 0.00702     |
-----------------------------------------
box reached target
box reached target
--------------------------------
| time/              |         |
|    fps             | 627     |
|    iterations      | 1456    |
|    time_elapsed    | 4752    |
|    total_timesteps | 2981888 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 627        |
|    iterations           | 1457       |
|    time_elapsed         | 4755       |
|    total_timesteps      | 2983936    |
| train/                  |            |
|    approx_kl            | 0.18906173 |
|    clip_fraction        | 0.363      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.614     |
|    explained_variance   | 0.897      |
|    learning_rate        | 0.00142    |
|    loss                 | 0.0169     |
|    n_updates            | 14560      |
|    policy_gradient_loss | 0.00605    |
|    std                  | 0.328      |
|    value_loss           | 0.00739    |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 627        |
|    iterations           | 1458       |
|    time_elapsed         | 4758       |
|    total_timesteps      | 2985984    |
| train/                  |            |
|    approx_kl            | 0.11793324 |
|    clip_fraction        | 0.422      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.633     |
|    explained_variance   | 0.693      |
|    learning_rate        | 0.00142    |
|    loss                 | -0.0262    |
|    n_updates            | 14570      |
|    policy_gradient_loss | 0.026      |
|    std                  | 0.334      |
|    value_loss           | 0.00258    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 627        |
|    iterations           | 1459       |
|    time_elapsed         | 4761       |
|    total_timesteps      | 2988032    |
| train/                  |            |
|    approx_kl            | 0.10720653 |
|    clip_fraction        | 0.318      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.691     |
|    explained_variance   | 0.792      |
|    learning_rate        | 0.00142    |
|    loss                 | -0.0157    |
|    n_updates            | 14580      |
|    policy_gradient_loss | 0.016      |
|    std                  | 0.344      |
|    value_loss           | 0.0127     |
----------------------------------------
box reached target
box reached target
box reached target
box reached target
box reached target
Eval num_timesteps=2990000, episode_reward=1.54 +/- 3.17
Episode length: 257.40 +/- 52.39
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 257        |
|    mean_reward          | 1.54       |
| time/                   |            |
|    total_timesteps      | 2990000    |
| train/                  |            |
|    approx_kl            | 0.15205613 |
|    clip_fraction        | 0.367      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.702     |
|    explained_variance   | 0.715      |
|    learning_rate        | 0.00142    |
|    loss                 | 0.00495    |
|    n_updates            | 14590      |
|    policy_gradient_loss | -0.000575  |
|    std                  | 0.344      |
|    value_loss           | 0.00963    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 627     |
|    iterations      | 1460    |
|    time_elapsed    | 4765    |
|    total_timesteps | 2990080 |
--------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 627       |
|    iterations           | 1461      |
|    time_elapsed         | 4768      |
|    total_timesteps      | 2992128   |
| train/                  |           |
|    approx_kl            | 0.1861003 |
|    clip_fraction        | 0.414     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.678    |
|    explained_variance   | 0.856     |
|    learning_rate        | 0.00142   |
|    loss                 | -0.000958 |
|    n_updates            | 14600     |
|    policy_gradient_loss | 0.0026    |
|    std                  | 0.338     |
|    value_loss           | 0.0179    |
---------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 627        |
|    iterations           | 1462       |
|    time_elapsed         | 4771       |
|    total_timesteps      | 2994176    |
| train/                  |            |
|    approx_kl            | 0.11962385 |
|    clip_fraction        | 0.334      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.658     |
|    explained_variance   | 0.823      |
|    learning_rate        | 0.00142    |
|    loss                 | -0.00967   |
|    n_updates            | 14610      |
|    policy_gradient_loss | 0.00971    |
|    std                  | 0.335      |
|    value_loss           | 0.00744    |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 627        |
|    iterations           | 1463       |
|    time_elapsed         | 4774       |
|    total_timesteps      | 2996224    |
| train/                  |            |
|    approx_kl            | 0.08250723 |
|    clip_fraction        | 0.379      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.714     |
|    explained_variance   | 0.841      |
|    learning_rate        | 0.00142    |
|    loss                 | -0.00696   |
|    n_updates            | 14620      |
|    policy_gradient_loss | 0.0145     |
|    std                  | 0.35       |
|    value_loss           | 0.0125     |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 627        |
|    iterations           | 1464       |
|    time_elapsed         | 4777       |
|    total_timesteps      | 2998272    |
| train/                  |            |
|    approx_kl            | 0.18478337 |
|    clip_fraction        | 0.339      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.748     |
|    explained_variance   | 0.752      |
|    learning_rate        | 0.00142    |
|    loss                 | -0.0103    |
|    n_updates            | 14630      |
|    policy_gradient_loss | 0.0104     |
|    std                  | 0.347      |
|    value_loss           | 0.0216     |
----------------------------------------
box reached target
box reached target
Eval num_timesteps=3000000, episode_reward=-1.11 +/- 0.15
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1.11      |
| time/                   |            |
|    total_timesteps      | 3000000    |
| train/                  |            |
|    approx_kl            | 0.13256182 |
|    clip_fraction        | 0.366      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.709     |
|    explained_variance   | 0.809      |
|    learning_rate        | 0.00142    |
|    loss                 | 0.0133     |
|    n_updates            | 14640      |
|    policy_gradient_loss | -0.00661   |
|    std                  | 0.34       |
|    value_loss           | 0.002      |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 627     |
|    iterations      | 1465    |
|    time_elapsed    | 4781    |
|    total_timesteps | 3000320 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 627        |
|    iterations           | 1466       |
|    time_elapsed         | 4784       |
|    total_timesteps      | 3002368    |
| train/                  |            |
|    approx_kl            | 0.11247245 |
|    clip_fraction        | 0.426      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.665     |
|    explained_variance   | 0.813      |
|    learning_rate        | 0.00141    |
|    loss                 | -0.0161    |
|    n_updates            | 14650      |
|    policy_gradient_loss | 0.00741    |
|    std                  | 0.336      |
|    value_loss           | 0.00999    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 627        |
|    iterations           | 1467       |
|    time_elapsed         | 4787       |
|    total_timesteps      | 3004416    |
| train/                  |            |
|    approx_kl            | 0.25620303 |
|    clip_fraction        | 0.351      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.641     |
|    explained_variance   | 0.746      |
|    learning_rate        | 0.00141    |
|    loss                 | -0.0259    |
|    n_updates            | 14660      |
|    policy_gradient_loss | 0.00259    |
|    std                  | 0.33       |
|    value_loss           | 0.00402    |
----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 627       |
|    iterations           | 1468      |
|    time_elapsed         | 4790      |
|    total_timesteps      | 3006464   |
| train/                  |           |
|    approx_kl            | 0.2616675 |
|    clip_fraction        | 0.442     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.668    |
|    explained_variance   | 0.575     |
|    learning_rate        | 0.00141   |
|    loss                 | 0.0223    |
|    n_updates            | 14670     |
|    policy_gradient_loss | 0.0148    |
|    std                  | 0.337     |
|    value_loss           | 0.00782   |
---------------------------------------
box reached target
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 627        |
|    iterations           | 1469       |
|    time_elapsed         | 4793       |
|    total_timesteps      | 3008512    |
| train/                  |            |
|    approx_kl            | 0.08744605 |
|    clip_fraction        | 0.331      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.659     |
|    explained_variance   | 0.718      |
|    learning_rate        | 0.00141    |
|    loss                 | -0.0103    |
|    n_updates            | 14680      |
|    policy_gradient_loss | 0.00689    |
|    std                  | 0.331      |
|    value_loss           | 0.00992    |
----------------------------------------
box reached target
box reached target
Eval num_timesteps=3010000, episode_reward=0.53 +/- 2.31
Episode length: 290.40 +/- 19.20
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 290         |
|    mean_reward          | 0.526       |
| time/                   |             |
|    total_timesteps      | 3010000     |
| train/                  |             |
|    approx_kl            | 0.122125834 |
|    clip_fraction        | 0.406       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.624      |
|    explained_variance   | 0.429       |
|    learning_rate        | 0.00141     |
|    loss                 | 0.06        |
|    n_updates            | 14690       |
|    policy_gradient_loss | 0.0196      |
|    std                  | 0.332       |
|    value_loss           | 0.0838      |
-----------------------------------------
box reached target
box reached target
--------------------------------
| time/              |         |
|    fps             | 627     |
|    iterations      | 1470    |
|    time_elapsed    | 4797    |
|    total_timesteps | 3010560 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 627        |
|    iterations           | 1471       |
|    time_elapsed         | 4800       |
|    total_timesteps      | 3012608    |
| train/                  |            |
|    approx_kl            | 0.11250894 |
|    clip_fraction        | 0.387      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.64      |
|    explained_variance   | 0.929      |
|    learning_rate        | 0.00141    |
|    loss                 | -0.0465    |
|    n_updates            | 14700      |
|    policy_gradient_loss | -0.000949  |
|    std                  | 0.334      |
|    value_loss           | 0.0158     |
----------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 627       |
|    iterations           | 1472      |
|    time_elapsed         | 4803      |
|    total_timesteps      | 3014656   |
| train/                  |           |
|    approx_kl            | 0.0819864 |
|    clip_fraction        | 0.335     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.612    |
|    explained_variance   | 0.838     |
|    learning_rate        | 0.00141   |
|    loss                 | -0.0112   |
|    n_updates            | 14710     |
|    policy_gradient_loss | 0.0122    |
|    std                  | 0.326     |
|    value_loss           | 0.00665   |
---------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 627       |
|    iterations           | 1473      |
|    time_elapsed         | 4806      |
|    total_timesteps      | 3016704   |
| train/                  |           |
|    approx_kl            | 0.1350272 |
|    clip_fraction        | 0.421     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.6      |
|    explained_variance   | 0.918     |
|    learning_rate        | 0.00141   |
|    loss                 | 0.0107    |
|    n_updates            | 14720     |
|    policy_gradient_loss | 0.0117    |
|    std                  | 0.321     |
|    value_loss           | 0.00535   |
---------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 627        |
|    iterations           | 1474       |
|    time_elapsed         | 4809       |
|    total_timesteps      | 3018752    |
| train/                  |            |
|    approx_kl            | 0.13086519 |
|    clip_fraction        | 0.397      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.568     |
|    explained_variance   | 0.788      |
|    learning_rate        | 0.00141    |
|    loss                 | -0.033     |
|    n_updates            | 14730      |
|    policy_gradient_loss | -0.00345   |
|    std                  | 0.318      |
|    value_loss           | 0.00577    |
----------------------------------------
box reached target
Eval num_timesteps=3020000, episode_reward=-0.89 +/- 0.23
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -0.886     |
| time/                   |            |
|    total_timesteps      | 3020000    |
| train/                  |            |
|    approx_kl            | 0.15146118 |
|    clip_fraction        | 0.423      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.571     |
|    explained_variance   | 0.868      |
|    learning_rate        | 0.00141    |
|    loss                 | 0.0534     |
|    n_updates            | 14740      |
|    policy_gradient_loss | 0.0139     |
|    std                  | 0.319      |
|    value_loss           | 0.00804    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 627     |
|    iterations      | 1475    |
|    time_elapsed    | 4813    |
|    total_timesteps | 3020800 |
--------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 627       |
|    iterations           | 1476      |
|    time_elapsed         | 4816      |
|    total_timesteps      | 3022848   |
| train/                  |           |
|    approx_kl            | 0.1774817 |
|    clip_fraction        | 0.419     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.611    |
|    explained_variance   | 0.269     |
|    learning_rate        | 0.00141   |
|    loss                 | -0.0119   |
|    n_updates            | 14750     |
|    policy_gradient_loss | 0.0106    |
|    std                  | 0.336     |
|    value_loss           | 0.00734   |
---------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 627        |
|    iterations           | 1477       |
|    time_elapsed         | 4819       |
|    total_timesteps      | 3024896    |
| train/                  |            |
|    approx_kl            | 0.08307882 |
|    clip_fraction        | 0.367      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.627     |
|    explained_variance   | 0.791      |
|    learning_rate        | 0.00141    |
|    loss                 | -0.0274    |
|    n_updates            | 14760      |
|    policy_gradient_loss | 0.00658    |
|    std                  | 0.326      |
|    value_loss           | 0.0114     |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 627        |
|    iterations           | 1478       |
|    time_elapsed         | 4822       |
|    total_timesteps      | 3026944    |
| train/                  |            |
|    approx_kl            | 0.23444787 |
|    clip_fraction        | 0.377      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.586     |
|    explained_variance   | 0.669      |
|    learning_rate        | 0.00141    |
|    loss                 | -0.0373    |
|    n_updates            | 14770      |
|    policy_gradient_loss | 0.00594    |
|    std                  | 0.328      |
|    value_loss           | 0.0172     |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 627        |
|    iterations           | 1479       |
|    time_elapsed         | 4825       |
|    total_timesteps      | 3028992    |
| train/                  |            |
|    approx_kl            | 0.12470744 |
|    clip_fraction        | 0.387      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.629     |
|    explained_variance   | 0.748      |
|    learning_rate        | 0.00141    |
|    loss                 | 0.017      |
|    n_updates            | 14780      |
|    policy_gradient_loss | 0.00189    |
|    std                  | 0.333      |
|    value_loss           | 0.00697    |
----------------------------------------
box reached target
Eval num_timesteps=3030000, episode_reward=0.10 +/- 2.51
Episode length: 270.80 +/- 58.40
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 271        |
|    mean_reward          | 0.1        |
| time/                   |            |
|    total_timesteps      | 3030000    |
| train/                  |            |
|    approx_kl            | 0.18497778 |
|    clip_fraction        | 0.34       |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.645     |
|    explained_variance   | 0.842      |
|    learning_rate        | 0.00141    |
|    loss                 | -0.0129    |
|    n_updates            | 14790      |
|    policy_gradient_loss | -0.00386   |
|    std                  | 0.332      |
|    value_loss           | 0.00395    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 627     |
|    iterations      | 1480    |
|    time_elapsed    | 4829    |
|    total_timesteps | 3031040 |
--------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 627        |
|    iterations           | 1481       |
|    time_elapsed         | 4832       |
|    total_timesteps      | 3033088    |
| train/                  |            |
|    approx_kl            | 0.09315819 |
|    clip_fraction        | 0.36       |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.649     |
|    explained_variance   | 0.797      |
|    learning_rate        | 0.00141    |
|    loss                 | 0.0557     |
|    n_updates            | 14800      |
|    policy_gradient_loss | 0.000303   |
|    std                  | 0.334      |
|    value_loss           | 0.0054     |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 627        |
|    iterations           | 1482       |
|    time_elapsed         | 4835       |
|    total_timesteps      | 3035136    |
| train/                  |            |
|    approx_kl            | 0.12414028 |
|    clip_fraction        | 0.363      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.673     |
|    explained_variance   | 0.655      |
|    learning_rate        | 0.00141    |
|    loss                 | -0.053     |
|    n_updates            | 14810      |
|    policy_gradient_loss | -0.00296   |
|    std                  | 0.341      |
|    value_loss           | 0.00834    |
----------------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 627        |
|    iterations           | 1483       |
|    time_elapsed         | 4838       |
|    total_timesteps      | 3037184    |
| train/                  |            |
|    approx_kl            | 0.12089205 |
|    clip_fraction        | 0.389      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.675     |
|    explained_variance   | 0.656      |
|    learning_rate        | 0.00141    |
|    loss                 | 0.155      |
|    n_updates            | 14820      |
|    policy_gradient_loss | 0.00376    |
|    std                  | 0.336      |
|    value_loss           | 0.00477    |
----------------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 627        |
|    iterations           | 1484       |
|    time_elapsed         | 4841       |
|    total_timesteps      | 3039232    |
| train/                  |            |
|    approx_kl            | 0.11336696 |
|    clip_fraction        | 0.384      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.595     |
|    explained_variance   | 0.63       |
|    learning_rate        | 0.00141    |
|    loss                 | 0.0317     |
|    n_updates            | 14830      |
|    policy_gradient_loss | -0.000909  |
|    std                  | 0.321      |
|    value_loss           | 0.0268     |
----------------------------------------
Eval num_timesteps=3040000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 300       |
|    mean_reward          | -1        |
| time/                   |           |
|    total_timesteps      | 3040000   |
| train/                  |           |
|    approx_kl            | 0.1655439 |
|    clip_fraction        | 0.4       |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.559    |
|    explained_variance   | 0.859     |
|    learning_rate        | 0.00141   |
|    loss                 | -0.0196   |
|    n_updates            | 14840     |
|    policy_gradient_loss | 0.0131    |
|    std                  | 0.317     |
|    value_loss           | 0.0135    |
---------------------------------------
--------------------------------
| time/              |         |
|    fps             | 627     |
|    iterations      | 1485    |
|    time_elapsed    | 4845    |
|    total_timesteps | 3041280 |
--------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 627         |
|    iterations           | 1486        |
|    time_elapsed         | 4848        |
|    total_timesteps      | 3043328     |
| train/                  |             |
|    approx_kl            | 0.109985344 |
|    clip_fraction        | 0.318       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.563      |
|    explained_variance   | 0.427       |
|    learning_rate        | 0.00141     |
|    loss                 | 0.0133      |
|    n_updates            | 14850       |
|    policy_gradient_loss | -0.00666    |
|    std                  | 0.322       |
|    value_loss           | 0.00288     |
-----------------------------------------
box reached target
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 627       |
|    iterations           | 1487      |
|    time_elapsed         | 4851      |
|    total_timesteps      | 3045376   |
| train/                  |           |
|    approx_kl            | 0.0913879 |
|    clip_fraction        | 0.34      |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.564    |
|    explained_variance   | 0.77      |
|    learning_rate        | 0.00141   |
|    loss                 | 0.0434    |
|    n_updates            | 14860     |
|    policy_gradient_loss | 0.0296    |
|    std                  | 0.324     |
|    value_loss           | 0.0106    |
---------------------------------------
box reached target
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 627        |
|    iterations           | 1488       |
|    time_elapsed         | 4854       |
|    total_timesteps      | 3047424    |
| train/                  |            |
|    approx_kl            | 0.13310163 |
|    clip_fraction        | 0.422      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.589     |
|    explained_variance   | 0.806      |
|    learning_rate        | 0.00141    |
|    loss                 | 0.00238    |
|    n_updates            | 14870      |
|    policy_gradient_loss | 0.00207    |
|    std                  | 0.323      |
|    value_loss           | 0.0208     |
----------------------------------------
box reached target
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 627        |
|    iterations           | 1489       |
|    time_elapsed         | 4857       |
|    total_timesteps      | 3049472    |
| train/                  |            |
|    approx_kl            | 0.18871766 |
|    clip_fraction        | 0.407      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.519     |
|    explained_variance   | 0.338      |
|    learning_rate        | 0.00141    |
|    loss                 | -0.0373    |
|    n_updates            | 14880      |
|    policy_gradient_loss | 0.00324    |
|    std                  | 0.311      |
|    value_loss           | 0.0353     |
----------------------------------------
Eval num_timesteps=3050000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 300       |
|    mean_reward          | -1        |
| time/                   |           |
|    total_timesteps      | 3050000   |
| train/                  |           |
|    approx_kl            | 0.4209512 |
|    clip_fraction        | 0.384     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.461    |
|    explained_variance   | 0.787     |
|    learning_rate        | 0.00141   |
|    loss                 | 0.0486    |
|    n_updates            | 14890     |
|    policy_gradient_loss | 0.00418   |
|    std                  | 0.304     |
|    value_loss           | 0.0489    |
---------------------------------------
--------------------------------
| time/              |         |
|    fps             | 627     |
|    iterations      | 1490    |
|    time_elapsed    | 4861    |
|    total_timesteps | 3051520 |
--------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 627        |
|    iterations           | 1491       |
|    time_elapsed         | 4864       |
|    total_timesteps      | 3053568    |
| train/                  |            |
|    approx_kl            | 0.28522742 |
|    clip_fraction        | 0.403      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.442     |
|    explained_variance   | 0.397      |
|    learning_rate        | 0.0014     |
|    loss                 | -0.0311    |
|    n_updates            | 14900      |
|    policy_gradient_loss | -0.00107   |
|    std                  | 0.297      |
|    value_loss           | 0.00772    |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 627        |
|    iterations           | 1492       |
|    time_elapsed         | 4867       |
|    total_timesteps      | 3055616    |
| train/                  |            |
|    approx_kl            | 0.25872958 |
|    clip_fraction        | 0.439      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.415     |
|    explained_variance   | 0.683      |
|    learning_rate        | 0.0014     |
|    loss                 | -0.0265    |
|    n_updates            | 14910      |
|    policy_gradient_loss | 0.0135     |
|    std                  | 0.296      |
|    value_loss           | 0.0112     |
----------------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 627        |
|    iterations           | 1493       |
|    time_elapsed         | 4870       |
|    total_timesteps      | 3057664    |
| train/                  |            |
|    approx_kl            | 0.48006722 |
|    clip_fraction        | 0.395      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.398     |
|    explained_variance   | 0.619      |
|    learning_rate        | 0.0014     |
|    loss                 | 0.062      |
|    n_updates            | 14920      |
|    policy_gradient_loss | 0.0176     |
|    std                  | 0.296      |
|    value_loss           | 0.0302     |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 627        |
|    iterations           | 1494       |
|    time_elapsed         | 4873       |
|    total_timesteps      | 3059712    |
| train/                  |            |
|    approx_kl            | 0.21906729 |
|    clip_fraction        | 0.389      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.377     |
|    explained_variance   | 0.881      |
|    learning_rate        | 0.0014     |
|    loss                 | -0.0149    |
|    n_updates            | 14930      |
|    policy_gradient_loss | 0.00139    |
|    std                  | 0.293      |
|    value_loss           | 0.00491    |
----------------------------------------
box reached target
Eval num_timesteps=3060000, episode_reward=0.23 +/- 2.46
Episode length: 271.80 +/- 56.40
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 272        |
|    mean_reward          | 0.229      |
| time/                   |            |
|    total_timesteps      | 3060000    |
| train/                  |            |
|    approx_kl            | 0.15355223 |
|    clip_fraction        | 0.353      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.379     |
|    explained_variance   | 0.743      |
|    learning_rate        | 0.0014     |
|    loss                 | -0.0101    |
|    n_updates            | 14940      |
|    policy_gradient_loss | -0.00259   |
|    std                  | 0.292      |
|    value_loss           | 0.00604    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 627     |
|    iterations      | 1495    |
|    time_elapsed    | 4877    |
|    total_timesteps | 3061760 |
--------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 627        |
|    iterations           | 1496       |
|    time_elapsed         | 4880       |
|    total_timesteps      | 3063808    |
| train/                  |            |
|    approx_kl            | 0.15095927 |
|    clip_fraction        | 0.355      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.367     |
|    explained_variance   | 0.716      |
|    learning_rate        | 0.0014     |
|    loss                 | 0.005      |
|    n_updates            | 14950      |
|    policy_gradient_loss | -0.000346  |
|    std                  | 0.287      |
|    value_loss           | 0.0109     |
----------------------------------------
box reached target
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 627         |
|    iterations           | 1497        |
|    time_elapsed         | 4883        |
|    total_timesteps      | 3065856     |
| train/                  |             |
|    approx_kl            | 0.120498955 |
|    clip_fraction        | 0.383       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.367      |
|    explained_variance   | 0.653       |
|    learning_rate        | 0.0014      |
|    loss                 | -0.00706    |
|    n_updates            | 14960       |
|    policy_gradient_loss | 0.0154      |
|    std                  | 0.29        |
|    value_loss           | 0.0385      |
-----------------------------------------
box reached target
box reached target
box reached target
box reached target
--------------------------------------
| time/                   |          |
|    fps                  | 627      |
|    iterations           | 1498     |
|    time_elapsed         | 4886     |
|    total_timesteps      | 3067904  |
| train/                  |          |
|    approx_kl            | 0.33791  |
|    clip_fraction        | 0.458    |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.376   |
|    explained_variance   | 0.729    |
|    learning_rate        | 0.0014   |
|    loss                 | 0.00955  |
|    n_updates            | 14970    |
|    policy_gradient_loss | 0.0183   |
|    std                  | 0.29     |
|    value_loss           | 0.0259   |
--------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 627       |
|    iterations           | 1499      |
|    time_elapsed         | 4889      |
|    total_timesteps      | 3069952   |
| train/                  |           |
|    approx_kl            | 0.1708924 |
|    clip_fraction        | 0.376     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.334    |
|    explained_variance   | 0.939     |
|    learning_rate        | 0.0014    |
|    loss                 | -0.00293  |
|    n_updates            | 14980     |
|    policy_gradient_loss | -0.00245  |
|    std                  | 0.285     |
|    value_loss           | 0.011     |
---------------------------------------
Eval num_timesteps=3070000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1         |
| time/                   |            |
|    total_timesteps      | 3070000    |
| train/                  |            |
|    approx_kl            | 0.27823406 |
|    clip_fraction        | 0.427      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.339     |
|    explained_variance   | 0.952      |
|    learning_rate        | 0.0014     |
|    loss                 | 0.00881    |
|    n_updates            | 14990      |
|    policy_gradient_loss | 0.00314    |
|    std                  | 0.287      |
|    value_loss           | 0.00304    |
----------------------------------------
box reached target
box reached target
--------------------------------
| time/              |         |
|    fps             | 627     |
|    iterations      | 1500    |
|    time_elapsed    | 4893    |
|    total_timesteps | 3072000 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 627        |
|    iterations           | 1501       |
|    time_elapsed         | 4896       |
|    total_timesteps      | 3074048    |
| train/                  |            |
|    approx_kl            | 0.18752132 |
|    clip_fraction        | 0.39       |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.316     |
|    explained_variance   | 0.964      |
|    learning_rate        | 0.0014     |
|    loss                 | 0.00596    |
|    n_updates            | 15000      |
|    policy_gradient_loss | 0.0187     |
|    std                  | 0.282      |
|    value_loss           | 0.00624    |
----------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 627       |
|    iterations           | 1502      |
|    time_elapsed         | 4899      |
|    total_timesteps      | 3076096   |
| train/                  |           |
|    approx_kl            | 0.3224561 |
|    clip_fraction        | 0.394     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.305    |
|    explained_variance   | 0.742     |
|    learning_rate        | 0.0014    |
|    loss                 | -0.0636   |
|    n_updates            | 15010     |
|    policy_gradient_loss | 0.00231   |
|    std                  | 0.277     |
|    value_loss           | 0.00382   |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 627        |
|    iterations           | 1503       |
|    time_elapsed         | 4903       |
|    total_timesteps      | 3078144    |
| train/                  |            |
|    approx_kl            | 0.37602386 |
|    clip_fraction        | 0.412      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.278     |
|    explained_variance   | 0.818      |
|    learning_rate        | 0.0014     |
|    loss                 | 0.0301     |
|    n_updates            | 15020      |
|    policy_gradient_loss | 0.0093     |
|    std                  | 0.275      |
|    value_loss           | 0.00921    |
----------------------------------------
box reached target
Eval num_timesteps=3080000, episode_reward=0.25 +/- 2.51
Episode length: 279.20 +/- 41.60
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 279        |
|    mean_reward          | 0.254      |
| time/                   |            |
|    total_timesteps      | 3080000    |
| train/                  |            |
|    approx_kl            | 0.12982106 |
|    clip_fraction        | 0.404      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.281     |
|    explained_variance   | 0.79       |
|    learning_rate        | 0.0014     |
|    loss                 | -0.000809  |
|    n_updates            | 15030      |
|    policy_gradient_loss | 0.00514    |
|    std                  | 0.28       |
|    value_loss           | 0.00638    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 627     |
|    iterations      | 1504    |
|    time_elapsed    | 4906    |
|    total_timesteps | 3080192 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 627        |
|    iterations           | 1505       |
|    time_elapsed         | 4909       |
|    total_timesteps      | 3082240    |
| train/                  |            |
|    approx_kl            | 0.13704246 |
|    clip_fraction        | 0.355      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.319     |
|    explained_variance   | 0.724      |
|    learning_rate        | 0.0014     |
|    loss                 | 0.0138     |
|    n_updates            | 15040      |
|    policy_gradient_loss | 0.00778    |
|    std                  | 0.281      |
|    value_loss           | 0.00908    |
----------------------------------------
box reached target
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 627       |
|    iterations           | 1506      |
|    time_elapsed         | 4912      |
|    total_timesteps      | 3084288   |
| train/                  |           |
|    approx_kl            | 0.1536948 |
|    clip_fraction        | 0.403     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.327    |
|    explained_variance   | 0.796     |
|    learning_rate        | 0.0014    |
|    loss                 | 0.0128    |
|    n_updates            | 15050     |
|    policy_gradient_loss | 0.0165    |
|    std                  | 0.284     |
|    value_loss           | 0.00701   |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 627        |
|    iterations           | 1507       |
|    time_elapsed         | 4916       |
|    total_timesteps      | 3086336    |
| train/                  |            |
|    approx_kl            | 0.10678244 |
|    clip_fraction        | 0.412      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.332     |
|    explained_variance   | 0.792      |
|    learning_rate        | 0.0014     |
|    loss                 | -0.0188    |
|    n_updates            | 15060      |
|    policy_gradient_loss | 0.0186     |
|    std                  | 0.286      |
|    value_loss           | 0.0175     |
----------------------------------------
box reached target
--------------------------------------
| time/                   |          |
|    fps                  | 627      |
|    iterations           | 1508     |
|    time_elapsed         | 4919     |
|    total_timesteps      | 3088384  |
| train/                  |          |
|    approx_kl            | 2.021834 |
|    clip_fraction        | 0.501    |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.369   |
|    explained_variance   | -0.181   |
|    learning_rate        | 0.0014   |
|    loss                 | -0.0101  |
|    n_updates            | 15070    |
|    policy_gradient_loss | 0.00775  |
|    std                  | 0.29     |
|    value_loss           | 0.00435  |
--------------------------------------
box reached target
box reached target
box reached target
box reached target
Eval num_timesteps=3090000, episode_reward=1.76 +/- 2.76
Episode length: 246.40 +/- 65.80
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 246        |
|    mean_reward          | 1.76       |
| time/                   |            |
|    total_timesteps      | 3090000    |
| train/                  |            |
|    approx_kl            | 0.17593995 |
|    clip_fraction        | 0.427      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.332     |
|    explained_variance   | 0.927      |
|    learning_rate        | 0.0014     |
|    loss                 | 0.00705    |
|    n_updates            | 15080      |
|    policy_gradient_loss | 0.00477    |
|    std                  | 0.282      |
|    value_loss           | 0.00427    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 627     |
|    iterations      | 1509    |
|    time_elapsed    | 4922    |
|    total_timesteps | 3090432 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 627        |
|    iterations           | 1510       |
|    time_elapsed         | 4925       |
|    total_timesteps      | 3092480    |
| train/                  |            |
|    approx_kl            | 0.12273216 |
|    clip_fraction        | 0.396      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.34      |
|    explained_variance   | 0.916      |
|    learning_rate        | 0.0014     |
|    loss                 | 0.0152     |
|    n_updates            | 15090      |
|    policy_gradient_loss | 0.00607    |
|    std                  | 0.29       |
|    value_loss           | 0.0104     |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 627        |
|    iterations           | 1511       |
|    time_elapsed         | 4928       |
|    total_timesteps      | 3094528    |
| train/                  |            |
|    approx_kl            | 0.19207433 |
|    clip_fraction        | 0.398      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.324     |
|    explained_variance   | 0.801      |
|    learning_rate        | 0.0014     |
|    loss                 | -0.0538    |
|    n_updates            | 15100      |
|    policy_gradient_loss | -0.000136  |
|    std                  | 0.28       |
|    value_loss           | 0.00673    |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 627        |
|    iterations           | 1512       |
|    time_elapsed         | 4931       |
|    total_timesteps      | 3096576    |
| train/                  |            |
|    approx_kl            | 0.12511168 |
|    clip_fraction        | 0.343      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.288     |
|    explained_variance   | 0.733      |
|    learning_rate        | 0.0014     |
|    loss                 | 0.0706     |
|    n_updates            | 15110      |
|    policy_gradient_loss | 0.00376    |
|    std                  | 0.279      |
|    value_loss           | 0.00427    |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 627        |
|    iterations           | 1513       |
|    time_elapsed         | 4935       |
|    total_timesteps      | 3098624    |
| train/                  |            |
|    approx_kl            | 0.13732466 |
|    clip_fraction        | 0.408      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.231     |
|    explained_variance   | 0.558      |
|    learning_rate        | 0.0014     |
|    loss                 | -0.0066    |
|    n_updates            | 15120      |
|    policy_gradient_loss | 0.00305    |
|    std                  | 0.268      |
|    value_loss           | 0.057      |
----------------------------------------
Eval num_timesteps=3100000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1         |
| time/                   |            |
|    total_timesteps      | 3100000    |
| train/                  |            |
|    approx_kl            | 0.39961183 |
|    clip_fraction        | 0.467      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.238     |
|    explained_variance   | 0.812      |
|    learning_rate        | 0.0014     |
|    loss                 | 0.038      |
|    n_updates            | 15130      |
|    policy_gradient_loss | 0.0321     |
|    std                  | 0.277      |
|    value_loss           | 0.0148     |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 627     |
|    iterations      | 1514    |
|    time_elapsed    | 4939    |
|    total_timesteps | 3100672 |
--------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 627        |
|    iterations           | 1515       |
|    time_elapsed         | 4942       |
|    total_timesteps      | 3102720    |
| train/                  |            |
|    approx_kl            | 0.18868604 |
|    clip_fraction        | 0.387      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.24      |
|    explained_variance   | 0.62       |
|    learning_rate        | 0.0014     |
|    loss                 | 0.0339     |
|    n_updates            | 15140      |
|    policy_gradient_loss | 0.017      |
|    std                  | 0.271      |
|    value_loss           | 0.00533    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 627        |
|    iterations           | 1516       |
|    time_elapsed         | 4945       |
|    total_timesteps      | 3104768    |
| train/                  |            |
|    approx_kl            | 0.21739939 |
|    clip_fraction        | 0.442      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.194     |
|    explained_variance   | 0.898      |
|    learning_rate        | 0.00139    |
|    loss                 | 0.157      |
|    n_updates            | 15150      |
|    policy_gradient_loss | 0.00215    |
|    std                  | 0.265      |
|    value_loss           | 0.00708    |
----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 627       |
|    iterations           | 1517      |
|    time_elapsed         | 4948      |
|    total_timesteps      | 3106816   |
| train/                  |           |
|    approx_kl            | 0.1953795 |
|    clip_fraction        | 0.433     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.165    |
|    explained_variance   | 0.786     |
|    learning_rate        | 0.00139   |
|    loss                 | -0.0481   |
|    n_updates            | 15160     |
|    policy_gradient_loss | 0.0205    |
|    std                  | 0.265     |
|    value_loss           | 0.00689   |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 627        |
|    iterations           | 1518       |
|    time_elapsed         | 4951       |
|    total_timesteps      | 3108864    |
| train/                  |            |
|    approx_kl            | 0.08229634 |
|    clip_fraction        | 0.355      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.167     |
|    explained_variance   | 0.75       |
|    learning_rate        | 0.00139    |
|    loss                 | -0.00364   |
|    n_updates            | 15170      |
|    policy_gradient_loss | 0.00787    |
|    std                  | 0.267      |
|    value_loss           | 0.00891    |
----------------------------------------
box reached target
box reached target
box reached target
box reached target
box reached target
Eval num_timesteps=3110000, episode_reward=4.15 +/- 1.93
Episode length: 192.00 +/- 55.23
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 192       |
|    mean_reward          | 4.15      |
| time/                   |           |
|    total_timesteps      | 3110000   |
| train/                  |           |
|    approx_kl            | 0.1415436 |
|    clip_fraction        | 0.389     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.175    |
|    explained_variance   | 0.69      |
|    learning_rate        | 0.00139   |
|    loss                 | -0.0147   |
|    n_updates            | 15180     |
|    policy_gradient_loss | 0.00357   |
|    std                  | 0.264     |
|    value_loss           | 0.00527   |
---------------------------------------
New best mean reward!
box reached target
--------------------------------
| time/              |         |
|    fps             | 627     |
|    iterations      | 1519    |
|    time_elapsed    | 4954    |
|    total_timesteps | 3110912 |
--------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 627        |
|    iterations           | 1520       |
|    time_elapsed         | 4957       |
|    total_timesteps      | 3112960    |
| train/                  |            |
|    approx_kl            | 0.22984332 |
|    clip_fraction        | 0.447      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.141     |
|    explained_variance   | 0.771      |
|    learning_rate        | 0.00139    |
|    loss                 | 0.0245     |
|    n_updates            | 15190      |
|    policy_gradient_loss | 0.017      |
|    std                  | 0.261      |
|    value_loss           | 0.0183     |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 627        |
|    iterations           | 1521       |
|    time_elapsed         | 4960       |
|    total_timesteps      | 3115008    |
| train/                  |            |
|    approx_kl            | 0.20311397 |
|    clip_fraction        | 0.418      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.11      |
|    explained_variance   | 0.906      |
|    learning_rate        | 0.00139    |
|    loss                 | 0.0148     |
|    n_updates            | 15200      |
|    policy_gradient_loss | 0.0115     |
|    std                  | 0.253      |
|    value_loss           | 0.00687    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 627        |
|    iterations           | 1522       |
|    time_elapsed         | 4963       |
|    total_timesteps      | 3117056    |
| train/                  |            |
|    approx_kl            | 0.27111647 |
|    clip_fraction        | 0.366      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.107     |
|    explained_variance   | 0.718      |
|    learning_rate        | 0.00139    |
|    loss                 | -0.0273    |
|    n_updates            | 15210      |
|    policy_gradient_loss | 0.00571    |
|    std                  | 0.26       |
|    value_loss           | 0.00516    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 627        |
|    iterations           | 1523       |
|    time_elapsed         | 4966       |
|    total_timesteps      | 3119104    |
| train/                  |            |
|    approx_kl            | 0.15909149 |
|    clip_fraction        | 0.417      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.134     |
|    explained_variance   | 0.877      |
|    learning_rate        | 0.00139    |
|    loss                 | 0.00488    |
|    n_updates            | 15220      |
|    policy_gradient_loss | 0.0206     |
|    std                  | 0.259      |
|    value_loss           | 0.00302    |
----------------------------------------
Eval num_timesteps=3120000, episode_reward=-0.73 +/- 0.54
Episode length: 300.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 300       |
|    mean_reward          | -0.73     |
| time/                   |           |
|    total_timesteps      | 3120000   |
| train/                  |           |
|    approx_kl            | 0.8068037 |
|    clip_fraction        | 0.454     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.17     |
|    explained_variance   | 0.65      |
|    learning_rate        | 0.00139   |
|    loss                 | 0.096     |
|    n_updates            | 15230     |
|    policy_gradient_loss | 0.0183    |
|    std                  | 0.266     |
|    value_loss           | 0.00251   |
---------------------------------------
box reached target
--------------------------------
| time/              |         |
|    fps             | 627     |
|    iterations      | 1524    |
|    time_elapsed    | 4970    |
|    total_timesteps | 3121152 |
--------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 627        |
|    iterations           | 1525       |
|    time_elapsed         | 4973       |
|    total_timesteps      | 3123200    |
| train/                  |            |
|    approx_kl            | 0.14289524 |
|    clip_fraction        | 0.353      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.183     |
|    explained_variance   | 0.79       |
|    learning_rate        | 0.00139    |
|    loss                 | 0.0129     |
|    n_updates            | 15240      |
|    policy_gradient_loss | 0.00641    |
|    std                  | 0.264      |
|    value_loss           | 0.00758    |
----------------------------------------
--------------------------------------
| time/                   |          |
|    fps                  | 627      |
|    iterations           | 1526     |
|    time_elapsed         | 4976     |
|    total_timesteps      | 3125248  |
| train/                  |          |
|    approx_kl            | 0.144011 |
|    clip_fraction        | 0.419    |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.173   |
|    explained_variance   | 0.807    |
|    learning_rate        | 0.00139  |
|    loss                 | 0.055    |
|    n_updates            | 15250    |
|    policy_gradient_loss | 0.00618  |
|    std                  | 0.265    |
|    value_loss           | 0.00778  |
--------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 627       |
|    iterations           | 1527      |
|    time_elapsed         | 4979      |
|    total_timesteps      | 3127296   |
| train/                  |           |
|    approx_kl            | 0.1900136 |
|    clip_fraction        | 0.363     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.212    |
|    explained_variance   | 0.694     |
|    learning_rate        | 0.00139   |
|    loss                 | -0.0353   |
|    n_updates            | 15260     |
|    policy_gradient_loss | -0.00305  |
|    std                  | 0.269     |
|    value_loss           | 0.0118    |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 628        |
|    iterations           | 1528       |
|    time_elapsed         | 4983       |
|    total_timesteps      | 3129344    |
| train/                  |            |
|    approx_kl            | 0.42346013 |
|    clip_fraction        | 0.405      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.214     |
|    explained_variance   | 0.393      |
|    learning_rate        | 0.00139    |
|    loss                 | -0.0332    |
|    n_updates            | 15270      |
|    policy_gradient_loss | -0.00509   |
|    std                  | 0.27       |
|    value_loss           | 0.00269    |
----------------------------------------
box reached target
Eval num_timesteps=3130000, episode_reward=0.12 +/- 2.45
Episode length: 275.80 +/- 48.40
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 276        |
|    mean_reward          | 0.116      |
| time/                   |            |
|    total_timesteps      | 3130000    |
| train/                  |            |
|    approx_kl            | 0.47182262 |
|    clip_fraction        | 0.47       |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.247     |
|    explained_variance   | 0.589      |
|    learning_rate        | 0.00139    |
|    loss                 | -0.0283    |
|    n_updates            | 15280      |
|    policy_gradient_loss | 0.0346     |
|    std                  | 0.275      |
|    value_loss           | 0.00467    |
----------------------------------------
box reached target
--------------------------------
| time/              |         |
|    fps             | 627     |
|    iterations      | 1529    |
|    time_elapsed    | 4986    |
|    total_timesteps | 3131392 |
--------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 627        |
|    iterations           | 1530       |
|    time_elapsed         | 4989       |
|    total_timesteps      | 3133440    |
| train/                  |            |
|    approx_kl            | 0.17456965 |
|    clip_fraction        | 0.43       |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.254     |
|    explained_variance   | 0.723      |
|    learning_rate        | 0.00139    |
|    loss                 | -0.00756   |
|    n_updates            | 15290      |
|    policy_gradient_loss | 0.00088    |
|    std                  | 0.273      |
|    value_loss           | 0.0118     |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 627        |
|    iterations           | 1531       |
|    time_elapsed         | 4992       |
|    total_timesteps      | 3135488    |
| train/                  |            |
|    approx_kl            | 0.14779378 |
|    clip_fraction        | 0.359      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.268     |
|    explained_variance   | 0.549      |
|    learning_rate        | 0.00139    |
|    loss                 | -0.00522   |
|    n_updates            | 15300      |
|    policy_gradient_loss | 0.0145     |
|    std                  | 0.28       |
|    value_loss           | 0.0153     |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 628        |
|    iterations           | 1532       |
|    time_elapsed         | 4996       |
|    total_timesteps      | 3137536    |
| train/                  |            |
|    approx_kl            | 0.10406513 |
|    clip_fraction        | 0.377      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.341     |
|    explained_variance   | 0.518      |
|    learning_rate        | 0.00139    |
|    loss                 | -0.00829   |
|    n_updates            | 15310      |
|    policy_gradient_loss | -0.00547   |
|    std                  | 0.288      |
|    value_loss           | 0.00485    |
----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 628         |
|    iterations           | 1533        |
|    time_elapsed         | 4999        |
|    total_timesteps      | 3139584     |
| train/                  |             |
|    approx_kl            | 0.073857315 |
|    clip_fraction        | 0.321       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.374      |
|    explained_variance   | 0.743       |
|    learning_rate        | 0.00139     |
|    loss                 | 0.0482      |
|    n_updates            | 15320       |
|    policy_gradient_loss | 0.00755     |
|    std                  | 0.295       |
|    value_loss           | 0.00242     |
-----------------------------------------
Eval num_timesteps=3140000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1         |
| time/                   |            |
|    total_timesteps      | 3140000    |
| train/                  |            |
|    approx_kl            | 0.13367692 |
|    clip_fraction        | 0.387      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.419     |
|    explained_variance   | 0.7        |
|    learning_rate        | 0.00139    |
|    loss                 | 0.0179     |
|    n_updates            | 15330      |
|    policy_gradient_loss | 0.00393    |
|    std                  | 0.298      |
|    value_loss           | 0.00276    |
----------------------------------------
box reached target
box reached target
--------------------------------
| time/              |         |
|    fps             | 627     |
|    iterations      | 1534    |
|    time_elapsed    | 5003    |
|    total_timesteps | 3141632 |
--------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 627        |
|    iterations           | 1535       |
|    time_elapsed         | 5006       |
|    total_timesteps      | 3143680    |
| train/                  |            |
|    approx_kl            | 0.15056348 |
|    clip_fraction        | 0.388      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.407     |
|    explained_variance   | 0.936      |
|    learning_rate        | 0.00139    |
|    loss                 | 0.0197     |
|    n_updates            | 15340      |
|    policy_gradient_loss | 0.0107     |
|    std                  | 0.29       |
|    value_loss           | 0.00713    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 627        |
|    iterations           | 1536       |
|    time_elapsed         | 5009       |
|    total_timesteps      | 3145728    |
| train/                  |            |
|    approx_kl            | 0.11988452 |
|    clip_fraction        | 0.363      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.336     |
|    explained_variance   | 0.495      |
|    learning_rate        | 0.00139    |
|    loss                 | 0.0447     |
|    n_updates            | 15350      |
|    policy_gradient_loss | -0.000478  |
|    std                  | 0.284      |
|    value_loss           | 0.0332     |
----------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 628       |
|    iterations           | 1537      |
|    time_elapsed         | 5012      |
|    total_timesteps      | 3147776   |
| train/                  |           |
|    approx_kl            | 0.7757407 |
|    clip_fraction        | 0.436     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.36     |
|    explained_variance   | 0.761     |
|    learning_rate        | 0.00139   |
|    loss                 | -0.0525   |
|    n_updates            | 15360     |
|    policy_gradient_loss | 0.000138  |
|    std                  | 0.288     |
|    value_loss           | 0.0191    |
---------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 628        |
|    iterations           | 1538       |
|    time_elapsed         | 5015       |
|    total_timesteps      | 3149824    |
| train/                  |            |
|    approx_kl            | 0.20330036 |
|    clip_fraction        | 0.384      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.353     |
|    explained_variance   | 0.59       |
|    learning_rate        | 0.00139    |
|    loss                 | -0.00358   |
|    n_updates            | 15370      |
|    policy_gradient_loss | 0.0165     |
|    std                  | 0.288      |
|    value_loss           | 0.0332     |
----------------------------------------
box reached target
Eval num_timesteps=3150000, episode_reward=0.24 +/- 2.48
Episode length: 274.20 +/- 51.60
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 274       |
|    mean_reward          | 0.241     |
| time/                   |           |
|    total_timesteps      | 3150000   |
| train/                  |           |
|    approx_kl            | 0.5001187 |
|    clip_fraction        | 0.378     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.314    |
|    explained_variance   | 0.77      |
|    learning_rate        | 0.00139   |
|    loss                 | -0.0283   |
|    n_updates            | 15380     |
|    policy_gradient_loss | -0.0132   |
|    std                  | 0.28      |
|    value_loss           | 0.0223    |
---------------------------------------
--------------------------------
| time/              |         |
|    fps             | 627     |
|    iterations      | 1539    |
|    time_elapsed    | 5019    |
|    total_timesteps | 3151872 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 628        |
|    iterations           | 1540       |
|    time_elapsed         | 5022       |
|    total_timesteps      | 3153920    |
| train/                  |            |
|    approx_kl            | 0.19502552 |
|    clip_fraction        | 0.371      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.362     |
|    explained_variance   | 0.811      |
|    learning_rate        | 0.00139    |
|    loss                 | -0.0179    |
|    n_updates            | 15390      |
|    policy_gradient_loss | 0.005      |
|    std                  | 0.293      |
|    value_loss           | 0.00693    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 628        |
|    iterations           | 1541       |
|    time_elapsed         | 5025       |
|    total_timesteps      | 3155968    |
| train/                  |            |
|    approx_kl            | 0.11822018 |
|    clip_fraction        | 0.386      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.413     |
|    explained_variance   | 0.102      |
|    learning_rate        | 0.00138    |
|    loss                 | 0.00166    |
|    n_updates            | 15400      |
|    policy_gradient_loss | 0.00409    |
|    std                  | 0.297      |
|    value_loss           | 0.00966    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 628        |
|    iterations           | 1542       |
|    time_elapsed         | 5028       |
|    total_timesteps      | 3158016    |
| train/                  |            |
|    approx_kl            | 0.20657784 |
|    clip_fraction        | 0.385      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.445     |
|    explained_variance   | 0.706      |
|    learning_rate        | 0.00138    |
|    loss                 | -0.0116    |
|    n_updates            | 15410      |
|    policy_gradient_loss | -0.0023    |
|    std                  | 0.302      |
|    value_loss           | 0.00419    |
----------------------------------------
box reached target
Eval num_timesteps=3160000, episode_reward=0.45 +/- 2.46
Episode length: 276.40 +/- 47.20
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 276        |
|    mean_reward          | 0.45       |
| time/                   |            |
|    total_timesteps      | 3160000    |
| train/                  |            |
|    approx_kl            | 0.13524827 |
|    clip_fraction        | 0.349      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.475     |
|    explained_variance   | 0.682      |
|    learning_rate        | 0.00138    |
|    loss                 | 0.0684     |
|    n_updates            | 15420      |
|    policy_gradient_loss | -0.00104   |
|    std                  | 0.305      |
|    value_loss           | 0.00838    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 627     |
|    iterations      | 1543    |
|    time_elapsed    | 5032    |
|    total_timesteps | 3160064 |
--------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 628        |
|    iterations           | 1544       |
|    time_elapsed         | 5035       |
|    total_timesteps      | 3162112    |
| train/                  |            |
|    approx_kl            | 0.20277543 |
|    clip_fraction        | 0.357      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.452     |
|    explained_variance   | 0.661      |
|    learning_rate        | 0.00138    |
|    loss                 | -0.0292    |
|    n_updates            | 15430      |
|    policy_gradient_loss | -0.0019    |
|    std                  | 0.298      |
|    value_loss           | 0.00562    |
----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 628       |
|    iterations           | 1545      |
|    time_elapsed         | 5038      |
|    total_timesteps      | 3164160   |
| train/                  |           |
|    approx_kl            | 0.1724264 |
|    clip_fraction        | 0.362     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.394    |
|    explained_variance   | 0.731     |
|    learning_rate        | 0.00138   |
|    loss                 | 0.0397    |
|    n_updates            | 15440     |
|    policy_gradient_loss | 0.00159   |
|    std                  | 0.292     |
|    value_loss           | 0.0295    |
---------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 628        |
|    iterations           | 1546       |
|    time_elapsed         | 5041       |
|    total_timesteps      | 3166208    |
| train/                  |            |
|    approx_kl            | 0.24646986 |
|    clip_fraction        | 0.398      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.404     |
|    explained_variance   | 0.707      |
|    learning_rate        | 0.00138    |
|    loss                 | -0.0274    |
|    n_updates            | 15450      |
|    policy_gradient_loss | 0.00994    |
|    std                  | 0.297      |
|    value_loss           | 0.00453    |
----------------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 628        |
|    iterations           | 1547       |
|    time_elapsed         | 5044       |
|    total_timesteps      | 3168256    |
| train/                  |            |
|    approx_kl            | 0.20712423 |
|    clip_fraction        | 0.404      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.445     |
|    explained_variance   | 0.668      |
|    learning_rate        | 0.00138    |
|    loss                 | -0.0304    |
|    n_updates            | 15460      |
|    policy_gradient_loss | 0.0125     |
|    std                  | 0.306      |
|    value_loss           | 0.0146     |
----------------------------------------
box reached target
box reached target
Eval num_timesteps=3170000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1         |
| time/                   |            |
|    total_timesteps      | 3170000    |
| train/                  |            |
|    approx_kl            | 0.16023928 |
|    clip_fraction        | 0.393      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.487     |
|    explained_variance   | 0.631      |
|    learning_rate        | 0.00138    |
|    loss                 | -0.00783   |
|    n_updates            | 15470      |
|    policy_gradient_loss | 0.00997    |
|    std                  | 0.308      |
|    value_loss           | 0.0302     |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 628     |
|    iterations      | 1548    |
|    time_elapsed    | 5048    |
|    total_timesteps | 3170304 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 628        |
|    iterations           | 1549       |
|    time_elapsed         | 5051       |
|    total_timesteps      | 3172352    |
| train/                  |            |
|    approx_kl            | 0.09454921 |
|    clip_fraction        | 0.343      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.459     |
|    explained_variance   | 0.695      |
|    learning_rate        | 0.00138    |
|    loss                 | -0.00265   |
|    n_updates            | 15480      |
|    policy_gradient_loss | 0.00915    |
|    std                  | 0.302      |
|    value_loss           | 0.0205     |
----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 628         |
|    iterations           | 1550        |
|    time_elapsed         | 5054        |
|    total_timesteps      | 3174400     |
| train/                  |             |
|    approx_kl            | 0.097439446 |
|    clip_fraction        | 0.363       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.461      |
|    explained_variance   | 0.695       |
|    learning_rate        | 0.00138     |
|    loss                 | -0.00876    |
|    n_updates            | 15490       |
|    policy_gradient_loss | 0.0125      |
|    std                  | 0.305       |
|    value_loss           | 0.0104      |
-----------------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 628         |
|    iterations           | 1551        |
|    time_elapsed         | 5057        |
|    total_timesteps      | 3176448     |
| train/                  |             |
|    approx_kl            | 0.096270874 |
|    clip_fraction        | 0.39        |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.497      |
|    explained_variance   | 0.579       |
|    learning_rate        | 0.00138     |
|    loss                 | 0.0135      |
|    n_updates            | 15500       |
|    policy_gradient_loss | 0.0132      |
|    std                  | 0.311       |
|    value_loss           | 0.00661     |
-----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 628        |
|    iterations           | 1552       |
|    time_elapsed         | 5060       |
|    total_timesteps      | 3178496    |
| train/                  |            |
|    approx_kl            | 0.17414878 |
|    clip_fraction        | 0.337      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.509     |
|    explained_variance   | 0.822      |
|    learning_rate        | 0.00138    |
|    loss                 | -0.042     |
|    n_updates            | 15510      |
|    policy_gradient_loss | 0.00449    |
|    std                  | 0.311      |
|    value_loss           | 0.00957    |
----------------------------------------
box reached target
Eval num_timesteps=3180000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1         |
| time/                   |            |
|    total_timesteps      | 3180000    |
| train/                  |            |
|    approx_kl            | 0.32199484 |
|    clip_fraction        | 0.376      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.511     |
|    explained_variance   | 0.275      |
|    learning_rate        | 0.00138    |
|    loss                 | -0.00241   |
|    n_updates            | 15520      |
|    policy_gradient_loss | 0.00776    |
|    std                  | 0.312      |
|    value_loss           | 0.00799    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 628     |
|    iterations      | 1553    |
|    time_elapsed    | 5064    |
|    total_timesteps | 3180544 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 628        |
|    iterations           | 1554       |
|    time_elapsed         | 5067       |
|    total_timesteps      | 3182592    |
| train/                  |            |
|    approx_kl            | 0.13814037 |
|    clip_fraction        | 0.361      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.488     |
|    explained_variance   | 0.618      |
|    learning_rate        | 0.00138    |
|    loss                 | -0.0175    |
|    n_updates            | 15530      |
|    policy_gradient_loss | -0.00359   |
|    std                  | 0.305      |
|    value_loss           | 0.00709    |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 628        |
|    iterations           | 1555       |
|    time_elapsed         | 5070       |
|    total_timesteps      | 3184640    |
| train/                  |            |
|    approx_kl            | 0.16251014 |
|    clip_fraction        | 0.386      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.449     |
|    explained_variance   | 0.615      |
|    learning_rate        | 0.00138    |
|    loss                 | -0.0304    |
|    n_updates            | 15540      |
|    policy_gradient_loss | 0.00128    |
|    std                  | 0.302      |
|    value_loss           | 0.0202     |
----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 628       |
|    iterations           | 1556      |
|    time_elapsed         | 5073      |
|    total_timesteps      | 3186688   |
| train/                  |           |
|    approx_kl            | 0.3526644 |
|    clip_fraction        | 0.39      |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.423    |
|    explained_variance   | 0.776     |
|    learning_rate        | 0.00138   |
|    loss                 | -0.0394   |
|    n_updates            | 15550     |
|    policy_gradient_loss | -0.00733  |
|    std                  | 0.295     |
|    value_loss           | 0.00722   |
---------------------------------------
box reached target
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 628       |
|    iterations           | 1557      |
|    time_elapsed         | 5076      |
|    total_timesteps      | 3188736   |
| train/                  |           |
|    approx_kl            | 1.0210351 |
|    clip_fraction        | 0.392     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.404    |
|    explained_variance   | 0.702     |
|    learning_rate        | 0.00138   |
|    loss                 | 0.0522    |
|    n_updates            | 15560     |
|    policy_gradient_loss | 0.00488   |
|    std                  | 0.297     |
|    value_loss           | 0.00482   |
---------------------------------------
Eval num_timesteps=3190000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1         |
| time/                   |            |
|    total_timesteps      | 3190000    |
| train/                  |            |
|    approx_kl            | 0.17687277 |
|    clip_fraction        | 0.412      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.385     |
|    explained_variance   | 0.577      |
|    learning_rate        | 0.00138    |
|    loss                 | 0.0315     |
|    n_updates            | 15570      |
|    policy_gradient_loss | 0.00358    |
|    std                  | 0.292      |
|    value_loss           | 0.0457     |
----------------------------------------
box reached target
--------------------------------
| time/              |         |
|    fps             | 628     |
|    iterations      | 1558    |
|    time_elapsed    | 5080    |
|    total_timesteps | 3190784 |
--------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 628         |
|    iterations           | 1559        |
|    time_elapsed         | 5083        |
|    total_timesteps      | 3192832     |
| train/                  |             |
|    approx_kl            | 0.107645355 |
|    clip_fraction        | 0.382       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.367      |
|    explained_variance   | 0.538       |
|    learning_rate        | 0.00138     |
|    loss                 | 0.00045     |
|    n_updates            | 15580       |
|    policy_gradient_loss | 0.0108      |
|    std                  | 0.288       |
|    value_loss           | 0.0316      |
-----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 628        |
|    iterations           | 1560       |
|    time_elapsed         | 5086       |
|    total_timesteps      | 3194880    |
| train/                  |            |
|    approx_kl            | 0.07523966 |
|    clip_fraction        | 0.366      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.355     |
|    explained_variance   | 0.745      |
|    learning_rate        | 0.00138    |
|    loss                 | 0.0212     |
|    n_updates            | 15590      |
|    policy_gradient_loss | 0.00786    |
|    std                  | 0.292      |
|    value_loss           | 0.00914    |
----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 628         |
|    iterations           | 1561        |
|    time_elapsed         | 5089        |
|    total_timesteps      | 3196928     |
| train/                  |             |
|    approx_kl            | 0.067888446 |
|    clip_fraction        | 0.338       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.4        |
|    explained_variance   | 0.436       |
|    learning_rate        | 0.00138     |
|    loss                 | 0.00112     |
|    n_updates            | 15600       |
|    policy_gradient_loss | 0.00198     |
|    std                  | 0.296       |
|    value_loss           | 0.0054      |
-----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 628        |
|    iterations           | 1562       |
|    time_elapsed         | 5092       |
|    total_timesteps      | 3198976    |
| train/                  |            |
|    approx_kl            | 0.14503038 |
|    clip_fraction        | 0.399      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.447     |
|    explained_variance   | 0.503      |
|    learning_rate        | 0.00138    |
|    loss                 | 0.0467     |
|    n_updates            | 15610      |
|    policy_gradient_loss | 0.0249     |
|    std                  | 0.306      |
|    value_loss           | 0.00681    |
----------------------------------------
box reached target
box reached target
box reached target
Eval num_timesteps=3200000, episode_reward=1.38 +/- 3.09
Episode length: 248.60 +/- 63.37
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 249        |
|    mean_reward          | 1.38       |
| time/                   |            |
|    total_timesteps      | 3200000    |
| train/                  |            |
|    approx_kl            | 0.17971596 |
|    clip_fraction        | 0.386      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.487     |
|    explained_variance   | 0.737      |
|    learning_rate        | 0.00138    |
|    loss                 | -0.0235    |
|    n_updates            | 15620      |
|    policy_gradient_loss | 0.0141     |
|    std                  | 0.309      |
|    value_loss           | 0.00449    |
----------------------------------------
box reached target
--------------------------------
| time/              |         |
|    fps             | 628     |
|    iterations      | 1563    |
|    time_elapsed    | 5096    |
|    total_timesteps | 3201024 |
--------------------------------
box reached target
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 628        |
|    iterations           | 1564       |
|    time_elapsed         | 5099       |
|    total_timesteps      | 3203072    |
| train/                  |            |
|    approx_kl            | 0.18119122 |
|    clip_fraction        | 0.361      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.452     |
|    explained_variance   | 0.596      |
|    learning_rate        | 0.00138    |
|    loss                 | -0.0417    |
|    n_updates            | 15630      |
|    policy_gradient_loss | -0.00309   |
|    std                  | 0.299      |
|    value_loss           | 0.0143     |
----------------------------------------
box reached target
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 628        |
|    iterations           | 1565       |
|    time_elapsed         | 5102       |
|    total_timesteps      | 3205120    |
| train/                  |            |
|    approx_kl            | 0.62811136 |
|    clip_fraction        | 0.424      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.431     |
|    explained_variance   | 0.658      |
|    learning_rate        | 0.00138    |
|    loss                 | 0.0175     |
|    n_updates            | 15640      |
|    policy_gradient_loss | 0.0106     |
|    std                  | 0.3        |
|    value_loss           | 0.0303     |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 628        |
|    iterations           | 1566       |
|    time_elapsed         | 5105       |
|    total_timesteps      | 3207168    |
| train/                  |            |
|    approx_kl            | 0.06623584 |
|    clip_fraction        | 0.325      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.465     |
|    explained_variance   | 0.772      |
|    learning_rate        | 0.00138    |
|    loss                 | 0.0412     |
|    n_updates            | 15650      |
|    policy_gradient_loss | 0.0116     |
|    std                  | 0.306      |
|    value_loss           | 0.0227     |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 628        |
|    iterations           | 1567       |
|    time_elapsed         | 5108       |
|    total_timesteps      | 3209216    |
| train/                  |            |
|    approx_kl            | 0.13221279 |
|    clip_fraction        | 0.338      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.462     |
|    explained_variance   | 0.592      |
|    learning_rate        | 0.00137    |
|    loss                 | 0.00402    |
|    n_updates            | 15660      |
|    policy_gradient_loss | 0.00851    |
|    std                  | 0.304      |
|    value_loss           | 0.00588    |
----------------------------------------
box reached target
box reached target
box reached target
Eval num_timesteps=3210000, episode_reward=2.60 +/- 3.11
Episode length: 245.20 +/- 59.41
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 245         |
|    mean_reward          | 2.6         |
| time/                   |             |
|    total_timesteps      | 3210000     |
| train/                  |             |
|    approx_kl            | 0.097765915 |
|    clip_fraction        | 0.362       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.443      |
|    explained_variance   | 0.564       |
|    learning_rate        | 0.00137     |
|    loss                 | -0.0192     |
|    n_updates            | 15670       |
|    policy_gradient_loss | 0.00964     |
|    std                  | 0.3         |
|    value_loss           | 0.0132      |
-----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 628     |
|    iterations      | 1568    |
|    time_elapsed    | 5112    |
|    total_timesteps | 3211264 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 628        |
|    iterations           | 1569       |
|    time_elapsed         | 5115       |
|    total_timesteps      | 3213312    |
| train/                  |            |
|    approx_kl            | 0.08934793 |
|    clip_fraction        | 0.341      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.424     |
|    explained_variance   | 0.497      |
|    learning_rate        | 0.00137    |
|    loss                 | -0.0182    |
|    n_updates            | 15680      |
|    policy_gradient_loss | 0.00108    |
|    std                  | 0.297      |
|    value_loss           | 0.00374    |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 628        |
|    iterations           | 1570       |
|    time_elapsed         | 5118       |
|    total_timesteps      | 3215360    |
| train/                  |            |
|    approx_kl            | 0.23878545 |
|    clip_fraction        | 0.364      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.424     |
|    explained_variance   | 0.751      |
|    learning_rate        | 0.00137    |
|    loss                 | -0.0303    |
|    n_updates            | 15690      |
|    policy_gradient_loss | 0.00382    |
|    std                  | 0.298      |
|    value_loss           | 0.00694    |
----------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 628       |
|    iterations           | 1571      |
|    time_elapsed         | 5121      |
|    total_timesteps      | 3217408   |
| train/                  |           |
|    approx_kl            | 0.2110825 |
|    clip_fraction        | 0.429     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.446    |
|    explained_variance   | 0.758     |
|    learning_rate        | 0.00137   |
|    loss                 | 0.0235    |
|    n_updates            | 15700     |
|    policy_gradient_loss | 0.023     |
|    std                  | 0.309     |
|    value_loss           | 0.00995   |
---------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 628        |
|    iterations           | 1572       |
|    time_elapsed         | 5124       |
|    total_timesteps      | 3219456    |
| train/                  |            |
|    approx_kl            | 0.16284999 |
|    clip_fraction        | 0.351      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.475     |
|    explained_variance   | 0.856      |
|    learning_rate        | 0.00137    |
|    loss                 | 0.0285     |
|    n_updates            | 15710      |
|    policy_gradient_loss | 0.00771    |
|    std                  | 0.304      |
|    value_loss           | 0.00764    |
----------------------------------------
Eval num_timesteps=3220000, episode_reward=-0.54 +/- 0.59
Episode length: 300.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 300         |
|    mean_reward          | -0.538      |
| time/                   |             |
|    total_timesteps      | 3220000     |
| train/                  |             |
|    approx_kl            | 0.094282106 |
|    clip_fraction        | 0.348       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.46       |
|    explained_variance   | 0.728       |
|    learning_rate        | 0.00137     |
|    loss                 | 0.00755     |
|    n_updates            | 15720       |
|    policy_gradient_loss | 0.00566     |
|    std                  | 0.304       |
|    value_loss           | 0.0214      |
-----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 628     |
|    iterations      | 1573    |
|    time_elapsed    | 5128    |
|    total_timesteps | 3221504 |
--------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 628        |
|    iterations           | 1574       |
|    time_elapsed         | 5131       |
|    total_timesteps      | 3223552    |
| train/                  |            |
|    approx_kl            | 0.08889096 |
|    clip_fraction        | 0.335      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.489     |
|    explained_variance   | 0.602      |
|    learning_rate        | 0.00137    |
|    loss                 | 0.0791     |
|    n_updates            | 15730      |
|    policy_gradient_loss | 0.0106     |
|    std                  | 0.31       |
|    value_loss           | 0.00618    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 628        |
|    iterations           | 1575       |
|    time_elapsed         | 5134       |
|    total_timesteps      | 3225600    |
| train/                  |            |
|    approx_kl            | 0.08800735 |
|    clip_fraction        | 0.343      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.499     |
|    explained_variance   | 0.857      |
|    learning_rate        | 0.00137    |
|    loss                 | -0.0203    |
|    n_updates            | 15740      |
|    policy_gradient_loss | 0.00961    |
|    std                  | 0.31       |
|    value_loss           | 0.013      |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 628        |
|    iterations           | 1576       |
|    time_elapsed         | 5137       |
|    total_timesteps      | 3227648    |
| train/                  |            |
|    approx_kl            | 0.13301405 |
|    clip_fraction        | 0.349      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.472     |
|    explained_variance   | 0.585      |
|    learning_rate        | 0.00137    |
|    loss                 | -0.0124    |
|    n_updates            | 15750      |
|    policy_gradient_loss | 0.00649    |
|    std                  | 0.305      |
|    value_loss           | 0.0101     |
----------------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 628        |
|    iterations           | 1577       |
|    time_elapsed         | 5140       |
|    total_timesteps      | 3229696    |
| train/                  |            |
|    approx_kl            | 0.21455224 |
|    clip_fraction        | 0.436      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.459     |
|    explained_variance   | 0.0507     |
|    learning_rate        | 0.00137    |
|    loss                 | -0.00137   |
|    n_updates            | 15760      |
|    policy_gradient_loss | 0.0142     |
|    std                  | 0.304      |
|    value_loss           | 0.0141     |
----------------------------------------
Eval num_timesteps=3230000, episode_reward=-0.65 +/- 0.69
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -0.654     |
| time/                   |            |
|    total_timesteps      | 3230000    |
| train/                  |            |
|    approx_kl            | 0.10046092 |
|    clip_fraction        | 0.373      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.466     |
|    explained_variance   | 0.585      |
|    learning_rate        | 0.00137    |
|    loss                 | 0.0669     |
|    n_updates            | 15770      |
|    policy_gradient_loss | 0.00974    |
|    std                  | 0.307      |
|    value_loss           | 0.0456     |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 628     |
|    iterations      | 1578    |
|    time_elapsed    | 5144    |
|    total_timesteps | 3231744 |
--------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 628        |
|    iterations           | 1579       |
|    time_elapsed         | 5147       |
|    total_timesteps      | 3233792    |
| train/                  |            |
|    approx_kl            | 0.12393939 |
|    clip_fraction        | 0.338      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.502     |
|    explained_variance   | 0.625      |
|    learning_rate        | 0.00137    |
|    loss                 | 0.0477     |
|    n_updates            | 15780      |
|    policy_gradient_loss | 0.00796    |
|    std                  | 0.312      |
|    value_loss           | 0.00559    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 628        |
|    iterations           | 1580       |
|    time_elapsed         | 5150       |
|    total_timesteps      | 3235840    |
| train/                  |            |
|    approx_kl            | 0.23160186 |
|    clip_fraction        | 0.412      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.54      |
|    explained_variance   | 0.255      |
|    learning_rate        | 0.00137    |
|    loss                 | 0.0228     |
|    n_updates            | 15790      |
|    policy_gradient_loss | 0.014      |
|    std                  | 0.32       |
|    value_loss           | 0.0521     |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 628        |
|    iterations           | 1581       |
|    time_elapsed         | 5153       |
|    total_timesteps      | 3237888    |
| train/                  |            |
|    approx_kl            | 0.08884001 |
|    clip_fraction        | 0.349      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.585     |
|    explained_variance   | 0.485      |
|    learning_rate        | 0.00137    |
|    loss                 | -0.0144    |
|    n_updates            | 15800      |
|    policy_gradient_loss | 0.00755    |
|    std                  | 0.327      |
|    value_loss           | 0.00424    |
----------------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 628         |
|    iterations           | 1582        |
|    time_elapsed         | 5156        |
|    total_timesteps      | 3239936     |
| train/                  |             |
|    approx_kl            | 0.088390544 |
|    clip_fraction        | 0.355       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.636      |
|    explained_variance   | 0.48        |
|    learning_rate        | 0.00137     |
|    loss                 | -0.0223     |
|    n_updates            | 15810       |
|    policy_gradient_loss | -0.00136    |
|    std                  | 0.334       |
|    value_loss           | 0.00556     |
-----------------------------------------
box reached target
Eval num_timesteps=3240000, episode_reward=0.55 +/- 2.41
Episode length: 273.20 +/- 53.60
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 273        |
|    mean_reward          | 0.546      |
| time/                   |            |
|    total_timesteps      | 3240000    |
| train/                  |            |
|    approx_kl            | 0.15467647 |
|    clip_fraction        | 0.359      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.608     |
|    explained_variance   | 0.157      |
|    learning_rate        | 0.00137    |
|    loss                 | -0.041     |
|    n_updates            | 15820      |
|    policy_gradient_loss | 0.00617    |
|    std                  | 0.327      |
|    value_loss           | 0.00841    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 628     |
|    iterations      | 1583    |
|    time_elapsed    | 5160    |
|    total_timesteps | 3241984 |
--------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 628        |
|    iterations           | 1584       |
|    time_elapsed         | 5163       |
|    total_timesteps      | 3244032    |
| train/                  |            |
|    approx_kl            | 0.14373621 |
|    clip_fraction        | 0.367      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.665     |
|    explained_variance   | 0.746      |
|    learning_rate        | 0.00137    |
|    loss                 | -0.0324    |
|    n_updates            | 15830      |
|    policy_gradient_loss | -0.00293   |
|    std                  | 0.344      |
|    value_loss           | 0.0149     |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 628        |
|    iterations           | 1585       |
|    time_elapsed         | 5166       |
|    total_timesteps      | 3246080    |
| train/                  |            |
|    approx_kl            | 0.11258216 |
|    clip_fraction        | 0.366      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.709     |
|    explained_variance   | 0.752      |
|    learning_rate        | 0.00137    |
|    loss                 | 0.0152     |
|    n_updates            | 15840      |
|    policy_gradient_loss | 0.000801   |
|    std                  | 0.346      |
|    value_loss           | 0.0087     |
----------------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 628        |
|    iterations           | 1586       |
|    time_elapsed         | 5169       |
|    total_timesteps      | 3248128    |
| train/                  |            |
|    approx_kl            | 0.15885274 |
|    clip_fraction        | 0.359      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.671     |
|    explained_variance   | 0.494      |
|    learning_rate        | 0.00137    |
|    loss                 | 0.0221     |
|    n_updates            | 15850      |
|    policy_gradient_loss | -0.00375   |
|    std                  | 0.337      |
|    value_loss           | 0.00347    |
----------------------------------------
box reached target
box reached target
Eval num_timesteps=3250000, episode_reward=1.49 +/- 3.05
Episode length: 239.20 +/- 74.46
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 239        |
|    mean_reward          | 1.49       |
| time/                   |            |
|    total_timesteps      | 3250000    |
| train/                  |            |
|    approx_kl            | 0.19050056 |
|    clip_fraction        | 0.368      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.644     |
|    explained_variance   | 0.798      |
|    learning_rate        | 0.00137    |
|    loss                 | 0.0356     |
|    n_updates            | 15860      |
|    policy_gradient_loss | 0.00236    |
|    std                  | 0.331      |
|    value_loss           | 0.0213     |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 628     |
|    iterations      | 1587    |
|    time_elapsed    | 5173    |
|    total_timesteps | 3250176 |
--------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 628        |
|    iterations           | 1588       |
|    time_elapsed         | 5176       |
|    total_timesteps      | 3252224    |
| train/                  |            |
|    approx_kl            | 0.08304468 |
|    clip_fraction        | 0.338      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.614     |
|    explained_variance   | 0.841      |
|    learning_rate        | 0.00137    |
|    loss                 | 0.00904    |
|    n_updates            | 15870      |
|    policy_gradient_loss | 0.00408    |
|    std                  | 0.332      |
|    value_loss           | 0.00521    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 628        |
|    iterations           | 1589       |
|    time_elapsed         | 5179       |
|    total_timesteps      | 3254272    |
| train/                  |            |
|    approx_kl            | 0.08996354 |
|    clip_fraction        | 0.342      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.595     |
|    explained_variance   | 0.814      |
|    learning_rate        | 0.00137    |
|    loss                 | 0.000533   |
|    n_updates            | 15880      |
|    policy_gradient_loss | 0.00795    |
|    std                  | 0.324      |
|    value_loss           | 0.0514     |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 628        |
|    iterations           | 1590       |
|    time_elapsed         | 5182       |
|    total_timesteps      | 3256320    |
| train/                  |            |
|    approx_kl            | 0.08280845 |
|    clip_fraction        | 0.354      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.574     |
|    explained_variance   | 0.744      |
|    learning_rate        | 0.00137    |
|    loss                 | 0.0344     |
|    n_updates            | 15890      |
|    policy_gradient_loss | 0.00357    |
|    std                  | 0.322      |
|    value_loss           | 0.025      |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 628        |
|    iterations           | 1591       |
|    time_elapsed         | 5185       |
|    total_timesteps      | 3258368    |
| train/                  |            |
|    approx_kl            | 0.19481575 |
|    clip_fraction        | 0.387      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.549     |
|    explained_variance   | 0.885      |
|    learning_rate        | 0.00137    |
|    loss                 | -0.0394    |
|    n_updates            | 15900      |
|    policy_gradient_loss | 0.00055    |
|    std                  | 0.321      |
|    value_loss           | 0.00894    |
----------------------------------------
box reached target
box reached target
box reached target
Eval num_timesteps=3260000, episode_reward=-0.77 +/- 0.45
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -0.774     |
| time/                   |            |
|    total_timesteps      | 3260000    |
| train/                  |            |
|    approx_kl            | 0.24613377 |
|    clip_fraction        | 0.359      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.586     |
|    explained_variance   | 0.766      |
|    learning_rate        | 0.00136    |
|    loss                 | -0.0184    |
|    n_updates            | 15910      |
|    policy_gradient_loss | -0.00952   |
|    std                  | 0.323      |
|    value_loss           | 0.00544    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 628     |
|    iterations      | 1592    |
|    time_elapsed    | 5189    |
|    total_timesteps | 3260416 |
--------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 628        |
|    iterations           | 1593       |
|    time_elapsed         | 5192       |
|    total_timesteps      | 3262464    |
| train/                  |            |
|    approx_kl            | 0.20436352 |
|    clip_fraction        | 0.394      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.569     |
|    explained_variance   | 0.569      |
|    learning_rate        | 0.00136    |
|    loss                 | -0.0302    |
|    n_updates            | 15920      |
|    policy_gradient_loss | 0.00179    |
|    std                  | 0.324      |
|    value_loss           | 0.0448     |
----------------------------------------
box reached target
box reached target
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 628        |
|    iterations           | 1594       |
|    time_elapsed         | 5195       |
|    total_timesteps      | 3264512    |
| train/                  |            |
|    approx_kl            | 0.13335444 |
|    clip_fraction        | 0.322      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.611     |
|    explained_variance   | 0.868      |
|    learning_rate        | 0.00136    |
|    loss                 | 0.00576    |
|    n_updates            | 15930      |
|    policy_gradient_loss | 0.0011     |
|    std                  | 0.334      |
|    value_loss           | 0.0156     |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 628        |
|    iterations           | 1595       |
|    time_elapsed         | 5198       |
|    total_timesteps      | 3266560    |
| train/                  |            |
|    approx_kl            | 0.08604785 |
|    clip_fraction        | 0.339      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.646     |
|    explained_variance   | 0.842      |
|    learning_rate        | 0.00136    |
|    loss                 | -0.0174    |
|    n_updates            | 15940      |
|    policy_gradient_loss | -0.00222   |
|    std                  | 0.334      |
|    value_loss           | 0.0364     |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 628        |
|    iterations           | 1596       |
|    time_elapsed         | 5201       |
|    total_timesteps      | 3268608    |
| train/                  |            |
|    approx_kl            | 0.07530333 |
|    clip_fraction        | 0.356      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.645     |
|    explained_variance   | 0.775      |
|    learning_rate        | 0.00136    |
|    loss                 | 0.0197     |
|    n_updates            | 15950      |
|    policy_gradient_loss | 0.00435    |
|    std                  | 0.339      |
|    value_loss           | 0.0137     |
----------------------------------------
box reached target
Eval num_timesteps=3270000, episode_reward=-0.71 +/- 0.58
Episode length: 300.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 300         |
|    mean_reward          | -0.708      |
| time/                   |             |
|    total_timesteps      | 3270000     |
| train/                  |             |
|    approx_kl            | 0.095035106 |
|    clip_fraction        | 0.341       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.656      |
|    explained_variance   | 0.71        |
|    learning_rate        | 0.00136     |
|    loss                 | 0.0959      |
|    n_updates            | 15960       |
|    policy_gradient_loss | 0.0197      |
|    std                  | 0.342       |
|    value_loss           | 0.0268      |
-----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 628     |
|    iterations      | 1597    |
|    time_elapsed    | 5205    |
|    total_timesteps | 3270656 |
--------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 628        |
|    iterations           | 1598       |
|    time_elapsed         | 5208       |
|    total_timesteps      | 3272704    |
| train/                  |            |
|    approx_kl            | 0.11011677 |
|    clip_fraction        | 0.346      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.706     |
|    explained_variance   | 0.772      |
|    learning_rate        | 0.00136    |
|    loss                 | 0.00987    |
|    n_updates            | 15970      |
|    policy_gradient_loss | -0.00904   |
|    std                  | 0.345      |
|    value_loss           | 0.02       |
----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 628         |
|    iterations           | 1599        |
|    time_elapsed         | 5211        |
|    total_timesteps      | 3274752     |
| train/                  |             |
|    approx_kl            | 0.052998036 |
|    clip_fraction        | 0.293       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.698      |
|    explained_variance   | 0.884       |
|    learning_rate        | 0.00136     |
|    loss                 | -0.0204     |
|    n_updates            | 15980       |
|    policy_gradient_loss | 0.00122     |
|    std                  | 0.344       |
|    value_loss           | 0.0157      |
-----------------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 628         |
|    iterations           | 1600        |
|    time_elapsed         | 5214        |
|    total_timesteps      | 3276800     |
| train/                  |             |
|    approx_kl            | 0.064489946 |
|    clip_fraction        | 0.327       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.716      |
|    explained_variance   | 0.564       |
|    learning_rate        | 0.00136     |
|    loss                 | -0.0317     |
|    n_updates            | 15990       |
|    policy_gradient_loss | 0.00338     |
|    std                  | 0.347       |
|    value_loss           | 0.00835     |
-----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 628        |
|    iterations           | 1601       |
|    time_elapsed         | 5217       |
|    total_timesteps      | 3278848    |
| train/                  |            |
|    approx_kl            | 0.11928041 |
|    clip_fraction        | 0.356      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.708     |
|    explained_variance   | 0.616      |
|    learning_rate        | 0.00136    |
|    loss                 | -0.025     |
|    n_updates            | 16000      |
|    policy_gradient_loss | -0.00224   |
|    std                  | 0.344      |
|    value_loss           | 0.0108     |
----------------------------------------
box reached target
Eval num_timesteps=3280000, episode_reward=0.48 +/- 2.40
Episode length: 276.20 +/- 47.60
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 276        |
|    mean_reward          | 0.476      |
| time/                   |            |
|    total_timesteps      | 3280000    |
| train/                  |            |
|    approx_kl            | 0.16826408 |
|    clip_fraction        | 0.358      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.679     |
|    explained_variance   | 0.927      |
|    learning_rate        | 0.00136    |
|    loss                 | 0.0143     |
|    n_updates            | 16010      |
|    policy_gradient_loss | 0.0112     |
|    std                  | 0.339      |
|    value_loss           | 0.00541    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 628     |
|    iterations      | 1602    |
|    time_elapsed    | 5221    |
|    total_timesteps | 3280896 |
--------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 628        |
|    iterations           | 1603       |
|    time_elapsed         | 5224       |
|    total_timesteps      | 3282944    |
| train/                  |            |
|    approx_kl            | 0.13585545 |
|    clip_fraction        | 0.306      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.682     |
|    explained_variance   | 0.543      |
|    learning_rate        | 0.00136    |
|    loss                 | -0.023     |
|    n_updates            | 16020      |
|    policy_gradient_loss | 0.000243   |
|    std                  | 0.343      |
|    value_loss           | 0.00418    |
----------------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 628        |
|    iterations           | 1604       |
|    time_elapsed         | 5227       |
|    total_timesteps      | 3284992    |
| train/                  |            |
|    approx_kl            | 0.08865626 |
|    clip_fraction        | 0.336      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.64      |
|    explained_variance   | 0.611      |
|    learning_rate        | 0.00136    |
|    loss                 | 0.0595     |
|    n_updates            | 16030      |
|    policy_gradient_loss | -0.00257   |
|    std                  | 0.331      |
|    value_loss           | 0.0172     |
----------------------------------------
box reached target
box reached target
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 628        |
|    iterations           | 1605       |
|    time_elapsed         | 5230       |
|    total_timesteps      | 3287040    |
| train/                  |            |
|    approx_kl            | 0.09284206 |
|    clip_fraction        | 0.39       |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.631     |
|    explained_variance   | 0.884      |
|    learning_rate        | 0.00136    |
|    loss                 | 0.0262     |
|    n_updates            | 16040      |
|    policy_gradient_loss | 0.00643    |
|    std                  | 0.334      |
|    value_loss           | 0.00897    |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 628        |
|    iterations           | 1606       |
|    time_elapsed         | 5233       |
|    total_timesteps      | 3289088    |
| train/                  |            |
|    approx_kl            | 0.14525887 |
|    clip_fraction        | 0.373      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.615     |
|    explained_variance   | 0.847      |
|    learning_rate        | 0.00136    |
|    loss                 | 0.00105    |
|    n_updates            | 16050      |
|    policy_gradient_loss | -0.00171   |
|    std                  | 0.334      |
|    value_loss           | 0.0219     |
----------------------------------------
box reached target
Eval num_timesteps=3290000, episode_reward=-0.73 +/- 0.53
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -0.733     |
| time/                   |            |
|    total_timesteps      | 3290000    |
| train/                  |            |
|    approx_kl            | 0.14190188 |
|    clip_fraction        | 0.389      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.586     |
|    explained_variance   | 0.547      |
|    learning_rate        | 0.00136    |
|    loss                 | 0.0144     |
|    n_updates            | 16060      |
|    policy_gradient_loss | 0.00048    |
|    std                  | 0.322      |
|    value_loss           | 0.0193     |
----------------------------------------
box reached target
--------------------------------
| time/              |         |
|    fps             | 628     |
|    iterations      | 1607    |
|    time_elapsed    | 5237    |
|    total_timesteps | 3291136 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 628        |
|    iterations           | 1608       |
|    time_elapsed         | 5240       |
|    total_timesteps      | 3293184    |
| train/                  |            |
|    approx_kl            | 0.14102115 |
|    clip_fraction        | 0.372      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.524     |
|    explained_variance   | 0.8        |
|    learning_rate        | 0.00136    |
|    loss                 | -0.00324   |
|    n_updates            | 16070      |
|    policy_gradient_loss | -0.00334   |
|    std                  | 0.315      |
|    value_loss           | 0.0159     |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 628        |
|    iterations           | 1609       |
|    time_elapsed         | 5244       |
|    total_timesteps      | 3295232    |
| train/                  |            |
|    approx_kl            | 0.09073982 |
|    clip_fraction        | 0.362      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.488     |
|    explained_variance   | 0.635      |
|    learning_rate        | 0.00136    |
|    loss                 | 0.0237     |
|    n_updates            | 16080      |
|    policy_gradient_loss | 0.0018     |
|    std                  | 0.312      |
|    value_loss           | 0.0065     |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 628        |
|    iterations           | 1610       |
|    time_elapsed         | 5247       |
|    total_timesteps      | 3297280    |
| train/                  |            |
|    approx_kl            | 0.20053108 |
|    clip_fraction        | 0.37       |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.519     |
|    explained_variance   | 0.74       |
|    learning_rate        | 0.00136    |
|    loss                 | -0.0202    |
|    n_updates            | 16090      |
|    policy_gradient_loss | 0.00186    |
|    std                  | 0.319      |
|    value_loss           | 0.00989    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 628        |
|    iterations           | 1611       |
|    time_elapsed         | 5250       |
|    total_timesteps      | 3299328    |
| train/                  |            |
|    approx_kl            | 0.21354204 |
|    clip_fraction        | 0.371      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.508     |
|    explained_variance   | 0.828      |
|    learning_rate        | 0.00136    |
|    loss                 | 0.0335     |
|    n_updates            | 16100      |
|    policy_gradient_loss | 0.00985    |
|    std                  | 0.318      |
|    value_loss           | 0.00928    |
----------------------------------------
Eval num_timesteps=3300000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1         |
| time/                   |            |
|    total_timesteps      | 3300000    |
| train/                  |            |
|    approx_kl            | 0.10104467 |
|    clip_fraction        | 0.376      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.534     |
|    explained_variance   | 0.861      |
|    learning_rate        | 0.00136    |
|    loss                 | 0.0182     |
|    n_updates            | 16110      |
|    policy_gradient_loss | 0.00601    |
|    std                  | 0.322      |
|    value_loss           | 0.00743    |
----------------------------------------
box reached target
--------------------------------
| time/              |         |
|    fps             | 628     |
|    iterations      | 1612    |
|    time_elapsed    | 5254    |
|    total_timesteps | 3301376 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 628        |
|    iterations           | 1613       |
|    time_elapsed         | 5257       |
|    total_timesteps      | 3303424    |
| train/                  |            |
|    approx_kl            | 0.11386434 |
|    clip_fraction        | 0.408      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.528     |
|    explained_variance   | 0.841      |
|    learning_rate        | 0.00136    |
|    loss                 | -0.00726   |
|    n_updates            | 16120      |
|    policy_gradient_loss | 0.00891    |
|    std                  | 0.319      |
|    value_loss           | 0.0165     |
----------------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 628        |
|    iterations           | 1614       |
|    time_elapsed         | 5260       |
|    total_timesteps      | 3305472    |
| train/                  |            |
|    approx_kl            | 0.17355771 |
|    clip_fraction        | 0.381      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.496     |
|    explained_variance   | 0.0649     |
|    learning_rate        | 0.00136    |
|    loss                 | -0.0383    |
|    n_updates            | 16130      |
|    policy_gradient_loss | 0.00193    |
|    std                  | 0.312      |
|    value_loss           | 0.00194    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 628        |
|    iterations           | 1615       |
|    time_elapsed         | 5263       |
|    total_timesteps      | 3307520    |
| train/                  |            |
|    approx_kl            | 0.15911016 |
|    clip_fraction        | 0.394      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.477     |
|    explained_variance   | 0.941      |
|    learning_rate        | 0.00136    |
|    loss                 | 0.0625     |
|    n_updates            | 16140      |
|    policy_gradient_loss | 0.0112     |
|    std                  | 0.312      |
|    value_loss           | 0.0157     |
----------------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 628        |
|    iterations           | 1616       |
|    time_elapsed         | 5266       |
|    total_timesteps      | 3309568    |
| train/                  |            |
|    approx_kl            | 0.14608072 |
|    clip_fraction        | 0.344      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.507     |
|    explained_variance   | 0.789      |
|    learning_rate        | 0.00136    |
|    loss                 | 0.0125     |
|    n_updates            | 16150      |
|    policy_gradient_loss | 0.0127     |
|    std                  | 0.318      |
|    value_loss           | 0.00541    |
----------------------------------------
Eval num_timesteps=3310000, episode_reward=-0.79 +/- 0.42
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -0.791     |
| time/                   |            |
|    total_timesteps      | 3310000    |
| train/                  |            |
|    approx_kl            | 0.10077934 |
|    clip_fraction        | 0.363      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.55      |
|    explained_variance   | 0.867      |
|    learning_rate        | 0.00135    |
|    loss                 | -0.0067    |
|    n_updates            | 16160      |
|    policy_gradient_loss | 0.00414    |
|    std                  | 0.323      |
|    value_loss           | 0.0145     |
----------------------------------------
box reached target
--------------------------------
| time/              |         |
|    fps             | 628     |
|    iterations      | 1617    |
|    time_elapsed    | 5270    |
|    total_timesteps | 3311616 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 628        |
|    iterations           | 1618       |
|    time_elapsed         | 5273       |
|    total_timesteps      | 3313664    |
| train/                  |            |
|    approx_kl            | 0.15950784 |
|    clip_fraction        | 0.375      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.61      |
|    explained_variance   | 0.877      |
|    learning_rate        | 0.00135    |
|    loss                 | 0.0139     |
|    n_updates            | 16170      |
|    policy_gradient_loss | -0.00453   |
|    std                  | 0.333      |
|    value_loss           | 0.00954    |
----------------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 628        |
|    iterations           | 1619       |
|    time_elapsed         | 5276       |
|    total_timesteps      | 3315712    |
| train/                  |            |
|    approx_kl            | 0.15319222 |
|    clip_fraction        | 0.369      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.664     |
|    explained_variance   | 0.48       |
|    learning_rate        | 0.00135    |
|    loss                 | -0.007     |
|    n_updates            | 16180      |
|    policy_gradient_loss | -0.00298   |
|    std                  | 0.341      |
|    value_loss           | 0.003      |
----------------------------------------
box reached target
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 628        |
|    iterations           | 1620       |
|    time_elapsed         | 5279       |
|    total_timesteps      | 3317760    |
| train/                  |            |
|    approx_kl            | 0.19590649 |
|    clip_fraction        | 0.333      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.672     |
|    explained_variance   | 0.816      |
|    learning_rate        | 0.00135    |
|    loss                 | 0.0198     |
|    n_updates            | 16190      |
|    policy_gradient_loss | 0.0113     |
|    std                  | 0.339      |
|    value_loss           | 0.0184     |
----------------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 628        |
|    iterations           | 1621       |
|    time_elapsed         | 5282       |
|    total_timesteps      | 3319808    |
| train/                  |            |
|    approx_kl            | 0.14432763 |
|    clip_fraction        | 0.374      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.652     |
|    explained_variance   | 0.301      |
|    learning_rate        | 0.00135    |
|    loss                 | 0.0581     |
|    n_updates            | 16200      |
|    policy_gradient_loss | 0.0116     |
|    std                  | 0.34       |
|    value_loss           | 0.0939     |
----------------------------------------
box reached target
box reached target
box reached target
Eval num_timesteps=3320000, episode_reward=2.23 +/- 2.68
Episode length: 265.00 +/- 45.80
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 265        |
|    mean_reward          | 2.23       |
| time/                   |            |
|    total_timesteps      | 3320000    |
| train/                  |            |
|    approx_kl            | 0.10991111 |
|    clip_fraction        | 0.335      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.621     |
|    explained_variance   | 0.871      |
|    learning_rate        | 0.00135    |
|    loss                 | 0.003      |
|    n_updates            | 16210      |
|    policy_gradient_loss | 0.00125    |
|    std                  | 0.331      |
|    value_loss           | 0.0155     |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 628     |
|    iterations      | 1622    |
|    time_elapsed    | 5286    |
|    total_timesteps | 3321856 |
--------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 628       |
|    iterations           | 1623      |
|    time_elapsed         | 5289      |
|    total_timesteps      | 3323904   |
| train/                  |           |
|    approx_kl            | 0.1043237 |
|    clip_fraction        | 0.382     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.582    |
|    explained_variance   | 0.533     |
|    learning_rate        | 0.00135   |
|    loss                 | 0.0013    |
|    n_updates            | 16220     |
|    policy_gradient_loss | -0.0013   |
|    std                  | 0.326     |
|    value_loss           | 0.0519    |
---------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 628       |
|    iterations           | 1624      |
|    time_elapsed         | 5292      |
|    total_timesteps      | 3325952   |
| train/                  |           |
|    approx_kl            | 0.1326834 |
|    clip_fraction        | 0.357     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.547    |
|    explained_variance   | 0.718     |
|    learning_rate        | 0.00135   |
|    loss                 | 0.0106    |
|    n_updates            | 16230     |
|    policy_gradient_loss | -0.00475  |
|    std                  | 0.319     |
|    value_loss           | 0.0125    |
---------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 628        |
|    iterations           | 1625       |
|    time_elapsed         | 5295       |
|    total_timesteps      | 3328000    |
| train/                  |            |
|    approx_kl            | 0.18815583 |
|    clip_fraction        | 0.378      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.526     |
|    explained_variance   | 0.789      |
|    learning_rate        | 0.00135    |
|    loss                 | -0.0252    |
|    n_updates            | 16240      |
|    policy_gradient_loss | -0.00597   |
|    std                  | 0.313      |
|    value_loss           | 0.0112     |
----------------------------------------
box reached target
box reached target
box reached target
Eval num_timesteps=3330000, episode_reward=0.50 +/- 2.51
Episode length: 274.20 +/- 51.60
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 274         |
|    mean_reward          | 0.503       |
| time/                   |             |
|    total_timesteps      | 3330000     |
| train/                  |             |
|    approx_kl            | 0.089593194 |
|    clip_fraction        | 0.338       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.532      |
|    explained_variance   | 0.892       |
|    learning_rate        | 0.00135     |
|    loss                 | 0.0218      |
|    n_updates            | 16250       |
|    policy_gradient_loss | 0.00956     |
|    std                  | 0.322       |
|    value_loss           | 0.016       |
-----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 628     |
|    iterations      | 1626    |
|    time_elapsed    | 5299    |
|    total_timesteps | 3330048 |
--------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 628         |
|    iterations           | 1627        |
|    time_elapsed         | 5302        |
|    total_timesteps      | 3332096     |
| train/                  |             |
|    approx_kl            | 0.123595126 |
|    clip_fraction        | 0.39        |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.584      |
|    explained_variance   | 0.866       |
|    learning_rate        | 0.00135     |
|    loss                 | 0.0119      |
|    n_updates            | 16260       |
|    policy_gradient_loss | 0.000228    |
|    std                  | 0.328       |
|    value_loss           | 0.0172      |
-----------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 628       |
|    iterations           | 1628      |
|    time_elapsed         | 5305      |
|    total_timesteps      | 3334144   |
| train/                  |           |
|    approx_kl            | 0.2552144 |
|    clip_fraction        | 0.389     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.578    |
|    explained_variance   | 0.858     |
|    learning_rate        | 0.00135   |
|    loss                 | -0.0441   |
|    n_updates            | 16270     |
|    policy_gradient_loss | -0.00495  |
|    std                  | 0.322     |
|    value_loss           | 0.0114    |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 628        |
|    iterations           | 1629       |
|    time_elapsed         | 5308       |
|    total_timesteps      | 3336192    |
| train/                  |            |
|    approx_kl            | 0.12652254 |
|    clip_fraction        | 0.389      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.575     |
|    explained_variance   | 0.836      |
|    learning_rate        | 0.00135    |
|    loss                 | -0.0392    |
|    n_updates            | 16280      |
|    policy_gradient_loss | 0.00591    |
|    std                  | 0.321      |
|    value_loss           | 0.00813    |
----------------------------------------
box reached target
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 628        |
|    iterations           | 1630       |
|    time_elapsed         | 5311       |
|    total_timesteps      | 3338240    |
| train/                  |            |
|    approx_kl            | 0.31019753 |
|    clip_fraction        | 0.384      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.53      |
|    explained_variance   | 0.793      |
|    learning_rate        | 0.00135    |
|    loss                 | -0.0115    |
|    n_updates            | 16290      |
|    policy_gradient_loss | 0.0048     |
|    std                  | 0.315      |
|    value_loss           | 0.0106     |
----------------------------------------
Eval num_timesteps=3340000, episode_reward=-0.74 +/- 0.51
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -0.744     |
| time/                   |            |
|    total_timesteps      | 3340000    |
| train/                  |            |
|    approx_kl            | 0.08545047 |
|    clip_fraction        | 0.356      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.551     |
|    explained_variance   | 0.823      |
|    learning_rate        | 0.00135    |
|    loss                 | -0.013     |
|    n_updates            | 16300      |
|    policy_gradient_loss | 0.000939   |
|    std                  | 0.324      |
|    value_loss           | 0.0233     |
----------------------------------------
box reached target
--------------------------------
| time/              |         |
|    fps             | 628     |
|    iterations      | 1631    |
|    time_elapsed    | 5315    |
|    total_timesteps | 3340288 |
--------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 628        |
|    iterations           | 1632       |
|    time_elapsed         | 5318       |
|    total_timesteps      | 3342336    |
| train/                  |            |
|    approx_kl            | 0.17569588 |
|    clip_fraction        | 0.38       |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.618     |
|    explained_variance   | 0.829      |
|    learning_rate        | 0.00135    |
|    loss                 | 0.0229     |
|    n_updates            | 16310      |
|    policy_gradient_loss | 0.0156     |
|    std                  | 0.333      |
|    value_loss           | 0.00923    |
----------------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 628         |
|    iterations           | 1633        |
|    time_elapsed         | 5321        |
|    total_timesteps      | 3344384     |
| train/                  |             |
|    approx_kl            | 0.105736844 |
|    clip_fraction        | 0.315       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.651      |
|    explained_variance   | 0.844       |
|    learning_rate        | 0.00135     |
|    loss                 | 0.00943     |
|    n_updates            | 16320       |
|    policy_gradient_loss | 0.000477    |
|    std                  | 0.338       |
|    value_loss           | 0.015       |
-----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 628        |
|    iterations           | 1634       |
|    time_elapsed         | 5324       |
|    total_timesteps      | 3346432    |
| train/                  |            |
|    approx_kl            | 0.11718195 |
|    clip_fraction        | 0.33       |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.656     |
|    explained_variance   | 0.935      |
|    learning_rate        | 0.00135    |
|    loss                 | 0.0227     |
|    n_updates            | 16330      |
|    policy_gradient_loss | 0.000559   |
|    std                  | 0.338      |
|    value_loss           | 0.00515    |
----------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 628       |
|    iterations           | 1635      |
|    time_elapsed         | 5327      |
|    total_timesteps      | 3348480   |
| train/                  |           |
|    approx_kl            | 0.1772922 |
|    clip_fraction        | 0.39      |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.659    |
|    explained_variance   | -0.195    |
|    learning_rate        | 0.00135   |
|    loss                 | -0.0235   |
|    n_updates            | 16340     |
|    policy_gradient_loss | -0.0033   |
|    std                  | 0.336     |
|    value_loss           | 0.00839   |
---------------------------------------
box reached target
box reached target
box reached target
Eval num_timesteps=3350000, episode_reward=-0.87 +/- 0.25
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -0.874     |
| time/                   |            |
|    total_timesteps      | 3350000    |
| train/                  |            |
|    approx_kl            | 0.13730757 |
|    clip_fraction        | 0.353      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.656     |
|    explained_variance   | 0.919      |
|    learning_rate        | 0.00135    |
|    loss                 | -0.00511   |
|    n_updates            | 16350      |
|    policy_gradient_loss | 0.00597    |
|    std                  | 0.336      |
|    value_loss           | 0.0102     |
----------------------------------------
box reached target
--------------------------------
| time/              |         |
|    fps             | 628     |
|    iterations      | 1636    |
|    time_elapsed    | 5331    |
|    total_timesteps | 3350528 |
--------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 628        |
|    iterations           | 1637       |
|    time_elapsed         | 5334       |
|    total_timesteps      | 3352576    |
| train/                  |            |
|    approx_kl            | 0.16644439 |
|    clip_fraction        | 0.397      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.601     |
|    explained_variance   | 0.804      |
|    learning_rate        | 0.00135    |
|    loss                 | -0.0195    |
|    n_updates            | 16360      |
|    policy_gradient_loss | 0.00728    |
|    std                  | 0.324      |
|    value_loss           | 0.0385     |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 628        |
|    iterations           | 1638       |
|    time_elapsed         | 5337       |
|    total_timesteps      | 3354624    |
| train/                  |            |
|    approx_kl            | 0.28101495 |
|    clip_fraction        | 0.366      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.59      |
|    explained_variance   | 0.769      |
|    learning_rate        | 0.00135    |
|    loss                 | 0.0209     |
|    n_updates            | 16370      |
|    policy_gradient_loss | -0.000471  |
|    std                  | 0.325      |
|    value_loss           | 0.021      |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 628        |
|    iterations           | 1639       |
|    time_elapsed         | 5340       |
|    total_timesteps      | 3356672    |
| train/                  |            |
|    approx_kl            | 0.19098143 |
|    clip_fraction        | 0.365      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.581     |
|    explained_variance   | 0.702      |
|    learning_rate        | 0.00135    |
|    loss                 | -0.0112    |
|    n_updates            | 16380      |
|    policy_gradient_loss | -0.0111    |
|    std                  | 0.32       |
|    value_loss           | 0.00521    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 628        |
|    iterations           | 1640       |
|    time_elapsed         | 5343       |
|    total_timesteps      | 3358720    |
| train/                  |            |
|    approx_kl            | 0.54668695 |
|    clip_fraction        | 0.394      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.52      |
|    explained_variance   | 0.779      |
|    learning_rate        | 0.00135    |
|    loss                 | -0.0293    |
|    n_updates            | 16390      |
|    policy_gradient_loss | -0.00901   |
|    std                  | 0.311      |
|    value_loss           | 0.0123     |
----------------------------------------
Eval num_timesteps=3360000, episode_reward=-0.74 +/- 0.52
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -0.738     |
| time/                   |            |
|    total_timesteps      | 3360000    |
| train/                  |            |
|    approx_kl            | 0.05288004 |
|    clip_fraction        | 0.338      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.508     |
|    explained_variance   | 0.824      |
|    learning_rate        | 0.00135    |
|    loss                 | 0.0533     |
|    n_updates            | 16400      |
|    policy_gradient_loss | 0.0045     |
|    std                  | 0.314      |
|    value_loss           | 0.00459    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 628     |
|    iterations      | 1641    |
|    time_elapsed    | 5347    |
|    total_timesteps | 3360768 |
--------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 628        |
|    iterations           | 1642       |
|    time_elapsed         | 5350       |
|    total_timesteps      | 3362816    |
| train/                  |            |
|    approx_kl            | 0.23263232 |
|    clip_fraction        | 0.39       |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.553     |
|    explained_variance   | 0.653      |
|    learning_rate        | 0.00134    |
|    loss                 | -0.0582    |
|    n_updates            | 16410      |
|    policy_gradient_loss | -0.0113    |
|    std                  | 0.319      |
|    value_loss           | 0.00398    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 628        |
|    iterations           | 1643       |
|    time_elapsed         | 5353       |
|    total_timesteps      | 3364864    |
| train/                  |            |
|    approx_kl            | 0.06730746 |
|    clip_fraction        | 0.373      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.615     |
|    explained_variance   | 0.864      |
|    learning_rate        | 0.00134    |
|    loss                 | 0.0191     |
|    n_updates            | 16420      |
|    policy_gradient_loss | 0.00274    |
|    std                  | 0.333      |
|    value_loss           | 0.0139     |
----------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 628       |
|    iterations           | 1644      |
|    time_elapsed         | 5356      |
|    total_timesteps      | 3366912   |
| train/                  |           |
|    approx_kl            | 0.1836623 |
|    clip_fraction        | 0.388     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.618    |
|    explained_variance   | 0.323     |
|    learning_rate        | 0.00134   |
|    loss                 | -0.0119   |
|    n_updates            | 16430     |
|    policy_gradient_loss | -0.00485  |
|    std                  | 0.326     |
|    value_loss           | 0.00356   |
---------------------------------------
box reached target
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 628       |
|    iterations           | 1645      |
|    time_elapsed         | 5359      |
|    total_timesteps      | 3368960   |
| train/                  |           |
|    approx_kl            | 0.0710979 |
|    clip_fraction        | 0.284     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.589    |
|    explained_variance   | 0.782     |
|    learning_rate        | 0.00134   |
|    loss                 | -0.00722  |
|    n_updates            | 16440     |
|    policy_gradient_loss | 0.00115   |
|    std                  | 0.326     |
|    value_loss           | 0.00541   |
---------------------------------------
box reached target
box reached target
box reached target
Eval num_timesteps=3370000, episode_reward=1.47 +/- 3.03
Episode length: 243.00 +/- 69.82
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 243        |
|    mean_reward          | 1.47       |
| time/                   |            |
|    total_timesteps      | 3370000    |
| train/                  |            |
|    approx_kl            | 0.41270947 |
|    clip_fraction        | 0.425      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.607     |
|    explained_variance   | 0.806      |
|    learning_rate        | 0.00134    |
|    loss                 | 0.0229     |
|    n_updates            | 16450      |
|    policy_gradient_loss | 0.0197     |
|    std                  | 0.327      |
|    value_loss           | 0.0222     |
----------------------------------------
box reached target
--------------------------------
| time/              |         |
|    fps             | 628     |
|    iterations      | 1646    |
|    time_elapsed    | 5363    |
|    total_timesteps | 3371008 |
--------------------------------
box reached target
box reached target
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 628       |
|    iterations           | 1647      |
|    time_elapsed         | 5366      |
|    total_timesteps      | 3373056   |
| train/                  |           |
|    approx_kl            | 0.1056173 |
|    clip_fraction        | 0.392     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.579    |
|    explained_variance   | 0.935     |
|    learning_rate        | 0.00134   |
|    loss                 | 0.0145    |
|    n_updates            | 16460     |
|    policy_gradient_loss | -0.0028   |
|    std                  | 0.322     |
|    value_loss           | 0.00931   |
---------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 628        |
|    iterations           | 1648       |
|    time_elapsed         | 5369       |
|    total_timesteps      | 3375104    |
| train/                  |            |
|    approx_kl            | 0.11642961 |
|    clip_fraction        | 0.364      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.569     |
|    explained_variance   | 0.928      |
|    learning_rate        | 0.00134    |
|    loss                 | 0.0269     |
|    n_updates            | 16470      |
|    policy_gradient_loss | 0.00934    |
|    std                  | 0.32       |
|    value_loss           | 0.01       |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 628        |
|    iterations           | 1649       |
|    time_elapsed         | 5372       |
|    total_timesteps      | 3377152    |
| train/                  |            |
|    approx_kl            | 0.18866529 |
|    clip_fraction        | 0.377      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.547     |
|    explained_variance   | 0.947      |
|    learning_rate        | 0.00134    |
|    loss                 | -0.0117    |
|    n_updates            | 16480      |
|    policy_gradient_loss | -0.00612   |
|    std                  | 0.317      |
|    value_loss           | 0.00566    |
----------------------------------------
box reached target
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 628         |
|    iterations           | 1650        |
|    time_elapsed         | 5375        |
|    total_timesteps      | 3379200     |
| train/                  |             |
|    approx_kl            | 0.044101596 |
|    clip_fraction        | 0.295       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.536      |
|    explained_variance   | 0.881       |
|    learning_rate        | 0.00134     |
|    loss                 | 0.002       |
|    n_updates            | 16490       |
|    policy_gradient_loss | 0.00872     |
|    std                  | 0.317       |
|    value_loss           | 0.0105      |
-----------------------------------------
box reached target
box reached target
Eval num_timesteps=3380000, episode_reward=0.20 +/- 2.40
Episode length: 274.40 +/- 51.20
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 274        |
|    mean_reward          | 0.199      |
| time/                   |            |
|    total_timesteps      | 3380000    |
| train/                  |            |
|    approx_kl            | 0.08360082 |
|    clip_fraction        | 0.35       |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.607     |
|    explained_variance   | 0.909      |
|    learning_rate        | 0.00134    |
|    loss                 | 0.0294     |
|    n_updates            | 16500      |
|    policy_gradient_loss | 0.00459    |
|    std                  | 0.337      |
|    value_loss           | 0.0106     |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 628     |
|    iterations      | 1651    |
|    time_elapsed    | 5379    |
|    total_timesteps | 3381248 |
--------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 628        |
|    iterations           | 1652       |
|    time_elapsed         | 5382       |
|    total_timesteps      | 3383296    |
| train/                  |            |
|    approx_kl            | 0.11859432 |
|    clip_fraction        | 0.341      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.68      |
|    explained_variance   | 0.928      |
|    learning_rate        | 0.00134    |
|    loss                 | -0.0197    |
|    n_updates            | 16510      |
|    policy_gradient_loss | 0.0139     |
|    std                  | 0.343      |
|    value_loss           | 0.00611    |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 628        |
|    iterations           | 1653       |
|    time_elapsed         | 5385       |
|    total_timesteps      | 3385344    |
| train/                  |            |
|    approx_kl            | 0.12289382 |
|    clip_fraction        | 0.361      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.686     |
|    explained_variance   | 0.899      |
|    learning_rate        | 0.00134    |
|    loss                 | -0.00104   |
|    n_updates            | 16520      |
|    policy_gradient_loss | 0.00462    |
|    std                  | 0.345      |
|    value_loss           | 0.0113     |
----------------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 628        |
|    iterations           | 1654       |
|    time_elapsed         | 5388       |
|    total_timesteps      | 3387392    |
| train/                  |            |
|    approx_kl            | 0.11220207 |
|    clip_fraction        | 0.325      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.753     |
|    explained_variance   | 0.892      |
|    learning_rate        | 0.00134    |
|    loss                 | 0.0159     |
|    n_updates            | 16530      |
|    policy_gradient_loss | -0.000456  |
|    std                  | 0.359      |
|    value_loss           | 0.00984    |
----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 628       |
|    iterations           | 1655      |
|    time_elapsed         | 5391      |
|    total_timesteps      | 3389440   |
| train/                  |           |
|    approx_kl            | 0.1732078 |
|    clip_fraction        | 0.381     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.787    |
|    explained_variance   | 0.857     |
|    learning_rate        | 0.00134   |
|    loss                 | -0.0015   |
|    n_updates            | 16540     |
|    policy_gradient_loss | 0.00524   |
|    std                  | 0.365     |
|    value_loss           | 0.0185    |
---------------------------------------
box reached target
box reached target
Eval num_timesteps=3390000, episode_reward=1.46 +/- 3.02
Episode length: 252.00 +/- 59.65
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 252        |
|    mean_reward          | 1.46       |
| time/                   |            |
|    total_timesteps      | 3390000    |
| train/                  |            |
|    approx_kl            | 0.08695637 |
|    clip_fraction        | 0.339      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.824     |
|    explained_variance   | 0.873      |
|    learning_rate        | 0.00134    |
|    loss                 | -0.0194    |
|    n_updates            | 16550      |
|    policy_gradient_loss | -0.000451  |
|    std                  | 0.369      |
|    value_loss           | 0.00938    |
----------------------------------------
box reached target
--------------------------------
| time/              |         |
|    fps             | 628     |
|    iterations      | 1656    |
|    time_elapsed    | 5395    |
|    total_timesteps | 3391488 |
--------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 628        |
|    iterations           | 1657       |
|    time_elapsed         | 5398       |
|    total_timesteps      | 3393536    |
| train/                  |            |
|    approx_kl            | 0.10708302 |
|    clip_fraction        | 0.353      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.826     |
|    explained_variance   | 0.852      |
|    learning_rate        | 0.00134    |
|    loss                 | -0.019     |
|    n_updates            | 16560      |
|    policy_gradient_loss | 0.00122    |
|    std                  | 0.371      |
|    value_loss           | 0.00636    |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 628        |
|    iterations           | 1658       |
|    time_elapsed         | 5401       |
|    total_timesteps      | 3395584    |
| train/                  |            |
|    approx_kl            | 0.25501427 |
|    clip_fraction        | 0.401      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.826     |
|    explained_variance   | 0.819      |
|    learning_rate        | 0.00134    |
|    loss                 | -0.0222    |
|    n_updates            | 16570      |
|    policy_gradient_loss | 0.012      |
|    std                  | 0.362      |
|    value_loss           | 0.0156     |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 628        |
|    iterations           | 1659       |
|    time_elapsed         | 5404       |
|    total_timesteps      | 3397632    |
| train/                  |            |
|    approx_kl            | 0.05212553 |
|    clip_fraction        | 0.337      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.814     |
|    explained_variance   | 0.858      |
|    learning_rate        | 0.00134    |
|    loss                 | -0.0363    |
|    n_updates            | 16580      |
|    policy_gradient_loss | 0.0092     |
|    std                  | 0.37       |
|    value_loss           | 0.0139     |
----------------------------------------
box reached target
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 628         |
|    iterations           | 1660        |
|    time_elapsed         | 5407        |
|    total_timesteps      | 3399680     |
| train/                  |             |
|    approx_kl            | 0.050233666 |
|    clip_fraction        | 0.333       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.832      |
|    explained_variance   | 0.709       |
|    learning_rate        | 0.00134     |
|    loss                 | 0.00371     |
|    n_updates            | 16590       |
|    policy_gradient_loss | 0.00438     |
|    std                  | 0.374       |
|    value_loss           | 0.0121      |
-----------------------------------------
Eval num_timesteps=3400000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1         |
| time/                   |            |
|    total_timesteps      | 3400000    |
| train/                  |            |
|    approx_kl            | 0.22248231 |
|    clip_fraction        | 0.35       |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.826     |
|    explained_variance   | 0.893      |
|    learning_rate        | 0.00134    |
|    loss                 | 0.0254     |
|    n_updates            | 16600      |
|    policy_gradient_loss | 0.0114     |
|    std                  | 0.366      |
|    value_loss           | 0.0112     |
----------------------------------------
box reached target
box reached target
--------------------------------
| time/              |         |
|    fps             | 628     |
|    iterations      | 1661    |
|    time_elapsed    | 5411    |
|    total_timesteps | 3401728 |
--------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 628        |
|    iterations           | 1662       |
|    time_elapsed         | 5414       |
|    total_timesteps      | 3403776    |
| train/                  |            |
|    approx_kl            | 0.07296071 |
|    clip_fraction        | 0.382      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.855     |
|    explained_variance   | 0.873      |
|    learning_rate        | 0.00134    |
|    loss                 | -0.0198    |
|    n_updates            | 16610      |
|    policy_gradient_loss | 0.00986    |
|    std                  | 0.384      |
|    value_loss           | 0.0148     |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 628        |
|    iterations           | 1663       |
|    time_elapsed         | 5417       |
|    total_timesteps      | 3405824    |
| train/                  |            |
|    approx_kl            | 0.18062246 |
|    clip_fraction        | 0.387      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.906     |
|    explained_variance   | 0.926      |
|    learning_rate        | 0.00134    |
|    loss                 | 0.0166     |
|    n_updates            | 16620      |
|    policy_gradient_loss | -0.000693  |
|    std                  | 0.383      |
|    value_loss           | 0.00943    |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 628        |
|    iterations           | 1664       |
|    time_elapsed         | 5420       |
|    total_timesteps      | 3407872    |
| train/                  |            |
|    approx_kl            | 0.10310739 |
|    clip_fraction        | 0.338      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.928     |
|    explained_variance   | 0.888      |
|    learning_rate        | 0.00134    |
|    loss                 | -0.00324   |
|    n_updates            | 16630      |
|    policy_gradient_loss | -0.00108   |
|    std                  | 0.395      |
|    value_loss           | 0.00536    |
----------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 628       |
|    iterations           | 1665      |
|    time_elapsed         | 5423      |
|    total_timesteps      | 3409920   |
| train/                  |           |
|    approx_kl            | 0.0823131 |
|    clip_fraction        | 0.301     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.918    |
|    explained_variance   | 0.922     |
|    learning_rate        | 0.00134   |
|    loss                 | -0.0132   |
|    n_updates            | 16640     |
|    policy_gradient_loss | -0.0112   |
|    std                  | 0.387     |
|    value_loss           | 0.00555   |
---------------------------------------
Eval num_timesteps=3410000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 300       |
|    mean_reward          | -1        |
| time/                   |           |
|    total_timesteps      | 3410000   |
| train/                  |           |
|    approx_kl            | 0.1049749 |
|    clip_fraction        | 0.322     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.903    |
|    explained_variance   | 0.9       |
|    learning_rate        | 0.00134   |
|    loss                 | 0.0302    |
|    n_updates            | 16650     |
|    policy_gradient_loss | -0.00633  |
|    std                  | 0.388     |
|    value_loss           | 0.0071    |
---------------------------------------
box reached target
box reached target
box reached target
box reached target
--------------------------------
| time/              |         |
|    fps             | 628     |
|    iterations      | 1666    |
|    time_elapsed    | 5427    |
|    total_timesteps | 3411968 |
--------------------------------
box reached target
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 628         |
|    iterations           | 1667        |
|    time_elapsed         | 5430        |
|    total_timesteps      | 3414016     |
| train/                  |             |
|    approx_kl            | 0.106475174 |
|    clip_fraction        | 0.338       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.841      |
|    explained_variance   | 0.889       |
|    learning_rate        | 0.00133     |
|    loss                 | -0.02       |
|    n_updates            | 16660       |
|    policy_gradient_loss | 0.00158     |
|    std                  | 0.37        |
|    value_loss           | 0.0219      |
-----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 628       |
|    iterations           | 1668      |
|    time_elapsed         | 5433      |
|    total_timesteps      | 3416064   |
| train/                  |           |
|    approx_kl            | 0.2824384 |
|    clip_fraction        | 0.353     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.812    |
|    explained_variance   | 0.796     |
|    learning_rate        | 0.00133   |
|    loss                 | -0.0249   |
|    n_updates            | 16670     |
|    policy_gradient_loss | -0.0133   |
|    std                  | 0.372     |
|    value_loss           | 0.0216    |
---------------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 628        |
|    iterations           | 1669       |
|    time_elapsed         | 5436       |
|    total_timesteps      | 3418112    |
| train/                  |            |
|    approx_kl            | 0.25584814 |
|    clip_fraction        | 0.366      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.747     |
|    explained_variance   | 0.449      |
|    learning_rate        | 0.00133    |
|    loss                 | -0.0316    |
|    n_updates            | 16680      |
|    policy_gradient_loss | 0.000583   |
|    std                  | 0.351      |
|    value_loss           | 0.0215     |
----------------------------------------
box reached target
box reached target
box reached target
box reached target
Eval num_timesteps=3420000, episode_reward=2.69 +/- 3.01
Episode length: 216.20 +/- 68.57
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 216        |
|    mean_reward          | 2.69       |
| time/                   |            |
|    total_timesteps      | 3420000    |
| train/                  |            |
|    approx_kl            | 0.28555548 |
|    clip_fraction        | 0.387      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.632     |
|    explained_variance   | 0.843      |
|    learning_rate        | 0.00133    |
|    loss                 | 0.0491     |
|    n_updates            | 16690      |
|    policy_gradient_loss | 0.00124    |
|    std                  | 0.329      |
|    value_loss           | 0.0433     |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 628     |
|    iterations      | 1670    |
|    time_elapsed    | 5440    |
|    total_timesteps | 3420160 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 628        |
|    iterations           | 1671       |
|    time_elapsed         | 5443       |
|    total_timesteps      | 3422208    |
| train/                  |            |
|    approx_kl            | 0.18745132 |
|    clip_fraction        | 0.391      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.57      |
|    explained_variance   | 0.862      |
|    learning_rate        | 0.00133    |
|    loss                 | -0.00939   |
|    n_updates            | 16700      |
|    policy_gradient_loss | 0.00488    |
|    std                  | 0.326      |
|    value_loss           | 0.00792    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 628        |
|    iterations           | 1672       |
|    time_elapsed         | 5446       |
|    total_timesteps      | 3424256    |
| train/                  |            |
|    approx_kl            | 0.16953845 |
|    clip_fraction        | 0.384      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.542     |
|    explained_variance   | 0.689      |
|    learning_rate        | 0.00133    |
|    loss                 | -0.0476    |
|    n_updates            | 16710      |
|    policy_gradient_loss | 0.00338    |
|    std                  | 0.32       |
|    value_loss           | 0.00994    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 628        |
|    iterations           | 1673       |
|    time_elapsed         | 5449       |
|    total_timesteps      | 3426304    |
| train/                  |            |
|    approx_kl            | 0.15972248 |
|    clip_fraction        | 0.392      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.517     |
|    explained_variance   | 0.681      |
|    learning_rate        | 0.00133    |
|    loss                 | 0.0405     |
|    n_updates            | 16720      |
|    policy_gradient_loss | 6.12e-05   |
|    std                  | 0.316      |
|    value_loss           | 0.00569    |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 628        |
|    iterations           | 1674       |
|    time_elapsed         | 5452       |
|    total_timesteps      | 3428352    |
| train/                  |            |
|    approx_kl            | 0.07829973 |
|    clip_fraction        | 0.327      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.528     |
|    explained_variance   | 0.743      |
|    learning_rate        | 0.00133    |
|    loss                 | 0.131      |
|    n_updates            | 16730      |
|    policy_gradient_loss | 0.00414    |
|    std                  | 0.331      |
|    value_loss           | 0.00865    |
----------------------------------------
box reached target
box reached target
Eval num_timesteps=3430000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1         |
| time/                   |            |
|    total_timesteps      | 3430000    |
| train/                  |            |
|    approx_kl            | 0.62383664 |
|    clip_fraction        | 0.364      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.514     |
|    explained_variance   | 0.939      |
|    learning_rate        | 0.00133    |
|    loss                 | 0.021      |
|    n_updates            | 16740      |
|    policy_gradient_loss | -0.00618   |
|    std                  | 0.319      |
|    value_loss           | 0.00636    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 628     |
|    iterations      | 1675    |
|    time_elapsed    | 5456    |
|    total_timesteps | 3430400 |
--------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 628        |
|    iterations           | 1676       |
|    time_elapsed         | 5459       |
|    total_timesteps      | 3432448    |
| train/                  |            |
|    approx_kl            | 0.32295504 |
|    clip_fraction        | 0.414      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.488     |
|    explained_variance   | 0.773      |
|    learning_rate        | 0.00133    |
|    loss                 | 0.0428     |
|    n_updates            | 16750      |
|    policy_gradient_loss | 0.0014     |
|    std                  | 0.318      |
|    value_loss           | 0.0179     |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 628        |
|    iterations           | 1677       |
|    time_elapsed         | 5462       |
|    total_timesteps      | 3434496    |
| train/                  |            |
|    approx_kl            | 0.31593794 |
|    clip_fraction        | 0.413      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.424     |
|    explained_variance   | 0.676      |
|    learning_rate        | 0.00133    |
|    loss                 | -0.00873   |
|    n_updates            | 16760      |
|    policy_gradient_loss | -0.00285   |
|    std                  | 0.301      |
|    value_loss           | 0.0351     |
----------------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 628        |
|    iterations           | 1678       |
|    time_elapsed         | 5465       |
|    total_timesteps      | 3436544    |
| train/                  |            |
|    approx_kl            | 0.20354608 |
|    clip_fraction        | 0.381      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.354     |
|    explained_variance   | 0.818      |
|    learning_rate        | 0.00133    |
|    loss                 | -0.0119    |
|    n_updates            | 16770      |
|    policy_gradient_loss | 0.00895    |
|    std                  | 0.295      |
|    value_loss           | 0.00628    |
----------------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 628         |
|    iterations           | 1679        |
|    time_elapsed         | 5468        |
|    total_timesteps      | 3438592     |
| train/                  |             |
|    approx_kl            | 0.123108156 |
|    clip_fraction        | 0.393       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.357      |
|    explained_variance   | 0.401       |
|    learning_rate        | 0.00133     |
|    loss                 | -0.00477    |
|    n_updates            | 16780       |
|    policy_gradient_loss | 0.00628     |
|    std                  | 0.298       |
|    value_loss           | 0.0244      |
-----------------------------------------
box reached target
Eval num_timesteps=3440000, episode_reward=0.20 +/- 2.41
Episode length: 273.20 +/- 53.60
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 273        |
|    mean_reward          | 0.204      |
| time/                   |            |
|    total_timesteps      | 3440000    |
| train/                  |            |
|    approx_kl            | 0.24698372 |
|    clip_fraction        | 0.43       |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.365     |
|    explained_variance   | 0.819      |
|    learning_rate        | 0.00133    |
|    loss                 | 0.0382     |
|    n_updates            | 16790      |
|    policy_gradient_loss | 0.0107     |
|    std                  | 0.3        |
|    value_loss           | 0.00845    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 628     |
|    iterations      | 1680    |
|    time_elapsed    | 5472    |
|    total_timesteps | 3440640 |
--------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 628        |
|    iterations           | 1681       |
|    time_elapsed         | 5475       |
|    total_timesteps      | 3442688    |
| train/                  |            |
|    approx_kl            | 0.49973598 |
|    clip_fraction        | 0.38       |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.352     |
|    explained_variance   | 0.271      |
|    learning_rate        | 0.00133    |
|    loss                 | -0.0467    |
|    n_updates            | 16800      |
|    policy_gradient_loss | 0.0127     |
|    std                  | 0.296      |
|    value_loss           | 0.00771    |
----------------------------------------
box reached target
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 628        |
|    iterations           | 1682       |
|    time_elapsed         | 5478       |
|    total_timesteps      | 3444736    |
| train/                  |            |
|    approx_kl            | 0.19127333 |
|    clip_fraction        | 0.376      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.309     |
|    explained_variance   | 0.704      |
|    learning_rate        | 0.00133    |
|    loss                 | -0.0143    |
|    n_updates            | 16810      |
|    policy_gradient_loss | -0.00279   |
|    std                  | 0.293      |
|    value_loss           | 0.0296     |
----------------------------------------
box reached target
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 628        |
|    iterations           | 1683       |
|    time_elapsed         | 5481       |
|    total_timesteps      | 3446784    |
| train/                  |            |
|    approx_kl            | 0.20281416 |
|    clip_fraction        | 0.411      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.302     |
|    explained_variance   | 0.548      |
|    learning_rate        | 0.00133    |
|    loss                 | 0.0337     |
|    n_updates            | 16820      |
|    policy_gradient_loss | 0.0103     |
|    std                  | 0.294      |
|    value_loss           | 0.058      |
----------------------------------------
box reached target
box reached target
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 628       |
|    iterations           | 1684      |
|    time_elapsed         | 5485      |
|    total_timesteps      | 3448832   |
| train/                  |           |
|    approx_kl            | 0.2520842 |
|    clip_fraction        | 0.436     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.312    |
|    explained_variance   | 0.886     |
|    learning_rate        | 0.00133   |
|    loss                 | -0.00214  |
|    n_updates            | 16830     |
|    policy_gradient_loss | 0.0134    |
|    std                  | 0.298     |
|    value_loss           | 0.0205    |
---------------------------------------
box reached target
box reached target
Eval num_timesteps=3450000, episode_reward=0.24 +/- 2.48
Episode length: 275.40 +/- 49.20
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 275        |
|    mean_reward          | 0.242      |
| time/                   |            |
|    total_timesteps      | 3450000    |
| train/                  |            |
|    approx_kl            | 0.64023274 |
|    clip_fraction        | 0.396      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.343     |
|    explained_variance   | 0.89       |
|    learning_rate        | 0.00133    |
|    loss                 | 0.00459    |
|    n_updates            | 16840      |
|    policy_gradient_loss | 0.0137     |
|    std                  | 0.304      |
|    value_loss           | 0.0135     |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 628     |
|    iterations      | 1685    |
|    time_elapsed    | 5488    |
|    total_timesteps | 3450880 |
--------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 628        |
|    iterations           | 1686       |
|    time_elapsed         | 5491       |
|    total_timesteps      | 3452928    |
| train/                  |            |
|    approx_kl            | 0.18597905 |
|    clip_fraction        | 0.398      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.327     |
|    explained_variance   | 0.689      |
|    learning_rate        | 0.00133    |
|    loss                 | -0.0109    |
|    n_updates            | 16850      |
|    policy_gradient_loss | 0.00286    |
|    std                  | 0.296      |
|    value_loss           | 0.0105     |
----------------------------------------
box reached target
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 628        |
|    iterations           | 1687       |
|    time_elapsed         | 5494       |
|    total_timesteps      | 3454976    |
| train/                  |            |
|    approx_kl            | 0.16133635 |
|    clip_fraction        | 0.402      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.363     |
|    explained_variance   | 0.885      |
|    learning_rate        | 0.00133    |
|    loss                 | 0.0543     |
|    n_updates            | 16860      |
|    policy_gradient_loss | 0.0137     |
|    std                  | 0.308      |
|    value_loss           | 0.0125     |
----------------------------------------
box reached target
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 628        |
|    iterations           | 1688       |
|    time_elapsed         | 5498       |
|    total_timesteps      | 3457024    |
| train/                  |            |
|    approx_kl            | 0.17162786 |
|    clip_fraction        | 0.394      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.411     |
|    explained_variance   | 0.89       |
|    learning_rate        | 0.00133    |
|    loss                 | 0.133      |
|    n_updates            | 16870      |
|    policy_gradient_loss | 0.0158     |
|    std                  | 0.31       |
|    value_loss           | 0.0117     |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 628        |
|    iterations           | 1689       |
|    time_elapsed         | 5501       |
|    total_timesteps      | 3459072    |
| train/                  |            |
|    approx_kl            | 0.10453953 |
|    clip_fraction        | 0.355      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.412     |
|    explained_variance   | 0.937      |
|    learning_rate        | 0.00133    |
|    loss                 | 0.00476    |
|    n_updates            | 16880      |
|    policy_gradient_loss | 0.00182    |
|    std                  | 0.308      |
|    value_loss           | 0.0184     |
----------------------------------------
Eval num_timesteps=3460000, episode_reward=-0.86 +/- 0.29
Episode length: 300.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 300       |
|    mean_reward          | -0.857    |
| time/                   |           |
|    total_timesteps      | 3460000   |
| train/                  |           |
|    approx_kl            | 0.1874533 |
|    clip_fraction        | 0.399     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.378    |
|    explained_variance   | 0.88      |
|    learning_rate        | 0.00133   |
|    loss                 | -0.0261   |
|    n_updates            | 16890     |
|    policy_gradient_loss | 0.0155    |
|    std                  | 0.302     |
|    value_loss           | 0.0148    |
---------------------------------------
box reached target
--------------------------------
| time/              |         |
|    fps             | 628     |
|    iterations      | 1690    |
|    time_elapsed    | 5505    |
|    total_timesteps | 3461120 |
--------------------------------
box reached target
box reached target
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 628        |
|    iterations           | 1691       |
|    time_elapsed         | 5508       |
|    total_timesteps      | 3463168    |
| train/                  |            |
|    approx_kl            | 0.17812239 |
|    clip_fraction        | 0.401      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.343     |
|    explained_variance   | 0.939      |
|    learning_rate        | 0.00133    |
|    loss                 | 0.0234     |
|    n_updates            | 16900      |
|    policy_gradient_loss | -0.00194   |
|    std                  | 0.293      |
|    value_loss           | 0.00957    |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 628        |
|    iterations           | 1692       |
|    time_elapsed         | 5511       |
|    total_timesteps      | 3465216    |
| train/                  |            |
|    approx_kl            | 0.18133396 |
|    clip_fraction        | 0.399      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.326     |
|    explained_variance   | 0.842      |
|    learning_rate        | 0.00132    |
|    loss                 | 0.00656    |
|    n_updates            | 16910      |
|    policy_gradient_loss | 0.0232     |
|    std                  | 0.294      |
|    value_loss           | 0.0415     |
----------------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 628        |
|    iterations           | 1693       |
|    time_elapsed         | 5514       |
|    total_timesteps      | 3467264    |
| train/                  |            |
|    approx_kl            | 0.15305024 |
|    clip_fraction        | 0.345      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.331     |
|    explained_variance   | 0.933      |
|    learning_rate        | 0.00132    |
|    loss                 | -0.0419    |
|    n_updates            | 16920      |
|    policy_gradient_loss | -0.00786   |
|    std                  | 0.292      |
|    value_loss           | 0.00664    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 628        |
|    iterations           | 1694       |
|    time_elapsed         | 5517       |
|    total_timesteps      | 3469312    |
| train/                  |            |
|    approx_kl            | 0.20924096 |
|    clip_fraction        | 0.425      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.305     |
|    explained_variance   | 0.929      |
|    learning_rate        | 0.00132    |
|    loss                 | -0.00687   |
|    n_updates            | 16930      |
|    policy_gradient_loss | 0.0085     |
|    std                  | 0.29       |
|    value_loss           | 0.00764    |
----------------------------------------
box reached target
box reached target
Eval num_timesteps=3470000, episode_reward=0.28 +/- 2.55
Episode length: 280.80 +/- 38.40
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 281        |
|    mean_reward          | 0.276      |
| time/                   |            |
|    total_timesteps      | 3470000    |
| train/                  |            |
|    approx_kl            | 0.15556252 |
|    clip_fraction        | 0.391      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.307     |
|    explained_variance   | 0.531      |
|    learning_rate        | 0.00132    |
|    loss                 | 0.00556    |
|    n_updates            | 16940      |
|    policy_gradient_loss | 0.00437    |
|    std                  | 0.286      |
|    value_loss           | 0.00285    |
----------------------------------------
box reached target
box reached target
--------------------------------
| time/              |         |
|    fps             | 628     |
|    iterations      | 1695    |
|    time_elapsed    | 5521    |
|    total_timesteps | 3471360 |
--------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 628        |
|    iterations           | 1696       |
|    time_elapsed         | 5524       |
|    total_timesteps      | 3473408    |
| train/                  |            |
|    approx_kl            | 0.40597415 |
|    clip_fraction        | 0.446      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.242     |
|    explained_variance   | 0.954      |
|    learning_rate        | 0.00132    |
|    loss                 | -0.0471    |
|    n_updates            | 16950      |
|    policy_gradient_loss | -0.00493   |
|    std                  | 0.278      |
|    value_loss           | 0.00962    |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 628        |
|    iterations           | 1697       |
|    time_elapsed         | 5527       |
|    total_timesteps      | 3475456    |
| train/                  |            |
|    approx_kl            | 0.07743831 |
|    clip_fraction        | 0.386      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.268     |
|    explained_variance   | 0.943      |
|    learning_rate        | 0.00132    |
|    loss                 | 0.0183     |
|    n_updates            | 16960      |
|    policy_gradient_loss | 0.0149     |
|    std                  | 0.287      |
|    value_loss           | 0.00687    |
----------------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 628        |
|    iterations           | 1698       |
|    time_elapsed         | 5530       |
|    total_timesteps      | 3477504    |
| train/                  |            |
|    approx_kl            | 0.11664829 |
|    clip_fraction        | 0.378      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.319     |
|    explained_variance   | 0.874      |
|    learning_rate        | 0.00132    |
|    loss                 | 0.00336    |
|    n_updates            | 16970      |
|    policy_gradient_loss | 0.00632    |
|    std                  | 0.29       |
|    value_loss           | 0.011      |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 628        |
|    iterations           | 1699       |
|    time_elapsed         | 5533       |
|    total_timesteps      | 3479552    |
| train/                  |            |
|    approx_kl            | 0.09270506 |
|    clip_fraction        | 0.374      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.319     |
|    explained_variance   | 0.849      |
|    learning_rate        | 0.00132    |
|    loss                 | 0.0498     |
|    n_updates            | 16980      |
|    policy_gradient_loss | 0.0237     |
|    std                  | 0.289      |
|    value_loss           | 0.0588     |
----------------------------------------
box reached target
Eval num_timesteps=3480000, episode_reward=0.51 +/- 2.54
Episode length: 287.00 +/- 26.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 287        |
|    mean_reward          | 0.514      |
| time/                   |            |
|    total_timesteps      | 3480000    |
| train/                  |            |
|    approx_kl            | 0.21125445 |
|    clip_fraction        | 0.358      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.338     |
|    explained_variance   | 0.881      |
|    learning_rate        | 0.00132    |
|    loss                 | -0.00414   |
|    n_updates            | 16990      |
|    policy_gradient_loss | -0.00277   |
|    std                  | 0.293      |
|    value_loss           | 0.0151     |
----------------------------------------
box reached target
box reached target
--------------------------------
| time/              |         |
|    fps             | 628     |
|    iterations      | 1700    |
|    time_elapsed    | 5537    |
|    total_timesteps | 3481600 |
--------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 628        |
|    iterations           | 1701       |
|    time_elapsed         | 5540       |
|    total_timesteps      | 3483648    |
| train/                  |            |
|    approx_kl            | 0.12137547 |
|    clip_fraction        | 0.369      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.381     |
|    explained_variance   | 0.889      |
|    learning_rate        | 0.00132    |
|    loss                 | 0.00735    |
|    n_updates            | 17000      |
|    policy_gradient_loss | 0.00985    |
|    std                  | 0.3        |
|    value_loss           | 0.02       |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 628        |
|    iterations           | 1702       |
|    time_elapsed         | 5543       |
|    total_timesteps      | 3485696    |
| train/                  |            |
|    approx_kl            | 0.19871636 |
|    clip_fraction        | 0.343      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.391     |
|    explained_variance   | 0.936      |
|    learning_rate        | 0.00132    |
|    loss                 | -9.33e-05  |
|    n_updates            | 17010      |
|    policy_gradient_loss | -0.000178  |
|    std                  | 0.3        |
|    value_loss           | 0.0075     |
----------------------------------------
box reached target
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 628        |
|    iterations           | 1703       |
|    time_elapsed         | 5546       |
|    total_timesteps      | 3487744    |
| train/                  |            |
|    approx_kl            | 0.13808921 |
|    clip_fraction        | 0.394      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.399     |
|    explained_variance   | 0.872      |
|    learning_rate        | 0.00132    |
|    loss                 | 0.00276    |
|    n_updates            | 17020      |
|    policy_gradient_loss | 0.0195     |
|    std                  | 0.299      |
|    value_loss           | 0.0133     |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 628        |
|    iterations           | 1704       |
|    time_elapsed         | 5549       |
|    total_timesteps      | 3489792    |
| train/                  |            |
|    approx_kl            | 0.14495042 |
|    clip_fraction        | 0.392      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.426     |
|    explained_variance   | 0.846      |
|    learning_rate        | 0.00132    |
|    loss                 | -0.0172    |
|    n_updates            | 17030      |
|    policy_gradient_loss | 0.00652    |
|    std                  | 0.305      |
|    value_loss           | 0.014      |
----------------------------------------
Eval num_timesteps=3490000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1         |
| time/                   |            |
|    total_timesteps      | 3490000    |
| train/                  |            |
|    approx_kl            | 0.15011793 |
|    clip_fraction        | 0.351      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.474     |
|    explained_variance   | 0.817      |
|    learning_rate        | 0.00132    |
|    loss                 | 0.00227    |
|    n_updates            | 17040      |
|    policy_gradient_loss | -0.002     |
|    std                  | 0.312      |
|    value_loss           | 0.00622    |
----------------------------------------
box reached target
--------------------------------
| time/              |         |
|    fps             | 628     |
|    iterations      | 1705    |
|    time_elapsed    | 5553    |
|    total_timesteps | 3491840 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 628        |
|    iterations           | 1706       |
|    time_elapsed         | 5556       |
|    total_timesteps      | 3493888    |
| train/                  |            |
|    approx_kl            | 0.14966583 |
|    clip_fraction        | 0.404      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.457     |
|    explained_variance   | 0.69       |
|    learning_rate        | 0.00132    |
|    loss                 | 0.0498     |
|    n_updates            | 17050      |
|    policy_gradient_loss | 0.0152     |
|    std                  | 0.309      |
|    value_loss           | 0.0176     |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 628        |
|    iterations           | 1707       |
|    time_elapsed         | 5559       |
|    total_timesteps      | 3495936    |
| train/                  |            |
|    approx_kl            | 0.11194976 |
|    clip_fraction        | 0.363      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.455     |
|    explained_variance   | 0.809      |
|    learning_rate        | 0.00132    |
|    loss                 | 0.0132     |
|    n_updates            | 17060      |
|    policy_gradient_loss | -0.00497   |
|    std                  | 0.308      |
|    value_loss           | 0.00402    |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 628        |
|    iterations           | 1708       |
|    time_elapsed         | 5562       |
|    total_timesteps      | 3497984    |
| train/                  |            |
|    approx_kl            | 0.21135908 |
|    clip_fraction        | 0.435      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.451     |
|    explained_variance   | 0.846      |
|    learning_rate        | 0.00132    |
|    loss                 | -0.00101   |
|    n_updates            | 17070      |
|    policy_gradient_loss | 0.0159     |
|    std                  | 0.313      |
|    value_loss           | 0.0136     |
----------------------------------------
Eval num_timesteps=3500000, episode_reward=-0.89 +/- 0.22
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -0.891     |
| time/                   |            |
|    total_timesteps      | 3500000    |
| train/                  |            |
|    approx_kl            | 0.13969451 |
|    clip_fraction        | 0.311      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.445     |
|    explained_variance   | 0.866      |
|    learning_rate        | 0.00132    |
|    loss                 | -0.00148   |
|    n_updates            | 17080      |
|    policy_gradient_loss | 0.00218    |
|    std                  | 0.307      |
|    value_loss           | 0.011      |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 628     |
|    iterations      | 1709    |
|    time_elapsed    | 5566    |
|    total_timesteps | 3500032 |
--------------------------------
box reached target
box reached target
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 628       |
|    iterations           | 1710      |
|    time_elapsed         | 5569      |
|    total_timesteps      | 3502080   |
| train/                  |           |
|    approx_kl            | 0.1832609 |
|    clip_fraction        | 0.365     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.413    |
|    explained_variance   | 0.362     |
|    learning_rate        | 0.00132   |
|    loss                 | -0.00661  |
|    n_updates            | 17090     |
|    policy_gradient_loss | 0.00329   |
|    std                  | 0.302     |
|    value_loss           | 0.00431   |
---------------------------------------
box reached target
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 628       |
|    iterations           | 1711      |
|    time_elapsed         | 5572      |
|    total_timesteps      | 3504128   |
| train/                  |           |
|    approx_kl            | 0.2540384 |
|    clip_fraction        | 0.411     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.415    |
|    explained_variance   | 0.82      |
|    learning_rate        | 0.00132   |
|    loss                 | 0.0258    |
|    n_updates            | 17100     |
|    policy_gradient_loss | 0.00499   |
|    std                  | 0.306     |
|    value_loss           | 0.0169    |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 628        |
|    iterations           | 1712       |
|    time_elapsed         | 5575       |
|    total_timesteps      | 3506176    |
| train/                  |            |
|    approx_kl            | 0.10218005 |
|    clip_fraction        | 0.337      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.427     |
|    explained_variance   | 0.949      |
|    learning_rate        | 0.00132    |
|    loss                 | 0.0444     |
|    n_updates            | 17110      |
|    policy_gradient_loss | -0.0048    |
|    std                  | 0.305      |
|    value_loss           | 0.00661    |
----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 628       |
|    iterations           | 1713      |
|    time_elapsed         | 5578      |
|    total_timesteps      | 3508224   |
| train/                  |           |
|    approx_kl            | 0.5733617 |
|    clip_fraction        | 0.335     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.411    |
|    explained_variance   | 0.844     |
|    learning_rate        | 0.00132   |
|    loss                 | -0.00501  |
|    n_updates            | 17120     |
|    policy_gradient_loss | 0.00573   |
|    std                  | 0.304     |
|    value_loss           | 0.00331   |
---------------------------------------
box reached target
box reached target
Eval num_timesteps=3510000, episode_reward=1.73 +/- 2.82
Episode length: 242.80 +/- 70.06
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 243        |
|    mean_reward          | 1.73       |
| time/                   |            |
|    total_timesteps      | 3510000    |
| train/                  |            |
|    approx_kl            | 0.24039447 |
|    clip_fraction        | 0.353      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.384     |
|    explained_variance   | 0.89       |
|    learning_rate        | 0.00132    |
|    loss                 | -0.023     |
|    n_updates            | 17130      |
|    policy_gradient_loss | 0.00292    |
|    std                  | 0.301      |
|    value_loss           | 0.00456    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 628     |
|    iterations      | 1714    |
|    time_elapsed    | 5582    |
|    total_timesteps | 3510272 |
--------------------------------
box reached target
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 628       |
|    iterations           | 1715      |
|    time_elapsed         | 5585      |
|    total_timesteps      | 3512320   |
| train/                  |           |
|    approx_kl            | 0.4810602 |
|    clip_fraction        | 0.455     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.375    |
|    explained_variance   | 0.246     |
|    learning_rate        | 0.00132   |
|    loss                 | 0.0645    |
|    n_updates            | 17140     |
|    policy_gradient_loss | 0.00701   |
|    std                  | 0.295     |
|    value_loss           | 0.00489   |
---------------------------------------
box reached target
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 628        |
|    iterations           | 1716       |
|    time_elapsed         | 5588       |
|    total_timesteps      | 3514368    |
| train/                  |            |
|    approx_kl            | 0.17486447 |
|    clip_fraction        | 0.413      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.317     |
|    explained_variance   | 0.706      |
|    learning_rate        | 0.00132    |
|    loss                 | 0.127      |
|    n_updates            | 17150      |
|    policy_gradient_loss | 0.00707    |
|    std                  | 0.291      |
|    value_loss           | 0.0257     |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 628        |
|    iterations           | 1717       |
|    time_elapsed         | 5591       |
|    total_timesteps      | 3516416    |
| train/                  |            |
|    approx_kl            | 0.25576136 |
|    clip_fraction        | 0.39       |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.323     |
|    explained_variance   | 0.925      |
|    learning_rate        | 0.00131    |
|    loss                 | -0.0214    |
|    n_updates            | 17160      |
|    policy_gradient_loss | 0.000436   |
|    std                  | 0.296      |
|    value_loss           | 0.0123     |
----------------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 628        |
|    iterations           | 1718       |
|    time_elapsed         | 5594       |
|    total_timesteps      | 3518464    |
| train/                  |            |
|    approx_kl            | 0.24485144 |
|    clip_fraction        | 0.399      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.369     |
|    explained_variance   | 0.829      |
|    learning_rate        | 0.00131    |
|    loss                 | -0.0195    |
|    n_updates            | 17170      |
|    policy_gradient_loss | 0.00645    |
|    std                  | 0.301      |
|    value_loss           | 0.0104     |
----------------------------------------
box reached target
Eval num_timesteps=3520000, episode_reward=0.20 +/- 2.56
Episode length: 270.80 +/- 58.40
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 271        |
|    mean_reward          | 0.204      |
| time/                   |            |
|    total_timesteps      | 3520000    |
| train/                  |            |
|    approx_kl            | 0.30974996 |
|    clip_fraction        | 0.403      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.377     |
|    explained_variance   | 0.932      |
|    learning_rate        | 0.00131    |
|    loss                 | -0.00954   |
|    n_updates            | 17180      |
|    policy_gradient_loss | 0.00876    |
|    std                  | 0.3        |
|    value_loss           | 0.00691    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 628     |
|    iterations      | 1719    |
|    time_elapsed    | 5598    |
|    total_timesteps | 3520512 |
--------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 628        |
|    iterations           | 1720       |
|    time_elapsed         | 5601       |
|    total_timesteps      | 3522560    |
| train/                  |            |
|    approx_kl            | 0.37484276 |
|    clip_fraction        | 0.454      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.345     |
|    explained_variance   | 0.782      |
|    learning_rate        | 0.00131    |
|    loss                 | -0.0265    |
|    n_updates            | 17190      |
|    policy_gradient_loss | -0.00829   |
|    std                  | 0.29       |
|    value_loss           | 0.0143     |
----------------------------------------
box reached target
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 628        |
|    iterations           | 1721       |
|    time_elapsed         | 5604       |
|    total_timesteps      | 3524608    |
| train/                  |            |
|    approx_kl            | 0.27847755 |
|    clip_fraction        | 0.411      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.317     |
|    explained_variance   | 0.898      |
|    learning_rate        | 0.00131    |
|    loss                 | 0.00384    |
|    n_updates            | 17200      |
|    policy_gradient_loss | -0.0033    |
|    std                  | 0.289      |
|    value_loss           | 0.00378    |
----------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 628       |
|    iterations           | 1722      |
|    time_elapsed         | 5607      |
|    total_timesteps      | 3526656   |
| train/                  |           |
|    approx_kl            | 0.2331354 |
|    clip_fraction        | 0.409     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.291    |
|    explained_variance   | 0.911     |
|    learning_rate        | 0.00131   |
|    loss                 | -0.00113  |
|    n_updates            | 17210     |
|    policy_gradient_loss | 0.00862   |
|    std                  | 0.283     |
|    value_loss           | 0.0133    |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 628        |
|    iterations           | 1723       |
|    time_elapsed         | 5610       |
|    total_timesteps      | 3528704    |
| train/                  |            |
|    approx_kl            | 0.15472153 |
|    clip_fraction        | 0.422      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.313     |
|    explained_variance   | 0.756      |
|    learning_rate        | 0.00131    |
|    loss                 | 0.69       |
|    n_updates            | 17220      |
|    policy_gradient_loss | 0.015      |
|    std                  | 0.29       |
|    value_loss           | 0.0125     |
----------------------------------------
box reached target
Eval num_timesteps=3530000, episode_reward=-0.99 +/- 0.03
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -0.987     |
| time/                   |            |
|    total_timesteps      | 3530000    |
| train/                  |            |
|    approx_kl            | 0.15567273 |
|    clip_fraction        | 0.386      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.341     |
|    explained_variance   | 0.00507    |
|    learning_rate        | 0.00131    |
|    loss                 | -0.00519   |
|    n_updates            | 17230      |
|    policy_gradient_loss | 0.00915    |
|    std                  | 0.295      |
|    value_loss           | 0.0025     |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 628     |
|    iterations      | 1724    |
|    time_elapsed    | 5614    |
|    total_timesteps | 3530752 |
--------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 628        |
|    iterations           | 1725       |
|    time_elapsed         | 5617       |
|    total_timesteps      | 3532800    |
| train/                  |            |
|    approx_kl            | 0.17178586 |
|    clip_fraction        | 0.385      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.347     |
|    explained_variance   | 0.903      |
|    learning_rate        | 0.00131    |
|    loss                 | -0.0256    |
|    n_updates            | 17240      |
|    policy_gradient_loss | -0.000957  |
|    std                  | 0.294      |
|    value_loss           | 0.0112     |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 628        |
|    iterations           | 1726       |
|    time_elapsed         | 5620       |
|    total_timesteps      | 3534848    |
| train/                  |            |
|    approx_kl            | 0.12254001 |
|    clip_fraction        | 0.414      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.348     |
|    explained_variance   | 0.903      |
|    learning_rate        | 0.00131    |
|    loss                 | 0.0807     |
|    n_updates            | 17250      |
|    policy_gradient_loss | 0.0051     |
|    std                  | 0.296      |
|    value_loss           | 0.00999    |
----------------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 628        |
|    iterations           | 1727       |
|    time_elapsed         | 5623       |
|    total_timesteps      | 3536896    |
| train/                  |            |
|    approx_kl            | 0.17878765 |
|    clip_fraction        | 0.398      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.324     |
|    explained_variance   | 0.885      |
|    learning_rate        | 0.00131    |
|    loss                 | 0.0735     |
|    n_updates            | 17260      |
|    policy_gradient_loss | 0.012      |
|    std                  | 0.29       |
|    value_loss           | 0.00654    |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 628        |
|    iterations           | 1728       |
|    time_elapsed         | 5626       |
|    total_timesteps      | 3538944    |
| train/                  |            |
|    approx_kl            | 0.18248463 |
|    clip_fraction        | 0.386      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.309     |
|    explained_variance   | 0.893      |
|    learning_rate        | 0.00131    |
|    loss                 | 0.0882     |
|    n_updates            | 17270      |
|    policy_gradient_loss | 0.0121     |
|    std                  | 0.29       |
|    value_loss           | 0.00776    |
----------------------------------------
box reached target
Eval num_timesteps=3540000, episode_reward=0.21 +/- 2.44
Episode length: 273.00 +/- 54.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 273       |
|    mean_reward          | 0.211     |
| time/                   |           |
|    total_timesteps      | 3540000   |
| train/                  |           |
|    approx_kl            | 0.2544986 |
|    clip_fraction        | 0.38      |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.327    |
|    explained_variance   | 0.988     |
|    learning_rate        | 0.00131   |
|    loss                 | -0.0289   |
|    n_updates            | 17280     |
|    policy_gradient_loss | 0.00778   |
|    std                  | 0.288     |
|    value_loss           | 0.00193   |
---------------------------------------
box reached target
--------------------------------
| time/              |         |
|    fps             | 628     |
|    iterations      | 1729    |
|    time_elapsed    | 5630    |
|    total_timesteps | 3540992 |
--------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 628        |
|    iterations           | 1730       |
|    time_elapsed         | 5633       |
|    total_timesteps      | 3543040    |
| train/                  |            |
|    approx_kl            | 0.08884989 |
|    clip_fraction        | 0.418      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.383     |
|    explained_variance   | 0.698      |
|    learning_rate        | 0.00131    |
|    loss                 | 0.0179     |
|    n_updates            | 17290      |
|    policy_gradient_loss | 0.012      |
|    std                  | 0.306      |
|    value_loss           | 0.0232     |
----------------------------------------
box reached target
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 628        |
|    iterations           | 1731       |
|    time_elapsed         | 5636       |
|    total_timesteps      | 3545088    |
| train/                  |            |
|    approx_kl            | 0.08169934 |
|    clip_fraction        | 0.339      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.414     |
|    explained_variance   | 0.44       |
|    learning_rate        | 0.00131    |
|    loss                 | 0.0579     |
|    n_updates            | 17300      |
|    policy_gradient_loss | 0.0057     |
|    std                  | 0.305      |
|    value_loss           | 0.0462     |
----------------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 628        |
|    iterations           | 1732       |
|    time_elapsed         | 5639       |
|    total_timesteps      | 3547136    |
| train/                  |            |
|    approx_kl            | 0.17919572 |
|    clip_fraction        | 0.396      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.434     |
|    explained_variance   | 0.695      |
|    learning_rate        | 0.00131    |
|    loss                 | -0.0116    |
|    n_updates            | 17310      |
|    policy_gradient_loss | 0.0105     |
|    std                  | 0.313      |
|    value_loss           | 0.0378     |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 628        |
|    iterations           | 1733       |
|    time_elapsed         | 5642       |
|    total_timesteps      | 3549184    |
| train/                  |            |
|    approx_kl            | 0.08863267 |
|    clip_fraction        | 0.383      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.446     |
|    explained_variance   | 0.834      |
|    learning_rate        | 0.00131    |
|    loss                 | 0.022      |
|    n_updates            | 17320      |
|    policy_gradient_loss | 0.00399    |
|    std                  | 0.312      |
|    value_loss           | 0.0182     |
----------------------------------------
box reached target
Eval num_timesteps=3550000, episode_reward=-0.59 +/- 0.60
Episode length: 300.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 300         |
|    mean_reward          | -0.589      |
| time/                   |             |
|    total_timesteps      | 3550000     |
| train/                  |             |
|    approx_kl            | 0.100781724 |
|    clip_fraction        | 0.387       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.467      |
|    explained_variance   | 0.888       |
|    learning_rate        | 0.00131     |
|    loss                 | -0.00512    |
|    n_updates            | 17330       |
|    policy_gradient_loss | 0.00977     |
|    std                  | 0.317       |
|    value_loss           | 0.00524     |
-----------------------------------------
box reached target
--------------------------------
| time/              |         |
|    fps             | 628     |
|    iterations      | 1734    |
|    time_elapsed    | 5646    |
|    total_timesteps | 3551232 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 628        |
|    iterations           | 1735       |
|    time_elapsed         | 5649       |
|    total_timesteps      | 3553280    |
| train/                  |            |
|    approx_kl            | 0.18291032 |
|    clip_fraction        | 0.409      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.446     |
|    explained_variance   | 0.837      |
|    learning_rate        | 0.00131    |
|    loss                 | -0.00113   |
|    n_updates            | 17340      |
|    policy_gradient_loss | -0.00117   |
|    std                  | 0.308      |
|    value_loss           | 0.0162     |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 628        |
|    iterations           | 1736       |
|    time_elapsed         | 5652       |
|    total_timesteps      | 3555328    |
| train/                  |            |
|    approx_kl            | 0.18607941 |
|    clip_fraction        | 0.368      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.438     |
|    explained_variance   | 0.715      |
|    learning_rate        | 0.00131    |
|    loss                 | -0.0368    |
|    n_updates            | 17350      |
|    policy_gradient_loss | -0.00204   |
|    std                  | 0.303      |
|    value_loss           | 0.00673    |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 628        |
|    iterations           | 1737       |
|    time_elapsed         | 5655       |
|    total_timesteps      | 3557376    |
| train/                  |            |
|    approx_kl            | 0.11209964 |
|    clip_fraction        | 0.366      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.431     |
|    explained_variance   | 0.583      |
|    learning_rate        | 0.00131    |
|    loss                 | -0.00851   |
|    n_updates            | 17360      |
|    policy_gradient_loss | 0.00739    |
|    std                  | 0.312      |
|    value_loss           | 0.0162     |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 628        |
|    iterations           | 1738       |
|    time_elapsed         | 5658       |
|    total_timesteps      | 3559424    |
| train/                  |            |
|    approx_kl            | 0.26545107 |
|    clip_fraction        | 0.382      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.445     |
|    explained_variance   | 0.91       |
|    learning_rate        | 0.00131    |
|    loss                 | -0.0168    |
|    n_updates            | 17370      |
|    policy_gradient_loss | -0.0111    |
|    std                  | 0.309      |
|    value_loss           | 0.00512    |
----------------------------------------
Eval num_timesteps=3560000, episode_reward=-1.06 +/- 0.24
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1.06      |
| time/                   |            |
|    total_timesteps      | 3560000    |
| train/                  |            |
|    approx_kl            | 0.19947866 |
|    clip_fraction        | 0.413      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.43      |
|    explained_variance   | 0.791      |
|    learning_rate        | 0.00131    |
|    loss                 | -0.0143    |
|    n_updates            | 17380      |
|    policy_gradient_loss | -0.000662  |
|    std                  | 0.309      |
|    value_loss           | 0.0124     |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 628     |
|    iterations      | 1739    |
|    time_elapsed    | 5662    |
|    total_timesteps | 3561472 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 628        |
|    iterations           | 1740       |
|    time_elapsed         | 5665       |
|    total_timesteps      | 3563520    |
| train/                  |            |
|    approx_kl            | 0.12533149 |
|    clip_fraction        | 0.366      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.445     |
|    explained_variance   | 0.0734     |
|    learning_rate        | 0.00131    |
|    loss                 | 0.0665     |
|    n_updates            | 17390      |
|    policy_gradient_loss | -0.00151   |
|    std                  | 0.313      |
|    value_loss           | 0.00262    |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 628        |
|    iterations           | 1741       |
|    time_elapsed         | 5668       |
|    total_timesteps      | 3565568    |
| train/                  |            |
|    approx_kl            | 0.30199087 |
|    clip_fraction        | 0.364      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.427     |
|    explained_variance   | 0.699      |
|    learning_rate        | 0.00131    |
|    loss                 | 0.094      |
|    n_updates            | 17400      |
|    policy_gradient_loss | -0.000427  |
|    std                  | 0.31       |
|    value_loss           | 0.00314    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 628        |
|    iterations           | 1742       |
|    time_elapsed         | 5671       |
|    total_timesteps      | 3567616    |
| train/                  |            |
|    approx_kl            | 0.23665802 |
|    clip_fraction        | 0.413      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.359     |
|    explained_variance   | 0.824      |
|    learning_rate        | 0.0013     |
|    loss                 | -0.00982   |
|    n_updates            | 17410      |
|    policy_gradient_loss | -0.000974  |
|    std                  | 0.297      |
|    value_loss           | 0.0109     |
----------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 629       |
|    iterations           | 1743      |
|    time_elapsed         | 5675      |
|    total_timesteps      | 3569664   |
| train/                  |           |
|    approx_kl            | 0.3641989 |
|    clip_fraction        | 0.385     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.342    |
|    explained_variance   | 0.804     |
|    learning_rate        | 0.0013    |
|    loss                 | -0.043    |
|    n_updates            | 17420     |
|    policy_gradient_loss | 0.0212    |
|    std                  | 0.303     |
|    value_loss           | 0.00678   |
---------------------------------------
box reached target
Eval num_timesteps=3570000, episode_reward=0.10 +/- 2.47
Episode length: 272.80 +/- 54.40
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 273       |
|    mean_reward          | 0.0952    |
| time/                   |           |
|    total_timesteps      | 3570000   |
| train/                  |           |
|    approx_kl            | 0.2441387 |
|    clip_fraction        | 0.415     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.307    |
|    explained_variance   | 0.887     |
|    learning_rate        | 0.0013    |
|    loss                 | 0.0106    |
|    n_updates            | 17430     |
|    policy_gradient_loss | 0.00191   |
|    std                  | 0.293     |
|    value_loss           | 0.00635   |
---------------------------------------
box reached target
--------------------------------
| time/              |         |
|    fps             | 628     |
|    iterations      | 1744    |
|    time_elapsed    | 5678    |
|    total_timesteps | 3571712 |
--------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 628        |
|    iterations           | 1745       |
|    time_elapsed         | 5681       |
|    total_timesteps      | 3573760    |
| train/                  |            |
|    approx_kl            | 0.49590656 |
|    clip_fraction        | 0.418      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.289     |
|    explained_variance   | 0.86       |
|    learning_rate        | 0.0013     |
|    loss                 | 0.0253     |
|    n_updates            | 17440      |
|    policy_gradient_loss | 0.00343    |
|    std                  | 0.291      |
|    value_loss           | 0.016      |
----------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 628       |
|    iterations           | 1746      |
|    time_elapsed         | 5685      |
|    total_timesteps      | 3575808   |
| train/                  |           |
|    approx_kl            | 0.1777263 |
|    clip_fraction        | 0.397     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.219    |
|    explained_variance   | 0.756     |
|    learning_rate        | 0.0013    |
|    loss                 | -0.024    |
|    n_updates            | 17450     |
|    policy_gradient_loss | 0.0138    |
|    std                  | 0.285     |
|    value_loss           | 0.0129    |
---------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 629        |
|    iterations           | 1747       |
|    time_elapsed         | 5688       |
|    total_timesteps      | 3577856    |
| train/                  |            |
|    approx_kl            | 0.59899366 |
|    clip_fraction        | 0.424      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.211     |
|    explained_variance   | 0.684      |
|    learning_rate        | 0.0013     |
|    loss                 | -0.00175   |
|    n_updates            | 17460      |
|    policy_gradient_loss | 0.0149     |
|    std                  | 0.284      |
|    value_loss           | 0.0175     |
----------------------------------------
box reached target
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 629        |
|    iterations           | 1748       |
|    time_elapsed         | 5691       |
|    total_timesteps      | 3579904    |
| train/                  |            |
|    approx_kl            | 0.21045235 |
|    clip_fraction        | 0.405      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.208     |
|    explained_variance   | 0.847      |
|    learning_rate        | 0.0013     |
|    loss                 | -0.0166    |
|    n_updates            | 17470      |
|    policy_gradient_loss | 0.00157    |
|    std                  | 0.284      |
|    value_loss           | 0.0118     |
----------------------------------------
box reached target
Eval num_timesteps=3580000, episode_reward=0.48 +/- 2.37
Episode length: 276.80 +/- 46.40
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 277        |
|    mean_reward          | 0.476      |
| time/                   |            |
|    total_timesteps      | 3580000    |
| train/                  |            |
|    approx_kl            | 0.33971736 |
|    clip_fraction        | 0.433      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.171     |
|    explained_variance   | 0.84       |
|    learning_rate        | 0.0013     |
|    loss                 | -0.00432   |
|    n_updates            | 17480      |
|    policy_gradient_loss | 0.0075     |
|    std                  | 0.28       |
|    value_loss           | 0.0192     |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 628     |
|    iterations      | 1749    |
|    time_elapsed    | 5695    |
|    total_timesteps | 3581952 |
--------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 628        |
|    iterations           | 1750       |
|    time_elapsed         | 5698       |
|    total_timesteps      | 3584000    |
| train/                  |            |
|    approx_kl            | 0.31540042 |
|    clip_fraction        | 0.428      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.122     |
|    explained_variance   | 0.151      |
|    learning_rate        | 0.0013     |
|    loss                 | -0.0309    |
|    n_updates            | 17490      |
|    policy_gradient_loss | 0.000363   |
|    std                  | 0.277      |
|    value_loss           | 0.00703    |
----------------------------------------
box reached target
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 628        |
|    iterations           | 1751       |
|    time_elapsed         | 5701       |
|    total_timesteps      | 3586048    |
| train/                  |            |
|    approx_kl            | 0.50466704 |
|    clip_fraction        | 0.466      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.114     |
|    explained_variance   | 0.59       |
|    learning_rate        | 0.0013     |
|    loss                 | 0.0459     |
|    n_updates            | 17500      |
|    policy_gradient_loss | 0.0471     |
|    std                  | 0.277      |
|    value_loss           | 0.0293     |
----------------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 629        |
|    iterations           | 1752       |
|    time_elapsed         | 5704       |
|    total_timesteps      | 3588096    |
| train/                  |            |
|    approx_kl            | 0.30731082 |
|    clip_fraction        | 0.435      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.123     |
|    explained_variance   | 0.87       |
|    learning_rate        | 0.0013     |
|    loss                 | -0.0229    |
|    n_updates            | 17510      |
|    policy_gradient_loss | 0.0209     |
|    std                  | 0.28       |
|    value_loss           | 0.0125     |
----------------------------------------
box reached target
box reached target
box reached target
Eval num_timesteps=3590000, episode_reward=0.39 +/- 2.36
Episode length: 274.20 +/- 51.60
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 274        |
|    mean_reward          | 0.387      |
| time/                   |            |
|    total_timesteps      | 3590000    |
| train/                  |            |
|    approx_kl            | 0.26264417 |
|    clip_fraction        | 0.403      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.15      |
|    explained_variance   | 0.92       |
|    learning_rate        | 0.0013     |
|    loss                 | 0.0179     |
|    n_updates            | 17520      |
|    policy_gradient_loss | 0.00321    |
|    std                  | 0.281      |
|    value_loss           | 0.00965    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 628     |
|    iterations      | 1753    |
|    time_elapsed    | 5708    |
|    total_timesteps | 3590144 |
--------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 628        |
|    iterations           | 1754       |
|    time_elapsed         | 5711       |
|    total_timesteps      | 3592192    |
| train/                  |            |
|    approx_kl            | 0.19996238 |
|    clip_fraction        | 0.401      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.146     |
|    explained_variance   | 0.894      |
|    learning_rate        | 0.0013     |
|    loss                 | -0.0255    |
|    n_updates            | 17530      |
|    policy_gradient_loss | 0.0106     |
|    std                  | 0.282      |
|    value_loss           | 0.0134     |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 628        |
|    iterations           | 1755       |
|    time_elapsed         | 5714       |
|    total_timesteps      | 3594240    |
| train/                  |            |
|    approx_kl            | 0.46582812 |
|    clip_fraction        | 0.447      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.123     |
|    explained_variance   | 0.799      |
|    learning_rate        | 0.0013     |
|    loss                 | -0.0292    |
|    n_updates            | 17540      |
|    policy_gradient_loss | -0.00609   |
|    std                  | 0.272      |
|    value_loss           | 0.018      |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 629        |
|    iterations           | 1756       |
|    time_elapsed         | 5717       |
|    total_timesteps      | 3596288    |
| train/                  |            |
|    approx_kl            | 0.24307719 |
|    clip_fraction        | 0.395      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.114     |
|    explained_variance   | 0.834      |
|    learning_rate        | 0.0013     |
|    loss                 | -0.0519    |
|    n_updates            | 17550      |
|    policy_gradient_loss | -0.00363   |
|    std                  | 0.275      |
|    value_loss           | 0.0139     |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 629        |
|    iterations           | 1757       |
|    time_elapsed         | 5720       |
|    total_timesteps      | 3598336    |
| train/                  |            |
|    approx_kl            | 0.40412036 |
|    clip_fraction        | 0.429      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.121     |
|    explained_variance   | 0.748      |
|    learning_rate        | 0.0013     |
|    loss                 | 0.0317     |
|    n_updates            | 17560      |
|    policy_gradient_loss | 0.0117     |
|    std                  | 0.278      |
|    value_loss           | 0.00979    |
----------------------------------------
box reached target
box reached target
Eval num_timesteps=3600000, episode_reward=0.50 +/- 2.43
Episode length: 282.20 +/- 35.60
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 282        |
|    mean_reward          | 0.5        |
| time/                   |            |
|    total_timesteps      | 3600000    |
| train/                  |            |
|    approx_kl            | 0.17025308 |
|    clip_fraction        | 0.426      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.165     |
|    explained_variance   | 0.654      |
|    learning_rate        | 0.0013     |
|    loss                 | 0.0373     |
|    n_updates            | 17570      |
|    policy_gradient_loss | 0.00825    |
|    std                  | 0.286      |
|    value_loss           | 0.0263     |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 628     |
|    iterations      | 1758    |
|    time_elapsed    | 5724    |
|    total_timesteps | 3600384 |
--------------------------------
box reached target
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 628        |
|    iterations           | 1759       |
|    time_elapsed         | 5727       |
|    total_timesteps      | 3602432    |
| train/                  |            |
|    approx_kl            | 0.24606422 |
|    clip_fraction        | 0.403      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.233     |
|    explained_variance   | 0.766      |
|    learning_rate        | 0.0013     |
|    loss                 | -0.0293    |
|    n_updates            | 17580      |
|    policy_gradient_loss | 0.0123     |
|    std                  | 0.299      |
|    value_loss           | 0.017      |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 629        |
|    iterations           | 1760       |
|    time_elapsed         | 5730       |
|    total_timesteps      | 3604480    |
| train/                  |            |
|    approx_kl            | 0.25874722 |
|    clip_fraction        | 0.409      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.268     |
|    explained_variance   | 0.864      |
|    learning_rate        | 0.0013     |
|    loss                 | -0.0259    |
|    n_updates            | 17590      |
|    policy_gradient_loss | 0.00385    |
|    std                  | 0.299      |
|    value_loss           | 0.00983    |
----------------------------------------
box reached target
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 629         |
|    iterations           | 1761        |
|    time_elapsed         | 5733        |
|    total_timesteps      | 3606528     |
| train/                  |             |
|    approx_kl            | 0.097276516 |
|    clip_fraction        | 0.374       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.274      |
|    explained_variance   | 0.73        |
|    learning_rate        | 0.0013      |
|    loss                 | -0.0476     |
|    n_updates            | 17600       |
|    policy_gradient_loss | 0.00809     |
|    std                  | 0.302       |
|    value_loss           | 0.0146      |
-----------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 629       |
|    iterations           | 1762      |
|    time_elapsed         | 5736      |
|    total_timesteps      | 3608576   |
| train/                  |           |
|    approx_kl            | 0.3441587 |
|    clip_fraction        | 0.391     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.297    |
|    explained_variance   | 0.827     |
|    learning_rate        | 0.0013    |
|    loss                 | 0.00562   |
|    n_updates            | 17610     |
|    policy_gradient_loss | 0.00567   |
|    std                  | 0.303     |
|    value_loss           | 0.017     |
---------------------------------------
Eval num_timesteps=3610000, episode_reward=-0.65 +/- 0.69
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -0.655     |
| time/                   |            |
|    total_timesteps      | 3610000    |
| train/                  |            |
|    approx_kl            | 0.14248493 |
|    clip_fraction        | 0.373      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.316     |
|    explained_variance   | 0.91       |
|    learning_rate        | 0.0013     |
|    loss                 | 0.0717     |
|    n_updates            | 17620      |
|    policy_gradient_loss | 0.00939    |
|    std                  | 0.305      |
|    value_loss           | 0.00337    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 628     |
|    iterations      | 1763    |
|    time_elapsed    | 5740    |
|    total_timesteps | 3610624 |
--------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 629        |
|    iterations           | 1764       |
|    time_elapsed         | 5743       |
|    total_timesteps      | 3612672    |
| train/                  |            |
|    approx_kl            | 0.17247564 |
|    clip_fraction        | 0.353      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.32      |
|    explained_variance   | 0.623      |
|    learning_rate        | 0.0013     |
|    loss                 | 0.00491    |
|    n_updates            | 17630      |
|    policy_gradient_loss | 0.00614    |
|    std                  | 0.307      |
|    value_loss           | 0.00106    |
----------------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 629        |
|    iterations           | 1765       |
|    time_elapsed         | 5746       |
|    total_timesteps      | 3614720    |
| train/                  |            |
|    approx_kl            | 0.17183934 |
|    clip_fraction        | 0.403      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.314     |
|    explained_variance   | 0.907      |
|    learning_rate        | 0.0013     |
|    loss                 | 0.00967    |
|    n_updates            | 17640      |
|    policy_gradient_loss | 0.000692   |
|    std                  | 0.308      |
|    value_loss           | 0.00553    |
----------------------------------------
box reached target
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 629        |
|    iterations           | 1766       |
|    time_elapsed         | 5749       |
|    total_timesteps      | 3616768    |
| train/                  |            |
|    approx_kl            | 0.21858074 |
|    clip_fraction        | 0.377      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.267     |
|    explained_variance   | 0.945      |
|    learning_rate        | 0.0013     |
|    loss                 | 0.0423     |
|    n_updates            | 17650      |
|    policy_gradient_loss | -0.00674   |
|    std                  | 0.298      |
|    value_loss           | 0.0067     |
----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 629       |
|    iterations           | 1767      |
|    time_elapsed         | 5752      |
|    total_timesteps      | 3618816   |
| train/                  |           |
|    approx_kl            | 0.3719703 |
|    clip_fraction        | 0.441     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.232    |
|    explained_variance   | 0.743     |
|    learning_rate        | 0.00129   |
|    loss                 | -0.0241   |
|    n_updates            | 17660     |
|    policy_gradient_loss | 0.0155    |
|    std                  | 0.291     |
|    value_loss           | 0.0336    |
---------------------------------------
box reached target
box reached target
box reached target
box reached target
Eval num_timesteps=3620000, episode_reward=0.20 +/- 2.39
Episode length: 276.00 +/- 48.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 276       |
|    mean_reward          | 0.197     |
| time/                   |           |
|    total_timesteps      | 3620000   |
| train/                  |           |
|    approx_kl            | 0.2189014 |
|    clip_fraction        | 0.424     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.212    |
|    explained_variance   | 0.78      |
|    learning_rate        | 0.00129   |
|    loss                 | -0.000125 |
|    n_updates            | 17670     |
|    policy_gradient_loss | 0.0121    |
|    std                  | 0.29      |
|    value_loss           | 0.00659   |
---------------------------------------
--------------------------------
| time/              |         |
|    fps             | 629     |
|    iterations      | 1768    |
|    time_elapsed    | 5756    |
|    total_timesteps | 3620864 |
--------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 629        |
|    iterations           | 1769       |
|    time_elapsed         | 5759       |
|    total_timesteps      | 3622912    |
| train/                  |            |
|    approx_kl            | 0.13493942 |
|    clip_fraction        | 0.394      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.158     |
|    explained_variance   | 0.879      |
|    learning_rate        | 0.00129    |
|    loss                 | -0.0436    |
|    n_updates            | 17680      |
|    policy_gradient_loss | 0.00187    |
|    std                  | 0.282      |
|    value_loss           | 0.0285     |
----------------------------------------
box reached target
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 629        |
|    iterations           | 1770       |
|    time_elapsed         | 5762       |
|    total_timesteps      | 3624960    |
| train/                  |            |
|    approx_kl            | 0.27931243 |
|    clip_fraction        | 0.434      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.114     |
|    explained_variance   | 0.923      |
|    learning_rate        | 0.00129    |
|    loss                 | -0.0375    |
|    n_updates            | 17690      |
|    policy_gradient_loss | 0.0147     |
|    std                  | 0.271      |
|    value_loss           | 0.00436    |
----------------------------------------
box reached target
box reached target
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 629       |
|    iterations           | 1771      |
|    time_elapsed         | 5765      |
|    total_timesteps      | 3627008   |
| train/                  |           |
|    approx_kl            | 0.1847808 |
|    clip_fraction        | 0.458     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0936   |
|    explained_variance   | 0.808     |
|    learning_rate        | 0.00129   |
|    loss                 | 0.0397    |
|    n_updates            | 17700     |
|    policy_gradient_loss | 0.0182    |
|    std                  | 0.274     |
|    value_loss           | 0.0162    |
---------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 629        |
|    iterations           | 1772       |
|    time_elapsed         | 5768       |
|    total_timesteps      | 3629056    |
| train/                  |            |
|    approx_kl            | 0.45471337 |
|    clip_fraction        | 0.464      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.111     |
|    explained_variance   | 0.898      |
|    learning_rate        | 0.00129    |
|    loss                 | 0.00264    |
|    n_updates            | 17710      |
|    policy_gradient_loss | 0.0188     |
|    std                  | 0.274      |
|    value_loss           | 0.0111     |
----------------------------------------
box reached target
box reached target
Eval num_timesteps=3630000, episode_reward=0.30 +/- 2.45
Episode length: 270.80 +/- 58.40
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 271        |
|    mean_reward          | 0.304      |
| time/                   |            |
|    total_timesteps      | 3630000    |
| train/                  |            |
|    approx_kl            | 0.34205455 |
|    clip_fraction        | 0.4        |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.128     |
|    explained_variance   | 0.831      |
|    learning_rate        | 0.00129    |
|    loss                 | -0.0188    |
|    n_updates            | 17720      |
|    policy_gradient_loss | -0.00126   |
|    std                  | 0.278      |
|    value_loss           | 0.0134     |
----------------------------------------
box reached target
--------------------------------
| time/              |         |
|    fps             | 629     |
|    iterations      | 1773    |
|    time_elapsed    | 5772    |
|    total_timesteps | 3631104 |
--------------------------------
box reached target
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 629        |
|    iterations           | 1774       |
|    time_elapsed         | 5775       |
|    total_timesteps      | 3633152    |
| train/                  |            |
|    approx_kl            | 0.13072687 |
|    clip_fraction        | 0.408      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.109     |
|    explained_variance   | 0.925      |
|    learning_rate        | 0.00129    |
|    loss                 | -0.0615    |
|    n_updates            | 17730      |
|    policy_gradient_loss | 0.0174     |
|    std                  | 0.274      |
|    value_loss           | 0.0106     |
----------------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 629        |
|    iterations           | 1775       |
|    time_elapsed         | 5778       |
|    total_timesteps      | 3635200    |
| train/                  |            |
|    approx_kl            | 0.25172853 |
|    clip_fraction        | 0.435      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.0998    |
|    explained_variance   | 0.808      |
|    learning_rate        | 0.00129    |
|    loss                 | -0.0129    |
|    n_updates            | 17740      |
|    policy_gradient_loss | 0.0105     |
|    std                  | 0.281      |
|    value_loss           | 0.0241     |
----------------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 629        |
|    iterations           | 1776       |
|    time_elapsed         | 5781       |
|    total_timesteps      | 3637248    |
| train/                  |            |
|    approx_kl            | 0.17673317 |
|    clip_fraction        | 0.455      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.16      |
|    explained_variance   | 0.854      |
|    learning_rate        | 0.00129    |
|    loss                 | 0.00752    |
|    n_updates            | 17750      |
|    policy_gradient_loss | 0.0202     |
|    std                  | 0.29       |
|    value_loss           | 0.0113     |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 629        |
|    iterations           | 1777       |
|    time_elapsed         | 5784       |
|    total_timesteps      | 3639296    |
| train/                  |            |
|    approx_kl            | 0.20644543 |
|    clip_fraction        | 0.42       |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.186     |
|    explained_variance   | 0.831      |
|    learning_rate        | 0.00129    |
|    loss                 | -0.0168    |
|    n_updates            | 17760      |
|    policy_gradient_loss | 0.00356    |
|    std                  | 0.29       |
|    value_loss           | 0.0246     |
----------------------------------------
box reached target
box reached target
box reached target
box reached target
Eval num_timesteps=3640000, episode_reward=1.51 +/- 3.07
Episode length: 271.20 +/- 35.27
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 271        |
|    mean_reward          | 1.51       |
| time/                   |            |
|    total_timesteps      | 3640000    |
| train/                  |            |
|    approx_kl            | 0.21842736 |
|    clip_fraction        | 0.382      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.206     |
|    explained_variance   | 0.903      |
|    learning_rate        | 0.00129    |
|    loss                 | -0.00267   |
|    n_updates            | 17770      |
|    policy_gradient_loss | -0.00118   |
|    std                  | 0.293      |
|    value_loss           | 0.0104     |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 629     |
|    iterations      | 1778    |
|    time_elapsed    | 5788    |
|    total_timesteps | 3641344 |
--------------------------------
box reached target
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 629       |
|    iterations           | 1779      |
|    time_elapsed         | 5791      |
|    total_timesteps      | 3643392   |
| train/                  |           |
|    approx_kl            | 0.2029328 |
|    clip_fraction        | 0.436     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.166    |
|    explained_variance   | 0.841     |
|    learning_rate        | 0.00129   |
|    loss                 | 0.0113    |
|    n_updates            | 17780     |
|    policy_gradient_loss | 0.00804   |
|    std                  | 0.285     |
|    value_loss           | 0.0169    |
---------------------------------------
box reached target
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 629        |
|    iterations           | 1780       |
|    time_elapsed         | 5794       |
|    total_timesteps      | 3645440    |
| train/                  |            |
|    approx_kl            | 0.50746274 |
|    clip_fraction        | 0.438      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.172     |
|    explained_variance   | 0.814      |
|    learning_rate        | 0.00129    |
|    loss                 | -0.0297    |
|    n_updates            | 17790      |
|    policy_gradient_loss | 0.0225     |
|    std                  | 0.287      |
|    value_loss           | 0.0194     |
----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 629       |
|    iterations           | 1781      |
|    time_elapsed         | 5797      |
|    total_timesteps      | 3647488   |
| train/                  |           |
|    approx_kl            | 0.2501924 |
|    clip_fraction        | 0.416     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.172    |
|    explained_variance   | 0.852     |
|    learning_rate        | 0.00129   |
|    loss                 | 0.0524    |
|    n_updates            | 17800     |
|    policy_gradient_loss | 0.0122    |
|    std                  | 0.284     |
|    value_loss           | 0.0247    |
---------------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 629        |
|    iterations           | 1782       |
|    time_elapsed         | 5800       |
|    total_timesteps      | 3649536    |
| train/                  |            |
|    approx_kl            | 0.80314803 |
|    clip_fraction        | 0.421      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.152     |
|    explained_variance   | 0.164      |
|    learning_rate        | 0.00129    |
|    loss                 | -0.0436    |
|    n_updates            | 17810      |
|    policy_gradient_loss | -0.012     |
|    std                  | 0.278      |
|    value_loss           | 0.00507    |
----------------------------------------
Eval num_timesteps=3650000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 300       |
|    mean_reward          | -1        |
| time/                   |           |
|    total_timesteps      | 3650000   |
| train/                  |           |
|    approx_kl            | 0.3263569 |
|    clip_fraction        | 0.426     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.113    |
|    explained_variance   | 0.952     |
|    learning_rate        | 0.00129   |
|    loss                 | -0.0201   |
|    n_updates            | 17820     |
|    policy_gradient_loss | 0.00695   |
|    std                  | 0.276     |
|    value_loss           | 0.00856   |
---------------------------------------
--------------------------------
| time/              |         |
|    fps             | 629     |
|    iterations      | 1783    |
|    time_elapsed    | 5804    |
|    total_timesteps | 3651584 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 629        |
|    iterations           | 1784       |
|    time_elapsed         | 5807       |
|    total_timesteps      | 3653632    |
| train/                  |            |
|    approx_kl            | 0.30574036 |
|    clip_fraction        | 0.416      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.13      |
|    explained_variance   | 0.638      |
|    learning_rate        | 0.00129    |
|    loss                 | -0.0338    |
|    n_updates            | 17830      |
|    policy_gradient_loss | 0.00568    |
|    std                  | 0.281      |
|    value_loss           | 0.00697    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 629        |
|    iterations           | 1785       |
|    time_elapsed         | 5810       |
|    total_timesteps      | 3655680    |
| train/                  |            |
|    approx_kl            | 0.33986974 |
|    clip_fraction        | 0.404      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.148     |
|    explained_variance   | 0.85       |
|    learning_rate        | 0.00129    |
|    loss                 | 0.0393     |
|    n_updates            | 17840      |
|    policy_gradient_loss | 0.0359     |
|    std                  | 0.281      |
|    value_loss           | 0.00508    |
----------------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 629         |
|    iterations           | 1786        |
|    time_elapsed         | 5813        |
|    total_timesteps      | 3657728     |
| train/                  |             |
|    approx_kl            | 0.082595155 |
|    clip_fraction        | 0.378       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.122      |
|    explained_variance   | 0.309       |
|    learning_rate        | 0.00129     |
|    loss                 | 0.0207      |
|    n_updates            | 17850       |
|    policy_gradient_loss | 0.0153      |
|    std                  | 0.275       |
|    value_loss           | 0.00651     |
-----------------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 629        |
|    iterations           | 1787       |
|    time_elapsed         | 5817       |
|    total_timesteps      | 3659776    |
| train/                  |            |
|    approx_kl            | 0.36700195 |
|    clip_fraction        | 0.466      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.161     |
|    explained_variance   | 0.717      |
|    learning_rate        | 0.00129    |
|    loss                 | 0.0181     |
|    n_updates            | 17860      |
|    policy_gradient_loss | 0.011      |
|    std                  | 0.286      |
|    value_loss           | 0.0166     |
----------------------------------------
box reached target
box reached target
Eval num_timesteps=3660000, episode_reward=0.55 +/- 2.35
Episode length: 276.80 +/- 46.40
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 277        |
|    mean_reward          | 0.554      |
| time/                   |            |
|    total_timesteps      | 3660000    |
| train/                  |            |
|    approx_kl            | 0.21059921 |
|    clip_fraction        | 0.414      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.159     |
|    explained_variance   | 0.508      |
|    learning_rate        | 0.00129    |
|    loss                 | -0.00752   |
|    n_updates            | 17870      |
|    policy_gradient_loss | 0.0122     |
|    std                  | 0.281      |
|    value_loss           | 0.0322     |
----------------------------------------
box reached target
--------------------------------
| time/              |         |
|    fps             | 629     |
|    iterations      | 1788    |
|    time_elapsed    | 5820    |
|    total_timesteps | 3661824 |
--------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 629        |
|    iterations           | 1789       |
|    time_elapsed         | 5823       |
|    total_timesteps      | 3663872    |
| train/                  |            |
|    approx_kl            | 0.40043864 |
|    clip_fraction        | 0.462      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.113     |
|    explained_variance   | 0.72       |
|    learning_rate        | 0.00129    |
|    loss                 | 0.0165     |
|    n_updates            | 17880      |
|    policy_gradient_loss | 0.00575    |
|    std                  | 0.273      |
|    value_loss           | 0.0187     |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 629        |
|    iterations           | 1790       |
|    time_elapsed         | 5826       |
|    total_timesteps      | 3665920    |
| train/                  |            |
|    approx_kl            | 0.17124844 |
|    clip_fraction        | 0.459      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.0809    |
|    explained_variance   | 0.928      |
|    learning_rate        | 0.00129    |
|    loss                 | -0.00458   |
|    n_updates            | 17890      |
|    policy_gradient_loss | 0.0168     |
|    std                  | 0.268      |
|    value_loss           | 0.00916    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 629        |
|    iterations           | 1791       |
|    time_elapsed         | 5830       |
|    total_timesteps      | 3667968    |
| train/                  |            |
|    approx_kl            | 0.17053582 |
|    clip_fraction        | 0.367      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.0138    |
|    explained_variance   | 0.644      |
|    learning_rate        | 0.00129    |
|    loss                 | 0.00672    |
|    n_updates            | 17900      |
|    policy_gradient_loss | 0.00286    |
|    std                  | 0.258      |
|    value_loss           | 0.00315    |
----------------------------------------
box reached target
Eval num_timesteps=3670000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 300       |
|    mean_reward          | -1        |
| time/                   |           |
|    total_timesteps      | 3670000   |
| train/                  |           |
|    approx_kl            | 0.3256442 |
|    clip_fraction        | 0.433     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0266   |
|    explained_variance   | 0.82      |
|    learning_rate        | 0.00128   |
|    loss                 | 0.00606   |
|    n_updates            | 17910     |
|    policy_gradient_loss | 0.0117    |
|    std                  | 0.266     |
|    value_loss           | 0.00441   |
---------------------------------------
--------------------------------
| time/              |         |
|    fps             | 629     |
|    iterations      | 1792    |
|    time_elapsed    | 5833    |
|    total_timesteps | 3670016 |
--------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 629        |
|    iterations           | 1793       |
|    time_elapsed         | 5837       |
|    total_timesteps      | 3672064    |
| train/                  |            |
|    approx_kl            | 0.62930787 |
|    clip_fraction        | 0.395      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.0436    |
|    explained_variance   | 0.771      |
|    learning_rate        | 0.00128    |
|    loss                 | -0.0114    |
|    n_updates            | 17920      |
|    policy_gradient_loss | 0.00595    |
|    std                  | 0.262      |
|    value_loss           | 0.0115     |
----------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 629       |
|    iterations           | 1794      |
|    time_elapsed         | 5840      |
|    total_timesteps      | 3674112   |
| train/                  |           |
|    approx_kl            | 0.4905243 |
|    clip_fraction        | 0.425     |
|    clip_range           | 0.2       |
|    entropy_loss         | -6.81e-05 |
|    explained_variance   | 0.56      |
|    learning_rate        | 0.00128   |
|    loss                 | -0.0366   |
|    n_updates            | 17930     |
|    policy_gradient_loss | -0.00447  |
|    std                  | 0.255     |
|    value_loss           | 0.025     |
---------------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 629        |
|    iterations           | 1795       |
|    time_elapsed         | 5843       |
|    total_timesteps      | 3676160    |
| train/                  |            |
|    approx_kl            | 0.09762061 |
|    clip_fraction        | 0.401      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.0456    |
|    explained_variance   | 0.813      |
|    learning_rate        | 0.00128    |
|    loss                 | 0.0401     |
|    n_updates            | 17940      |
|    policy_gradient_loss | 0.00525    |
|    std                  | 0.263      |
|    value_loss           | 0.00921    |
----------------------------------------
box reached target
box reached target
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 629        |
|    iterations           | 1796       |
|    time_elapsed         | 5846       |
|    total_timesteps      | 3678208    |
| train/                  |            |
|    approx_kl            | 0.40034753 |
|    clip_fraction        | 0.491      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.0782    |
|    explained_variance   | 0.829      |
|    learning_rate        | 0.00128    |
|    loss                 | -0.0212    |
|    n_updates            | 17950      |
|    policy_gradient_loss | 0.00704    |
|    std                  | 0.262      |
|    value_loss           | 0.0157     |
----------------------------------------
box reached target
box reached target
Eval num_timesteps=3680000, episode_reward=0.26 +/- 2.52
Episode length: 277.40 +/- 45.20
--------------------------------------
| eval/                   |          |
|    mean_ep_length       | 277      |
|    mean_reward          | 0.258    |
| time/                   |          |
|    total_timesteps      | 3680000  |
| train/                  |          |
|    approx_kl            | 0.250188 |
|    clip_fraction        | 0.477    |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0783  |
|    explained_variance   | 0.846    |
|    learning_rate        | 0.00128  |
|    loss                 | 0.0273   |
|    n_updates            | 17960    |
|    policy_gradient_loss | 0.00936  |
|    std                  | 0.268    |
|    value_loss           | 0.0257   |
--------------------------------------
--------------------------------
| time/              |         |
|    fps             | 629     |
|    iterations      | 1797    |
|    time_elapsed    | 5850    |
|    total_timesteps | 3680256 |
--------------------------------
box reached target
box reached target
--------------------------------------
| time/                   |          |
|    fps                  | 629      |
|    iterations           | 1798     |
|    time_elapsed         | 5853     |
|    total_timesteps      | 3682304  |
| train/                  |          |
|    approx_kl            | 0.296086 |
|    clip_fraction        | 0.389    |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0679  |
|    explained_variance   | 0.905    |
|    learning_rate        | 0.00128  |
|    loss                 | 0.0389   |
|    n_updates            | 17970    |
|    policy_gradient_loss | 0.00419  |
|    std                  | 0.26     |
|    value_loss           | 0.0075   |
--------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 629        |
|    iterations           | 1799       |
|    time_elapsed         | 5856       |
|    total_timesteps      | 3684352    |
| train/                  |            |
|    approx_kl            | 0.27571782 |
|    clip_fraction        | 0.415      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.00768    |
|    explained_variance   | 0.856      |
|    learning_rate        | 0.00128    |
|    loss                 | -0.031     |
|    n_updates            | 17980      |
|    policy_gradient_loss | 0.00374    |
|    std                  | 0.248      |
|    value_loss           | 0.012      |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 629        |
|    iterations           | 1800       |
|    time_elapsed         | 5859       |
|    total_timesteps      | 3686400    |
| train/                  |            |
|    approx_kl            | 0.23325431 |
|    clip_fraction        | 0.443      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.038      |
|    explained_variance   | 0.918      |
|    learning_rate        | 0.00128    |
|    loss                 | -0.0289    |
|    n_updates            | 17990      |
|    policy_gradient_loss | 0.0107     |
|    std                  | 0.248      |
|    value_loss           | 0.00738    |
----------------------------------------
box reached target
box reached target
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 629        |
|    iterations           | 1801       |
|    time_elapsed         | 5862       |
|    total_timesteps      | 3688448    |
| train/                  |            |
|    approx_kl            | 0.21158044 |
|    clip_fraction        | 0.426      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.017      |
|    explained_variance   | 0.34       |
|    learning_rate        | 0.00128    |
|    loss                 | -0.00812   |
|    n_updates            | 18000      |
|    policy_gradient_loss | 0.00986    |
|    std                  | 0.252      |
|    value_loss           | 0.00841    |
----------------------------------------
box reached target
box reached target
Eval num_timesteps=3690000, episode_reward=1.78 +/- 2.92
Episode length: 256.00 +/- 60.36
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 256        |
|    mean_reward          | 1.78       |
| time/                   |            |
|    total_timesteps      | 3690000    |
| train/                  |            |
|    approx_kl            | 0.24432322 |
|    clip_fraction        | 0.422      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.0059    |
|    explained_variance   | 0.918      |
|    learning_rate        | 0.00128    |
|    loss                 | 0.0184     |
|    n_updates            | 18010      |
|    policy_gradient_loss | 0.0111     |
|    std                  | 0.253      |
|    value_loss           | 0.0127     |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 629     |
|    iterations      | 1802    |
|    time_elapsed    | 5866    |
|    total_timesteps | 3690496 |
--------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 629        |
|    iterations           | 1803       |
|    time_elapsed         | 5869       |
|    total_timesteps      | 3692544    |
| train/                  |            |
|    approx_kl            | 0.12535211 |
|    clip_fraction        | 0.383      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.0295    |
|    explained_variance   | 0.9        |
|    learning_rate        | 0.00128    |
|    loss                 | 0.016      |
|    n_updates            | 18020      |
|    policy_gradient_loss | 0.013      |
|    std                  | 0.252      |
|    value_loss           | 0.00321    |
----------------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 629        |
|    iterations           | 1804       |
|    time_elapsed         | 5872       |
|    total_timesteps      | 3694592    |
| train/                  |            |
|    approx_kl            | 0.40581805 |
|    clip_fraction        | 0.415      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.00586    |
|    explained_variance   | 0.908      |
|    learning_rate        | 0.00128    |
|    loss                 | 0.0296     |
|    n_updates            | 18030      |
|    policy_gradient_loss | 0.00736    |
|    std                  | 0.248      |
|    value_loss           | 0.0149     |
----------------------------------------
box reached target
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 629        |
|    iterations           | 1805       |
|    time_elapsed         | 5875       |
|    total_timesteps      | 3696640    |
| train/                  |            |
|    approx_kl            | 0.18521708 |
|    clip_fraction        | 0.415      |
|    clip_range           | 0.2        |
|    entropy_loss         | -5.06e-05  |
|    explained_variance   | 0.802      |
|    learning_rate        | 0.00128    |
|    loss                 | 0.0298     |
|    n_updates            | 18040      |
|    policy_gradient_loss | 0.00954    |
|    std                  | 0.25       |
|    value_loss           | 0.0164     |
----------------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 629        |
|    iterations           | 1806       |
|    time_elapsed         | 5878       |
|    total_timesteps      | 3698688    |
| train/                  |            |
|    approx_kl            | 0.15074411 |
|    clip_fraction        | 0.438      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.0055     |
|    explained_variance   | 0.867      |
|    learning_rate        | 0.00128    |
|    loss                 | 0.00643    |
|    n_updates            | 18050      |
|    policy_gradient_loss | 0.0174     |
|    std                  | 0.252      |
|    value_loss           | 0.0203     |
----------------------------------------
Eval num_timesteps=3700000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 300       |
|    mean_reward          | -1        |
| time/                   |           |
|    total_timesteps      | 3700000   |
| train/                  |           |
|    approx_kl            | 0.1954793 |
|    clip_fraction        | 0.403     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.01     |
|    explained_variance   | 0.913     |
|    learning_rate        | 0.00128   |
|    loss                 | -0.0465   |
|    n_updates            | 18060     |
|    policy_gradient_loss | 0.00674   |
|    std                  | 0.25      |
|    value_loss           | 0.0119    |
---------------------------------------
--------------------------------
| time/              |         |
|    fps             | 629     |
|    iterations      | 1807    |
|    time_elapsed    | 5882    |
|    total_timesteps | 3700736 |
--------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 629       |
|    iterations           | 1808      |
|    time_elapsed         | 5885      |
|    total_timesteps      | 3702784   |
| train/                  |           |
|    approx_kl            | 0.1815463 |
|    clip_fraction        | 0.404     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0606   |
|    explained_variance   | 0.817     |
|    learning_rate        | 0.00128   |
|    loss                 | 0.00893   |
|    n_updates            | 18070     |
|    policy_gradient_loss | 0.0029    |
|    std                  | 0.257     |
|    value_loss           | 0.00425   |
---------------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 629        |
|    iterations           | 1809       |
|    time_elapsed         | 5888       |
|    total_timesteps      | 3704832    |
| train/                  |            |
|    approx_kl            | 0.41667992 |
|    clip_fraction        | 0.444      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.0702    |
|    explained_variance   | 0.746      |
|    learning_rate        | 0.00128    |
|    loss                 | 0.0706     |
|    n_updates            | 18080      |
|    policy_gradient_loss | 0.0262     |
|    std                  | 0.26       |
|    value_loss           | 0.0044     |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 629        |
|    iterations           | 1810       |
|    time_elapsed         | 5891       |
|    total_timesteps      | 3706880    |
| train/                  |            |
|    approx_kl            | 0.35925668 |
|    clip_fraction        | 0.456      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.1       |
|    explained_variance   | 0.827      |
|    learning_rate        | 0.00128    |
|    loss                 | 0.0166     |
|    n_updates            | 18090      |
|    policy_gradient_loss | 0.0269     |
|    std                  | 0.264      |
|    value_loss           | 0.0131     |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 629        |
|    iterations           | 1811       |
|    time_elapsed         | 5894       |
|    total_timesteps      | 3708928    |
| train/                  |            |
|    approx_kl            | 0.58845115 |
|    clip_fraction        | 0.492      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.131     |
|    explained_variance   | 0.861      |
|    learning_rate        | 0.00128    |
|    loss                 | 0.0104     |
|    n_updates            | 18100      |
|    policy_gradient_loss | 0.0147     |
|    std                  | 0.267      |
|    value_loss           | 0.00961    |
----------------------------------------
box reached target
box reached target
box reached target
box reached target
Eval num_timesteps=3710000, episode_reward=0.30 +/- 2.58
Episode length: 290.20 +/- 19.60
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 290        |
|    mean_reward          | 0.297      |
| time/                   |            |
|    total_timesteps      | 3710000    |
| train/                  |            |
|    approx_kl            | 0.42177993 |
|    clip_fraction        | 0.425      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.122     |
|    explained_variance   | 0.825      |
|    learning_rate        | 0.00128    |
|    loss                 | -0.0302    |
|    n_updates            | 18110      |
|    policy_gradient_loss | -0.00134   |
|    std                  | 0.262      |
|    value_loss           | 0.00607    |
----------------------------------------
box reached target
--------------------------------
| time/              |         |
|    fps             | 629     |
|    iterations      | 1812    |
|    time_elapsed    | 5898    |
|    total_timesteps | 3710976 |
--------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 629        |
|    iterations           | 1813       |
|    time_elapsed         | 5901       |
|    total_timesteps      | 3713024    |
| train/                  |            |
|    approx_kl            | 0.15712404 |
|    clip_fraction        | 0.41       |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.091     |
|    explained_variance   | 0.941      |
|    learning_rate        | 0.00128    |
|    loss                 | -0.0444    |
|    n_updates            | 18120      |
|    policy_gradient_loss | 0.0036     |
|    std                  | 0.262      |
|    value_loss           | 0.00947    |
----------------------------------------
box reached target
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 629       |
|    iterations           | 1814      |
|    time_elapsed         | 5904      |
|    total_timesteps      | 3715072   |
| train/                  |           |
|    approx_kl            | 0.4392412 |
|    clip_fraction        | 0.436     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0846   |
|    explained_variance   | 0.895     |
|    learning_rate        | 0.00128   |
|    loss                 | 0.00194   |
|    n_updates            | 18130     |
|    policy_gradient_loss | 0.0205    |
|    std                  | 0.257     |
|    value_loss           | 0.00905   |
---------------------------------------
box reached target
box reached target
box reached target
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 629        |
|    iterations           | 1815       |
|    time_elapsed         | 5907       |
|    total_timesteps      | 3717120    |
| train/                  |            |
|    approx_kl            | 0.20487797 |
|    clip_fraction        | 0.417      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.0475    |
|    explained_variance   | 0.87       |
|    learning_rate        | 0.00128    |
|    loss                 | 0.0788     |
|    n_updates            | 18140      |
|    policy_gradient_loss | 0.0393     |
|    std                  | 0.254      |
|    value_loss           | 0.0207     |
----------------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 629        |
|    iterations           | 1816       |
|    time_elapsed         | 5910       |
|    total_timesteps      | 3719168    |
| train/                  |            |
|    approx_kl            | 0.12613003 |
|    clip_fraction        | 0.393      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.00156   |
|    explained_variance   | 0.962      |
|    learning_rate        | 0.00128    |
|    loss                 | 0.0254     |
|    n_updates            | 18150      |
|    policy_gradient_loss | 0.00674    |
|    std                  | 0.247      |
|    value_loss           | 0.0112     |
----------------------------------------
box reached target
Eval num_timesteps=3720000, episode_reward=-0.88 +/- 0.24
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -0.878     |
| time/                   |            |
|    total_timesteps      | 3720000    |
| train/                  |            |
|    approx_kl            | 0.29737365 |
|    clip_fraction        | 0.4        |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.0427     |
|    explained_variance   | 0.762      |
|    learning_rate        | 0.00127    |
|    loss                 | -0.0133    |
|    n_updates            | 18160      |
|    policy_gradient_loss | 0.0216     |
|    std                  | 0.24       |
|    value_loss           | 0.02       |
----------------------------------------
box reached target
--------------------------------
| time/              |         |
|    fps             | 629     |
|    iterations      | 1817    |
|    time_elapsed    | 5914    |
|    total_timesteps | 3721216 |
--------------------------------
box reached target
box reached target
--------------------------------------
| time/                   |          |
|    fps                  | 629      |
|    iterations           | 1818     |
|    time_elapsed         | 5917     |
|    total_timesteps      | 3723264  |
| train/                  |          |
|    approx_kl            | 1.068624 |
|    clip_fraction        | 0.505    |
|    clip_range           | 0.2      |
|    entropy_loss         | 0.0879   |
|    explained_variance   | 0.925    |
|    learning_rate        | 0.00127  |
|    loss                 | -0.0157  |
|    n_updates            | 18170    |
|    policy_gradient_loss | 0.0209   |
|    std                  | 0.235    |
|    value_loss           | 0.00937  |
--------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 629        |
|    iterations           | 1819       |
|    time_elapsed         | 5920       |
|    total_timesteps      | 3725312    |
| train/                  |            |
|    approx_kl            | 0.49409616 |
|    clip_fraction        | 0.488      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.0834     |
|    explained_variance   | 0.914      |
|    learning_rate        | 0.00127    |
|    loss                 | 0.0304     |
|    n_updates            | 18180      |
|    policy_gradient_loss | 0.0356     |
|    std                  | 0.239      |
|    value_loss           | 0.0156     |
----------------------------------------
box reached target
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 629        |
|    iterations           | 1820       |
|    time_elapsed         | 5923       |
|    total_timesteps      | 3727360    |
| train/                  |            |
|    approx_kl            | 0.20886242 |
|    clip_fraction        | 0.428      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.0789     |
|    explained_variance   | 0.745      |
|    learning_rate        | 0.00127    |
|    loss                 | -0.0296    |
|    n_updates            | 18190      |
|    policy_gradient_loss | 0.0171     |
|    std                  | 0.233      |
|    value_loss           | 0.0105     |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 629        |
|    iterations           | 1821       |
|    time_elapsed         | 5926       |
|    total_timesteps      | 3729408    |
| train/                  |            |
|    approx_kl            | 0.26178494 |
|    clip_fraction        | 0.468      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.0925     |
|    explained_variance   | 0.838      |
|    learning_rate        | 0.00127    |
|    loss                 | -0.00574   |
|    n_updates            | 18200      |
|    policy_gradient_loss | 0.0147     |
|    std                  | 0.238      |
|    value_loss           | 0.0181     |
----------------------------------------
box reached target
Eval num_timesteps=3730000, episode_reward=0.49 +/- 2.49
Episode length: 270.60 +/- 58.80
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 271         |
|    mean_reward          | 0.493       |
| time/                   |             |
|    total_timesteps      | 3730000     |
| train/                  |             |
|    approx_kl            | 0.082021624 |
|    clip_fraction        | 0.402       |
|    clip_range           | 0.2         |
|    entropy_loss         | 0.0514      |
|    explained_variance   | 0.888       |
|    learning_rate        | 0.00127     |
|    loss                 | 0.0174      |
|    n_updates            | 18210       |
|    policy_gradient_loss | 0.0203      |
|    std                  | 0.243       |
|    value_loss           | 0.0116      |
-----------------------------------------
box reached target
--------------------------------
| time/              |         |
|    fps             | 629     |
|    iterations      | 1822    |
|    time_elapsed    | 5930    |
|    total_timesteps | 3731456 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 629        |
|    iterations           | 1823       |
|    time_elapsed         | 5933       |
|    total_timesteps      | 3733504    |
| train/                  |            |
|    approx_kl            | 0.39301872 |
|    clip_fraction        | 0.436      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.0554     |
|    explained_variance   | 0.731      |
|    learning_rate        | 0.00127    |
|    loss                 | 0.00285    |
|    n_updates            | 18220      |
|    policy_gradient_loss | 0.00493    |
|    std                  | 0.237      |
|    value_loss           | 0.0108     |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 629        |
|    iterations           | 1824       |
|    time_elapsed         | 5936       |
|    total_timesteps      | 3735552    |
| train/                  |            |
|    approx_kl            | 0.26939565 |
|    clip_fraction        | 0.413      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.106      |
|    explained_variance   | 0.771      |
|    learning_rate        | 0.00127    |
|    loss                 | -0.017     |
|    n_updates            | 18230      |
|    policy_gradient_loss | 0.0127     |
|    std                  | 0.232      |
|    value_loss           | 0.00629    |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 629        |
|    iterations           | 1825       |
|    time_elapsed         | 5939       |
|    total_timesteps      | 3737600    |
| train/                  |            |
|    approx_kl            | 0.25519714 |
|    clip_fraction        | 0.428      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.0848     |
|    explained_variance   | 0.749      |
|    learning_rate        | 0.00127    |
|    loss                 | -0.0282    |
|    n_updates            | 18240      |
|    policy_gradient_loss | 0.0141     |
|    std                  | 0.235      |
|    value_loss           | 0.0157     |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 629        |
|    iterations           | 1826       |
|    time_elapsed         | 5942       |
|    total_timesteps      | 3739648    |
| train/                  |            |
|    approx_kl            | 0.22225904 |
|    clip_fraction        | 0.4        |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.0977     |
|    explained_variance   | 0.858      |
|    learning_rate        | 0.00127    |
|    loss                 | -0.0581    |
|    n_updates            | 18250      |
|    policy_gradient_loss | 0.00467    |
|    std                  | 0.232      |
|    value_loss           | 0.0108     |
----------------------------------------
box reached target
box reached target
Eval num_timesteps=3740000, episode_reward=0.22 +/- 2.44
Episode length: 273.00 +/- 54.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 273        |
|    mean_reward          | 0.218      |
| time/                   |            |
|    total_timesteps      | 3740000    |
| train/                  |            |
|    approx_kl            | 0.49828747 |
|    clip_fraction        | 0.489      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.0919     |
|    explained_variance   | 0.734      |
|    learning_rate        | 0.00127    |
|    loss                 | 0.0344     |
|    n_updates            | 18260      |
|    policy_gradient_loss | 0.0178     |
|    std                  | 0.234      |
|    value_loss           | 0.0138     |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 629     |
|    iterations      | 1827    |
|    time_elapsed    | 5946    |
|    total_timesteps | 3741696 |
--------------------------------
box reached target
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 629        |
|    iterations           | 1828       |
|    time_elapsed         | 5949       |
|    total_timesteps      | 3743744    |
| train/                  |            |
|    approx_kl            | 0.16154163 |
|    clip_fraction        | 0.41       |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.108      |
|    explained_variance   | 0.908      |
|    learning_rate        | 0.00127    |
|    loss                 | -0.0294    |
|    n_updates            | 18270      |
|    policy_gradient_loss | 0.00907    |
|    std                  | 0.229      |
|    value_loss           | 0.0118     |
----------------------------------------
box reached target
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 629        |
|    iterations           | 1829       |
|    time_elapsed         | 5952       |
|    total_timesteps      | 3745792    |
| train/                  |            |
|    approx_kl            | 0.45931333 |
|    clip_fraction        | 0.482      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.148      |
|    explained_variance   | 0.941      |
|    learning_rate        | 0.00127    |
|    loss                 | 0.0138     |
|    n_updates            | 18280      |
|    policy_gradient_loss | 0.00765    |
|    std                  | 0.222      |
|    value_loss           | 0.00783    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 629        |
|    iterations           | 1830       |
|    time_elapsed         | 5955       |
|    total_timesteps      | 3747840    |
| train/                  |            |
|    approx_kl            | 0.38222635 |
|    clip_fraction        | 0.445      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.17       |
|    explained_variance   | 0.894      |
|    learning_rate        | 0.00127    |
|    loss                 | 0.0391     |
|    n_updates            | 18290      |
|    policy_gradient_loss | 0.0225     |
|    std                  | 0.228      |
|    value_loss           | 0.0143     |
----------------------------------------
box reached target
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 629       |
|    iterations           | 1831      |
|    time_elapsed         | 5958      |
|    total_timesteps      | 3749888   |
| train/                  |           |
|    approx_kl            | 0.2496526 |
|    clip_fraction        | 0.39      |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.136     |
|    explained_variance   | 0.472     |
|    learning_rate        | 0.00127   |
|    loss                 | -0.0239   |
|    n_updates            | 18300     |
|    policy_gradient_loss | 0.00661   |
|    std                  | 0.227     |
|    value_loss           | 0.00507   |
---------------------------------------
Eval num_timesteps=3750000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1         |
| time/                   |            |
|    total_timesteps      | 3750000    |
| train/                  |            |
|    approx_kl            | 0.19864765 |
|    clip_fraction        | 0.45       |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.141      |
|    explained_variance   | 0.738      |
|    learning_rate        | 0.00127    |
|    loss                 | 0.0347     |
|    n_updates            | 18310      |
|    policy_gradient_loss | 0.017      |
|    std                  | 0.231      |
|    value_loss           | 0.00987    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 629     |
|    iterations      | 1832    |
|    time_elapsed    | 5962    |
|    total_timesteps | 3751936 |
--------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 629        |
|    iterations           | 1833       |
|    time_elapsed         | 5965       |
|    total_timesteps      | 3753984    |
| train/                  |            |
|    approx_kl            | 0.62475413 |
|    clip_fraction        | 0.468      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.139      |
|    explained_variance   | 0.86       |
|    learning_rate        | 0.00127    |
|    loss                 | -0.0196    |
|    n_updates            | 18320      |
|    policy_gradient_loss | 0.00261    |
|    std                  | 0.225      |
|    value_loss           | 0.00365    |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 629        |
|    iterations           | 1834       |
|    time_elapsed         | 5968       |
|    total_timesteps      | 3756032    |
| train/                  |            |
|    approx_kl            | 0.48593342 |
|    clip_fraction        | 0.454      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.17       |
|    explained_variance   | 0.827      |
|    learning_rate        | 0.00127    |
|    loss                 | 0.0643     |
|    n_updates            | 18330      |
|    policy_gradient_loss | 0.00602    |
|    std                  | 0.223      |
|    value_loss           | 0.00261    |
----------------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 629        |
|    iterations           | 1835       |
|    time_elapsed         | 5971       |
|    total_timesteps      | 3758080    |
| train/                  |            |
|    approx_kl            | 0.32730985 |
|    clip_fraction        | 0.486      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.206      |
|    explained_variance   | 0.801      |
|    learning_rate        | 0.00127    |
|    loss                 | -0.0152    |
|    n_updates            | 18340      |
|    policy_gradient_loss | 0.0281     |
|    std                  | 0.217      |
|    value_loss           | 0.00777    |
----------------------------------------
box reached target
Eval num_timesteps=3760000, episode_reward=0.30 +/- 2.60
Episode length: 273.60 +/- 52.80
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 274       |
|    mean_reward          | 0.299     |
| time/                   |           |
|    total_timesteps      | 3760000   |
| train/                  |           |
|    approx_kl            | 0.1415518 |
|    clip_fraction        | 0.439     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.258     |
|    explained_variance   | 0.849     |
|    learning_rate        | 0.00127   |
|    loss                 | -0.062    |
|    n_updates            | 18350     |
|    policy_gradient_loss | 0.0161    |
|    std                  | 0.215     |
|    value_loss           | 0.0231    |
---------------------------------------
--------------------------------
| time/              |         |
|    fps             | 629     |
|    iterations      | 1836    |
|    time_elapsed    | 5975    |
|    total_timesteps | 3760128 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 629        |
|    iterations           | 1837       |
|    time_elapsed         | 5978       |
|    total_timesteps      | 3762176    |
| train/                  |            |
|    approx_kl            | 0.18618897 |
|    clip_fraction        | 0.503      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.224      |
|    explained_variance   | 0.344      |
|    learning_rate        | 0.00127    |
|    loss                 | 0.0272     |
|    n_updates            | 18360      |
|    policy_gradient_loss | 0.0241     |
|    std                  | 0.221      |
|    value_loss           | 0.00452    |
----------------------------------------
box reached target
box reached target
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 629       |
|    iterations           | 1838      |
|    time_elapsed         | 5981      |
|    total_timesteps      | 3764224   |
| train/                  |           |
|    approx_kl            | 0.2524365 |
|    clip_fraction        | 0.428     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.213     |
|    explained_variance   | 0.687     |
|    learning_rate        | 0.00127   |
|    loss                 | 0.0106    |
|    n_updates            | 18370     |
|    policy_gradient_loss | 0.012     |
|    std                  | 0.216     |
|    value_loss           | 0.00503   |
---------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 629        |
|    iterations           | 1839       |
|    time_elapsed         | 5984       |
|    total_timesteps      | 3766272    |
| train/                  |            |
|    approx_kl            | 0.30055583 |
|    clip_fraction        | 0.441      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.237      |
|    explained_variance   | 0.774      |
|    learning_rate        | 0.00127    |
|    loss                 | -0.0377    |
|    n_updates            | 18380      |
|    policy_gradient_loss | 0.0214     |
|    std                  | 0.218      |
|    value_loss           | 0.0163     |
----------------------------------------
box reached target
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 629        |
|    iterations           | 1840       |
|    time_elapsed         | 5987       |
|    total_timesteps      | 3768320    |
| train/                  |            |
|    approx_kl            | 0.28221962 |
|    clip_fraction        | 0.455      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.245      |
|    explained_variance   | 0.816      |
|    learning_rate        | 0.00127    |
|    loss                 | 0.0476     |
|    n_updates            | 18390      |
|    policy_gradient_loss | 0.0252     |
|    std                  | 0.216      |
|    value_loss           | 0.0112     |
----------------------------------------
box reached target
box reached target
Eval num_timesteps=3770000, episode_reward=1.67 +/- 2.83
Episode length: 243.20 +/- 69.75
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 243       |
|    mean_reward          | 1.67      |
| time/                   |           |
|    total_timesteps      | 3770000   |
| train/                  |           |
|    approx_kl            | 0.3135309 |
|    clip_fraction        | 0.469     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.278     |
|    explained_variance   | 0.79      |
|    learning_rate        | 0.00127   |
|    loss                 | -0.027    |
|    n_updates            | 18400     |
|    policy_gradient_loss | 0.014     |
|    std                  | 0.209     |
|    value_loss           | 0.0578    |
---------------------------------------
--------------------------------
| time/              |         |
|    fps             | 629     |
|    iterations      | 1841    |
|    time_elapsed    | 5991    |
|    total_timesteps | 3770368 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 629        |
|    iterations           | 1842       |
|    time_elapsed         | 5994       |
|    total_timesteps      | 3772416    |
| train/                  |            |
|    approx_kl            | 0.81570673 |
|    clip_fraction        | 0.495      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.322      |
|    explained_variance   | 0.646      |
|    learning_rate        | 0.00126    |
|    loss                 | 0.0333     |
|    n_updates            | 18410      |
|    policy_gradient_loss | 0.0141     |
|    std                  | 0.205      |
|    value_loss           | 0.0241     |
----------------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 629        |
|    iterations           | 1843       |
|    time_elapsed         | 5997       |
|    total_timesteps      | 3774464    |
| train/                  |            |
|    approx_kl            | 0.35672283 |
|    clip_fraction        | 0.435      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.335      |
|    explained_variance   | 0.809      |
|    learning_rate        | 0.00126    |
|    loss                 | -0.0303    |
|    n_updates            | 18420      |
|    policy_gradient_loss | -0.00062   |
|    std                  | 0.206      |
|    value_loss           | 0.00619    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 629        |
|    iterations           | 1844       |
|    time_elapsed         | 6000       |
|    total_timesteps      | 3776512    |
| train/                  |            |
|    approx_kl            | 0.36661103 |
|    clip_fraction        | 0.49       |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.303      |
|    explained_variance   | 0.86       |
|    learning_rate        | 0.00126    |
|    loss                 | -0.0319    |
|    n_updates            | 18430      |
|    policy_gradient_loss | 0.024      |
|    std                  | 0.211      |
|    value_loss           | 0.0182     |
----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 629       |
|    iterations           | 1845      |
|    time_elapsed         | 6003      |
|    total_timesteps      | 3778560   |
| train/                  |           |
|    approx_kl            | 0.6511238 |
|    clip_fraction        | 0.475     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.305     |
|    explained_variance   | 0.505     |
|    learning_rate        | 0.00126   |
|    loss                 | -0.0163   |
|    n_updates            | 18440     |
|    policy_gradient_loss | 0.0029    |
|    std                  | 0.208     |
|    value_loss           | 0.0102    |
---------------------------------------
box reached target
box reached target
Eval num_timesteps=3780000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 300       |
|    mean_reward          | -1        |
| time/                   |           |
|    total_timesteps      | 3780000   |
| train/                  |           |
|    approx_kl            | 0.7171619 |
|    clip_fraction        | 0.498     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.343     |
|    explained_variance   | 0.834     |
|    learning_rate        | 0.00126   |
|    loss                 | 0.0353    |
|    n_updates            | 18450     |
|    policy_gradient_loss | 0.0167    |
|    std                  | 0.203     |
|    value_loss           | 0.00864   |
---------------------------------------
--------------------------------
| time/              |         |
|    fps             | 629     |
|    iterations      | 1846    |
|    time_elapsed    | 6007    |
|    total_timesteps | 3780608 |
--------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 629        |
|    iterations           | 1847       |
|    time_elapsed         | 6010       |
|    total_timesteps      | 3782656    |
| train/                  |            |
|    approx_kl            | 0.20821482 |
|    clip_fraction        | 0.466      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.363      |
|    explained_variance   | 0.891      |
|    learning_rate        | 0.00126    |
|    loss                 | 0.0998     |
|    n_updates            | 18460      |
|    policy_gradient_loss | 0.0159     |
|    std                  | 0.205      |
|    value_loss           | 0.0125     |
----------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 629       |
|    iterations           | 1848      |
|    time_elapsed         | 6013      |
|    total_timesteps      | 3784704   |
| train/                  |           |
|    approx_kl            | 0.5411663 |
|    clip_fraction        | 0.5       |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.371     |
|    explained_variance   | 0.855     |
|    learning_rate        | 0.00126   |
|    loss                 | -0.0267   |
|    n_updates            | 18470     |
|    policy_gradient_loss | 0.0217    |
|    std                  | 0.201     |
|    value_loss           | 0.00964   |
---------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 629       |
|    iterations           | 1849      |
|    time_elapsed         | 6017      |
|    total_timesteps      | 3786752   |
| train/                  |           |
|    approx_kl            | 0.6411426 |
|    clip_fraction        | 0.408     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.416     |
|    explained_variance   | 0.905     |
|    learning_rate        | 0.00126   |
|    loss                 | -0.00198  |
|    n_updates            | 18480     |
|    policy_gradient_loss | 0.00853   |
|    std                  | 0.198     |
|    value_loss           | 0.00672   |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 629        |
|    iterations           | 1850       |
|    time_elapsed         | 6020       |
|    total_timesteps      | 3788800    |
| train/                  |            |
|    approx_kl            | 0.22482444 |
|    clip_fraction        | 0.42       |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.434      |
|    explained_variance   | 0.401      |
|    learning_rate        | 0.00126    |
|    loss                 | 0.0234     |
|    n_updates            | 18490      |
|    policy_gradient_loss | 0.0166     |
|    std                  | 0.197      |
|    value_loss           | 0.00446    |
----------------------------------------
Eval num_timesteps=3790000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1         |
| time/                   |            |
|    total_timesteps      | 3790000    |
| train/                  |            |
|    approx_kl            | 0.25687003 |
|    clip_fraction        | 0.449      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.408      |
|    explained_variance   | 0.348      |
|    learning_rate        | 0.00126    |
|    loss                 | 0.027      |
|    n_updates            | 18500      |
|    policy_gradient_loss | 0.0111     |
|    std                  | 0.199      |
|    value_loss           | 0.00373    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 629     |
|    iterations      | 1851    |
|    time_elapsed    | 6024    |
|    total_timesteps | 3790848 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 629        |
|    iterations           | 1852       |
|    time_elapsed         | 6027       |
|    total_timesteps      | 3792896    |
| train/                  |            |
|    approx_kl            | 0.20899004 |
|    clip_fraction        | 0.456      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.383      |
|    explained_variance   | 0.358      |
|    learning_rate        | 0.00126    |
|    loss                 | 0.0099     |
|    n_updates            | 18510      |
|    policy_gradient_loss | 0.0161     |
|    std                  | 0.202      |
|    value_loss           | 0.00443    |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 629        |
|    iterations           | 1853       |
|    time_elapsed         | 6030       |
|    total_timesteps      | 3794944    |
| train/                  |            |
|    approx_kl            | 0.50705063 |
|    clip_fraction        | 0.452      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.392      |
|    explained_variance   | 0.71       |
|    learning_rate        | 0.00126    |
|    loss                 | -0.0233    |
|    n_updates            | 18520      |
|    policy_gradient_loss | 0.0145     |
|    std                  | 0.2        |
|    value_loss           | 0.00416    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 629        |
|    iterations           | 1854       |
|    time_elapsed         | 6033       |
|    total_timesteps      | 3796992    |
| train/                  |            |
|    approx_kl            | 0.28946906 |
|    clip_fraction        | 0.439      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.411      |
|    explained_variance   | 0.858      |
|    learning_rate        | 0.00126    |
|    loss                 | 0.0386     |
|    n_updates            | 18530      |
|    policy_gradient_loss | 0.0244     |
|    std                  | 0.198      |
|    value_loss           | 0.00786    |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 629        |
|    iterations           | 1855       |
|    time_elapsed         | 6036       |
|    total_timesteps      | 3799040    |
| train/                  |            |
|    approx_kl            | 0.23722921 |
|    clip_fraction        | 0.426      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.363      |
|    explained_variance   | 0.727      |
|    learning_rate        | 0.00126    |
|    loss                 | 0.0136     |
|    n_updates            | 18540      |
|    policy_gradient_loss | 0.0255     |
|    std                  | 0.205      |
|    value_loss           | 0.00713    |
----------------------------------------
box reached target
Eval num_timesteps=3800000, episode_reward=-0.78 +/- 0.44
Episode length: 300.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 300       |
|    mean_reward          | -0.78     |
| time/                   |           |
|    total_timesteps      | 3800000   |
| train/                  |           |
|    approx_kl            | 0.5181047 |
|    clip_fraction        | 0.498     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.329     |
|    explained_variance   | 0.893     |
|    learning_rate        | 0.00126   |
|    loss                 | -0.00801  |
|    n_updates            | 18550     |
|    policy_gradient_loss | 0.0161    |
|    std                  | 0.204     |
|    value_loss           | 0.00762   |
---------------------------------------
--------------------------------
| time/              |         |
|    fps             | 629     |
|    iterations      | 1856    |
|    time_elapsed    | 6040    |
|    total_timesteps | 3801088 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 629        |
|    iterations           | 1857       |
|    time_elapsed         | 6043       |
|    total_timesteps      | 3803136    |
| train/                  |            |
|    approx_kl            | 0.28433958 |
|    clip_fraction        | 0.493      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.325      |
|    explained_variance   | 0.765      |
|    learning_rate        | 0.00126    |
|    loss                 | 0.0168     |
|    n_updates            | 18560      |
|    policy_gradient_loss | 0.0106     |
|    std                  | 0.206      |
|    value_loss           | 0.01       |
----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 629       |
|    iterations           | 1858      |
|    time_elapsed         | 6046      |
|    total_timesteps      | 3805184   |
| train/                  |           |
|    approx_kl            | 0.3444996 |
|    clip_fraction        | 0.424     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.316     |
|    explained_variance   | 0.766     |
|    learning_rate        | 0.00126   |
|    loss                 | -0.052    |
|    n_updates            | 18570     |
|    policy_gradient_loss | 0.013     |
|    std                  | 0.209     |
|    value_loss           | 0.0132    |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 629        |
|    iterations           | 1859       |
|    time_elapsed         | 6049       |
|    total_timesteps      | 3807232    |
| train/                  |            |
|    approx_kl            | 0.43971223 |
|    clip_fraction        | 0.402      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.312      |
|    explained_variance   | 0.689      |
|    learning_rate        | 0.00126    |
|    loss                 | 0.0193     |
|    n_updates            | 18580      |
|    policy_gradient_loss | 0.0122     |
|    std                  | 0.206      |
|    value_loss           | 0.00525    |
----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 629       |
|    iterations           | 1860      |
|    time_elapsed         | 6052      |
|    total_timesteps      | 3809280   |
| train/                  |           |
|    approx_kl            | 0.4920319 |
|    clip_fraction        | 0.479     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.362     |
|    explained_variance   | 0.757     |
|    learning_rate        | 0.00126   |
|    loss                 | 0.0069    |
|    n_updates            | 18590     |
|    policy_gradient_loss | 0.00184   |
|    std                  | 0.202     |
|    value_loss           | 0.00231   |
---------------------------------------
Eval num_timesteps=3810000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1         |
| time/                   |            |
|    total_timesteps      | 3810000    |
| train/                  |            |
|    approx_kl            | 0.18702982 |
|    clip_fraction        | 0.401      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.404      |
|    explained_variance   | 0.58       |
|    learning_rate        | 0.00126    |
|    loss                 | -0.0179    |
|    n_updates            | 18600      |
|    policy_gradient_loss | 0.0141     |
|    std                  | 0.2        |
|    value_loss           | 0.00236    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 629     |
|    iterations      | 1861    |
|    time_elapsed    | 6056    |
|    total_timesteps | 3811328 |
--------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 629       |
|    iterations           | 1862      |
|    time_elapsed         | 6059      |
|    total_timesteps      | 3813376   |
| train/                  |           |
|    approx_kl            | 0.6560785 |
|    clip_fraction        | 0.493     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.388     |
|    explained_variance   | 0.544     |
|    learning_rate        | 0.00126   |
|    loss                 | -0.0186   |
|    n_updates            | 18610     |
|    policy_gradient_loss | 0.0195    |
|    std                  | 0.203     |
|    value_loss           | 0.00319   |
---------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 629        |
|    iterations           | 1863       |
|    time_elapsed         | 6062       |
|    total_timesteps      | 3815424    |
| train/                  |            |
|    approx_kl            | 0.82246006 |
|    clip_fraction        | 0.49       |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.403      |
|    explained_variance   | 0.633      |
|    learning_rate        | 0.00126    |
|    loss                 | 0.0668     |
|    n_updates            | 18620      |
|    policy_gradient_loss | 0.015      |
|    std                  | 0.2        |
|    value_loss           | 0.00489    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 629        |
|    iterations           | 1864       |
|    time_elapsed         | 6065       |
|    total_timesteps      | 3817472    |
| train/                  |            |
|    approx_kl            | 0.49914744 |
|    clip_fraction        | 0.482      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.403      |
|    explained_variance   | 0.895      |
|    learning_rate        | 0.00126    |
|    loss                 | -0.0355    |
|    n_updates            | 18630      |
|    policy_gradient_loss | 0.00699    |
|    std                  | 0.201      |
|    value_loss           | 0.00365    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 629        |
|    iterations           | 1865       |
|    time_elapsed         | 6068       |
|    total_timesteps      | 3819520    |
| train/                  |            |
|    approx_kl            | 0.59867203 |
|    clip_fraction        | 0.483      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.412      |
|    explained_variance   | 0.675      |
|    learning_rate        | 0.00126    |
|    loss                 | 0.0473     |
|    n_updates            | 18640      |
|    policy_gradient_loss | 0.00579    |
|    std                  | 0.2        |
|    value_loss           | 0.0055     |
----------------------------------------
Eval num_timesteps=3820000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1         |
| time/                   |            |
|    total_timesteps      | 3820000    |
| train/                  |            |
|    approx_kl            | 0.31171265 |
|    clip_fraction        | 0.448      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.398      |
|    explained_variance   | 0.334      |
|    learning_rate        | 0.00126    |
|    loss                 | -0.0115    |
|    n_updates            | 18650      |
|    policy_gradient_loss | 0.0166     |
|    std                  | 0.202      |
|    value_loss           | 0.00277    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 629     |
|    iterations      | 1866    |
|    time_elapsed    | 6072    |
|    total_timesteps | 3821568 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 629        |
|    iterations           | 1867       |
|    time_elapsed         | 6075       |
|    total_timesteps      | 3823616    |
| train/                  |            |
|    approx_kl            | 0.24121182 |
|    clip_fraction        | 0.444      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.387      |
|    explained_variance   | 0.478      |
|    learning_rate        | 0.00125    |
|    loss                 | -0.0476    |
|    n_updates            | 18660      |
|    policy_gradient_loss | 0.0183     |
|    std                  | 0.201      |
|    value_loss           | 0.00167    |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 629        |
|    iterations           | 1868       |
|    time_elapsed         | 6078       |
|    total_timesteps      | 3825664    |
| train/                  |            |
|    approx_kl            | 0.33301413 |
|    clip_fraction        | 0.462      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.362      |
|    explained_variance   | 0.575      |
|    learning_rate        | 0.00125    |
|    loss                 | -0.0284    |
|    n_updates            | 18670      |
|    policy_gradient_loss | 0.0227     |
|    std                  | 0.204      |
|    value_loss           | 0.0021     |
----------------------------------------
box reached target
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 629       |
|    iterations           | 1869      |
|    time_elapsed         | 6081      |
|    total_timesteps      | 3827712   |
| train/                  |           |
|    approx_kl            | 0.8034898 |
|    clip_fraction        | 0.504     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.333     |
|    explained_variance   | 0.606     |
|    learning_rate        | 0.00125   |
|    loss                 | 0.0103    |
|    n_updates            | 18680     |
|    policy_gradient_loss | 0.0463    |
|    std                  | 0.208     |
|    value_loss           | 0.00708   |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 629        |
|    iterations           | 1870       |
|    time_elapsed         | 6084       |
|    total_timesteps      | 3829760    |
| train/                  |            |
|    approx_kl            | 0.20105672 |
|    clip_fraction        | 0.413      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.283      |
|    explained_variance   | 0.711      |
|    learning_rate        | 0.00125    |
|    loss                 | -0.0452    |
|    n_updates            | 18690      |
|    policy_gradient_loss | 0.0149     |
|    std                  | 0.215      |
|    value_loss           | 0.0131     |
----------------------------------------
box reached target
Eval num_timesteps=3830000, episode_reward=0.22 +/- 2.43
Episode length: 274.60 +/- 50.80
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 275        |
|    mean_reward          | 0.217      |
| time/                   |            |
|    total_timesteps      | 3830000    |
| train/                  |            |
|    approx_kl            | 0.22937971 |
|    clip_fraction        | 0.395      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.271      |
|    explained_variance   | 0.0709     |
|    learning_rate        | 0.00125    |
|    loss                 | 0.00568    |
|    n_updates            | 18700      |
|    policy_gradient_loss | 0.0147     |
|    std                  | 0.21       |
|    value_loss           | 0.00243    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 629     |
|    iterations      | 1871    |
|    time_elapsed    | 6088    |
|    total_timesteps | 3831808 |
--------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 629        |
|    iterations           | 1872       |
|    time_elapsed         | 6091       |
|    total_timesteps      | 3833856    |
| train/                  |            |
|    approx_kl            | 0.26796937 |
|    clip_fraction        | 0.42       |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.286      |
|    explained_variance   | 0.579      |
|    learning_rate        | 0.00125    |
|    loss                 | -0.0207    |
|    n_updates            | 18710      |
|    policy_gradient_loss | 0.00619    |
|    std                  | 0.213      |
|    value_loss           | 0.00203    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 629        |
|    iterations           | 1873       |
|    time_elapsed         | 6094       |
|    total_timesteps      | 3835904    |
| train/                  |            |
|    approx_kl            | 0.26002866 |
|    clip_fraction        | 0.418      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.269      |
|    explained_variance   | 0.857      |
|    learning_rate        | 0.00125    |
|    loss                 | 0.00395    |
|    n_updates            | 18720      |
|    policy_gradient_loss | 0.0161     |
|    std                  | 0.215      |
|    value_loss           | 0.00728    |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 629        |
|    iterations           | 1874       |
|    time_elapsed         | 6097       |
|    total_timesteps      | 3837952    |
| train/                  |            |
|    approx_kl            | 0.23360512 |
|    clip_fraction        | 0.464      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.223      |
|    explained_variance   | 0.682      |
|    learning_rate        | 0.00125    |
|    loss                 | -0.0337    |
|    n_updates            | 18730      |
|    policy_gradient_loss | 0.0429     |
|    std                  | 0.222      |
|    value_loss           | 0.0017     |
----------------------------------------
box reached target
box reached target
Eval num_timesteps=3840000, episode_reward=1.49 +/- 3.05
Episode length: 237.60 +/- 76.59
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 238       |
|    mean_reward          | 1.49      |
| time/                   |           |
|    total_timesteps      | 3840000   |
| train/                  |           |
|    approx_kl            | 0.1451154 |
|    clip_fraction        | 0.437     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.172     |
|    explained_variance   | 0.869     |
|    learning_rate        | 0.00125   |
|    loss                 | -0.017    |
|    n_updates            | 18740     |
|    policy_gradient_loss | 0.0209    |
|    std                  | 0.227     |
|    value_loss           | 0.0167    |
---------------------------------------
--------------------------------
| time/              |         |
|    fps             | 629     |
|    iterations      | 1875    |
|    time_elapsed    | 6101    |
|    total_timesteps | 3840000 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 629        |
|    iterations           | 1876       |
|    time_elapsed         | 6104       |
|    total_timesteps      | 3842048    |
| train/                  |            |
|    approx_kl            | 0.32850358 |
|    clip_fraction        | 0.45       |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.122      |
|    explained_variance   | 0.634      |
|    learning_rate        | 0.00125    |
|    loss                 | 0.104      |
|    n_updates            | 18750      |
|    policy_gradient_loss | 0.00761    |
|    std                  | 0.229      |
|    value_loss           | 0.00534    |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 629        |
|    iterations           | 1877       |
|    time_elapsed         | 6107       |
|    total_timesteps      | 3844096    |
| train/                  |            |
|    approx_kl            | 0.15342528 |
|    clip_fraction        | 0.405      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.0849     |
|    explained_variance   | 0.671      |
|    learning_rate        | 0.00125    |
|    loss                 | -0.0163    |
|    n_updates            | 18760      |
|    policy_gradient_loss | 0.0152     |
|    std                  | 0.237      |
|    value_loss           | 0.00199    |
----------------------------------------
--------------------------------------
| time/                   |          |
|    fps                  | 629      |
|    iterations           | 1878     |
|    time_elapsed         | 6110     |
|    total_timesteps      | 3846144  |
| train/                  |          |
|    approx_kl            | 1.32802  |
|    clip_fraction        | 0.514    |
|    clip_range           | 0.2      |
|    entropy_loss         | 0.131    |
|    explained_variance   | 0.676    |
|    learning_rate        | 0.00125  |
|    loss                 | 0.0335   |
|    n_updates            | 18770    |
|    policy_gradient_loss | 0.011    |
|    std                  | 0.224    |
|    value_loss           | 0.00797  |
--------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 629        |
|    iterations           | 1879       |
|    time_elapsed         | 6113       |
|    total_timesteps      | 3848192    |
| train/                  |            |
|    approx_kl            | 0.21746102 |
|    clip_fraction        | 0.438      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.167      |
|    explained_variance   | 0.701      |
|    learning_rate        | 0.00125    |
|    loss                 | 0.0107     |
|    n_updates            | 18780      |
|    policy_gradient_loss | 0.00843    |
|    std                  | 0.223      |
|    value_loss           | 0.00702    |
----------------------------------------
Eval num_timesteps=3850000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1         |
| time/                   |            |
|    total_timesteps      | 3850000    |
| train/                  |            |
|    approx_kl            | 0.32214737 |
|    clip_fraction        | 0.438      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.144      |
|    explained_variance   | 0.315      |
|    learning_rate        | 0.00125    |
|    loss                 | 0.0496     |
|    n_updates            | 18790      |
|    policy_gradient_loss | 0.0292     |
|    std                  | 0.23       |
|    value_loss           | 0.0165     |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 629     |
|    iterations      | 1880    |
|    time_elapsed    | 6117    |
|    total_timesteps | 3850240 |
--------------------------------
box reached target
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 629       |
|    iterations           | 1881      |
|    time_elapsed         | 6120      |
|    total_timesteps      | 3852288   |
| train/                  |           |
|    approx_kl            | 0.2682724 |
|    clip_fraction        | 0.371     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.137     |
|    explained_variance   | 0.835     |
|    learning_rate        | 0.00125   |
|    loss                 | 0.00497   |
|    n_updates            | 18800     |
|    policy_gradient_loss | -0.00425  |
|    std                  | 0.224     |
|    value_loss           | 0.00744   |
---------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 629       |
|    iterations           | 1882      |
|    time_elapsed         | 6123      |
|    total_timesteps      | 3854336   |
| train/                  |           |
|    approx_kl            | 0.2938469 |
|    clip_fraction        | 0.406     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.147     |
|    explained_variance   | 0.804     |
|    learning_rate        | 0.00125   |
|    loss                 | 0.00823   |
|    n_updates            | 18810     |
|    policy_gradient_loss | 0.039     |
|    std                  | 0.227     |
|    value_loss           | 0.0113    |
---------------------------------------
box reached target
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 629        |
|    iterations           | 1883       |
|    time_elapsed         | 6126       |
|    total_timesteps      | 3856384    |
| train/                  |            |
|    approx_kl            | 0.21622992 |
|    clip_fraction        | 0.393      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.127      |
|    explained_variance   | 0.729      |
|    learning_rate        | 0.00125    |
|    loss                 | -0.0429    |
|    n_updates            | 18820      |
|    policy_gradient_loss | 0.0103     |
|    std                  | 0.232      |
|    value_loss           | 0.00259    |
----------------------------------------
box reached target
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 629       |
|    iterations           | 1884      |
|    time_elapsed         | 6129      |
|    total_timesteps      | 3858432   |
| train/                  |           |
|    approx_kl            | 0.2552232 |
|    clip_fraction        | 0.456     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.116     |
|    explained_variance   | 0.551     |
|    learning_rate        | 0.00125   |
|    loss                 | -0.00979  |
|    n_updates            | 18830     |
|    policy_gradient_loss | 0.0149    |
|    std                  | 0.227     |
|    value_loss           | 0.0464    |
---------------------------------------
box reached target
box reached target
Eval num_timesteps=3860000, episode_reward=0.32 +/- 2.64
Episode length: 283.60 +/- 32.80
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 284        |
|    mean_reward          | 0.319      |
| time/                   |            |
|    total_timesteps      | 3860000    |
| train/                  |            |
|    approx_kl            | 0.82338846 |
|    clip_fraction        | 0.442      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.164      |
|    explained_variance   | 0.869      |
|    learning_rate        | 0.00125    |
|    loss                 | 0.0164     |
|    n_updates            | 18840      |
|    policy_gradient_loss | 0.0109     |
|    std                  | 0.223      |
|    value_loss           | 0.0092     |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 629     |
|    iterations      | 1885    |
|    time_elapsed    | 6133    |
|    total_timesteps | 3860480 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 629        |
|    iterations           | 1886       |
|    time_elapsed         | 6136       |
|    total_timesteps      | 3862528    |
| train/                  |            |
|    approx_kl            | 0.37575468 |
|    clip_fraction        | 0.459      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.156      |
|    explained_variance   | 0.714      |
|    learning_rate        | 0.00125    |
|    loss                 | -0.0195    |
|    n_updates            | 18850      |
|    policy_gradient_loss | 0.0168     |
|    std                  | 0.226      |
|    value_loss           | 0.0262     |
----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 629       |
|    iterations           | 1887      |
|    time_elapsed         | 6139      |
|    total_timesteps      | 3864576   |
| train/                  |           |
|    approx_kl            | 0.4425612 |
|    clip_fraction        | 0.405     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.161     |
|    explained_variance   | 0.631     |
|    learning_rate        | 0.00125   |
|    loss                 | -0.0324   |
|    n_updates            | 18860     |
|    policy_gradient_loss | 0.000929  |
|    std                  | 0.225     |
|    value_loss           | 0.00313   |
---------------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 629        |
|    iterations           | 1888       |
|    time_elapsed         | 6142       |
|    total_timesteps      | 3866624    |
| train/                  |            |
|    approx_kl            | 0.20448342 |
|    clip_fraction        | 0.379      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.115      |
|    explained_variance   | 0.605      |
|    learning_rate        | 0.00125    |
|    loss                 | -0.0569    |
|    n_updates            | 18870      |
|    policy_gradient_loss | -0.00217   |
|    std                  | 0.233      |
|    value_loss           | 0.00133    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 629        |
|    iterations           | 1889       |
|    time_elapsed         | 6145       |
|    total_timesteps      | 3868672    |
| train/                  |            |
|    approx_kl            | 0.32932627 |
|    clip_fraction        | 0.434      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.129      |
|    explained_variance   | 0.821      |
|    learning_rate        | 0.00125    |
|    loss                 | -0.0238    |
|    n_updates            | 18880      |
|    policy_gradient_loss | 0.00798    |
|    std                  | 0.223      |
|    value_loss           | 0.00658    |
----------------------------------------
box reached target
box reached target
Eval num_timesteps=3870000, episode_reward=1.39 +/- 3.12
Episode length: 258.60 +/- 51.64
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 259        |
|    mean_reward          | 1.39       |
| time/                   |            |
|    total_timesteps      | 3870000    |
| train/                  |            |
|    approx_kl            | 0.21485256 |
|    clip_fraction        | 0.391      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.168      |
|    explained_variance   | 0.0277     |
|    learning_rate        | 0.00125    |
|    loss                 | 0.0175     |
|    n_updates            | 18890      |
|    policy_gradient_loss | 0.0199     |
|    std                  | 0.223      |
|    value_loss           | 0.00282    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 629     |
|    iterations      | 1890    |
|    time_elapsed    | 6149    |
|    total_timesteps | 3870720 |
--------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 629        |
|    iterations           | 1891       |
|    time_elapsed         | 6152       |
|    total_timesteps      | 3872768    |
| train/                  |            |
|    approx_kl            | 0.30962953 |
|    clip_fraction        | 0.447      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.182      |
|    explained_variance   | 0.831      |
|    learning_rate        | 0.00125    |
|    loss                 | -0.059     |
|    n_updates            | 18900      |
|    policy_gradient_loss | 0.0101     |
|    std                  | 0.223      |
|    value_loss           | 0.00645    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 629        |
|    iterations           | 1892       |
|    time_elapsed         | 6155       |
|    total_timesteps      | 3874816    |
| train/                  |            |
|    approx_kl            | 0.37459582 |
|    clip_fraction        | 0.447      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.153      |
|    explained_variance   | 0.836      |
|    learning_rate        | 0.00124    |
|    loss                 | -0.0182    |
|    n_updates            | 18910      |
|    policy_gradient_loss | 0.0104     |
|    std                  | 0.227      |
|    value_loss           | 0.0136     |
----------------------------------------
box reached target
box reached target
box reached target
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 629       |
|    iterations           | 1893      |
|    time_elapsed         | 6158      |
|    total_timesteps      | 3876864   |
| train/                  |           |
|    approx_kl            | 0.4307882 |
|    clip_fraction        | 0.439     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.138     |
|    explained_variance   | 0.785     |
|    learning_rate        | 0.00124   |
|    loss                 | -0.0226   |
|    n_updates            | 18920     |
|    policy_gradient_loss | 0.012     |
|    std                  | 0.227     |
|    value_loss           | 0.00195   |
---------------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 629        |
|    iterations           | 1894       |
|    time_elapsed         | 6161       |
|    total_timesteps      | 3878912    |
| train/                  |            |
|    approx_kl            | 0.15654376 |
|    clip_fraction        | 0.427      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.116      |
|    explained_variance   | 0.767      |
|    learning_rate        | 0.00124    |
|    loss                 | -0.00431   |
|    n_updates            | 18930      |
|    policy_gradient_loss | 0.0118     |
|    std                  | 0.235      |
|    value_loss           | 0.0418     |
----------------------------------------
box reached target
Eval num_timesteps=3880000, episode_reward=0.36 +/- 2.34
Episode length: 274.40 +/- 51.20
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 274       |
|    mean_reward          | 0.359     |
| time/                   |           |
|    total_timesteps      | 3880000   |
| train/                  |           |
|    approx_kl            | 0.1492294 |
|    clip_fraction        | 0.42      |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.0547    |
|    explained_variance   | 0.754     |
|    learning_rate        | 0.00124   |
|    loss                 | -0.00481  |
|    n_updates            | 18940     |
|    policy_gradient_loss | 0.0277    |
|    std                  | 0.239     |
|    value_loss           | 0.035     |
---------------------------------------
box reached target
--------------------------------
| time/              |         |
|    fps             | 629     |
|    iterations      | 1895    |
|    time_elapsed    | 6165    |
|    total_timesteps | 3880960 |
--------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 629       |
|    iterations           | 1896      |
|    time_elapsed         | 6168      |
|    total_timesteps      | 3883008   |
| train/                  |           |
|    approx_kl            | 1.2649606 |
|    clip_fraction        | 0.441     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.0555    |
|    explained_variance   | 0.845     |
|    learning_rate        | 0.00124   |
|    loss                 | 0.0706    |
|    n_updates            | 18950     |
|    policy_gradient_loss | 0.00228   |
|    std                  | 0.237     |
|    value_loss           | 0.00953   |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 629        |
|    iterations           | 1897       |
|    time_elapsed         | 6171       |
|    total_timesteps      | 3885056    |
| train/                  |            |
|    approx_kl            | 0.23682334 |
|    clip_fraction        | 0.43       |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.0773     |
|    explained_variance   | 0.735      |
|    learning_rate        | 0.00124    |
|    loss                 | 2.01e-05   |
|    n_updates            | 18960      |
|    policy_gradient_loss | 0.0108     |
|    std                  | 0.232      |
|    value_loss           | 0.0347     |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 629        |
|    iterations           | 1898       |
|    time_elapsed         | 6174       |
|    total_timesteps      | 3887104    |
| train/                  |            |
|    approx_kl            | 0.31708294 |
|    clip_fraction        | 0.448      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.12       |
|    explained_variance   | 0.182      |
|    learning_rate        | 0.00124    |
|    loss                 | -0.0252    |
|    n_updates            | 18970      |
|    policy_gradient_loss | 0.00377    |
|    std                  | 0.229      |
|    value_loss           | 0.00584    |
----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 629       |
|    iterations           | 1899      |
|    time_elapsed         | 6177      |
|    total_timesteps      | 3889152   |
| train/                  |           |
|    approx_kl            | 0.9930504 |
|    clip_fraction        | 0.422     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.192     |
|    explained_variance   | 0.733     |
|    learning_rate        | 0.00124   |
|    loss                 | 0.0203    |
|    n_updates            | 18980     |
|    policy_gradient_loss | -0.0127   |
|    std                  | 0.216     |
|    value_loss           | 0.0182    |
---------------------------------------
Eval num_timesteps=3890000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1         |
| time/                   |            |
|    total_timesteps      | 3890000    |
| train/                  |            |
|    approx_kl            | 0.17877589 |
|    clip_fraction        | 0.4        |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.202      |
|    explained_variance   | 0.351      |
|    learning_rate        | 0.00124    |
|    loss                 | -0.0117    |
|    n_updates            | 18990      |
|    policy_gradient_loss | -0.0105    |
|    std                  | 0.223      |
|    value_loss           | 0.00738    |
----------------------------------------
box reached target
--------------------------------
| time/              |         |
|    fps             | 629     |
|    iterations      | 1900    |
|    time_elapsed    | 6181    |
|    total_timesteps | 3891200 |
--------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 629        |
|    iterations           | 1901       |
|    time_elapsed         | 6184       |
|    total_timesteps      | 3893248    |
| train/                  |            |
|    approx_kl            | 0.25786522 |
|    clip_fraction        | 0.421      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.183      |
|    explained_variance   | 0.832      |
|    learning_rate        | 0.00124    |
|    loss                 | -0.00631   |
|    n_updates            | 19000      |
|    policy_gradient_loss | 0.00146    |
|    std                  | 0.223      |
|    value_loss           | 0.0115     |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 629        |
|    iterations           | 1902       |
|    time_elapsed         | 6187       |
|    total_timesteps      | 3895296    |
| train/                  |            |
|    approx_kl            | 0.19196603 |
|    clip_fraction        | 0.41       |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.191      |
|    explained_variance   | 0.865      |
|    learning_rate        | 0.00124    |
|    loss                 | -0.0213    |
|    n_updates            | 19010      |
|    policy_gradient_loss | 0.0123     |
|    std                  | 0.224      |
|    value_loss           | 0.00908    |
----------------------------------------
box reached target
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 629       |
|    iterations           | 1903      |
|    time_elapsed         | 6191      |
|    total_timesteps      | 3897344   |
| train/                  |           |
|    approx_kl            | 0.2450602 |
|    clip_fraction        | 0.448     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.215     |
|    explained_variance   | 0.783     |
|    learning_rate        | 0.00124   |
|    loss                 | 0.00586   |
|    n_updates            | 19020     |
|    policy_gradient_loss | 0.00698   |
|    std                  | 0.22      |
|    value_loss           | 0.0121    |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 629        |
|    iterations           | 1904       |
|    time_elapsed         | 6194       |
|    total_timesteps      | 3899392    |
| train/                  |            |
|    approx_kl            | 0.40006125 |
|    clip_fraction        | 0.51       |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.215      |
|    explained_variance   | 0.692      |
|    learning_rate        | 0.00124    |
|    loss                 | 0.177      |
|    n_updates            | 19030      |
|    policy_gradient_loss | 0.0248     |
|    std                  | 0.224      |
|    value_loss           | 0.0537     |
----------------------------------------
Eval num_timesteps=3900000, episode_reward=-0.77 +/- 0.57
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -0.772     |
| time/                   |            |
|    total_timesteps      | 3900000    |
| train/                  |            |
|    approx_kl            | 0.36212265 |
|    clip_fraction        | 0.419      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.197      |
|    explained_variance   | 0.343      |
|    learning_rate        | 0.00124    |
|    loss                 | -0.00795   |
|    n_updates            | 19040      |
|    policy_gradient_loss | 0.00576    |
|    std                  | 0.224      |
|    value_loss           | 0.0024     |
----------------------------------------
box reached target
box reached target
--------------------------------
| time/              |         |
|    fps             | 629     |
|    iterations      | 1905    |
|    time_elapsed    | 6198    |
|    total_timesteps | 3901440 |
--------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 629       |
|    iterations           | 1906      |
|    time_elapsed         | 6201      |
|    total_timesteps      | 3903488   |
| train/                  |           |
|    approx_kl            | 0.8833531 |
|    clip_fraction        | 0.525     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.189     |
|    explained_variance   | 0.787     |
|    learning_rate        | 0.00124   |
|    loss                 | -0.0541   |
|    n_updates            | 19050     |
|    policy_gradient_loss | 0.0137    |
|    std                  | 0.226     |
|    value_loss           | 0.0163    |
---------------------------------------
box reached target
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 629        |
|    iterations           | 1907       |
|    time_elapsed         | 6204       |
|    total_timesteps      | 3905536    |
| train/                  |            |
|    approx_kl            | 0.16462177 |
|    clip_fraction        | 0.427      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.141      |
|    explained_variance   | 0.727      |
|    learning_rate        | 0.00124    |
|    loss                 | -0.00546   |
|    n_updates            | 19060      |
|    policy_gradient_loss | 0.0425     |
|    std                  | 0.233      |
|    value_loss           | 0.0106     |
----------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 629       |
|    iterations           | 1908      |
|    time_elapsed         | 6207      |
|    total_timesteps      | 3907584   |
| train/                  |           |
|    approx_kl            | 0.6744213 |
|    clip_fraction        | 0.454     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.125     |
|    explained_variance   | 0.795     |
|    learning_rate        | 0.00124   |
|    loss                 | -0.00749  |
|    n_updates            | 19070     |
|    policy_gradient_loss | 0.0046    |
|    std                  | 0.233     |
|    value_loss           | 0.0118    |
---------------------------------------
box reached target
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 629        |
|    iterations           | 1909       |
|    time_elapsed         | 6210       |
|    total_timesteps      | 3909632    |
| train/                  |            |
|    approx_kl            | 0.25429893 |
|    clip_fraction        | 0.44       |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.135      |
|    explained_variance   | 0.959      |
|    learning_rate        | 0.00124    |
|    loss                 | 0.0228     |
|    n_updates            | 19080      |
|    policy_gradient_loss | 0.00144    |
|    std                  | 0.232      |
|    value_loss           | 0.00383    |
----------------------------------------
box reached target
box reached target
Eval num_timesteps=3910000, episode_reward=0.39 +/- 2.49
Episode length: 282.80 +/- 34.40
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 283       |
|    mean_reward          | 0.386     |
| time/                   |           |
|    total_timesteps      | 3910000   |
| train/                  |           |
|    approx_kl            | 0.2704711 |
|    clip_fraction        | 0.42      |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.0771    |
|    explained_variance   | 0.918     |
|    learning_rate        | 0.00124   |
|    loss                 | 0.222     |
|    n_updates            | 19090     |
|    policy_gradient_loss | 0.00282   |
|    std                  | 0.243     |
|    value_loss           | 0.0107    |
---------------------------------------
box reached target
box reached target
--------------------------------
| time/              |         |
|    fps             | 629     |
|    iterations      | 1910    |
|    time_elapsed    | 6214    |
|    total_timesteps | 3911680 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 629        |
|    iterations           | 1911       |
|    time_elapsed         | 6217       |
|    total_timesteps      | 3913728    |
| train/                  |            |
|    approx_kl            | 0.15370035 |
|    clip_fraction        | 0.404      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.0772     |
|    explained_variance   | 0.844      |
|    learning_rate        | 0.00124    |
|    loss                 | -0.0136    |
|    n_updates            | 19100      |
|    policy_gradient_loss | 0.0115     |
|    std                  | 0.238      |
|    value_loss           | 0.0196     |
----------------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 629        |
|    iterations           | 1912       |
|    time_elapsed         | 6220       |
|    total_timesteps      | 3915776    |
| train/                  |            |
|    approx_kl            | 0.32642382 |
|    clip_fraction        | 0.422      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.105      |
|    explained_variance   | 0.495      |
|    learning_rate        | 0.00124    |
|    loss                 | 0.0443     |
|    n_updates            | 19110      |
|    policy_gradient_loss | 0.00229    |
|    std                  | 0.237      |
|    value_loss           | 0.00419    |
----------------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 629        |
|    iterations           | 1913       |
|    time_elapsed         | 6223       |
|    total_timesteps      | 3917824    |
| train/                  |            |
|    approx_kl            | 0.15859678 |
|    clip_fraction        | 0.39       |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.0919     |
|    explained_variance   | 0.955      |
|    learning_rate        | 0.00124    |
|    loss                 | -0.0336    |
|    n_updates            | 19120      |
|    policy_gradient_loss | 0.00527    |
|    std                  | 0.237      |
|    value_loss           | 0.00551    |
----------------------------------------
box reached target
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 629        |
|    iterations           | 1914       |
|    time_elapsed         | 6226       |
|    total_timesteps      | 3919872    |
| train/                  |            |
|    approx_kl            | 0.20431548 |
|    clip_fraction        | 0.443      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.0571     |
|    explained_variance   | 0.89       |
|    learning_rate        | 0.00124    |
|    loss                 | 0.0584     |
|    n_updates            | 19130      |
|    policy_gradient_loss | 0.00889    |
|    std                  | 0.243      |
|    value_loss           | 0.0127     |
----------------------------------------
Eval num_timesteps=3920000, episode_reward=-0.91 +/- 0.26
Episode length: 300.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 300       |
|    mean_reward          | -0.905    |
| time/                   |           |
|    total_timesteps      | 3920000   |
| train/                  |           |
|    approx_kl            | 0.4150148 |
|    clip_fraction        | 0.471     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.0129    |
|    explained_variance   | 0.892     |
|    learning_rate        | 0.00124   |
|    loss                 | 0.0582    |
|    n_updates            | 19140     |
|    policy_gradient_loss | 0.0271    |
|    std                  | 0.255     |
|    value_loss           | 0.0107    |
---------------------------------------
--------------------------------
| time/              |         |
|    fps             | 629     |
|    iterations      | 1915    |
|    time_elapsed    | 6230    |
|    total_timesteps | 3921920 |
--------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 629        |
|    iterations           | 1916       |
|    time_elapsed         | 6233       |
|    total_timesteps      | 3923968    |
| train/                  |            |
|    approx_kl            | 0.27434796 |
|    clip_fraction        | 0.345      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.0352    |
|    explained_variance   | 0.861      |
|    learning_rate        | 0.00124    |
|    loss                 | -0.0268    |
|    n_updates            | 19150      |
|    policy_gradient_loss | -0.00322   |
|    std                  | 0.258      |
|    value_loss           | 0.00302    |
----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 629         |
|    iterations           | 1917        |
|    time_elapsed         | 6236        |
|    total_timesteps      | 3926016     |
| train/                  |             |
|    approx_kl            | 0.119163334 |
|    clip_fraction        | 0.408       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0632     |
|    explained_variance   | 0.748       |
|    learning_rate        | 0.00123     |
|    loss                 | 0.0152      |
|    n_updates            | 19160       |
|    policy_gradient_loss | 0.00537     |
|    std                  | 0.258       |
|    value_loss           | 0.0318      |
-----------------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 629        |
|    iterations           | 1918       |
|    time_elapsed         | 6239       |
|    total_timesteps      | 3928064    |
| train/                  |            |
|    approx_kl            | 0.16176394 |
|    clip_fraction        | 0.442      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.0164    |
|    explained_variance   | 0.815      |
|    learning_rate        | 0.00123    |
|    loss                 | -0.0256    |
|    n_updates            | 19170      |
|    policy_gradient_loss | 0.0177     |
|    std                  | 0.248      |
|    value_loss           | 0.00577    |
----------------------------------------
box reached target
box reached target
Eval num_timesteps=3930000, episode_reward=0.33 +/- 2.34
Episode length: 274.40 +/- 51.20
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 274        |
|    mean_reward          | 0.332      |
| time/                   |            |
|    total_timesteps      | 3930000    |
| train/                  |            |
|    approx_kl            | 0.18770432 |
|    clip_fraction        | 0.373      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.0352    |
|    explained_variance   | 0.766      |
|    learning_rate        | 0.00123    |
|    loss                 | -0.0352    |
|    n_updates            | 19180      |
|    policy_gradient_loss | 0.0113     |
|    std                  | 0.256      |
|    value_loss           | 0.0113     |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 629     |
|    iterations      | 1919    |
|    time_elapsed    | 6243    |
|    total_timesteps | 3930112 |
--------------------------------
box reached target
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 629        |
|    iterations           | 1920       |
|    time_elapsed         | 6246       |
|    total_timesteps      | 3932160    |
| train/                  |            |
|    approx_kl            | 0.34797534 |
|    clip_fraction        | 0.429      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.0596    |
|    explained_variance   | 0.858      |
|    learning_rate        | 0.00123    |
|    loss                 | 0.0217     |
|    n_updates            | 19190      |
|    policy_gradient_loss | 0.0149     |
|    std                  | 0.256      |
|    value_loss           | 0.0097     |
----------------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 629        |
|    iterations           | 1921       |
|    time_elapsed         | 6249       |
|    total_timesteps      | 3934208    |
| train/                  |            |
|    approx_kl            | 0.16525939 |
|    clip_fraction        | 0.383      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.00403   |
|    explained_variance   | 0.879      |
|    learning_rate        | 0.00123    |
|    loss                 | 0.0314     |
|    n_updates            | 19200      |
|    policy_gradient_loss | 0.00646    |
|    std                  | 0.249      |
|    value_loss           | 0.0182     |
----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 629       |
|    iterations           | 1922      |
|    time_elapsed         | 6252      |
|    total_timesteps      | 3936256   |
| train/                  |           |
|    approx_kl            | 0.2205225 |
|    clip_fraction        | 0.402     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00747  |
|    explained_variance   | 0.822     |
|    learning_rate        | 0.00123   |
|    loss                 | -0.0316   |
|    n_updates            | 19210     |
|    policy_gradient_loss | 0.0105    |
|    std                  | 0.253     |
|    value_loss           | 0.0115    |
---------------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 629        |
|    iterations           | 1923       |
|    time_elapsed         | 6255       |
|    total_timesteps      | 3938304    |
| train/                  |            |
|    approx_kl            | 0.11525446 |
|    clip_fraction        | 0.407      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.0694    |
|    explained_variance   | 0.779      |
|    learning_rate        | 0.00123    |
|    loss                 | -0.0137    |
|    n_updates            | 19220      |
|    policy_gradient_loss | 0.0166     |
|    std                  | 0.262      |
|    value_loss           | 0.00409    |
----------------------------------------
box reached target
box reached target
box reached target
Eval num_timesteps=3940000, episode_reward=1.12 +/- 2.14
Episode length: 285.60 +/- 28.80
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 286        |
|    mean_reward          | 1.12       |
| time/                   |            |
|    total_timesteps      | 3940000    |
| train/                  |            |
|    approx_kl            | 0.18514612 |
|    clip_fraction        | 0.384      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.115     |
|    explained_variance   | 0.859      |
|    learning_rate        | 0.00123    |
|    loss                 | 0.0167     |
|    n_updates            | 19230      |
|    policy_gradient_loss | 0.0138     |
|    std                  | 0.27       |
|    value_loss           | 0.0137     |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 629     |
|    iterations      | 1924    |
|    time_elapsed    | 6259    |
|    total_timesteps | 3940352 |
--------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 629        |
|    iterations           | 1925       |
|    time_elapsed         | 6262       |
|    total_timesteps      | 3942400    |
| train/                  |            |
|    approx_kl            | 0.14109263 |
|    clip_fraction        | 0.417      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.125     |
|    explained_variance   | 0.838      |
|    learning_rate        | 0.00123    |
|    loss                 | -0.0131    |
|    n_updates            | 19240      |
|    policy_gradient_loss | 0.0127     |
|    std                  | 0.266      |
|    value_loss           | 0.0138     |
----------------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 629        |
|    iterations           | 1926       |
|    time_elapsed         | 6265       |
|    total_timesteps      | 3944448    |
| train/                  |            |
|    approx_kl            | 0.11484681 |
|    clip_fraction        | 0.34       |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.153     |
|    explained_variance   | 0.94       |
|    learning_rate        | 0.00123    |
|    loss                 | -0.0172    |
|    n_updates            | 19250      |
|    policy_gradient_loss | 0.016      |
|    std                  | 0.27       |
|    value_loss           | 0.00566    |
----------------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 629        |
|    iterations           | 1927       |
|    time_elapsed         | 6268       |
|    total_timesteps      | 3946496    |
| train/                  |            |
|    approx_kl            | 0.20528324 |
|    clip_fraction        | 0.399      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.144     |
|    explained_variance   | 0.874      |
|    learning_rate        | 0.00123    |
|    loss                 | 0.0254     |
|    n_updates            | 19260      |
|    policy_gradient_loss | 0.00505    |
|    std                  | 0.265      |
|    value_loss           | 0.0104     |
----------------------------------------
box reached target
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 629       |
|    iterations           | 1928      |
|    time_elapsed         | 6271      |
|    total_timesteps      | 3948544   |
| train/                  |           |
|    approx_kl            | 0.1796464 |
|    clip_fraction        | 0.377     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.161    |
|    explained_variance   | 0.918     |
|    learning_rate        | 0.00123   |
|    loss                 | -0.0423   |
|    n_updates            | 19270     |
|    policy_gradient_loss | 0.00373   |
|    std                  | 0.27      |
|    value_loss           | 0.0106    |
---------------------------------------
box reached target
Eval num_timesteps=3950000, episode_reward=0.24 +/- 2.48
Episode length: 280.60 +/- 38.80
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 281        |
|    mean_reward          | 0.242      |
| time/                   |            |
|    total_timesteps      | 3950000    |
| train/                  |            |
|    approx_kl            | 0.09647521 |
|    clip_fraction        | 0.33       |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.167     |
|    explained_variance   | 0.722      |
|    learning_rate        | 0.00123    |
|    loss                 | -0.00711   |
|    n_updates            | 19280      |
|    policy_gradient_loss | 0.00151    |
|    std                  | 0.267      |
|    value_loss           | 0.0227     |
----------------------------------------
box reached target
--------------------------------
| time/              |         |
|    fps             | 629     |
|    iterations      | 1929    |
|    time_elapsed    | 6275    |
|    total_timesteps | 3950592 |
--------------------------------
box reached target
box reached target
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 629        |
|    iterations           | 1930       |
|    time_elapsed         | 6278       |
|    total_timesteps      | 3952640    |
| train/                  |            |
|    approx_kl            | 0.19932172 |
|    clip_fraction        | 0.391      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.164     |
|    explained_variance   | 0.872      |
|    learning_rate        | 0.00123    |
|    loss                 | 0.00888    |
|    n_updates            | 19290      |
|    policy_gradient_loss | 0.00834    |
|    std                  | 0.271      |
|    value_loss           | 0.0116     |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 629        |
|    iterations           | 1931       |
|    time_elapsed         | 6281       |
|    total_timesteps      | 3954688    |
| train/                  |            |
|    approx_kl            | 0.13370192 |
|    clip_fraction        | 0.392      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.167     |
|    explained_variance   | 0.846      |
|    learning_rate        | 0.00123    |
|    loss                 | 0.00762    |
|    n_updates            | 19300      |
|    policy_gradient_loss | -0.000746  |
|    std                  | 0.27       |
|    value_loss           | 0.0251     |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 629        |
|    iterations           | 1932       |
|    time_elapsed         | 6284       |
|    total_timesteps      | 3956736    |
| train/                  |            |
|    approx_kl            | 0.10957894 |
|    clip_fraction        | 0.376      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.174     |
|    explained_variance   | 0.796      |
|    learning_rate        | 0.00123    |
|    loss                 | -0.0125    |
|    n_updates            | 19310      |
|    policy_gradient_loss | 0.00536    |
|    std                  | 0.269      |
|    value_loss           | 0.00682    |
----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 629       |
|    iterations           | 1933      |
|    time_elapsed         | 6287      |
|    total_timesteps      | 3958784   |
| train/                  |           |
|    approx_kl            | 0.3157804 |
|    clip_fraction        | 0.413     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.173    |
|    explained_variance   | 0.865     |
|    learning_rate        | 0.00123   |
|    loss                 | -0.00568  |
|    n_updates            | 19320     |
|    policy_gradient_loss | 0.00131   |
|    std                  | 0.269     |
|    value_loss           | 0.00699   |
---------------------------------------
box reached target
box reached target
box reached target
Eval num_timesteps=3960000, episode_reward=1.79 +/- 3.00
Episode length: 250.40 +/- 66.30
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 250        |
|    mean_reward          | 1.79       |
| time/                   |            |
|    total_timesteps      | 3960000    |
| train/                  |            |
|    approx_kl            | 0.20898847 |
|    clip_fraction        | 0.401      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.189     |
|    explained_variance   | 0.678      |
|    learning_rate        | 0.00123    |
|    loss                 | -0.00851   |
|    n_updates            | 19330      |
|    policy_gradient_loss | 0.0158     |
|    std                  | 0.275      |
|    value_loss           | 0.0154     |
----------------------------------------
box reached target
--------------------------------
| time/              |         |
|    fps             | 629     |
|    iterations      | 1934    |
|    time_elapsed    | 6291    |
|    total_timesteps | 3960832 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 629        |
|    iterations           | 1935       |
|    time_elapsed         | 6294       |
|    total_timesteps      | 3962880    |
| train/                  |            |
|    approx_kl            | 0.19746932 |
|    clip_fraction        | 0.377      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.192     |
|    explained_variance   | 0.828      |
|    learning_rate        | 0.00123    |
|    loss                 | 0.0682     |
|    n_updates            | 19340      |
|    policy_gradient_loss | 0.00714    |
|    std                  | 0.277      |
|    value_loss           | 0.0155     |
----------------------------------------
box reached target
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 629        |
|    iterations           | 1936       |
|    time_elapsed         | 6297       |
|    total_timesteps      | 3964928    |
| train/                  |            |
|    approx_kl            | 0.14951135 |
|    clip_fraction        | 0.379      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.212     |
|    explained_variance   | 0.732      |
|    learning_rate        | 0.00123    |
|    loss                 | 0.0523     |
|    n_updates            | 19350      |
|    policy_gradient_loss | -0.00596   |
|    std                  | 0.281      |
|    value_loss           | 0.00536    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 629        |
|    iterations           | 1937       |
|    time_elapsed         | 6300       |
|    total_timesteps      | 3966976    |
| train/                  |            |
|    approx_kl            | 0.35214508 |
|    clip_fraction        | 0.432      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.24      |
|    explained_variance   | 0.813      |
|    learning_rate        | 0.00123    |
|    loss                 | 0.0695     |
|    n_updates            | 19360      |
|    policy_gradient_loss | 0.0185     |
|    std                  | 0.284      |
|    value_loss           | 0.0179     |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 629        |
|    iterations           | 1938       |
|    time_elapsed         | 6303       |
|    total_timesteps      | 3969024    |
| train/                  |            |
|    approx_kl            | 0.22366694 |
|    clip_fraction        | 0.37       |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.234     |
|    explained_variance   | 0.628      |
|    learning_rate        | 0.00123    |
|    loss                 | 0.00614    |
|    n_updates            | 19370      |
|    policy_gradient_loss | 0.0135     |
|    std                  | 0.282      |
|    value_loss           | 0.0058     |
----------------------------------------
box reached target
box reached target
Eval num_timesteps=3970000, episode_reward=0.30 +/- 2.60
Episode length: 283.00 +/- 34.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 283        |
|    mean_reward          | 0.302      |
| time/                   |            |
|    total_timesteps      | 3970000    |
| train/                  |            |
|    approx_kl            | 0.21182363 |
|    clip_fraction        | 0.391      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.197     |
|    explained_variance   | 0.657      |
|    learning_rate        | 0.00123    |
|    loss                 | -0.0136    |
|    n_updates            | 19380      |
|    policy_gradient_loss | 0.00288    |
|    std                  | 0.273      |
|    value_loss           | 0.019      |
----------------------------------------
box reached target
--------------------------------
| time/              |         |
|    fps             | 629     |
|    iterations      | 1939    |
|    time_elapsed    | 6307    |
|    total_timesteps | 3971072 |
--------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 629        |
|    iterations           | 1940       |
|    time_elapsed         | 6310       |
|    total_timesteps      | 3973120    |
| train/                  |            |
|    approx_kl            | 0.14988425 |
|    clip_fraction        | 0.411      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.199     |
|    explained_variance   | 0.855      |
|    learning_rate        | 0.00123    |
|    loss                 | -0.000189  |
|    n_updates            | 19390      |
|    policy_gradient_loss | 0.00533    |
|    std                  | 0.274      |
|    value_loss           | 0.0125     |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 629        |
|    iterations           | 1941       |
|    time_elapsed         | 6313       |
|    total_timesteps      | 3975168    |
| train/                  |            |
|    approx_kl            | 0.29826748 |
|    clip_fraction        | 0.411      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.156     |
|    explained_variance   | 0.922      |
|    learning_rate        | 0.00123    |
|    loss                 | 0.0309     |
|    n_updates            | 19400      |
|    policy_gradient_loss | 0.00707    |
|    std                  | 0.268      |
|    value_loss           | 0.00915    |
----------------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 629         |
|    iterations           | 1942        |
|    time_elapsed         | 6316        |
|    total_timesteps      | 3977216     |
| train/                  |             |
|    approx_kl            | 0.113425195 |
|    clip_fraction        | 0.325       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.154      |
|    explained_variance   | 0.754       |
|    learning_rate        | 0.00122     |
|    loss                 | -0.0462     |
|    n_updates            | 19410       |
|    policy_gradient_loss | 0.000515    |
|    std                  | 0.271       |
|    value_loss           | 0.002       |
-----------------------------------------
box reached target
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 629       |
|    iterations           | 1943      |
|    time_elapsed         | 6319      |
|    total_timesteps      | 3979264   |
| train/                  |           |
|    approx_kl            | 0.4443344 |
|    clip_fraction        | 0.403     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.149    |
|    explained_variance   | 0.923     |
|    learning_rate        | 0.00122   |
|    loss                 | -0.0129   |
|    n_updates            | 19420     |
|    policy_gradient_loss | -0.00121  |
|    std                  | 0.268     |
|    value_loss           | 0.00521   |
---------------------------------------
Eval num_timesteps=3980000, episode_reward=-1.11 +/- 0.15
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1.11      |
| time/                   |            |
|    total_timesteps      | 3980000    |
| train/                  |            |
|    approx_kl            | 0.11482948 |
|    clip_fraction        | 0.395      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.117     |
|    explained_variance   | 0.802      |
|    learning_rate        | 0.00122    |
|    loss                 | -0.0221    |
|    n_updates            | 19430      |
|    policy_gradient_loss | 0.0127     |
|    std                  | 0.263      |
|    value_loss           | 0.0134     |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 629     |
|    iterations      | 1944    |
|    time_elapsed    | 6323    |
|    total_timesteps | 3981312 |
--------------------------------
box reached target
box reached target
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 629       |
|    iterations           | 1945      |
|    time_elapsed         | 6326      |
|    total_timesteps      | 3983360   |
| train/                  |           |
|    approx_kl            | 0.2573414 |
|    clip_fraction        | 0.386     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0883   |
|    explained_variance   | 0.776     |
|    learning_rate        | 0.00122   |
|    loss                 | 0.041     |
|    n_updates            | 19440     |
|    policy_gradient_loss | 0.0318    |
|    std                  | 0.258     |
|    value_loss           | 0.00624   |
---------------------------------------
box reached target
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 629       |
|    iterations           | 1946      |
|    time_elapsed         | 6329      |
|    total_timesteps      | 3985408   |
| train/                  |           |
|    approx_kl            | 0.2247048 |
|    clip_fraction        | 0.413     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.108    |
|    explained_variance   | 0.945     |
|    learning_rate        | 0.00122   |
|    loss                 | 0.0414    |
|    n_updates            | 19450     |
|    policy_gradient_loss | 0.0172    |
|    std                  | 0.263     |
|    value_loss           | 0.00911   |
---------------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 629        |
|    iterations           | 1947       |
|    time_elapsed         | 6332       |
|    total_timesteps      | 3987456    |
| train/                  |            |
|    approx_kl            | 0.27284175 |
|    clip_fraction        | 0.425      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.125     |
|    explained_variance   | 0.941      |
|    learning_rate        | 0.00122    |
|    loss                 | 0.00849    |
|    n_updates            | 19460      |
|    policy_gradient_loss | 0.00904    |
|    std                  | 0.264      |
|    value_loss           | 0.0107     |
----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 629       |
|    iterations           | 1948      |
|    time_elapsed         | 6335      |
|    total_timesteps      | 3989504   |
| train/                  |           |
|    approx_kl            | 0.5153822 |
|    clip_fraction        | 0.438     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0746   |
|    explained_variance   | 0.88      |
|    learning_rate        | 0.00122   |
|    loss                 | 0.000814  |
|    n_updates            | 19470     |
|    policy_gradient_loss | -0.00738  |
|    std                  | 0.249     |
|    value_loss           | 0.0059    |
---------------------------------------
Eval num_timesteps=3990000, episode_reward=-0.46 +/- 0.67
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -0.456     |
| time/                   |            |
|    total_timesteps      | 3990000    |
| train/                  |            |
|    approx_kl            | 0.11996609 |
|    clip_fraction        | 0.364      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.00509   |
|    explained_variance   | 0.636      |
|    learning_rate        | 0.00122    |
|    loss                 | -0.00236   |
|    n_updates            | 19480      |
|    policy_gradient_loss | 0.0184     |
|    std                  | 0.246      |
|    value_loss           | 0.00647    |
----------------------------------------
box reached target
--------------------------------
| time/              |         |
|    fps             | 629     |
|    iterations      | 1949    |
|    time_elapsed    | 6339    |
|    total_timesteps | 3991552 |
--------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 629        |
|    iterations           | 1950       |
|    time_elapsed         | 6342       |
|    total_timesteps      | 3993600    |
| train/                  |            |
|    approx_kl            | 0.16096035 |
|    clip_fraction        | 0.348      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.0161     |
|    explained_variance   | 0.644      |
|    learning_rate        | 0.00122    |
|    loss                 | 0.00356    |
|    n_updates            | 19490      |
|    policy_gradient_loss | 0.00557    |
|    std                  | 0.245      |
|    value_loss           | 0.013      |
----------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 629       |
|    iterations           | 1951      |
|    time_elapsed         | 6346      |
|    total_timesteps      | 3995648   |
| train/                  |           |
|    approx_kl            | 0.3913313 |
|    clip_fraction        | 0.458     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.0325    |
|    explained_variance   | 0.908     |
|    learning_rate        | 0.00122   |
|    loss                 | -0.0182   |
|    n_updates            | 19500     |
|    policy_gradient_loss | 0.00579   |
|    std                  | 0.242     |
|    value_loss           | 0.012     |
---------------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 629        |
|    iterations           | 1952       |
|    time_elapsed         | 6349       |
|    total_timesteps      | 3997696    |
| train/                  |            |
|    approx_kl            | 0.07473031 |
|    clip_fraction        | 0.374      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.0102     |
|    explained_variance   | 0.873      |
|    learning_rate        | 0.00122    |
|    loss                 | 0.036      |
|    n_updates            | 19510      |
|    policy_gradient_loss | 0.0165     |
|    std                  | 0.249      |
|    value_loss           | 0.0294     |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 629        |
|    iterations           | 1953       |
|    time_elapsed         | 6352       |
|    total_timesteps      | 3999744    |
| train/                  |            |
|    approx_kl            | 0.27476507 |
|    clip_fraction        | 0.413      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.00817   |
|    explained_variance   | 0.895      |
|    learning_rate        | 0.00122    |
|    loss                 | -0.0141    |
|    n_updates            | 19520      |
|    policy_gradient_loss | 0.0112     |
|    std                  | 0.247      |
|    value_loss           | 0.0105     |
----------------------------------------
box reached target
Eval num_timesteps=4000000, episode_reward=0.49 +/- 2.66
Episode length: 282.80 +/- 34.40
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 283        |
|    mean_reward          | 0.493      |
| time/                   |            |
|    total_timesteps      | 4000000    |
| train/                  |            |
|    approx_kl            | 0.13952836 |
|    clip_fraction        | 0.339      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.00335    |
|    explained_variance   | 0.898      |
|    learning_rate        | 0.00122    |
|    loss                 | 0.00106    |
|    n_updates            | 19530      |
|    policy_gradient_loss | -0.00402   |
|    std                  | 0.243      |
|    value_loss           | 0.00894    |
----------------------------------------
box reached target
--------------------------------
| time/              |         |
|    fps             | 629     |
|    iterations      | 1954    |
|    time_elapsed    | 6356    |
|    total_timesteps | 4001792 |
--------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 629        |
|    iterations           | 1955       |
|    time_elapsed         | 6359       |
|    total_timesteps      | 4003840    |
| train/                  |            |
|    approx_kl            | 0.07524109 |
|    clip_fraction        | 0.348      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.0249     |
|    explained_variance   | 0.864      |
|    learning_rate        | 0.00122    |
|    loss                 | -0.0396    |
|    n_updates            | 19540      |
|    policy_gradient_loss | 0.00436    |
|    std                  | 0.243      |
|    value_loss           | 0.0126     |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 629        |
|    iterations           | 1956       |
|    time_elapsed         | 6362       |
|    total_timesteps      | 4005888    |
| train/                  |            |
|    approx_kl            | 0.18221445 |
|    clip_fraction        | 0.37       |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.042      |
|    explained_variance   | 0.971      |
|    learning_rate        | 0.00122    |
|    loss                 | -0.00317   |
|    n_updates            | 19550      |
|    policy_gradient_loss | -0.00194   |
|    std                  | 0.238      |
|    value_loss           | 0.00331    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 629        |
|    iterations           | 1957       |
|    time_elapsed         | 6365       |
|    total_timesteps      | 4007936    |
| train/                  |            |
|    approx_kl            | 0.68763006 |
|    clip_fraction        | 0.469      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.0858     |
|    explained_variance   | 0.856      |
|    learning_rate        | 0.00122    |
|    loss                 | -0.0156    |
|    n_updates            | 19560      |
|    policy_gradient_loss | 0.0121     |
|    std                  | 0.233      |
|    value_loss           | 0.0322     |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 629        |
|    iterations           | 1958       |
|    time_elapsed         | 6368       |
|    total_timesteps      | 4009984    |
| train/                  |            |
|    approx_kl            | 0.17923866 |
|    clip_fraction        | 0.4        |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.12       |
|    explained_variance   | 0.643      |
|    learning_rate        | 0.00122    |
|    loss                 | 0.00616    |
|    n_updates            | 19570      |
|    policy_gradient_loss | 0.00363    |
|    std                  | 0.233      |
|    value_loss           | 0.00553    |
----------------------------------------
box reached target
Eval num_timesteps=4010000, episode_reward=0.18 +/- 2.37
Episode length: 280.80 +/- 38.40
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 281        |
|    mean_reward          | 0.184      |
| time/                   |            |
|    total_timesteps      | 4010000    |
| train/                  |            |
|    approx_kl            | 0.22724907 |
|    clip_fraction        | 0.409      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.118      |
|    explained_variance   | 0.865      |
|    learning_rate        | 0.00122    |
|    loss                 | 0.0302     |
|    n_updates            | 19580      |
|    policy_gradient_loss | 0.00778    |
|    std                  | 0.236      |
|    value_loss           | 0.00715    |
----------------------------------------
box reached target
box reached target
--------------------------------
| time/              |         |
|    fps             | 629     |
|    iterations      | 1959    |
|    time_elapsed    | 6372    |
|    total_timesteps | 4012032 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 629        |
|    iterations           | 1960       |
|    time_elapsed         | 6375       |
|    total_timesteps      | 4014080    |
| train/                  |            |
|    approx_kl            | 0.21402216 |
|    clip_fraction        | 0.445      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.119      |
|    explained_variance   | 0.936      |
|    learning_rate        | 0.00122    |
|    loss                 | -0.0149    |
|    n_updates            | 19590      |
|    policy_gradient_loss | 0.0142     |
|    std                  | 0.235      |
|    value_loss           | 0.0126     |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 629        |
|    iterations           | 1961       |
|    time_elapsed         | 6378       |
|    total_timesteps      | 4016128    |
| train/                  |            |
|    approx_kl            | 0.21043861 |
|    clip_fraction        | 0.44       |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.0957     |
|    explained_variance   | 0.68       |
|    learning_rate        | 0.00122    |
|    loss                 | -0.0157    |
|    n_updates            | 19600      |
|    policy_gradient_loss | 0.0191     |
|    std                  | 0.238      |
|    value_loss           | 0.00615    |
----------------------------------------
box reached target
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 629        |
|    iterations           | 1962       |
|    time_elapsed         | 6381       |
|    total_timesteps      | 4018176    |
| train/                  |            |
|    approx_kl            | 0.31434464 |
|    clip_fraction        | 0.447      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.0975     |
|    explained_variance   | 0.825      |
|    learning_rate        | 0.00122    |
|    loss                 | 0.0524     |
|    n_updates            | 19610      |
|    policy_gradient_loss | -0.00234   |
|    std                  | 0.232      |
|    value_loss           | 0.00503    |
----------------------------------------
box reached target
Eval num_timesteps=4020000, episode_reward=0.57 +/- 2.33
Episode length: 274.00 +/- 52.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 274        |
|    mean_reward          | 0.567      |
| time/                   |            |
|    total_timesteps      | 4020000    |
| train/                  |            |
|    approx_kl            | 0.21072996 |
|    clip_fraction        | 0.446      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.12       |
|    explained_variance   | 0.82       |
|    learning_rate        | 0.00122    |
|    loss                 | 0.052      |
|    n_updates            | 19620      |
|    policy_gradient_loss | 0.00691    |
|    std                  | 0.234      |
|    value_loss           | 0.0187     |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 629     |
|    iterations      | 1963    |
|    time_elapsed    | 6385    |
|    total_timesteps | 4020224 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 629        |
|    iterations           | 1964       |
|    time_elapsed         | 6388       |
|    total_timesteps      | 4022272    |
| train/                  |            |
|    approx_kl            | 0.24811581 |
|    clip_fraction        | 0.416      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.113      |
|    explained_variance   | 0.808      |
|    learning_rate        | 0.00122    |
|    loss                 | -0.0255    |
|    n_updates            | 19630      |
|    policy_gradient_loss | 0.0159     |
|    std                  | 0.235      |
|    value_loss           | 0.00697    |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 629        |
|    iterations           | 1965       |
|    time_elapsed         | 6391       |
|    total_timesteps      | 4024320    |
| train/                  |            |
|    approx_kl            | 0.15282944 |
|    clip_fraction        | 0.401      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.0992     |
|    explained_variance   | 0.861      |
|    learning_rate        | 0.00122    |
|    loss                 | -0.0217    |
|    n_updates            | 19640      |
|    policy_gradient_loss | 0.0123     |
|    std                  | 0.24       |
|    value_loss           | 0.00355    |
----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 629       |
|    iterations           | 1966      |
|    time_elapsed         | 6394      |
|    total_timesteps      | 4026368   |
| train/                  |           |
|    approx_kl            | 0.4643622 |
|    clip_fraction        | 0.436     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.0236    |
|    explained_variance   | 0.734     |
|    learning_rate        | 0.00122   |
|    loss                 | 0.0154    |
|    n_updates            | 19650     |
|    policy_gradient_loss | 0.0334    |
|    std                  | 0.241     |
|    value_loss           | 0.0175    |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 629        |
|    iterations           | 1967       |
|    time_elapsed         | 6397       |
|    total_timesteps      | 4028416    |
| train/                  |            |
|    approx_kl            | 0.23342645 |
|    clip_fraction        | 0.434      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.052      |
|    explained_variance   | 0.756      |
|    learning_rate        | 0.00121    |
|    loss                 | -0.059     |
|    n_updates            | 19660      |
|    policy_gradient_loss | 0.000858   |
|    std                  | 0.241      |
|    value_loss           | 0.00312    |
----------------------------------------
box reached target
box reached target
Eval num_timesteps=4030000, episode_reward=1.41 +/- 3.06
Episode length: 251.40 +/- 59.53
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 251       |
|    mean_reward          | 1.41      |
| time/                   |           |
|    total_timesteps      | 4030000   |
| train/                  |           |
|    approx_kl            | 0.2268874 |
|    clip_fraction        | 0.396     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.0279    |
|    explained_variance   | 0.801     |
|    learning_rate        | 0.00121   |
|    loss                 | 0.0466    |
|    n_updates            | 19670     |
|    policy_gradient_loss | -0.0017   |
|    std                  | 0.242     |
|    value_loss           | 0.00483   |
---------------------------------------
--------------------------------
| time/              |         |
|    fps             | 629     |
|    iterations      | 1968    |
|    time_elapsed    | 6401    |
|    total_timesteps | 4030464 |
--------------------------------
box reached target
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 629       |
|    iterations           | 1969      |
|    time_elapsed         | 6404      |
|    total_timesteps      | 4032512   |
| train/                  |           |
|    approx_kl            | 0.5593219 |
|    clip_fraction        | 0.427     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.0527    |
|    explained_variance   | 0.461     |
|    learning_rate        | 0.00121   |
|    loss                 | -0.042    |
|    n_updates            | 19680     |
|    policy_gradient_loss | -0.000887 |
|    std                  | 0.238     |
|    value_loss           | 0.00294   |
---------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 629       |
|    iterations           | 1970      |
|    time_elapsed         | 6407      |
|    total_timesteps      | 4034560   |
| train/                  |           |
|    approx_kl            | 0.2371585 |
|    clip_fraction        | 0.45      |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.0599    |
|    explained_variance   | 0.772     |
|    learning_rate        | 0.00121   |
|    loss                 | 0.00267   |
|    n_updates            | 19690     |
|    policy_gradient_loss | 0.0201    |
|    std                  | 0.241     |
|    value_loss           | 0.0157    |
---------------------------------------
box reached target
box reached target
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 629         |
|    iterations           | 1971        |
|    time_elapsed         | 6410        |
|    total_timesteps      | 4036608     |
| train/                  |             |
|    approx_kl            | 0.110862195 |
|    clip_fraction        | 0.431       |
|    clip_range           | 0.2         |
|    entropy_loss         | 0.0556      |
|    explained_variance   | 0.857       |
|    learning_rate        | 0.00121     |
|    loss                 | 0.0283      |
|    n_updates            | 19700       |
|    policy_gradient_loss | 0.0108      |
|    std                  | 0.241       |
|    value_loss           | 0.0107      |
-----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 629        |
|    iterations           | 1972       |
|    time_elapsed         | 6413       |
|    total_timesteps      | 4038656    |
| train/                  |            |
|    approx_kl            | 0.19945768 |
|    clip_fraction        | 0.442      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.0246     |
|    explained_variance   | 0.778      |
|    learning_rate        | 0.00121    |
|    loss                 | -0.0132    |
|    n_updates            | 19710      |
|    policy_gradient_loss | 0.0218     |
|    std                  | 0.246      |
|    value_loss           | 0.0391     |
----------------------------------------
box reached target
box reached target
box reached target
box reached target
Eval num_timesteps=4040000, episode_reward=1.46 +/- 3.01
Episode length: 252.00 +/- 61.40
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 252        |
|    mean_reward          | 1.46       |
| time/                   |            |
|    total_timesteps      | 4040000    |
| train/                  |            |
|    approx_kl            | 0.42016095 |
|    clip_fraction        | 0.461      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.0103    |
|    explained_variance   | 0.547      |
|    learning_rate        | 0.00121    |
|    loss                 | -0.00365   |
|    n_updates            | 19720      |
|    policy_gradient_loss | 0.0154     |
|    std                  | 0.243      |
|    value_loss           | 0.0054     |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 629     |
|    iterations      | 1973    |
|    time_elapsed    | 6417    |
|    total_timesteps | 4040704 |
--------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 629        |
|    iterations           | 1974       |
|    time_elapsed         | 6420       |
|    total_timesteps      | 4042752    |
| train/                  |            |
|    approx_kl            | 0.16183563 |
|    clip_fraction        | 0.383      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.0111    |
|    explained_variance   | 0.852      |
|    learning_rate        | 0.00121    |
|    loss                 | -0.0165    |
|    n_updates            | 19730      |
|    policy_gradient_loss | 0.0173     |
|    std                  | 0.251      |
|    value_loss           | 0.0254     |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 629        |
|    iterations           | 1975       |
|    time_elapsed         | 6423       |
|    total_timesteps      | 4044800    |
| train/                  |            |
|    approx_kl            | 0.12070951 |
|    clip_fraction        | 0.35       |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.0096    |
|    explained_variance   | 0.671      |
|    learning_rate        | 0.00121    |
|    loss                 | -0.0157    |
|    n_updates            | 19740      |
|    policy_gradient_loss | 0.00996    |
|    std                  | 0.247      |
|    value_loss           | 0.0114     |
----------------------------------------
box reached target
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 629        |
|    iterations           | 1976       |
|    time_elapsed         | 6426       |
|    total_timesteps      | 4046848    |
| train/                  |            |
|    approx_kl            | 0.26060918 |
|    clip_fraction        | 0.406      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.00807   |
|    explained_variance   | 0.768      |
|    learning_rate        | 0.00121    |
|    loss                 | 0.0736     |
|    n_updates            | 19750      |
|    policy_gradient_loss | 0.0149     |
|    std                  | 0.247      |
|    value_loss           | 0.0405     |
----------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 629       |
|    iterations           | 1977      |
|    time_elapsed         | 6429      |
|    total_timesteps      | 4048896   |
| train/                  |           |
|    approx_kl            | 0.3108312 |
|    clip_fraction        | 0.439     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.00276  |
|    explained_variance   | 0.8       |
|    learning_rate        | 0.00121   |
|    loss                 | 0.0315    |
|    n_updates            | 19760     |
|    policy_gradient_loss | 0.00703   |
|    std                  | 0.244     |
|    value_loss           | 0.0306    |
---------------------------------------
box reached target
Eval num_timesteps=4050000, episode_reward=-0.29 +/- 0.58
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -0.293     |
| time/                   |            |
|    total_timesteps      | 4050000    |
| train/                  |            |
|    approx_kl            | 0.16668251 |
|    clip_fraction        | 0.38       |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.0074     |
|    explained_variance   | 0.884      |
|    learning_rate        | 0.00121    |
|    loss                 | -0.0385    |
|    n_updates            | 19770      |
|    policy_gradient_loss | 0.00602    |
|    std                  | 0.244      |
|    value_loss           | 0.00754    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 629     |
|    iterations      | 1978    |
|    time_elapsed    | 6433    |
|    total_timesteps | 4050944 |
--------------------------------
box reached target
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 629        |
|    iterations           | 1979       |
|    time_elapsed         | 6436       |
|    total_timesteps      | 4052992    |
| train/                  |            |
|    approx_kl            | 0.11123635 |
|    clip_fraction        | 0.396      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.023      |
|    explained_variance   | 0.943      |
|    learning_rate        | 0.00121    |
|    loss                 | -0.0274    |
|    n_updates            | 19780      |
|    policy_gradient_loss | 0.00947    |
|    std                  | 0.242      |
|    value_loss           | 0.00753    |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 629        |
|    iterations           | 1980       |
|    time_elapsed         | 6439       |
|    total_timesteps      | 4055040    |
| train/                  |            |
|    approx_kl            | 0.47538304 |
|    clip_fraction        | 0.466      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.0664     |
|    explained_variance   | 0.939      |
|    learning_rate        | 0.00121    |
|    loss                 | 0.0585     |
|    n_updates            | 19790      |
|    policy_gradient_loss | 0.00786    |
|    std                  | 0.236      |
|    value_loss           | 0.013      |
----------------------------------------
box reached target
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 629       |
|    iterations           | 1981      |
|    time_elapsed         | 6442      |
|    total_timesteps      | 4057088   |
| train/                  |           |
|    approx_kl            | 0.4004879 |
|    clip_fraction        | 0.458     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.0948    |
|    explained_variance   | 0.306     |
|    learning_rate        | 0.00121   |
|    loss                 | 0.0227    |
|    n_updates            | 19800     |
|    policy_gradient_loss | 0.00383   |
|    std                  | 0.231     |
|    value_loss           | 0.0219    |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 629        |
|    iterations           | 1982       |
|    time_elapsed         | 6445       |
|    total_timesteps      | 4059136    |
| train/                  |            |
|    approx_kl            | 0.18330792 |
|    clip_fraction        | 0.425      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.132      |
|    explained_variance   | 0.849      |
|    learning_rate        | 0.00121    |
|    loss                 | -0.024     |
|    n_updates            | 19810      |
|    policy_gradient_loss | 0.00458    |
|    std                  | 0.228      |
|    value_loss           | 0.0165     |
----------------------------------------
box reached target
Eval num_timesteps=4060000, episode_reward=-1.08 +/- 0.17
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1.08      |
| time/                   |            |
|    total_timesteps      | 4060000    |
| train/                  |            |
|    approx_kl            | 0.39683092 |
|    clip_fraction        | 0.481      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.16       |
|    explained_variance   | 0.625      |
|    learning_rate        | 0.00121    |
|    loss                 | 0.0326     |
|    n_updates            | 19820      |
|    policy_gradient_loss | 0.00718    |
|    std                  | 0.221      |
|    value_loss           | 0.00642    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 629     |
|    iterations      | 1983    |
|    time_elapsed    | 6449    |
|    total_timesteps | 4061184 |
--------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 629        |
|    iterations           | 1984       |
|    time_elapsed         | 6452       |
|    total_timesteps      | 4063232    |
| train/                  |            |
|    approx_kl            | 0.16463661 |
|    clip_fraction        | 0.414      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.147      |
|    explained_variance   | 0.67       |
|    learning_rate        | 0.00121    |
|    loss                 | 0.0358     |
|    n_updates            | 19830      |
|    policy_gradient_loss | 0.00467    |
|    std                  | 0.228      |
|    value_loss           | 0.037      |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 629        |
|    iterations           | 1985       |
|    time_elapsed         | 6455       |
|    total_timesteps      | 4065280    |
| train/                  |            |
|    approx_kl            | 0.20598379 |
|    clip_fraction        | 0.445      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.143      |
|    explained_variance   | 0.914      |
|    learning_rate        | 0.00121    |
|    loss                 | 0.00675    |
|    n_updates            | 19840      |
|    policy_gradient_loss | 0.0138     |
|    std                  | 0.223      |
|    value_loss           | 0.0122     |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 629        |
|    iterations           | 1986       |
|    time_elapsed         | 6458       |
|    total_timesteps      | 4067328    |
| train/                  |            |
|    approx_kl            | 0.13893302 |
|    clip_fraction        | 0.385      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.157      |
|    explained_variance   | 0.722      |
|    learning_rate        | 0.00121    |
|    loss                 | 0.00744    |
|    n_updates            | 19850      |
|    policy_gradient_loss | 0.0113     |
|    std                  | 0.224      |
|    value_loss           | 0.00299    |
----------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 629       |
|    iterations           | 1987      |
|    time_elapsed         | 6461      |
|    total_timesteps      | 4069376   |
| train/                  |           |
|    approx_kl            | 1.3628769 |
|    clip_fraction        | 0.467     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.166     |
|    explained_variance   | 0.879     |
|    learning_rate        | 0.00121   |
|    loss                 | -0.022    |
|    n_updates            | 19860     |
|    policy_gradient_loss | 0.0118    |
|    std                  | 0.219     |
|    value_loss           | 0.011     |
---------------------------------------
Eval num_timesteps=4070000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1         |
| time/                   |            |
|    total_timesteps      | 4070000    |
| train/                  |            |
|    approx_kl            | 0.27254587 |
|    clip_fraction        | 0.426      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.24       |
|    explained_variance   | 0.842      |
|    learning_rate        | 0.00121    |
|    loss                 | 0.0131     |
|    n_updates            | 19870      |
|    policy_gradient_loss | 0.00352    |
|    std                  | 0.213      |
|    value_loss           | 0.0248     |
----------------------------------------
box reached target
--------------------------------
| time/              |         |
|    fps             | 629     |
|    iterations      | 1988    |
|    time_elapsed    | 6465    |
|    total_timesteps | 4071424 |
--------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 629        |
|    iterations           | 1989       |
|    time_elapsed         | 6468       |
|    total_timesteps      | 4073472    |
| train/                  |            |
|    approx_kl            | 0.21863094 |
|    clip_fraction        | 0.426      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.25       |
|    explained_variance   | 0.739      |
|    learning_rate        | 0.00121    |
|    loss                 | -0.00508   |
|    n_updates            | 19880      |
|    policy_gradient_loss | 0.0203     |
|    std                  | 0.215      |
|    value_loss           | 0.0103     |
----------------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 629        |
|    iterations           | 1990       |
|    time_elapsed         | 6471       |
|    total_timesteps      | 4075520    |
| train/                  |            |
|    approx_kl            | 0.38171744 |
|    clip_fraction        | 0.468      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.255      |
|    explained_variance   | 0.799      |
|    learning_rate        | 0.00121    |
|    loss                 | 0.0674     |
|    n_updates            | 19890      |
|    policy_gradient_loss | 0.0188     |
|    std                  | 0.215      |
|    value_loss           | 0.0127     |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 629        |
|    iterations           | 1991       |
|    time_elapsed         | 6474       |
|    total_timesteps      | 4077568    |
| train/                  |            |
|    approx_kl            | 0.13960437 |
|    clip_fraction        | 0.434      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.251      |
|    explained_variance   | 0.861      |
|    learning_rate        | 0.00121    |
|    loss                 | 0.106      |
|    n_updates            | 19900      |
|    policy_gradient_loss | 0.0167     |
|    std                  | 0.214      |
|    value_loss           | 0.0116     |
----------------------------------------
box reached target
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 629       |
|    iterations           | 1992      |
|    time_elapsed         | 6477      |
|    total_timesteps      | 4079616   |
| train/                  |           |
|    approx_kl            | 0.2953378 |
|    clip_fraction        | 0.496     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.214     |
|    explained_variance   | 0.883     |
|    learning_rate        | 0.0012    |
|    loss                 | 0.0415    |
|    n_updates            | 19910     |
|    policy_gradient_loss | 0.0103    |
|    std                  | 0.22      |
|    value_loss           | 0.00898   |
---------------------------------------
box reached target
box reached target
Eval num_timesteps=4080000, episode_reward=1.50 +/- 3.07
Episode length: 248.60 +/- 63.53
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 249        |
|    mean_reward          | 1.5        |
| time/                   |            |
|    total_timesteps      | 4080000    |
| train/                  |            |
|    approx_kl            | 0.21746136 |
|    clip_fraction        | 0.439      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.209      |
|    explained_variance   | 0.743      |
|    learning_rate        | 0.0012     |
|    loss                 | 0.0129     |
|    n_updates            | 19920      |
|    policy_gradient_loss | 0.0131     |
|    std                  | 0.218      |
|    value_loss           | 0.0254     |
----------------------------------------
box reached target
--------------------------------
| time/              |         |
|    fps             | 629     |
|    iterations      | 1993    |
|    time_elapsed    | 6481    |
|    total_timesteps | 4081664 |
--------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 629        |
|    iterations           | 1994       |
|    time_elapsed         | 6484       |
|    total_timesteps      | 4083712    |
| train/                  |            |
|    approx_kl            | 0.15885368 |
|    clip_fraction        | 0.427      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.202      |
|    explained_variance   | 0.75       |
|    learning_rate        | 0.0012     |
|    loss                 | -0.0365    |
|    n_updates            | 19930      |
|    policy_gradient_loss | 0.0174     |
|    std                  | 0.22       |
|    value_loss           | 0.0157     |
----------------------------------------
box reached target
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 629       |
|    iterations           | 1995      |
|    time_elapsed         | 6487      |
|    total_timesteps      | 4085760   |
| train/                  |           |
|    approx_kl            | 0.4570357 |
|    clip_fraction        | 0.407     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.217     |
|    explained_variance   | 0.94      |
|    learning_rate        | 0.0012    |
|    loss                 | -0.0591   |
|    n_updates            | 19940     |
|    policy_gradient_loss | 0.00419   |
|    std                  | 0.219     |
|    value_loss           | 0.0083    |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 629        |
|    iterations           | 1996       |
|    time_elapsed         | 6490       |
|    total_timesteps      | 4087808    |
| train/                  |            |
|    approx_kl            | 0.30402714 |
|    clip_fraction        | 0.439      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.206      |
|    explained_variance   | 0.922      |
|    learning_rate        | 0.0012     |
|    loss                 | -0.00343   |
|    n_updates            | 19950      |
|    policy_gradient_loss | 0.00564    |
|    std                  | 0.219      |
|    value_loss           | 0.0111     |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 629        |
|    iterations           | 1997       |
|    time_elapsed         | 6493       |
|    total_timesteps      | 4089856    |
| train/                  |            |
|    approx_kl            | 0.14389537 |
|    clip_fraction        | 0.399      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.192      |
|    explained_variance   | 0.849      |
|    learning_rate        | 0.0012     |
|    loss                 | -0.0187    |
|    n_updates            | 19960      |
|    policy_gradient_loss | 0.0115     |
|    std                  | 0.223      |
|    value_loss           | 0.00933    |
----------------------------------------
Eval num_timesteps=4090000, episode_reward=-0.62 +/- 0.69
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -0.617     |
| time/                   |            |
|    total_timesteps      | 4090000    |
| train/                  |            |
|    approx_kl            | 0.17148617 |
|    clip_fraction        | 0.426      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.174      |
|    explained_variance   | 0.906      |
|    learning_rate        | 0.0012     |
|    loss                 | -0.0122    |
|    n_updates            | 19970      |
|    policy_gradient_loss | 0.00175    |
|    std                  | 0.222      |
|    value_loss           | 0.00908    |
----------------------------------------
box reached target
--------------------------------
| time/              |         |
|    fps             | 629     |
|    iterations      | 1998    |
|    time_elapsed    | 6497    |
|    total_timesteps | 4091904 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 629        |
|    iterations           | 1999       |
|    time_elapsed         | 6500       |
|    total_timesteps      | 4093952    |
| train/                  |            |
|    approx_kl            | 0.26629907 |
|    clip_fraction        | 0.407      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.186      |
|    explained_variance   | 0.973      |
|    learning_rate        | 0.0012     |
|    loss                 | -0.0188    |
|    n_updates            | 19980      |
|    policy_gradient_loss | 0.0142     |
|    std                  | 0.221      |
|    value_loss           | 0.00321    |
----------------------------------------
box reached target
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 629       |
|    iterations           | 2000      |
|    time_elapsed         | 6503      |
|    total_timesteps      | 4096000   |
| train/                  |           |
|    approx_kl            | 0.6179046 |
|    clip_fraction        | 0.435     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.171     |
|    explained_variance   | 0.921     |
|    learning_rate        | 0.0012    |
|    loss                 | 0.0198    |
|    n_updates            | 19990     |
|    policy_gradient_loss | 0.00383   |
|    std                  | 0.224     |
|    value_loss           | 0.00551   |
---------------------------------------
box reached target
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 629       |
|    iterations           | 2001      |
|    time_elapsed         | 6506      |
|    total_timesteps      | 4098048   |
| train/                  |           |
|    approx_kl            | 0.5232193 |
|    clip_fraction        | 0.461     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.196     |
|    explained_variance   | 0.878     |
|    learning_rate        | 0.0012    |
|    loss                 | -0.0177   |
|    n_updates            | 20000     |
|    policy_gradient_loss | -0.000356 |
|    std                  | 0.217     |
|    value_loss           | 0.00823   |
---------------------------------------
box reached target
box reached target
box reached target
Eval num_timesteps=4100000, episode_reward=0.25 +/- 2.50
Episode length: 276.60 +/- 46.80
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 277       |
|    mean_reward          | 0.248     |
| time/                   |           |
|    total_timesteps      | 4100000   |
| train/                  |           |
|    approx_kl            | 0.3932808 |
|    clip_fraction        | 0.503     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.258     |
|    explained_variance   | 0.801     |
|    learning_rate        | 0.0012    |
|    loss                 | -0.00368  |
|    n_updates            | 20010     |
|    policy_gradient_loss | 0.0319    |
|    std                  | 0.214     |
|    value_loss           | 0.0237    |
---------------------------------------
--------------------------------
| time/              |         |
|    fps             | 629     |
|    iterations      | 2002    |
|    time_elapsed    | 6510    |
|    total_timesteps | 4100096 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 629        |
|    iterations           | 2003       |
|    time_elapsed         | 6513       |
|    total_timesteps      | 4102144    |
| train/                  |            |
|    approx_kl            | 0.14494026 |
|    clip_fraction        | 0.421      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.266      |
|    explained_variance   | 0.926      |
|    learning_rate        | 0.0012     |
|    loss                 | 0.021      |
|    n_updates            | 20020      |
|    policy_gradient_loss | 0.00675    |
|    std                  | 0.216      |
|    value_loss           | 0.00842    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 629        |
|    iterations           | 2004       |
|    time_elapsed         | 6516       |
|    total_timesteps      | 4104192    |
| train/                  |            |
|    approx_kl            | 0.17618477 |
|    clip_fraction        | 0.447      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.247      |
|    explained_variance   | 0.818      |
|    learning_rate        | 0.0012     |
|    loss                 | 0.0372     |
|    n_updates            | 20030      |
|    policy_gradient_loss | 0.0111     |
|    std                  | 0.217      |
|    value_loss           | 0.00896    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 629        |
|    iterations           | 2005       |
|    time_elapsed         | 6519       |
|    total_timesteps      | 4106240    |
| train/                  |            |
|    approx_kl            | 0.26695356 |
|    clip_fraction        | 0.414      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.25       |
|    explained_variance   | 0.862      |
|    learning_rate        | 0.0012     |
|    loss                 | 0.000874   |
|    n_updates            | 20040      |
|    policy_gradient_loss | 0.0235     |
|    std                  | 0.216      |
|    value_loss           | 0.00799    |
----------------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 629        |
|    iterations           | 2006       |
|    time_elapsed         | 6522       |
|    total_timesteps      | 4108288    |
| train/                  |            |
|    approx_kl            | 0.20996116 |
|    clip_fraction        | 0.416      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.205      |
|    explained_variance   | 0.71       |
|    learning_rate        | 0.0012     |
|    loss                 | -0.0276    |
|    n_updates            | 20050      |
|    policy_gradient_loss | 0.00684    |
|    std                  | 0.221      |
|    value_loss           | 0.00249    |
----------------------------------------
Eval num_timesteps=4110000, episode_reward=-0.90 +/- 0.21
Episode length: 300.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 300       |
|    mean_reward          | -0.897    |
| time/                   |           |
|    total_timesteps      | 4110000   |
| train/                  |           |
|    approx_kl            | 0.2635452 |
|    clip_fraction        | 0.451     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.246     |
|    explained_variance   | 0.88      |
|    learning_rate        | 0.0012    |
|    loss                 | 0.00495   |
|    n_updates            | 20060     |
|    policy_gradient_loss | 0.0182    |
|    std                  | 0.212     |
|    value_loss           | 0.00894   |
---------------------------------------
--------------------------------
| time/              |         |
|    fps             | 629     |
|    iterations      | 2007    |
|    time_elapsed    | 6526    |
|    total_timesteps | 4110336 |
--------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 629        |
|    iterations           | 2008       |
|    time_elapsed         | 6529       |
|    total_timesteps      | 4112384    |
| train/                  |            |
|    approx_kl            | 0.45755702 |
|    clip_fraction        | 0.437      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.318      |
|    explained_variance   | 0.715      |
|    learning_rate        | 0.0012     |
|    loss                 | -0.0766    |
|    n_updates            | 20070      |
|    policy_gradient_loss | -0.0107    |
|    std                  | 0.206      |
|    value_loss           | 0.00718    |
----------------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 629        |
|    iterations           | 2009       |
|    time_elapsed         | 6533       |
|    total_timesteps      | 4114432    |
| train/                  |            |
|    approx_kl            | 0.27387363 |
|    clip_fraction        | 0.485      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.343      |
|    explained_variance   | 0.851      |
|    learning_rate        | 0.0012     |
|    loss                 | 0.0314     |
|    n_updates            | 20080      |
|    policy_gradient_loss | 0.017      |
|    std                  | 0.203      |
|    value_loss           | 0.0535     |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 629        |
|    iterations           | 2010       |
|    time_elapsed         | 6536       |
|    total_timesteps      | 4116480    |
| train/                  |            |
|    approx_kl            | 0.84964776 |
|    clip_fraction        | 0.526      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.359      |
|    explained_variance   | 0.699      |
|    learning_rate        | 0.0012     |
|    loss                 | 0.0764     |
|    n_updates            | 20090      |
|    policy_gradient_loss | 0.0225     |
|    std                  | 0.202      |
|    value_loss           | 0.0349     |
----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 629       |
|    iterations           | 2011      |
|    time_elapsed         | 6539      |
|    total_timesteps      | 4118528   |
| train/                  |           |
|    approx_kl            | 0.3165221 |
|    clip_fraction        | 0.468     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.338     |
|    explained_variance   | 0.836     |
|    learning_rate        | 0.0012    |
|    loss                 | -0.00803  |
|    n_updates            | 20100     |
|    policy_gradient_loss | 0.0132    |
|    std                  | 0.206     |
|    value_loss           | 0.01      |
---------------------------------------
Eval num_timesteps=4120000, episode_reward=-0.88 +/- 0.23
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -0.883     |
| time/                   |            |
|    total_timesteps      | 4120000    |
| train/                  |            |
|    approx_kl            | 0.12796587 |
|    clip_fraction        | 0.387      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.299      |
|    explained_variance   | 0.85       |
|    learning_rate        | 0.0012     |
|    loss                 | -0.0137    |
|    n_updates            | 20110      |
|    policy_gradient_loss | 0.0078     |
|    std                  | 0.21       |
|    value_loss           | 0.00988    |
----------------------------------------
box reached target
--------------------------------
| time/              |         |
|    fps             | 629     |
|    iterations      | 2012    |
|    time_elapsed    | 6543    |
|    total_timesteps | 4120576 |
--------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 629        |
|    iterations           | 2013       |
|    time_elapsed         | 6546       |
|    total_timesteps      | 4122624    |
| train/                  |            |
|    approx_kl            | 0.53384686 |
|    clip_fraction        | 0.46       |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.312      |
|    explained_variance   | 0.906      |
|    learning_rate        | 0.0012     |
|    loss                 | -0.0174    |
|    n_updates            | 20120      |
|    policy_gradient_loss | 0.00414    |
|    std                  | 0.204      |
|    value_loss           | 0.0085     |
----------------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 629        |
|    iterations           | 2014       |
|    time_elapsed         | 6549       |
|    total_timesteps      | 4124672    |
| train/                  |            |
|    approx_kl            | 0.16233897 |
|    clip_fraction        | 0.433      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.327      |
|    explained_variance   | 0.815      |
|    learning_rate        | 0.0012     |
|    loss                 | 0.139      |
|    n_updates            | 20130      |
|    policy_gradient_loss | 0.0214     |
|    std                  | 0.206      |
|    value_loss           | 0.0105     |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 629        |
|    iterations           | 2015       |
|    time_elapsed         | 6552       |
|    total_timesteps      | 4126720    |
| train/                  |            |
|    approx_kl            | 0.34366655 |
|    clip_fraction        | 0.443      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.323      |
|    explained_variance   | 0.836      |
|    learning_rate        | 0.0012     |
|    loss                 | 0.00414    |
|    n_updates            | 20140      |
|    policy_gradient_loss | 0.0121     |
|    std                  | 0.204      |
|    value_loss           | 0.0103     |
----------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 629       |
|    iterations           | 2016      |
|    time_elapsed         | 6555      |
|    total_timesteps      | 4128768   |
| train/                  |           |
|    approx_kl            | 0.3338441 |
|    clip_fraction        | 0.435     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.332     |
|    explained_variance   | 0.93      |
|    learning_rate        | 0.0012    |
|    loss                 | 0.0357    |
|    n_updates            | 20150     |
|    policy_gradient_loss | 0.0308    |
|    std                  | 0.205     |
|    value_loss           | 0.00583   |
---------------------------------------
box reached target
box reached target
Eval num_timesteps=4130000, episode_reward=-0.65 +/- 0.70
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -0.648     |
| time/                   |            |
|    total_timesteps      | 4130000    |
| train/                  |            |
|    approx_kl            | 0.40899938 |
|    clip_fraction        | 0.479      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.26       |
|    explained_variance   | 0.885      |
|    learning_rate        | 0.00119    |
|    loss                 | -0.0142    |
|    n_updates            | 20160      |
|    policy_gradient_loss | 0.0106     |
|    std                  | 0.216      |
|    value_loss           | 0.00911    |
----------------------------------------
box reached target
box reached target
--------------------------------
| time/              |         |
|    fps             | 629     |
|    iterations      | 2017    |
|    time_elapsed    | 6559    |
|    total_timesteps | 4130816 |
--------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 629       |
|    iterations           | 2018      |
|    time_elapsed         | 6562      |
|    total_timesteps      | 4132864   |
| train/                  |           |
|    approx_kl            | 0.8339088 |
|    clip_fraction        | 0.496     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.246     |
|    explained_variance   | 0.898     |
|    learning_rate        | 0.00119   |
|    loss                 | -0.0305   |
|    n_updates            | 20170     |
|    policy_gradient_loss | 0.0161    |
|    std                  | 0.213     |
|    value_loss           | 0.0164    |
---------------------------------------
box reached target
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 629        |
|    iterations           | 2019       |
|    time_elapsed         | 6565       |
|    total_timesteps      | 4134912    |
| train/                  |            |
|    approx_kl            | 0.14929989 |
|    clip_fraction        | 0.417      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.171      |
|    explained_variance   | 0.8        |
|    learning_rate        | 0.00119    |
|    loss                 | 0.0057     |
|    n_updates            | 20180      |
|    policy_gradient_loss | 0.017      |
|    std                  | 0.227      |
|    value_loss           | 0.0173     |
----------------------------------------
box reached target
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 629       |
|    iterations           | 2020      |
|    time_elapsed         | 6568      |
|    total_timesteps      | 4136960   |
| train/                  |           |
|    approx_kl            | 0.2771388 |
|    clip_fraction        | 0.45      |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.102     |
|    explained_variance   | 0.915     |
|    learning_rate        | 0.00119   |
|    loss                 | -0.0322   |
|    n_updates            | 20190     |
|    policy_gradient_loss | 0.00457   |
|    std                  | 0.232     |
|    value_loss           | 0.0185    |
---------------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 629        |
|    iterations           | 2021       |
|    time_elapsed         | 6571       |
|    total_timesteps      | 4139008    |
| train/                  |            |
|    approx_kl            | 0.11987285 |
|    clip_fraction        | 0.428      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.0657     |
|    explained_variance   | 0.892      |
|    learning_rate        | 0.00119    |
|    loss                 | -0.0402    |
|    n_updates            | 20200      |
|    policy_gradient_loss | 0.0134     |
|    std                  | 0.236      |
|    value_loss           | 0.0129     |
----------------------------------------
Eval num_timesteps=4140000, episode_reward=-0.83 +/- 0.35
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -0.826     |
| time/                   |            |
|    total_timesteps      | 4140000    |
| train/                  |            |
|    approx_kl            | 0.19720082 |
|    clip_fraction        | 0.435      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.0199     |
|    explained_variance   | 0.819      |
|    learning_rate        | 0.00119    |
|    loss                 | 0.000979   |
|    n_updates            | 20210      |
|    policy_gradient_loss | 0.0115     |
|    std                  | 0.239      |
|    value_loss           | 0.0212     |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 629     |
|    iterations      | 2022    |
|    time_elapsed    | 6575    |
|    total_timesteps | 4141056 |
--------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 629       |
|    iterations           | 2023      |
|    time_elapsed         | 6578      |
|    total_timesteps      | 4143104   |
| train/                  |           |
|    approx_kl            | 1.2630832 |
|    clip_fraction        | 0.466     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.0133    |
|    explained_variance   | 0.84      |
|    learning_rate        | 0.00119   |
|    loss                 | -0.0296   |
|    n_updates            | 20220     |
|    policy_gradient_loss | 0.0159    |
|    std                  | 0.233     |
|    value_loss           | 0.019     |
---------------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 629        |
|    iterations           | 2024       |
|    time_elapsed         | 6581       |
|    total_timesteps      | 4145152    |
| train/                  |            |
|    approx_kl            | 0.27207172 |
|    clip_fraction        | 0.425      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.0591     |
|    explained_variance   | 0.745      |
|    learning_rate        | 0.00119    |
|    loss                 | -0.0337    |
|    n_updates            | 20230      |
|    policy_gradient_loss | 0.00321    |
|    std                  | 0.237      |
|    value_loss           | 0.00801    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 629        |
|    iterations           | 2025       |
|    time_elapsed         | 6584       |
|    total_timesteps      | 4147200    |
| train/                  |            |
|    approx_kl            | 0.50177586 |
|    clip_fraction        | 0.465      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.0436     |
|    explained_variance   | 0.936      |
|    learning_rate        | 0.00119    |
|    loss                 | 0.00738    |
|    n_updates            | 20240      |
|    policy_gradient_loss | 0.00518    |
|    std                  | 0.237      |
|    value_loss           | 0.00757    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 629        |
|    iterations           | 2026       |
|    time_elapsed         | 6587       |
|    total_timesteps      | 4149248    |
| train/                  |            |
|    approx_kl            | 0.20074856 |
|    clip_fraction        | 0.395      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.0241     |
|    explained_variance   | -0.0957    |
|    learning_rate        | 0.00119    |
|    loss                 | 0.0747     |
|    n_updates            | 20250      |
|    policy_gradient_loss | 0.0137     |
|    std                  | 0.239      |
|    value_loss           | 0.00171    |
----------------------------------------
box reached target
Eval num_timesteps=4150000, episode_reward=0.59 +/- 2.44
Episode length: 276.20 +/- 47.60
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 276       |
|    mean_reward          | 0.591     |
| time/                   |           |
|    total_timesteps      | 4150000   |
| train/                  |           |
|    approx_kl            | 0.2891933 |
|    clip_fraction        | 0.345     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.028     |
|    explained_variance   | 0.525     |
|    learning_rate        | 0.00119   |
|    loss                 | 0.02      |
|    n_updates            | 20260     |
|    policy_gradient_loss | -0.00466  |
|    std                  | 0.237     |
|    value_loss           | 0.00121   |
---------------------------------------
box reached target
--------------------------------
| time/              |         |
|    fps             | 629     |
|    iterations      | 2027    |
|    time_elapsed    | 6591    |
|    total_timesteps | 4151296 |
--------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 629        |
|    iterations           | 2028       |
|    time_elapsed         | 6594       |
|    total_timesteps      | 4153344    |
| train/                  |            |
|    approx_kl            | 0.12353268 |
|    clip_fraction        | 0.423      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.034      |
|    explained_variance   | 0.819      |
|    learning_rate        | 0.00119    |
|    loss                 | 0.0148     |
|    n_updates            | 20270      |
|    policy_gradient_loss | 0.00379    |
|    std                  | 0.239      |
|    value_loss           | 0.0116     |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 629        |
|    iterations           | 2029       |
|    time_elapsed         | 6597       |
|    total_timesteps      | 4155392    |
| train/                  |            |
|    approx_kl            | 0.25779498 |
|    clip_fraction        | 0.434      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.00615   |
|    explained_variance   | 0.818      |
|    learning_rate        | 0.00119    |
|    loss                 | -0.0226    |
|    n_updates            | 20280      |
|    policy_gradient_loss | 0.0026     |
|    std                  | 0.244      |
|    value_loss           | 0.0155     |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 629        |
|    iterations           | 2030       |
|    time_elapsed         | 6600       |
|    total_timesteps      | 4157440    |
| train/                  |            |
|    approx_kl            | 0.24453092 |
|    clip_fraction        | 0.403      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.000574   |
|    explained_variance   | 0.784      |
|    learning_rate        | 0.00119    |
|    loss                 | -0.0179    |
|    n_updates            | 20290      |
|    policy_gradient_loss | 0.00106    |
|    std                  | 0.24       |
|    value_loss           | 0.00574    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 629        |
|    iterations           | 2031       |
|    time_elapsed         | 6603       |
|    total_timesteps      | 4159488    |
| train/                  |            |
|    approx_kl            | 0.16395897 |
|    clip_fraction        | 0.402      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.0195     |
|    explained_variance   | 0.74       |
|    learning_rate        | 0.00119    |
|    loss                 | -0.0227    |
|    n_updates            | 20300      |
|    policy_gradient_loss | 0.00591    |
|    std                  | 0.242      |
|    value_loss           | 0.0143     |
----------------------------------------
Eval num_timesteps=4160000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1         |
| time/                   |            |
|    total_timesteps      | 4160000    |
| train/                  |            |
|    approx_kl            | 0.23357514 |
|    clip_fraction        | 0.41       |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.0131    |
|    explained_variance   | 0.0032     |
|    learning_rate        | 0.00119    |
|    loss                 | 0.0366     |
|    n_updates            | 20310      |
|    policy_gradient_loss | 0.00639    |
|    std                  | 0.243      |
|    value_loss           | 0.00226    |
----------------------------------------
box reached target
--------------------------------
| time/              |         |
|    fps             | 629     |
|    iterations      | 2032    |
|    time_elapsed    | 6607    |
|    total_timesteps | 4161536 |
--------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 629        |
|    iterations           | 2033       |
|    time_elapsed         | 6610       |
|    total_timesteps      | 4163584    |
| train/                  |            |
|    approx_kl            | 0.24472772 |
|    clip_fraction        | 0.402      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.0396    |
|    explained_variance   | 0.569      |
|    learning_rate        | 0.00119    |
|    loss                 | -0.0278    |
|    n_updates            | 20320      |
|    policy_gradient_loss | -0.000957  |
|    std                  | 0.248      |
|    value_loss           | 0.0448     |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 629        |
|    iterations           | 2034       |
|    time_elapsed         | 6613       |
|    total_timesteps      | 4165632    |
| train/                  |            |
|    approx_kl            | 0.28082255 |
|    clip_fraction        | 0.427      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.0212    |
|    explained_variance   | 0.494      |
|    learning_rate        | 0.00119    |
|    loss                 | -0.0339    |
|    n_updates            | 20330      |
|    policy_gradient_loss | 0.00725    |
|    std                  | 0.243      |
|    value_loss           | 0.0676     |
----------------------------------------
box reached target
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 629       |
|    iterations           | 2035      |
|    time_elapsed         | 6616      |
|    total_timesteps      | 4167680   |
| train/                  |           |
|    approx_kl            | 1.0754455 |
|    clip_fraction        | 0.482     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.0027    |
|    explained_variance   | 0.829     |
|    learning_rate        | 0.00119   |
|    loss                 | 0.0343    |
|    n_updates            | 20340     |
|    policy_gradient_loss | 0.0198    |
|    std                  | 0.24      |
|    value_loss           | 0.018     |
---------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 629       |
|    iterations           | 2036      |
|    time_elapsed         | 6619      |
|    total_timesteps      | 4169728   |
| train/                  |           |
|    approx_kl            | 0.3228157 |
|    clip_fraction        | 0.457     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.0521    |
|    explained_variance   | 0.65      |
|    learning_rate        | 0.00119   |
|    loss                 | 0.0211    |
|    n_updates            | 20350     |
|    policy_gradient_loss | 0.00906   |
|    std                  | 0.234     |
|    value_loss           | 0.0541    |
---------------------------------------
box reached target
Eval num_timesteps=4170000, episode_reward=0.33 +/- 2.51
Episode length: 288.20 +/- 23.60
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 288        |
|    mean_reward          | 0.327      |
| time/                   |            |
|    total_timesteps      | 4170000    |
| train/                  |            |
|    approx_kl            | 0.12841979 |
|    clip_fraction        | 0.427      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.0904     |
|    explained_variance   | 0.644      |
|    learning_rate        | 0.00119    |
|    loss                 | 0.0414     |
|    n_updates            | 20360      |
|    policy_gradient_loss | 0.015      |
|    std                  | 0.234      |
|    value_loss           | 0.0159     |
----------------------------------------
box reached target
box reached target
box reached target
--------------------------------
| time/              |         |
|    fps             | 629     |
|    iterations      | 2037    |
|    time_elapsed    | 6623    |
|    total_timesteps | 4171776 |
--------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 629       |
|    iterations           | 2038      |
|    time_elapsed         | 6626      |
|    total_timesteps      | 4173824   |
| train/                  |           |
|    approx_kl            | 0.4512428 |
|    clip_fraction        | 0.424     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.11      |
|    explained_variance   | 0.247     |
|    learning_rate        | 0.00119   |
|    loss                 | -0.0278   |
|    n_updates            | 20370     |
|    policy_gradient_loss | 0.0195    |
|    std                  | 0.229     |
|    value_loss           | 0.0362    |
---------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 629        |
|    iterations           | 2039       |
|    time_elapsed         | 6629       |
|    total_timesteps      | 4175872    |
| train/                  |            |
|    approx_kl            | 0.11812028 |
|    clip_fraction        | 0.415      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.118      |
|    explained_variance   | 0.466      |
|    learning_rate        | 0.00119    |
|    loss                 | 0.0513     |
|    n_updates            | 20380      |
|    policy_gradient_loss | 0.00882    |
|    std                  | 0.229      |
|    value_loss           | 0.0101     |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 629        |
|    iterations           | 2040       |
|    time_elapsed         | 6632       |
|    total_timesteps      | 4177920    |
| train/                  |            |
|    approx_kl            | 0.19754916 |
|    clip_fraction        | 0.411      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.113      |
|    explained_variance   | 0.41       |
|    learning_rate        | 0.00119    |
|    loss                 | -0.00596   |
|    n_updates            | 20390      |
|    policy_gradient_loss | 0.013      |
|    std                  | 0.228      |
|    value_loss           | 0.0188     |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 629        |
|    iterations           | 2041       |
|    time_elapsed         | 6635       |
|    total_timesteps      | 4179968    |
| train/                  |            |
|    approx_kl            | 0.21151529 |
|    clip_fraction        | 0.443      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.117      |
|    explained_variance   | 0.639      |
|    learning_rate        | 0.00119    |
|    loss                 | -0.0392    |
|    n_updates            | 20400      |
|    policy_gradient_loss | -0.000848  |
|    std                  | 0.23       |
|    value_loss           | 0.0123     |
----------------------------------------
Eval num_timesteps=4180000, episode_reward=-0.73 +/- 0.40
Episode length: 300.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 300       |
|    mean_reward          | -0.732    |
| time/                   |           |
|    total_timesteps      | 4180000   |
| train/                  |           |
|    approx_kl            | 0.3954838 |
|    clip_fraction        | 0.448     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.113     |
|    explained_variance   | 0.507     |
|    learning_rate        | 0.00118   |
|    loss                 | 0.00564   |
|    n_updates            | 20410     |
|    policy_gradient_loss | 0.00736   |
|    std                  | 0.23      |
|    value_loss           | 0.00705   |
---------------------------------------
--------------------------------
| time/              |         |
|    fps             | 629     |
|    iterations      | 2042    |
|    time_elapsed    | 6639    |
|    total_timesteps | 4182016 |
--------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 629       |
|    iterations           | 2043      |
|    time_elapsed         | 6642      |
|    total_timesteps      | 4184064   |
| train/                  |           |
|    approx_kl            | 0.2207137 |
|    clip_fraction        | 0.465     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.164     |
|    explained_variance   | -0.33     |
|    learning_rate        | 0.00118   |
|    loss                 | 0.0179    |
|    n_updates            | 20420     |
|    policy_gradient_loss | -0.000946 |
|    std                  | 0.22      |
|    value_loss           | 0.00658   |
---------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 629       |
|    iterations           | 2044      |
|    time_elapsed         | 6645      |
|    total_timesteps      | 4186112   |
| train/                  |           |
|    approx_kl            | 0.1863843 |
|    clip_fraction        | 0.497     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.172     |
|    explained_variance   | 0.652     |
|    learning_rate        | 0.00118   |
|    loss                 | 0.0986    |
|    n_updates            | 20430     |
|    policy_gradient_loss | 0.0302    |
|    std                  | 0.224     |
|    value_loss           | 0.0263    |
---------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 629        |
|    iterations           | 2045       |
|    time_elapsed         | 6648       |
|    total_timesteps      | 4188160    |
| train/                  |            |
|    approx_kl            | 0.12071044 |
|    clip_fraction        | 0.366      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.172      |
|    explained_variance   | 0.699      |
|    learning_rate        | 0.00118    |
|    loss                 | 0.00747    |
|    n_updates            | 20440      |
|    policy_gradient_loss | 0.0115     |
|    std                  | 0.223      |
|    value_loss           | 0.0181     |
----------------------------------------
box reached target
box reached target
Eval num_timesteps=4190000, episode_reward=0.24 +/- 2.48
Episode length: 281.60 +/- 36.80
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 282        |
|    mean_reward          | 0.238      |
| time/                   |            |
|    total_timesteps      | 4190000    |
| train/                  |            |
|    approx_kl            | 0.29781568 |
|    clip_fraction        | 0.429      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.214      |
|    explained_variance   | 0.799      |
|    learning_rate        | 0.00118    |
|    loss                 | -0.0164    |
|    n_updates            | 20450      |
|    policy_gradient_loss | 0.0109     |
|    std                  | 0.214      |
|    value_loss           | 0.00586    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 629     |
|    iterations      | 2046    |
|    time_elapsed    | 6652    |
|    total_timesteps | 4190208 |
--------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 629        |
|    iterations           | 2047       |
|    time_elapsed         | 6655       |
|    total_timesteps      | 4192256    |
| train/                  |            |
|    approx_kl            | 0.33484054 |
|    clip_fraction        | 0.444      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.277      |
|    explained_variance   | 0.841      |
|    learning_rate        | 0.00118    |
|    loss                 | 0.0461     |
|    n_updates            | 20460      |
|    policy_gradient_loss | 0.00568    |
|    std                  | 0.207      |
|    value_loss           | 0.0101     |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 629        |
|    iterations           | 2048       |
|    time_elapsed         | 6658       |
|    total_timesteps      | 4194304    |
| train/                  |            |
|    approx_kl            | 0.25159293 |
|    clip_fraction        | 0.446      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.32       |
|    explained_variance   | 0.725      |
|    learning_rate        | 0.00118    |
|    loss                 | -0.00394   |
|    n_updates            | 20470      |
|    policy_gradient_loss | 0.00772    |
|    std                  | 0.205      |
|    value_loss           | 0.0201     |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 629        |
|    iterations           | 2049       |
|    time_elapsed         | 6662       |
|    total_timesteps      | 4196352    |
| train/                  |            |
|    approx_kl            | 0.39219454 |
|    clip_fraction        | 0.435      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.308      |
|    explained_variance   | 0.965      |
|    learning_rate        | 0.00118    |
|    loss                 | 0.00956    |
|    n_updates            | 20480      |
|    policy_gradient_loss | 0.0191     |
|    std                  | 0.21       |
|    value_loss           | 0.00312    |
----------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 629       |
|    iterations           | 2050      |
|    time_elapsed         | 6665      |
|    total_timesteps      | 4198400   |
| train/                  |           |
|    approx_kl            | 0.6180375 |
|    clip_fraction        | 0.443     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.294     |
|    explained_variance   | 0.687     |
|    learning_rate        | 0.00118   |
|    loss                 | -0.00521  |
|    n_updates            | 20490     |
|    policy_gradient_loss | 0.00776   |
|    std                  | 0.21      |
|    value_loss           | 0.014     |
---------------------------------------
box reached target
Eval num_timesteps=4200000, episode_reward=-0.56 +/- 0.57
Episode length: 300.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 300       |
|    mean_reward          | -0.562    |
| time/                   |           |
|    total_timesteps      | 4200000   |
| train/                  |           |
|    approx_kl            | 0.3016318 |
|    clip_fraction        | 0.485     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.24      |
|    explained_variance   | 0.786     |
|    learning_rate        | 0.00118   |
|    loss                 | -0.0416   |
|    n_updates            | 20500     |
|    policy_gradient_loss | 0.0223    |
|    std                  | 0.217     |
|    value_loss           | 0.012     |
---------------------------------------
--------------------------------
| time/              |         |
|    fps             | 629     |
|    iterations      | 2051    |
|    time_elapsed    | 6669    |
|    total_timesteps | 4200448 |
--------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 629        |
|    iterations           | 2052       |
|    time_elapsed         | 6672       |
|    total_timesteps      | 4202496    |
| train/                  |            |
|    approx_kl            | 0.12616912 |
|    clip_fraction        | 0.421      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.186      |
|    explained_variance   | 0.797      |
|    learning_rate        | 0.00118    |
|    loss                 | 0.013      |
|    n_updates            | 20510      |
|    policy_gradient_loss | 0.0121     |
|    std                  | 0.222      |
|    value_loss           | 0.0111     |
----------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 629       |
|    iterations           | 2053      |
|    time_elapsed         | 6675      |
|    total_timesteps      | 4204544   |
| train/                  |           |
|    approx_kl            | 0.1916782 |
|    clip_fraction        | 0.446     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.195     |
|    explained_variance   | 0.783     |
|    learning_rate        | 0.00118   |
|    loss                 | 0.0328    |
|    n_updates            | 20520     |
|    policy_gradient_loss | 0.00636   |
|    std                  | 0.22      |
|    value_loss           | 0.0267    |
---------------------------------------
--------------------------------------
| time/                   |          |
|    fps                  | 629      |
|    iterations           | 2054     |
|    time_elapsed         | 6678     |
|    total_timesteps      | 4206592  |
| train/                  |          |
|    approx_kl            | 0.202971 |
|    clip_fraction        | 0.43     |
|    clip_range           | 0.2      |
|    entropy_loss         | 0.195    |
|    explained_variance   | 0.741    |
|    learning_rate        | 0.00118  |
|    loss                 | -0.0298  |
|    n_updates            | 20530    |
|    policy_gradient_loss | 0.00837  |
|    std                  | 0.219    |
|    value_loss           | 0.00978  |
--------------------------------------
box reached target
box reached target
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 629       |
|    iterations           | 2055      |
|    time_elapsed         | 6681      |
|    total_timesteps      | 4208640   |
| train/                  |           |
|    approx_kl            | 0.4391376 |
|    clip_fraction        | 0.418     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.238     |
|    explained_variance   | 0.703     |
|    learning_rate        | 0.00118   |
|    loss                 | 0.00201   |
|    n_updates            | 20540     |
|    policy_gradient_loss | -0.00313  |
|    std                  | 0.214     |
|    value_loss           | 0.00635   |
---------------------------------------
Eval num_timesteps=4210000, episode_reward=-0.72 +/- 0.55
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -0.725     |
| time/                   |            |
|    total_timesteps      | 4210000    |
| train/                  |            |
|    approx_kl            | 0.14762357 |
|    clip_fraction        | 0.404      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.275      |
|    explained_variance   | 0.793      |
|    learning_rate        | 0.00118    |
|    loss                 | -0.0113    |
|    n_updates            | 20550      |
|    policy_gradient_loss | -0.000123  |
|    std                  | 0.211      |
|    value_loss           | 0.0329     |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 629     |
|    iterations      | 2056    |
|    time_elapsed    | 6685    |
|    total_timesteps | 4210688 |
--------------------------------
box reached target
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 629       |
|    iterations           | 2057      |
|    time_elapsed         | 6688      |
|    total_timesteps      | 4212736   |
| train/                  |           |
|    approx_kl            | 0.5207092 |
|    clip_fraction        | 0.406     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.297     |
|    explained_variance   | 0.863     |
|    learning_rate        | 0.00118   |
|    loss                 | -0.0127   |
|    n_updates            | 20560     |
|    policy_gradient_loss | 0.00571   |
|    std                  | 0.21      |
|    value_loss           | 0.00828   |
---------------------------------------
box reached target
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 629       |
|    iterations           | 2058      |
|    time_elapsed         | 6691      |
|    total_timesteps      | 4214784   |
| train/                  |           |
|    approx_kl            | 1.6820166 |
|    clip_fraction        | 0.446     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.325     |
|    explained_variance   | 0.947     |
|    learning_rate        | 0.00118   |
|    loss                 | 0.00363   |
|    n_updates            | 20570     |
|    policy_gradient_loss | 0.091     |
|    std                  | 0.208     |
|    value_loss           | 0.00886   |
---------------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 629        |
|    iterations           | 2059       |
|    time_elapsed         | 6694       |
|    total_timesteps      | 4216832    |
| train/                  |            |
|    approx_kl            | 0.36662397 |
|    clip_fraction        | 0.458      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.355      |
|    explained_variance   | 0.802      |
|    learning_rate        | 0.00118    |
|    loss                 | 0.0431     |
|    n_updates            | 20580      |
|    policy_gradient_loss | 0.0207     |
|    std                  | 0.202      |
|    value_loss           | 0.0151     |
----------------------------------------
box reached target
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 629        |
|    iterations           | 2060       |
|    time_elapsed         | 6697       |
|    total_timesteps      | 4218880    |
| train/                  |            |
|    approx_kl            | 0.32602718 |
|    clip_fraction        | 0.472      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.382      |
|    explained_variance   | 0.836      |
|    learning_rate        | 0.00118    |
|    loss                 | -0.0385    |
|    n_updates            | 20590      |
|    policy_gradient_loss | 0.0142     |
|    std                  | 0.201      |
|    value_loss           | 0.0169     |
----------------------------------------
Eval num_timesteps=4220000, episode_reward=-0.76 +/- 0.29
Episode length: 300.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 300       |
|    mean_reward          | -0.761    |
| time/                   |           |
|    total_timesteps      | 4220000   |
| train/                  |           |
|    approx_kl            | 0.3422736 |
|    clip_fraction        | 0.482     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.402     |
|    explained_variance   | 0.773     |
|    learning_rate        | 0.00118   |
|    loss                 | -0.0164   |
|    n_updates            | 20600     |
|    policy_gradient_loss | 0.0211    |
|    std                  | 0.198     |
|    value_loss           | 0.0434    |
---------------------------------------
--------------------------------
| time/              |         |
|    fps             | 629     |
|    iterations      | 2061    |
|    time_elapsed    | 6701    |
|    total_timesteps | 4220928 |
--------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 629       |
|    iterations           | 2062      |
|    time_elapsed         | 6704      |
|    total_timesteps      | 4222976   |
| train/                  |           |
|    approx_kl            | 1.0926948 |
|    clip_fraction        | 0.462     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.414     |
|    explained_variance   | 0.623     |
|    learning_rate        | 0.00118   |
|    loss                 | 0.0569    |
|    n_updates            | 20610     |
|    policy_gradient_loss | 0.0272    |
|    std                  | 0.198     |
|    value_loss           | 0.00819   |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 629        |
|    iterations           | 2063       |
|    time_elapsed         | 6707       |
|    total_timesteps      | 4225024    |
| train/                  |            |
|    approx_kl            | 0.47375607 |
|    clip_fraction        | 0.427      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.443      |
|    explained_variance   | 0.69       |
|    learning_rate        | 0.00118    |
|    loss                 | 0.0126     |
|    n_updates            | 20620      |
|    policy_gradient_loss | 0.0228     |
|    std                  | 0.194      |
|    value_loss           | 0.00513    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 629        |
|    iterations           | 2064       |
|    time_elapsed         | 6710       |
|    total_timesteps      | 4227072    |
| train/                  |            |
|    approx_kl            | 0.12503742 |
|    clip_fraction        | 0.408      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.442      |
|    explained_variance   | 0.821      |
|    learning_rate        | 0.00118    |
|    loss                 | 0.0229     |
|    n_updates            | 20630      |
|    policy_gradient_loss | 0.0151     |
|    std                  | 0.198      |
|    value_loss           | 0.0139     |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 629        |
|    iterations           | 2065       |
|    time_elapsed         | 6713       |
|    total_timesteps      | 4229120    |
| train/                  |            |
|    approx_kl            | 0.19895008 |
|    clip_fraction        | 0.434      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.4        |
|    explained_variance   | 0.751      |
|    learning_rate        | 0.00118    |
|    loss                 | 0.0218     |
|    n_updates            | 20640      |
|    policy_gradient_loss | 0.0207     |
|    std                  | 0.203      |
|    value_loss           | 0.00566    |
----------------------------------------
box reached target
Eval num_timesteps=4230000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1         |
| time/                   |            |
|    total_timesteps      | 4230000    |
| train/                  |            |
|    approx_kl            | 0.26793107 |
|    clip_fraction        | 0.449      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.405      |
|    explained_variance   | 0.672      |
|    learning_rate        | 0.00118    |
|    loss                 | 0.0323     |
|    n_updates            | 20650      |
|    policy_gradient_loss | 0.0522     |
|    std                  | 0.2        |
|    value_loss           | 0.0186     |
----------------------------------------
box reached target
box reached target
box reached target
--------------------------------
| time/              |         |
|    fps             | 629     |
|    iterations      | 2066    |
|    time_elapsed    | 6717    |
|    total_timesteps | 4231168 |
--------------------------------
box reached target
box reached target
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 629        |
|    iterations           | 2067       |
|    time_elapsed         | 6720       |
|    total_timesteps      | 4233216    |
| train/                  |            |
|    approx_kl            | 0.21221545 |
|    clip_fraction        | 0.442      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.403      |
|    explained_variance   | 0.805      |
|    learning_rate        | 0.00117    |
|    loss                 | 0.0306     |
|    n_updates            | 20660      |
|    policy_gradient_loss | 0.0164     |
|    std                  | 0.202      |
|    value_loss           | 0.0353     |
----------------------------------------
box reached target
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 629       |
|    iterations           | 2068      |
|    time_elapsed         | 6723      |
|    total_timesteps      | 4235264   |
| train/                  |           |
|    approx_kl            | 0.3748326 |
|    clip_fraction        | 0.469     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.408     |
|    explained_variance   | 0.866     |
|    learning_rate        | 0.00117   |
|    loss                 | 0.0112    |
|    n_updates            | 20670     |
|    policy_gradient_loss | 0.0114    |
|    std                  | 0.199     |
|    value_loss           | 0.0182    |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 629        |
|    iterations           | 2069       |
|    time_elapsed         | 6726       |
|    total_timesteps      | 4237312    |
| train/                  |            |
|    approx_kl            | 0.20221509 |
|    clip_fraction        | 0.453      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.421      |
|    explained_variance   | 0.786      |
|    learning_rate        | 0.00117    |
|    loss                 | 0.00649    |
|    n_updates            | 20680      |
|    policy_gradient_loss | 0.0103     |
|    std                  | 0.203      |
|    value_loss           | 0.0209     |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 629        |
|    iterations           | 2070       |
|    time_elapsed         | 6729       |
|    total_timesteps      | 4239360    |
| train/                  |            |
|    approx_kl            | 0.72008055 |
|    clip_fraction        | 0.438      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.422      |
|    explained_variance   | 0.823      |
|    learning_rate        | 0.00117    |
|    loss                 | -0.0209    |
|    n_updates            | 20690      |
|    policy_gradient_loss | 0.000456   |
|    std                  | 0.199      |
|    value_loss           | 0.00457    |
----------------------------------------
Eval num_timesteps=4240000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
--------------------------------------
| eval/                   |          |
|    mean_ep_length       | 300      |
|    mean_reward          | -1       |
| time/                   |          |
|    total_timesteps      | 4240000  |
| train/                  |          |
|    approx_kl            | 0.244232 |
|    clip_fraction        | 0.45     |
|    clip_range           | 0.2      |
|    entropy_loss         | 0.432    |
|    explained_variance   | 0.662    |
|    learning_rate        | 0.00117  |
|    loss                 | 0.0177   |
|    n_updates            | 20700    |
|    policy_gradient_loss | 0.0172   |
|    std                  | 0.201    |
|    value_loss           | 0.00721  |
--------------------------------------
box reached target
--------------------------------
| time/              |         |
|    fps             | 629     |
|    iterations      | 2071    |
|    time_elapsed    | 6733    |
|    total_timesteps | 4241408 |
--------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 629        |
|    iterations           | 2072       |
|    time_elapsed         | 6736       |
|    total_timesteps      | 4243456    |
| train/                  |            |
|    approx_kl            | 0.23387644 |
|    clip_fraction        | 0.507      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.337      |
|    explained_variance   | 0.846      |
|    learning_rate        | 0.00117    |
|    loss                 | 0.0103     |
|    n_updates            | 20710      |
|    policy_gradient_loss | 0.0182     |
|    std                  | 0.215      |
|    value_loss           | 0.011      |
----------------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 629        |
|    iterations           | 2073       |
|    time_elapsed         | 6739       |
|    total_timesteps      | 4245504    |
| train/                  |            |
|    approx_kl            | 0.24870364 |
|    clip_fraction        | 0.44       |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.288      |
|    explained_variance   | 0.703      |
|    learning_rate        | 0.00117    |
|    loss                 | 0.0186     |
|    n_updates            | 20720      |
|    policy_gradient_loss | 0.0247     |
|    std                  | 0.213      |
|    value_loss           | 0.0183     |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 629        |
|    iterations           | 2074       |
|    time_elapsed         | 6742       |
|    total_timesteps      | 4247552    |
| train/                  |            |
|    approx_kl            | 0.18265738 |
|    clip_fraction        | 0.382      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.303      |
|    explained_variance   | 0.781      |
|    learning_rate        | 0.00117    |
|    loss                 | 0.0324     |
|    n_updates            | 20730      |
|    policy_gradient_loss | 0.0198     |
|    std                  | 0.214      |
|    value_loss           | 0.0153     |
----------------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 629        |
|    iterations           | 2075       |
|    time_elapsed         | 6745       |
|    total_timesteps      | 4249600    |
| train/                  |            |
|    approx_kl            | 0.37756142 |
|    clip_fraction        | 0.456      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.308      |
|    explained_variance   | 0.689      |
|    learning_rate        | 0.00117    |
|    loss                 | -0.0369    |
|    n_updates            | 20740      |
|    policy_gradient_loss | 0.00841    |
|    std                  | 0.209      |
|    value_loss           | 0.00532    |
----------------------------------------
box reached target
box reached target
Eval num_timesteps=4250000, episode_reward=1.71 +/- 2.84
Episode length: 263.60 +/- 48.70
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 264        |
|    mean_reward          | 1.71       |
| time/                   |            |
|    total_timesteps      | 4250000    |
| train/                  |            |
|    approx_kl            | 0.29140463 |
|    clip_fraction        | 0.445      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.316      |
|    explained_variance   | 0.935      |
|    learning_rate        | 0.00117    |
|    loss                 | 0.0212     |
|    n_updates            | 20750      |
|    policy_gradient_loss | 0.0377     |
|    std                  | 0.212      |
|    value_loss           | 0.0113     |
----------------------------------------
box reached target
box reached target
--------------------------------
| time/              |         |
|    fps             | 629     |
|    iterations      | 2076    |
|    time_elapsed    | 6749    |
|    total_timesteps | 4251648 |
--------------------------------
box reached target
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 629        |
|    iterations           | 2077       |
|    time_elapsed         | 6752       |
|    total_timesteps      | 4253696    |
| train/                  |            |
|    approx_kl            | 0.46133405 |
|    clip_fraction        | 0.472      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.369      |
|    explained_variance   | 0.88       |
|    learning_rate        | 0.00117    |
|    loss                 | -0.0299    |
|    n_updates            | 20760      |
|    policy_gradient_loss | 0.0214     |
|    std                  | 0.202      |
|    value_loss           | 0.0107     |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 629        |
|    iterations           | 2078       |
|    time_elapsed         | 6755       |
|    total_timesteps      | 4255744    |
| train/                  |            |
|    approx_kl            | 0.54887235 |
|    clip_fraction        | 0.484      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.389      |
|    explained_variance   | 0.879      |
|    learning_rate        | 0.00117    |
|    loss                 | 0.00349    |
|    n_updates            | 20770      |
|    policy_gradient_loss | 0.0197     |
|    std                  | 0.204      |
|    value_loss           | 0.0155     |
----------------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 629        |
|    iterations           | 2079       |
|    time_elapsed         | 6758       |
|    total_timesteps      | 4257792    |
| train/                  |            |
|    approx_kl            | 0.13364166 |
|    clip_fraction        | 0.423      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.345      |
|    explained_variance   | 0.789      |
|    learning_rate        | 0.00117    |
|    loss                 | -0.0127    |
|    n_updates            | 20780      |
|    policy_gradient_loss | 0.0112     |
|    std                  | 0.207      |
|    value_loss           | 0.0173     |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 629        |
|    iterations           | 2080       |
|    time_elapsed         | 6761       |
|    total_timesteps      | 4259840    |
| train/                  |            |
|    approx_kl            | 0.33499855 |
|    clip_fraction        | 0.438      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.349      |
|    explained_variance   | 0.943      |
|    learning_rate        | 0.00117    |
|    loss                 | -0.0361    |
|    n_updates            | 20790      |
|    policy_gradient_loss | -0.000299  |
|    std                  | 0.207      |
|    value_loss           | 0.00726    |
----------------------------------------
Eval num_timesteps=4260000, episode_reward=-1.08 +/- 0.16
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1.08      |
| time/                   |            |
|    total_timesteps      | 4260000    |
| train/                  |            |
|    approx_kl            | 0.27152905 |
|    clip_fraction        | 0.413      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.323      |
|    explained_variance   | 0.819      |
|    learning_rate        | 0.00117    |
|    loss                 | -0.0152    |
|    n_updates            | 20800      |
|    policy_gradient_loss | 0.0196     |
|    std                  | 0.209      |
|    value_loss           | 0.0118     |
----------------------------------------
box reached target
--------------------------------
| time/              |         |
|    fps             | 629     |
|    iterations      | 2081    |
|    time_elapsed    | 6765    |
|    total_timesteps | 4261888 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 629        |
|    iterations           | 2082       |
|    time_elapsed         | 6768       |
|    total_timesteps      | 4263936    |
| train/                  |            |
|    approx_kl            | 0.24870649 |
|    clip_fraction        | 0.456      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.343      |
|    explained_variance   | 0.858      |
|    learning_rate        | 0.00117    |
|    loss                 | -0.0266    |
|    n_updates            | 20810      |
|    policy_gradient_loss | 0.0345     |
|    std                  | 0.206      |
|    value_loss           | 0.0141     |
----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 629       |
|    iterations           | 2083      |
|    time_elapsed         | 6771      |
|    total_timesteps      | 4265984   |
| train/                  |           |
|    approx_kl            | 0.5241072 |
|    clip_fraction        | 0.485     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.302     |
|    explained_variance   | 0.799     |
|    learning_rate        | 0.00117   |
|    loss                 | 0.0374    |
|    n_updates            | 20820     |
|    policy_gradient_loss | 0.0337    |
|    std                  | 0.214     |
|    value_loss           | 0.00765   |
---------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 629       |
|    iterations           | 2084      |
|    time_elapsed         | 6774      |
|    total_timesteps      | 4268032   |
| train/                  |           |
|    approx_kl            | 0.2291672 |
|    clip_fraction        | 0.438     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.282     |
|    explained_variance   | 0.832     |
|    learning_rate        | 0.00117   |
|    loss                 | 0.0206    |
|    n_updates            | 20830     |
|    policy_gradient_loss | 0.00871   |
|    std                  | 0.215     |
|    value_loss           | 0.00385   |
---------------------------------------
box reached target
box reached target
box reached target
box reached target
box reached target
Eval num_timesteps=4270000, episode_reward=0.26 +/- 2.52
Episode length: 285.20 +/- 29.60
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 285        |
|    mean_reward          | 0.261      |
| time/                   |            |
|    total_timesteps      | 4270000    |
| train/                  |            |
|    approx_kl            | 0.22863741 |
|    clip_fraction        | 0.475      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.252      |
|    explained_variance   | 0.737      |
|    learning_rate        | 0.00117    |
|    loss                 | 0.0135     |
|    n_updates            | 20840      |
|    policy_gradient_loss | 0.0102     |
|    std                  | 0.217      |
|    value_loss           | 0.0398     |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 629     |
|    iterations      | 2085    |
|    time_elapsed    | 6778    |
|    total_timesteps | 4270080 |
--------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 629        |
|    iterations           | 2086       |
|    time_elapsed         | 6781       |
|    total_timesteps      | 4272128    |
| train/                  |            |
|    approx_kl            | 0.14132243 |
|    clip_fraction        | 0.435      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.241      |
|    explained_variance   | 0.662      |
|    learning_rate        | 0.00117    |
|    loss                 | -0.03      |
|    n_updates            | 20850      |
|    policy_gradient_loss | 0.00752    |
|    std                  | 0.219      |
|    value_loss           | 0.0469     |
----------------------------------------
box reached target
box reached target
--------------------------------------
| time/                   |          |
|    fps                  | 629      |
|    iterations           | 2087     |
|    time_elapsed         | 6784     |
|    total_timesteps      | 4274176  |
| train/                  |          |
|    approx_kl            | 0.157951 |
|    clip_fraction        | 0.42     |
|    clip_range           | 0.2      |
|    entropy_loss         | 0.2      |
|    explained_variance   | 0.821    |
|    learning_rate        | 0.00117  |
|    loss                 | -0.031   |
|    n_updates            | 20860    |
|    policy_gradient_loss | 0.0332   |
|    std                  | 0.227    |
|    value_loss           | 0.0211   |
--------------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 629        |
|    iterations           | 2088       |
|    time_elapsed         | 6787       |
|    total_timesteps      | 4276224    |
| train/                  |            |
|    approx_kl            | 0.17074932 |
|    clip_fraction        | 0.396      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.14       |
|    explained_variance   | 0.684      |
|    learning_rate        | 0.00117    |
|    loss                 | -0.0204    |
|    n_updates            | 20870      |
|    policy_gradient_loss | 0.014      |
|    std                  | 0.232      |
|    value_loss           | 0.023      |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 629        |
|    iterations           | 2089       |
|    time_elapsed         | 6790       |
|    total_timesteps      | 4278272    |
| train/                  |            |
|    approx_kl            | 0.21270363 |
|    clip_fraction        | 0.369      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.0635     |
|    explained_variance   | 0.818      |
|    learning_rate        | 0.00117    |
|    loss                 | -0.00191   |
|    n_updates            | 20880      |
|    policy_gradient_loss | 0.0174     |
|    std                  | 0.24       |
|    value_loss           | 0.025      |
----------------------------------------
box reached target
box reached target
box reached target
Eval num_timesteps=4280000, episode_reward=1.47 +/- 3.17
Episode length: 264.00 +/- 50.52
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 264        |
|    mean_reward          | 1.47       |
| time/                   |            |
|    total_timesteps      | 4280000    |
| train/                  |            |
|    approx_kl            | 0.25454783 |
|    clip_fraction        | 0.416      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.0341     |
|    explained_variance   | 0.904      |
|    learning_rate        | 0.00117    |
|    loss                 | -0.0329    |
|    n_updates            | 20890      |
|    policy_gradient_loss | 0.0423     |
|    std                  | 0.241      |
|    value_loss           | 0.00865    |
----------------------------------------
box reached target
--------------------------------
| time/              |         |
|    fps             | 629     |
|    iterations      | 2090    |
|    time_elapsed    | 6794    |
|    total_timesteps | 4280320 |
--------------------------------
box reached target
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 629       |
|    iterations           | 2091      |
|    time_elapsed         | 6797      |
|    total_timesteps      | 4282368   |
| train/                  |           |
|    approx_kl            | 0.1972588 |
|    clip_fraction        | 0.427     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.0089    |
|    explained_variance   | 0.913     |
|    learning_rate        | 0.00117   |
|    loss                 | 0.0108    |
|    n_updates            | 20900     |
|    policy_gradient_loss | 0.00615   |
|    std                  | 0.244     |
|    value_loss           | 0.01      |
---------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 629        |
|    iterations           | 2092       |
|    time_elapsed         | 6800       |
|    total_timesteps      | 4284416    |
| train/                  |            |
|    approx_kl            | 0.13972503 |
|    clip_fraction        | 0.374      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.029     |
|    explained_variance   | 0.827      |
|    learning_rate        | 0.00116    |
|    loss                 | -0.00482   |
|    n_updates            | 20910      |
|    policy_gradient_loss | 0.000883   |
|    std                  | 0.25       |
|    value_loss           | 0.0219     |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 629        |
|    iterations           | 2093       |
|    time_elapsed         | 6803       |
|    total_timesteps      | 4286464    |
| train/                  |            |
|    approx_kl            | 0.39967728 |
|    clip_fraction        | 0.416      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.0321    |
|    explained_variance   | 0.775      |
|    learning_rate        | 0.00116    |
|    loss                 | -0.0108    |
|    n_updates            | 20920      |
|    policy_gradient_loss | 0.00636    |
|    std                  | 0.245      |
|    value_loss           | 0.01       |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2094       |
|    time_elapsed         | 6807       |
|    total_timesteps      | 4288512    |
| train/                  |            |
|    approx_kl            | 0.13827044 |
|    clip_fraction        | 0.36       |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.00754   |
|    explained_variance   | 0.806      |
|    learning_rate        | 0.00116    |
|    loss                 | 0.000183   |
|    n_updates            | 20930      |
|    policy_gradient_loss | -0.00304   |
|    std                  | 0.244      |
|    value_loss           | 0.0156     |
----------------------------------------
box reached target
box reached target
box reached target
Eval num_timesteps=4290000, episode_reward=0.17 +/- 2.52
Episode length: 278.20 +/- 43.60
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 278         |
|    mean_reward          | 0.166       |
| time/                   |             |
|    total_timesteps      | 4290000     |
| train/                  |             |
|    approx_kl            | 0.094552696 |
|    clip_fraction        | 0.379       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0205     |
|    explained_variance   | 0.844       |
|    learning_rate        | 0.00116     |
|    loss                 | 0.0217      |
|    n_updates            | 20940       |
|    policy_gradient_loss | 0.00611     |
|    std                  | 0.248       |
|    value_loss           | 0.00802     |
-----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 629     |
|    iterations      | 2095    |
|    time_elapsed    | 6810    |
|    total_timesteps | 4290560 |
--------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 629         |
|    iterations           | 2096        |
|    time_elapsed         | 6814        |
|    total_timesteps      | 4292608     |
| train/                  |             |
|    approx_kl            | 0.089859754 |
|    clip_fraction        | 0.356       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0439     |
|    explained_variance   | 0.794       |
|    learning_rate        | 0.00116     |
|    loss                 | 0.0132      |
|    n_updates            | 20950       |
|    policy_gradient_loss | 0.0053      |
|    std                  | 0.25        |
|    value_loss           | 0.0203      |
-----------------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 629        |
|    iterations           | 2097       |
|    time_elapsed         | 6817       |
|    total_timesteps      | 4294656    |
| train/                  |            |
|    approx_kl            | 0.14086139 |
|    clip_fraction        | 0.379      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.0713    |
|    explained_variance   | 0.787      |
|    learning_rate        | 0.00116    |
|    loss                 | -0.0537    |
|    n_updates            | 20960      |
|    policy_gradient_loss | 0.00373    |
|    std                  | 0.252      |
|    value_loss           | 0.0155     |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2098       |
|    time_elapsed         | 6820       |
|    total_timesteps      | 4296704    |
| train/                  |            |
|    approx_kl            | 0.35524765 |
|    clip_fraction        | 0.457      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.0877    |
|    explained_variance   | 0.884      |
|    learning_rate        | 0.00116    |
|    loss                 | 0.0389     |
|    n_updates            | 20970      |
|    policy_gradient_loss | -0.00136   |
|    std                  | 0.254      |
|    value_loss           | 0.0183     |
----------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 630       |
|    iterations           | 2099      |
|    time_elapsed         | 6823      |
|    total_timesteps      | 4298752   |
| train/                  |           |
|    approx_kl            | 0.1916129 |
|    clip_fraction        | 0.378     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0731   |
|    explained_variance   | 0.852     |
|    learning_rate        | 0.00116   |
|    loss                 | 0.0184    |
|    n_updates            | 20980     |
|    policy_gradient_loss | 0.0102    |
|    std                  | 0.25      |
|    value_loss           | 0.0129    |
---------------------------------------
box reached target
Eval num_timesteps=4300000, episode_reward=-1.07 +/- 0.14
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1.07      |
| time/                   |            |
|    total_timesteps      | 4300000    |
| train/                  |            |
|    approx_kl            | 0.23867922 |
|    clip_fraction        | 0.399      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.075     |
|    explained_variance   | 0.875      |
|    learning_rate        | 0.00116    |
|    loss                 | -0.00663   |
|    n_updates            | 20990      |
|    policy_gradient_loss | 0.0131     |
|    std                  | 0.253      |
|    value_loss           | 0.0109     |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 629     |
|    iterations      | 2100    |
|    time_elapsed    | 6827    |
|    total_timesteps | 4300800 |
--------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 629        |
|    iterations           | 2101       |
|    time_elapsed         | 6830       |
|    total_timesteps      | 4302848    |
| train/                  |            |
|    approx_kl            | 0.25018674 |
|    clip_fraction        | 0.442      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.0851    |
|    explained_variance   | 0.896      |
|    learning_rate        | 0.00116    |
|    loss                 | -0.0333    |
|    n_updates            | 21000      |
|    policy_gradient_loss | -0.00474   |
|    std                  | 0.251      |
|    value_loss           | 0.00922    |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 629        |
|    iterations           | 2102       |
|    time_elapsed         | 6833       |
|    total_timesteps      | 4304896    |
| train/                  |            |
|    approx_kl            | 0.17011842 |
|    clip_fraction        | 0.418      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.0716    |
|    explained_variance   | 0.909      |
|    learning_rate        | 0.00116    |
|    loss                 | -0.00741   |
|    n_updates            | 21010      |
|    policy_gradient_loss | 0.00167    |
|    std                  | 0.251      |
|    value_loss           | 0.0153     |
----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 630       |
|    iterations           | 2103      |
|    time_elapsed         | 6836      |
|    total_timesteps      | 4306944   |
| train/                  |           |
|    approx_kl            | 0.1738243 |
|    clip_fraction        | 0.413     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0835   |
|    explained_variance   | 0.317     |
|    learning_rate        | 0.00116   |
|    loss                 | 0.0122    |
|    n_updates            | 21020     |
|    policy_gradient_loss | 0.0139    |
|    std                  | 0.25      |
|    value_loss           | 0.0205    |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2104       |
|    time_elapsed         | 6839       |
|    total_timesteps      | 4308992    |
| train/                  |            |
|    approx_kl            | 0.20082326 |
|    clip_fraction        | 0.36       |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.0707    |
|    explained_variance   | 0.749      |
|    learning_rate        | 0.00116    |
|    loss                 | -0.00591   |
|    n_updates            | 21030      |
|    policy_gradient_loss | 0.00404    |
|    std                  | 0.248      |
|    value_loss           | 0.00647    |
----------------------------------------
box reached target
Eval num_timesteps=4310000, episode_reward=0.32 +/- 2.64
Episode length: 283.00 +/- 34.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 283        |
|    mean_reward          | 0.318      |
| time/                   |            |
|    total_timesteps      | 4310000    |
| train/                  |            |
|    approx_kl            | 0.18993555 |
|    clip_fraction        | 0.383      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.058     |
|    explained_variance   | 0.0432     |
|    learning_rate        | 0.00116    |
|    loss                 | -0.0476    |
|    n_updates            | 21040      |
|    policy_gradient_loss | -0.00727   |
|    std                  | 0.25       |
|    value_loss           | 0.0033     |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 629     |
|    iterations      | 2105    |
|    time_elapsed    | 6843    |
|    total_timesteps | 4311040 |
--------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 629        |
|    iterations           | 2106       |
|    time_elapsed         | 6846       |
|    total_timesteps      | 4313088    |
| train/                  |            |
|    approx_kl            | 0.61122704 |
|    clip_fraction        | 0.425      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.0596    |
|    explained_variance   | 0.368      |
|    learning_rate        | 0.00116    |
|    loss                 | -0.0493    |
|    n_updates            | 21050      |
|    policy_gradient_loss | -0.00969   |
|    std                  | 0.248      |
|    value_loss           | 0.0092     |
----------------------------------------
--------------------------------------
| time/                   |          |
|    fps                  | 630      |
|    iterations           | 2107     |
|    time_elapsed         | 6849     |
|    total_timesteps      | 4315136  |
| train/                  |          |
|    approx_kl            | 0.172409 |
|    clip_fraction        | 0.414    |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0436  |
|    explained_variance   | 0.33     |
|    learning_rate        | 0.00116  |
|    loss                 | 0.000491 |
|    n_updates            | 21060    |
|    policy_gradient_loss | 0.0154   |
|    std                  | 0.248    |
|    value_loss           | 0.106    |
--------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2108       |
|    time_elapsed         | 6852       |
|    total_timesteps      | 4317184    |
| train/                  |            |
|    approx_kl            | 0.26617584 |
|    clip_fraction        | 0.376      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.0469    |
|    explained_variance   | 0.373      |
|    learning_rate        | 0.00116    |
|    loss                 | 0.00349    |
|    n_updates            | 21070      |
|    policy_gradient_loss | -0.00194   |
|    std                  | 0.247      |
|    value_loss           | 0.00585    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2109       |
|    time_elapsed         | 6855       |
|    total_timesteps      | 4319232    |
| train/                  |            |
|    approx_kl            | 0.22884443 |
|    clip_fraction        | 0.425      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.021     |
|    explained_variance   | 0.0907     |
|    learning_rate        | 0.00116    |
|    loss                 | 0.0451     |
|    n_updates            | 21080      |
|    policy_gradient_loss | 0.000446   |
|    std                  | 0.244      |
|    value_loss           | 0.0799     |
----------------------------------------
box reached target
Eval num_timesteps=4320000, episode_reward=0.42 +/- 2.35
Episode length: 277.00 +/- 46.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 277         |
|    mean_reward          | 0.421       |
| time/                   |             |
|    total_timesteps      | 4320000     |
| train/                  |             |
|    approx_kl            | 0.109073445 |
|    clip_fraction        | 0.381       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0177     |
|    explained_variance   | 0.0802      |
|    learning_rate        | 0.00116     |
|    loss                 | -0.0363     |
|    n_updates            | 21090       |
|    policy_gradient_loss | 0.00582     |
|    std                  | 0.242       |
|    value_loss           | 0.00603     |
-----------------------------------------
box reached target
--------------------------------
| time/              |         |
|    fps             | 629     |
|    iterations      | 2110    |
|    time_elapsed    | 6859    |
|    total_timesteps | 4321280 |
--------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 630       |
|    iterations           | 2111      |
|    time_elapsed         | 6862      |
|    total_timesteps      | 4323328   |
| train/                  |           |
|    approx_kl            | 0.4598501 |
|    clip_fraction        | 0.405     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.0298    |
|    explained_variance   | 0.889     |
|    learning_rate        | 0.00116   |
|    loss                 | -0.0273   |
|    n_updates            | 21100     |
|    policy_gradient_loss | -0.00235  |
|    std                  | 0.234     |
|    value_loss           | 0.00978   |
---------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2112       |
|    time_elapsed         | 6865       |
|    total_timesteps      | 4325376    |
| train/                  |            |
|    approx_kl            | 0.24152783 |
|    clip_fraction        | 0.412      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.0434     |
|    explained_variance   | 0.473      |
|    learning_rate        | 0.00116    |
|    loss                 | -0.0423    |
|    n_updates            | 21110      |
|    policy_gradient_loss | 0.00412    |
|    std                  | 0.238      |
|    value_loss           | 0.00648    |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2113       |
|    time_elapsed         | 6868       |
|    total_timesteps      | 4327424    |
| train/                  |            |
|    approx_kl            | 0.18951222 |
|    clip_fraction        | 0.405      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.0175     |
|    explained_variance   | 0.934      |
|    learning_rate        | 0.00116    |
|    loss                 | -0.0454    |
|    n_updates            | 21120      |
|    policy_gradient_loss | 0.011      |
|    std                  | 0.242      |
|    value_loss           | 0.00643    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2114       |
|    time_elapsed         | 6871       |
|    total_timesteps      | 4329472    |
| train/                  |            |
|    approx_kl            | 0.41998774 |
|    clip_fraction        | 0.412      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.0046    |
|    explained_variance   | -0.0976    |
|    learning_rate        | 0.00116    |
|    loss                 | -0.0202    |
|    n_updates            | 21130      |
|    policy_gradient_loss | 0.00752    |
|    std                  | 0.244      |
|    value_loss           | 0.0607     |
----------------------------------------
Eval num_timesteps=4330000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1         |
| time/                   |            |
|    total_timesteps      | 4330000    |
| train/                  |            |
|    approx_kl            | 0.19495302 |
|    clip_fraction        | 0.395      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.025     |
|    explained_variance   | 0.424      |
|    learning_rate        | 0.00116    |
|    loss                 | -0.00862   |
|    n_updates            | 21140      |
|    policy_gradient_loss | 0.0133     |
|    std                  | 0.246      |
|    value_loss           | 0.00612    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 629     |
|    iterations      | 2115    |
|    time_elapsed    | 6875    |
|    total_timesteps | 4331520 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2116       |
|    time_elapsed         | 6878       |
|    total_timesteps      | 4333568    |
| train/                  |            |
|    approx_kl            | 0.21394011 |
|    clip_fraction        | 0.407      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.0291    |
|    explained_variance   | 0.662      |
|    learning_rate        | 0.00116    |
|    loss                 | -0.0219    |
|    n_updates            | 21150      |
|    policy_gradient_loss | -0.00442   |
|    std                  | 0.243      |
|    value_loss           | 0.00765    |
----------------------------------------
box reached target
--------------------------------------
| time/                   |          |
|    fps                  | 630      |
|    iterations           | 2117     |
|    time_elapsed         | 6881     |
|    total_timesteps      | 4335616  |
| train/                  |          |
|    approx_kl            | 0.136213 |
|    clip_fraction        | 0.348    |
|    clip_range           | 0.2      |
|    entropy_loss         | -0.0139  |
|    explained_variance   | 0.0686   |
|    learning_rate        | 0.00115  |
|    loss                 | 0.053    |
|    n_updates            | 21160    |
|    policy_gradient_loss | 0.00922  |
|    std                  | 0.245    |
|    value_loss           | 0.00435  |
--------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2118       |
|    time_elapsed         | 6884       |
|    total_timesteps      | 4337664    |
| train/                  |            |
|    approx_kl            | 0.26101223 |
|    clip_fraction        | 0.442      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.0282    |
|    explained_variance   | 0.876      |
|    learning_rate        | 0.00115    |
|    loss                 | -0.0414    |
|    n_updates            | 21170      |
|    policy_gradient_loss | -0.00502   |
|    std                  | 0.245      |
|    value_loss           | 0.0101     |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2119       |
|    time_elapsed         | 6887       |
|    total_timesteps      | 4339712    |
| train/                  |            |
|    approx_kl            | 0.30643836 |
|    clip_fraction        | 0.42       |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.0369    |
|    explained_variance   | 0.76       |
|    learning_rate        | 0.00115    |
|    loss                 | 0.0421     |
|    n_updates            | 21180      |
|    policy_gradient_loss | -0.00245   |
|    std                  | 0.248      |
|    value_loss           | 0.011      |
----------------------------------------
box reached target
box reached target
Eval num_timesteps=4340000, episode_reward=1.57 +/- 2.83
Episode length: 248.20 +/- 63.67
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 248        |
|    mean_reward          | 1.57       |
| time/                   |            |
|    total_timesteps      | 4340000    |
| train/                  |            |
|    approx_kl            | 0.18588766 |
|    clip_fraction        | 0.393      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.0303    |
|    explained_variance   | 0.757      |
|    learning_rate        | 0.00115    |
|    loss                 | -0.00449   |
|    n_updates            | 21190      |
|    policy_gradient_loss | 0.00751    |
|    std                  | 0.243      |
|    value_loss           | 0.0178     |
----------------------------------------
box reached target
--------------------------------
| time/              |         |
|    fps             | 630     |
|    iterations      | 2120    |
|    time_elapsed    | 6891    |
|    total_timesteps | 4341760 |
--------------------------------
box reached target
--------------------------------------
| time/                   |          |
|    fps                  | 630      |
|    iterations           | 2121     |
|    time_elapsed         | 6894     |
|    total_timesteps      | 4343808  |
| train/                  |          |
|    approx_kl            | 0.342696 |
|    clip_fraction        | 0.411    |
|    clip_range           | 0.2      |
|    entropy_loss         | 0.0331   |
|    explained_variance   | 0.778    |
|    learning_rate        | 0.00115  |
|    loss                 | 0.233    |
|    n_updates            | 21200    |
|    policy_gradient_loss | 0.00689  |
|    std                  | 0.238    |
|    value_loss           | 0.0109   |
--------------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2122       |
|    time_elapsed         | 6897       |
|    total_timesteps      | 4345856    |
| train/                  |            |
|    approx_kl            | 0.42335135 |
|    clip_fraction        | 0.377      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.0897     |
|    explained_variance   | 0.9        |
|    learning_rate        | 0.00115    |
|    loss                 | -0.0415    |
|    n_updates            | 21210      |
|    policy_gradient_loss | -0.00639   |
|    std                  | 0.228      |
|    value_loss           | 0.0064     |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2123       |
|    time_elapsed         | 6900       |
|    total_timesteps      | 4347904    |
| train/                  |            |
|    approx_kl            | 0.15789773 |
|    clip_fraction        | 0.429      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.157      |
|    explained_variance   | 0.551      |
|    learning_rate        | 0.00115    |
|    loss                 | 0.032      |
|    n_updates            | 21220      |
|    policy_gradient_loss | 0.014      |
|    std                  | 0.221      |
|    value_loss           | 0.0394     |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2124       |
|    time_elapsed         | 6903       |
|    total_timesteps      | 4349952    |
| train/                  |            |
|    approx_kl            | 0.33714503 |
|    clip_fraction        | 0.466      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.193      |
|    explained_variance   | 0.365      |
|    learning_rate        | 0.00115    |
|    loss                 | 0.000683   |
|    n_updates            | 21230      |
|    policy_gradient_loss | 0.0222     |
|    std                  | 0.219      |
|    value_loss           | 0.0357     |
----------------------------------------
box reached target
Eval num_timesteps=4350000, episode_reward=0.54 +/- 2.31
Episode length: 273.60 +/- 52.80
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 274        |
|    mean_reward          | 0.535      |
| time/                   |            |
|    total_timesteps      | 4350000    |
| train/                  |            |
|    approx_kl            | 0.32344794 |
|    clip_fraction        | 0.46       |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.169      |
|    explained_variance   | 0.693      |
|    learning_rate        | 0.00115    |
|    loss                 | 0.0357     |
|    n_updates            | 21240      |
|    policy_gradient_loss | 0.0091     |
|    std                  | 0.223      |
|    value_loss           | 0.0152     |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 630     |
|    iterations      | 2125    |
|    time_elapsed    | 6907    |
|    total_timesteps | 4352000 |
--------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2126       |
|    time_elapsed         | 6910       |
|    total_timesteps      | 4354048    |
| train/                  |            |
|    approx_kl            | 0.17725092 |
|    clip_fraction        | 0.435      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.142      |
|    explained_variance   | 0.708      |
|    learning_rate        | 0.00115    |
|    loss                 | 0.0741     |
|    n_updates            | 21250      |
|    policy_gradient_loss | 0.0147     |
|    std                  | 0.227      |
|    value_loss           | 0.00915    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2127       |
|    time_elapsed         | 6913       |
|    total_timesteps      | 4356096    |
| train/                  |            |
|    approx_kl            | 0.31259954 |
|    clip_fraction        | 0.455      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.132      |
|    explained_variance   | 0.5        |
|    learning_rate        | 0.00115    |
|    loss                 | 0.0311     |
|    n_updates            | 21260      |
|    policy_gradient_loss | 0.0084     |
|    std                  | 0.222      |
|    value_loss           | 0.0196     |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2128       |
|    time_elapsed         | 6916       |
|    total_timesteps      | 4358144    |
| train/                  |            |
|    approx_kl            | 0.18945098 |
|    clip_fraction        | 0.434      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.164      |
|    explained_variance   | 0.53       |
|    learning_rate        | 0.00115    |
|    loss                 | 0.043      |
|    n_updates            | 21270      |
|    policy_gradient_loss | 0.00875    |
|    std                  | 0.222      |
|    value_loss           | 0.00849    |
----------------------------------------
box reached target
box reached target
Eval num_timesteps=4360000, episode_reward=1.54 +/- 3.11
Episode length: 262.00 +/- 46.61
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 262        |
|    mean_reward          | 1.54       |
| time/                   |            |
|    total_timesteps      | 4360000    |
| train/                  |            |
|    approx_kl            | 0.11842167 |
|    clip_fraction        | 0.351      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.155      |
|    explained_variance   | 0.732      |
|    learning_rate        | 0.00115    |
|    loss                 | 0.0432     |
|    n_updates            | 21280      |
|    policy_gradient_loss | 0.00338    |
|    std                  | 0.225      |
|    value_loss           | 0.00614    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 630     |
|    iterations      | 2129    |
|    time_elapsed    | 6920    |
|    total_timesteps | 4360192 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2130       |
|    time_elapsed         | 6923       |
|    total_timesteps      | 4362240    |
| train/                  |            |
|    approx_kl            | 0.96003336 |
|    clip_fraction        | 0.442      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.159      |
|    explained_variance   | 0.457      |
|    learning_rate        | 0.00115    |
|    loss                 | -0.0226    |
|    n_updates            | 21290      |
|    policy_gradient_loss | -0.00594   |
|    std                  | 0.222      |
|    value_loss           | 0.0104     |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2131       |
|    time_elapsed         | 6926       |
|    total_timesteps      | 4364288    |
| train/                  |            |
|    approx_kl            | 0.50309813 |
|    clip_fraction        | 0.452      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.208      |
|    explained_variance   | 0.563      |
|    learning_rate        | 0.00115    |
|    loss                 | -0.00174   |
|    n_updates            | 21300      |
|    policy_gradient_loss | -0.00656   |
|    std                  | 0.215      |
|    value_loss           | 0.00689    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2132       |
|    time_elapsed         | 6929       |
|    total_timesteps      | 4366336    |
| train/                  |            |
|    approx_kl            | 0.15132987 |
|    clip_fraction        | 0.354      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.251      |
|    explained_variance   | 0.676      |
|    learning_rate        | 0.00115    |
|    loss                 | -0.0115    |
|    n_updates            | 21310      |
|    policy_gradient_loss | 0.00887    |
|    std                  | 0.213      |
|    value_loss           | 0.0159     |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2133       |
|    time_elapsed         | 6932       |
|    total_timesteps      | 4368384    |
| train/                  |            |
|    approx_kl            | 0.21448904 |
|    clip_fraction        | 0.375      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.247      |
|    explained_variance   | 0.434      |
|    learning_rate        | 0.00115    |
|    loss                 | -0.0161    |
|    n_updates            | 21320      |
|    policy_gradient_loss | 0.00472    |
|    std                  | 0.217      |
|    value_loss           | 0.0084     |
----------------------------------------
box reached target
box reached target
box reached target
Eval num_timesteps=4370000, episode_reward=1.58 +/- 3.16
Episode length: 266.80 +/- 45.71
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 267        |
|    mean_reward          | 1.58       |
| time/                   |            |
|    total_timesteps      | 4370000    |
| train/                  |            |
|    approx_kl            | 0.22497651 |
|    clip_fraction        | 0.416      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.228      |
|    explained_variance   | 0.543      |
|    learning_rate        | 0.00115    |
|    loss                 | 0.0565     |
|    n_updates            | 21330      |
|    policy_gradient_loss | 0.00952    |
|    std                  | 0.217      |
|    value_loss           | 0.0139     |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 630     |
|    iterations      | 2134    |
|    time_elapsed    | 6936    |
|    total_timesteps | 4370432 |
--------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2135       |
|    time_elapsed         | 6939       |
|    total_timesteps      | 4372480    |
| train/                  |            |
|    approx_kl            | 0.34892076 |
|    clip_fraction        | 0.476      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.232      |
|    explained_variance   | 0.857      |
|    learning_rate        | 0.00115    |
|    loss                 | 0.02       |
|    n_updates            | 21340      |
|    policy_gradient_loss | 0.00545    |
|    std                  | 0.215      |
|    value_loss           | 0.00794    |
----------------------------------------
box reached target
--------------------------------------
| time/                   |          |
|    fps                  | 630      |
|    iterations           | 2136     |
|    time_elapsed         | 6942     |
|    total_timesteps      | 4374528  |
| train/                  |          |
|    approx_kl            | 0.729519 |
|    clip_fraction        | 0.507    |
|    clip_range           | 0.2      |
|    entropy_loss         | 0.292    |
|    explained_variance   | 0.724    |
|    learning_rate        | 0.00115  |
|    loss                 | -0.0103  |
|    n_updates            | 21350    |
|    policy_gradient_loss | 0.0134   |
|    std                  | 0.208    |
|    value_loss           | 0.0199   |
--------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2137       |
|    time_elapsed         | 6945       |
|    total_timesteps      | 4376576    |
| train/                  |            |
|    approx_kl            | 0.25597268 |
|    clip_fraction        | 0.404      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.29       |
|    explained_variance   | 0.727      |
|    learning_rate        | 0.00115    |
|    loss                 | -0.00613   |
|    n_updates            | 21360      |
|    policy_gradient_loss | 0.00534    |
|    std                  | 0.212      |
|    value_loss           | 0.0243     |
----------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 630       |
|    iterations           | 2138      |
|    time_elapsed         | 6948      |
|    total_timesteps      | 4378624   |
| train/                  |           |
|    approx_kl            | 0.2344285 |
|    clip_fraction        | 0.393     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.25      |
|    explained_variance   | 0.477     |
|    learning_rate        | 0.00115   |
|    loss                 | 0.022     |
|    n_updates            | 21370     |
|    policy_gradient_loss | 0.0282    |
|    std                  | 0.216     |
|    value_loss           | 0.00335   |
---------------------------------------
Eval num_timesteps=4380000, episode_reward=-0.76 +/- 0.48
Episode length: 300.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 300       |
|    mean_reward          | -0.761    |
| time/                   |           |
|    total_timesteps      | 4380000   |
| train/                  |           |
|    approx_kl            | 0.1992861 |
|    clip_fraction        | 0.423     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.186     |
|    explained_variance   | 0.852     |
|    learning_rate        | 0.00115   |
|    loss                 | -0.0123   |
|    n_updates            | 21380     |
|    policy_gradient_loss | 0.0185    |
|    std                  | 0.226     |
|    value_loss           | 0.013     |
---------------------------------------
box reached target
--------------------------------
| time/              |         |
|    fps             | 630     |
|    iterations      | 2139    |
|    time_elapsed    | 6952    |
|    total_timesteps | 4380672 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2140       |
|    time_elapsed         | 6955       |
|    total_timesteps      | 4382720    |
| train/                  |            |
|    approx_kl            | 0.16910215 |
|    clip_fraction        | 0.394      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.118      |
|    explained_variance   | 0.897      |
|    learning_rate        | 0.00115    |
|    loss                 | 0.0173     |
|    n_updates            | 21390      |
|    policy_gradient_loss | 0.00625    |
|    std                  | 0.232      |
|    value_loss           | 0.00817    |
----------------------------------------
box reached target
--------------------------------------
| time/                   |          |
|    fps                  | 630      |
|    iterations           | 2141     |
|    time_elapsed         | 6958     |
|    total_timesteps      | 4384768  |
| train/                  |          |
|    approx_kl            | 0.097807 |
|    clip_fraction        | 0.353    |
|    clip_range           | 0.2      |
|    entropy_loss         | 0.0874   |
|    explained_variance   | 0.753    |
|    learning_rate        | 0.00115  |
|    loss                 | 0.00682  |
|    n_updates            | 21400    |
|    policy_gradient_loss | 0.00394  |
|    std                  | 0.234    |
|    value_loss           | 0.00721  |
--------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2142       |
|    time_elapsed         | 6961       |
|    total_timesteps      | 4386816    |
| train/                  |            |
|    approx_kl            | 0.21378879 |
|    clip_fraction        | 0.361      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.0865     |
|    explained_variance   | 0.74       |
|    learning_rate        | 0.00114    |
|    loss                 | 0.031      |
|    n_updates            | 21410      |
|    policy_gradient_loss | 0.0027     |
|    std                  | 0.235      |
|    value_loss           | 0.0136     |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2143       |
|    time_elapsed         | 6964       |
|    total_timesteps      | 4388864    |
| train/                  |            |
|    approx_kl            | 0.31558913 |
|    clip_fraction        | 0.392      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.0925     |
|    explained_variance   | 0.66       |
|    learning_rate        | 0.00114    |
|    loss                 | -0.0435    |
|    n_updates            | 21420      |
|    policy_gradient_loss | -0.00651   |
|    std                  | 0.229      |
|    value_loss           | 0.00298    |
----------------------------------------
box reached target
Eval num_timesteps=4390000, episode_reward=0.34 +/- 2.40
Episode length: 274.60 +/- 50.80
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 275        |
|    mean_reward          | 0.342      |
| time/                   |            |
|    total_timesteps      | 4390000    |
| train/                  |            |
|    approx_kl            | 0.19810432 |
|    clip_fraction        | 0.419      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.131      |
|    explained_variance   | 0.803      |
|    learning_rate        | 0.00114    |
|    loss                 | -0.00635   |
|    n_updates            | 21430      |
|    policy_gradient_loss | 0.0186     |
|    std                  | 0.229      |
|    value_loss           | 0.0245     |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 630     |
|    iterations      | 2144    |
|    time_elapsed    | 6968    |
|    total_timesteps | 4390912 |
--------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2145       |
|    time_elapsed         | 6971       |
|    total_timesteps      | 4392960    |
| train/                  |            |
|    approx_kl            | 0.11554607 |
|    clip_fraction        | 0.375      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.127      |
|    explained_variance   | 0.705      |
|    learning_rate        | 0.00114    |
|    loss                 | -0.0168    |
|    n_updates            | 21440      |
|    policy_gradient_loss | 0.0119     |
|    std                  | 0.229      |
|    value_loss           | 0.00835    |
----------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 630       |
|    iterations           | 2146      |
|    time_elapsed         | 6974      |
|    total_timesteps      | 4395008   |
| train/                  |           |
|    approx_kl            | 1.5126384 |
|    clip_fraction        | 0.485     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.146     |
|    explained_variance   | 0.804     |
|    learning_rate        | 0.00114   |
|    loss                 | 0.107     |
|    n_updates            | 21450     |
|    policy_gradient_loss | 0.00528   |
|    std                  | 0.224     |
|    value_loss           | 0.0107    |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2147       |
|    time_elapsed         | 6978       |
|    total_timesteps      | 4397056    |
| train/                  |            |
|    approx_kl            | 0.21540979 |
|    clip_fraction        | 0.445      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.146      |
|    explained_variance   | 0.706      |
|    learning_rate        | 0.00114    |
|    loss                 | 0.0107     |
|    n_updates            | 21460      |
|    policy_gradient_loss | 0.0156     |
|    std                  | 0.227      |
|    value_loss           | 0.0194     |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2148       |
|    time_elapsed         | 6981       |
|    total_timesteps      | 4399104    |
| train/                  |            |
|    approx_kl            | 0.24795985 |
|    clip_fraction        | 0.424      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.162      |
|    explained_variance   | 0.309      |
|    learning_rate        | 0.00114    |
|    loss                 | -0.0118    |
|    n_updates            | 21470      |
|    policy_gradient_loss | 0.00413    |
|    std                  | 0.224      |
|    value_loss           | 0.00841    |
----------------------------------------
box reached target
box reached target
Eval num_timesteps=4400000, episode_reward=1.56 +/- 3.14
Episode length: 269.40 +/- 39.87
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 269        |
|    mean_reward          | 1.56       |
| time/                   |            |
|    total_timesteps      | 4400000    |
| train/                  |            |
|    approx_kl            | 0.18456967 |
|    clip_fraction        | 0.421      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.136      |
|    explained_variance   | 0.878      |
|    learning_rate        | 0.00114    |
|    loss                 | 0.0526     |
|    n_updates            | 21480      |
|    policy_gradient_loss | 0.0136     |
|    std                  | 0.231      |
|    value_loss           | 0.00713    |
----------------------------------------
box reached target
box reached target
--------------------------------
| time/              |         |
|    fps             | 630     |
|    iterations      | 2149    |
|    time_elapsed    | 6984    |
|    total_timesteps | 4401152 |
--------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 630         |
|    iterations           | 2150        |
|    time_elapsed         | 6987        |
|    total_timesteps      | 4403200     |
| train/                  |             |
|    approx_kl            | 0.110405445 |
|    clip_fraction        | 0.376       |
|    clip_range           | 0.2         |
|    entropy_loss         | 0.075       |
|    explained_variance   | 0.863       |
|    learning_rate        | 0.00114     |
|    loss                 | 0.0916      |
|    n_updates            | 21490       |
|    policy_gradient_loss | 0.0181      |
|    std                  | 0.238       |
|    value_loss           | 0.0127      |
-----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2151       |
|    time_elapsed         | 6991       |
|    total_timesteps      | 4405248    |
| train/                  |            |
|    approx_kl            | 0.18473914 |
|    clip_fraction        | 0.438      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.0511     |
|    explained_variance   | 0.869      |
|    learning_rate        | 0.00114    |
|    loss                 | 0.0876     |
|    n_updates            | 21500      |
|    policy_gradient_loss | 0.00953    |
|    std                  | 0.236      |
|    value_loss           | 0.00704    |
----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 630       |
|    iterations           | 2152      |
|    time_elapsed         | 6994      |
|    total_timesteps      | 4407296   |
| train/                  |           |
|    approx_kl            | 0.3223667 |
|    clip_fraction        | 0.408     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.0479    |
|    explained_variance   | 0.886     |
|    learning_rate        | 0.00114   |
|    loss                 | -0.0216   |
|    n_updates            | 21510     |
|    policy_gradient_loss | 0.00295   |
|    std                  | 0.239     |
|    value_loss           | 0.00859   |
---------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2153       |
|    time_elapsed         | 6997       |
|    total_timesteps      | 4409344    |
| train/                  |            |
|    approx_kl            | 0.29254055 |
|    clip_fraction        | 0.421      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.00162    |
|    explained_variance   | 0.503      |
|    learning_rate        | 0.00114    |
|    loss                 | -0.0357    |
|    n_updates            | 21520      |
|    policy_gradient_loss | 0.00477    |
|    std                  | 0.24       |
|    value_loss           | 0.00564    |
----------------------------------------
box reached target
Eval num_timesteps=4410000, episode_reward=0.42 +/- 2.35
Episode length: 274.20 +/- 51.60
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 274        |
|    mean_reward          | 0.415      |
| time/                   |            |
|    total_timesteps      | 4410000    |
| train/                  |            |
|    approx_kl            | 0.24196926 |
|    clip_fraction        | 0.411      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.0299     |
|    explained_variance   | 0.845      |
|    learning_rate        | 0.00114    |
|    loss                 | 0.0226     |
|    n_updates            | 21530      |
|    policy_gradient_loss | 0.0128     |
|    std                  | 0.238      |
|    value_loss           | 0.0157     |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 630     |
|    iterations      | 2154    |
|    time_elapsed    | 7001    |
|    total_timesteps | 4411392 |
--------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2155       |
|    time_elapsed         | 7004       |
|    total_timesteps      | 4413440    |
| train/                  |            |
|    approx_kl            | 0.19363773 |
|    clip_fraction        | 0.412      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.051      |
|    explained_variance   | 0.739      |
|    learning_rate        | 0.00114    |
|    loss                 | -0.0288    |
|    n_updates            | 21540      |
|    policy_gradient_loss | 0.00147    |
|    std                  | 0.234      |
|    value_loss           | 0.00266    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2156       |
|    time_elapsed         | 7007       |
|    total_timesteps      | 4415488    |
| train/                  |            |
|    approx_kl            | 0.34231028 |
|    clip_fraction        | 0.442      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.0811     |
|    explained_variance   | 0.222      |
|    learning_rate        | 0.00114    |
|    loss                 | 0.0458     |
|    n_updates            | 21550      |
|    policy_gradient_loss | 0.0191     |
|    std                  | 0.232      |
|    value_loss           | 0.0144     |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2157       |
|    time_elapsed         | 7010       |
|    total_timesteps      | 4417536    |
| train/                  |            |
|    approx_kl            | 0.13999704 |
|    clip_fraction        | 0.384      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.0678     |
|    explained_variance   | 0.587      |
|    learning_rate        | 0.00114    |
|    loss                 | 0.00523    |
|    n_updates            | 21560      |
|    policy_gradient_loss | 0.00129    |
|    std                  | 0.233      |
|    value_loss           | 0.00574    |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2158       |
|    time_elapsed         | 7013       |
|    total_timesteps      | 4419584    |
| train/                  |            |
|    approx_kl            | 0.13507757 |
|    clip_fraction        | 0.444      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.0312     |
|    explained_variance   | 0.668      |
|    learning_rate        | 0.00114    |
|    loss                 | 0.000614   |
|    n_updates            | 21570      |
|    policy_gradient_loss | 0.00877    |
|    std                  | 0.243      |
|    value_loss           | 0.00816    |
----------------------------------------
Eval num_timesteps=4420000, episode_reward=-0.89 +/- 0.22
Episode length: 300.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 300       |
|    mean_reward          | -0.892    |
| time/                   |           |
|    total_timesteps      | 4420000   |
| train/                  |           |
|    approx_kl            | 0.2550981 |
|    clip_fraction        | 0.443     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.00927   |
|    explained_variance   | 0.754     |
|    learning_rate        | 0.00114   |
|    loss                 | 0.0434    |
|    n_updates            | 21580     |
|    policy_gradient_loss | 0.000669  |
|    std                  | 0.239     |
|    value_loss           | 0.0138    |
---------------------------------------
--------------------------------
| time/              |         |
|    fps             | 630     |
|    iterations      | 2159    |
|    time_elapsed    | 7017    |
|    total_timesteps | 4421632 |
--------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 630         |
|    iterations           | 2160        |
|    time_elapsed         | 7020        |
|    total_timesteps      | 4423680     |
| train/                  |             |
|    approx_kl            | 0.115921006 |
|    clip_fraction        | 0.36        |
|    clip_range           | 0.2         |
|    entropy_loss         | 0.0317      |
|    explained_variance   | 0.317       |
|    learning_rate        | 0.00114     |
|    loss                 | -0.0151     |
|    n_updates            | 21590       |
|    policy_gradient_loss | -0.000287   |
|    std                  | 0.238       |
|    value_loss           | 0.00486     |
-----------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 630       |
|    iterations           | 2161      |
|    time_elapsed         | 7023      |
|    total_timesteps      | 4425728   |
| train/                  |           |
|    approx_kl            | 0.3797244 |
|    clip_fraction        | 0.423     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.0184    |
|    explained_variance   | 0.866     |
|    learning_rate        | 0.00114   |
|    loss                 | -0.0165   |
|    n_updates            | 21600     |
|    policy_gradient_loss | 0.00227   |
|    std                  | 0.241     |
|    value_loss           | 0.0107    |
---------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2162       |
|    time_elapsed         | 7026       |
|    total_timesteps      | 4427776    |
| train/                  |            |
|    approx_kl            | 0.18871237 |
|    clip_fraction        | 0.437      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.0132     |
|    explained_variance   | 0.739      |
|    learning_rate        | 0.00114    |
|    loss                 | 0.0188     |
|    n_updates            | 21610      |
|    policy_gradient_loss | 0.00272    |
|    std                  | 0.243      |
|    value_loss           | 0.00906    |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2163       |
|    time_elapsed         | 7029       |
|    total_timesteps      | 4429824    |
| train/                  |            |
|    approx_kl            | 0.07748827 |
|    clip_fraction        | 0.363      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.0248     |
|    explained_variance   | 0.756      |
|    learning_rate        | 0.00114    |
|    loss                 | -0.0301    |
|    n_updates            | 21620      |
|    policy_gradient_loss | 0.012      |
|    std                  | 0.239      |
|    value_loss           | 0.0134     |
----------------------------------------
box reached target
Eval num_timesteps=4430000, episode_reward=0.24 +/- 2.48
Episode length: 283.60 +/- 32.80
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 284        |
|    mean_reward          | 0.242      |
| time/                   |            |
|    total_timesteps      | 4430000    |
| train/                  |            |
|    approx_kl            | 0.11530149 |
|    clip_fraction        | 0.384      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.0227     |
|    explained_variance   | 0.861      |
|    learning_rate        | 0.00114    |
|    loss                 | 0.0111     |
|    n_updates            | 21630      |
|    policy_gradient_loss | 0.00975    |
|    std                  | 0.241      |
|    value_loss           | 0.00846    |
----------------------------------------
box reached target
box reached target
--------------------------------
| time/              |         |
|    fps             | 630     |
|    iterations      | 2164    |
|    time_elapsed    | 7033    |
|    total_timesteps | 4431872 |
--------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2165       |
|    time_elapsed         | 7036       |
|    total_timesteps      | 4433920    |
| train/                  |            |
|    approx_kl            | 0.26937556 |
|    clip_fraction        | 0.468      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.0626     |
|    explained_variance   | 0.697      |
|    learning_rate        | 0.00114    |
|    loss                 | -0.0155    |
|    n_updates            | 21640      |
|    policy_gradient_loss | 0.00804    |
|    std                  | 0.231      |
|    value_loss           | 0.0279     |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2166       |
|    time_elapsed         | 7039       |
|    total_timesteps      | 4435968    |
| train/                  |            |
|    approx_kl            | 0.11243655 |
|    clip_fraction        | 0.378      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.146      |
|    explained_variance   | 0.889      |
|    learning_rate        | 0.00114    |
|    loss                 | 0.0534     |
|    n_updates            | 21650      |
|    policy_gradient_loss | 0.0117     |
|    std                  | 0.223      |
|    value_loss           | 0.015      |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2167       |
|    time_elapsed         | 7042       |
|    total_timesteps      | 4438016    |
| train/                  |            |
|    approx_kl            | 0.13773216 |
|    clip_fraction        | 0.376      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.146      |
|    explained_variance   | 0.845      |
|    learning_rate        | 0.00113    |
|    loss                 | -0.0518    |
|    n_updates            | 21660      |
|    policy_gradient_loss | 0.00399    |
|    std                  | 0.228      |
|    value_loss           | 0.0147     |
----------------------------------------
box reached target
box reached target
Eval num_timesteps=4440000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 300       |
|    mean_reward          | -1        |
| time/                   |           |
|    total_timesteps      | 4440000   |
| train/                  |           |
|    approx_kl            | 0.1787785 |
|    clip_fraction        | 0.364     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.127     |
|    explained_variance   | 0.721     |
|    learning_rate        | 0.00113   |
|    loss                 | 0.0169    |
|    n_updates            | 21670     |
|    policy_gradient_loss | 0.00345   |
|    std                  | 0.231     |
|    value_loss           | 0.00839   |
---------------------------------------
--------------------------------
| time/              |         |
|    fps             | 630     |
|    iterations      | 2168    |
|    time_elapsed    | 7046    |
|    total_timesteps | 4440064 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2169       |
|    time_elapsed         | 7049       |
|    total_timesteps      | 4442112    |
| train/                  |            |
|    approx_kl            | 0.09774623 |
|    clip_fraction        | 0.401      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.156      |
|    explained_variance   | 0.94       |
|    learning_rate        | 0.00113    |
|    loss                 | -0.04      |
|    n_updates            | 21680      |
|    policy_gradient_loss | 0.00522    |
|    std                  | 0.223      |
|    value_loss           | 0.0117     |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2170       |
|    time_elapsed         | 7052       |
|    total_timesteps      | 4444160    |
| train/                  |            |
|    approx_kl            | 0.56780595 |
|    clip_fraction        | 0.463      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.172      |
|    explained_variance   | 0.593      |
|    learning_rate        | 0.00113    |
|    loss                 | 0.0255     |
|    n_updates            | 21690      |
|    policy_gradient_loss | 0.00375    |
|    std                  | 0.222      |
|    value_loss           | 0.00655    |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2171       |
|    time_elapsed         | 7055       |
|    total_timesteps      | 4446208    |
| train/                  |            |
|    approx_kl            | 0.36911255 |
|    clip_fraction        | 0.429      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.151      |
|    explained_variance   | 0.874      |
|    learning_rate        | 0.00113    |
|    loss                 | 0.000227   |
|    n_updates            | 21700      |
|    policy_gradient_loss | 0.00595    |
|    std                  | 0.226      |
|    value_loss           | 0.00736    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2172       |
|    time_elapsed         | 7058       |
|    total_timesteps      | 4448256    |
| train/                  |            |
|    approx_kl            | 0.24388392 |
|    clip_fraction        | 0.44       |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.136      |
|    explained_variance   | 0.601      |
|    learning_rate        | 0.00113    |
|    loss                 | -0.00275   |
|    n_updates            | 21710      |
|    policy_gradient_loss | 0.0225     |
|    std                  | 0.228      |
|    value_loss           | 0.0117     |
----------------------------------------
box reached target
box reached target
Eval num_timesteps=4450000, episode_reward=0.24 +/- 2.47
Episode length: 273.20 +/- 53.60
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 273        |
|    mean_reward          | 0.236      |
| time/                   |            |
|    total_timesteps      | 4450000    |
| train/                  |            |
|    approx_kl            | 0.42903394 |
|    clip_fraction        | 0.488      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.134      |
|    explained_variance   | 0.641      |
|    learning_rate        | 0.00113    |
|    loss                 | -0.0297    |
|    n_updates            | 21720      |
|    policy_gradient_loss | 0.0138     |
|    std                  | 0.227      |
|    value_loss           | 0.00288    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 630     |
|    iterations      | 2173    |
|    time_elapsed    | 7062    |
|    total_timesteps | 4450304 |
--------------------------------
box reached target
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 630       |
|    iterations           | 2174      |
|    time_elapsed         | 7065      |
|    total_timesteps      | 4452352   |
| train/                  |           |
|    approx_kl            | 0.3980487 |
|    clip_fraction        | 0.435     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.112     |
|    explained_variance   | 0.852     |
|    learning_rate        | 0.00113   |
|    loss                 | -0.0253   |
|    n_updates            | 21730     |
|    policy_gradient_loss | 0.0116    |
|    std                  | 0.229     |
|    value_loss           | 0.00749   |
---------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 630       |
|    iterations           | 2175      |
|    time_elapsed         | 7068      |
|    total_timesteps      | 4454400   |
| train/                  |           |
|    approx_kl            | 0.2964518 |
|    clip_fraction        | 0.465     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.108     |
|    explained_variance   | 0.68      |
|    learning_rate        | 0.00113   |
|    loss                 | 0.0198    |
|    n_updates            | 21740     |
|    policy_gradient_loss | 0.0119    |
|    std                  | 0.23      |
|    value_loss           | 0.0309    |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2176       |
|    time_elapsed         | 7071       |
|    total_timesteps      | 4456448    |
| train/                  |            |
|    approx_kl            | 0.26661152 |
|    clip_fraction        | 0.442      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.105      |
|    explained_variance   | -0.0195    |
|    learning_rate        | 0.00113    |
|    loss                 | -0.0172    |
|    n_updates            | 21750      |
|    policy_gradient_loss | 0.021      |
|    std                  | 0.23       |
|    value_loss           | 0.033      |
----------------------------------------
box reached target
box reached target
--------------------------------------
| time/                   |          |
|    fps                  | 630      |
|    iterations           | 2177     |
|    time_elapsed         | 7074     |
|    total_timesteps      | 4458496  |
| train/                  |          |
|    approx_kl            | 0.138754 |
|    clip_fraction        | 0.395    |
|    clip_range           | 0.2      |
|    entropy_loss         | 0.0818   |
|    explained_variance   | 0.87     |
|    learning_rate        | 0.00113  |
|    loss                 | 0.0714   |
|    n_updates            | 21760    |
|    policy_gradient_loss | 0.00864  |
|    std                  | 0.235    |
|    value_loss           | 0.0106   |
--------------------------------------
Eval num_timesteps=4460000, episode_reward=-0.84 +/- 0.30
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -0.84      |
| time/                   |            |
|    total_timesteps      | 4460000    |
| train/                  |            |
|    approx_kl            | 0.08179453 |
|    clip_fraction        | 0.384      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.0638     |
|    explained_variance   | 0.703      |
|    learning_rate        | 0.00113    |
|    loss                 | -0.00274   |
|    n_updates            | 21770      |
|    policy_gradient_loss | 0.0175     |
|    std                  | 0.238      |
|    value_loss           | 0.032      |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 630     |
|    iterations      | 2178    |
|    time_elapsed    | 7078    |
|    total_timesteps | 4460544 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2179       |
|    time_elapsed         | 7081       |
|    total_timesteps      | 4462592    |
| train/                  |            |
|    approx_kl            | 0.18926223 |
|    clip_fraction        | 0.414      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.0544     |
|    explained_variance   | 0.389      |
|    learning_rate        | 0.00113    |
|    loss                 | -0.0191    |
|    n_updates            | 21780      |
|    policy_gradient_loss | 0.00157    |
|    std                  | 0.235      |
|    value_loss           | 0.00697    |
----------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 630       |
|    iterations           | 2180      |
|    time_elapsed         | 7084      |
|    total_timesteps      | 4464640   |
| train/                  |           |
|    approx_kl            | 0.1505132 |
|    clip_fraction        | 0.365     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.0649    |
|    explained_variance   | 0.348     |
|    learning_rate        | 0.00113   |
|    loss                 | -0.0156   |
|    n_updates            | 21790     |
|    policy_gradient_loss | 0.0041    |
|    std                  | 0.235     |
|    value_loss           | 0.00574   |
---------------------------------------
box reached target
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 630         |
|    iterations           | 2181        |
|    time_elapsed         | 7087        |
|    total_timesteps      | 4466688     |
| train/                  |             |
|    approx_kl            | 0.110898346 |
|    clip_fraction        | 0.39        |
|    clip_range           | 0.2         |
|    entropy_loss         | 0.0496      |
|    explained_variance   | 0.79        |
|    learning_rate        | 0.00113     |
|    loss                 | 0.023       |
|    n_updates            | 21800       |
|    policy_gradient_loss | 0.00358     |
|    std                  | 0.238       |
|    value_loss           | 0.0138      |
-----------------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2182       |
|    time_elapsed         | 7090       |
|    total_timesteps      | 4468736    |
| train/                  |            |
|    approx_kl            | 0.28844696 |
|    clip_fraction        | 0.42       |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.0654     |
|    explained_variance   | 0.701      |
|    learning_rate        | 0.00113    |
|    loss                 | 0.0111     |
|    n_updates            | 21810      |
|    policy_gradient_loss | -0.00454   |
|    std                  | 0.232      |
|    value_loss           | 0.0224     |
----------------------------------------
box reached target
Eval num_timesteps=4470000, episode_reward=0.26 +/- 2.52
Episode length: 272.20 +/- 55.60
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 272        |
|    mean_reward          | 0.259      |
| time/                   |            |
|    total_timesteps      | 4470000    |
| train/                  |            |
|    approx_kl            | 0.25164735 |
|    clip_fraction        | 0.464      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.0929     |
|    explained_variance   | 0.815      |
|    learning_rate        | 0.00113    |
|    loss                 | 0.00891    |
|    n_updates            | 21820      |
|    policy_gradient_loss | 0.0109     |
|    std                  | 0.23       |
|    value_loss           | 0.0209     |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 630     |
|    iterations      | 2183    |
|    time_elapsed    | 7094    |
|    total_timesteps | 4470784 |
--------------------------------
box reached target
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 630       |
|    iterations           | 2184      |
|    time_elapsed         | 7097      |
|    total_timesteps      | 4472832   |
| train/                  |           |
|    approx_kl            | 0.2231681 |
|    clip_fraction        | 0.403     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.0866    |
|    explained_variance   | -0.0129   |
|    learning_rate        | 0.00113   |
|    loss                 | -0.0131   |
|    n_updates            | 21830     |
|    policy_gradient_loss | 0.0014    |
|    std                  | 0.234     |
|    value_loss           | 0.00609   |
---------------------------------------
box reached target
box reached target
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 630       |
|    iterations           | 2185      |
|    time_elapsed         | 7100      |
|    total_timesteps      | 4474880   |
| train/                  |           |
|    approx_kl            | 0.2624107 |
|    clip_fraction        | 0.455     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.108     |
|    explained_variance   | 0.827     |
|    learning_rate        | 0.00113   |
|    loss                 | -0.0318   |
|    n_updates            | 21840     |
|    policy_gradient_loss | -0.000259 |
|    std                  | 0.229     |
|    value_loss           | 0.0111    |
---------------------------------------
box reached target
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 630       |
|    iterations           | 2186      |
|    time_elapsed         | 7103      |
|    total_timesteps      | 4476928   |
| train/                  |           |
|    approx_kl            | 0.1609289 |
|    clip_fraction        | 0.4       |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.162     |
|    explained_variance   | 0.74      |
|    learning_rate        | 0.00113   |
|    loss                 | 0.000624  |
|    n_updates            | 21850     |
|    policy_gradient_loss | 0.00884   |
|    std                  | 0.221     |
|    value_loss           | 0.0296    |
---------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2187       |
|    time_elapsed         | 7106       |
|    total_timesteps      | 4478976    |
| train/                  |            |
|    approx_kl            | 0.17182365 |
|    clip_fraction        | 0.437      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.244      |
|    explained_variance   | 0.608      |
|    learning_rate        | 0.00113    |
|    loss                 | -0.000632  |
|    n_updates            | 21860      |
|    policy_gradient_loss | 0.0191     |
|    std                  | 0.214      |
|    value_loss           | 0.0369     |
----------------------------------------
box reached target
Eval num_timesteps=4480000, episode_reward=-1.02 +/- 0.04
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1.02      |
| time/                   |            |
|    total_timesteps      | 4480000    |
| train/                  |            |
|    approx_kl            | 0.15836987 |
|    clip_fraction        | 0.387      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.241      |
|    explained_variance   | 0.644      |
|    learning_rate        | 0.00113    |
|    loss                 | 0.00969    |
|    n_updates            | 21870      |
|    policy_gradient_loss | 0.00925    |
|    std                  | 0.216      |
|    value_loss           | 0.0328     |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 630     |
|    iterations      | 2188    |
|    time_elapsed    | 7110    |
|    total_timesteps | 4481024 |
--------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 630       |
|    iterations           | 2189      |
|    time_elapsed         | 7113      |
|    total_timesteps      | 4483072   |
| train/                  |           |
|    approx_kl            | 0.1300149 |
|    clip_fraction        | 0.442     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.204     |
|    explained_variance   | 0.778     |
|    learning_rate        | 0.00113   |
|    loss                 | 0.00842   |
|    n_updates            | 21880     |
|    policy_gradient_loss | 0.00296   |
|    std                  | 0.22      |
|    value_loss           | 0.0201    |
---------------------------------------
box reached target
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2190       |
|    time_elapsed         | 7116       |
|    total_timesteps      | 4485120    |
| train/                  |            |
|    approx_kl            | 0.13096173 |
|    clip_fraction        | 0.389      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.184      |
|    explained_variance   | 0.813      |
|    learning_rate        | 0.00113    |
|    loss                 | 0.00297    |
|    n_updates            | 21890      |
|    policy_gradient_loss | 0.00688    |
|    std                  | 0.222      |
|    value_loss           | 0.0173     |
----------------------------------------
box reached target
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 630       |
|    iterations           | 2191      |
|    time_elapsed         | 7119      |
|    total_timesteps      | 4487168   |
| train/                  |           |
|    approx_kl            | 0.4135134 |
|    clip_fraction        | 0.445     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.211     |
|    explained_variance   | 0.859     |
|    learning_rate        | 0.00113   |
|    loss                 | 0.136     |
|    n_updates            | 21900     |
|    policy_gradient_loss | 0.0192    |
|    std                  | 0.215     |
|    value_loss           | 0.0284    |
---------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2192       |
|    time_elapsed         | 7123       |
|    total_timesteps      | 4489216    |
| train/                  |            |
|    approx_kl            | 0.37097353 |
|    clip_fraction        | 0.498      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.232      |
|    explained_variance   | 0.755      |
|    learning_rate        | 0.00113    |
|    loss                 | -0.00197   |
|    n_updates            | 21910      |
|    policy_gradient_loss | 0.0183     |
|    std                  | 0.217      |
|    value_loss           | 0.0675     |
----------------------------------------
Eval num_timesteps=4490000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 300       |
|    mean_reward          | -1        |
| time/                   |           |
|    total_timesteps      | 4490000   |
| train/                  |           |
|    approx_kl            | 0.1050273 |
|    clip_fraction        | 0.375     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.243     |
|    explained_variance   | 0.901     |
|    learning_rate        | 0.00112   |
|    loss                 | -0.0257   |
|    n_updates            | 21920     |
|    policy_gradient_loss | 0.00136   |
|    std                  | 0.214     |
|    value_loss           | 0.013     |
---------------------------------------
box reached target
--------------------------------
| time/              |         |
|    fps             | 630     |
|    iterations      | 2193    |
|    time_elapsed    | 7127    |
|    total_timesteps | 4491264 |
--------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 630         |
|    iterations           | 2194        |
|    time_elapsed         | 7130        |
|    total_timesteps      | 4493312     |
| train/                  |             |
|    approx_kl            | 0.120045826 |
|    clip_fraction        | 0.426       |
|    clip_range           | 0.2         |
|    entropy_loss         | 0.231       |
|    explained_variance   | 0.897       |
|    learning_rate        | 0.00112     |
|    loss                 | 0.031       |
|    n_updates            | 21930       |
|    policy_gradient_loss | 0.0177      |
|    std                  | 0.218       |
|    value_loss           | 0.0121      |
-----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2195       |
|    time_elapsed         | 7133       |
|    total_timesteps      | 4495360    |
| train/                  |            |
|    approx_kl            | 0.20540407 |
|    clip_fraction        | 0.405      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.236      |
|    explained_variance   | 0.848      |
|    learning_rate        | 0.00112    |
|    loss                 | 0.00137    |
|    n_updates            | 21940      |
|    policy_gradient_loss | 0.0153     |
|    std                  | 0.214      |
|    value_loss           | 0.00612    |
----------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 630       |
|    iterations           | 2196      |
|    time_elapsed         | 7136      |
|    total_timesteps      | 4497408   |
| train/                  |           |
|    approx_kl            | 0.2538578 |
|    clip_fraction        | 0.41      |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.249     |
|    explained_variance   | 0.778     |
|    learning_rate        | 0.00112   |
|    loss                 | 0.051     |
|    n_updates            | 21950     |
|    policy_gradient_loss | 0.0202    |
|    std                  | 0.215     |
|    value_loss           | 0.0167    |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2197       |
|    time_elapsed         | 7139       |
|    total_timesteps      | 4499456    |
| train/                  |            |
|    approx_kl            | 0.22015229 |
|    clip_fraction        | 0.41       |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.271      |
|    explained_variance   | 0.851      |
|    learning_rate        | 0.00112    |
|    loss                 | -0.0107    |
|    n_updates            | 21960      |
|    policy_gradient_loss | 0.00594    |
|    std                  | 0.21       |
|    value_loss           | 0.0161     |
----------------------------------------
Eval num_timesteps=4500000, episode_reward=-1.04 +/- 0.09
Episode length: 300.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 300       |
|    mean_reward          | -1.04     |
| time/                   |           |
|    total_timesteps      | 4500000   |
| train/                  |           |
|    approx_kl            | 0.3016671 |
|    clip_fraction        | 0.487     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.276     |
|    explained_variance   | 0.773     |
|    learning_rate        | 0.00112   |
|    loss                 | -0.038    |
|    n_updates            | 21970     |
|    policy_gradient_loss | 0.00647   |
|    std                  | 0.211     |
|    value_loss           | 0.0146    |
---------------------------------------
--------------------------------
| time/              |         |
|    fps             | 630     |
|    iterations      | 2198    |
|    time_elapsed    | 7143    |
|    total_timesteps | 4501504 |
--------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2199       |
|    time_elapsed         | 7146       |
|    total_timesteps      | 4503552    |
| train/                  |            |
|    approx_kl            | 0.25524476 |
|    clip_fraction        | 0.445      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.263      |
|    explained_variance   | 0.526      |
|    learning_rate        | 0.00112    |
|    loss                 | -0.0283    |
|    n_updates            | 21980      |
|    policy_gradient_loss | 0.00133    |
|    std                  | 0.211      |
|    value_loss           | 0.00373    |
----------------------------------------
box reached target
box reached target
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 630       |
|    iterations           | 2200      |
|    time_elapsed         | 7149      |
|    total_timesteps      | 4505600   |
| train/                  |           |
|    approx_kl            | 0.6637839 |
|    clip_fraction        | 0.443     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.273     |
|    explained_variance   | 0.135     |
|    learning_rate        | 0.00112   |
|    loss                 | 0.0238    |
|    n_updates            | 21990     |
|    policy_gradient_loss | 0.00494   |
|    std                  | 0.212     |
|    value_loss           | 0.108     |
---------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2201       |
|    time_elapsed         | 7152       |
|    total_timesteps      | 4507648    |
| train/                  |            |
|    approx_kl            | 0.12268603 |
|    clip_fraction        | 0.407      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.252      |
|    explained_variance   | 0.882      |
|    learning_rate        | 0.00112    |
|    loss                 | 0.018      |
|    n_updates            | 22000      |
|    policy_gradient_loss | 0.0189     |
|    std                  | 0.216      |
|    value_loss           | 0.028      |
----------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 630       |
|    iterations           | 2202      |
|    time_elapsed         | 7155      |
|    total_timesteps      | 4509696   |
| train/                  |           |
|    approx_kl            | 0.3265406 |
|    clip_fraction        | 0.428     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.232     |
|    explained_variance   | 0.826     |
|    learning_rate        | 0.00112   |
|    loss                 | -0.00485  |
|    n_updates            | 22010     |
|    policy_gradient_loss | 0.0194    |
|    std                  | 0.213     |
|    value_loss           | 0.0153    |
---------------------------------------
Eval num_timesteps=4510000, episode_reward=-0.80 +/- 0.40
Episode length: 300.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 300       |
|    mean_reward          | -0.8      |
| time/                   |           |
|    total_timesteps      | 4510000   |
| train/                  |           |
|    approx_kl            | 0.1336841 |
|    clip_fraction        | 0.374     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.243     |
|    explained_variance   | 0.823     |
|    learning_rate        | 0.00112   |
|    loss                 | 0.0634    |
|    n_updates            | 22020     |
|    policy_gradient_loss | 0.00731   |
|    std                  | 0.216     |
|    value_loss           | 0.00885   |
---------------------------------------
--------------------------------
| time/              |         |
|    fps             | 630     |
|    iterations      | 2203    |
|    time_elapsed    | 7159    |
|    total_timesteps | 4511744 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2204       |
|    time_elapsed         | 7162       |
|    total_timesteps      | 4513792    |
| train/                  |            |
|    approx_kl            | 0.21469453 |
|    clip_fraction        | 0.445      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.264      |
|    explained_variance   | 0.462      |
|    learning_rate        | 0.00112    |
|    loss                 | -0.0238    |
|    n_updates            | 22030      |
|    policy_gradient_loss | 0.000226   |
|    std                  | 0.211      |
|    value_loss           | 0.00518    |
----------------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2205       |
|    time_elapsed         | 7165       |
|    total_timesteps      | 4515840    |
| train/                  |            |
|    approx_kl            | 0.30039406 |
|    clip_fraction        | 0.412      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.275      |
|    explained_variance   | 0.457      |
|    learning_rate        | 0.00112    |
|    loss                 | 0.0158     |
|    n_updates            | 22040      |
|    policy_gradient_loss | 0.00785    |
|    std                  | 0.213      |
|    value_loss           | 0.0101     |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2206       |
|    time_elapsed         | 7168       |
|    total_timesteps      | 4517888    |
| train/                  |            |
|    approx_kl            | 0.68606466 |
|    clip_fraction        | 0.475      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.296      |
|    explained_variance   | 0.423      |
|    learning_rate        | 0.00112    |
|    loss                 | -0.0231    |
|    n_updates            | 22050      |
|    policy_gradient_loss | 0.0112     |
|    std                  | 0.209      |
|    value_loss           | 0.0302     |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2207       |
|    time_elapsed         | 7171       |
|    total_timesteps      | 4519936    |
| train/                  |            |
|    approx_kl            | 0.20948946 |
|    clip_fraction        | 0.464      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.28       |
|    explained_variance   | 0.864      |
|    learning_rate        | 0.00112    |
|    loss                 | -0.0197    |
|    n_updates            | 22060      |
|    policy_gradient_loss | 0.02       |
|    std                  | 0.213      |
|    value_loss           | 0.0116     |
----------------------------------------
box reached target
Eval num_timesteps=4520000, episode_reward=0.34 +/- 2.63
Episode length: 288.40 +/- 23.20
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 288        |
|    mean_reward          | 0.34       |
| time/                   |            |
|    total_timesteps      | 4520000    |
| train/                  |            |
|    approx_kl            | 0.30642068 |
|    clip_fraction        | 0.441      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.273      |
|    explained_variance   | 0.684      |
|    learning_rate        | 0.00112    |
|    loss                 | -0.00884   |
|    n_updates            | 22070      |
|    policy_gradient_loss | 0.00961    |
|    std                  | 0.209      |
|    value_loss           | 0.0113     |
----------------------------------------
box reached target
--------------------------------
| time/              |         |
|    fps             | 630     |
|    iterations      | 2208    |
|    time_elapsed    | 7175    |
|    total_timesteps | 4521984 |
--------------------------------
box reached target
box reached target
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 630       |
|    iterations           | 2209      |
|    time_elapsed         | 7178      |
|    total_timesteps      | 4524032   |
| train/                  |           |
|    approx_kl            | 0.2991451 |
|    clip_fraction        | 0.429     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.285     |
|    explained_variance   | 0.771     |
|    learning_rate        | 0.00112   |
|    loss                 | -0.0201   |
|    n_updates            | 22080     |
|    policy_gradient_loss | 0.00674   |
|    std                  | 0.211     |
|    value_loss           | 0.0213    |
---------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 630       |
|    iterations           | 2210      |
|    time_elapsed         | 7181      |
|    total_timesteps      | 4526080   |
| train/                  |           |
|    approx_kl            | 0.3475476 |
|    clip_fraction        | 0.462     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.272     |
|    explained_variance   | 0.849     |
|    learning_rate        | 0.00112   |
|    loss                 | 0.088     |
|    n_updates            | 22090     |
|    policy_gradient_loss | 0.015     |
|    std                  | 0.212     |
|    value_loss           | 0.0302    |
---------------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2211       |
|    time_elapsed         | 7184       |
|    total_timesteps      | 4528128    |
| train/                  |            |
|    approx_kl            | 0.13000923 |
|    clip_fraction        | 0.404      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.27       |
|    explained_variance   | 0.895      |
|    learning_rate        | 0.00112    |
|    loss                 | 0.0634     |
|    n_updates            | 22100      |
|    policy_gradient_loss | 0.0172     |
|    std                  | 0.213      |
|    value_loss           | 0.032      |
----------------------------------------
box reached target
Eval num_timesteps=4530000, episode_reward=-1.13 +/- 0.19
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1.13      |
| time/                   |            |
|    total_timesteps      | 4530000    |
| train/                  |            |
|    approx_kl            | 0.16508579 |
|    clip_fraction        | 0.45       |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.242      |
|    explained_variance   | 0.653      |
|    learning_rate        | 0.00112    |
|    loss                 | 0.0666     |
|    n_updates            | 22110      |
|    policy_gradient_loss | 0.00347    |
|    std                  | 0.214      |
|    value_loss           | 0.019      |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 630     |
|    iterations      | 2212    |
|    time_elapsed    | 7188    |
|    total_timesteps | 4530176 |
--------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2213       |
|    time_elapsed         | 7191       |
|    total_timesteps      | 4532224    |
| train/                  |            |
|    approx_kl            | 0.17769852 |
|    clip_fraction        | 0.389      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.253      |
|    explained_variance   | 0.855      |
|    learning_rate        | 0.00112    |
|    loss                 | -0.0102    |
|    n_updates            | 22120      |
|    policy_gradient_loss | 0.00511    |
|    std                  | 0.213      |
|    value_loss           | 0.0103     |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2214       |
|    time_elapsed         | 7194       |
|    total_timesteps      | 4534272    |
| train/                  |            |
|    approx_kl            | 0.28460765 |
|    clip_fraction        | 0.467      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.305      |
|    explained_variance   | 0.646      |
|    learning_rate        | 0.00112    |
|    loss                 | -0.0425    |
|    n_updates            | 22130      |
|    policy_gradient_loss | 0.00591    |
|    std                  | 0.206      |
|    value_loss           | 0.0115     |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2215       |
|    time_elapsed         | 7197       |
|    total_timesteps      | 4536320    |
| train/                  |            |
|    approx_kl            | 0.20784444 |
|    clip_fraction        | 0.443      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.366      |
|    explained_variance   | 0.491      |
|    learning_rate        | 0.00112    |
|    loss                 | -0.0116    |
|    n_updates            | 22140      |
|    policy_gradient_loss | -0.000337  |
|    std                  | 0.2        |
|    value_loss           | 0.00884    |
----------------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2216       |
|    time_elapsed         | 7200       |
|    total_timesteps      | 4538368    |
| train/                  |            |
|    approx_kl            | 0.39698482 |
|    clip_fraction        | 0.46       |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.384      |
|    explained_variance   | 0.496      |
|    learning_rate        | 0.00112    |
|    loss                 | 0.041      |
|    n_updates            | 22150      |
|    policy_gradient_loss | 0.013      |
|    std                  | 0.201      |
|    value_loss           | 0.0336     |
----------------------------------------
Eval num_timesteps=4540000, episode_reward=-0.97 +/- 0.11
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -0.97      |
| time/                   |            |
|    total_timesteps      | 4540000    |
| train/                  |            |
|    approx_kl            | 0.46399602 |
|    clip_fraction        | 0.503      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.405      |
|    explained_variance   | 0.533      |
|    learning_rate        | 0.00112    |
|    loss                 | 0.0398     |
|    n_updates            | 22160      |
|    policy_gradient_loss | 0.00407    |
|    std                  | 0.195      |
|    value_loss           | 0.0644     |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 630     |
|    iterations      | 2217    |
|    time_elapsed    | 7204    |
|    total_timesteps | 4540416 |
--------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2218       |
|    time_elapsed         | 7207       |
|    total_timesteps      | 4542464    |
| train/                  |            |
|    approx_kl            | 0.36331224 |
|    clip_fraction        | 0.422      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.413      |
|    explained_variance   | 0.723      |
|    learning_rate        | 0.00111    |
|    loss                 | 0.00776    |
|    n_updates            | 22170      |
|    policy_gradient_loss | 0.00343    |
|    std                  | 0.198      |
|    value_loss           | 0.0104     |
----------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 630       |
|    iterations           | 2219      |
|    time_elapsed         | 7210      |
|    total_timesteps      | 4544512   |
| train/                  |           |
|    approx_kl            | 0.5531475 |
|    clip_fraction        | 0.456     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.394     |
|    explained_variance   | 0.749     |
|    learning_rate        | 0.00111   |
|    loss                 | 0.00366   |
|    n_updates            | 22180     |
|    policy_gradient_loss | 0.0149    |
|    std                  | 0.2       |
|    value_loss           | 0.0218    |
---------------------------------------
box reached target
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2220       |
|    time_elapsed         | 7213       |
|    total_timesteps      | 4546560    |
| train/                  |            |
|    approx_kl            | 0.32211488 |
|    clip_fraction        | 0.473      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.405      |
|    explained_variance   | 0.167      |
|    learning_rate        | 0.00111    |
|    loss                 | 0.000486   |
|    n_updates            | 22190      |
|    policy_gradient_loss | 0.022      |
|    std                  | 0.198      |
|    value_loss           | 0.0625     |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2221       |
|    time_elapsed         | 7217       |
|    total_timesteps      | 4548608    |
| train/                  |            |
|    approx_kl            | 0.26894382 |
|    clip_fraction        | 0.447      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.381      |
|    explained_variance   | 0.795      |
|    learning_rate        | 0.00111    |
|    loss                 | 0.0595     |
|    n_updates            | 22200      |
|    policy_gradient_loss | 0.00765    |
|    std                  | 0.201      |
|    value_loss           | 0.0519     |
----------------------------------------
Eval num_timesteps=4550000, episode_reward=-1.08 +/- 0.15
Episode length: 300.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 300       |
|    mean_reward          | -1.08     |
| time/                   |           |
|    total_timesteps      | 4550000   |
| train/                  |           |
|    approx_kl            | 0.1748153 |
|    clip_fraction        | 0.449     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.331     |
|    explained_variance   | 0.795     |
|    learning_rate        | 0.00111   |
|    loss                 | 0.0604    |
|    n_updates            | 22210     |
|    policy_gradient_loss | 0.02      |
|    std                  | 0.208     |
|    value_loss           | 0.0281    |
---------------------------------------
--------------------------------
| time/              |         |
|    fps             | 630     |
|    iterations      | 2222    |
|    time_elapsed    | 7221    |
|    total_timesteps | 4550656 |
--------------------------------
box reached target
box reached target
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2223       |
|    time_elapsed         | 7224       |
|    total_timesteps      | 4552704    |
| train/                  |            |
|    approx_kl            | 0.47047722 |
|    clip_fraction        | 0.434      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.351      |
|    explained_variance   | 0.251      |
|    learning_rate        | 0.00111    |
|    loss                 | 0.00739    |
|    n_updates            | 22220      |
|    policy_gradient_loss | -0.000955  |
|    std                  | 0.201      |
|    value_loss           | 0.00749    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2224       |
|    time_elapsed         | 7227       |
|    total_timesteps      | 4554752    |
| train/                  |            |
|    approx_kl            | 0.44660026 |
|    clip_fraction        | 0.446      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.409      |
|    explained_variance   | 0.754      |
|    learning_rate        | 0.00111    |
|    loss                 | -0.0152    |
|    n_updates            | 22230      |
|    policy_gradient_loss | 0.00973    |
|    std                  | 0.193      |
|    value_loss           | 0.0411     |
----------------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2225       |
|    time_elapsed         | 7230       |
|    total_timesteps      | 4556800    |
| train/                  |            |
|    approx_kl            | 0.17044277 |
|    clip_fraction        | 0.42       |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.427      |
|    explained_variance   | 0.805      |
|    learning_rate        | 0.00111    |
|    loss                 | -0.00721   |
|    n_updates            | 22240      |
|    policy_gradient_loss | 0.0128     |
|    std                  | 0.198      |
|    value_loss           | 0.0134     |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2226       |
|    time_elapsed         | 7233       |
|    total_timesteps      | 4558848    |
| train/                  |            |
|    approx_kl            | 0.29890376 |
|    clip_fraction        | 0.45       |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.39       |
|    explained_variance   | 0.723      |
|    learning_rate        | 0.00111    |
|    loss                 | -0.0387    |
|    n_updates            | 22250      |
|    policy_gradient_loss | 0.012      |
|    std                  | 0.2        |
|    value_loss           | 0.0512     |
----------------------------------------
box reached target
Eval num_timesteps=4560000, episode_reward=0.35 +/- 2.42
Episode length: 282.60 +/- 34.80
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 283        |
|    mean_reward          | 0.353      |
| time/                   |            |
|    total_timesteps      | 4560000    |
| train/                  |            |
|    approx_kl            | 0.33142585 |
|    clip_fraction        | 0.467      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.364      |
|    explained_variance   | 0.649      |
|    learning_rate        | 0.00111    |
|    loss                 | 0.0466     |
|    n_updates            | 22260      |
|    policy_gradient_loss | 0.0169     |
|    std                  | 0.204      |
|    value_loss           | 0.0249     |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 630     |
|    iterations      | 2227    |
|    time_elapsed    | 7237    |
|    total_timesteps | 4560896 |
--------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2228       |
|    time_elapsed         | 7240       |
|    total_timesteps      | 4562944    |
| train/                  |            |
|    approx_kl            | 0.24707866 |
|    clip_fraction        | 0.374      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.376      |
|    explained_variance   | 0.274      |
|    learning_rate        | 0.00111    |
|    loss                 | -0.00166   |
|    n_updates            | 22270      |
|    policy_gradient_loss | -0.00413   |
|    std                  | 0.199      |
|    value_loss           | 0.0142     |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2229       |
|    time_elapsed         | 7243       |
|    total_timesteps      | 4564992    |
| train/                  |            |
|    approx_kl            | 0.16847718 |
|    clip_fraction        | 0.4        |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.37       |
|    explained_variance   | 0.922      |
|    learning_rate        | 0.00111    |
|    loss                 | 0.0645     |
|    n_updates            | 22280      |
|    policy_gradient_loss | 0.00653    |
|    std                  | 0.203      |
|    value_loss           | 0.01       |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2230       |
|    time_elapsed         | 7246       |
|    total_timesteps      | 4567040    |
| train/                  |            |
|    approx_kl            | 0.19646502 |
|    clip_fraction        | 0.471      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.322      |
|    explained_variance   | 0.639      |
|    learning_rate        | 0.00111    |
|    loss                 | -0.00701   |
|    n_updates            | 22290      |
|    policy_gradient_loss | 0.0127     |
|    std                  | 0.209      |
|    value_loss           | 0.0189     |
----------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 630       |
|    iterations           | 2231      |
|    time_elapsed         | 7249      |
|    total_timesteps      | 4569088   |
| train/                  |           |
|    approx_kl            | 1.1319121 |
|    clip_fraction        | 0.493     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.283     |
|    explained_variance   | 0.723     |
|    learning_rate        | 0.00111   |
|    loss                 | 0.0279    |
|    n_updates            | 22300     |
|    policy_gradient_loss | 0.0357    |
|    std                  | 0.206     |
|    value_loss           | 0.0218    |
---------------------------------------
box reached target
Eval num_timesteps=4570000, episode_reward=-0.82 +/- 0.27
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -0.823     |
| time/                   |            |
|    total_timesteps      | 4570000    |
| train/                  |            |
|    approx_kl            | 0.13923565 |
|    clip_fraction        | 0.486      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.259      |
|    explained_variance   | 0.96       |
|    learning_rate        | 0.00111    |
|    loss                 | 0.0294     |
|    n_updates            | 22310      |
|    policy_gradient_loss | 0.0235     |
|    std                  | 0.216      |
|    value_loss           | 0.00504    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 630     |
|    iterations      | 2232    |
|    time_elapsed    | 7253    |
|    total_timesteps | 4571136 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2233       |
|    time_elapsed         | 7256       |
|    total_timesteps      | 4573184    |
| train/                  |            |
|    approx_kl            | 0.11988471 |
|    clip_fraction        | 0.381      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.256      |
|    explained_variance   | 0.738      |
|    learning_rate        | 0.00111    |
|    loss                 | -0.038     |
|    n_updates            | 22320      |
|    policy_gradient_loss | 0.0177     |
|    std                  | 0.211      |
|    value_loss           | 0.0122     |
----------------------------------------
box reached target
--------------------------------------
| time/                   |          |
|    fps                  | 630      |
|    iterations           | 2234     |
|    time_elapsed         | 7259     |
|    total_timesteps      | 4575232  |
| train/                  |          |
|    approx_kl            | 0.258487 |
|    clip_fraction        | 0.416    |
|    clip_range           | 0.2      |
|    entropy_loss         | 0.27     |
|    explained_variance   | 0.543    |
|    learning_rate        | 0.00111  |
|    loss                 | 0.0152   |
|    n_updates            | 22330    |
|    policy_gradient_loss | 0.00709  |
|    std                  | 0.212    |
|    value_loss           | 0.00551  |
--------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 630       |
|    iterations           | 2235      |
|    time_elapsed         | 7262      |
|    total_timesteps      | 4577280   |
| train/                  |           |
|    approx_kl            | 0.2799099 |
|    clip_fraction        | 0.449     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.276     |
|    explained_variance   | 0.805     |
|    learning_rate        | 0.00111   |
|    loss                 | -0.0268   |
|    n_updates            | 22340     |
|    policy_gradient_loss | 0.00879   |
|    std                  | 0.21      |
|    value_loss           | 0.0242    |
---------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 630       |
|    iterations           | 2236      |
|    time_elapsed         | 7265      |
|    total_timesteps      | 4579328   |
| train/                  |           |
|    approx_kl            | 0.5915843 |
|    clip_fraction        | 0.432     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.277     |
|    explained_variance   | 0.284     |
|    learning_rate        | 0.00111   |
|    loss                 | -0.0126   |
|    n_updates            | 22350     |
|    policy_gradient_loss | 0.00502   |
|    std                  | 0.209     |
|    value_loss           | 0.0066    |
---------------------------------------
Eval num_timesteps=4580000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 300       |
|    mean_reward          | -1        |
| time/                   |           |
|    total_timesteps      | 4580000   |
| train/                  |           |
|    approx_kl            | 0.3720438 |
|    clip_fraction        | 0.452     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.31      |
|    explained_variance   | 0.839     |
|    learning_rate        | 0.00111   |
|    loss                 | 0.0374    |
|    n_updates            | 22360     |
|    policy_gradient_loss | 0.0047    |
|    std                  | 0.207     |
|    value_loss           | 0.0133    |
---------------------------------------
box reached target
box reached target
box reached target
--------------------------------
| time/              |         |
|    fps             | 630     |
|    iterations      | 2237    |
|    time_elapsed    | 7269    |
|    total_timesteps | 4581376 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2238       |
|    time_elapsed         | 7272       |
|    total_timesteps      | 4583424    |
| train/                  |            |
|    approx_kl            | 0.22586213 |
|    clip_fraction        | 0.439      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.305      |
|    explained_variance   | 0.602      |
|    learning_rate        | 0.00111    |
|    loss                 | -0.0293    |
|    n_updates            | 22370      |
|    policy_gradient_loss | 0.00549    |
|    std                  | 0.208      |
|    value_loss           | 0.0668     |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2239       |
|    time_elapsed         | 7275       |
|    total_timesteps      | 4585472    |
| train/                  |            |
|    approx_kl            | 0.23374663 |
|    clip_fraction        | 0.421      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.287      |
|    explained_variance   | 0.724      |
|    learning_rate        | 0.00111    |
|    loss                 | -0.0331    |
|    n_updates            | 22380      |
|    policy_gradient_loss | 0.0111     |
|    std                  | 0.212      |
|    value_loss           | 0.00879    |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2240       |
|    time_elapsed         | 7278       |
|    total_timesteps      | 4587520    |
| train/                  |            |
|    approx_kl            | 0.26905358 |
|    clip_fraction        | 0.439      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.32       |
|    explained_variance   | 0.586      |
|    learning_rate        | 0.00111    |
|    loss                 | -0.0271    |
|    n_updates            | 22390      |
|    policy_gradient_loss | -0.00127   |
|    std                  | 0.202      |
|    value_loss           | 0.00832    |
----------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 630       |
|    iterations           | 2241      |
|    time_elapsed         | 7281      |
|    total_timesteps      | 4589568   |
| train/                  |           |
|    approx_kl            | 0.2558248 |
|    clip_fraction        | 0.434     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.361     |
|    explained_variance   | 0.632     |
|    learning_rate        | 0.00111   |
|    loss                 | -0.000479 |
|    n_updates            | 22400     |
|    policy_gradient_loss | 0.012     |
|    std                  | 0.203     |
|    value_loss           | 0.0109    |
---------------------------------------
box reached target
Eval num_timesteps=4590000, episode_reward=0.31 +/- 2.45
Episode length: 274.00 +/- 52.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 274        |
|    mean_reward          | 0.307      |
| time/                   |            |
|    total_timesteps      | 4590000    |
| train/                  |            |
|    approx_kl            | 0.24192704 |
|    clip_fraction        | 0.455      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.343      |
|    explained_variance   | 0.894      |
|    learning_rate        | 0.00111    |
|    loss                 | -0.00645   |
|    n_updates            | 22410      |
|    policy_gradient_loss | 0.0243     |
|    std                  | 0.205      |
|    value_loss           | 0.0158     |
----------------------------------------
box reached target
--------------------------------
| time/              |         |
|    fps             | 630     |
|    iterations      | 2242    |
|    time_elapsed    | 7285    |
|    total_timesteps | 4591616 |
--------------------------------
box reached target
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2243       |
|    time_elapsed         | 7288       |
|    total_timesteps      | 4593664    |
| train/                  |            |
|    approx_kl            | 0.21000054 |
|    clip_fraction        | 0.425      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.354      |
|    explained_variance   | 0.694      |
|    learning_rate        | 0.0011     |
|    loss                 | -0.0385    |
|    n_updates            | 22420      |
|    policy_gradient_loss | 0.00897    |
|    std                  | 0.202      |
|    value_loss           | 0.0176     |
----------------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2244       |
|    time_elapsed         | 7291       |
|    total_timesteps      | 4595712    |
| train/                  |            |
|    approx_kl            | 0.20771238 |
|    clip_fraction        | 0.426      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.366      |
|    explained_variance   | 0.795      |
|    learning_rate        | 0.0011     |
|    loss                 | -0.0124    |
|    n_updates            | 22430      |
|    policy_gradient_loss | 0.0134     |
|    std                  | 0.202      |
|    value_loss           | 0.0324     |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2245       |
|    time_elapsed         | 7294       |
|    total_timesteps      | 4597760    |
| train/                  |            |
|    approx_kl            | 0.53160745 |
|    clip_fraction        | 0.491      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.348      |
|    explained_variance   | 0.885      |
|    learning_rate        | 0.0011     |
|    loss                 | -0.00695   |
|    n_updates            | 22440      |
|    policy_gradient_loss | 0.00281    |
|    std                  | 0.204      |
|    value_loss           | 0.0126     |
----------------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2246       |
|    time_elapsed         | 7297       |
|    total_timesteps      | 4599808    |
| train/                  |            |
|    approx_kl            | 0.33019093 |
|    clip_fraction        | 0.433      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.346      |
|    explained_variance   | 0.722      |
|    learning_rate        | 0.0011     |
|    loss                 | 0.0286     |
|    n_updates            | 22450      |
|    policy_gradient_loss | 0.0115     |
|    std                  | 0.204      |
|    value_loss           | 0.0157     |
----------------------------------------
box reached target
Eval num_timesteps=4600000, episode_reward=0.79 +/- 2.28
Episode length: 278.60 +/- 42.80
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 279       |
|    mean_reward          | 0.79      |
| time/                   |           |
|    total_timesteps      | 4600000   |
| train/                  |           |
|    approx_kl            | 0.1366105 |
|    clip_fraction        | 0.423     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.344     |
|    explained_variance   | 0.804     |
|    learning_rate        | 0.0011    |
|    loss                 | 0.00124   |
|    n_updates            | 22460     |
|    policy_gradient_loss | 0.0144    |
|    std                  | 0.205     |
|    value_loss           | 0.0136    |
---------------------------------------
--------------------------------
| time/              |         |
|    fps             | 630     |
|    iterations      | 2247    |
|    time_elapsed    | 7301    |
|    total_timesteps | 4601856 |
--------------------------------
box reached target
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2248       |
|    time_elapsed         | 7304       |
|    total_timesteps      | 4603904    |
| train/                  |            |
|    approx_kl            | 0.37283778 |
|    clip_fraction        | 0.48       |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.33       |
|    explained_variance   | 0.643      |
|    learning_rate        | 0.0011     |
|    loss                 | -0.00859   |
|    n_updates            | 22470      |
|    policy_gradient_loss | 0.0131     |
|    std                  | 0.206      |
|    value_loss           | 0.00377    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2249       |
|    time_elapsed         | 7307       |
|    total_timesteps      | 4605952    |
| train/                  |            |
|    approx_kl            | 0.32510573 |
|    clip_fraction        | 0.456      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.342      |
|    explained_variance   | 0.916      |
|    learning_rate        | 0.0011     |
|    loss                 | -0.0281    |
|    n_updates            | 22480      |
|    policy_gradient_loss | 0.0124     |
|    std                  | 0.205      |
|    value_loss           | 0.0325     |
----------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 630       |
|    iterations           | 2250      |
|    time_elapsed         | 7310      |
|    total_timesteps      | 4608000   |
| train/                  |           |
|    approx_kl            | 0.2529993 |
|    clip_fraction        | 0.44      |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.287     |
|    explained_variance   | 0.709     |
|    learning_rate        | 0.0011    |
|    loss                 | -0.0261   |
|    n_updates            | 22490     |
|    policy_gradient_loss | 0.00311   |
|    std                  | 0.212     |
|    value_loss           | 0.0163    |
---------------------------------------
box reached target
box reached target
Eval num_timesteps=4610000, episode_reward=0.19 +/- 2.49
Episode length: 274.60 +/- 50.80
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 275        |
|    mean_reward          | 0.194      |
| time/                   |            |
|    total_timesteps      | 4610000    |
| train/                  |            |
|    approx_kl            | 0.32945567 |
|    clip_fraction        | 0.454      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.264      |
|    explained_variance   | 0.597      |
|    learning_rate        | 0.0011     |
|    loss                 | 0.0754     |
|    n_updates            | 22500      |
|    policy_gradient_loss | 0.0534     |
|    std                  | 0.212      |
|    value_loss           | 0.074      |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 630     |
|    iterations      | 2251    |
|    time_elapsed    | 7314    |
|    total_timesteps | 4610048 |
--------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 630       |
|    iterations           | 2252      |
|    time_elapsed         | 7317      |
|    total_timesteps      | 4612096   |
| train/                  |           |
|    approx_kl            | 0.2320727 |
|    clip_fraction        | 0.43      |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.311     |
|    explained_variance   | 0.76      |
|    learning_rate        | 0.0011    |
|    loss                 | -0.0318   |
|    n_updates            | 22510     |
|    policy_gradient_loss | 0.00944   |
|    std                  | 0.205     |
|    value_loss           | 0.0458    |
---------------------------------------
box reached target
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 630       |
|    iterations           | 2253      |
|    time_elapsed         | 7320      |
|    total_timesteps      | 4614144   |
| train/                  |           |
|    approx_kl            | 0.1903491 |
|    clip_fraction        | 0.438     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.314     |
|    explained_variance   | 0.66      |
|    learning_rate        | 0.0011    |
|    loss                 | -0.0139   |
|    n_updates            | 22520     |
|    policy_gradient_loss | 0.00473   |
|    std                  | 0.207     |
|    value_loss           | 0.0109    |
---------------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2254       |
|    time_elapsed         | 7323       |
|    total_timesteps      | 4616192    |
| train/                  |            |
|    approx_kl            | 0.15814303 |
|    clip_fraction        | 0.432      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.283      |
|    explained_variance   | 0.911      |
|    learning_rate        | 0.0011     |
|    loss                 | -0.0161    |
|    n_updates            | 22530      |
|    policy_gradient_loss | 0.00666    |
|    std                  | 0.212      |
|    value_loss           | 0.0219     |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2255       |
|    time_elapsed         | 7326       |
|    total_timesteps      | 4618240    |
| train/                  |            |
|    approx_kl            | 0.15056711 |
|    clip_fraction        | 0.393      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.279      |
|    explained_variance   | 0.94       |
|    learning_rate        | 0.0011     |
|    loss                 | 0.0255     |
|    n_updates            | 22540      |
|    policy_gradient_loss | 0.00749    |
|    std                  | 0.209      |
|    value_loss           | 0.0109     |
----------------------------------------
box reached target
Eval num_timesteps=4620000, episode_reward=-0.89 +/- 0.23
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -0.887     |
| time/                   |            |
|    total_timesteps      | 4620000    |
| train/                  |            |
|    approx_kl            | 0.28469992 |
|    clip_fraction        | 0.435      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.281      |
|    explained_variance   | 0.617      |
|    learning_rate        | 0.0011     |
|    loss                 | -0.0199    |
|    n_updates            | 22550      |
|    policy_gradient_loss | 0.0115     |
|    std                  | 0.21       |
|    value_loss           | 0.00996    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 630     |
|    iterations      | 2256    |
|    time_elapsed    | 7330    |
|    total_timesteps | 4620288 |
--------------------------------
box reached target
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 630       |
|    iterations           | 2257      |
|    time_elapsed         | 7333      |
|    total_timesteps      | 4622336   |
| train/                  |           |
|    approx_kl            | 0.2534606 |
|    clip_fraction        | 0.432     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.292     |
|    explained_variance   | 0.208     |
|    learning_rate        | 0.0011    |
|    loss                 | 0.0184    |
|    n_updates            | 22560     |
|    policy_gradient_loss | 0.0243    |
|    std                  | 0.209     |
|    value_loss           | 0.0805    |
---------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2258       |
|    time_elapsed         | 7336       |
|    total_timesteps      | 4624384    |
| train/                  |            |
|    approx_kl            | 0.41762915 |
|    clip_fraction        | 0.447      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.293      |
|    explained_variance   | 0.895      |
|    learning_rate        | 0.0011     |
|    loss                 | 0.0121     |
|    n_updates            | 22570      |
|    policy_gradient_loss | 0.00634    |
|    std                  | 0.21       |
|    value_loss           | 0.0163     |
----------------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2259       |
|    time_elapsed         | 7340       |
|    total_timesteps      | 4626432    |
| train/                  |            |
|    approx_kl            | 0.19786716 |
|    clip_fraction        | 0.453      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.268      |
|    explained_variance   | 0.735      |
|    learning_rate        | 0.0011     |
|    loss                 | -0.0213    |
|    n_updates            | 22580      |
|    policy_gradient_loss | 0.0133     |
|    std                  | 0.214      |
|    value_loss           | 0.0128     |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2260       |
|    time_elapsed         | 7343       |
|    total_timesteps      | 4628480    |
| train/                  |            |
|    approx_kl            | 0.21739927 |
|    clip_fraction        | 0.44       |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.246      |
|    explained_variance   | 0.619      |
|    learning_rate        | 0.0011     |
|    loss                 | -0.000243  |
|    n_updates            | 22590      |
|    policy_gradient_loss | 0.00997    |
|    std                  | 0.215      |
|    value_loss           | 0.045      |
----------------------------------------
Eval num_timesteps=4630000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1         |
| time/                   |            |
|    total_timesteps      | 4630000    |
| train/                  |            |
|    approx_kl            | 0.17709747 |
|    clip_fraction        | 0.402      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.258      |
|    explained_variance   | 0.602      |
|    learning_rate        | 0.0011     |
|    loss                 | 0.104      |
|    n_updates            | 22600      |
|    policy_gradient_loss | 0.0149     |
|    std                  | 0.212      |
|    value_loss           | 0.0226     |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 630     |
|    iterations      | 2261    |
|    time_elapsed    | 7347    |
|    total_timesteps | 4630528 |
--------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2262       |
|    time_elapsed         | 7350       |
|    total_timesteps      | 4632576    |
| train/                  |            |
|    approx_kl            | 0.19744006 |
|    clip_fraction        | 0.388      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.276      |
|    explained_variance   | 0.636      |
|    learning_rate        | 0.0011     |
|    loss                 | -0.0106    |
|    n_updates            | 22610      |
|    policy_gradient_loss | 0.00745    |
|    std                  | 0.212      |
|    value_loss           | 0.0684     |
----------------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2263       |
|    time_elapsed         | 7353       |
|    total_timesteps      | 4634624    |
| train/                  |            |
|    approx_kl            | 0.22987702 |
|    clip_fraction        | 0.449      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.22       |
|    explained_variance   | 0.827      |
|    learning_rate        | 0.0011     |
|    loss                 | -0.0402    |
|    n_updates            | 22620      |
|    policy_gradient_loss | 0.00977    |
|    std                  | 0.219      |
|    value_loss           | 0.0166     |
----------------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2264       |
|    time_elapsed         | 7356       |
|    total_timesteps      | 4636672    |
| train/                  |            |
|    approx_kl            | 0.20032382 |
|    clip_fraction        | 0.403      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.194      |
|    explained_variance   | 0.949      |
|    learning_rate        | 0.0011     |
|    loss                 | -0.0239    |
|    n_updates            | 22630      |
|    policy_gradient_loss | 0.022      |
|    std                  | 0.218      |
|    value_loss           | 0.00846    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2265       |
|    time_elapsed         | 7359       |
|    total_timesteps      | 4638720    |
| train/                  |            |
|    approx_kl            | 0.13852769 |
|    clip_fraction        | 0.426      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.228      |
|    explained_variance   | 0.309      |
|    learning_rate        | 0.0011     |
|    loss                 | 0.0264     |
|    n_updates            | 22640      |
|    policy_gradient_loss | 0.0145     |
|    std                  | 0.215      |
|    value_loss           | 0.0654     |
----------------------------------------
box reached target
box reached target
Eval num_timesteps=4640000, episode_reward=0.23 +/- 2.46
Episode length: 273.60 +/- 52.80
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 274       |
|    mean_reward          | 0.228     |
| time/                   |           |
|    total_timesteps      | 4640000   |
| train/                  |           |
|    approx_kl            | 0.3532123 |
|    clip_fraction        | 0.438     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.207     |
|    explained_variance   | 0.683     |
|    learning_rate        | 0.0011    |
|    loss                 | -0.0352   |
|    n_updates            | 22650     |
|    policy_gradient_loss | 0.00962   |
|    std                  | 0.22      |
|    value_loss           | 0.00628   |
---------------------------------------
box reached target
--------------------------------
| time/              |         |
|    fps             | 630     |
|    iterations      | 2266    |
|    time_elapsed    | 7363    |
|    total_timesteps | 4640768 |
--------------------------------
box reached target
--------------------------------------
| time/                   |          |
|    fps                  | 630      |
|    iterations           | 2267     |
|    time_elapsed         | 7366     |
|    total_timesteps      | 4642816  |
| train/                  |          |
|    approx_kl            | 0.321989 |
|    clip_fraction        | 0.427    |
|    clip_range           | 0.2      |
|    entropy_loss         | 0.187    |
|    explained_variance   | 0.912    |
|    learning_rate        | 0.0011   |
|    loss                 | 0.0541   |
|    n_updates            | 22660    |
|    policy_gradient_loss | 0.00213  |
|    std                  | 0.218    |
|    value_loss           | 0.0212   |
--------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2268       |
|    time_elapsed         | 7369       |
|    total_timesteps      | 4644864    |
| train/                  |            |
|    approx_kl            | 0.18153042 |
|    clip_fraction        | 0.435      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.178      |
|    explained_variance   | 0.713      |
|    learning_rate        | 0.00109    |
|    loss                 | -0.0571    |
|    n_updates            | 22670      |
|    policy_gradient_loss | 0.00765    |
|    std                  | 0.223      |
|    value_loss           | 0.018      |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2269       |
|    time_elapsed         | 7372       |
|    total_timesteps      | 4646912    |
| train/                  |            |
|    approx_kl            | 0.27124596 |
|    clip_fraction        | 0.406      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.232      |
|    explained_variance   | 0.0411     |
|    learning_rate        | 0.00109    |
|    loss                 | 0.00652    |
|    n_updates            | 22680      |
|    policy_gradient_loss | 0.00203    |
|    std                  | 0.21       |
|    value_loss           | 0.0159     |
----------------------------------------
box reached target
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 630       |
|    iterations           | 2270      |
|    time_elapsed         | 7375      |
|    total_timesteps      | 4648960   |
| train/                  |           |
|    approx_kl            | 0.465559  |
|    clip_fraction        | 0.416     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.277     |
|    explained_variance   | 0.556     |
|    learning_rate        | 0.00109   |
|    loss                 | -0.0144   |
|    n_updates            | 22690     |
|    policy_gradient_loss | -0.000279 |
|    std                  | 0.21      |
|    value_loss           | 0.014     |
---------------------------------------
Eval num_timesteps=4650000, episode_reward=-1.06 +/- 0.11
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1.06      |
| time/                   |            |
|    total_timesteps      | 4650000    |
| train/                  |            |
|    approx_kl            | 0.17578977 |
|    clip_fraction        | 0.394      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.295      |
|    explained_variance   | 0.901      |
|    learning_rate        | 0.00109    |
|    loss                 | -0.00632   |
|    n_updates            | 22700      |
|    policy_gradient_loss | -0.00309   |
|    std                  | 0.208      |
|    value_loss           | 0.0116     |
----------------------------------------
box reached target
--------------------------------
| time/              |         |
|    fps             | 630     |
|    iterations      | 2271    |
|    time_elapsed    | 7379    |
|    total_timesteps | 4651008 |
--------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2272       |
|    time_elapsed         | 7382       |
|    total_timesteps      | 4653056    |
| train/                  |            |
|    approx_kl            | 0.17518792 |
|    clip_fraction        | 0.439      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.298      |
|    explained_variance   | 0.939      |
|    learning_rate        | 0.00109    |
|    loss                 | 0.0575     |
|    n_updates            | 22710      |
|    policy_gradient_loss | 0.00678    |
|    std                  | 0.207      |
|    value_loss           | 0.0134     |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2273       |
|    time_elapsed         | 7385       |
|    total_timesteps      | 4655104    |
| train/                  |            |
|    approx_kl            | 0.17856874 |
|    clip_fraction        | 0.395      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.305      |
|    explained_variance   | 0.817      |
|    learning_rate        | 0.00109    |
|    loss                 | 0.0163     |
|    n_updates            | 22720      |
|    policy_gradient_loss | 0.00647    |
|    std                  | 0.207      |
|    value_loss           | 0.0177     |
----------------------------------------
box reached target
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 630       |
|    iterations           | 2274      |
|    time_elapsed         | 7388      |
|    total_timesteps      | 4657152   |
| train/                  |           |
|    approx_kl            | 0.2695797 |
|    clip_fraction        | 0.478     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.324     |
|    explained_variance   | 0.646     |
|    learning_rate        | 0.00109   |
|    loss                 | -0.00837  |
|    n_updates            | 22730     |
|    policy_gradient_loss | 0.0168    |
|    std                  | 0.205     |
|    value_loss           | 0.0219    |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2275       |
|    time_elapsed         | 7391       |
|    total_timesteps      | 4659200    |
| train/                  |            |
|    approx_kl            | 0.20315063 |
|    clip_fraction        | 0.425      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.325      |
|    explained_variance   | 0.759      |
|    learning_rate        | 0.00109    |
|    loss                 | -0.0281    |
|    n_updates            | 22740      |
|    policy_gradient_loss | 0.0171     |
|    std                  | 0.206      |
|    value_loss           | 0.029      |
----------------------------------------
box reached target
Eval num_timesteps=4660000, episode_reward=-0.57 +/- 0.52
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -0.572     |
| time/                   |            |
|    total_timesteps      | 4660000    |
| train/                  |            |
|    approx_kl            | 0.26894015 |
|    clip_fraction        | 0.427      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.313      |
|    explained_variance   | 0.712      |
|    learning_rate        | 0.00109    |
|    loss                 | 0.0136     |
|    n_updates            | 22750      |
|    policy_gradient_loss | 0.0073     |
|    std                  | 0.205      |
|    value_loss           | 0.0166     |
----------------------------------------
box reached target
--------------------------------
| time/              |         |
|    fps             | 630     |
|    iterations      | 2276    |
|    time_elapsed    | 7395    |
|    total_timesteps | 4661248 |
--------------------------------
box reached target
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 630       |
|    iterations           | 2277      |
|    time_elapsed         | 7398      |
|    total_timesteps      | 4663296   |
| train/                  |           |
|    approx_kl            | 0.2620201 |
|    clip_fraction        | 0.469     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.335     |
|    explained_variance   | 0.925     |
|    learning_rate        | 0.00109   |
|    loss                 | 0.0061    |
|    n_updates            | 22760     |
|    policy_gradient_loss | 0.00677   |
|    std                  | 0.203     |
|    value_loss           | 0.0165    |
---------------------------------------
box reached target
box reached target
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 630         |
|    iterations           | 2278        |
|    time_elapsed         | 7401        |
|    total_timesteps      | 4665344     |
| train/                  |             |
|    approx_kl            | 0.114562064 |
|    clip_fraction        | 0.396       |
|    clip_range           | 0.2         |
|    entropy_loss         | 0.356       |
|    explained_variance   | 0.659       |
|    learning_rate        | 0.00109     |
|    loss                 | 0.085       |
|    n_updates            | 22770       |
|    policy_gradient_loss | 0.00989     |
|    std                  | 0.201       |
|    value_loss           | 0.0727      |
-----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2279       |
|    time_elapsed         | 7404       |
|    total_timesteps      | 4667392    |
| train/                  |            |
|    approx_kl            | 0.23258102 |
|    clip_fraction        | 0.419      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.392      |
|    explained_variance   | 0.784      |
|    learning_rate        | 0.00109    |
|    loss                 | 0.00288    |
|    n_updates            | 22780      |
|    policy_gradient_loss | 0.0193     |
|    std                  | 0.197      |
|    value_loss           | 0.0272     |
----------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 630       |
|    iterations           | 2280      |
|    time_elapsed         | 7407      |
|    total_timesteps      | 4669440   |
| train/                  |           |
|    approx_kl            | 0.2642911 |
|    clip_fraction        | 0.42      |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.409     |
|    explained_variance   | 0.355     |
|    learning_rate        | 0.00109   |
|    loss                 | 0.0181    |
|    n_updates            | 22790     |
|    policy_gradient_loss | 0.0172    |
|    std                  | 0.196     |
|    value_loss           | 0.0102    |
---------------------------------------
box reached target
Eval num_timesteps=4670000, episode_reward=0.40 +/- 2.40
Episode length: 273.60 +/- 52.80
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 274        |
|    mean_reward          | 0.405      |
| time/                   |            |
|    total_timesteps      | 4670000    |
| train/                  |            |
|    approx_kl            | 0.23921934 |
|    clip_fraction        | 0.486      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.385      |
|    explained_variance   | 0.713      |
|    learning_rate        | 0.00109    |
|    loss                 | -0.0206    |
|    n_updates            | 22800      |
|    policy_gradient_loss | 0.0288     |
|    std                  | 0.2        |
|    value_loss           | 0.033      |
----------------------------------------
box reached target
--------------------------------
| time/              |         |
|    fps             | 630     |
|    iterations      | 2281    |
|    time_elapsed    | 7411    |
|    total_timesteps | 4671488 |
--------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2282       |
|    time_elapsed         | 7414       |
|    total_timesteps      | 4673536    |
| train/                  |            |
|    approx_kl            | 0.12460957 |
|    clip_fraction        | 0.413      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.338      |
|    explained_variance   | 0.867      |
|    learning_rate        | 0.00109    |
|    loss                 | 0.00847    |
|    n_updates            | 22810      |
|    policy_gradient_loss | 0.00491    |
|    std                  | 0.207      |
|    value_loss           | 0.0303     |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2283       |
|    time_elapsed         | 7417       |
|    total_timesteps      | 4675584    |
| train/                  |            |
|    approx_kl            | 0.38083985 |
|    clip_fraction        | 0.48       |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.317      |
|    explained_variance   | 0.74       |
|    learning_rate        | 0.00109    |
|    loss                 | -0.00557   |
|    n_updates            | 22820      |
|    policy_gradient_loss | 0.013      |
|    std                  | 0.202      |
|    value_loss           | 0.046      |
----------------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2284       |
|    time_elapsed         | 7420       |
|    total_timesteps      | 4677632    |
| train/                  |            |
|    approx_kl            | 0.12580666 |
|    clip_fraction        | 0.402      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.329      |
|    explained_variance   | 0.399      |
|    learning_rate        | 0.00109    |
|    loss                 | -0.00375   |
|    n_updates            | 22830      |
|    policy_gradient_loss | 0.0135     |
|    std                  | 0.204      |
|    value_loss           | 0.0051     |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2285       |
|    time_elapsed         | 7423       |
|    total_timesteps      | 4679680    |
| train/                  |            |
|    approx_kl            | 0.18520674 |
|    clip_fraction        | 0.434      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.344      |
|    explained_variance   | 0.806      |
|    learning_rate        | 0.00109    |
|    loss                 | -0.0153    |
|    n_updates            | 22840      |
|    policy_gradient_loss | 0.0245     |
|    std                  | 0.204      |
|    value_loss           | 0.0258     |
----------------------------------------
Eval num_timesteps=4680000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1         |
| time/                   |            |
|    total_timesteps      | 4680000    |
| train/                  |            |
|    approx_kl            | 0.19298644 |
|    clip_fraction        | 0.391      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.314      |
|    explained_variance   | 0.719      |
|    learning_rate        | 0.00109    |
|    loss                 | -0.0429    |
|    n_updates            | 22850      |
|    policy_gradient_loss | 0.00873    |
|    std                  | 0.206      |
|    value_loss           | 0.00414    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 630     |
|    iterations      | 2286    |
|    time_elapsed    | 7427    |
|    total_timesteps | 4681728 |
--------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 630       |
|    iterations           | 2287      |
|    time_elapsed         | 7430      |
|    total_timesteps      | 4683776   |
| train/                  |           |
|    approx_kl            | 0.3407998 |
|    clip_fraction        | 0.426     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.31      |
|    explained_variance   | 0.706     |
|    learning_rate        | 0.00109   |
|    loss                 | 0.0954    |
|    n_updates            | 22860     |
|    policy_gradient_loss | 0.019     |
|    std                  | 0.209     |
|    value_loss           | 0.0177    |
---------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 630       |
|    iterations           | 2288      |
|    time_elapsed         | 7433      |
|    total_timesteps      | 4685824   |
| train/                  |           |
|    approx_kl            | 0.3848961 |
|    clip_fraction        | 0.456     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.284     |
|    explained_variance   | 0.679     |
|    learning_rate        | 0.00109   |
|    loss                 | 0.14      |
|    n_updates            | 22870     |
|    policy_gradient_loss | 0.00871   |
|    std                  | 0.209     |
|    value_loss           | 0.0172    |
---------------------------------------
--------------------------------------
| time/                   |          |
|    fps                  | 630      |
|    iterations           | 2289     |
|    time_elapsed         | 7437     |
|    total_timesteps      | 4687872  |
| train/                  |          |
|    approx_kl            | 0.401643 |
|    clip_fraction        | 0.418    |
|    clip_range           | 0.2      |
|    entropy_loss         | 0.26     |
|    explained_variance   | 0.758    |
|    learning_rate        | 0.00109  |
|    loss                 | -0.0107  |
|    n_updates            | 22880    |
|    policy_gradient_loss | 0.0109   |
|    std                  | 0.212    |
|    value_loss           | 0.00469  |
--------------------------------------
box reached target
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 630       |
|    iterations           | 2290      |
|    time_elapsed         | 7440      |
|    total_timesteps      | 4689920   |
| train/                  |           |
|    approx_kl            | 0.5963657 |
|    clip_fraction        | 0.455     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.243     |
|    explained_variance   | 0.629     |
|    learning_rate        | 0.00109   |
|    loss                 | 0.0183    |
|    n_updates            | 22890     |
|    policy_gradient_loss | 0.0102    |
|    std                  | 0.214     |
|    value_loss           | 0.0272    |
---------------------------------------
box reached target
Eval num_timesteps=4690000, episode_reward=0.26 +/- 2.52
Episode length: 278.80 +/- 42.40
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 279       |
|    mean_reward          | 0.259     |
| time/                   |           |
|    total_timesteps      | 4690000   |
| train/                  |           |
|    approx_kl            | 0.1695496 |
|    clip_fraction        | 0.446     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.194     |
|    explained_variance   | 0.695     |
|    learning_rate        | 0.00109   |
|    loss                 | 0.0319    |
|    n_updates            | 22900     |
|    policy_gradient_loss | 0.0218    |
|    std                  | 0.222     |
|    value_loss           | 0.0333    |
---------------------------------------
box reached target
--------------------------------
| time/              |         |
|    fps             | 630     |
|    iterations      | 2291    |
|    time_elapsed    | 7443    |
|    total_timesteps | 4691968 |
--------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2292       |
|    time_elapsed         | 7447       |
|    total_timesteps      | 4694016    |
| train/                  |            |
|    approx_kl            | 0.24957418 |
|    clip_fraction        | 0.424      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.124      |
|    explained_variance   | 0.871      |
|    learning_rate        | 0.00109    |
|    loss                 | -0.0209    |
|    n_updates            | 22910      |
|    policy_gradient_loss | 0.00318    |
|    std                  | 0.229      |
|    value_loss           | 0.0117     |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2293       |
|    time_elapsed         | 7450       |
|    total_timesteps      | 4696064    |
| train/                  |            |
|    approx_kl            | 0.23514307 |
|    clip_fraction        | 0.394      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.134      |
|    explained_variance   | 0.615      |
|    learning_rate        | 0.00108    |
|    loss                 | -0.012     |
|    n_updates            | 22920      |
|    policy_gradient_loss | 0.0142     |
|    std                  | 0.224      |
|    value_loss           | 0.0181     |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2294       |
|    time_elapsed         | 7453       |
|    total_timesteps      | 4698112    |
| train/                  |            |
|    approx_kl            | 0.35335547 |
|    clip_fraction        | 0.444      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.179      |
|    explained_variance   | 0.347      |
|    learning_rate        | 0.00108    |
|    loss                 | 0.0532     |
|    n_updates            | 22930      |
|    policy_gradient_loss | -0.00494   |
|    std                  | 0.218      |
|    value_loss           | 0.00877    |
----------------------------------------
box reached target
Eval num_timesteps=4700000, episode_reward=-1.04 +/- 0.07
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1.04      |
| time/                   |            |
|    total_timesteps      | 4700000    |
| train/                  |            |
|    approx_kl            | 0.19767264 |
|    clip_fraction        | 0.43       |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.205      |
|    explained_variance   | 0.775      |
|    learning_rate        | 0.00108    |
|    loss                 | -0.0219    |
|    n_updates            | 22940      |
|    policy_gradient_loss | 0.00627    |
|    std                  | 0.217      |
|    value_loss           | 0.018      |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 630     |
|    iterations      | 2295    |
|    time_elapsed    | 7457    |
|    total_timesteps | 4700160 |
--------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2296       |
|    time_elapsed         | 7460       |
|    total_timesteps      | 4702208    |
| train/                  |            |
|    approx_kl            | 0.12920727 |
|    clip_fraction        | 0.418      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.23       |
|    explained_variance   | 0.741      |
|    learning_rate        | 0.00108    |
|    loss                 | 0.0063     |
|    n_updates            | 22950      |
|    policy_gradient_loss | 0.0108     |
|    std                  | 0.215      |
|    value_loss           | 0.00739    |
----------------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2297       |
|    time_elapsed         | 7463       |
|    total_timesteps      | 4704256    |
| train/                  |            |
|    approx_kl            | 0.16678065 |
|    clip_fraction        | 0.473      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.199      |
|    explained_variance   | 0.61       |
|    learning_rate        | 0.00108    |
|    loss                 | 0.0477     |
|    n_updates            | 22960      |
|    policy_gradient_loss | 0.0224     |
|    std                  | 0.221      |
|    value_loss           | 0.0944     |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2298       |
|    time_elapsed         | 7466       |
|    total_timesteps      | 4706304    |
| train/                  |            |
|    approx_kl            | 0.19361004 |
|    clip_fraction        | 0.427      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.167      |
|    explained_variance   | 0.807      |
|    learning_rate        | 0.00108    |
|    loss                 | 0.00422    |
|    n_updates            | 22970      |
|    policy_gradient_loss | 0.0164     |
|    std                  | 0.223      |
|    value_loss           | 0.014      |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2299       |
|    time_elapsed         | 7469       |
|    total_timesteps      | 4708352    |
| train/                  |            |
|    approx_kl            | 0.13684995 |
|    clip_fraction        | 0.434      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.122      |
|    explained_variance   | 0.757      |
|    learning_rate        | 0.00108    |
|    loss                 | -0.0211    |
|    n_updates            | 22980      |
|    policy_gradient_loss | 0.0108     |
|    std                  | 0.229      |
|    value_loss           | 0.0207     |
----------------------------------------
Eval num_timesteps=4710000, episode_reward=-1.07 +/- 0.14
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1.07      |
| time/                   |            |
|    total_timesteps      | 4710000    |
| train/                  |            |
|    approx_kl            | 0.20255911 |
|    clip_fraction        | 0.413      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.0939     |
|    explained_variance   | 0.795      |
|    learning_rate        | 0.00108    |
|    loss                 | 0.0998     |
|    n_updates            | 22990      |
|    policy_gradient_loss | 0.0153     |
|    std                  | 0.23       |
|    value_loss           | 0.0167     |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 630     |
|    iterations      | 2300    |
|    time_elapsed    | 7473    |
|    total_timesteps | 4710400 |
--------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2301       |
|    time_elapsed         | 7476       |
|    total_timesteps      | 4712448    |
| train/                  |            |
|    approx_kl            | 0.14803007 |
|    clip_fraction        | 0.367      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.0868     |
|    explained_variance   | 0.664      |
|    learning_rate        | 0.00108    |
|    loss                 | 0.0139     |
|    n_updates            | 23000      |
|    policy_gradient_loss | 0.00614    |
|    std                  | 0.231      |
|    value_loss           | 0.00958    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2302       |
|    time_elapsed         | 7479       |
|    total_timesteps      | 4714496    |
| train/                  |            |
|    approx_kl            | 0.22217333 |
|    clip_fraction        | 0.43       |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.0768     |
|    explained_variance   | 0.339      |
|    learning_rate        | 0.00108    |
|    loss                 | -0.00296   |
|    n_updates            | 23010      |
|    policy_gradient_loss | 0.00766    |
|    std                  | 0.232      |
|    value_loss           | 0.0498     |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2303       |
|    time_elapsed         | 7482       |
|    total_timesteps      | 4716544    |
| train/                  |            |
|    approx_kl            | 0.14089501 |
|    clip_fraction        | 0.415      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.0582     |
|    explained_variance   | 0.683      |
|    learning_rate        | 0.00108    |
|    loss                 | 0.0149     |
|    n_updates            | 23020      |
|    policy_gradient_loss | 0.00665    |
|    std                  | 0.237      |
|    value_loss           | 0.00568    |
----------------------------------------
box reached target
box reached target
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2304       |
|    time_elapsed         | 7485       |
|    total_timesteps      | 4718592    |
| train/                  |            |
|    approx_kl            | 0.16775069 |
|    clip_fraction        | 0.399      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.0192     |
|    explained_variance   | 0.413      |
|    learning_rate        | 0.00108    |
|    loss                 | -0.0137    |
|    n_updates            | 23030      |
|    policy_gradient_loss | 0.00477    |
|    std                  | 0.241      |
|    value_loss           | 0.0166     |
----------------------------------------
box reached target
Eval num_timesteps=4720000, episode_reward=0.48 +/- 2.47
Episode length: 279.60 +/- 40.80
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 280        |
|    mean_reward          | 0.48       |
| time/                   |            |
|    total_timesteps      | 4720000    |
| train/                  |            |
|    approx_kl            | 0.20747805 |
|    clip_fraction        | 0.408      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.0283     |
|    explained_variance   | 0.0859     |
|    learning_rate        | 0.00108    |
|    loss                 | -0.00166   |
|    n_updates            | 23040      |
|    policy_gradient_loss | 0.00109    |
|    std                  | 0.239      |
|    value_loss           | 0.153      |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 630     |
|    iterations      | 2305    |
|    time_elapsed    | 7489    |
|    total_timesteps | 4720640 |
--------------------------------
box reached target
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2306       |
|    time_elapsed         | 7492       |
|    total_timesteps      | 4722688    |
| train/                  |            |
|    approx_kl            | 0.34716266 |
|    clip_fraction        | 0.388      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.018      |
|    explained_variance   | 0.221      |
|    learning_rate        | 0.00108    |
|    loss                 | -0.0331    |
|    n_updates            | 23050      |
|    policy_gradient_loss | 0.00404    |
|    std                  | 0.24       |
|    value_loss           | 0.00848    |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2307       |
|    time_elapsed         | 7495       |
|    total_timesteps      | 4724736    |
| train/                  |            |
|    approx_kl            | 0.19158262 |
|    clip_fraction        | 0.43       |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.0683     |
|    explained_variance   | 0.666      |
|    learning_rate        | 0.00108    |
|    loss                 | 0.0467     |
|    n_updates            | 23060      |
|    policy_gradient_loss | 0.0107     |
|    std                  | 0.23       |
|    value_loss           | 0.0364     |
----------------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2308       |
|    time_elapsed         | 7498       |
|    total_timesteps      | 4726784    |
| train/                  |            |
|    approx_kl            | 0.21495134 |
|    clip_fraction        | 0.434      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.0848     |
|    explained_variance   | 0.687      |
|    learning_rate        | 0.00108    |
|    loss                 | 0.0458     |
|    n_updates            | 23070      |
|    policy_gradient_loss | 0.0158     |
|    std                  | 0.234      |
|    value_loss           | 0.0131     |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2309       |
|    time_elapsed         | 7501       |
|    total_timesteps      | 4728832    |
| train/                  |            |
|    approx_kl            | 0.26051635 |
|    clip_fraction        | 0.398      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.0823     |
|    explained_variance   | 0.708      |
|    learning_rate        | 0.00108    |
|    loss                 | 0.0536     |
|    n_updates            | 23080      |
|    policy_gradient_loss | -0.000773  |
|    std                  | 0.23       |
|    value_loss           | 0.0278     |
----------------------------------------
Eval num_timesteps=4730000, episode_reward=-0.80 +/- 0.39
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -0.802     |
| time/                   |            |
|    total_timesteps      | 4730000    |
| train/                  |            |
|    approx_kl            | 0.16023079 |
|    clip_fraction        | 0.388      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.116      |
|    explained_variance   | 0.61       |
|    learning_rate        | 0.00108    |
|    loss                 | -0.0443    |
|    n_updates            | 23090      |
|    policy_gradient_loss | 0.00797    |
|    std                  | 0.23       |
|    value_loss           | 0.0067     |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 630     |
|    iterations      | 2310    |
|    time_elapsed    | 7505    |
|    total_timesteps | 4730880 |
--------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2311       |
|    time_elapsed         | 7508       |
|    total_timesteps      | 4732928    |
| train/                  |            |
|    approx_kl            | 0.26420262 |
|    clip_fraction        | 0.392      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.143      |
|    explained_variance   | 0.272      |
|    learning_rate        | 0.00108    |
|    loss                 | -0.0149    |
|    n_updates            | 23100      |
|    policy_gradient_loss | 0.0073     |
|    std                  | 0.223      |
|    value_loss           | 0.00849    |
----------------------------------------
box reached target
box reached target
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 630       |
|    iterations           | 2312      |
|    time_elapsed         | 7511      |
|    total_timesteps      | 4734976   |
| train/                  |           |
|    approx_kl            | 0.3189518 |
|    clip_fraction        | 0.445     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.18      |
|    explained_variance   | 0.807     |
|    learning_rate        | 0.00108   |
|    loss                 | -0.0126   |
|    n_updates            | 23110     |
|    policy_gradient_loss | 0.00342   |
|    std                  | 0.218     |
|    value_loss           | 0.0112    |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2313       |
|    time_elapsed         | 7514       |
|    total_timesteps      | 4737024    |
| train/                  |            |
|    approx_kl            | 0.10278268 |
|    clip_fraction        | 0.405      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.177      |
|    explained_variance   | 0.762      |
|    learning_rate        | 0.00108    |
|    loss                 | 0.087      |
|    n_updates            | 23120      |
|    policy_gradient_loss | 0.0162     |
|    std                  | 0.225      |
|    value_loss           | 0.0298     |
----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 630       |
|    iterations           | 2314      |
|    time_elapsed         | 7517      |
|    total_timesteps      | 4739072   |
| train/                  |           |
|    approx_kl            | 0.2956464 |
|    clip_fraction        | 0.411     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.134     |
|    explained_variance   | 0.679     |
|    learning_rate        | 0.00108   |
|    loss                 | -0.0225   |
|    n_updates            | 23130     |
|    policy_gradient_loss | 0.00739   |
|    std                  | 0.227     |
|    value_loss           | 0.0102    |
---------------------------------------
Eval num_timesteps=4740000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 300       |
|    mean_reward          | -1        |
| time/                   |           |
|    total_timesteps      | 4740000   |
| train/                  |           |
|    approx_kl            | 0.1948533 |
|    clip_fraction        | 0.384     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.111     |
|    explained_variance   | 0.511     |
|    learning_rate        | 0.00108   |
|    loss                 | 0.048     |
|    n_updates            | 23140     |
|    policy_gradient_loss | -0.00704  |
|    std                  | 0.231     |
|    value_loss           | 0.0182    |
---------------------------------------
box reached target
--------------------------------
| time/              |         |
|    fps             | 630     |
|    iterations      | 2315    |
|    time_elapsed    | 7521    |
|    total_timesteps | 4741120 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2316       |
|    time_elapsed         | 7524       |
|    total_timesteps      | 4743168    |
| train/                  |            |
|    approx_kl            | 0.34550583 |
|    clip_fraction        | 0.408      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.157      |
|    explained_variance   | 0.661      |
|    learning_rate        | 0.00108    |
|    loss                 | -0.0109    |
|    n_updates            | 23150      |
|    policy_gradient_loss | -0.00537   |
|    std                  | 0.222      |
|    value_loss           | 0.0142     |
----------------------------------------
box reached target
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2317       |
|    time_elapsed         | 7527       |
|    total_timesteps      | 4745216    |
| train/                  |            |
|    approx_kl            | 0.23430964 |
|    clip_fraction        | 0.375      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.162      |
|    explained_variance   | 0.433      |
|    learning_rate        | 0.00108    |
|    loss                 | 0.0163     |
|    n_updates            | 23160      |
|    policy_gradient_loss | 0.0145     |
|    std                  | 0.228      |
|    value_loss           | 0.00904    |
----------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 630       |
|    iterations           | 2318      |
|    time_elapsed         | 7530      |
|    total_timesteps      | 4747264   |
| train/                  |           |
|    approx_kl            | 0.2814679 |
|    clip_fraction        | 0.446     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.161     |
|    explained_variance   | 0.79      |
|    learning_rate        | 0.00107   |
|    loss                 | 0.00941   |
|    n_updates            | 23170     |
|    policy_gradient_loss | 0.00817   |
|    std                  | 0.224     |
|    value_loss           | 0.0355    |
---------------------------------------
box reached target
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 630         |
|    iterations           | 2319        |
|    time_elapsed         | 7533        |
|    total_timesteps      | 4749312     |
| train/                  |             |
|    approx_kl            | 0.105821654 |
|    clip_fraction        | 0.351       |
|    clip_range           | 0.2         |
|    entropy_loss         | 0.183       |
|    explained_variance   | 0.846       |
|    learning_rate        | 0.00107     |
|    loss                 | -0.043      |
|    n_updates            | 23180       |
|    policy_gradient_loss | 0.0098      |
|    std                  | 0.224       |
|    value_loss           | 0.00833     |
-----------------------------------------
Eval num_timesteps=4750000, episode_reward=-1.05 +/- 0.11
Episode length: 300.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 300       |
|    mean_reward          | -1.05     |
| time/                   |           |
|    total_timesteps      | 4750000   |
| train/                  |           |
|    approx_kl            | 0.1703397 |
|    clip_fraction        | 0.419     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.174     |
|    explained_variance   | 0.587     |
|    learning_rate        | 0.00107   |
|    loss                 | 0.0146    |
|    n_updates            | 23190     |
|    policy_gradient_loss | 0.0109    |
|    std                  | 0.226     |
|    value_loss           | 0.0188    |
---------------------------------------
--------------------------------
| time/              |         |
|    fps             | 630     |
|    iterations      | 2320    |
|    time_elapsed    | 7537    |
|    total_timesteps | 4751360 |
--------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2321       |
|    time_elapsed         | 7540       |
|    total_timesteps      | 4753408    |
| train/                  |            |
|    approx_kl            | 0.30741903 |
|    clip_fraction        | 0.438      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.179      |
|    explained_variance   | 0.647      |
|    learning_rate        | 0.00107    |
|    loss                 | -0.00314   |
|    n_updates            | 23200      |
|    policy_gradient_loss | 0.00663    |
|    std                  | 0.221      |
|    value_loss           | 0.00942    |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2322       |
|    time_elapsed         | 7543       |
|    total_timesteps      | 4755456    |
| train/                  |            |
|    approx_kl            | 0.20200378 |
|    clip_fraction        | 0.437      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.164      |
|    explained_variance   | 0.83       |
|    learning_rate        | 0.00107    |
|    loss                 | 0.077      |
|    n_updates            | 23210      |
|    policy_gradient_loss | 0.0126     |
|    std                  | 0.226      |
|    value_loss           | 0.0254     |
----------------------------------------
box reached target
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 630       |
|    iterations           | 2323      |
|    time_elapsed         | 7546      |
|    total_timesteps      | 4757504   |
| train/                  |           |
|    approx_kl            | 0.1877477 |
|    clip_fraction        | 0.436     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.175     |
|    explained_variance   | 0.272     |
|    learning_rate        | 0.00107   |
|    loss                 | 0.00832   |
|    n_updates            | 23220     |
|    policy_gradient_loss | 0.00695   |
|    std                  | 0.223     |
|    value_loss           | 0.0329    |
---------------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2324       |
|    time_elapsed         | 7550       |
|    total_timesteps      | 4759552    |
| train/                  |            |
|    approx_kl            | 0.20227599 |
|    clip_fraction        | 0.396      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.177      |
|    explained_variance   | 0.717      |
|    learning_rate        | 0.00107    |
|    loss                 | -0.00899   |
|    n_updates            | 23230      |
|    policy_gradient_loss | 0.02       |
|    std                  | 0.224      |
|    value_loss           | 0.053      |
----------------------------------------
Eval num_timesteps=4760000, episode_reward=-1.12 +/- 0.16
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1.12      |
| time/                   |            |
|    total_timesteps      | 4760000    |
| train/                  |            |
|    approx_kl            | 0.14748801 |
|    clip_fraction        | 0.402      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.137      |
|    explained_variance   | 0.832      |
|    learning_rate        | 0.00107    |
|    loss                 | -0.0293    |
|    n_updates            | 23240      |
|    policy_gradient_loss | 0.00162    |
|    std                  | 0.229      |
|    value_loss           | 0.0211     |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 630     |
|    iterations      | 2325    |
|    time_elapsed    | 7554    |
|    total_timesteps | 4761600 |
--------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2326       |
|    time_elapsed         | 7557       |
|    total_timesteps      | 4763648    |
| train/                  |            |
|    approx_kl            | 0.26078212 |
|    clip_fraction        | 0.43       |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.0808     |
|    explained_variance   | 0.701      |
|    learning_rate        | 0.00107    |
|    loss                 | 0.00545    |
|    n_updates            | 23250      |
|    policy_gradient_loss | 0.0166     |
|    std                  | 0.231      |
|    value_loss           | 0.0155     |
----------------------------------------
box reached target
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 630       |
|    iterations           | 2327      |
|    time_elapsed         | 7560      |
|    total_timesteps      | 4765696   |
| train/                  |           |
|    approx_kl            | 0.1251256 |
|    clip_fraction        | 0.412     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.117     |
|    explained_variance   | 0.777     |
|    learning_rate        | 0.00107   |
|    loss                 | -0.0475   |
|    n_updates            | 23260     |
|    policy_gradient_loss | 0.00819   |
|    std                  | 0.229     |
|    value_loss           | 0.0135    |
---------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 630       |
|    iterations           | 2328      |
|    time_elapsed         | 7563      |
|    total_timesteps      | 4767744   |
| train/                  |           |
|    approx_kl            | 0.1339649 |
|    clip_fraction        | 0.36      |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.124     |
|    explained_variance   | 0.855     |
|    learning_rate        | 0.00107   |
|    loss                 | -0.0133   |
|    n_updates            | 23270     |
|    policy_gradient_loss | 0.00951   |
|    std                  | 0.227     |
|    value_loss           | 0.0168    |
---------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2329       |
|    time_elapsed         | 7566       |
|    total_timesteps      | 4769792    |
| train/                  |            |
|    approx_kl            | 0.15866481 |
|    clip_fraction        | 0.384      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.0948     |
|    explained_variance   | 0.917      |
|    learning_rate        | 0.00107    |
|    loss                 | -0.0269    |
|    n_updates            | 23280      |
|    policy_gradient_loss | 0.00573    |
|    std                  | 0.232      |
|    value_loss           | 0.00771    |
----------------------------------------
box reached target
Eval num_timesteps=4770000, episode_reward=0.18 +/- 2.51
Episode length: 273.40 +/- 53.20
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 273        |
|    mean_reward          | 0.183      |
| time/                   |            |
|    total_timesteps      | 4770000    |
| train/                  |            |
|    approx_kl            | 0.11237948 |
|    clip_fraction        | 0.395      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.0588     |
|    explained_variance   | 0.909      |
|    learning_rate        | 0.00107    |
|    loss                 | -0.0191    |
|    n_updates            | 23290      |
|    policy_gradient_loss | 0.0168     |
|    std                  | 0.239      |
|    value_loss           | 0.00838    |
----------------------------------------
box reached target
--------------------------------
| time/              |         |
|    fps             | 630     |
|    iterations      | 2330    |
|    time_elapsed    | 7570    |
|    total_timesteps | 4771840 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2331       |
|    time_elapsed         | 7573       |
|    total_timesteps      | 4773888    |
| train/                  |            |
|    approx_kl            | 0.18422017 |
|    clip_fraction        | 0.389      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.0234     |
|    explained_variance   | 0.94       |
|    learning_rate        | 0.00107    |
|    loss                 | 0.00205    |
|    n_updates            | 23300      |
|    policy_gradient_loss | 0.00201    |
|    std                  | 0.239      |
|    value_loss           | 0.00459    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2332       |
|    time_elapsed         | 7576       |
|    total_timesteps      | 4775936    |
| train/                  |            |
|    approx_kl            | 0.21888824 |
|    clip_fraction        | 0.361      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.0178     |
|    explained_variance   | 0.599      |
|    learning_rate        | 0.00107    |
|    loss                 | 0.00821    |
|    n_updates            | 23310      |
|    policy_gradient_loss | -0.00975   |
|    std                  | 0.238      |
|    value_loss           | 0.00552    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2333       |
|    time_elapsed         | 7579       |
|    total_timesteps      | 4777984    |
| train/                  |            |
|    approx_kl            | 0.09372191 |
|    clip_fraction        | 0.341      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.00225   |
|    explained_variance   | 0.383      |
|    learning_rate        | 0.00107    |
|    loss                 | 0.0589     |
|    n_updates            | 23320      |
|    policy_gradient_loss | 0.00724    |
|    std                  | 0.245      |
|    value_loss           | 0.00644    |
----------------------------------------
box reached target
box reached target
Eval num_timesteps=4780000, episode_reward=0.27 +/- 2.53
Episode length: 276.60 +/- 46.80
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 277        |
|    mean_reward          | 0.265      |
| time/                   |            |
|    total_timesteps      | 4780000    |
| train/                  |            |
|    approx_kl            | 0.14575286 |
|    clip_fraction        | 0.368      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.0347    |
|    explained_variance   | 0.458      |
|    learning_rate        | 0.00107    |
|    loss                 | -0.0541    |
|    n_updates            | 23330      |
|    policy_gradient_loss | 0.00526    |
|    std                  | 0.245      |
|    value_loss           | 0.00622    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 630     |
|    iterations      | 2334    |
|    time_elapsed    | 7583    |
|    total_timesteps | 4780032 |
--------------------------------
box reached target
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2335       |
|    time_elapsed         | 7586       |
|    total_timesteps      | 4782080    |
| train/                  |            |
|    approx_kl            | 0.14220922 |
|    clip_fraction        | 0.385      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.0233    |
|    explained_variance   | 0.419      |
|    learning_rate        | 0.00107    |
|    loss                 | 0.0233     |
|    n_updates            | 23340      |
|    policy_gradient_loss | 0.00223    |
|    std                  | 0.244      |
|    value_loss           | 0.0444     |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2336       |
|    time_elapsed         | 7589       |
|    total_timesteps      | 4784128    |
| train/                  |            |
|    approx_kl            | 0.13055366 |
|    clip_fraction        | 0.374      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.00627    |
|    explained_variance   | 0.869      |
|    learning_rate        | 0.00107    |
|    loss                 | -0.00087   |
|    n_updates            | 23350      |
|    policy_gradient_loss | 0.00456    |
|    std                  | 0.241      |
|    value_loss           | 0.0139     |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2337       |
|    time_elapsed         | 7592       |
|    total_timesteps      | 4786176    |
| train/                  |            |
|    approx_kl            | 0.23271714 |
|    clip_fraction        | 0.397      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.00862    |
|    explained_variance   | 0.659      |
|    learning_rate        | 0.00107    |
|    loss                 | -0.0284    |
|    n_updates            | 23360      |
|    policy_gradient_loss | 0.00958    |
|    std                  | 0.24       |
|    value_loss           | 0.0343     |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2338       |
|    time_elapsed         | 7595       |
|    total_timesteps      | 4788224    |
| train/                  |            |
|    approx_kl            | 0.11916892 |
|    clip_fraction        | 0.359      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.0149     |
|    explained_variance   | 0.829      |
|    learning_rate        | 0.00107    |
|    loss                 | 0.0381     |
|    n_updates            | 23370      |
|    policy_gradient_loss | 0.00233    |
|    std                  | 0.243      |
|    value_loss           | 0.018      |
----------------------------------------
box reached target
Eval num_timesteps=4790000, episode_reward=0.41 +/- 2.37
Episode length: 273.80 +/- 52.40
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 274        |
|    mean_reward          | 0.41       |
| time/                   |            |
|    total_timesteps      | 4790000    |
| train/                  |            |
|    approx_kl            | 0.09045446 |
|    clip_fraction        | 0.353      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.0247    |
|    explained_variance   | 0.691      |
|    learning_rate        | 0.00107    |
|    loss                 | -0.0159    |
|    n_updates            | 23380      |
|    policy_gradient_loss | 0.00942    |
|    std                  | 0.248      |
|    value_loss           | 0.00665    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 630     |
|    iterations      | 2339    |
|    time_elapsed    | 7599    |
|    total_timesteps | 4790272 |
--------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 630         |
|    iterations           | 2340        |
|    time_elapsed         | 7602        |
|    total_timesteps      | 4792320     |
| train/                  |             |
|    approx_kl            | 0.113043934 |
|    clip_fraction        | 0.356       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0559     |
|    explained_variance   | 0.574       |
|    learning_rate        | 0.00107     |
|    loss                 | -0.00885    |
|    n_updates            | 23390       |
|    policy_gradient_loss | 0.0079      |
|    std                  | 0.251       |
|    value_loss           | 0.00444     |
-----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2341       |
|    time_elapsed         | 7605       |
|    total_timesteps      | 4794368    |
| train/                  |            |
|    approx_kl            | 0.26333195 |
|    clip_fraction        | 0.413      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.0417    |
|    explained_variance   | 0.812      |
|    learning_rate        | 0.00107    |
|    loss                 | 0.0342     |
|    n_updates            | 23400      |
|    policy_gradient_loss | 0.00208    |
|    std                  | 0.246      |
|    value_loss           | 0.015      |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2342       |
|    time_elapsed         | 7608       |
|    total_timesteps      | 4796416    |
| train/                  |            |
|    approx_kl            | 0.17464103 |
|    clip_fraction        | 0.381      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.0651    |
|    explained_variance   | 0.713      |
|    learning_rate        | 0.00107    |
|    loss                 | 0.0363     |
|    n_updates            | 23410      |
|    policy_gradient_loss | 0.0126     |
|    std                  | 0.252      |
|    value_loss           | 0.0147     |
----------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 630       |
|    iterations           | 2343      |
|    time_elapsed         | 7611      |
|    total_timesteps      | 4798464   |
| train/                  |           |
|    approx_kl            | 0.2063376 |
|    clip_fraction        | 0.361     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0527   |
|    explained_variance   | 0.204     |
|    learning_rate        | 0.00106   |
|    loss                 | -0.00455  |
|    n_updates            | 23420     |
|    policy_gradient_loss | 0.00317   |
|    std                  | 0.247     |
|    value_loss           | 0.00811   |
---------------------------------------
box reached target
Eval num_timesteps=4800000, episode_reward=0.24 +/- 2.48
Episode length: 279.00 +/- 42.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 279        |
|    mean_reward          | 0.239      |
| time/                   |            |
|    total_timesteps      | 4800000    |
| train/                  |            |
|    approx_kl            | 0.11574937 |
|    clip_fraction        | 0.326      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.0574    |
|    explained_variance   | 0.899      |
|    learning_rate        | 0.00106    |
|    loss                 | -0.0185    |
|    n_updates            | 23430      |
|    policy_gradient_loss | -0.00265   |
|    std                  | 0.251      |
|    value_loss           | 0.00769    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 630     |
|    iterations      | 2344    |
|    time_elapsed    | 7615    |
|    total_timesteps | 4800512 |
--------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 630       |
|    iterations           | 2345      |
|    time_elapsed         | 7618      |
|    total_timesteps      | 4802560   |
| train/                  |           |
|    approx_kl            | 0.1689193 |
|    clip_fraction        | 0.423     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0719   |
|    explained_variance   | 0.708     |
|    learning_rate        | 0.00106   |
|    loss                 | -0.0212   |
|    n_updates            | 23440     |
|    policy_gradient_loss | 0.0112    |
|    std                  | 0.248     |
|    value_loss           | 0.0154    |
---------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 630       |
|    iterations           | 2346      |
|    time_elapsed         | 7621      |
|    total_timesteps      | 4804608   |
| train/                  |           |
|    approx_kl            | 0.2276492 |
|    clip_fraction        | 0.398     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0552   |
|    explained_variance   | 0.63      |
|    learning_rate        | 0.00106   |
|    loss                 | -0.0398   |
|    n_updates            | 23450     |
|    policy_gradient_loss | 0.0029    |
|    std                  | 0.251     |
|    value_loss           | 0.0175    |
---------------------------------------
box reached target
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2347       |
|    time_elapsed         | 7624       |
|    total_timesteps      | 4806656    |
| train/                  |            |
|    approx_kl            | 0.18211752 |
|    clip_fraction        | 0.368      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.0417    |
|    explained_variance   | 0.882      |
|    learning_rate        | 0.00106    |
|    loss                 | 0.00787    |
|    n_updates            | 23460      |
|    policy_gradient_loss | -0.00201   |
|    std                  | 0.247      |
|    value_loss           | 0.0133     |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2348       |
|    time_elapsed         | 7627       |
|    total_timesteps      | 4808704    |
| train/                  |            |
|    approx_kl            | 0.21871853 |
|    clip_fraction        | 0.407      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.0321    |
|    explained_variance   | 0.845      |
|    learning_rate        | 0.00106    |
|    loss                 | -0.0125    |
|    n_updates            | 23470      |
|    policy_gradient_loss | 0.0113     |
|    std                  | 0.248      |
|    value_loss           | 0.0372     |
----------------------------------------
box reached target
Eval num_timesteps=4810000, episode_reward=0.63 +/- 2.58
Episode length: 277.60 +/- 44.80
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 278        |
|    mean_reward          | 0.626      |
| time/                   |            |
|    total_timesteps      | 4810000    |
| train/                  |            |
|    approx_kl            | 0.19125915 |
|    clip_fraction        | 0.386      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.023     |
|    explained_variance   | 0.879      |
|    learning_rate        | 0.00106    |
|    loss                 | -0.0216    |
|    n_updates            | 23480      |
|    policy_gradient_loss | -0.00297   |
|    std                  | 0.244      |
|    value_loss           | 0.0192     |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 630     |
|    iterations      | 2349    |
|    time_elapsed    | 7631    |
|    total_timesteps | 4810752 |
--------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 630         |
|    iterations           | 2350        |
|    time_elapsed         | 7634        |
|    total_timesteps      | 4812800     |
| train/                  |             |
|    approx_kl            | 0.114980236 |
|    clip_fraction        | 0.373       |
|    clip_range           | 0.2         |
|    entropy_loss         | 0.014       |
|    explained_variance   | 0.314       |
|    learning_rate        | 0.00106     |
|    loss                 | 0.00896     |
|    n_updates            | 23490       |
|    policy_gradient_loss | 0.00996     |
|    std                  | 0.24        |
|    value_loss           | 0.00677     |
-----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2351       |
|    time_elapsed         | 7637       |
|    total_timesteps      | 4814848    |
| train/                  |            |
|    approx_kl            | 0.11388365 |
|    clip_fraction        | 0.383      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.0215     |
|    explained_variance   | 0.836      |
|    learning_rate        | 0.00106    |
|    loss                 | 0.0877     |
|    n_updates            | 23500      |
|    policy_gradient_loss | 0.00757    |
|    std                  | 0.242      |
|    value_loss           | 0.0117     |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2352       |
|    time_elapsed         | 7640       |
|    total_timesteps      | 4816896    |
| train/                  |            |
|    approx_kl            | 0.20837516 |
|    clip_fraction        | 0.358      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.00151   |
|    explained_variance   | 0.83       |
|    learning_rate        | 0.00106    |
|    loss                 | -0.0446    |
|    n_updates            | 23510      |
|    policy_gradient_loss | -0.0112    |
|    std                  | 0.244      |
|    value_loss           | 0.00549    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2353       |
|    time_elapsed         | 7643       |
|    total_timesteps      | 4818944    |
| train/                  |            |
|    approx_kl            | 0.34103522 |
|    clip_fraction        | 0.43       |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.00176    |
|    explained_variance   | 0.862      |
|    learning_rate        | 0.00106    |
|    loss                 | -0.0351    |
|    n_updates            | 23520      |
|    policy_gradient_loss | -0.00155   |
|    std                  | 0.241      |
|    value_loss           | 0.0114     |
----------------------------------------
box reached target
Eval num_timesteps=4820000, episode_reward=0.50 +/- 2.42
Episode length: 276.20 +/- 47.60
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 276        |
|    mean_reward          | 0.504      |
| time/                   |            |
|    total_timesteps      | 4820000    |
| train/                  |            |
|    approx_kl            | 0.35018504 |
|    clip_fraction        | 0.432      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.0213     |
|    explained_variance   | 0.641      |
|    learning_rate        | 0.00106    |
|    loss                 | 0.021      |
|    n_updates            | 23530      |
|    policy_gradient_loss | 0.00448    |
|    std                  | 0.238      |
|    value_loss           | 0.00783    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 630     |
|    iterations      | 2354    |
|    time_elapsed    | 7647    |
|    total_timesteps | 4820992 |
--------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2355       |
|    time_elapsed         | 7650       |
|    total_timesteps      | 4823040    |
| train/                  |            |
|    approx_kl            | 0.15757811 |
|    clip_fraction        | 0.412      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.033      |
|    explained_variance   | 0.593      |
|    learning_rate        | 0.00106    |
|    loss                 | 0.0933     |
|    n_updates            | 23540      |
|    policy_gradient_loss | 0.0126     |
|    std                  | 0.24       |
|    value_loss           | 0.00553    |
----------------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2356       |
|    time_elapsed         | 7653       |
|    total_timesteps      | 4825088    |
| train/                  |            |
|    approx_kl            | 0.16373014 |
|    clip_fraction        | 0.39       |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.0189     |
|    explained_variance   | 0.898      |
|    learning_rate        | 0.00106    |
|    loss                 | -0.0298    |
|    n_updates            | 23550      |
|    policy_gradient_loss | 0.0159     |
|    std                  | 0.244      |
|    value_loss           | 0.00885    |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2357       |
|    time_elapsed         | 7656       |
|    total_timesteps      | 4827136    |
| train/                  |            |
|    approx_kl            | 0.14358883 |
|    clip_fraction        | 0.4        |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.0329     |
|    explained_variance   | 0.378      |
|    learning_rate        | 0.00106    |
|    loss                 | 0.0327     |
|    n_updates            | 23560      |
|    policy_gradient_loss | 0.00555    |
|    std                  | 0.238      |
|    value_loss           | 0.0318     |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2358       |
|    time_elapsed         | 7659       |
|    total_timesteps      | 4829184    |
| train/                  |            |
|    approx_kl            | 0.28890115 |
|    clip_fraction        | 0.374      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.0319     |
|    explained_variance   | 0.866      |
|    learning_rate        | 0.00106    |
|    loss                 | -0.0432    |
|    n_updates            | 23570      |
|    policy_gradient_loss | 0.000129   |
|    std                  | 0.24       |
|    value_loss           | 0.0123     |
----------------------------------------
Eval num_timesteps=4830000, episode_reward=-1.04 +/- 0.08
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1.04      |
| time/                   |            |
|    total_timesteps      | 4830000    |
| train/                  |            |
|    approx_kl            | 0.13991809 |
|    clip_fraction        | 0.433      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.0461     |
|    explained_variance   | 0.735      |
|    learning_rate        | 0.00106    |
|    loss                 | 0.018      |
|    n_updates            | 23580      |
|    policy_gradient_loss | 0.0196     |
|    std                  | 0.238      |
|    value_loss           | 0.0103     |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 630     |
|    iterations      | 2359    |
|    time_elapsed    | 7663    |
|    total_timesteps | 4831232 |
--------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2360       |
|    time_elapsed         | 7666       |
|    total_timesteps      | 4833280    |
| train/                  |            |
|    approx_kl            | 0.22275943 |
|    clip_fraction        | 0.401      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.0669     |
|    explained_variance   | 0.638      |
|    learning_rate        | 0.00106    |
|    loss                 | 0.0133     |
|    n_updates            | 23590      |
|    policy_gradient_loss | -0.00348   |
|    std                  | 0.234      |
|    value_loss           | 0.00766    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2361       |
|    time_elapsed         | 7669       |
|    total_timesteps      | 4835328    |
| train/                  |            |
|    approx_kl            | 0.19418743 |
|    clip_fraction        | 0.419      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.0774     |
|    explained_variance   | 0.601      |
|    learning_rate        | 0.00106    |
|    loss                 | 0.0278     |
|    n_updates            | 23600      |
|    policy_gradient_loss | 0.0094     |
|    std                  | 0.234      |
|    value_loss           | 0.0231     |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2362       |
|    time_elapsed         | 7672       |
|    total_timesteps      | 4837376    |
| train/                  |            |
|    approx_kl            | 0.11674884 |
|    clip_fraction        | 0.403      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.0372     |
|    explained_variance   | 0.586      |
|    learning_rate        | 0.00106    |
|    loss                 | 0.0171     |
|    n_updates            | 23610      |
|    policy_gradient_loss | 0.0101     |
|    std                  | 0.241      |
|    value_loss           | 0.00736    |
----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 630       |
|    iterations           | 2363      |
|    time_elapsed         | 7675      |
|    total_timesteps      | 4839424   |
| train/                  |           |
|    approx_kl            | 0.2407827 |
|    clip_fraction        | 0.428     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0146   |
|    explained_variance   | 0.233     |
|    learning_rate        | 0.00106   |
|    loss                 | 0.00881   |
|    n_updates            | 23620     |
|    policy_gradient_loss | 0.0291    |
|    std                  | 0.25      |
|    value_loss           | 0.0187    |
---------------------------------------
Eval num_timesteps=4840000, episode_reward=-1.08 +/- 0.15
Episode length: 300.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 300       |
|    mean_reward          | -1.08     |
| time/                   |           |
|    total_timesteps      | 4840000   |
| train/                  |           |
|    approx_kl            | 0.1921813 |
|    clip_fraction        | 0.394     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.0945   |
|    explained_variance   | -0.429    |
|    learning_rate        | 0.00106   |
|    loss                 | -0.00742  |
|    n_updates            | 23630     |
|    policy_gradient_loss | 0.00812   |
|    std                  | 0.258     |
|    value_loss           | 0.00887   |
---------------------------------------
--------------------------------
| time/              |         |
|    fps             | 630     |
|    iterations      | 2364    |
|    time_elapsed    | 7679    |
|    total_timesteps | 4841472 |
--------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 630       |
|    iterations           | 2365      |
|    time_elapsed         | 7682      |
|    total_timesteps      | 4843520   |
| train/                  |           |
|    approx_kl            | 0.1551491 |
|    clip_fraction        | 0.386     |
|    clip_range           | 0.2       |
|    entropy_loss         | -0.109    |
|    explained_variance   | 0.247     |
|    learning_rate        | 0.00106   |
|    loss                 | 0.00559   |
|    n_updates            | 23640     |
|    policy_gradient_loss | 0.00881   |
|    std                  | 0.257     |
|    value_loss           | 0.00626   |
---------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2366       |
|    time_elapsed         | 7686       |
|    total_timesteps      | 4845568    |
| train/                  |            |
|    approx_kl            | 0.27245703 |
|    clip_fraction        | 0.432      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.0876    |
|    explained_variance   | 0.827      |
|    learning_rate        | 0.00106    |
|    loss                 | 0.00983    |
|    n_updates            | 23650      |
|    policy_gradient_loss | 0.00478    |
|    std                  | 0.254      |
|    value_loss           | 0.0106     |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2367       |
|    time_elapsed         | 7689       |
|    total_timesteps      | 4847616    |
| train/                  |            |
|    approx_kl            | 0.16249079 |
|    clip_fraction        | 0.373      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.0258    |
|    explained_variance   | 0.866      |
|    learning_rate        | 0.00106    |
|    loss                 | -0.0204    |
|    n_updates            | 23660      |
|    policy_gradient_loss | 0.000436   |
|    std                  | 0.243      |
|    value_loss           | 0.01       |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2368       |
|    time_elapsed         | 7692       |
|    total_timesteps      | 4849664    |
| train/                  |            |
|    approx_kl            | 0.41034716 |
|    clip_fraction        | 0.462      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.0287     |
|    explained_variance   | 0.592      |
|    learning_rate        | 0.00105    |
|    loss                 | 0.00494    |
|    n_updates            | 23670      |
|    policy_gradient_loss | 0.00804    |
|    std                  | 0.239      |
|    value_loss           | 0.00968    |
----------------------------------------
box reached target
Eval num_timesteps=4850000, episode_reward=0.25 +/- 2.51
Episode length: 278.60 +/- 42.80
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 279        |
|    mean_reward          | 0.253      |
| time/                   |            |
|    total_timesteps      | 4850000    |
| train/                  |            |
|    approx_kl            | 0.17376703 |
|    clip_fraction        | 0.358      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.0124     |
|    explained_variance   | -0.11      |
|    learning_rate        | 0.00105    |
|    loss                 | 0.0439     |
|    n_updates            | 23680      |
|    policy_gradient_loss | 0.0211     |
|    std                  | 0.243      |
|    value_loss           | 0.0223     |
----------------------------------------
box reached target
--------------------------------
| time/              |         |
|    fps             | 630     |
|    iterations      | 2369    |
|    time_elapsed    | 7696    |
|    total_timesteps | 4851712 |
--------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 630       |
|    iterations           | 2370      |
|    time_elapsed         | 7699      |
|    total_timesteps      | 4853760   |
| train/                  |           |
|    approx_kl            | 0.3092882 |
|    clip_fraction        | 0.434     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.00111   |
|    explained_variance   | 0.55      |
|    learning_rate        | 0.00105   |
|    loss                 | 0.0557    |
|    n_updates            | 23690     |
|    policy_gradient_loss | 0.0103    |
|    std                  | 0.243     |
|    value_loss           | 0.014     |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2371       |
|    time_elapsed         | 7702       |
|    total_timesteps      | 4855808    |
| train/                  |            |
|    approx_kl            | 0.16508321 |
|    clip_fraction        | 0.378      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.0082     |
|    explained_variance   | 0.804      |
|    learning_rate        | 0.00105    |
|    loss                 | 0.0237     |
|    n_updates            | 23700      |
|    policy_gradient_loss | -0.00325   |
|    std                  | 0.242      |
|    value_loss           | 0.00824    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2372       |
|    time_elapsed         | 7705       |
|    total_timesteps      | 4857856    |
| train/                  |            |
|    approx_kl            | 0.24865043 |
|    clip_fraction        | 0.397      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.0188     |
|    explained_variance   | 0.301      |
|    learning_rate        | 0.00105    |
|    loss                 | 0.0263     |
|    n_updates            | 23710      |
|    policy_gradient_loss | 0.0116     |
|    std                  | 0.239      |
|    value_loss           | 0.00814    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2373       |
|    time_elapsed         | 7708       |
|    total_timesteps      | 4859904    |
| train/                  |            |
|    approx_kl            | 0.20607598 |
|    clip_fraction        | 0.387      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.00163   |
|    explained_variance   | 0.738      |
|    learning_rate        | 0.00105    |
|    loss                 | 0.0388     |
|    n_updates            | 23720      |
|    policy_gradient_loss | 0.001      |
|    std                  | 0.244      |
|    value_loss           | 0.00583    |
----------------------------------------
Eval num_timesteps=4860000, episode_reward=-0.71 +/- 0.58
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -0.709     |
| time/                   |            |
|    total_timesteps      | 4860000    |
| train/                  |            |
|    approx_kl            | 0.56854117 |
|    clip_fraction        | 0.4        |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.0121    |
|    explained_variance   | 0.748      |
|    learning_rate        | 0.00105    |
|    loss                 | 0.143      |
|    n_updates            | 23730      |
|    policy_gradient_loss | 0.0294     |
|    std                  | 0.24       |
|    value_loss           | 0.00622    |
----------------------------------------
box reached target
box reached target
box reached target
--------------------------------
| time/              |         |
|    fps             | 630     |
|    iterations      | 2374    |
|    time_elapsed    | 7712    |
|    total_timesteps | 4861952 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2375       |
|    time_elapsed         | 7715       |
|    total_timesteps      | 4864000    |
| train/                  |            |
|    approx_kl            | 0.23560089 |
|    clip_fraction        | 0.466      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.0327     |
|    explained_variance   | 0.929      |
|    learning_rate        | 0.00105    |
|    loss                 | 0.0162     |
|    n_updates            | 23740      |
|    policy_gradient_loss | 0.0063     |
|    std                  | 0.238      |
|    value_loss           | 0.0174     |
----------------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2376       |
|    time_elapsed         | 7718       |
|    total_timesteps      | 4866048    |
| train/                  |            |
|    approx_kl            | 0.24465731 |
|    clip_fraction        | 0.374      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.0305     |
|    explained_variance   | 0.166      |
|    learning_rate        | 0.00105    |
|    loss                 | -0.0105    |
|    n_updates            | 23750      |
|    policy_gradient_loss | 0.00228    |
|    std                  | 0.239      |
|    value_loss           | 0.00234    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2377       |
|    time_elapsed         | 7721       |
|    total_timesteps      | 4868096    |
| train/                  |            |
|    approx_kl            | 0.13445854 |
|    clip_fraction        | 0.418      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.00796   |
|    explained_variance   | 0.656      |
|    learning_rate        | 0.00105    |
|    loss                 | 0.0762     |
|    n_updates            | 23760      |
|    policy_gradient_loss | 0.0166     |
|    std                  | 0.247      |
|    value_loss           | 0.0479     |
----------------------------------------
box reached target
box reached target
Eval num_timesteps=4870000, episode_reward=-0.98 +/- 0.05
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -0.977     |
| time/                   |            |
|    total_timesteps      | 4870000    |
| train/                  |            |
|    approx_kl            | 0.14749786 |
|    clip_fraction        | 0.357      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.0552    |
|    explained_variance   | 0.389      |
|    learning_rate        | 0.00105    |
|    loss                 | -0.00654   |
|    n_updates            | 23770      |
|    policy_gradient_loss | -0.00392   |
|    std                  | 0.248      |
|    value_loss           | 0.0066     |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 630     |
|    iterations      | 2378    |
|    time_elapsed    | 7725    |
|    total_timesteps | 4870144 |
--------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2379       |
|    time_elapsed         | 7728       |
|    total_timesteps      | 4872192    |
| train/                  |            |
|    approx_kl            | 0.09021491 |
|    clip_fraction        | 0.343      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.075     |
|    explained_variance   | 0.879      |
|    learning_rate        | 0.00105    |
|    loss                 | 0.109      |
|    n_updates            | 23780      |
|    policy_gradient_loss | 0.00805    |
|    std                  | 0.252      |
|    value_loss           | 0.025      |
----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 630         |
|    iterations           | 2380        |
|    time_elapsed         | 7731        |
|    total_timesteps      | 4874240     |
| train/                  |             |
|    approx_kl            | 0.122894175 |
|    clip_fraction        | 0.373       |
|    clip_range           | 0.2         |
|    entropy_loss         | -0.0697     |
|    explained_variance   | 0.931       |
|    learning_rate        | 0.00105     |
|    loss                 | -0.00454    |
|    n_updates            | 23790       |
|    policy_gradient_loss | 0.00163     |
|    std                  | 0.25        |
|    value_loss           | 0.0107      |
-----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2381       |
|    time_elapsed         | 7734       |
|    total_timesteps      | 4876288    |
| train/                  |            |
|    approx_kl            | 0.18554965 |
|    clip_fraction        | 0.42       |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.0749    |
|    explained_variance   | 0.709      |
|    learning_rate        | 0.00105    |
|    loss                 | -0.0348    |
|    n_updates            | 23800      |
|    policy_gradient_loss | -0.00403   |
|    std                  | 0.252      |
|    value_loss           | 0.00538    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2382       |
|    time_elapsed         | 7737       |
|    total_timesteps      | 4878336    |
| train/                  |            |
|    approx_kl            | 0.27291125 |
|    clip_fraction        | 0.368      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.058     |
|    explained_variance   | 0.47       |
|    learning_rate        | 0.00105    |
|    loss                 | -0.0111    |
|    n_updates            | 23810      |
|    policy_gradient_loss | -0.00639   |
|    std                  | 0.247      |
|    value_loss           | 0.00531    |
----------------------------------------
box reached target
box reached target
Eval num_timesteps=4880000, episode_reward=0.40 +/- 2.42
Episode length: 278.40 +/- 43.20
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 278        |
|    mean_reward          | 0.401      |
| time/                   |            |
|    total_timesteps      | 4880000    |
| train/                  |            |
|    approx_kl            | 0.14543562 |
|    clip_fraction        | 0.349      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.0298    |
|    explained_variance   | 0.651      |
|    learning_rate        | 0.00105    |
|    loss                 | 0.121      |
|    n_updates            | 23820      |
|    policy_gradient_loss | 0.00206    |
|    std                  | 0.244      |
|    value_loss           | 0.00915    |
----------------------------------------
box reached target
--------------------------------
| time/              |         |
|    fps             | 630     |
|    iterations      | 2383    |
|    time_elapsed    | 7741    |
|    total_timesteps | 4880384 |
--------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2384       |
|    time_elapsed         | 7744       |
|    total_timesteps      | 4882432    |
| train/                  |            |
|    approx_kl            | 0.12474929 |
|    clip_fraction        | 0.329      |
|    clip_range           | 0.2        |
|    entropy_loss         | -0.00463   |
|    explained_variance   | 0.83       |
|    learning_rate        | 0.00105    |
|    loss                 | 0.0463     |
|    n_updates            | 23830      |
|    policy_gradient_loss | -0.000244  |
|    std                  | 0.241      |
|    value_loss           | 0.0292     |
----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 630       |
|    iterations           | 2385      |
|    time_elapsed         | 7747      |
|    total_timesteps      | 4884480   |
| train/                  |           |
|    approx_kl            | 0.2690676 |
|    clip_fraction        | 0.402     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.0121    |
|    explained_variance   | 0.845     |
|    learning_rate        | 0.00105   |
|    loss                 | -0.0506   |
|    n_updates            | 23840     |
|    policy_gradient_loss | -0.00414  |
|    std                  | 0.241     |
|    value_loss           | 0.0259    |
---------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2386       |
|    time_elapsed         | 7750       |
|    total_timesteps      | 4886528    |
| train/                  |            |
|    approx_kl            | 0.16385743 |
|    clip_fraction        | 0.335      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.0297     |
|    explained_variance   | 0.695      |
|    learning_rate        | 0.00105    |
|    loss                 | 0.0156     |
|    n_updates            | 23850      |
|    policy_gradient_loss | 0.0051     |
|    std                  | 0.239      |
|    value_loss           | 0.00454    |
----------------------------------------
box reached target
box reached target
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2387       |
|    time_elapsed         | 7753       |
|    total_timesteps      | 4888576    |
| train/                  |            |
|    approx_kl            | 0.23965037 |
|    clip_fraction        | 0.394      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.0331     |
|    explained_variance   | 0.925      |
|    learning_rate        | 0.00105    |
|    loss                 | -0.0714    |
|    n_updates            | 23860      |
|    policy_gradient_loss | 0.00239    |
|    std                  | 0.237      |
|    value_loss           | 0.0112     |
----------------------------------------
box reached target
box reached target
box reached target
Eval num_timesteps=4890000, episode_reward=0.22 +/- 2.44
Episode length: 269.20 +/- 61.60
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 269        |
|    mean_reward          | 0.222      |
| time/                   |            |
|    total_timesteps      | 4890000    |
| train/                  |            |
|    approx_kl            | 0.23113658 |
|    clip_fraction        | 0.421      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.0779     |
|    explained_variance   | 0.863      |
|    learning_rate        | 0.00105    |
|    loss                 | 0.0046     |
|    n_updates            | 23870      |
|    policy_gradient_loss | 0.00104    |
|    std                  | 0.23       |
|    value_loss           | 0.0651     |
----------------------------------------
box reached target
--------------------------------
| time/              |         |
|    fps             | 630     |
|    iterations      | 2388    |
|    time_elapsed    | 7757    |
|    total_timesteps | 4890624 |
--------------------------------
box reached target
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2389       |
|    time_elapsed         | 7760       |
|    total_timesteps      | 4892672    |
| train/                  |            |
|    approx_kl            | 0.13359526 |
|    clip_fraction        | 0.366      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.0977     |
|    explained_variance   | 0.92       |
|    learning_rate        | 0.00105    |
|    loss                 | 0.0117     |
|    n_updates            | 23880      |
|    policy_gradient_loss | 0.00599    |
|    std                  | 0.231      |
|    value_loss           | 0.0331     |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2390       |
|    time_elapsed         | 7763       |
|    total_timesteps      | 4894720    |
| train/                  |            |
|    approx_kl            | 0.21422657 |
|    clip_fraction        | 0.358      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.0739     |
|    explained_variance   | 0.901      |
|    learning_rate        | 0.00105    |
|    loss                 | -0.00113   |
|    n_updates            | 23890      |
|    policy_gradient_loss | 0.0269     |
|    std                  | 0.234      |
|    value_loss           | 0.0163     |
----------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 630       |
|    iterations           | 2391      |
|    time_elapsed         | 7766      |
|    total_timesteps      | 4896768   |
| train/                  |           |
|    approx_kl            | 0.4552191 |
|    clip_fraction        | 0.352     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.101     |
|    explained_variance   | 0.892     |
|    learning_rate        | 0.00105   |
|    loss                 | -0.0309   |
|    n_updates            | 23900     |
|    policy_gradient_loss | 0.00302   |
|    std                  | 0.229     |
|    value_loss           | 0.0113    |
---------------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2392       |
|    time_elapsed         | 7769       |
|    total_timesteps      | 4898816    |
| train/                  |            |
|    approx_kl            | 0.37540418 |
|    clip_fraction        | 0.411      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.112      |
|    explained_variance   | 0.803      |
|    learning_rate        | 0.00105    |
|    loss                 | -0.0553    |
|    n_updates            | 23910      |
|    policy_gradient_loss | 0.0104     |
|    std                  | 0.228      |
|    value_loss           | 0.00586    |
----------------------------------------
box reached target
box reached target
box reached target
Eval num_timesteps=4900000, episode_reward=0.49 +/- 2.48
Episode length: 287.40 +/- 25.20
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 287        |
|    mean_reward          | 0.488      |
| time/                   |            |
|    total_timesteps      | 4900000    |
| train/                  |            |
|    approx_kl            | 0.17979713 |
|    clip_fraction        | 0.406      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.125      |
|    explained_variance   | 0.752      |
|    learning_rate        | 0.00104    |
|    loss                 | -0.0286    |
|    n_updates            | 23920      |
|    policy_gradient_loss | 0.0102     |
|    std                  | 0.226      |
|    value_loss           | 0.121      |
----------------------------------------
box reached target
--------------------------------
| time/              |         |
|    fps             | 630     |
|    iterations      | 2393    |
|    time_elapsed    | 7773    |
|    total_timesteps | 4900864 |
--------------------------------
box reached target
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 630       |
|    iterations           | 2394      |
|    time_elapsed         | 7776      |
|    total_timesteps      | 4902912   |
| train/                  |           |
|    approx_kl            | 0.2486524 |
|    clip_fraction        | 0.42      |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.167     |
|    explained_variance   | 0.776     |
|    learning_rate        | 0.00104   |
|    loss                 | 0.0148    |
|    n_updates            | 23930     |
|    policy_gradient_loss | 0.0105    |
|    std                  | 0.22      |
|    value_loss           | 0.0596    |
---------------------------------------
box reached target
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 630       |
|    iterations           | 2395      |
|    time_elapsed         | 7779      |
|    total_timesteps      | 4904960   |
| train/                  |           |
|    approx_kl            | 0.2523605 |
|    clip_fraction        | 0.392     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.239     |
|    explained_variance   | 0.814     |
|    learning_rate        | 0.00104   |
|    loss                 | -0.0281   |
|    n_updates            | 23940     |
|    policy_gradient_loss | -0.00683  |
|    std                  | 0.211     |
|    value_loss           | 0.0294    |
---------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2396       |
|    time_elapsed         | 7782       |
|    total_timesteps      | 4907008    |
| train/                  |            |
|    approx_kl            | 0.55270493 |
|    clip_fraction        | 0.439      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.281      |
|    explained_variance   | 0.909      |
|    learning_rate        | 0.00104    |
|    loss                 | -0.0228    |
|    n_updates            | 23950      |
|    policy_gradient_loss | 0.00846    |
|    std                  | 0.21       |
|    value_loss           | 0.0132     |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2397       |
|    time_elapsed         | 7785       |
|    total_timesteps      | 4909056    |
| train/                  |            |
|    approx_kl            | 0.32884014 |
|    clip_fraction        | 0.436      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.277      |
|    explained_variance   | 0.843      |
|    learning_rate        | 0.00104    |
|    loss                 | -0.0186    |
|    n_updates            | 23960      |
|    policy_gradient_loss | 0.00249    |
|    std                  | 0.21       |
|    value_loss           | 0.021      |
----------------------------------------
box reached target
box reached target
box reached target
Eval num_timesteps=4910000, episode_reward=-0.73 +/- 0.73
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -0.73      |
| time/                   |            |
|    total_timesteps      | 4910000    |
| train/                  |            |
|    approx_kl            | 0.34918052 |
|    clip_fraction        | 0.446      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.269      |
|    explained_variance   | 0.725      |
|    learning_rate        | 0.00104    |
|    loss                 | 0.0368     |
|    n_updates            | 23970      |
|    policy_gradient_loss | 0.0133     |
|    std                  | 0.211      |
|    value_loss           | 0.0116     |
----------------------------------------
box reached target
box reached target
--------------------------------
| time/              |         |
|    fps             | 630     |
|    iterations      | 2398    |
|    time_elapsed    | 7789    |
|    total_timesteps | 4911104 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2399       |
|    time_elapsed         | 7792       |
|    total_timesteps      | 4913152    |
| train/                  |            |
|    approx_kl            | 0.21474934 |
|    clip_fraction        | 0.419      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.281      |
|    explained_variance   | 0.891      |
|    learning_rate        | 0.00104    |
|    loss                 | 0.0459     |
|    n_updates            | 23980      |
|    policy_gradient_loss | 0.0422     |
|    std                  | 0.212      |
|    value_loss           | 0.0399     |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2400       |
|    time_elapsed         | 7795       |
|    total_timesteps      | 4915200    |
| train/                  |            |
|    approx_kl            | 0.21012047 |
|    clip_fraction        | 0.448      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.246      |
|    explained_variance   | 0.643      |
|    learning_rate        | 0.00104    |
|    loss                 | 0.00346    |
|    n_updates            | 23990      |
|    policy_gradient_loss | 0.00565    |
|    std                  | 0.216      |
|    value_loss           | 0.0159     |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2401       |
|    time_elapsed         | 7798       |
|    total_timesteps      | 4917248    |
| train/                  |            |
|    approx_kl            | 0.26065558 |
|    clip_fraction        | 0.433      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.186      |
|    explained_variance   | 0.336      |
|    learning_rate        | 0.00104    |
|    loss                 | -0.00997   |
|    n_updates            | 24000      |
|    policy_gradient_loss | 0.0346     |
|    std                  | 0.221      |
|    value_loss           | 0.00533    |
----------------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2402       |
|    time_elapsed         | 7802       |
|    total_timesteps      | 4919296    |
| train/                  |            |
|    approx_kl            | 0.28146958 |
|    clip_fraction        | 0.459      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.204      |
|    explained_variance   | 0.142      |
|    learning_rate        | 0.00104    |
|    loss                 | 0.0387     |
|    n_updates            | 24010      |
|    policy_gradient_loss | 0.0462     |
|    std                  | 0.217      |
|    value_loss           | 0.0439     |
----------------------------------------
box reached target
box reached target
box reached target
Eval num_timesteps=4920000, episode_reward=1.44 +/- 2.91
Episode length: 249.00 +/- 62.47
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 249       |
|    mean_reward          | 1.44      |
| time/                   |           |
|    total_timesteps      | 4920000   |
| train/                  |           |
|    approx_kl            | 0.2628789 |
|    clip_fraction        | 0.416     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.204     |
|    explained_variance   | 0.8       |
|    learning_rate        | 0.00104   |
|    loss                 | 0.0111    |
|    n_updates            | 24020     |
|    policy_gradient_loss | 0.000709  |
|    std                  | 0.218     |
|    value_loss           | 0.0465    |
---------------------------------------
--------------------------------
| time/              |         |
|    fps             | 630     |
|    iterations      | 2403    |
|    time_elapsed    | 7805    |
|    total_timesteps | 4921344 |
--------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 630       |
|    iterations           | 2404      |
|    time_elapsed         | 7808      |
|    total_timesteps      | 4923392   |
| train/                  |           |
|    approx_kl            | 0.2402712 |
|    clip_fraction        | 0.396     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.213     |
|    explained_variance   | 0.912     |
|    learning_rate        | 0.00104   |
|    loss                 | -0.00131  |
|    n_updates            | 24030     |
|    policy_gradient_loss | -0.00222  |
|    std                  | 0.215     |
|    value_loss           | 0.0126    |
---------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2405       |
|    time_elapsed         | 7811       |
|    total_timesteps      | 4925440    |
| train/                  |            |
|    approx_kl            | 0.16204172 |
|    clip_fraction        | 0.414      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.198      |
|    explained_variance   | 0.729      |
|    learning_rate        | 0.00104    |
|    loss                 | 0.00926    |
|    n_updates            | 24040      |
|    policy_gradient_loss | 0.0192     |
|    std                  | 0.221      |
|    value_loss           | 0.0413     |
----------------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2406       |
|    time_elapsed         | 7814       |
|    total_timesteps      | 4927488    |
| train/                  |            |
|    approx_kl            | 0.20861888 |
|    clip_fraction        | 0.425      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.187      |
|    explained_variance   | -0.0422    |
|    learning_rate        | 0.00104    |
|    loss                 | 0.0608     |
|    n_updates            | 24050      |
|    policy_gradient_loss | 0.0102     |
|    std                  | 0.219      |
|    value_loss           | 0.0196     |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2407       |
|    time_elapsed         | 7818       |
|    total_timesteps      | 4929536    |
| train/                  |            |
|    approx_kl            | 0.31759334 |
|    clip_fraction        | 0.415      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.216      |
|    explained_variance   | 0.752      |
|    learning_rate        | 0.00104    |
|    loss                 | 0.00295    |
|    n_updates            | 24060      |
|    policy_gradient_loss | 0.0177     |
|    std                  | 0.214      |
|    value_loss           | 0.0136     |
----------------------------------------
box reached target
Eval num_timesteps=4930000, episode_reward=0.43 +/- 2.45
Episode length: 267.80 +/- 64.40
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 268        |
|    mean_reward          | 0.431      |
| time/                   |            |
|    total_timesteps      | 4930000    |
| train/                  |            |
|    approx_kl            | 0.14514525 |
|    clip_fraction        | 0.392      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.221      |
|    explained_variance   | 0.768      |
|    learning_rate        | 0.00104    |
|    loss                 | -0.0381    |
|    n_updates            | 24070      |
|    policy_gradient_loss | 0.00367    |
|    std                  | 0.217      |
|    value_loss           | 0.0151     |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 630     |
|    iterations      | 2408    |
|    time_elapsed    | 7821    |
|    total_timesteps | 4931584 |
--------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2409       |
|    time_elapsed         | 7824       |
|    total_timesteps      | 4933632    |
| train/                  |            |
|    approx_kl            | 0.23676446 |
|    clip_fraction        | 0.459      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.207      |
|    explained_variance   | -0.245     |
|    learning_rate        | 0.00104    |
|    loss                 | 0.00832    |
|    n_updates            | 24080      |
|    policy_gradient_loss | 0.00832    |
|    std                  | 0.216      |
|    value_loss           | 0.00624    |
----------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 630       |
|    iterations           | 2410      |
|    time_elapsed         | 7828      |
|    total_timesteps      | 4935680   |
| train/                  |           |
|    approx_kl            | 0.1083424 |
|    clip_fraction        | 0.399     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.197     |
|    explained_variance   | 0.832     |
|    learning_rate        | 0.00104   |
|    loss                 | 0.113     |
|    n_updates            | 24090     |
|    policy_gradient_loss | 0.017     |
|    std                  | 0.22      |
|    value_loss           | 0.0252    |
---------------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2411       |
|    time_elapsed         | 7831       |
|    total_timesteps      | 4937728    |
| train/                  |            |
|    approx_kl            | 0.21134676 |
|    clip_fraction        | 0.376      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.2        |
|    explained_variance   | 0.726      |
|    learning_rate        | 0.00104    |
|    loss                 | 0.00901    |
|    n_updates            | 24100      |
|    policy_gradient_loss | -0.000702  |
|    std                  | 0.219      |
|    value_loss           | 0.0112     |
----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 630       |
|    iterations           | 2412      |
|    time_elapsed         | 7834      |
|    total_timesteps      | 4939776   |
| train/                  |           |
|    approx_kl            | 0.2457453 |
|    clip_fraction        | 0.476     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.124     |
|    explained_variance   | 0.844     |
|    learning_rate        | 0.00104   |
|    loss                 | -0.00621  |
|    n_updates            | 24110     |
|    policy_gradient_loss | 0.00993   |
|    std                  | 0.231     |
|    value_loss           | 0.017     |
---------------------------------------
box reached target
Eval num_timesteps=4940000, episode_reward=0.60 +/- 2.31
Episode length: 273.00 +/- 54.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 273        |
|    mean_reward          | 0.596      |
| time/                   |            |
|    total_timesteps      | 4940000    |
| train/                  |            |
|    approx_kl            | 0.13481921 |
|    clip_fraction        | 0.381      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.0837     |
|    explained_variance   | 0.736      |
|    learning_rate        | 0.00104    |
|    loss                 | 0.201      |
|    n_updates            | 24120      |
|    policy_gradient_loss | 0.0163     |
|    std                  | 0.233      |
|    value_loss           | 0.00432    |
----------------------------------------
box reached target
box reached target
box reached target
--------------------------------
| time/              |         |
|    fps             | 630     |
|    iterations      | 2413    |
|    time_elapsed    | 7838    |
|    total_timesteps | 4941824 |
--------------------------------
box reached target
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 630       |
|    iterations           | 2414      |
|    time_elapsed         | 7841      |
|    total_timesteps      | 4943872   |
| train/                  |           |
|    approx_kl            | 0.7332598 |
|    clip_fraction        | 0.452     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.086     |
|    explained_variance   | 0.861     |
|    learning_rate        | 0.00104   |
|    loss                 | 0.0107    |
|    n_updates            | 24130     |
|    policy_gradient_loss | 0.00291   |
|    std                  | 0.228     |
|    value_loss           | 0.0355    |
---------------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2415       |
|    time_elapsed         | 7844       |
|    total_timesteps      | 4945920    |
| train/                  |            |
|    approx_kl            | 0.34051988 |
|    clip_fraction        | 0.442      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.0876     |
|    explained_variance   | 0.877      |
|    learning_rate        | 0.00104    |
|    loss                 | 0.0737     |
|    n_updates            | 24140      |
|    policy_gradient_loss | 0.00244    |
|    std                  | 0.234      |
|    value_loss           | 0.0223     |
----------------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2416       |
|    time_elapsed         | 7847       |
|    total_timesteps      | 4947968    |
| train/                  |            |
|    approx_kl            | 0.26901174 |
|    clip_fraction        | 0.384      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.073      |
|    explained_variance   | 0.804      |
|    learning_rate        | 0.00104    |
|    loss                 | 0.0186     |
|    n_updates            | 24150      |
|    policy_gradient_loss | 0.00177    |
|    std                  | 0.232      |
|    value_loss           | 0.038      |
----------------------------------------
box reached target
Eval num_timesteps=4950000, episode_reward=-0.72 +/- 0.55
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -0.723     |
| time/                   |            |
|    total_timesteps      | 4950000    |
| train/                  |            |
|    approx_kl            | 0.24810717 |
|    clip_fraction        | 0.401      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.0505     |
|    explained_variance   | 0.875      |
|    learning_rate        | 0.00104    |
|    loss                 | -0.0253    |
|    n_updates            | 24160      |
|    policy_gradient_loss | 0.00338    |
|    std                  | 0.238      |
|    value_loss           | 0.028      |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 630     |
|    iterations      | 2417    |
|    time_elapsed    | 7851    |
|    total_timesteps | 4950016 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2418       |
|    time_elapsed         | 7854       |
|    total_timesteps      | 4952064    |
| train/                  |            |
|    approx_kl            | 0.13143447 |
|    clip_fraction        | 0.384      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.0505     |
|    explained_variance   | 0.889      |
|    learning_rate        | 0.00103    |
|    loss                 | 0.0188     |
|    n_updates            | 24170      |
|    policy_gradient_loss | -0.000496  |
|    std                  | 0.233      |
|    value_loss           | 0.0126     |
----------------------------------------
--------------------------------------
| time/                   |          |
|    fps                  | 630      |
|    iterations           | 2419     |
|    time_elapsed         | 7857     |
|    total_timesteps      | 4954112  |
| train/                  |          |
|    approx_kl            | 1.010068 |
|    clip_fraction        | 0.41     |
|    clip_range           | 0.2      |
|    entropy_loss         | 0.0951   |
|    explained_variance   | 0.825    |
|    learning_rate        | 0.00103  |
|    loss                 | -0.00502 |
|    n_updates            | 24180    |
|    policy_gradient_loss | -0.0209  |
|    std                  | 0.226    |
|    value_loss           | 0.0152   |
--------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 630       |
|    iterations           | 2420      |
|    time_elapsed         | 7860      |
|    total_timesteps      | 4956160   |
| train/                  |           |
|    approx_kl            | 0.5749786 |
|    clip_fraction        | 0.413     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.141     |
|    explained_variance   | 0.852     |
|    learning_rate        | 0.00103   |
|    loss                 | -0.0295   |
|    n_updates            | 24190     |
|    policy_gradient_loss | 0.00385   |
|    std                  | 0.221     |
|    value_loss           | 0.0106    |
---------------------------------------
box reached target
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2421       |
|    time_elapsed         | 7863       |
|    total_timesteps      | 4958208    |
| train/                  |            |
|    approx_kl            | 0.32661253 |
|    clip_fraction        | 0.446      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.192      |
|    explained_variance   | 0.483      |
|    learning_rate        | 0.00103    |
|    loss                 | 0.0131     |
|    n_updates            | 24200      |
|    policy_gradient_loss | 0.00318    |
|    std                  | 0.216      |
|    value_loss           | 0.011      |
----------------------------------------
box reached target
box reached target
box reached target
Eval num_timesteps=4960000, episode_reward=1.74 +/- 2.91
Episode length: 256.00 +/- 59.80
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 256        |
|    mean_reward          | 1.74       |
| time/                   |            |
|    total_timesteps      | 4960000    |
| train/                  |            |
|    approx_kl            | 0.11252233 |
|    clip_fraction        | 0.423      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.246      |
|    explained_variance   | 0.759      |
|    learning_rate        | 0.00103    |
|    loss                 | 0.039      |
|    n_updates            | 24210      |
|    policy_gradient_loss | 0.0111     |
|    std                  | 0.213      |
|    value_loss           | 0.0469     |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 630     |
|    iterations      | 2422    |
|    time_elapsed    | 7867    |
|    total_timesteps | 4960256 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2423       |
|    time_elapsed         | 7870       |
|    total_timesteps      | 4962304    |
| train/                  |            |
|    approx_kl            | 0.21898112 |
|    clip_fraction        | 0.444      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.24       |
|    explained_variance   | 0.737      |
|    learning_rate        | 0.00103    |
|    loss                 | -0.0401    |
|    n_updates            | 24220      |
|    policy_gradient_loss | 0.0157     |
|    std                  | 0.214      |
|    value_loss           | 0.0283     |
----------------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2424       |
|    time_elapsed         | 7873       |
|    total_timesteps      | 4964352    |
| train/                  |            |
|    approx_kl            | 0.30409938 |
|    clip_fraction        | 0.375      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.203      |
|    explained_variance   | 0.754      |
|    learning_rate        | 0.00103    |
|    loss                 | -0.0398    |
|    n_updates            | 24230      |
|    policy_gradient_loss | -0.00963   |
|    std                  | 0.219      |
|    value_loss           | 0.00969    |
----------------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2425       |
|    time_elapsed         | 7876       |
|    total_timesteps      | 4966400    |
| train/                  |            |
|    approx_kl            | 0.21134834 |
|    clip_fraction        | 0.477      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.168      |
|    explained_variance   | 0.89       |
|    learning_rate        | 0.00103    |
|    loss                 | -0.00376   |
|    n_updates            | 24240      |
|    policy_gradient_loss | 0.0235     |
|    std                  | 0.221      |
|    value_loss           | 0.0103     |
----------------------------------------
box reached target
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2426       |
|    time_elapsed         | 7879       |
|    total_timesteps      | 4968448    |
| train/                  |            |
|    approx_kl            | 0.15990457 |
|    clip_fraction        | 0.408      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.105      |
|    explained_variance   | 0.788      |
|    learning_rate        | 0.00103    |
|    loss                 | 0.0293     |
|    n_updates            | 24250      |
|    policy_gradient_loss | 0.014      |
|    std                  | 0.235      |
|    value_loss           | 0.0411     |
----------------------------------------
box reached target
box reached target
Eval num_timesteps=4970000, episode_reward=0.48 +/- 2.36
Episode length: 272.80 +/- 54.40
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 273        |
|    mean_reward          | 0.484      |
| time/                   |            |
|    total_timesteps      | 4970000    |
| train/                  |            |
|    approx_kl            | 0.09621841 |
|    clip_fraction        | 0.381      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.0519     |
|    explained_variance   | 0.777      |
|    learning_rate        | 0.00103    |
|    loss                 | 0.0156     |
|    n_updates            | 24260      |
|    policy_gradient_loss | 0.00693    |
|    std                  | 0.235      |
|    value_loss           | 0.0305     |
----------------------------------------
box reached target
--------------------------------
| time/              |         |
|    fps             | 630     |
|    iterations      | 2427    |
|    time_elapsed    | 7883    |
|    total_timesteps | 4970496 |
--------------------------------
box reached target
box reached target
--------------------------------------
| time/                   |          |
|    fps                  | 630      |
|    iterations           | 2428     |
|    time_elapsed         | 7886     |
|    total_timesteps      | 4972544  |
| train/                  |          |
|    approx_kl            | 0.308677 |
|    clip_fraction        | 0.431    |
|    clip_range           | 0.2      |
|    entropy_loss         | 0.0249   |
|    explained_variance   | 0.636    |
|    learning_rate        | 0.00103  |
|    loss                 | 0.0237   |
|    n_updates            | 24270    |
|    policy_gradient_loss | 0.00945  |
|    std                  | 0.238    |
|    value_loss           | 0.0528   |
--------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2429       |
|    time_elapsed         | 7889       |
|    total_timesteps      | 4974592    |
| train/                  |            |
|    approx_kl            | 0.08518919 |
|    clip_fraction        | 0.366      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.0308     |
|    explained_variance   | 0.79       |
|    learning_rate        | 0.00103    |
|    loss                 | -0.0066    |
|    n_updates            | 24280      |
|    policy_gradient_loss | 0.00279    |
|    std                  | 0.237      |
|    value_loss           | 0.0308     |
----------------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2430       |
|    time_elapsed         | 7892       |
|    total_timesteps      | 4976640    |
| train/                  |            |
|    approx_kl            | 0.24994779 |
|    clip_fraction        | 0.408      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.0332     |
|    explained_variance   | 0.792      |
|    learning_rate        | 0.00103    |
|    loss                 | 0.045      |
|    n_updates            | 24290      |
|    policy_gradient_loss | 0.00483    |
|    std                  | 0.238      |
|    value_loss           | 0.00681    |
----------------------------------------
box reached target
box reached target
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 630       |
|    iterations           | 2431      |
|    time_elapsed         | 7895      |
|    total_timesteps      | 4978688   |
| train/                  |           |
|    approx_kl            | 0.2354612 |
|    clip_fraction        | 0.399     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.0474    |
|    explained_variance   | 0.858     |
|    learning_rate        | 0.00103   |
|    loss                 | -0.0101   |
|    n_updates            | 24300     |
|    policy_gradient_loss | -0.0054   |
|    std                  | 0.233     |
|    value_loss           | 0.0384    |
---------------------------------------
box reached target
Eval num_timesteps=4980000, episode_reward=-0.48 +/- 0.64
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -0.476     |
| time/                   |            |
|    total_timesteps      | 4980000    |
| train/                  |            |
|    approx_kl            | 0.25470108 |
|    clip_fraction        | 0.371      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.0599     |
|    explained_variance   | 0.87       |
|    learning_rate        | 0.00103    |
|    loss                 | 0.00371    |
|    n_updates            | 24310      |
|    policy_gradient_loss | 0.00423    |
|    std                  | 0.237      |
|    value_loss           | 0.021      |
----------------------------------------
box reached target
--------------------------------
| time/              |         |
|    fps             | 630     |
|    iterations      | 2432    |
|    time_elapsed    | 7899    |
|    total_timesteps | 4980736 |
--------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 630       |
|    iterations           | 2433      |
|    time_elapsed         | 7902      |
|    total_timesteps      | 4982784   |
| train/                  |           |
|    approx_kl            | 0.1249382 |
|    clip_fraction        | 0.401     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.0359    |
|    explained_variance   | 0.904     |
|    learning_rate        | 0.00103   |
|    loss                 | -0.00915  |
|    n_updates            | 24320     |
|    policy_gradient_loss | 0.00663   |
|    std                  | 0.238     |
|    value_loss           | 0.0143    |
---------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2434       |
|    time_elapsed         | 7905       |
|    total_timesteps      | 4984832    |
| train/                  |            |
|    approx_kl            | 0.21689895 |
|    clip_fraction        | 0.385      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.043      |
|    explained_variance   | 0.915      |
|    learning_rate        | 0.00103    |
|    loss                 | 0.0729     |
|    n_updates            | 24330      |
|    policy_gradient_loss | 0.000242   |
|    std                  | 0.234      |
|    value_loss           | 0.0097     |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2435       |
|    time_elapsed         | 7908       |
|    total_timesteps      | 4986880    |
| train/                  |            |
|    approx_kl            | 0.14745626 |
|    clip_fraction        | 0.366      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.0496     |
|    explained_variance   | 0.872      |
|    learning_rate        | 0.00103    |
|    loss                 | -0.0194    |
|    n_updates            | 24340      |
|    policy_gradient_loss | -0.00126   |
|    std                  | 0.236      |
|    value_loss           | 0.0133     |
----------------------------------------
box reached target
box reached target
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2436       |
|    time_elapsed         | 7911       |
|    total_timesteps      | 4988928    |
| train/                  |            |
|    approx_kl            | 0.59581655 |
|    clip_fraction        | 0.402      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.0244     |
|    explained_variance   | 0.814      |
|    learning_rate        | 0.00103    |
|    loss                 | -0.000147  |
|    n_updates            | 24350      |
|    policy_gradient_loss | 0.0227     |
|    std                  | 0.237      |
|    value_loss           | 0.016      |
----------------------------------------
Eval num_timesteps=4990000, episode_reward=-0.68 +/- 0.64
Episode length: 300.00 +/- 0.00
--------------------------------------
| eval/                   |          |
|    mean_ep_length       | 300      |
|    mean_reward          | -0.678   |
| time/                   |          |
|    total_timesteps      | 4990000  |
| train/                  |          |
|    approx_kl            | 0.148978 |
|    clip_fraction        | 0.399    |
|    clip_range           | 0.2      |
|    entropy_loss         | 0.0894   |
|    explained_variance   | 0.795    |
|    learning_rate        | 0.00103  |
|    loss                 | 0.0239   |
|    n_updates            | 24360    |
|    policy_gradient_loss | 0.0073   |
|    std                  | 0.227    |
|    value_loss           | 0.0658   |
--------------------------------------
box reached target
--------------------------------
| time/              |         |
|    fps             | 630     |
|    iterations      | 2437    |
|    time_elapsed    | 7915    |
|    total_timesteps | 4990976 |
--------------------------------
box reached target
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2438       |
|    time_elapsed         | 7918       |
|    total_timesteps      | 4993024    |
| train/                  |            |
|    approx_kl            | 0.22154489 |
|    clip_fraction        | 0.411      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.13       |
|    explained_variance   | 0.874      |
|    learning_rate        | 0.00103    |
|    loss                 | 0.0141     |
|    n_updates            | 24370      |
|    policy_gradient_loss | 0.00923    |
|    std                  | 0.226      |
|    value_loss           | 0.016      |
----------------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2439       |
|    time_elapsed         | 7921       |
|    total_timesteps      | 4995072    |
| train/                  |            |
|    approx_kl            | 0.31367248 |
|    clip_fraction        | 0.457      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.187      |
|    explained_variance   | 0.879      |
|    learning_rate        | 0.00103    |
|    loss                 | 0.00716    |
|    n_updates            | 24380      |
|    policy_gradient_loss | -0.000721  |
|    std                  | 0.215      |
|    value_loss           | 0.0262     |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2440       |
|    time_elapsed         | 7924       |
|    total_timesteps      | 4997120    |
| train/                  |            |
|    approx_kl            | 0.13568072 |
|    clip_fraction        | 0.378      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.219      |
|    explained_variance   | 0.872      |
|    learning_rate        | 0.00103    |
|    loss                 | -0.00604   |
|    n_updates            | 24390      |
|    policy_gradient_loss | 0.000956   |
|    std                  | 0.219      |
|    value_loss           | 0.0293     |
----------------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2441       |
|    time_elapsed         | 7927       |
|    total_timesteps      | 4999168    |
| train/                  |            |
|    approx_kl            | 0.20743307 |
|    clip_fraction        | 0.415      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.171      |
|    explained_variance   | 0.906      |
|    learning_rate        | 0.00103    |
|    loss                 | -0.014     |
|    n_updates            | 24400      |
|    policy_gradient_loss | 0.0129     |
|    std                  | 0.223      |
|    value_loss           | 0.0151     |
----------------------------------------
box reached target
box reached target
Eval num_timesteps=5000000, episode_reward=0.22 +/- 2.52
Episode length: 282.40 +/- 35.20
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 282       |
|    mean_reward          | 0.218     |
| time/                   |           |
|    total_timesteps      | 5000000   |
| train/                  |           |
|    approx_kl            | 0.3194923 |
|    clip_fraction        | 0.366     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.146     |
|    explained_variance   | 0.826     |
|    learning_rate        | 0.00103   |
|    loss                 | -0.0101   |
|    n_updates            | 24410     |
|    policy_gradient_loss | 0.027     |
|    std                  | 0.225     |
|    value_loss           | 0.00981   |
---------------------------------------
--------------------------------
| time/              |         |
|    fps             | 630     |
|    iterations      | 2442    |
|    time_elapsed    | 7931    |
|    total_timesteps | 5001216 |
--------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2443       |
|    time_elapsed         | 7934       |
|    total_timesteps      | 5003264    |
| train/                  |            |
|    approx_kl            | 0.58376205 |
|    clip_fraction        | 0.44       |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.111      |
|    explained_variance   | 0.925      |
|    learning_rate        | 0.00102    |
|    loss                 | -0.0273    |
|    n_updates            | 24420      |
|    policy_gradient_loss | 0.012      |
|    std                  | 0.231      |
|    value_loss           | 0.00675    |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2444       |
|    time_elapsed         | 7937       |
|    total_timesteps      | 5005312    |
| train/                  |            |
|    approx_kl            | 0.44551885 |
|    clip_fraction        | 0.4        |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.108      |
|    explained_variance   | 0.949      |
|    learning_rate        | 0.00102    |
|    loss                 | -0.0513    |
|    n_updates            | 24430      |
|    policy_gradient_loss | -0.0113    |
|    std                  | 0.227      |
|    value_loss           | 0.00979    |
----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 630       |
|    iterations           | 2445      |
|    time_elapsed         | 7940      |
|    total_timesteps      | 5007360   |
| train/                  |           |
|    approx_kl            | 0.1675604 |
|    clip_fraction        | 0.38      |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.153     |
|    explained_variance   | 0.797     |
|    learning_rate        | 0.00102   |
|    loss                 | 0.00634   |
|    n_updates            | 24440     |
|    policy_gradient_loss | -0.00364  |
|    std                  | 0.222     |
|    value_loss           | 0.0161    |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2446       |
|    time_elapsed         | 7943       |
|    total_timesteps      | 5009408    |
| train/                  |            |
|    approx_kl            | 0.17034087 |
|    clip_fraction        | 0.381      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.151      |
|    explained_variance   | 0.834      |
|    learning_rate        | 0.00102    |
|    loss                 | -0.00132   |
|    n_updates            | 24450      |
|    policy_gradient_loss | 0.00142    |
|    std                  | 0.225      |
|    value_loss           | 0.0169     |
----------------------------------------
box reached target
Eval num_timesteps=5010000, episode_reward=-1.05 +/- 0.09
Episode length: 300.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 300       |
|    mean_reward          | -1.05     |
| time/                   |           |
|    total_timesteps      | 5010000   |
| train/                  |           |
|    approx_kl            | 0.1921198 |
|    clip_fraction        | 0.408     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.128     |
|    explained_variance   | 0.71      |
|    learning_rate        | 0.00102   |
|    loss                 | 0.0424    |
|    n_updates            | 24460     |
|    policy_gradient_loss | 0.00832   |
|    std                  | 0.228     |
|    value_loss           | 0.00933   |
---------------------------------------
box reached target
box reached target
--------------------------------
| time/              |         |
|    fps             | 630     |
|    iterations      | 2447    |
|    time_elapsed    | 7947    |
|    total_timesteps | 5011456 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2448       |
|    time_elapsed         | 7950       |
|    total_timesteps      | 5013504    |
| train/                  |            |
|    approx_kl            | 0.21677226 |
|    clip_fraction        | 0.415      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.143      |
|    explained_variance   | 0.92       |
|    learning_rate        | 0.00102    |
|    loss                 | 0.00301    |
|    n_updates            | 24470      |
|    policy_gradient_loss | 0.00368    |
|    std                  | 0.224      |
|    value_loss           | 0.0172     |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2449       |
|    time_elapsed         | 7954       |
|    total_timesteps      | 5015552    |
| train/                  |            |
|    approx_kl            | 0.12792537 |
|    clip_fraction        | 0.348      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.164      |
|    explained_variance   | 0.85       |
|    learning_rate        | 0.00102    |
|    loss                 | -0.0214    |
|    n_updates            | 24480      |
|    policy_gradient_loss | -0.00112   |
|    std                  | 0.223      |
|    value_loss           | 0.0102     |
----------------------------------------
box reached target
box reached target
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 630       |
|    iterations           | 2450      |
|    time_elapsed         | 7957      |
|    total_timesteps      | 5017600   |
| train/                  |           |
|    approx_kl            | 0.1783215 |
|    clip_fraction        | 0.391     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.189     |
|    explained_variance   | 0.879     |
|    learning_rate        | 0.00102   |
|    loss                 | 0.0199    |
|    n_updates            | 24490     |
|    policy_gradient_loss | 0.0022    |
|    std                  | 0.219     |
|    value_loss           | 0.0142    |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2451       |
|    time_elapsed         | 7960       |
|    total_timesteps      | 5019648    |
| train/                  |            |
|    approx_kl            | 0.25026616 |
|    clip_fraction        | 0.38       |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.213      |
|    explained_variance   | 0.936      |
|    learning_rate        | 0.00102    |
|    loss                 | 0.0334     |
|    n_updates            | 24500      |
|    policy_gradient_loss | -0.00162   |
|    std                  | 0.215      |
|    value_loss           | 0.0134     |
----------------------------------------
Eval num_timesteps=5020000, episode_reward=-0.49 +/- 0.64
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -0.489     |
| time/                   |            |
|    total_timesteps      | 5020000    |
| train/                  |            |
|    approx_kl            | 0.13042337 |
|    clip_fraction        | 0.358      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.22       |
|    explained_variance   | 0.793      |
|    learning_rate        | 0.00102    |
|    loss                 | -0.0098    |
|    n_updates            | 24510      |
|    policy_gradient_loss | -0.000644  |
|    std                  | 0.218      |
|    value_loss           | 0.0102     |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 630     |
|    iterations      | 2452    |
|    time_elapsed    | 7964    |
|    total_timesteps | 5021696 |
--------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 630       |
|    iterations           | 2453      |
|    time_elapsed         | 7967      |
|    total_timesteps      | 5023744   |
| train/                  |           |
|    approx_kl            | 0.4536832 |
|    clip_fraction        | 0.408     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.169     |
|    explained_variance   | 0.699     |
|    learning_rate        | 0.00102   |
|    loss                 | -0.000705 |
|    n_updates            | 24520     |
|    policy_gradient_loss | 0.00683   |
|    std                  | 0.225     |
|    value_loss           | 0.00764   |
---------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2454       |
|    time_elapsed         | 7970       |
|    total_timesteps      | 5025792    |
| train/                  |            |
|    approx_kl            | 0.16426088 |
|    clip_fraction        | 0.398      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.19       |
|    explained_variance   | 0.86       |
|    learning_rate        | 0.00102    |
|    loss                 | 0.0107     |
|    n_updates            | 24530      |
|    policy_gradient_loss | 0.0127     |
|    std                  | 0.217      |
|    value_loss           | 0.0106     |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2455       |
|    time_elapsed         | 7973       |
|    total_timesteps      | 5027840    |
| train/                  |            |
|    approx_kl            | 0.14216831 |
|    clip_fraction        | 0.377      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.218      |
|    explained_variance   | 0.896      |
|    learning_rate        | 0.00102    |
|    loss                 | 0.0434     |
|    n_updates            | 24540      |
|    policy_gradient_loss | 0.0129     |
|    std                  | 0.216      |
|    value_loss           | 0.00877    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2456       |
|    time_elapsed         | 7976       |
|    total_timesteps      | 5029888    |
| train/                  |            |
|    approx_kl            | 0.13211878 |
|    clip_fraction        | 0.389      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.234      |
|    explained_variance   | 0.767      |
|    learning_rate        | 0.00102    |
|    loss                 | -0.0171    |
|    n_updates            | 24550      |
|    policy_gradient_loss | 0.00743    |
|    std                  | 0.215      |
|    value_loss           | 0.0105     |
----------------------------------------
box reached target
Eval num_timesteps=5030000, episode_reward=0.64 +/- 2.54
Episode length: 287.40 +/- 25.20
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 287        |
|    mean_reward          | 0.636      |
| time/                   |            |
|    total_timesteps      | 5030000    |
| train/                  |            |
|    approx_kl            | 0.14125344 |
|    clip_fraction        | 0.353      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.213      |
|    explained_variance   | 0.792      |
|    learning_rate        | 0.00102    |
|    loss                 | 0.082      |
|    n_updates            | 24560      |
|    policy_gradient_loss | 0.0139     |
|    std                  | 0.219      |
|    value_loss           | 0.00799    |
----------------------------------------
box reached target
box reached target
--------------------------------
| time/              |         |
|    fps             | 630     |
|    iterations      | 2457    |
|    time_elapsed    | 7980    |
|    total_timesteps | 5031936 |
--------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2458       |
|    time_elapsed         | 7983       |
|    total_timesteps      | 5033984    |
| train/                  |            |
|    approx_kl            | 0.33851773 |
|    clip_fraction        | 0.428      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.22       |
|    explained_variance   | 0.886      |
|    learning_rate        | 0.00102    |
|    loss                 | 0.00404    |
|    n_updates            | 24570      |
|    policy_gradient_loss | 0.00946    |
|    std                  | 0.215      |
|    value_loss           | 0.0158     |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2459       |
|    time_elapsed         | 7986       |
|    total_timesteps      | 5036032    |
| train/                  |            |
|    approx_kl            | 0.13033485 |
|    clip_fraction        | 0.414      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.218      |
|    explained_variance   | 0.908      |
|    learning_rate        | 0.00102    |
|    loss                 | -0.0175    |
|    n_updates            | 24580      |
|    policy_gradient_loss | 0.0113     |
|    std                  | 0.22       |
|    value_loss           | 0.018      |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2460       |
|    time_elapsed         | 7989       |
|    total_timesteps      | 5038080    |
| train/                  |            |
|    approx_kl            | 0.27864552 |
|    clip_fraction        | 0.388      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.22       |
|    explained_variance   | 0.49       |
|    learning_rate        | 0.00102    |
|    loss                 | -0.0149    |
|    n_updates            | 24590      |
|    policy_gradient_loss | 0.00334    |
|    std                  | 0.217      |
|    value_loss           | 0.0211     |
----------------------------------------
box reached target
box reached target
Eval num_timesteps=5040000, episode_reward=-0.83 +/- 0.35
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -0.827     |
| time/                   |            |
|    total_timesteps      | 5040000    |
| train/                  |            |
|    approx_kl            | 0.25566328 |
|    clip_fraction        | 0.324      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.232      |
|    explained_variance   | 0.139      |
|    learning_rate        | 0.00102    |
|    loss                 | 0.0355     |
|    n_updates            | 24600      |
|    policy_gradient_loss | 0.0131     |
|    std                  | 0.218      |
|    value_loss           | 0.00408    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 630     |
|    iterations      | 2461    |
|    time_elapsed    | 7993    |
|    total_timesteps | 5040128 |
--------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2462       |
|    time_elapsed         | 7996       |
|    total_timesteps      | 5042176    |
| train/                  |            |
|    approx_kl            | 0.12253231 |
|    clip_fraction        | 0.434      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.187      |
|    explained_variance   | 0.838      |
|    learning_rate        | 0.00102    |
|    loss                 | 0.0439     |
|    n_updates            | 24610      |
|    policy_gradient_loss | 0.0145     |
|    std                  | 0.222      |
|    value_loss           | 0.0181     |
----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 630         |
|    iterations           | 2463        |
|    time_elapsed         | 7999        |
|    total_timesteps      | 5044224     |
| train/                  |             |
|    approx_kl            | 0.096485406 |
|    clip_fraction        | 0.415       |
|    clip_range           | 0.2         |
|    entropy_loss         | 0.147       |
|    explained_variance   | 0.837       |
|    learning_rate        | 0.00102     |
|    loss                 | 0.0359      |
|    n_updates            | 24620       |
|    policy_gradient_loss | 0.0122      |
|    std                  | 0.226       |
|    value_loss           | 0.0138      |
-----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2464       |
|    time_elapsed         | 8002       |
|    total_timesteps      | 5046272    |
| train/                  |            |
|    approx_kl            | 0.15287697 |
|    clip_fraction        | 0.356      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.11       |
|    explained_variance   | 0.704      |
|    learning_rate        | 0.00102    |
|    loss                 | -0.0492    |
|    n_updates            | 24630      |
|    policy_gradient_loss | 0.000766   |
|    std                  | 0.231      |
|    value_loss           | 0.00819    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2465       |
|    time_elapsed         | 8005       |
|    total_timesteps      | 5048320    |
| train/                  |            |
|    approx_kl            | 0.16689047 |
|    clip_fraction        | 0.359      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.0894     |
|    explained_variance   | 0.843      |
|    learning_rate        | 0.00102    |
|    loss                 | 0.122      |
|    n_updates            | 24640      |
|    policy_gradient_loss | 0.00698    |
|    std                  | 0.231      |
|    value_loss           | 0.0138     |
----------------------------------------
box reached target
box reached target
Eval num_timesteps=5050000, episode_reward=-0.76 +/- 0.48
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -0.758     |
| time/                   |            |
|    total_timesteps      | 5050000    |
| train/                  |            |
|    approx_kl            | 0.18766163 |
|    clip_fraction        | 0.365      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.112      |
|    explained_variance   | 0.73       |
|    learning_rate        | 0.00102    |
|    loss                 | 0.0336     |
|    n_updates            | 24650      |
|    policy_gradient_loss | 0.00459    |
|    std                  | 0.23       |
|    value_loss           | 0.00886    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 630     |
|    iterations      | 2466    |
|    time_elapsed    | 8009    |
|    total_timesteps | 5050368 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2467       |
|    time_elapsed         | 8012       |
|    total_timesteps      | 5052416    |
| train/                  |            |
|    approx_kl            | 0.16320863 |
|    clip_fraction        | 0.355      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.11       |
|    explained_variance   | 0.864      |
|    learning_rate        | 0.00102    |
|    loss                 | 0.0631     |
|    n_updates            | 24660      |
|    policy_gradient_loss | 0.00666    |
|    std                  | 0.23       |
|    value_loss           | 0.0175     |
----------------------------------------
box reached target
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2468       |
|    time_elapsed         | 8015       |
|    total_timesteps      | 5054464    |
| train/                  |            |
|    approx_kl            | 0.20182413 |
|    clip_fraction        | 0.4        |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.0767     |
|    explained_variance   | 0.833      |
|    learning_rate        | 0.00101    |
|    loss                 | 0.00144    |
|    n_updates            | 24670      |
|    policy_gradient_loss | 0.0057     |
|    std                  | 0.237      |
|    value_loss           | 0.0221     |
----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 630         |
|    iterations           | 2469        |
|    time_elapsed         | 8018        |
|    total_timesteps      | 5056512     |
| train/                  |             |
|    approx_kl            | 0.083663836 |
|    clip_fraction        | 0.329       |
|    clip_range           | 0.2         |
|    entropy_loss         | 0.062       |
|    explained_variance   | 0.796       |
|    learning_rate        | 0.00101     |
|    loss                 | -0.00884    |
|    n_updates            | 24680       |
|    policy_gradient_loss | 0.00559     |
|    std                  | 0.235       |
|    value_loss           | 0.0101      |
-----------------------------------------
box reached target
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2470       |
|    time_elapsed         | 8021       |
|    total_timesteps      | 5058560    |
| train/                  |            |
|    approx_kl            | 0.21174014 |
|    clip_fraction        | 0.386      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.0948     |
|    explained_variance   | 0.314      |
|    learning_rate        | 0.00101    |
|    loss                 | 0.0167     |
|    n_updates            | 24690      |
|    policy_gradient_loss | 0.0158     |
|    std                  | 0.231      |
|    value_loss           | 0.00273    |
----------------------------------------
box reached target
Eval num_timesteps=5060000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1         |
| time/                   |            |
|    total_timesteps      | 5060000    |
| train/                  |            |
|    approx_kl            | 0.24377608 |
|    clip_fraction        | 0.409      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.133      |
|    explained_variance   | 0.926      |
|    learning_rate        | 0.00101    |
|    loss                 | 0.0786     |
|    n_updates            | 24700      |
|    policy_gradient_loss | 0.0136     |
|    std                  | 0.226      |
|    value_loss           | 0.00673    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 630     |
|    iterations      | 2471    |
|    time_elapsed    | 8025    |
|    total_timesteps | 5060608 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2472       |
|    time_elapsed         | 8028       |
|    total_timesteps      | 5062656    |
| train/                  |            |
|    approx_kl            | 0.13314033 |
|    clip_fraction        | 0.404      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.123      |
|    explained_variance   | 0.863      |
|    learning_rate        | 0.00101    |
|    loss                 | 0.0338     |
|    n_updates            | 24710      |
|    policy_gradient_loss | 0.00657    |
|    std                  | 0.23       |
|    value_loss           | 0.0102     |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2473       |
|    time_elapsed         | 8031       |
|    total_timesteps      | 5064704    |
| train/                  |            |
|    approx_kl            | 0.21855885 |
|    clip_fraction        | 0.383      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.137      |
|    explained_variance   | 0.724      |
|    learning_rate        | 0.00101    |
|    loss                 | 0.0192     |
|    n_updates            | 24720      |
|    policy_gradient_loss | -0.00242   |
|    std                  | 0.225      |
|    value_loss           | 0.00957    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2474       |
|    time_elapsed         | 8034       |
|    total_timesteps      | 5066752    |
| train/                  |            |
|    approx_kl            | 0.18538123 |
|    clip_fraction        | 0.384      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.169      |
|    explained_variance   | 0.92       |
|    learning_rate        | 0.00101    |
|    loss                 | -0.0435    |
|    n_updates            | 24730      |
|    policy_gradient_loss | 0.00362    |
|    std                  | 0.221      |
|    value_loss           | 0.00649    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2475       |
|    time_elapsed         | 8038       |
|    total_timesteps      | 5068800    |
| train/                  |            |
|    approx_kl            | 0.49339393 |
|    clip_fraction        | 0.391      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.179      |
|    explained_variance   | 0.806      |
|    learning_rate        | 0.00101    |
|    loss                 | -0.0205    |
|    n_updates            | 24740      |
|    policy_gradient_loss | 0.00642    |
|    std                  | 0.22       |
|    value_loss           | 0.00314    |
----------------------------------------
box reached target
box reached target
Eval num_timesteps=5070000, episode_reward=0.50 +/- 2.45
Episode length: 269.00 +/- 62.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 269       |
|    mean_reward          | 0.499     |
| time/                   |           |
|    total_timesteps      | 5070000   |
| train/                  |           |
|    approx_kl            | 0.1341387 |
|    clip_fraction        | 0.406     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.178     |
|    explained_variance   | 0.609     |
|    learning_rate        | 0.00101   |
|    loss                 | 0.0189    |
|    n_updates            | 24750     |
|    policy_gradient_loss | 0.00657   |
|    std                  | 0.223     |
|    value_loss           | 0.00749   |
---------------------------------------
box reached target
--------------------------------
| time/              |         |
|    fps             | 630     |
|    iterations      | 2476    |
|    time_elapsed    | 8041    |
|    total_timesteps | 5070848 |
--------------------------------
box reached target
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2477       |
|    time_elapsed         | 8044       |
|    total_timesteps      | 5072896    |
| train/                  |            |
|    approx_kl            | 0.26218742 |
|    clip_fraction        | 0.444      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.173      |
|    explained_variance   | 0.805      |
|    learning_rate        | 0.00101    |
|    loss                 | 0.0131     |
|    n_updates            | 24760      |
|    policy_gradient_loss | 0.0117     |
|    std                  | 0.221      |
|    value_loss           | 0.0173     |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2478       |
|    time_elapsed         | 8048       |
|    total_timesteps      | 5074944    |
| train/                  |            |
|    approx_kl            | 0.13257234 |
|    clip_fraction        | 0.379      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.207      |
|    explained_variance   | 0.828      |
|    learning_rate        | 0.00101    |
|    loss                 | -0.0291    |
|    n_updates            | 24770      |
|    policy_gradient_loss | 0.00613    |
|    std                  | 0.218      |
|    value_loss           | 0.0317     |
----------------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2479       |
|    time_elapsed         | 8051       |
|    total_timesteps      | 5076992    |
| train/                  |            |
|    approx_kl            | 0.23454908 |
|    clip_fraction        | 0.417      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.231      |
|    explained_variance   | 0.905      |
|    learning_rate        | 0.00101    |
|    loss                 | -0.0181    |
|    n_updates            | 24780      |
|    policy_gradient_loss | 0.00849    |
|    std                  | 0.213      |
|    value_loss           | 0.00691    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2480       |
|    time_elapsed         | 8054       |
|    total_timesteps      | 5079040    |
| train/                  |            |
|    approx_kl            | 0.19342737 |
|    clip_fraction        | 0.381      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.238      |
|    explained_variance   | 0.956      |
|    learning_rate        | 0.00101    |
|    loss                 | -0.0303    |
|    n_updates            | 24790      |
|    policy_gradient_loss | -0.000352  |
|    std                  | 0.215      |
|    value_loss           | 0.00538    |
----------------------------------------
box reached target
Eval num_timesteps=5080000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 300       |
|    mean_reward          | -1        |
| time/                   |           |
|    total_timesteps      | 5080000   |
| train/                  |           |
|    approx_kl            | 0.3091808 |
|    clip_fraction        | 0.428     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.231     |
|    explained_variance   | 0.78      |
|    learning_rate        | 0.00101   |
|    loss                 | -0.0515   |
|    n_updates            | 24800     |
|    policy_gradient_loss | 0.0257    |
|    std                  | 0.215     |
|    value_loss           | 0.0107    |
---------------------------------------
--------------------------------
| time/              |         |
|    fps             | 630     |
|    iterations      | 2481    |
|    time_elapsed    | 8058    |
|    total_timesteps | 5081088 |
--------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 630       |
|    iterations           | 2482      |
|    time_elapsed         | 8061      |
|    total_timesteps      | 5083136   |
| train/                  |           |
|    approx_kl            | 0.3599209 |
|    clip_fraction        | 0.437     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.237     |
|    explained_variance   | 0.948     |
|    learning_rate        | 0.00101   |
|    loss                 | 0.0723    |
|    n_updates            | 24810     |
|    policy_gradient_loss | 0.00998   |
|    std                  | 0.214     |
|    value_loss           | 0.00388   |
---------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2483       |
|    time_elapsed         | 8064       |
|    total_timesteps      | 5085184    |
| train/                  |            |
|    approx_kl            | 0.10648017 |
|    clip_fraction        | 0.367      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.224      |
|    explained_variance   | 0.856      |
|    learning_rate        | 0.00101    |
|    loss                 | -0.00178   |
|    n_updates            | 24820      |
|    policy_gradient_loss | 0.00471    |
|    std                  | 0.218      |
|    value_loss           | 0.0101     |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2484       |
|    time_elapsed         | 8067       |
|    total_timesteps      | 5087232    |
| train/                  |            |
|    approx_kl            | 0.22689457 |
|    clip_fraction        | 0.419      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.202      |
|    explained_variance   | 0.949      |
|    learning_rate        | 0.00101    |
|    loss                 | -0.0139    |
|    n_updates            | 24830      |
|    policy_gradient_loss | 0.00483    |
|    std                  | 0.22       |
|    value_loss           | 0.00298    |
----------------------------------------
box reached target
box reached target
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 630       |
|    iterations           | 2485      |
|    time_elapsed         | 8070      |
|    total_timesteps      | 5089280   |
| train/                  |           |
|    approx_kl            | 0.3683731 |
|    clip_fraction        | 0.43      |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.19      |
|    explained_variance   | 0.723     |
|    learning_rate        | 0.00101   |
|    loss                 | 0.0917    |
|    n_updates            | 24840     |
|    policy_gradient_loss | 0.0155    |
|    std                  | 0.218     |
|    value_loss           | 0.0488    |
---------------------------------------
box reached target
Eval num_timesteps=5090000, episode_reward=0.48 +/- 2.40
Episode length: 278.00 +/- 44.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 278        |
|    mean_reward          | 0.48       |
| time/                   |            |
|    total_timesteps      | 5090000    |
| train/                  |            |
|    approx_kl            | 0.23525314 |
|    clip_fraction        | 0.405      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.202      |
|    explained_variance   | 0.96       |
|    learning_rate        | 0.00101    |
|    loss                 | 0.00304    |
|    n_updates            | 24850      |
|    policy_gradient_loss | 0.00201    |
|    std                  | 0.218      |
|    value_loss           | 0.007      |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 630     |
|    iterations      | 2486    |
|    time_elapsed    | 8074    |
|    total_timesteps | 5091328 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2487       |
|    time_elapsed         | 8077       |
|    total_timesteps      | 5093376    |
| train/                  |            |
|    approx_kl            | 0.45217854 |
|    clip_fraction        | 0.38       |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.227      |
|    explained_variance   | 0.501      |
|    learning_rate        | 0.00101    |
|    loss                 | -0.0271    |
|    n_updates            | 24860      |
|    policy_gradient_loss | -0.0056    |
|    std                  | 0.214      |
|    value_loss           | 0.00475    |
----------------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2488       |
|    time_elapsed         | 8080       |
|    total_timesteps      | 5095424    |
| train/                  |            |
|    approx_kl            | 0.20652597 |
|    clip_fraction        | 0.401      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.247      |
|    explained_variance   | 0.797      |
|    learning_rate        | 0.00101    |
|    loss                 | -0.00553   |
|    n_updates            | 24870      |
|    policy_gradient_loss | -0.00296   |
|    std                  | 0.212      |
|    value_loss           | 0.0102     |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2489       |
|    time_elapsed         | 8083       |
|    total_timesteps      | 5097472    |
| train/                  |            |
|    approx_kl            | 0.09382175 |
|    clip_fraction        | 0.385      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.257      |
|    explained_variance   | 0.958      |
|    learning_rate        | 0.00101    |
|    loss                 | 0.0423     |
|    n_updates            | 24880      |
|    policy_gradient_loss | 0.019      |
|    std                  | 0.214      |
|    value_loss           | 0.00628    |
----------------------------------------
box reached target
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 630       |
|    iterations           | 2490      |
|    time_elapsed         | 8086      |
|    total_timesteps      | 5099520   |
| train/                  |           |
|    approx_kl            | 0.1022711 |
|    clip_fraction        | 0.384     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.219     |
|    explained_variance   | 0.164     |
|    learning_rate        | 0.00101   |
|    loss                 | 0.0627    |
|    n_updates            | 24890     |
|    policy_gradient_loss | 0.0138    |
|    std                  | 0.218     |
|    value_loss           | 0.00138   |
---------------------------------------
box reached target
Eval num_timesteps=5100000, episode_reward=0.23 +/- 2.45
Episode length: 276.00 +/- 48.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 276        |
|    mean_reward          | 0.227      |
| time/                   |            |
|    total_timesteps      | 5100000    |
| train/                  |            |
|    approx_kl            | 0.34182832 |
|    clip_fraction        | 0.432      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.19       |
|    explained_variance   | 0.459      |
|    learning_rate        | 0.00101    |
|    loss                 | 0.00783    |
|    n_updates            | 24900      |
|    policy_gradient_loss | 0.0117     |
|    std                  | 0.223      |
|    value_loss           | 0.0377     |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 630     |
|    iterations      | 2491    |
|    time_elapsed    | 8090    |
|    total_timesteps | 5101568 |
--------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 630       |
|    iterations           | 2492      |
|    time_elapsed         | 8093      |
|    total_timesteps      | 5103616   |
| train/                  |           |
|    approx_kl            | 0.0875779 |
|    clip_fraction        | 0.396     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.173     |
|    explained_variance   | 0.826     |
|    learning_rate        | 0.00101   |
|    loss                 | 8.23e-05  |
|    n_updates            | 24910     |
|    policy_gradient_loss | 0.0141    |
|    std                  | 0.223     |
|    value_loss           | 0.0154    |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2493       |
|    time_elapsed         | 8096       |
|    total_timesteps      | 5105664    |
| train/                  |            |
|    approx_kl            | 0.24759921 |
|    clip_fraction        | 0.431      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.148      |
|    explained_variance   | 0.794      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0382    |
|    n_updates            | 24920      |
|    policy_gradient_loss | 0.0057     |
|    std                  | 0.225      |
|    value_loss           | 0.00597    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2494       |
|    time_elapsed         | 8099       |
|    total_timesteps      | 5107712    |
| train/                  |            |
|    approx_kl            | 0.20685294 |
|    clip_fraction        | 0.414      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.139      |
|    explained_variance   | 0.762      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0112    |
|    n_updates            | 24930      |
|    policy_gradient_loss | -0.00552   |
|    std                  | 0.224      |
|    value_loss           | 0.00503    |
----------------------------------------
box reached target
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 630       |
|    iterations           | 2495      |
|    time_elapsed         | 8102      |
|    total_timesteps      | 5109760   |
| train/                  |           |
|    approx_kl            | 0.6334342 |
|    clip_fraction        | 0.423     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.136     |
|    explained_variance   | 0.321     |
|    learning_rate        | 0.001     |
|    loss                 | -0.0226   |
|    n_updates            | 24940     |
|    policy_gradient_loss | 0.0255    |
|    std                  | 0.226     |
|    value_loss           | 0.00309   |
---------------------------------------
Eval num_timesteps=5110000, episode_reward=-0.41 +/- 0.72
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -0.411     |
| time/                   |            |
|    total_timesteps      | 5110000    |
| train/                  |            |
|    approx_kl            | 0.20224276 |
|    clip_fraction        | 0.41       |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.159      |
|    explained_variance   | 0.67       |
|    learning_rate        | 0.001      |
|    loss                 | 0.0485     |
|    n_updates            | 24950      |
|    policy_gradient_loss | -0.00353   |
|    std                  | 0.221      |
|    value_loss           | 0.0392     |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 630     |
|    iterations      | 2496    |
|    time_elapsed    | 8106    |
|    total_timesteps | 5111808 |
--------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 630       |
|    iterations           | 2497      |
|    time_elapsed         | 8109      |
|    total_timesteps      | 5113856   |
| train/                  |           |
|    approx_kl            | 0.2112217 |
|    clip_fraction        | 0.391     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.168     |
|    explained_variance   | 0.692     |
|    learning_rate        | 0.001     |
|    loss                 | -0.024    |
|    n_updates            | 24960     |
|    policy_gradient_loss | -0.0132   |
|    std                  | 0.222     |
|    value_loss           | 0.00468   |
---------------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2498       |
|    time_elapsed         | 8112       |
|    total_timesteps      | 5115904    |
| train/                  |            |
|    approx_kl            | 0.31941587 |
|    clip_fraction        | 0.441      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.162      |
|    explained_variance   | 0.707      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0297    |
|    n_updates            | 24970      |
|    policy_gradient_loss | 0.0139     |
|    std                  | 0.225      |
|    value_loss           | 0.00292    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2499       |
|    time_elapsed         | 8115       |
|    total_timesteps      | 5117952    |
| train/                  |            |
|    approx_kl            | 0.24514619 |
|    clip_fraction        | 0.464      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.115      |
|    explained_variance   | 0.721      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0288    |
|    n_updates            | 24980      |
|    policy_gradient_loss | 0.0121     |
|    std                  | 0.231      |
|    value_loss           | 0.0189     |
----------------------------------------
box reached target
box reached target
Eval num_timesteps=5120000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1         |
| time/                   |            |
|    total_timesteps      | 5120000    |
| train/                  |            |
|    approx_kl            | 0.19416538 |
|    clip_fraction        | 0.391      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.125      |
|    explained_variance   | -0.461     |
|    learning_rate        | 0.001      |
|    loss                 | -0.0553    |
|    n_updates            | 24990      |
|    policy_gradient_loss | 0.0101     |
|    std                  | 0.226      |
|    value_loss           | 0.00243    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 630     |
|    iterations      | 2500    |
|    time_elapsed    | 8119    |
|    total_timesteps | 5120000 |
--------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2501       |
|    time_elapsed         | 8122       |
|    total_timesteps      | 5122048    |
| train/                  |            |
|    approx_kl            | 0.16082856 |
|    clip_fraction        | 0.4        |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.176      |
|    explained_variance   | 0.493      |
|    learning_rate        | 0.001      |
|    loss                 | 0.0468     |
|    n_updates            | 25000      |
|    policy_gradient_loss | 0.00832    |
|    std                  | 0.221      |
|    value_loss           | 0.0552     |
----------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 630       |
|    iterations           | 2502      |
|    time_elapsed         | 8125      |
|    total_timesteps      | 5124096   |
| train/                  |           |
|    approx_kl            | 1.8643398 |
|    clip_fraction        | 0.501     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.258     |
|    explained_variance   | 0.265     |
|    learning_rate        | 0.001     |
|    loss                 | -0.0341   |
|    n_updates            | 25010     |
|    policy_gradient_loss | 0.00532   |
|    std                  | 0.211     |
|    value_loss           | 0.0364    |
---------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2503       |
|    time_elapsed         | 8128       |
|    total_timesteps      | 5126144    |
| train/                  |            |
|    approx_kl            | 0.14366126 |
|    clip_fraction        | 0.379      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.287      |
|    explained_variance   | 0.383      |
|    learning_rate        | 0.001      |
|    loss                 | -0.00406   |
|    n_updates            | 25020      |
|    policy_gradient_loss | 0.00956    |
|    std                  | 0.213      |
|    value_loss           | 0.0303     |
----------------------------------------
box reached target
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2504       |
|    time_elapsed         | 8131       |
|    total_timesteps      | 5128192    |
| train/                  |            |
|    approx_kl            | 0.15592211 |
|    clip_fraction        | 0.398      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.247      |
|    explained_variance   | 0.858      |
|    learning_rate        | 0.001      |
|    loss                 | -0.00635   |
|    n_updates            | 25030      |
|    policy_gradient_loss | 0.00609    |
|    std                  | 0.218      |
|    value_loss           | 0.0163     |
----------------------------------------
box reached target
box reached target
Eval num_timesteps=5130000, episode_reward=0.55 +/- 2.46
Episode length: 274.20 +/- 51.60
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 274        |
|    mean_reward          | 0.546      |
| time/                   |            |
|    total_timesteps      | 5130000    |
| train/                  |            |
|    approx_kl            | 0.14199065 |
|    clip_fraction        | 0.427      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.224      |
|    explained_variance   | 0.858      |
|    learning_rate        | 0.001      |
|    loss                 | -0.0495    |
|    n_updates            | 25040      |
|    policy_gradient_loss | 0.00469    |
|    std                  | 0.218      |
|    value_loss           | 0.0227     |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 630     |
|    iterations      | 2505    |
|    time_elapsed    | 8135    |
|    total_timesteps | 5130240 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2506       |
|    time_elapsed         | 8138       |
|    total_timesteps      | 5132288    |
| train/                  |            |
|    approx_kl            | 0.13312191 |
|    clip_fraction        | 0.412      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.252      |
|    explained_variance   | 0.715      |
|    learning_rate        | 0.001      |
|    loss                 | -0.00863   |
|    n_updates            | 25050      |
|    policy_gradient_loss | 0.00714    |
|    std                  | 0.211      |
|    value_loss           | 0.0165     |
----------------------------------------
box reached target
--------------------------------------
| time/                   |          |
|    fps                  | 630      |
|    iterations           | 2507     |
|    time_elapsed         | 8141     |
|    total_timesteps      | 5134336  |
| train/                  |          |
|    approx_kl            | 0.76099  |
|    clip_fraction        | 0.431    |
|    clip_range           | 0.2      |
|    entropy_loss         | 0.31     |
|    explained_variance   | 0.289    |
|    learning_rate        | 0.000999 |
|    loss                 | -0.0387  |
|    n_updates            | 25060    |
|    policy_gradient_loss | 0.0126   |
|    std                  | 0.205    |
|    value_loss           | 0.00543  |
--------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 630       |
|    iterations           | 2508      |
|    time_elapsed         | 8145      |
|    total_timesteps      | 5136384   |
| train/                  |           |
|    approx_kl            | 0.2926039 |
|    clip_fraction        | 0.386     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.326     |
|    explained_variance   | 0.965     |
|    learning_rate        | 0.000999  |
|    loss                 | -0.0229   |
|    n_updates            | 25070     |
|    policy_gradient_loss | 0.00557   |
|    std                  | 0.207     |
|    value_loss           | 0.00351   |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2509       |
|    time_elapsed         | 8148       |
|    total_timesteps      | 5138432    |
| train/                  |            |
|    approx_kl            | 0.22391164 |
|    clip_fraction        | 0.452      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.334      |
|    explained_variance   | 0.849      |
|    learning_rate        | 0.000998   |
|    loss                 | 0.0514     |
|    n_updates            | 25080      |
|    policy_gradient_loss | 0.00604    |
|    std                  | 0.203      |
|    value_loss           | 0.00883    |
----------------------------------------
box reached target
box reached target
Eval num_timesteps=5140000, episode_reward=0.23 +/- 2.47
Episode length: 268.20 +/- 63.60
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 268       |
|    mean_reward          | 0.235     |
| time/                   |           |
|    total_timesteps      | 5140000   |
| train/                  |           |
|    approx_kl            | 0.4333204 |
|    clip_fraction        | 0.394     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.326     |
|    explained_variance   | 0.724     |
|    learning_rate        | 0.000998  |
|    loss                 | 0.033     |
|    n_updates            | 25090     |
|    policy_gradient_loss | 0.00769   |
|    std                  | 0.206     |
|    value_loss           | 0.0128    |
---------------------------------------
--------------------------------
| time/              |         |
|    fps             | 630     |
|    iterations      | 2510    |
|    time_elapsed    | 8151    |
|    total_timesteps | 5140480 |
--------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 630       |
|    iterations           | 2511      |
|    time_elapsed         | 8155      |
|    total_timesteps      | 5142528   |
| train/                  |           |
|    approx_kl            | 3.0229492 |
|    clip_fraction        | 0.544     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.318     |
|    explained_variance   | 0.713     |
|    learning_rate        | 0.000998  |
|    loss                 | 0.1       |
|    n_updates            | 25100     |
|    policy_gradient_loss | 0.0131    |
|    std                  | 0.206     |
|    value_loss           | 0.0264    |
---------------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2512       |
|    time_elapsed         | 8158       |
|    total_timesteps      | 5144576    |
| train/                  |            |
|    approx_kl            | 0.15151744 |
|    clip_fraction        | 0.42       |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.296      |
|    explained_variance   | 0.66       |
|    learning_rate        | 0.000997   |
|    loss                 | 0.0108     |
|    n_updates            | 25110      |
|    policy_gradient_loss | 0.0141     |
|    std                  | 0.212      |
|    value_loss           | 0.0471     |
----------------------------------------
box reached target
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2513       |
|    time_elapsed         | 8161       |
|    total_timesteps      | 5146624    |
| train/                  |            |
|    approx_kl            | 0.17747313 |
|    clip_fraction        | 0.429      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.292      |
|    explained_variance   | 0.731      |
|    learning_rate        | 0.000997   |
|    loss                 | -0.0329    |
|    n_updates            | 25120      |
|    policy_gradient_loss | 0.00388    |
|    std                  | 0.208      |
|    value_loss           | 0.0297     |
----------------------------------------
box reached target
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 630       |
|    iterations           | 2514      |
|    time_elapsed         | 8164      |
|    total_timesteps      | 5148672   |
| train/                  |           |
|    approx_kl            | 0.4292997 |
|    clip_fraction        | 0.44      |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.327     |
|    explained_variance   | 0.953     |
|    learning_rate        | 0.000996  |
|    loss                 | 0.0434    |
|    n_updates            | 25130     |
|    policy_gradient_loss | 0.0201    |
|    std                  | 0.204     |
|    value_loss           | 0.0199    |
---------------------------------------
Eval num_timesteps=5150000, episode_reward=-0.46 +/- 0.70
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -0.461     |
| time/                   |            |
|    total_timesteps      | 5150000    |
| train/                  |            |
|    approx_kl            | 0.16852129 |
|    clip_fraction        | 0.456      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.333      |
|    explained_variance   | 0.804      |
|    learning_rate        | 0.000996   |
|    loss                 | 0.0327     |
|    n_updates            | 25140      |
|    policy_gradient_loss | 0.0204     |
|    std                  | 0.207      |
|    value_loss           | 0.0352     |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 630     |
|    iterations      | 2515    |
|    time_elapsed    | 8168    |
|    total_timesteps | 5150720 |
--------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2516       |
|    time_elapsed         | 8171       |
|    total_timesteps      | 5152768    |
| train/                  |            |
|    approx_kl            | 0.14168149 |
|    clip_fraction        | 0.399      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.327      |
|    explained_variance   | 0.623      |
|    learning_rate        | 0.000996   |
|    loss                 | -0.000852  |
|    n_updates            | 25150      |
|    policy_gradient_loss | 0.00409    |
|    std                  | 0.206      |
|    value_loss           | 0.0221     |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2517       |
|    time_elapsed         | 8174       |
|    total_timesteps      | 5154816    |
| train/                  |            |
|    approx_kl            | 0.18770772 |
|    clip_fraction        | 0.396      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.357      |
|    explained_variance   | 0.923      |
|    learning_rate        | 0.000995   |
|    loss                 | -0.0123    |
|    n_updates            | 25160      |
|    policy_gradient_loss | -0.00255   |
|    std                  | 0.201      |
|    value_loss           | 0.00475    |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2518       |
|    time_elapsed         | 8177       |
|    total_timesteps      | 5156864    |
| train/                  |            |
|    approx_kl            | 0.33720005 |
|    clip_fraction        | 0.433      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.373      |
|    explained_variance   | 0.87       |
|    learning_rate        | 0.000995   |
|    loss                 | 0.0453     |
|    n_updates            | 25170      |
|    policy_gradient_loss | 0.00463    |
|    std                  | 0.202      |
|    value_loss           | 0.0163     |
----------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 630       |
|    iterations           | 2519      |
|    time_elapsed         | 8180      |
|    total_timesteps      | 5158912   |
| train/                  |           |
|    approx_kl            | 0.5136783 |
|    clip_fraction        | 0.455     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.353     |
|    explained_variance   | 0.766     |
|    learning_rate        | 0.000994  |
|    loss                 | -0.00678  |
|    n_updates            | 25180     |
|    policy_gradient_loss | 0.0172    |
|    std                  | 0.203     |
|    value_loss           | 0.00965   |
---------------------------------------
box reached target
Eval num_timesteps=5160000, episode_reward=0.79 +/- 2.22
Episode length: 272.80 +/- 54.40
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 273        |
|    mean_reward          | 0.794      |
| time/                   |            |
|    total_timesteps      | 5160000    |
| train/                  |            |
|    approx_kl            | 0.29043072 |
|    clip_fraction        | 0.429      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.33       |
|    explained_variance   | 0.742      |
|    learning_rate        | 0.000994   |
|    loss                 | -0.00992   |
|    n_updates            | 25190      |
|    policy_gradient_loss | 0.0112     |
|    std                  | 0.208      |
|    value_loss           | 0.0348     |
----------------------------------------
box reached target
--------------------------------
| time/              |         |
|    fps             | 630     |
|    iterations      | 2520    |
|    time_elapsed    | 8184    |
|    total_timesteps | 5160960 |
--------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 630       |
|    iterations           | 2521      |
|    time_elapsed         | 8187      |
|    total_timesteps      | 5163008   |
| train/                  |           |
|    approx_kl            | 1.1572324 |
|    clip_fraction        | 0.435     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.295     |
|    explained_variance   | 0.623     |
|    learning_rate        | 0.000994  |
|    loss                 | 0.0378    |
|    n_updates            | 25200     |
|    policy_gradient_loss | 0.0191    |
|    std                  | 0.209     |
|    value_loss           | 0.0144    |
---------------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2522       |
|    time_elapsed         | 8190       |
|    total_timesteps      | 5165056    |
| train/                  |            |
|    approx_kl            | 0.16001678 |
|    clip_fraction        | 0.406      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.333      |
|    explained_variance   | 0.583      |
|    learning_rate        | 0.000993   |
|    loss                 | -0.00858   |
|    n_updates            | 25210      |
|    policy_gradient_loss | 0.014      |
|    std                  | 0.205      |
|    value_loss           | 0.0176     |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2523       |
|    time_elapsed         | 8193       |
|    total_timesteps      | 5167104    |
| train/                  |            |
|    approx_kl            | 0.16734338 |
|    clip_fraction        | 0.388      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.367      |
|    explained_variance   | 0.894      |
|    learning_rate        | 0.000993   |
|    loss                 | 0.00213    |
|    n_updates            | 25220      |
|    policy_gradient_loss | 0.0136     |
|    std                  | 0.201      |
|    value_loss           | 0.015      |
----------------------------------------
box reached target
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 630       |
|    iterations           | 2524      |
|    time_elapsed         | 8196      |
|    total_timesteps      | 5169152   |
| train/                  |           |
|    approx_kl            | 1.0347402 |
|    clip_fraction        | 0.492     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.369     |
|    explained_variance   | 0.878     |
|    learning_rate        | 0.000992  |
|    loss                 | 0.0152    |
|    n_updates            | 25230     |
|    policy_gradient_loss | 0.013     |
|    std                  | 0.204     |
|    value_loss           | 0.0115    |
---------------------------------------
box reached target
box reached target
Eval num_timesteps=5170000, episode_reward=1.58 +/- 2.95
Episode length: 253.20 +/- 58.20
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 253       |
|    mean_reward          | 1.58      |
| time/                   |           |
|    total_timesteps      | 5170000   |
| train/                  |           |
|    approx_kl            | 0.1624166 |
|    clip_fraction        | 0.407     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.37      |
|    explained_variance   | 0.851     |
|    learning_rate        | 0.000992  |
|    loss                 | 0.00982   |
|    n_updates            | 25240     |
|    policy_gradient_loss | 0.00363   |
|    std                  | 0.203     |
|    value_loss           | 0.0164    |
---------------------------------------
box reached target
--------------------------------
| time/              |         |
|    fps             | 630     |
|    iterations      | 2525    |
|    time_elapsed    | 8200    |
|    total_timesteps | 5171200 |
--------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2526       |
|    time_elapsed         | 8203       |
|    total_timesteps      | 5173248    |
| train/                  |            |
|    approx_kl            | 0.12887041 |
|    clip_fraction        | 0.404      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.359      |
|    explained_variance   | 0.888      |
|    learning_rate        | 0.000992   |
|    loss                 | 0.00605    |
|    n_updates            | 25250      |
|    policy_gradient_loss | -0.000674  |
|    std                  | 0.204      |
|    value_loss           | 0.0115     |
----------------------------------------
box reached target
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 630       |
|    iterations           | 2527      |
|    time_elapsed         | 8206      |
|    total_timesteps      | 5175296   |
| train/                  |           |
|    approx_kl            | 0.1692535 |
|    clip_fraction        | 0.42      |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.348     |
|    explained_variance   | 0.842     |
|    learning_rate        | 0.000991  |
|    loss                 | 0.0505    |
|    n_updates            | 25260     |
|    policy_gradient_loss | 0.00685   |
|    std                  | 0.203     |
|    value_loss           | 0.0148    |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2528       |
|    time_elapsed         | 8209       |
|    total_timesteps      | 5177344    |
| train/                  |            |
|    approx_kl            | 0.15139045 |
|    clip_fraction        | 0.409      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.356      |
|    explained_variance   | 0.753      |
|    learning_rate        | 0.000991   |
|    loss                 | 0.1        |
|    n_updates            | 25270      |
|    policy_gradient_loss | 0.023      |
|    std                  | 0.203      |
|    value_loss           | 0.048      |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2529       |
|    time_elapsed         | 8212       |
|    total_timesteps      | 5179392    |
| train/                  |            |
|    approx_kl            | 0.14782444 |
|    clip_fraction        | 0.424      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.339      |
|    explained_variance   | 0.824      |
|    learning_rate        | 0.00099    |
|    loss                 | 0.000336   |
|    n_updates            | 25280      |
|    policy_gradient_loss | 0.0202     |
|    std                  | 0.206      |
|    value_loss           | 0.00415    |
----------------------------------------
box reached target
Eval num_timesteps=5180000, episode_reward=-0.46 +/- 0.65
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -0.459     |
| time/                   |            |
|    total_timesteps      | 5180000    |
| train/                  |            |
|    approx_kl            | 0.32989353 |
|    clip_fraction        | 0.464      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.38       |
|    explained_variance   | 0.423      |
|    learning_rate        | 0.00099    |
|    loss                 | 0.0432     |
|    n_updates            | 25290      |
|    policy_gradient_loss | 0.00695    |
|    std                  | 0.198      |
|    value_loss           | 0.0244     |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 630     |
|    iterations      | 2530    |
|    time_elapsed    | 8216    |
|    total_timesteps | 5181440 |
--------------------------------
box reached target
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2531       |
|    time_elapsed         | 8219       |
|    total_timesteps      | 5183488    |
| train/                  |            |
|    approx_kl            | 0.18554185 |
|    clip_fraction        | 0.388      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.377      |
|    explained_variance   | 0.915      |
|    learning_rate        | 0.00099    |
|    loss                 | 0.00585    |
|    n_updates            | 25300      |
|    policy_gradient_loss | -0.00107   |
|    std                  | 0.204      |
|    value_loss           | 0.0086     |
----------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 630       |
|    iterations           | 2532      |
|    time_elapsed         | 8222      |
|    total_timesteps      | 5185536   |
| train/                  |           |
|    approx_kl            | 0.2875138 |
|    clip_fraction        | 0.433     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.376     |
|    explained_variance   | 0.827     |
|    learning_rate        | 0.000989  |
|    loss                 | 0.012     |
|    n_updates            | 25310     |
|    policy_gradient_loss | 0.00811   |
|    std                  | 0.202     |
|    value_loss           | 0.0233    |
---------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 630       |
|    iterations           | 2533      |
|    time_elapsed         | 8225      |
|    total_timesteps      | 5187584   |
| train/                  |           |
|    approx_kl            | 0.5582627 |
|    clip_fraction        | 0.425     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.38      |
|    explained_variance   | 0.847     |
|    learning_rate        | 0.000989  |
|    loss                 | -0.0178   |
|    n_updates            | 25320     |
|    policy_gradient_loss | -0.0152   |
|    std                  | 0.2       |
|    value_loss           | 0.0177    |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2534       |
|    time_elapsed         | 8228       |
|    total_timesteps      | 5189632    |
| train/                  |            |
|    approx_kl            | 0.11051076 |
|    clip_fraction        | 0.407      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.395      |
|    explained_variance   | 0.837      |
|    learning_rate        | 0.000988   |
|    loss                 | 0.0107     |
|    n_updates            | 25330      |
|    policy_gradient_loss | 0.0207     |
|    std                  | 0.202      |
|    value_loss           | 0.00769    |
----------------------------------------
Eval num_timesteps=5190000, episode_reward=-0.89 +/- 0.22
Episode length: 300.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 300       |
|    mean_reward          | -0.891    |
| time/                   |           |
|    total_timesteps      | 5190000   |
| train/                  |           |
|    approx_kl            | 0.4926063 |
|    clip_fraction        | 0.452     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.394     |
|    explained_variance   | 0.756     |
|    learning_rate        | 0.000988  |
|    loss                 | 0.0121    |
|    n_updates            | 25340     |
|    policy_gradient_loss | -0.00047  |
|    std                  | 0.198     |
|    value_loss           | 0.0119    |
---------------------------------------
box reached target
--------------------------------
| time/              |         |
|    fps             | 630     |
|    iterations      | 2535    |
|    time_elapsed    | 8232    |
|    total_timesteps | 5191680 |
--------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 630       |
|    iterations           | 2536      |
|    time_elapsed         | 8235      |
|    total_timesteps      | 5193728   |
| train/                  |           |
|    approx_kl            | 0.5884461 |
|    clip_fraction        | 0.456     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.447     |
|    explained_variance   | 0.854     |
|    learning_rate        | 0.000988  |
|    loss                 | -0.0564   |
|    n_updates            | 25350     |
|    policy_gradient_loss | -0.00443  |
|    std                  | 0.193     |
|    value_loss           | 0.0148    |
---------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2537       |
|    time_elapsed         | 8238       |
|    total_timesteps      | 5195776    |
| train/                  |            |
|    approx_kl            | 0.22425272 |
|    clip_fraction        | 0.448      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.5        |
|    explained_variance   | 0.792      |
|    learning_rate        | 0.000987   |
|    loss                 | -0.0605    |
|    n_updates            | 25360      |
|    policy_gradient_loss | 0.00259    |
|    std                  | 0.189      |
|    value_loss           | 0.0249     |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2538       |
|    time_elapsed         | 8241       |
|    total_timesteps      | 5197824    |
| train/                  |            |
|    approx_kl            | 0.22767983 |
|    clip_fraction        | 0.462      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.495      |
|    explained_variance   | 0.857      |
|    learning_rate        | 0.000987   |
|    loss                 | 0.024      |
|    n_updates            | 25370      |
|    policy_gradient_loss | 0.00739    |
|    std                  | 0.19       |
|    value_loss           | 0.00907    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2539       |
|    time_elapsed         | 8244       |
|    total_timesteps      | 5199872    |
| train/                  |            |
|    approx_kl            | 0.35349792 |
|    clip_fraction        | 0.427      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.507      |
|    explained_variance   | 0.775      |
|    learning_rate        | 0.000986   |
|    loss                 | 0.0124     |
|    n_updates            | 25380      |
|    policy_gradient_loss | 0.00189    |
|    std                  | 0.188      |
|    value_loss           | 0.00622    |
----------------------------------------
box reached target
box reached target
Eval num_timesteps=5200000, episode_reward=1.70 +/- 2.88
Episode length: 256.80 +/- 54.87
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 257       |
|    mean_reward          | 1.7       |
| time/                   |           |
|    total_timesteps      | 5200000   |
| train/                  |           |
|    approx_kl            | 0.8168416 |
|    clip_fraction        | 0.469     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.535     |
|    explained_variance   | 0.808     |
|    learning_rate        | 0.000986  |
|    loss                 | -0.0517   |
|    n_updates            | 25390     |
|    policy_gradient_loss | 0.0231    |
|    std                  | 0.187     |
|    value_loss           | 0.0122    |
---------------------------------------
box reached target
box reached target
--------------------------------
| time/              |         |
|    fps             | 630     |
|    iterations      | 2540    |
|    time_elapsed    | 8248    |
|    total_timesteps | 5201920 |
--------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 630       |
|    iterations           | 2541      |
|    time_elapsed         | 8251      |
|    total_timesteps      | 5203968   |
| train/                  |           |
|    approx_kl            | 0.2963611 |
|    clip_fraction        | 0.461     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.574     |
|    explained_variance   | 0.783     |
|    learning_rate        | 0.000986  |
|    loss                 | 0.0637    |
|    n_updates            | 25400     |
|    policy_gradient_loss | 0.0267    |
|    std                  | 0.181     |
|    value_loss           | 0.0239    |
---------------------------------------
box reached target
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 630       |
|    iterations           | 2542      |
|    time_elapsed         | 8254      |
|    total_timesteps      | 5206016   |
| train/                  |           |
|    approx_kl            | 0.2454209 |
|    clip_fraction        | 0.452     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.586     |
|    explained_variance   | 0.487     |
|    learning_rate        | 0.000985  |
|    loss                 | -0.0224   |
|    n_updates            | 25410     |
|    policy_gradient_loss | 0.00391   |
|    std                  | 0.184     |
|    value_loss           | 0.0235    |
---------------------------------------
box reached target
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 630       |
|    iterations           | 2543      |
|    time_elapsed         | 8257      |
|    total_timesteps      | 5208064   |
| train/                  |           |
|    approx_kl            | 0.6523732 |
|    clip_fraction        | 0.47      |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.58      |
|    explained_variance   | 0.579     |
|    learning_rate        | 0.000985  |
|    loss                 | 0.0646    |
|    n_updates            | 25420     |
|    policy_gradient_loss | 0.00882   |
|    std                  | 0.182     |
|    value_loss           | 0.055     |
---------------------------------------
Eval num_timesteps=5210000, episode_reward=-0.73 +/- 0.54
Episode length: 300.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 300       |
|    mean_reward          | -0.731    |
| time/                   |           |
|    total_timesteps      | 5210000   |
| train/                  |           |
|    approx_kl            | 0.1851471 |
|    clip_fraction        | 0.449     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.576     |
|    explained_variance   | 0.627     |
|    learning_rate        | 0.000984  |
|    loss                 | 0.0473    |
|    n_updates            | 25430     |
|    policy_gradient_loss | 0.018     |
|    std                  | 0.184     |
|    value_loss           | 0.0672    |
---------------------------------------
--------------------------------
| time/              |         |
|    fps             | 630     |
|    iterations      | 2544    |
|    time_elapsed    | 8261    |
|    total_timesteps | 5210112 |
--------------------------------
box reached target
box reached target
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2545       |
|    time_elapsed         | 8264       |
|    total_timesteps      | 5212160    |
| train/                  |            |
|    approx_kl            | 0.38119274 |
|    clip_fraction        | 0.438      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.527      |
|    explained_variance   | 0.643      |
|    learning_rate        | 0.000984   |
|    loss                 | 0.0392     |
|    n_updates            | 25440      |
|    policy_gradient_loss | 0.00548    |
|    std                  | 0.189      |
|    value_loss           | 0.0119     |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2546       |
|    time_elapsed         | 8268       |
|    total_timesteps      | 5214208    |
| train/                  |            |
|    approx_kl            | 0.45804527 |
|    clip_fraction        | 0.49       |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.522      |
|    explained_variance   | 0.747      |
|    learning_rate        | 0.000984   |
|    loss                 | -0.000879  |
|    n_updates            | 25450      |
|    policy_gradient_loss | 0.0237     |
|    std                  | 0.189      |
|    value_loss           | 0.0442     |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2547       |
|    time_elapsed         | 8271       |
|    total_timesteps      | 5216256    |
| train/                  |            |
|    approx_kl            | 0.32293576 |
|    clip_fraction        | 0.415      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.536      |
|    explained_variance   | 0.73       |
|    learning_rate        | 0.000983   |
|    loss                 | -0.021     |
|    n_updates            | 25460      |
|    policy_gradient_loss | 0.0107     |
|    std                  | 0.186      |
|    value_loss           | 0.00829    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2548       |
|    time_elapsed         | 8274       |
|    total_timesteps      | 5218304    |
| train/                  |            |
|    approx_kl            | 0.27192795 |
|    clip_fraction        | 0.425      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.564      |
|    explained_variance   | 0.773      |
|    learning_rate        | 0.000983   |
|    loss                 | -0.000317  |
|    n_updates            | 25470      |
|    policy_gradient_loss | 0.0143     |
|    std                  | 0.185      |
|    value_loss           | 0.0127     |
----------------------------------------
box reached target
Eval num_timesteps=5220000, episode_reward=-1.07 +/- 0.14
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1.07      |
| time/                   |            |
|    total_timesteps      | 5220000    |
| train/                  |            |
|    approx_kl            | 0.17073575 |
|    clip_fraction        | 0.406      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.495      |
|    explained_variance   | 0.592      |
|    learning_rate        | 0.000982   |
|    loss                 | 0.00979    |
|    n_updates            | 25480      |
|    policy_gradient_loss | 0.0241     |
|    std                  | 0.194      |
|    value_loss           | 0.00567    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 630     |
|    iterations      | 2549    |
|    time_elapsed    | 8278    |
|    total_timesteps | 5220352 |
--------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2550       |
|    time_elapsed         | 8281       |
|    total_timesteps      | 5222400    |
| train/                  |            |
|    approx_kl            | 0.18874915 |
|    clip_fraction        | 0.456      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.449      |
|    explained_variance   | 0.835      |
|    learning_rate        | 0.000982   |
|    loss                 | 0.0387     |
|    n_updates            | 25490      |
|    policy_gradient_loss | 0.00637    |
|    std                  | 0.195      |
|    value_loss           | 0.0119     |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2551       |
|    time_elapsed         | 8284       |
|    total_timesteps      | 5224448    |
| train/                  |            |
|    approx_kl            | 0.19909096 |
|    clip_fraction        | 0.453      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.433      |
|    explained_variance   | 0.697      |
|    learning_rate        | 0.000982   |
|    loss                 | 0.0232     |
|    n_updates            | 25500      |
|    policy_gradient_loss | 0.0169     |
|    std                  | 0.201      |
|    value_loss           | 0.0209     |
----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 630       |
|    iterations           | 2552      |
|    time_elapsed         | 8287      |
|    total_timesteps      | 5226496   |
| train/                  |           |
|    approx_kl            | 0.2201969 |
|    clip_fraction        | 0.437     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.379     |
|    explained_variance   | 0.693     |
|    learning_rate        | 0.000981  |
|    loss                 | -0.0133   |
|    n_updates            | 25510     |
|    policy_gradient_loss | 0.0112    |
|    std                  | 0.203     |
|    value_loss           | 0.018     |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2553       |
|    time_elapsed         | 8290       |
|    total_timesteps      | 5228544    |
| train/                  |            |
|    approx_kl            | 0.24214539 |
|    clip_fraction        | 0.401      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.377      |
|    explained_variance   | 0.676      |
|    learning_rate        | 0.000981   |
|    loss                 | -0.0351    |
|    n_updates            | 25520      |
|    policy_gradient_loss | 0.00353    |
|    std                  | 0.203      |
|    value_loss           | 0.00993    |
----------------------------------------
box reached target
box reached target
box reached target
Eval num_timesteps=5230000, episode_reward=0.53 +/- 2.37
Episode length: 268.80 +/- 62.40
--------------------------------------
| eval/                   |          |
|    mean_ep_length       | 269      |
|    mean_reward          | 0.529    |
| time/                   |          |
|    total_timesteps      | 5230000  |
| train/                  |          |
|    approx_kl            | 0.633492 |
|    clip_fraction        | 0.459    |
|    clip_range           | 0.2      |
|    entropy_loss         | 0.387    |
|    explained_variance   | 0.679    |
|    learning_rate        | 0.00098  |
|    loss                 | -0.0342  |
|    n_updates            | 25530    |
|    policy_gradient_loss | 0.00656  |
|    std                  | 0.201    |
|    value_loss           | 0.00816  |
--------------------------------------
--------------------------------
| time/              |         |
|    fps             | 630     |
|    iterations      | 2554    |
|    time_elapsed    | 8294    |
|    total_timesteps | 5230592 |
--------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2555       |
|    time_elapsed         | 8297       |
|    total_timesteps      | 5232640    |
| train/                  |            |
|    approx_kl            | 0.58471745 |
|    clip_fraction        | 0.466      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.389      |
|    explained_variance   | 0.803      |
|    learning_rate        | 0.00098    |
|    loss                 | 0.0172     |
|    n_updates            | 25540      |
|    policy_gradient_loss | 0.00827    |
|    std                  | 0.203      |
|    value_loss           | 0.0273     |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2556       |
|    time_elapsed         | 8300       |
|    total_timesteps      | 5234688    |
| train/                  |            |
|    approx_kl            | 0.22801852 |
|    clip_fraction        | 0.438      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.363      |
|    explained_variance   | 0.603      |
|    learning_rate        | 0.00098    |
|    loss                 | 0.000252   |
|    n_updates            | 25550      |
|    policy_gradient_loss | 0.0149     |
|    std                  | 0.205      |
|    value_loss           | 0.0246     |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2557       |
|    time_elapsed         | 8303       |
|    total_timesteps      | 5236736    |
| train/                  |            |
|    approx_kl            | 0.32212526 |
|    clip_fraction        | 0.426      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.358      |
|    explained_variance   | 0.735      |
|    learning_rate        | 0.000979   |
|    loss                 | 0.0236     |
|    n_updates            | 25560      |
|    policy_gradient_loss | 0.0167     |
|    std                  | 0.205      |
|    value_loss           | 0.00984    |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2558       |
|    time_elapsed         | 8306       |
|    total_timesteps      | 5238784    |
| train/                  |            |
|    approx_kl            | 0.25489873 |
|    clip_fraction        | 0.391      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.367      |
|    explained_variance   | 0.683      |
|    learning_rate        | 0.000979   |
|    loss                 | 0.00348    |
|    n_updates            | 25570      |
|    policy_gradient_loss | -0.00174   |
|    std                  | 0.204      |
|    value_loss           | 0.00566    |
----------------------------------------
box reached target
Eval num_timesteps=5240000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1         |
| time/                   |            |
|    total_timesteps      | 5240000    |
| train/                  |            |
|    approx_kl            | 0.42809394 |
|    clip_fraction        | 0.487      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.358      |
|    explained_variance   | 0.888      |
|    learning_rate        | 0.000978   |
|    loss                 | 0.00583    |
|    n_updates            | 25580      |
|    policy_gradient_loss | 0.0189     |
|    std                  | 0.206      |
|    value_loss           | 0.0129     |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 630     |
|    iterations      | 2559    |
|    time_elapsed    | 8310    |
|    total_timesteps | 5240832 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2560       |
|    time_elapsed         | 8313       |
|    total_timesteps      | 5242880    |
| train/                  |            |
|    approx_kl            | 0.10760163 |
|    clip_fraction        | 0.388      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.339      |
|    explained_variance   | 0.897      |
|    learning_rate        | 0.000978   |
|    loss                 | 0.0105     |
|    n_updates            | 25590      |
|    policy_gradient_loss | 0.00419    |
|    std                  | 0.209      |
|    value_loss           | 0.0112     |
----------------------------------------
box reached target
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 630       |
|    iterations           | 2561      |
|    time_elapsed         | 8316      |
|    total_timesteps      | 5244928   |
| train/                  |           |
|    approx_kl            | 0.3302136 |
|    clip_fraction        | 0.403     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.337     |
|    explained_variance   | 0.679     |
|    learning_rate        | 0.000978  |
|    loss                 | 0.0416    |
|    n_updates            | 25600     |
|    policy_gradient_loss | 0.00773   |
|    std                  | 0.207     |
|    value_loss           | 0.0079    |
---------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2562       |
|    time_elapsed         | 8319       |
|    total_timesteps      | 5246976    |
| train/                  |            |
|    approx_kl            | 0.49394575 |
|    clip_fraction        | 0.474      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.314      |
|    explained_variance   | 0.713      |
|    learning_rate        | 0.000977   |
|    loss                 | -0.0113    |
|    n_updates            | 25610      |
|    policy_gradient_loss | 0.0154     |
|    std                  | 0.211      |
|    value_loss           | 0.0297     |
----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 630         |
|    iterations           | 2563        |
|    time_elapsed         | 8322        |
|    total_timesteps      | 5249024     |
| train/                  |             |
|    approx_kl            | 0.124196835 |
|    clip_fraction        | 0.404       |
|    clip_range           | 0.2         |
|    entropy_loss         | 0.299       |
|    explained_variance   | 0.924       |
|    learning_rate        | 0.000977    |
|    loss                 | 0.0187      |
|    n_updates            | 25620       |
|    policy_gradient_loss | -0.00321    |
|    std                  | 0.211       |
|    value_loss           | 0.00858     |
-----------------------------------------
box reached target
box reached target
Eval num_timesteps=5250000, episode_reward=0.99 +/- 2.36
Episode length: 280.20 +/- 39.60
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 280        |
|    mean_reward          | 0.987      |
| time/                   |            |
|    total_timesteps      | 5250000    |
| train/                  |            |
|    approx_kl            | 0.17482892 |
|    clip_fraction        | 0.436      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.266      |
|    explained_variance   | 0.277      |
|    learning_rate        | 0.000976   |
|    loss                 | -0.0108    |
|    n_updates            | 25630      |
|    policy_gradient_loss | 0.0309     |
|    std                  | 0.218      |
|    value_loss           | 0.0111     |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 630     |
|    iterations      | 2564    |
|    time_elapsed    | 8326    |
|    total_timesteps | 5251072 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2565       |
|    time_elapsed         | 8329       |
|    total_timesteps      | 5253120    |
| train/                  |            |
|    approx_kl            | 0.20843977 |
|    clip_fraction        | 0.368      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.26       |
|    explained_variance   | 0.871      |
|    learning_rate        | 0.000976   |
|    loss                 | -0.0275    |
|    n_updates            | 25640      |
|    policy_gradient_loss | 0.00516    |
|    std                  | 0.214      |
|    value_loss           | 0.00768    |
----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 630       |
|    iterations           | 2566      |
|    time_elapsed         | 8332      |
|    total_timesteps      | 5255168   |
| train/                  |           |
|    approx_kl            | 0.3725462 |
|    clip_fraction        | 0.411     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.295     |
|    explained_variance   | -0.592    |
|    learning_rate        | 0.000976  |
|    loss                 | -0.0474   |
|    n_updates            | 25650     |
|    policy_gradient_loss | -0.00613  |
|    std                  | 0.21      |
|    value_loss           | 0.00315   |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2567       |
|    time_elapsed         | 8335       |
|    total_timesteps      | 5257216    |
| train/                  |            |
|    approx_kl            | 0.17385633 |
|    clip_fraction        | 0.386      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.327      |
|    explained_variance   | 0.552      |
|    learning_rate        | 0.000975   |
|    loss                 | 0.146      |
|    n_updates            | 25660      |
|    policy_gradient_loss | 0.0169     |
|    std                  | 0.209      |
|    value_loss           | 0.00311    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2568       |
|    time_elapsed         | 8338       |
|    total_timesteps      | 5259264    |
| train/                  |            |
|    approx_kl            | 0.29225063 |
|    clip_fraction        | 0.381      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.349      |
|    explained_variance   | 0.418      |
|    learning_rate        | 0.000975   |
|    loss                 | -0.0235    |
|    n_updates            | 25670      |
|    policy_gradient_loss | 0.000214   |
|    std                  | 0.204      |
|    value_loss           | 0.00743    |
----------------------------------------
box reached target
Eval num_timesteps=5260000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1         |
| time/                   |            |
|    total_timesteps      | 5260000    |
| train/                  |            |
|    approx_kl            | 0.17302808 |
|    clip_fraction        | 0.399      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.355      |
|    explained_variance   | 0.552      |
|    learning_rate        | 0.000974   |
|    loss                 | 0.026      |
|    n_updates            | 25680      |
|    policy_gradient_loss | 0.00305    |
|    std                  | 0.205      |
|    value_loss           | 0.00377    |
----------------------------------------
box reached target
--------------------------------
| time/              |         |
|    fps             | 630     |
|    iterations      | 2569    |
|    time_elapsed    | 8342    |
|    total_timesteps | 5261312 |
--------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2570       |
|    time_elapsed         | 8346       |
|    total_timesteps      | 5263360    |
| train/                  |            |
|    approx_kl            | 0.43348914 |
|    clip_fraction        | 0.45       |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.372      |
|    explained_variance   | 0.812      |
|    learning_rate        | 0.000974   |
|    loss                 | 0.0551     |
|    n_updates            | 25690      |
|    policy_gradient_loss | 0.00938    |
|    std                  | 0.202      |
|    value_loss           | 0.0145     |
----------------------------------------
box reached target
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 630       |
|    iterations           | 2571      |
|    time_elapsed         | 8349      |
|    total_timesteps      | 5265408   |
| train/                  |           |
|    approx_kl            | 0.2631895 |
|    clip_fraction        | 0.437     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.392     |
|    explained_variance   | 0.416     |
|    learning_rate        | 0.000974  |
|    loss                 | 0.034     |
|    n_updates            | 25700     |
|    policy_gradient_loss | 0.00354   |
|    std                  | 0.202     |
|    value_loss           | 0.0459    |
---------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 630       |
|    iterations           | 2572      |
|    time_elapsed         | 8352      |
|    total_timesteps      | 5267456   |
| train/                  |           |
|    approx_kl            | 0.3129297 |
|    clip_fraction        | 0.414     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.397     |
|    explained_variance   | 0.745     |
|    learning_rate        | 0.000973  |
|    loss                 | 0.00508   |
|    n_updates            | 25710     |
|    policy_gradient_loss | 0.00609   |
|    std                  | 0.201     |
|    value_loss           | 0.0212    |
---------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 630       |
|    iterations           | 2573      |
|    time_elapsed         | 8355      |
|    total_timesteps      | 5269504   |
| train/                  |           |
|    approx_kl            | 0.4856381 |
|    clip_fraction        | 0.386     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.41      |
|    explained_variance   | 0.0581    |
|    learning_rate        | 0.000973  |
|    loss                 | -0.022    |
|    n_updates            | 25720     |
|    policy_gradient_loss | -0.00285  |
|    std                  | 0.199     |
|    value_loss           | 0.00301   |
---------------------------------------
box reached target
Eval num_timesteps=5270000, episode_reward=0.59 +/- 2.37
Episode length: 278.80 +/- 42.40
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 279        |
|    mean_reward          | 0.589      |
| time/                   |            |
|    total_timesteps      | 5270000    |
| train/                  |            |
|    approx_kl            | 0.20206636 |
|    clip_fraction        | 0.421      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.427      |
|    explained_variance   | 0.757      |
|    learning_rate        | 0.000972   |
|    loss                 | -0.0148    |
|    n_updates            | 25730      |
|    policy_gradient_loss | 0.0166     |
|    std                  | 0.199      |
|    value_loss           | 0.00966    |
----------------------------------------
box reached target
box reached target
--------------------------------
| time/              |         |
|    fps             | 630     |
|    iterations      | 2574    |
|    time_elapsed    | 8359    |
|    total_timesteps | 5271552 |
--------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2575       |
|    time_elapsed         | 8362       |
|    total_timesteps      | 5273600    |
| train/                  |            |
|    approx_kl            | 0.14312531 |
|    clip_fraction        | 0.423      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.447      |
|    explained_variance   | 0.766      |
|    learning_rate        | 0.000972   |
|    loss                 | 0.00848    |
|    n_updates            | 25740      |
|    policy_gradient_loss | 0.00429    |
|    std                  | 0.194      |
|    value_loss           | 0.0197     |
----------------------------------------
box reached target
box reached target
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 630       |
|    iterations           | 2576      |
|    time_elapsed         | 8365      |
|    total_timesteps      | 5275648   |
| train/                  |           |
|    approx_kl            | 0.4485452 |
|    clip_fraction        | 0.481     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.473     |
|    explained_variance   | 0.749     |
|    learning_rate        | 0.000972  |
|    loss                 | 0.0536    |
|    n_updates            | 25750     |
|    policy_gradient_loss | 0.0143    |
|    std                  | 0.192     |
|    value_loss           | 0.028     |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2577       |
|    time_elapsed         | 8368       |
|    total_timesteps      | 5277696    |
| train/                  |            |
|    approx_kl            | 0.26405448 |
|    clip_fraction        | 0.445      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.468      |
|    explained_variance   | 0.702      |
|    learning_rate        | 0.000971   |
|    loss                 | 0.0908     |
|    n_updates            | 25760      |
|    policy_gradient_loss | 0.0136     |
|    std                  | 0.195      |
|    value_loss           | 0.0988     |
----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 630       |
|    iterations           | 2578      |
|    time_elapsed         | 8371      |
|    total_timesteps      | 5279744   |
| train/                  |           |
|    approx_kl            | 0.8175816 |
|    clip_fraction        | 0.392     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.408     |
|    explained_variance   | 0.818     |
|    learning_rate        | 0.000971  |
|    loss                 | -0.0205   |
|    n_updates            | 25770     |
|    policy_gradient_loss | 0.000754  |
|    std                  | 0.203     |
|    value_loss           | 0.00533   |
---------------------------------------
box reached target
box reached target
box reached target
Eval num_timesteps=5280000, episode_reward=2.80 +/- 3.11
Episode length: 226.20 +/- 62.47
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 226        |
|    mean_reward          | 2.8        |
| time/                   |            |
|    total_timesteps      | 5280000    |
| train/                  |            |
|    approx_kl            | 0.27306217 |
|    clip_fraction        | 0.373      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.399      |
|    explained_variance   | 0.752      |
|    learning_rate        | 0.00097    |
|    loss                 | -0.0391    |
|    n_updates            | 25780      |
|    policy_gradient_loss | 0.0239     |
|    std                  | 0.201      |
|    value_loss           | 0.00533    |
----------------------------------------
box reached target
--------------------------------
| time/              |         |
|    fps             | 630     |
|    iterations      | 2579    |
|    time_elapsed    | 8375    |
|    total_timesteps | 5281792 |
--------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 630       |
|    iterations           | 2580      |
|    time_elapsed         | 8378      |
|    total_timesteps      | 5283840   |
| train/                  |           |
|    approx_kl            | 0.3020147 |
|    clip_fraction        | 0.447     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.45      |
|    explained_variance   | 0.935     |
|    learning_rate        | 0.00097   |
|    loss                 | -0.00521  |
|    n_updates            | 25790     |
|    policy_gradient_loss | 0.000626  |
|    std                  | 0.194     |
|    value_loss           | 0.0118    |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2581       |
|    time_elapsed         | 8381       |
|    total_timesteps      | 5285888    |
| train/                  |            |
|    approx_kl            | 0.33914155 |
|    clip_fraction        | 0.486      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.465      |
|    explained_variance   | 0.857      |
|    learning_rate        | 0.00097    |
|    loss                 | -0.00188   |
|    n_updates            | 25800      |
|    policy_gradient_loss | 0.0231     |
|    std                  | 0.196      |
|    value_loss           | 0.00404    |
----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 630       |
|    iterations           | 2582      |
|    time_elapsed         | 8384      |
|    total_timesteps      | 5287936   |
| train/                  |           |
|    approx_kl            | 0.8000259 |
|    clip_fraction        | 0.473     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.457     |
|    explained_variance   | 0.616     |
|    learning_rate        | 0.000969  |
|    loss                 | 0.0343    |
|    n_updates            | 25810     |
|    policy_gradient_loss | 0.162     |
|    std                  | 0.194     |
|    value_loss           | 0.00299   |
---------------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2583       |
|    time_elapsed         | 8387       |
|    total_timesteps      | 5289984    |
| train/                  |            |
|    approx_kl            | 0.16964582 |
|    clip_fraction        | 0.434      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.454      |
|    explained_variance   | 0.14       |
|    learning_rate        | 0.000969   |
|    loss                 | -0.0282    |
|    n_updates            | 25820      |
|    policy_gradient_loss | 0.0143     |
|    std                  | 0.197      |
|    value_loss           | 0.00398    |
----------------------------------------
Eval num_timesteps=5290000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1         |
| time/                   |            |
|    total_timesteps      | 5290000    |
| train/                  |            |
|    approx_kl            | 0.22609437 |
|    clip_fraction        | 0.462      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.448      |
|    explained_variance   | 0.872      |
|    learning_rate        | 0.000968   |
|    loss                 | -0.0284    |
|    n_updates            | 25830      |
|    policy_gradient_loss | 0.00992    |
|    std                  | 0.198      |
|    value_loss           | 0.0235     |
----------------------------------------
box reached target
--------------------------------
| time/              |         |
|    fps             | 630     |
|    iterations      | 2584    |
|    time_elapsed    | 8391    |
|    total_timesteps | 5292032 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2585       |
|    time_elapsed         | 8394       |
|    total_timesteps      | 5294080    |
| train/                  |            |
|    approx_kl            | 0.26132792 |
|    clip_fraction        | 0.445      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.43       |
|    explained_variance   | 0.505      |
|    learning_rate        | 0.000968   |
|    loss                 | -0.000558  |
|    n_updates            | 25840      |
|    policy_gradient_loss | 0.00723    |
|    std                  | 0.198      |
|    value_loss           | 0.0194     |
----------------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2586       |
|    time_elapsed         | 8397       |
|    total_timesteps      | 5296128    |
| train/                  |            |
|    approx_kl            | 0.27039433 |
|    clip_fraction        | 0.373      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.419      |
|    explained_variance   | -0.591     |
|    learning_rate        | 0.000968   |
|    loss                 | 0.0556     |
|    n_updates            | 25850      |
|    policy_gradient_loss | 0.0289     |
|    std                  | 0.198      |
|    value_loss           | 0.00409    |
----------------------------------------
box reached target
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2587       |
|    time_elapsed         | 8400       |
|    total_timesteps      | 5298176    |
| train/                  |            |
|    approx_kl            | 0.29646987 |
|    clip_fraction        | 0.431      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.453      |
|    explained_variance   | 0.635      |
|    learning_rate        | 0.000967   |
|    loss                 | 0.047      |
|    n_updates            | 25860      |
|    policy_gradient_loss | 0.00616    |
|    std                  | 0.192      |
|    value_loss           | 0.0514     |
----------------------------------------
box reached target
Eval num_timesteps=5300000, episode_reward=-0.44 +/- 0.51
Episode length: 300.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 300       |
|    mean_reward          | -0.44     |
| time/                   |           |
|    total_timesteps      | 5300000   |
| train/                  |           |
|    approx_kl            | 0.3660254 |
|    clip_fraction        | 0.476     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.497     |
|    explained_variance   | 0.174     |
|    learning_rate        | 0.000967  |
|    loss                 | 0.0199    |
|    n_updates            | 25870     |
|    policy_gradient_loss | 0.0166    |
|    std                  | 0.189     |
|    value_loss           | 0.134     |
---------------------------------------
--------------------------------
| time/              |         |
|    fps             | 630     |
|    iterations      | 2588    |
|    time_elapsed    | 8404    |
|    total_timesteps | 5300224 |
--------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 630         |
|    iterations           | 2589        |
|    time_elapsed         | 8407        |
|    total_timesteps      | 5302272     |
| train/                  |             |
|    approx_kl            | 0.119288534 |
|    clip_fraction        | 0.357       |
|    clip_range           | 0.2         |
|    entropy_loss         | 0.498       |
|    explained_variance   | 0.854       |
|    learning_rate        | 0.000966    |
|    loss                 | -0.00743    |
|    n_updates            | 25880       |
|    policy_gradient_loss | 0.0124      |
|    std                  | 0.19        |
|    value_loss           | 0.0146      |
-----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 630       |
|    iterations           | 2590      |
|    time_elapsed         | 8410      |
|    total_timesteps      | 5304320   |
| train/                  |           |
|    approx_kl            | 0.2542909 |
|    clip_fraction        | 0.444     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.472     |
|    explained_variance   | 0.653     |
|    learning_rate        | 0.000966  |
|    loss                 | -0.0344   |
|    n_updates            | 25890     |
|    policy_gradient_loss | 0.0255    |
|    std                  | 0.194     |
|    value_loss           | 0.0193    |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2591       |
|    time_elapsed         | 8413       |
|    total_timesteps      | 5306368    |
| train/                  |            |
|    approx_kl            | 0.34278905 |
|    clip_fraction        | 0.404      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.477      |
|    explained_variance   | 0.788      |
|    learning_rate        | 0.000966   |
|    loss                 | -0.0321    |
|    n_updates            | 25900      |
|    policy_gradient_loss | -0.00726   |
|    std                  | 0.19       |
|    value_loss           | 0.0055     |
----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 630       |
|    iterations           | 2592      |
|    time_elapsed         | 8416      |
|    total_timesteps      | 5308416   |
| train/                  |           |
|    approx_kl            | 0.5220172 |
|    clip_fraction        | 0.445     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.493     |
|    explained_variance   | 0.631     |
|    learning_rate        | 0.000965  |
|    loss                 | -0.0379   |
|    n_updates            | 25910     |
|    policy_gradient_loss | 0.00335   |
|    std                  | 0.189     |
|    value_loss           | 0.0103    |
---------------------------------------
Eval num_timesteps=5310000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1         |
| time/                   |            |
|    total_timesteps      | 5310000    |
| train/                  |            |
|    approx_kl            | 0.14368494 |
|    clip_fraction        | 0.396      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.48       |
|    explained_variance   | 0.613      |
|    learning_rate        | 0.000965   |
|    loss                 | 0.0191     |
|    n_updates            | 25920      |
|    policy_gradient_loss | 0.00828    |
|    std                  | 0.191      |
|    value_loss           | 0.00407    |
----------------------------------------
box reached target
--------------------------------
| time/              |         |
|    fps             | 630     |
|    iterations      | 2593    |
|    time_elapsed    | 8420    |
|    total_timesteps | 5310464 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2594       |
|    time_elapsed         | 8423       |
|    total_timesteps      | 5312512    |
| train/                  |            |
|    approx_kl            | 0.15641053 |
|    clip_fraction        | 0.416      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.475      |
|    explained_variance   | 0.941      |
|    learning_rate        | 0.000964   |
|    loss                 | -0.0382    |
|    n_updates            | 25930      |
|    policy_gradient_loss | 0.0083     |
|    std                  | 0.192      |
|    value_loss           | 0.0108     |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2595       |
|    time_elapsed         | 8426       |
|    total_timesteps      | 5314560    |
| train/                  |            |
|    approx_kl            | 0.33880937 |
|    clip_fraction        | 0.408      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.466      |
|    explained_variance   | 0.507      |
|    learning_rate        | 0.000964   |
|    loss                 | -0.00179   |
|    n_updates            | 25940      |
|    policy_gradient_loss | -0.000663  |
|    std                  | 0.191      |
|    value_loss           | 0.00507    |
----------------------------------------
box reached target
box reached target
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 630       |
|    iterations           | 2596      |
|    time_elapsed         | 8429      |
|    total_timesteps      | 5316608   |
| train/                  |           |
|    approx_kl            | 0.3432279 |
|    clip_fraction        | 0.461     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.482     |
|    explained_variance   | 0.177     |
|    learning_rate        | 0.000964  |
|    loss                 | 0.023     |
|    n_updates            | 25950     |
|    policy_gradient_loss | 0.000257  |
|    std                  | 0.19      |
|    value_loss           | 0.0215    |
---------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 630       |
|    iterations           | 2597      |
|    time_elapsed         | 8432      |
|    total_timesteps      | 5318656   |
| train/                  |           |
|    approx_kl            | 0.2980889 |
|    clip_fraction        | 0.476     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.454     |
|    explained_variance   | 0.805     |
|    learning_rate        | 0.000963  |
|    loss                 | 0.0237    |
|    n_updates            | 25960     |
|    policy_gradient_loss | 0.00799   |
|    std                  | 0.196     |
|    value_loss           | 0.0809    |
---------------------------------------
box reached target
Eval num_timesteps=5320000, episode_reward=0.43 +/- 2.55
Episode length: 282.00 +/- 36.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 282        |
|    mean_reward          | 0.429      |
| time/                   |            |
|    total_timesteps      | 5320000    |
| train/                  |            |
|    approx_kl            | 0.11254081 |
|    clip_fraction        | 0.419      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.423      |
|    explained_variance   | 0.145      |
|    learning_rate        | 0.000963   |
|    loss                 | 0.0359     |
|    n_updates            | 25970      |
|    policy_gradient_loss | 0.0143     |
|    std                  | 0.195      |
|    value_loss           | 0.00492    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 630     |
|    iterations      | 2598    |
|    time_elapsed    | 8436    |
|    total_timesteps | 5320704 |
--------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2599       |
|    time_elapsed         | 8439       |
|    total_timesteps      | 5322752    |
| train/                  |            |
|    approx_kl            | 0.31140512 |
|    clip_fraction        | 0.388      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.443      |
|    explained_variance   | 0.189      |
|    learning_rate        | 0.000962   |
|    loss                 | 0.0185     |
|    n_updates            | 25980      |
|    policy_gradient_loss | 0.00758    |
|    std                  | 0.194      |
|    value_loss           | 0.00551    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2600       |
|    time_elapsed         | 8442       |
|    total_timesteps      | 5324800    |
| train/                  |            |
|    approx_kl            | 0.19509977 |
|    clip_fraction        | 0.456      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.438      |
|    explained_variance   | 0.907      |
|    learning_rate        | 0.000962   |
|    loss                 | 0.0753     |
|    n_updates            | 25990      |
|    policy_gradient_loss | 0.0228     |
|    std                  | 0.196      |
|    value_loss           | 0.0154     |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2601       |
|    time_elapsed         | 8445       |
|    total_timesteps      | 5326848    |
| train/                  |            |
|    approx_kl            | 0.29152572 |
|    clip_fraction        | 0.409      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.434      |
|    explained_variance   | 0.388      |
|    learning_rate        | 0.000962   |
|    loss                 | 0.0414     |
|    n_updates            | 26000      |
|    policy_gradient_loss | 0.00601    |
|    std                  | 0.193      |
|    value_loss           | 0.00689    |
----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 630       |
|    iterations           | 2602      |
|    time_elapsed         | 8448      |
|    total_timesteps      | 5328896   |
| train/                  |           |
|    approx_kl            | 0.0831836 |
|    clip_fraction        | 0.375     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.432     |
|    explained_variance   | 0.688     |
|    learning_rate        | 0.000961  |
|    loss                 | -0.0403   |
|    n_updates            | 26010     |
|    policy_gradient_loss | 0.0136    |
|    std                  | 0.197     |
|    value_loss           | 0.00419   |
---------------------------------------
Eval num_timesteps=5330000, episode_reward=-0.17 +/- 0.70
Episode length: 300.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 300       |
|    mean_reward          | -0.169    |
| time/                   |           |
|    total_timesteps      | 5330000   |
| train/                  |           |
|    approx_kl            | 0.6400763 |
|    clip_fraction        | 0.455     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.434     |
|    explained_variance   | 0.0792    |
|    learning_rate        | 0.000961  |
|    loss                 | -0.0615   |
|    n_updates            | 26020     |
|    policy_gradient_loss | -0.00103  |
|    std                  | 0.194     |
|    value_loss           | 0.00451   |
---------------------------------------
--------------------------------
| time/              |         |
|    fps             | 630     |
|    iterations      | 2603    |
|    time_elapsed    | 8452    |
|    total_timesteps | 5330944 |
--------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 630       |
|    iterations           | 2604      |
|    time_elapsed         | 8455      |
|    total_timesteps      | 5332992   |
| train/                  |           |
|    approx_kl            | 0.1127373 |
|    clip_fraction        | 0.375     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.439     |
|    explained_variance   | 0.572     |
|    learning_rate        | 0.00096   |
|    loss                 | -0.0177   |
|    n_updates            | 26030     |
|    policy_gradient_loss | 0.00132   |
|    std                  | 0.195     |
|    value_loss           | 0.00885   |
---------------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2605       |
|    time_elapsed         | 8458       |
|    total_timesteps      | 5335040    |
| train/                  |            |
|    approx_kl            | 0.27439505 |
|    clip_fraction        | 0.417      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.486      |
|    explained_variance   | 0.479      |
|    learning_rate        | 0.00096    |
|    loss                 | -0.0295    |
|    n_updates            | 26040      |
|    policy_gradient_loss | 0.00789    |
|    std                  | 0.19       |
|    value_loss           | 0.0556     |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2606       |
|    time_elapsed         | 8462       |
|    total_timesteps      | 5337088    |
| train/                  |            |
|    approx_kl            | 0.26393566 |
|    clip_fraction        | 0.477      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.475      |
|    explained_variance   | 0.705      |
|    learning_rate        | 0.00096    |
|    loss                 | 0.0329     |
|    n_updates            | 26050      |
|    policy_gradient_loss | 0.0146     |
|    std                  | 0.193      |
|    value_loss           | 0.0322     |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2607       |
|    time_elapsed         | 8465       |
|    total_timesteps      | 5339136    |
| train/                  |            |
|    approx_kl            | 0.17173114 |
|    clip_fraction        | 0.407      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.422      |
|    explained_variance   | 0.8        |
|    learning_rate        | 0.000959   |
|    loss                 | 0.0184     |
|    n_updates            | 26060      |
|    policy_gradient_loss | 0.00582    |
|    std                  | 0.198      |
|    value_loss           | 0.0102     |
----------------------------------------
box reached target
box reached target
box reached target
Eval num_timesteps=5340000, episode_reward=2.87 +/- 3.00
Episode length: 217.00 +/- 70.55
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 217        |
|    mean_reward          | 2.87       |
| time/                   |            |
|    total_timesteps      | 5340000    |
| train/                  |            |
|    approx_kl            | 0.13423595 |
|    clip_fraction        | 0.391      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.399      |
|    explained_variance   | 0.821      |
|    learning_rate        | 0.000959   |
|    loss                 | -0.0156    |
|    n_updates            | 26070      |
|    policy_gradient_loss | 0.0123     |
|    std                  | 0.201      |
|    value_loss           | 0.00918    |
----------------------------------------
box reached target
--------------------------------
| time/              |         |
|    fps             | 630     |
|    iterations      | 2608    |
|    time_elapsed    | 8468    |
|    total_timesteps | 5341184 |
--------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2609       |
|    time_elapsed         | 8471       |
|    total_timesteps      | 5343232    |
| train/                  |            |
|    approx_kl            | 0.23215209 |
|    clip_fraction        | 0.471      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.373      |
|    explained_variance   | 0.317      |
|    learning_rate        | 0.000958   |
|    loss                 | 0.0233     |
|    n_updates            | 26080      |
|    policy_gradient_loss | 0.00801    |
|    std                  | 0.203      |
|    value_loss           | 0.0204     |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2610       |
|    time_elapsed         | 8474       |
|    total_timesteps      | 5345280    |
| train/                  |            |
|    approx_kl            | 0.33765924 |
|    clip_fraction        | 0.432      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.36       |
|    explained_variance   | 0.9        |
|    learning_rate        | 0.000958   |
|    loss                 | 0.372      |
|    n_updates            | 26090      |
|    policy_gradient_loss | 0.0206     |
|    std                  | 0.205      |
|    value_loss           | 0.00346    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2611       |
|    time_elapsed         | 8477       |
|    total_timesteps      | 5347328    |
| train/                  |            |
|    approx_kl            | 0.39960152 |
|    clip_fraction        | 0.425      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.355      |
|    explained_variance   | 0.561      |
|    learning_rate        | 0.000958   |
|    loss                 | 0.0157     |
|    n_updates            | 26100      |
|    policy_gradient_loss | 0.00479    |
|    std                  | 0.202      |
|    value_loss           | 0.0187     |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2612       |
|    time_elapsed         | 8480       |
|    total_timesteps      | 5349376    |
| train/                  |            |
|    approx_kl            | 0.26679355 |
|    clip_fraction        | 0.398      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.424      |
|    explained_variance   | 0.845      |
|    learning_rate        | 0.000957   |
|    loss                 | 0.00478    |
|    n_updates            | 26110      |
|    policy_gradient_loss | -0.00553   |
|    std                  | 0.193      |
|    value_loss           | 0.00413    |
----------------------------------------
box reached target
box reached target
box reached target
Eval num_timesteps=5350000, episode_reward=1.80 +/- 2.79
Episode length: 246.60 +/- 65.57
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 247        |
|    mean_reward          | 1.8        |
| time/                   |            |
|    total_timesteps      | 5350000    |
| train/                  |            |
|    approx_kl            | 0.20950969 |
|    clip_fraction        | 0.395      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.473      |
|    explained_variance   | 0.779      |
|    learning_rate        | 0.000957   |
|    loss                 | 0.0267     |
|    n_updates            | 26120      |
|    policy_gradient_loss | 0.0071     |
|    std                  | 0.193      |
|    value_loss           | 0.0117     |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 630     |
|    iterations      | 2613    |
|    time_elapsed    | 8484    |
|    total_timesteps | 5351424 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2614       |
|    time_elapsed         | 8487       |
|    total_timesteps      | 5353472    |
| train/                  |            |
|    approx_kl            | 0.25769433 |
|    clip_fraction        | 0.45       |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.503      |
|    explained_variance   | 0.63       |
|    learning_rate        | 0.000956   |
|    loss                 | 0.00795    |
|    n_updates            | 26130      |
|    policy_gradient_loss | 0.0225     |
|    std                  | 0.188      |
|    value_loss           | 0.013      |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2615       |
|    time_elapsed         | 8490       |
|    total_timesteps      | 5355520    |
| train/                  |            |
|    approx_kl            | 0.26031107 |
|    clip_fraction        | 0.399      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.574      |
|    explained_variance   | 0.372      |
|    learning_rate        | 0.000956   |
|    loss                 | -0.00841   |
|    n_updates            | 26140      |
|    policy_gradient_loss | 0.0172     |
|    std                  | 0.179      |
|    value_loss           | 0.00322    |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2616       |
|    time_elapsed         | 8493       |
|    total_timesteps      | 5357568    |
| train/                  |            |
|    approx_kl            | 0.24477848 |
|    clip_fraction        | 0.402      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.626      |
|    explained_variance   | 0.335      |
|    learning_rate        | 0.000956   |
|    loss                 | -0.0222    |
|    n_updates            | 26150      |
|    policy_gradient_loss | 0.000104   |
|    std                  | 0.177      |
|    value_loss           | 0.00688    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2617       |
|    time_elapsed         | 8496       |
|    total_timesteps      | 5359616    |
| train/                  |            |
|    approx_kl            | 0.22664464 |
|    clip_fraction        | 0.448      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.608      |
|    explained_variance   | 0.807      |
|    learning_rate        | 0.000955   |
|    loss                 | 0.0291     |
|    n_updates            | 26160      |
|    policy_gradient_loss | 0.0338     |
|    std                  | 0.182      |
|    value_loss           | 0.0262     |
----------------------------------------
box reached target
Eval num_timesteps=5360000, episode_reward=0.48 +/- 2.45
Episode length: 279.00 +/- 42.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 279        |
|    mean_reward          | 0.483      |
| time/                   |            |
|    total_timesteps      | 5360000    |
| train/                  |            |
|    approx_kl            | 0.60515213 |
|    clip_fraction        | 0.399      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.548      |
|    explained_variance   | 0.809      |
|    learning_rate        | 0.000955   |
|    loss                 | -0.00796   |
|    n_updates            | 26170      |
|    policy_gradient_loss | -0.00133   |
|    std                  | 0.186      |
|    value_loss           | 0.0108     |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 630     |
|    iterations      | 2618    |
|    time_elapsed    | 8500    |
|    total_timesteps | 5361664 |
--------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 630       |
|    iterations           | 2619      |
|    time_elapsed         | 8503      |
|    total_timesteps      | 5363712   |
| train/                  |           |
|    approx_kl            | 0.5199225 |
|    clip_fraction        | 0.421     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.551     |
|    explained_variance   | 0.61      |
|    learning_rate        | 0.000954  |
|    loss                 | 0.0732    |
|    n_updates            | 26180     |
|    policy_gradient_loss | 0.00789   |
|    std                  | 0.183     |
|    value_loss           | 0.00385   |
---------------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2620       |
|    time_elapsed         | 8507       |
|    total_timesteps      | 5365760    |
| train/                  |            |
|    approx_kl            | 0.28477374 |
|    clip_fraction        | 0.49       |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.578      |
|    explained_variance   | 0.798      |
|    learning_rate        | 0.000954   |
|    loss                 | 0.0789     |
|    n_updates            | 26190      |
|    policy_gradient_loss | 0.0213     |
|    std                  | 0.181      |
|    value_loss           | 0.0115     |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2621       |
|    time_elapsed         | 8510       |
|    total_timesteps      | 5367808    |
| train/                  |            |
|    approx_kl            | 0.35676178 |
|    clip_fraction        | 0.449      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.59       |
|    explained_variance   | 0.868      |
|    learning_rate        | 0.000954   |
|    loss                 | 0.0337     |
|    n_updates            | 26200      |
|    policy_gradient_loss | 0.0154     |
|    std                  | 0.181      |
|    value_loss           | 0.0126     |
----------------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2622       |
|    time_elapsed         | 8513       |
|    total_timesteps      | 5369856    |
| train/                  |            |
|    approx_kl            | 0.63963675 |
|    clip_fraction        | 0.447      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.602      |
|    explained_variance   | 0.831      |
|    learning_rate        | 0.000953   |
|    loss                 | 0.0123     |
|    n_updates            | 26210      |
|    policy_gradient_loss | 0.00887    |
|    std                  | 0.177      |
|    value_loss           | 0.0089     |
----------------------------------------
box reached target
box reached target
Eval num_timesteps=5370000, episode_reward=1.48 +/- 3.04
Episode length: 241.00 +/- 72.51
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 241        |
|    mean_reward          | 1.48       |
| time/                   |            |
|    total_timesteps      | 5370000    |
| train/                  |            |
|    approx_kl            | 0.38850355 |
|    clip_fraction        | 0.43       |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.629      |
|    explained_variance   | 0.761      |
|    learning_rate        | 0.000953   |
|    loss                 | 0.0433     |
|    n_updates            | 26220      |
|    policy_gradient_loss | 0.00666    |
|    std                  | 0.178      |
|    value_loss           | 0.0298     |
----------------------------------------
box reached target
box reached target
box reached target
--------------------------------
| time/              |         |
|    fps             | 630     |
|    iterations      | 2623    |
|    time_elapsed    | 8516    |
|    total_timesteps | 5371904 |
--------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2624       |
|    time_elapsed         | 8519       |
|    total_timesteps      | 5373952    |
| train/                  |            |
|    approx_kl            | 0.25872374 |
|    clip_fraction        | 0.469      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.618      |
|    explained_variance   | 0.871      |
|    learning_rate        | 0.000952   |
|    loss                 | -0.0207    |
|    n_updates            | 26230      |
|    policy_gradient_loss | 0.0148     |
|    std                  | 0.178      |
|    value_loss           | 0.0263     |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2625       |
|    time_elapsed         | 8523       |
|    total_timesteps      | 5376000    |
| train/                  |            |
|    approx_kl            | 0.16017494 |
|    clip_fraction        | 0.429      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.63       |
|    explained_variance   | 0.793      |
|    learning_rate        | 0.000952   |
|    loss                 | 0.0602     |
|    n_updates            | 26240      |
|    policy_gradient_loss | 0.0224     |
|    std                  | 0.179      |
|    value_loss           | 0.0181     |
----------------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2626       |
|    time_elapsed         | 8526       |
|    total_timesteps      | 5378048    |
| train/                  |            |
|    approx_kl            | 0.23911355 |
|    clip_fraction        | 0.41       |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.61       |
|    explained_variance   | 0.557      |
|    learning_rate        | 0.000952   |
|    loss                 | -0.0431    |
|    n_updates            | 26250      |
|    policy_gradient_loss | 0.00867    |
|    std                  | 0.18       |
|    value_loss           | 0.0184     |
----------------------------------------
box reached target
box reached target
box reached target
Eval num_timesteps=5380000, episode_reward=3.05 +/- 2.80
Episode length: 227.20 +/- 59.56
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 227        |
|    mean_reward          | 3.05       |
| time/                   |            |
|    total_timesteps      | 5380000    |
| train/                  |            |
|    approx_kl            | 0.42115134 |
|    clip_fraction        | 0.47       |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.581      |
|    explained_variance   | 0.827      |
|    learning_rate        | 0.000951   |
|    loss                 | 0.00982    |
|    n_updates            | 26260      |
|    policy_gradient_loss | 0.00788    |
|    std                  | 0.182      |
|    value_loss           | 0.0309     |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 630     |
|    iterations      | 2627    |
|    time_elapsed    | 8529    |
|    total_timesteps | 5380096 |
--------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2628       |
|    time_elapsed         | 8532       |
|    total_timesteps      | 5382144    |
| train/                  |            |
|    approx_kl            | 0.50719815 |
|    clip_fraction        | 0.468      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.603      |
|    explained_variance   | 0.797      |
|    learning_rate        | 0.000951   |
|    loss                 | -0.0347    |
|    n_updates            | 26270      |
|    policy_gradient_loss | 0.00219    |
|    std                  | 0.176      |
|    value_loss           | 0.0145     |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2629       |
|    time_elapsed         | 8535       |
|    total_timesteps      | 5384192    |
| train/                  |            |
|    approx_kl            | 0.21241078 |
|    clip_fraction        | 0.448      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.638      |
|    explained_variance   | 0.898      |
|    learning_rate        | 0.00095    |
|    loss                 | -0.00708   |
|    n_updates            | 26280      |
|    policy_gradient_loss | 0.032      |
|    std                  | 0.177      |
|    value_loss           | 0.0154     |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2630       |
|    time_elapsed         | 8539       |
|    total_timesteps      | 5386240    |
| train/                  |            |
|    approx_kl            | 0.15430933 |
|    clip_fraction        | 0.399      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.635      |
|    explained_variance   | 0.794      |
|    learning_rate        | 0.00095    |
|    loss                 | 0.0307     |
|    n_updates            | 26290      |
|    policy_gradient_loss | 0.013      |
|    std                  | 0.176      |
|    value_loss           | 0.00559    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2631       |
|    time_elapsed         | 8542       |
|    total_timesteps      | 5388288    |
| train/                  |            |
|    approx_kl            | 0.21938577 |
|    clip_fraction        | 0.453      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.623      |
|    explained_variance   | 0.902      |
|    learning_rate        | 0.00095    |
|    loss                 | -0.00111   |
|    n_updates            | 26300      |
|    policy_gradient_loss | 0.0093     |
|    std                  | 0.178      |
|    value_loss           | 0.0146     |
----------------------------------------
box reached target
box reached target
Eval num_timesteps=5390000, episode_reward=0.49 +/- 2.34
Episode length: 274.20 +/- 51.60
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 274        |
|    mean_reward          | 0.49       |
| time/                   |            |
|    total_timesteps      | 5390000    |
| train/                  |            |
|    approx_kl            | 0.28172666 |
|    clip_fraction        | 0.404      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.62       |
|    explained_variance   | 0.65       |
|    learning_rate        | 0.000949   |
|    loss                 | -0.0537    |
|    n_updates            | 26310      |
|    policy_gradient_loss | -0.0104    |
|    std                  | 0.177      |
|    value_loss           | 0.00396    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 630     |
|    iterations      | 2632    |
|    time_elapsed    | 8545    |
|    total_timesteps | 5390336 |
--------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 630       |
|    iterations           | 2633      |
|    time_elapsed         | 8549      |
|    total_timesteps      | 5392384   |
| train/                  |           |
|    approx_kl            | 0.3860571 |
|    clip_fraction        | 0.44      |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.607     |
|    explained_variance   | 0.878     |
|    learning_rate        | 0.000949  |
|    loss                 | -0.0083   |
|    n_updates            | 26320     |
|    policy_gradient_loss | 0.0167    |
|    std                  | 0.178     |
|    value_loss           | 0.012     |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2634       |
|    time_elapsed         | 8552       |
|    total_timesteps      | 5394432    |
| train/                  |            |
|    approx_kl            | 0.55123955 |
|    clip_fraction        | 0.437      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.6        |
|    explained_variance   | 0.811      |
|    learning_rate        | 0.000948   |
|    loss                 | 0.00121    |
|    n_updates            | 26330      |
|    policy_gradient_loss | 0.00857    |
|    std                  | 0.18       |
|    value_loss           | 0.0093     |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2635       |
|    time_elapsed         | 8555       |
|    total_timesteps      | 5396480    |
| train/                  |            |
|    approx_kl            | 0.32967892 |
|    clip_fraction        | 0.407      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.582      |
|    explained_variance   | 0.792      |
|    learning_rate        | 0.000948   |
|    loss                 | 0.00136    |
|    n_updates            | 26340      |
|    policy_gradient_loss | 0.0124     |
|    std                  | 0.182      |
|    value_loss           | 0.01       |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2636       |
|    time_elapsed         | 8558       |
|    total_timesteps      | 5398528    |
| train/                  |            |
|    approx_kl            | 0.25896493 |
|    clip_fraction        | 0.493      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.571      |
|    explained_variance   | 0.365      |
|    learning_rate        | 0.000948   |
|    loss                 | -0.0165    |
|    n_updates            | 26350      |
|    policy_gradient_loss | 0.0265     |
|    std                  | 0.181      |
|    value_loss           | 0.0202     |
----------------------------------------
box reached target
Eval num_timesteps=5400000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1         |
| time/                   |            |
|    total_timesteps      | 5400000    |
| train/                  |            |
|    approx_kl            | 0.44100225 |
|    clip_fraction        | 0.444      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.604      |
|    explained_variance   | 0.625      |
|    learning_rate        | 0.000947   |
|    loss                 | 1.25       |
|    n_updates            | 26360      |
|    policy_gradient_loss | 0.0432     |
|    std                  | 0.177      |
|    value_loss           | 0.00766    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 630     |
|    iterations      | 2637    |
|    time_elapsed    | 8562    |
|    total_timesteps | 5400576 |
--------------------------------
box reached target
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 630       |
|    iterations           | 2638      |
|    time_elapsed         | 8565      |
|    total_timesteps      | 5402624   |
| train/                  |           |
|    approx_kl            | 0.3308556 |
|    clip_fraction        | 0.458     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.575     |
|    explained_variance   | 0.848     |
|    learning_rate        | 0.000947  |
|    loss                 | 0.00472   |
|    n_updates            | 26370     |
|    policy_gradient_loss | 0.02      |
|    std                  | 0.182     |
|    value_loss           | 0.0256    |
---------------------------------------
box reached target
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 630       |
|    iterations           | 2639      |
|    time_elapsed         | 8568      |
|    total_timesteps      | 5404672   |
| train/                  |           |
|    approx_kl            | 1.1431019 |
|    clip_fraction        | 0.514     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.554     |
|    explained_variance   | 0.79      |
|    learning_rate        | 0.000946  |
|    loss                 | 0.061     |
|    n_updates            | 26380     |
|    policy_gradient_loss | 0.00883   |
|    std                  | 0.183     |
|    value_loss           | 0.027     |
---------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2640       |
|    time_elapsed         | 8571       |
|    total_timesteps      | 5406720    |
| train/                  |            |
|    approx_kl            | 0.19324902 |
|    clip_fraction        | 0.403      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.542      |
|    explained_variance   | 0.752      |
|    learning_rate        | 0.000946   |
|    loss                 | -0.00207   |
|    n_updates            | 26390      |
|    policy_gradient_loss | 0.00898    |
|    std                  | 0.186      |
|    value_loss           | 0.0743     |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2641       |
|    time_elapsed         | 8574       |
|    total_timesteps      | 5408768    |
| train/                  |            |
|    approx_kl            | 0.43639058 |
|    clip_fraction        | 0.509      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.541      |
|    explained_variance   | 0.924      |
|    learning_rate        | 0.000946   |
|    loss                 | 0.068      |
|    n_updates            | 26400      |
|    policy_gradient_loss | 0.00559    |
|    std                  | 0.184      |
|    value_loss           | 0.00952    |
----------------------------------------
Eval num_timesteps=5410000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1         |
| time/                   |            |
|    total_timesteps      | 5410000    |
| train/                  |            |
|    approx_kl            | 0.12924603 |
|    clip_fraction        | 0.421      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.548      |
|    explained_variance   | 0.771      |
|    learning_rate        | 0.000945   |
|    loss                 | -0.0222    |
|    n_updates            | 26410      |
|    policy_gradient_loss | 0.0114     |
|    std                  | 0.183      |
|    value_loss           | 0.0288     |
----------------------------------------
box reached target
--------------------------------
| time/              |         |
|    fps             | 630     |
|    iterations      | 2642    |
|    time_elapsed    | 8578    |
|    total_timesteps | 5410816 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2643       |
|    time_elapsed         | 8581       |
|    total_timesteps      | 5412864    |
| train/                  |            |
|    approx_kl            | 0.38291487 |
|    clip_fraction        | 0.44       |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.547      |
|    explained_variance   | 0.903      |
|    learning_rate        | 0.000945   |
|    loss                 | 0.0515     |
|    n_updates            | 26420      |
|    policy_gradient_loss | 0.0223     |
|    std                  | 0.184      |
|    value_loss           | 0.00803    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2644       |
|    time_elapsed         | 8584       |
|    total_timesteps      | 5414912    |
| train/                  |            |
|    approx_kl            | 0.46042317 |
|    clip_fraction        | 0.456      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.542      |
|    explained_variance   | 0.642      |
|    learning_rate        | 0.000944   |
|    loss                 | -0.031     |
|    n_updates            | 26430      |
|    policy_gradient_loss | 0.00787    |
|    std                  | 0.184      |
|    value_loss           | 0.0126     |
----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 630         |
|    iterations           | 2645        |
|    time_elapsed         | 8587        |
|    total_timesteps      | 5416960     |
| train/                  |             |
|    approx_kl            | 0.124138966 |
|    clip_fraction        | 0.388       |
|    clip_range           | 0.2         |
|    entropy_loss         | 0.555       |
|    explained_variance   | 0.716       |
|    learning_rate        | 0.000944    |
|    loss                 | 0.0156      |
|    n_updates            | 26440       |
|    policy_gradient_loss | 0.00508     |
|    std                  | 0.183       |
|    value_loss           | 0.00632     |
-----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 630       |
|    iterations           | 2646      |
|    time_elapsed         | 8590      |
|    total_timesteps      | 5419008   |
| train/                  |           |
|    approx_kl            | 0.3206676 |
|    clip_fraction        | 0.425     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.566     |
|    explained_variance   | 0.739     |
|    learning_rate        | 0.000944  |
|    loss                 | 0.0427    |
|    n_updates            | 26450     |
|    policy_gradient_loss | 0.00397   |
|    std                  | 0.18      |
|    value_loss           | 0.00499   |
---------------------------------------
box reached target
Eval num_timesteps=5420000, episode_reward=-0.82 +/- 0.36
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -0.819     |
| time/                   |            |
|    total_timesteps      | 5420000    |
| train/                  |            |
|    approx_kl            | 0.22738938 |
|    clip_fraction        | 0.43       |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.595      |
|    explained_variance   | 0.787      |
|    learning_rate        | 0.000943   |
|    loss                 | 0.0337     |
|    n_updates            | 26460      |
|    policy_gradient_loss | 0.00616    |
|    std                  | 0.18       |
|    value_loss           | 0.00315    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 630     |
|    iterations      | 2647    |
|    time_elapsed    | 8594    |
|    total_timesteps | 5421056 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2648       |
|    time_elapsed         | 8597       |
|    total_timesteps      | 5423104    |
| train/                  |            |
|    approx_kl            | 0.16196872 |
|    clip_fraction        | 0.462      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.641      |
|    explained_variance   | 0.817      |
|    learning_rate        | 0.000943   |
|    loss                 | 0.041      |
|    n_updates            | 26470      |
|    policy_gradient_loss | 0.0158     |
|    std                  | 0.174      |
|    value_loss           | 0.0124     |
----------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 630       |
|    iterations           | 2649      |
|    time_elapsed         | 8600      |
|    total_timesteps      | 5425152   |
| train/                  |           |
|    approx_kl            | 1.0266106 |
|    clip_fraction        | 0.513     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.68      |
|    explained_variance   | 0.59      |
|    learning_rate        | 0.000942  |
|    loss                 | 0.0679    |
|    n_updates            | 26480     |
|    policy_gradient_loss | 0.0046    |
|    std                  | 0.171     |
|    value_loss           | 0.00936   |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2650       |
|    time_elapsed         | 8603       |
|    total_timesteps      | 5427200    |
| train/                  |            |
|    approx_kl            | 0.21066463 |
|    clip_fraction        | 0.465      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.689      |
|    explained_variance   | 0.798      |
|    learning_rate        | 0.000942   |
|    loss                 | -0.00637   |
|    n_updates            | 26490      |
|    policy_gradient_loss | 0.0238     |
|    std                  | 0.172      |
|    value_loss           | 0.0168     |
----------------------------------------
box reached target
--------------------------------------
| time/                   |          |
|    fps                  | 630      |
|    iterations           | 2651     |
|    time_elapsed         | 8606     |
|    total_timesteps      | 5429248  |
| train/                  |          |
|    approx_kl            | 1.12748  |
|    clip_fraction        | 0.559    |
|    clip_range           | 0.2      |
|    entropy_loss         | 0.721    |
|    explained_variance   | 0.959    |
|    learning_rate        | 0.000942 |
|    loss                 | -0.0476  |
|    n_updates            | 26500    |
|    policy_gradient_loss | -0.00481 |
|    std                  | 0.169    |
|    value_loss           | 0.00686  |
--------------------------------------
Eval num_timesteps=5430000, episode_reward=-1.08 +/- 0.16
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1.08      |
| time/                   |            |
|    total_timesteps      | 5430000    |
| train/                  |            |
|    approx_kl            | 0.16927293 |
|    clip_fraction        | 0.457      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.702      |
|    explained_variance   | 0.797      |
|    learning_rate        | 0.000941   |
|    loss                 | 0.0124     |
|    n_updates            | 26510      |
|    policy_gradient_loss | 0.0153     |
|    std                  | 0.173      |
|    value_loss           | 0.00553    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 630     |
|    iterations      | 2652    |
|    time_elapsed    | 8610    |
|    total_timesteps | 5431296 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2653       |
|    time_elapsed         | 8613       |
|    total_timesteps      | 5433344    |
| train/                  |            |
|    approx_kl            | 0.30910343 |
|    clip_fraction        | 0.461      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.706      |
|    explained_variance   | 0.77       |
|    learning_rate        | 0.000941   |
|    loss                 | -0.00783   |
|    n_updates            | 26520      |
|    policy_gradient_loss | 0.0181     |
|    std                  | 0.169      |
|    value_loss           | 0.00324    |
----------------------------------------
box reached target
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2654       |
|    time_elapsed         | 8616       |
|    total_timesteps      | 5435392    |
| train/                  |            |
|    approx_kl            | 0.23207235 |
|    clip_fraction        | 0.442      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.697      |
|    explained_variance   | 0.85       |
|    learning_rate        | 0.00094    |
|    loss                 | -0.0563    |
|    n_updates            | 26530      |
|    policy_gradient_loss | 0.0076     |
|    std                  | 0.172      |
|    value_loss           | 0.0036     |
----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 630       |
|    iterations           | 2655      |
|    time_elapsed         | 8619      |
|    total_timesteps      | 5437440   |
| train/                  |           |
|    approx_kl            | 0.6939635 |
|    clip_fraction        | 0.504     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.695     |
|    explained_variance   | 0.929     |
|    learning_rate        | 0.00094   |
|    loss                 | -0.0186   |
|    n_updates            | 26540     |
|    policy_gradient_loss | 0.0456    |
|    std                  | 0.167     |
|    value_loss           | 0.0203    |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2656       |
|    time_elapsed         | 8623       |
|    total_timesteps      | 5439488    |
| train/                  |            |
|    approx_kl            | 0.19199248 |
|    clip_fraction        | 0.391      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.732      |
|    explained_variance   | 0.87       |
|    learning_rate        | 0.00094    |
|    loss                 | -0.00986   |
|    n_updates            | 26550      |
|    policy_gradient_loss | 0.00576    |
|    std                  | 0.169      |
|    value_loss           | 0.0109     |
----------------------------------------
Eval num_timesteps=5440000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1         |
| time/                   |            |
|    total_timesteps      | 5440000    |
| train/                  |            |
|    approx_kl            | 0.18925974 |
|    clip_fraction        | 0.4        |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.7        |
|    explained_variance   | 0.884      |
|    learning_rate        | 0.000939   |
|    loss                 | 0.00889    |
|    n_updates            | 26560      |
|    policy_gradient_loss | 0.0235     |
|    std                  | 0.171      |
|    value_loss           | 0.00564    |
----------------------------------------
box reached target
--------------------------------
| time/              |         |
|    fps             | 630     |
|    iterations      | 2657    |
|    time_elapsed    | 8626    |
|    total_timesteps | 5441536 |
--------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 630       |
|    iterations           | 2658      |
|    time_elapsed         | 8630      |
|    total_timesteps      | 5443584   |
| train/                  |           |
|    approx_kl            | 0.8293942 |
|    clip_fraction        | 0.455     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.695     |
|    explained_variance   | 0.96      |
|    learning_rate        | 0.000939  |
|    loss                 | -0.0637   |
|    n_updates            | 26570     |
|    policy_gradient_loss | 0.0122    |
|    std                  | 0.171     |
|    value_loss           | 0.0039    |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2659       |
|    time_elapsed         | 8633       |
|    total_timesteps      | 5445632    |
| train/                  |            |
|    approx_kl            | 0.22459875 |
|    clip_fraction        | 0.424      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.674      |
|    explained_variance   | 0.86       |
|    learning_rate        | 0.000939   |
|    loss                 | 0.00716    |
|    n_updates            | 26580      |
|    policy_gradient_loss | 0.00203    |
|    std                  | 0.173      |
|    value_loss           | 0.0034     |
----------------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2660       |
|    time_elapsed         | 8636       |
|    total_timesteps      | 5447680    |
| train/                  |            |
|    approx_kl            | 0.32948363 |
|    clip_fraction        | 0.48       |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.669      |
|    explained_variance   | 0.76       |
|    learning_rate        | 0.000938   |
|    loss                 | 0.00411    |
|    n_updates            | 26590      |
|    policy_gradient_loss | 0.011      |
|    std                  | 0.173      |
|    value_loss           | 0.00152    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2661       |
|    time_elapsed         | 8639       |
|    total_timesteps      | 5449728    |
| train/                  |            |
|    approx_kl            | 0.24514303 |
|    clip_fraction        | 0.445      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.654      |
|    explained_variance   | 0.726      |
|    learning_rate        | 0.000938   |
|    loss                 | 0.0425     |
|    n_updates            | 26600      |
|    policy_gradient_loss | 0.0142     |
|    std                  | 0.176      |
|    value_loss           | 0.0288     |
----------------------------------------
box reached target
Eval num_timesteps=5450000, episode_reward=0.26 +/- 2.53
Episode length: 295.80 +/- 8.40
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 296        |
|    mean_reward          | 0.265      |
| time/                   |            |
|    total_timesteps      | 5450000    |
| train/                  |            |
|    approx_kl            | 0.14914024 |
|    clip_fraction        | 0.393      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.584      |
|    explained_variance   | 0.724      |
|    learning_rate        | 0.000937   |
|    loss                 | -0.00297   |
|    n_updates            | 26610      |
|    policy_gradient_loss | 0.00831    |
|    std                  | 0.184      |
|    value_loss           | 0.00576    |
----------------------------------------
box reached target
--------------------------------
| time/              |         |
|    fps             | 630     |
|    iterations      | 2662    |
|    time_elapsed    | 8643    |
|    total_timesteps | 5451776 |
--------------------------------
box reached target
box reached target
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 630       |
|    iterations           | 2663      |
|    time_elapsed         | 8646      |
|    total_timesteps      | 5453824   |
| train/                  |           |
|    approx_kl            | 0.3188582 |
|    clip_fraction        | 0.478     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.596     |
|    explained_variance   | 0.842     |
|    learning_rate        | 0.000937  |
|    loss                 | -0.0134   |
|    n_updates            | 26620     |
|    policy_gradient_loss | 0.000496  |
|    std                  | 0.177     |
|    value_loss           | 0.0171    |
---------------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2664       |
|    time_elapsed         | 8649       |
|    total_timesteps      | 5455872    |
| train/                  |            |
|    approx_kl            | 0.18440637 |
|    clip_fraction        | 0.421      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.641      |
|    explained_variance   | 0.733      |
|    learning_rate        | 0.000937   |
|    loss                 | 0.000893   |
|    n_updates            | 26630      |
|    policy_gradient_loss | 0.0104     |
|    std                  | 0.175      |
|    value_loss           | 0.0531     |
----------------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2665       |
|    time_elapsed         | 8652       |
|    total_timesteps      | 5457920    |
| train/                  |            |
|    approx_kl            | 0.25282228 |
|    clip_fraction        | 0.45       |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.648      |
|    explained_variance   | 0.796      |
|    learning_rate        | 0.000936   |
|    loss                 | -0.0129    |
|    n_updates            | 26640      |
|    policy_gradient_loss | 0.0128     |
|    std                  | 0.175      |
|    value_loss           | 0.0357     |
----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 630       |
|    iterations           | 2666      |
|    time_elapsed         | 8655      |
|    total_timesteps      | 5459968   |
| train/                  |           |
|    approx_kl            | 0.4137284 |
|    clip_fraction        | 0.526     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.646     |
|    explained_variance   | 0.833     |
|    learning_rate        | 0.000936  |
|    loss                 | -0.00532  |
|    n_updates            | 26650     |
|    policy_gradient_loss | 0.026     |
|    std                  | 0.176     |
|    value_loss           | 0.0349    |
---------------------------------------
Eval num_timesteps=5460000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1         |
| time/                   |            |
|    total_timesteps      | 5460000    |
| train/                  |            |
|    approx_kl            | 0.34521988 |
|    clip_fraction        | 0.438      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.639      |
|    explained_variance   | 0.419      |
|    learning_rate        | 0.000935   |
|    loss                 | -0.0275    |
|    n_updates            | 26660      |
|    policy_gradient_loss | 0.015      |
|    std                  | 0.175      |
|    value_loss           | 0.0036     |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 630     |
|    iterations      | 2667    |
|    time_elapsed    | 8659    |
|    total_timesteps | 5462016 |
--------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2668       |
|    time_elapsed         | 8662       |
|    total_timesteps      | 5464064    |
| train/                  |            |
|    approx_kl            | 0.50800425 |
|    clip_fraction        | 0.472      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.632      |
|    explained_variance   | 0.754      |
|    learning_rate        | 0.000935   |
|    loss                 | -0.0276    |
|    n_updates            | 26670      |
|    policy_gradient_loss | 0.0227     |
|    std                  | 0.177      |
|    value_loss           | 0.00703    |
----------------------------------------
box reached target
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 630       |
|    iterations           | 2669      |
|    time_elapsed         | 8665      |
|    total_timesteps      | 5466112   |
| train/                  |           |
|    approx_kl            | 0.6488421 |
|    clip_fraction        | 0.449     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.628     |
|    explained_variance   | 0.86      |
|    learning_rate        | 0.000935  |
|    loss                 | -0.0167   |
|    n_updates            | 26680     |
|    policy_gradient_loss | 0.00797   |
|    std                  | 0.176     |
|    value_loss           | 0.0116    |
---------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 630       |
|    iterations           | 2670      |
|    time_elapsed         | 8668      |
|    total_timesteps      | 5468160   |
| train/                  |           |
|    approx_kl            | 0.6385262 |
|    clip_fraction        | 0.489     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.677     |
|    explained_variance   | 0.817     |
|    learning_rate        | 0.000934  |
|    loss                 | -0.0266   |
|    n_updates            | 26690     |
|    policy_gradient_loss | 0.00326   |
|    std                  | 0.172     |
|    value_loss           | 0.0243    |
---------------------------------------
Eval num_timesteps=5470000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 300       |
|    mean_reward          | -1        |
| time/                   |           |
|    total_timesteps      | 5470000   |
| train/                  |           |
|    approx_kl            | 1.2134744 |
|    clip_fraction        | 0.486     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.723     |
|    explained_variance   | 0.847     |
|    learning_rate        | 0.000934  |
|    loss                 | -0.0103   |
|    n_updates            | 26700     |
|    policy_gradient_loss | 0.00914   |
|    std                  | 0.167     |
|    value_loss           | 0.0111    |
---------------------------------------
--------------------------------
| time/              |         |
|    fps             | 630     |
|    iterations      | 2671    |
|    time_elapsed    | 8672    |
|    total_timesteps | 5470208 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2672       |
|    time_elapsed         | 8675       |
|    total_timesteps      | 5472256    |
| train/                  |            |
|    approx_kl            | 0.26028597 |
|    clip_fraction        | 0.413      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.732      |
|    explained_variance   | 0.802      |
|    learning_rate        | 0.000933   |
|    loss                 | -0.0297    |
|    n_updates            | 26710      |
|    policy_gradient_loss | 0.00592    |
|    std                  | 0.17       |
|    value_loss           | 0.00407    |
----------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 630       |
|    iterations           | 2673      |
|    time_elapsed         | 8678      |
|    total_timesteps      | 5474304   |
| train/                  |           |
|    approx_kl            | 0.5047519 |
|    clip_fraction        | 0.482     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.737     |
|    explained_variance   | -0.139    |
|    learning_rate        | 0.000933  |
|    loss                 | -0.0292   |
|    n_updates            | 26720     |
|    policy_gradient_loss | 0.0153    |
|    std                  | 0.166     |
|    value_loss           | 0.00487   |
---------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2674       |
|    time_elapsed         | 8681       |
|    total_timesteps      | 5476352    |
| train/                  |            |
|    approx_kl            | 0.16109577 |
|    clip_fraction        | 0.455      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.718      |
|    explained_variance   | 0.809      |
|    learning_rate        | 0.000933   |
|    loss                 | 0.0149     |
|    n_updates            | 26730      |
|    policy_gradient_loss | 0.0123     |
|    std                  | 0.171      |
|    value_loss           | 0.0198     |
----------------------------------------
box reached target
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2675       |
|    time_elapsed         | 8684       |
|    total_timesteps      | 5478400    |
| train/                  |            |
|    approx_kl            | 0.34279045 |
|    clip_fraction        | 0.508      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.691      |
|    explained_variance   | 0.633      |
|    learning_rate        | 0.000932   |
|    loss                 | 0.0278     |
|    n_updates            | 26740      |
|    policy_gradient_loss | 0.0213     |
|    std                  | 0.173      |
|    value_loss           | 0.03       |
----------------------------------------
box reached target
Eval num_timesteps=5480000, episode_reward=-0.85 +/- 0.30
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -0.85      |
| time/                   |            |
|    total_timesteps      | 5480000    |
| train/                  |            |
|    approx_kl            | 0.36147973 |
|    clip_fraction        | 0.488      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.705      |
|    explained_variance   | 0.935      |
|    learning_rate        | 0.000932   |
|    loss                 | 0.005      |
|    n_updates            | 26750      |
|    policy_gradient_loss | 0.0163     |
|    std                  | 0.17       |
|    value_loss           | 0.0185     |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 630     |
|    iterations      | 2676    |
|    time_elapsed    | 8688    |
|    total_timesteps | 5480448 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2677       |
|    time_elapsed         | 8691       |
|    total_timesteps      | 5482496    |
| train/                  |            |
|    approx_kl            | 0.16728242 |
|    clip_fraction        | 0.458      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.727      |
|    explained_variance   | 0.907      |
|    learning_rate        | 0.000931   |
|    loss                 | -0.0161    |
|    n_updates            | 26760      |
|    policy_gradient_loss | 0.029      |
|    std                  | 0.169      |
|    value_loss           | 0.0179     |
----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 630       |
|    iterations           | 2678      |
|    time_elapsed         | 8694      |
|    total_timesteps      | 5484544   |
| train/                  |           |
|    approx_kl            | 0.7193626 |
|    clip_fraction        | 0.522     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.72      |
|    explained_variance   | 0.181     |
|    learning_rate        | 0.000931  |
|    loss                 | 0.0406    |
|    n_updates            | 26770     |
|    policy_gradient_loss | 0.0134    |
|    std                  | 0.171     |
|    value_loss           | 0.00322   |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2679       |
|    time_elapsed         | 8697       |
|    total_timesteps      | 5486592    |
| train/                  |            |
|    approx_kl            | 0.22054169 |
|    clip_fraction        | 0.406      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.691      |
|    explained_variance   | -0.0317    |
|    learning_rate        | 0.000931   |
|    loss                 | 0.00862    |
|    n_updates            | 26780      |
|    policy_gradient_loss | 0.0184     |
|    std                  | 0.174      |
|    value_loss           | 0.00422    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2680       |
|    time_elapsed         | 8700       |
|    total_timesteps      | 5488640    |
| train/                  |            |
|    approx_kl            | 0.31817287 |
|    clip_fraction        | 0.434      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.697      |
|    explained_variance   | 0.748      |
|    learning_rate        | 0.00093    |
|    loss                 | -0.00689   |
|    n_updates            | 26790      |
|    policy_gradient_loss | 0.0105     |
|    std                  | 0.172      |
|    value_loss           | 0.00664    |
----------------------------------------
Eval num_timesteps=5490000, episode_reward=-0.81 +/- 0.37
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -0.815     |
| time/                   |            |
|    total_timesteps      | 5490000    |
| train/                  |            |
|    approx_kl            | 0.30174243 |
|    clip_fraction        | 0.416      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.715      |
|    explained_variance   | 0.735      |
|    learning_rate        | 0.00093    |
|    loss                 | -0.0783    |
|    n_updates            | 26800      |
|    policy_gradient_loss | -0.00807   |
|    std                  | 0.169      |
|    value_loss           | 0.00486    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 630     |
|    iterations      | 2681    |
|    time_elapsed    | 8704    |
|    total_timesteps | 5490688 |
--------------------------------
box reached target
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2682       |
|    time_elapsed         | 8707       |
|    total_timesteps      | 5492736    |
| train/                  |            |
|    approx_kl            | 0.15671451 |
|    clip_fraction        | 0.434      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.741      |
|    explained_variance   | 0.453      |
|    learning_rate        | 0.000929   |
|    loss                 | 0.0406     |
|    n_updates            | 26810      |
|    policy_gradient_loss | 0.0203     |
|    std                  | 0.169      |
|    value_loss           | 0.00285    |
----------------------------------------
box reached target
--------------------------------------
| time/                   |          |
|    fps                  | 630      |
|    iterations           | 2683     |
|    time_elapsed         | 8710     |
|    total_timesteps      | 5494784  |
| train/                  |          |
|    approx_kl            | 0.412864 |
|    clip_fraction        | 0.5      |
|    clip_range           | 0.2      |
|    entropy_loss         | 0.742    |
|    explained_variance   | 0.878    |
|    learning_rate        | 0.000929 |
|    loss                 | 0.0943   |
|    n_updates            | 26820    |
|    policy_gradient_loss | 0.0218   |
|    std                  | 0.166    |
|    value_loss           | 0.0204   |
--------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2684       |
|    time_elapsed         | 8714       |
|    total_timesteps      | 5496832    |
| train/                  |            |
|    approx_kl            | 0.43116558 |
|    clip_fraction        | 0.47       |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.791      |
|    explained_variance   | 0.854      |
|    learning_rate        | 0.000929   |
|    loss                 | 0.0128     |
|    n_updates            | 26830      |
|    policy_gradient_loss | 0.0154     |
|    std                  | 0.163      |
|    value_loss           | 0.00635    |
----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 630       |
|    iterations           | 2685      |
|    time_elapsed         | 8717      |
|    total_timesteps      | 5498880   |
| train/                  |           |
|    approx_kl            | 0.2329005 |
|    clip_fraction        | 0.455     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.81      |
|    explained_variance   | 0.85      |
|    learning_rate        | 0.000928  |
|    loss                 | -0.0463   |
|    n_updates            | 26840     |
|    policy_gradient_loss | 0.0277    |
|    std                  | 0.162     |
|    value_loss           | 0.00829   |
---------------------------------------
Eval num_timesteps=5500000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1         |
| time/                   |            |
|    total_timesteps      | 5500000    |
| train/                  |            |
|    approx_kl            | 0.18886453 |
|    clip_fraction        | 0.454      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.811      |
|    explained_variance   | 0.603      |
|    learning_rate        | 0.000928   |
|    loss                 | -0.00343   |
|    n_updates            | 26850      |
|    policy_gradient_loss | 0.0208     |
|    std                  | 0.162      |
|    value_loss           | 0.00629    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 630     |
|    iterations      | 2686    |
|    time_elapsed    | 8721    |
|    total_timesteps | 5500928 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2687       |
|    time_elapsed         | 8724       |
|    total_timesteps      | 5502976    |
| train/                  |            |
|    approx_kl            | 0.32356554 |
|    clip_fraction        | 0.461      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.812      |
|    explained_variance   | 0.799      |
|    learning_rate        | 0.000927   |
|    loss                 | -0.0129    |
|    n_updates            | 26860      |
|    policy_gradient_loss | 0.0117     |
|    std                  | 0.162      |
|    value_loss           | 0.00244    |
----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 630       |
|    iterations           | 2688      |
|    time_elapsed         | 8727      |
|    total_timesteps      | 5505024   |
| train/                  |           |
|    approx_kl            | 0.3383426 |
|    clip_fraction        | 0.455     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.795     |
|    explained_variance   | 0.664     |
|    learning_rate        | 0.000927  |
|    loss                 | 0.00834   |
|    n_updates            | 26870     |
|    policy_gradient_loss | 0.0167    |
|    std                  | 0.163     |
|    value_loss           | 0.00486   |
---------------------------------------
box reached target
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2689       |
|    time_elapsed         | 8730       |
|    total_timesteps      | 5507072    |
| train/                  |            |
|    approx_kl            | 0.42291093 |
|    clip_fraction        | 0.453      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.765      |
|    explained_variance   | -0.103     |
|    learning_rate        | 0.000927   |
|    loss                 | 0.0927     |
|    n_updates            | 26880      |
|    policy_gradient_loss | 0.0313     |
|    std                  | 0.169      |
|    value_loss           | 0.00227    |
----------------------------------------
--------------------------------------
| time/                   |          |
|    fps                  | 630      |
|    iterations           | 2690     |
|    time_elapsed         | 8733     |
|    total_timesteps      | 5509120  |
| train/                  |          |
|    approx_kl            | 0.481664 |
|    clip_fraction        | 0.501    |
|    clip_range           | 0.2      |
|    entropy_loss         | 0.712    |
|    explained_variance   | 0.778    |
|    learning_rate        | 0.000926 |
|    loss                 | 0.00131  |
|    n_updates            | 26890    |
|    policy_gradient_loss | 0.0218   |
|    std                  | 0.171    |
|    value_loss           | 0.0764   |
--------------------------------------
box reached target
Eval num_timesteps=5510000, episode_reward=0.24 +/- 2.49
Episode length: 272.80 +/- 54.40
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 273       |
|    mean_reward          | 0.244     |
| time/                   |           |
|    total_timesteps      | 5510000   |
| train/                  |           |
|    approx_kl            | 0.6426185 |
|    clip_fraction        | 0.455     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.691     |
|    explained_variance   | -1.27     |
|    learning_rate        | 0.000926  |
|    loss                 | -0.0265   |
|    n_updates            | 26900     |
|    policy_gradient_loss | 0.022     |
|    std                  | 0.173     |
|    value_loss           | 0.00654   |
---------------------------------------
--------------------------------
| time/              |         |
|    fps             | 630     |
|    iterations      | 2691    |
|    time_elapsed    | 8737    |
|    total_timesteps | 5511168 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2692       |
|    time_elapsed         | 8740       |
|    total_timesteps      | 5513216    |
| train/                  |            |
|    approx_kl            | 0.25980192 |
|    clip_fraction        | 0.474      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.696      |
|    explained_variance   | 0.658      |
|    learning_rate        | 0.000925   |
|    loss                 | 0.0291     |
|    n_updates            | 26910      |
|    policy_gradient_loss | 0.0178     |
|    std                  | 0.171      |
|    value_loss           | 0.0054     |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2693       |
|    time_elapsed         | 8743       |
|    total_timesteps      | 5515264    |
| train/                  |            |
|    approx_kl            | 0.28551126 |
|    clip_fraction        | 0.461      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.708      |
|    explained_variance   | 0.743      |
|    learning_rate        | 0.000925   |
|    loss                 | -0.0299    |
|    n_updates            | 26920      |
|    policy_gradient_loss | 0.00188    |
|    std                  | 0.17       |
|    value_loss           | 0.0111     |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2694       |
|    time_elapsed         | 8746       |
|    total_timesteps      | 5517312    |
| train/                  |            |
|    approx_kl            | 0.36000115 |
|    clip_fraction        | 0.431      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.715      |
|    explained_variance   | 0.403      |
|    learning_rate        | 0.000925   |
|    loss                 | 0.0174     |
|    n_updates            | 26930      |
|    policy_gradient_loss | 0.0134     |
|    std                  | 0.171      |
|    value_loss           | 0.00438    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2695       |
|    time_elapsed         | 8749       |
|    total_timesteps      | 5519360    |
| train/                  |            |
|    approx_kl            | 0.51669896 |
|    clip_fraction        | 0.434      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.754      |
|    explained_variance   | 0.238      |
|    learning_rate        | 0.000924   |
|    loss                 | 0.0633     |
|    n_updates            | 26940      |
|    policy_gradient_loss | -0.0137    |
|    std                  | 0.163      |
|    value_loss           | 0.00376    |
----------------------------------------
box reached target
box reached target
Eval num_timesteps=5520000, episode_reward=0.22 +/- 2.44
Episode length: 271.00 +/- 58.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 271       |
|    mean_reward          | 0.218     |
| time/                   |           |
|    total_timesteps      | 5520000   |
| train/                  |           |
|    approx_kl            | 0.3681309 |
|    clip_fraction        | 0.453     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.775     |
|    explained_variance   | 0.612     |
|    learning_rate        | 0.000924  |
|    loss                 | -0.0522   |
|    n_updates            | 26950     |
|    policy_gradient_loss | 0.00623   |
|    std                  | 0.166     |
|    value_loss           | 0.00309   |
---------------------------------------
--------------------------------
| time/              |         |
|    fps             | 630     |
|    iterations      | 2696    |
|    time_elapsed    | 8753    |
|    total_timesteps | 5521408 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2697       |
|    time_elapsed         | 8756       |
|    total_timesteps      | 5523456    |
| train/                  |            |
|    approx_kl            | 0.22480452 |
|    clip_fraction        | 0.519      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.777      |
|    explained_variance   | 0.844      |
|    learning_rate        | 0.000923   |
|    loss                 | -0.029     |
|    n_updates            | 26960      |
|    policy_gradient_loss | 0.022      |
|    std                  | 0.167      |
|    value_loss           | 0.0201     |
----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 630       |
|    iterations           | 2698      |
|    time_elapsed         | 8759      |
|    total_timesteps      | 5525504   |
| train/                  |           |
|    approx_kl            | 0.4779474 |
|    clip_fraction        | 0.477     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.729     |
|    explained_variance   | 0.791     |
|    learning_rate        | 0.000923  |
|    loss                 | 0.0943    |
|    n_updates            | 26970     |
|    policy_gradient_loss | 0.0171    |
|    std                  | 0.171     |
|    value_loss           | 0.0202    |
---------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 630       |
|    iterations           | 2699      |
|    time_elapsed         | 8762      |
|    total_timesteps      | 5527552   |
| train/                  |           |
|    approx_kl            | 0.3063653 |
|    clip_fraction        | 0.48      |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.668     |
|    explained_variance   | 0.392     |
|    learning_rate        | 0.000923  |
|    loss                 | 0.0268    |
|    n_updates            | 26980     |
|    policy_gradient_loss | 0.0565    |
|    std                  | 0.178     |
|    value_loss           | 0.00546   |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2700       |
|    time_elapsed         | 8765       |
|    total_timesteps      | 5529600    |
| train/                  |            |
|    approx_kl            | 0.36902905 |
|    clip_fraction        | 0.432      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.585      |
|    explained_variance   | 0.803      |
|    learning_rate        | 0.000922   |
|    loss                 | -0.0181    |
|    n_updates            | 26990      |
|    policy_gradient_loss | 0.00593    |
|    std                  | 0.183      |
|    value_loss           | 0.017      |
----------------------------------------
box reached target
Eval num_timesteps=5530000, episode_reward=0.21 +/- 2.42
Episode length: 274.00 +/- 52.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 274        |
|    mean_reward          | 0.21       |
| time/                   |            |
|    total_timesteps      | 5530000    |
| train/                  |            |
|    approx_kl            | 0.81143796 |
|    clip_fraction        | 0.43       |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.553      |
|    explained_variance   | 0.672      |
|    learning_rate        | 0.000922   |
|    loss                 | -0.0282    |
|    n_updates            | 27000      |
|    policy_gradient_loss | -0.00218   |
|    std                  | 0.185      |
|    value_loss           | 0.00337    |
----------------------------------------
box reached target
--------------------------------
| time/              |         |
|    fps             | 630     |
|    iterations      | 2701    |
|    time_elapsed    | 8769    |
|    total_timesteps | 5531648 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2702       |
|    time_elapsed         | 8772       |
|    total_timesteps      | 5533696    |
| train/                  |            |
|    approx_kl            | 0.19289027 |
|    clip_fraction        | 0.406      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.558      |
|    explained_variance   | 0.806      |
|    learning_rate        | 0.000921   |
|    loss                 | 0.0358     |
|    n_updates            | 27010      |
|    policy_gradient_loss | 0.00672    |
|    std                  | 0.186      |
|    value_loss           | 0.0294     |
----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 630       |
|    iterations           | 2703      |
|    time_elapsed         | 8775      |
|    total_timesteps      | 5535744   |
| train/                  |           |
|    approx_kl            | 0.3233499 |
|    clip_fraction        | 0.448     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.542     |
|    explained_variance   | 0.471     |
|    learning_rate        | 0.000921  |
|    loss                 | 0.0134    |
|    n_updates            | 27020     |
|    policy_gradient_loss | 0.0113    |
|    std                  | 0.186     |
|    value_loss           | 0.0124    |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2704       |
|    time_elapsed         | 8778       |
|    total_timesteps      | 5537792    |
| train/                  |            |
|    approx_kl            | 0.47650912 |
|    clip_fraction        | 0.47       |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.519      |
|    explained_variance   | 0.473      |
|    learning_rate        | 0.000921   |
|    loss                 | 0.0561     |
|    n_updates            | 27030      |
|    policy_gradient_loss | 0.0178     |
|    std                  | 0.188      |
|    value_loss           | 0.00265    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2705       |
|    time_elapsed         | 8781       |
|    total_timesteps      | 5539840    |
| train/                  |            |
|    approx_kl            | 0.30291563 |
|    clip_fraction        | 0.424      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.521      |
|    explained_variance   | 0.786      |
|    learning_rate        | 0.00092    |
|    loss                 | 0.0232     |
|    n_updates            | 27040      |
|    policy_gradient_loss | 0.00826    |
|    std                  | 0.188      |
|    value_loss           | 0.00258    |
----------------------------------------
box reached target
Eval num_timesteps=5540000, episode_reward=0.26 +/- 2.51
Episode length: 278.80 +/- 42.40
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 279        |
|    mean_reward          | 0.256      |
| time/                   |            |
|    total_timesteps      | 5540000    |
| train/                  |            |
|    approx_kl            | 0.32748097 |
|    clip_fraction        | 0.401      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.516      |
|    explained_variance   | 0.663      |
|    learning_rate        | 0.00092    |
|    loss                 | 0.0127     |
|    n_updates            | 27050      |
|    policy_gradient_loss | -0.00248   |
|    std                  | 0.186      |
|    value_loss           | 0.0025     |
----------------------------------------
box reached target
--------------------------------
| time/              |         |
|    fps             | 630     |
|    iterations      | 2706    |
|    time_elapsed    | 8785    |
|    total_timesteps | 5541888 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2707       |
|    time_elapsed         | 8788       |
|    total_timesteps      | 5543936    |
| train/                  |            |
|    approx_kl            | 0.30058664 |
|    clip_fraction        | 0.443      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.541      |
|    explained_variance   | 0.887      |
|    learning_rate        | 0.000919   |
|    loss                 | -0.0045    |
|    n_updates            | 27060      |
|    policy_gradient_loss | 0.0127     |
|    std                  | 0.186      |
|    value_loss           | 0.0102     |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2708       |
|    time_elapsed         | 8791       |
|    total_timesteps      | 5545984    |
| train/                  |            |
|    approx_kl            | 0.16799189 |
|    clip_fraction        | 0.429      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.547      |
|    explained_variance   | 0.33       |
|    learning_rate        | 0.000919   |
|    loss                 | -0.0247    |
|    n_updates            | 27070      |
|    policy_gradient_loss | 0.00757    |
|    std                  | 0.184      |
|    value_loss           | 0.00494    |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2709       |
|    time_elapsed         | 8794       |
|    total_timesteps      | 5548032    |
| train/                  |            |
|    approx_kl            | 0.37126258 |
|    clip_fraction        | 0.413      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.55       |
|    explained_variance   | 0.6        |
|    learning_rate        | 0.000919   |
|    loss                 | -0.0219    |
|    n_updates            | 27080      |
|    policy_gradient_loss | 0.000207   |
|    std                  | 0.185      |
|    value_loss           | 0.00449    |
----------------------------------------
Eval num_timesteps=5550000, episode_reward=-0.95 +/- 0.10
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -0.95      |
| time/                   |            |
|    total_timesteps      | 5550000    |
| train/                  |            |
|    approx_kl            | 0.33469957 |
|    clip_fraction        | 0.446      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.539      |
|    explained_variance   | 0.285      |
|    learning_rate        | 0.000918   |
|    loss                 | 0.02       |
|    n_updates            | 27090      |
|    policy_gradient_loss | 0.027      |
|    std                  | 0.186      |
|    value_loss           | 0.0433     |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 630     |
|    iterations      | 2710    |
|    time_elapsed    | 8798    |
|    total_timesteps | 5550080 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2711       |
|    time_elapsed         | 8801       |
|    total_timesteps      | 5552128    |
| train/                  |            |
|    approx_kl            | 0.83845997 |
|    clip_fraction        | 0.434      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.564      |
|    explained_variance   | 0.556      |
|    learning_rate        | 0.000918   |
|    loss                 | -0.012     |
|    n_updates            | 27100      |
|    policy_gradient_loss | 0.153      |
|    std                  | 0.181      |
|    value_loss           | 0.00618    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2712       |
|    time_elapsed         | 8804       |
|    total_timesteps      | 5554176    |
| train/                  |            |
|    approx_kl            | 0.22840515 |
|    clip_fraction        | 0.444      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.568      |
|    explained_variance   | 0.645      |
|    learning_rate        | 0.000917   |
|    loss                 | 0.0524     |
|    n_updates            | 27110      |
|    policy_gradient_loss | 0.00791    |
|    std                  | 0.184      |
|    value_loss           | 0.0127     |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2713       |
|    time_elapsed         | 8807       |
|    total_timesteps      | 5556224    |
| train/                  |            |
|    approx_kl            | 0.32094115 |
|    clip_fraction        | 0.474      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.56       |
|    explained_variance   | 0.35       |
|    learning_rate        | 0.000917   |
|    loss                 | -0.0217    |
|    n_updates            | 27120      |
|    policy_gradient_loss | 0.00898    |
|    std                  | 0.183      |
|    value_loss           | 0.00304    |
----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 630       |
|    iterations           | 2714      |
|    time_elapsed         | 8810      |
|    total_timesteps      | 5558272   |
| train/                  |           |
|    approx_kl            | 0.8567165 |
|    clip_fraction        | 0.434     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.546     |
|    explained_variance   | 0.299     |
|    learning_rate        | 0.000917  |
|    loss                 | 0.0967    |
|    n_updates            | 27130     |
|    policy_gradient_loss | -0.00111  |
|    std                  | 0.186     |
|    value_loss           | 0.00233   |
---------------------------------------
box reached target
Eval num_timesteps=5560000, episode_reward=-0.95 +/- 0.10
Episode length: 300.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 300       |
|    mean_reward          | -0.952    |
| time/                   |           |
|    total_timesteps      | 5560000   |
| train/                  |           |
|    approx_kl            | 0.2926269 |
|    clip_fraction        | 0.447     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.517     |
|    explained_variance   | -0.219    |
|    learning_rate        | 0.000916  |
|    loss                 | 0.0634    |
|    n_updates            | 27140     |
|    policy_gradient_loss | 0.0102    |
|    std                  | 0.187     |
|    value_loss           | 0.00424   |
---------------------------------------
--------------------------------
| time/              |         |
|    fps             | 630     |
|    iterations      | 2715    |
|    time_elapsed    | 8814    |
|    total_timesteps | 5560320 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2716       |
|    time_elapsed         | 8817       |
|    total_timesteps      | 5562368    |
| train/                  |            |
|    approx_kl            | 0.20671995 |
|    clip_fraction        | 0.494      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.518      |
|    explained_variance   | 0.508      |
|    learning_rate        | 0.000916   |
|    loss                 | 0.0608     |
|    n_updates            | 27150      |
|    policy_gradient_loss | 0.036      |
|    std                  | 0.187      |
|    value_loss           | 0.0148     |
----------------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 630         |
|    iterations           | 2717        |
|    time_elapsed         | 8820        |
|    total_timesteps      | 5564416     |
| train/                  |             |
|    approx_kl            | 0.108176455 |
|    clip_fraction        | 0.385       |
|    clip_range           | 0.2         |
|    entropy_loss         | 0.509       |
|    explained_variance   | 0.103       |
|    learning_rate        | 0.000915    |
|    loss                 | -0.034      |
|    n_updates            | 27160       |
|    policy_gradient_loss | 0.0173      |
|    std                  | 0.188       |
|    value_loss           | 0.00134     |
-----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2718       |
|    time_elapsed         | 8823       |
|    total_timesteps      | 5566464    |
| train/                  |            |
|    approx_kl            | 0.38290733 |
|    clip_fraction        | 0.469      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.521      |
|    explained_variance   | -0.00586   |
|    learning_rate        | 0.000915   |
|    loss                 | -0.0582    |
|    n_updates            | 27170      |
|    policy_gradient_loss | 0.0104     |
|    std                  | 0.187      |
|    value_loss           | 0.0686     |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2719       |
|    time_elapsed         | 8826       |
|    total_timesteps      | 5568512    |
| train/                  |            |
|    approx_kl            | 0.30425447 |
|    clip_fraction        | 0.487      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.504      |
|    explained_variance   | 0.658      |
|    learning_rate        | 0.000915   |
|    loss                 | -0.0263    |
|    n_updates            | 27180      |
|    policy_gradient_loss | 0.0197     |
|    std                  | 0.187      |
|    value_loss           | 0.00639    |
----------------------------------------
Eval num_timesteps=5570000, episode_reward=-0.38 +/- 0.77
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -0.377     |
| time/                   |            |
|    total_timesteps      | 5570000    |
| train/                  |            |
|    approx_kl            | 0.47452924 |
|    clip_fraction        | 0.487      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.537      |
|    explained_variance   | 0.24       |
|    learning_rate        | 0.000914   |
|    loss                 | 0.0268     |
|    n_updates            | 27190      |
|    policy_gradient_loss | 0.0124     |
|    std                  | 0.183      |
|    value_loss           | 0.0684     |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 630     |
|    iterations      | 2720    |
|    time_elapsed    | 8830    |
|    total_timesteps | 5570560 |
--------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2721       |
|    time_elapsed         | 8833       |
|    total_timesteps      | 5572608    |
| train/                  |            |
|    approx_kl            | 0.14021587 |
|    clip_fraction        | 0.355      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.506      |
|    explained_variance   | 0.487      |
|    learning_rate        | 0.000914   |
|    loss                 | -0.00081   |
|    n_updates            | 27200      |
|    policy_gradient_loss | 0.00598    |
|    std                  | 0.189      |
|    value_loss           | 0.00213    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2722       |
|    time_elapsed         | 8837       |
|    total_timesteps      | 5574656    |
| train/                  |            |
|    approx_kl            | 0.34189475 |
|    clip_fraction        | 0.451      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.493      |
|    explained_variance   | 0.789      |
|    learning_rate        | 0.000913   |
|    loss                 | 0.0185     |
|    n_updates            | 27210      |
|    policy_gradient_loss | 0.000552   |
|    std                  | 0.188      |
|    value_loss           | 0.027      |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2723       |
|    time_elapsed         | 8840       |
|    total_timesteps      | 5576704    |
| train/                  |            |
|    approx_kl            | 0.18922268 |
|    clip_fraction        | 0.408      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.482      |
|    explained_variance   | 0.757      |
|    learning_rate        | 0.000913   |
|    loss                 | 0.026      |
|    n_updates            | 27220      |
|    policy_gradient_loss | 0.00576    |
|    std                  | 0.191      |
|    value_loss           | 0.00736    |
----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 630       |
|    iterations           | 2724      |
|    time_elapsed         | 8843      |
|    total_timesteps      | 5578752   |
| train/                  |           |
|    approx_kl            | 0.9565818 |
|    clip_fraction        | 0.457     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.474     |
|    explained_variance   | 0.144     |
|    learning_rate        | 0.000913  |
|    loss                 | 0.0341    |
|    n_updates            | 27230     |
|    policy_gradient_loss | 0.0122    |
|    std                  | 0.188     |
|    value_loss           | 0.00319   |
---------------------------------------
Eval num_timesteps=5580000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
--------------------------------------
| eval/                   |          |
|    mean_ep_length       | 300      |
|    mean_reward          | -1       |
| time/                   |          |
|    total_timesteps      | 5580000  |
| train/                  |          |
|    approx_kl            | 1.098382 |
|    clip_fraction        | 0.423    |
|    clip_range           | 0.2      |
|    entropy_loss         | 0.494    |
|    explained_variance   | 0.306    |
|    learning_rate        | 0.000912 |
|    loss                 | -0.0353  |
|    n_updates            | 27240    |
|    policy_gradient_loss | -0.00668 |
|    std                  | 0.188    |
|    value_loss           | 0.0053   |
--------------------------------------
--------------------------------
| time/              |         |
|    fps             | 630     |
|    iterations      | 2725    |
|    time_elapsed    | 8847    |
|    total_timesteps | 5580800 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2726       |
|    time_elapsed         | 8850       |
|    total_timesteps      | 5582848    |
| train/                  |            |
|    approx_kl            | 0.15136996 |
|    clip_fraction        | 0.414      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.515      |
|    explained_variance   | 0.301      |
|    learning_rate        | 0.000912   |
|    loss                 | -0.00482   |
|    n_updates            | 27250      |
|    policy_gradient_loss | 0.012      |
|    std                  | 0.185      |
|    value_loss           | 0.00259    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2727       |
|    time_elapsed         | 8853       |
|    total_timesteps      | 5584896    |
| train/                  |            |
|    approx_kl            | 0.40551442 |
|    clip_fraction        | 0.468      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.533      |
|    explained_variance   | 0.467      |
|    learning_rate        | 0.000911   |
|    loss                 | -0.0113    |
|    n_updates            | 27260      |
|    policy_gradient_loss | 0.0286     |
|    std                  | 0.183      |
|    value_loss           | 0.00571    |
----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 630       |
|    iterations           | 2728      |
|    time_elapsed         | 8856      |
|    total_timesteps      | 5586944   |
| train/                  |           |
|    approx_kl            | 1.0885624 |
|    clip_fraction        | 0.483     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.543     |
|    explained_variance   | 0.604     |
|    learning_rate        | 0.000911  |
|    loss                 | -0.0442   |
|    n_updates            | 27270     |
|    policy_gradient_loss | 0.0044    |
|    std                  | 0.183     |
|    value_loss           | 0.00474   |
---------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 630       |
|    iterations           | 2729      |
|    time_elapsed         | 8859      |
|    total_timesteps      | 5588992   |
| train/                  |           |
|    approx_kl            | 0.4101897 |
|    clip_fraction        | 0.478     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.574     |
|    explained_variance   | 0.491     |
|    learning_rate        | 0.000911  |
|    loss                 | -0.0121   |
|    n_updates            | 27280     |
|    policy_gradient_loss | 0.018     |
|    std                  | 0.18      |
|    value_loss           | 0.00181   |
---------------------------------------
Eval num_timesteps=5590000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 300       |
|    mean_reward          | -1        |
| time/                   |           |
|    total_timesteps      | 5590000   |
| train/                  |           |
|    approx_kl            | 2.2487946 |
|    clip_fraction        | 0.481     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.579     |
|    explained_variance   | 0.766     |
|    learning_rate        | 0.00091   |
|    loss                 | -0.0313   |
|    n_updates            | 27290     |
|    policy_gradient_loss | 0.0277    |
|    std                  | 0.177     |
|    value_loss           | 0.00381   |
---------------------------------------
--------------------------------
| time/              |         |
|    fps             | 630     |
|    iterations      | 2730    |
|    time_elapsed    | 8863    |
|    total_timesteps | 5591040 |
--------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 630       |
|    iterations           | 2731      |
|    time_elapsed         | 8866      |
|    total_timesteps      | 5593088   |
| train/                  |           |
|    approx_kl            | 0.6123538 |
|    clip_fraction        | 0.463     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.595     |
|    explained_variance   | -0.367    |
|    learning_rate        | 0.00091   |
|    loss                 | -0.0108   |
|    n_updates            | 27300     |
|    policy_gradient_loss | -0.0025   |
|    std                  | 0.179     |
|    value_loss           | 0.00547   |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2732       |
|    time_elapsed         | 8869       |
|    total_timesteps      | 5595136    |
| train/                  |            |
|    approx_kl            | 0.27418137 |
|    clip_fraction        | 0.461      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.599      |
|    explained_variance   | -0.0481    |
|    learning_rate        | 0.000909   |
|    loss                 | -0.0251    |
|    n_updates            | 27310      |
|    policy_gradient_loss | -0.000405  |
|    std                  | 0.178      |
|    value_loss           | 0.00938    |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2733       |
|    time_elapsed         | 8872       |
|    total_timesteps      | 5597184    |
| train/                  |            |
|    approx_kl            | 0.14989921 |
|    clip_fraction        | 0.443      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.596      |
|    explained_variance   | -0.116     |
|    learning_rate        | 0.000909   |
|    loss                 | 0.0336     |
|    n_updates            | 27320      |
|    policy_gradient_loss | 0.0151     |
|    std                  | 0.18       |
|    value_loss           | 0.00305    |
----------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 630       |
|    iterations           | 2734      |
|    time_elapsed         | 8875      |
|    total_timesteps      | 5599232   |
| train/                  |           |
|    approx_kl            | 0.5180471 |
|    clip_fraction        | 0.493     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.586     |
|    explained_variance   | 0.693     |
|    learning_rate        | 0.000909  |
|    loss                 | 0.00112   |
|    n_updates            | 27330     |
|    policy_gradient_loss | 0.0547    |
|    std                  | 0.182     |
|    value_loss           | 0.0279    |
---------------------------------------
Eval num_timesteps=5600000, episode_reward=-0.80 +/- 0.58
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -0.803     |
| time/                   |            |
|    total_timesteps      | 5600000    |
| train/                  |            |
|    approx_kl            | 0.23580447 |
|    clip_fraction        | 0.461      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.554      |
|    explained_variance   | 0.509      |
|    learning_rate        | 0.000908   |
|    loss                 | 0.0619     |
|    n_updates            | 27340      |
|    policy_gradient_loss | 0.0143     |
|    std                  | 0.184      |
|    value_loss           | 0.0506     |
----------------------------------------
box reached target
box reached target
--------------------------------
| time/              |         |
|    fps             | 630     |
|    iterations      | 2735    |
|    time_elapsed    | 8879    |
|    total_timesteps | 5601280 |
--------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2736       |
|    time_elapsed         | 8882       |
|    total_timesteps      | 5603328    |
| train/                  |            |
|    approx_kl            | 0.29763007 |
|    clip_fraction        | 0.485      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.56       |
|    explained_variance   | 0.33       |
|    learning_rate        | 0.000908   |
|    loss                 | 0.063      |
|    n_updates            | 27350      |
|    policy_gradient_loss | 0.0146     |
|    std                  | 0.182      |
|    value_loss           | 0.0453     |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2737       |
|    time_elapsed         | 8885       |
|    total_timesteps      | 5605376    |
| train/                  |            |
|    approx_kl            | 0.19322118 |
|    clip_fraction        | 0.449      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.56       |
|    explained_variance   | 0.798      |
|    learning_rate        | 0.000907   |
|    loss                 | 0.0494     |
|    n_updates            | 27360      |
|    policy_gradient_loss | 0.026      |
|    std                  | 0.182      |
|    value_loss           | 0.0461     |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2738       |
|    time_elapsed         | 8888       |
|    total_timesteps      | 5607424    |
| train/                  |            |
|    approx_kl            | 0.50809646 |
|    clip_fraction        | 0.475      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.598      |
|    explained_variance   | 0.798      |
|    learning_rate        | 0.000907   |
|    loss                 | -0.0474    |
|    n_updates            | 27370      |
|    policy_gradient_loss | -0.00275   |
|    std                  | 0.177      |
|    value_loss           | 0.0176     |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2739       |
|    time_elapsed         | 8891       |
|    total_timesteps      | 5609472    |
| train/                  |            |
|    approx_kl            | 0.20232865 |
|    clip_fraction        | 0.429      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.635      |
|    explained_variance   | 0.917      |
|    learning_rate        | 0.000907   |
|    loss                 | 0.0274     |
|    n_updates            | 27380      |
|    policy_gradient_loss | 0.00363    |
|    std                  | 0.176      |
|    value_loss           | 0.00576    |
----------------------------------------
box reached target
Eval num_timesteps=5610000, episode_reward=0.28 +/- 2.57
Episode length: 286.80 +/- 26.40
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 287       |
|    mean_reward          | 0.284     |
| time/                   |           |
|    total_timesteps      | 5610000   |
| train/                  |           |
|    approx_kl            | 0.4326097 |
|    clip_fraction        | 0.445     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.601     |
|    explained_variance   | 0.732     |
|    learning_rate        | 0.000906  |
|    loss                 | -0.00145  |
|    n_updates            | 27390     |
|    policy_gradient_loss | 0.0289    |
|    std                  | 0.179     |
|    value_loss           | 0.011     |
---------------------------------------
box reached target
--------------------------------
| time/              |         |
|    fps             | 630     |
|    iterations      | 2740    |
|    time_elapsed    | 8895    |
|    total_timesteps | 5611520 |
--------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2741       |
|    time_elapsed         | 8898       |
|    total_timesteps      | 5613568    |
| train/                  |            |
|    approx_kl            | 0.44644523 |
|    clip_fraction        | 0.478      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.61       |
|    explained_variance   | 0.748      |
|    learning_rate        | 0.000906   |
|    loss                 | -0.0352    |
|    n_updates            | 27400      |
|    policy_gradient_loss | -0.00286   |
|    std                  | 0.177      |
|    value_loss           | 0.0325     |
----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 630       |
|    iterations           | 2742      |
|    time_elapsed         | 8901      |
|    total_timesteps      | 5615616   |
| train/                  |           |
|    approx_kl            | 0.2938195 |
|    clip_fraction        | 0.431     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.611     |
|    explained_variance   | 0.8       |
|    learning_rate        | 0.000905  |
|    loss                 | 0.0368    |
|    n_updates            | 27410     |
|    policy_gradient_loss | 0.0101    |
|    std                  | 0.178     |
|    value_loss           | 0.0212    |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2743       |
|    time_elapsed         | 8904       |
|    total_timesteps      | 5617664    |
| train/                  |            |
|    approx_kl            | 0.42609316 |
|    clip_fraction        | 0.467      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.543      |
|    explained_variance   | 0.708      |
|    learning_rate        | 0.000905   |
|    loss                 | -0.0116    |
|    n_updates            | 27420      |
|    policy_gradient_loss | 0.00456    |
|    std                  | 0.186      |
|    value_loss           | 0.0094     |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2744       |
|    time_elapsed         | 8907       |
|    total_timesteps      | 5619712    |
| train/                  |            |
|    approx_kl            | 0.92469203 |
|    clip_fraction        | 0.504      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.552      |
|    explained_variance   | 0.813      |
|    learning_rate        | 0.000905   |
|    loss                 | -0.0202    |
|    n_updates            | 27430      |
|    policy_gradient_loss | -0.0085    |
|    std                  | 0.181      |
|    value_loss           | 0.0111     |
----------------------------------------
box reached target
Eval num_timesteps=5620000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1         |
| time/                   |            |
|    total_timesteps      | 5620000    |
| train/                  |            |
|    approx_kl            | 0.43931645 |
|    clip_fraction        | 0.417      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.599      |
|    explained_variance   | 0.778      |
|    learning_rate        | 0.000904   |
|    loss                 | 0.0188     |
|    n_updates            | 27440      |
|    policy_gradient_loss | -0.00188   |
|    std                  | 0.178      |
|    value_loss           | 0.0238     |
----------------------------------------
box reached target
--------------------------------
| time/              |         |
|    fps             | 630     |
|    iterations      | 2745    |
|    time_elapsed    | 8911    |
|    total_timesteps | 5621760 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2746       |
|    time_elapsed         | 8914       |
|    total_timesteps      | 5623808    |
| train/                  |            |
|    approx_kl            | 0.51562726 |
|    clip_fraction        | 0.475      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.647      |
|    explained_variance   | 0.833      |
|    learning_rate        | 0.000904   |
|    loss                 | -0.0465    |
|    n_updates            | 27450      |
|    policy_gradient_loss | 0.0137     |
|    std                  | 0.173      |
|    value_loss           | 0.0207     |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2747       |
|    time_elapsed         | 8917       |
|    total_timesteps      | 5625856    |
| train/                  |            |
|    approx_kl            | 0.76600516 |
|    clip_fraction        | 0.477      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.673      |
|    explained_variance   | 0.181      |
|    learning_rate        | 0.000903   |
|    loss                 | -0.000454  |
|    n_updates            | 27460      |
|    policy_gradient_loss | -0.003     |
|    std                  | 0.171      |
|    value_loss           | 0.0125     |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2748       |
|    time_elapsed         | 8920       |
|    total_timesteps      | 5627904    |
| train/                  |            |
|    approx_kl            | 0.44013128 |
|    clip_fraction        | 0.501      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.702      |
|    explained_variance   | 0.0191     |
|    learning_rate        | 0.000903   |
|    loss                 | -0.0248    |
|    n_updates            | 27470      |
|    policy_gradient_loss | 0.0285     |
|    std                  | 0.168      |
|    value_loss           | 0.00233    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2749       |
|    time_elapsed         | 8923       |
|    total_timesteps      | 5629952    |
| train/                  |            |
|    approx_kl            | 0.24466626 |
|    clip_fraction        | 0.453      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.713      |
|    explained_variance   | 0.754      |
|    learning_rate        | 0.000903   |
|    loss                 | -0.0187    |
|    n_updates            | 27480      |
|    policy_gradient_loss | 0.0171     |
|    std                  | 0.17       |
|    value_loss           | 0.0092     |
----------------------------------------
Eval num_timesteps=5630000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 300       |
|    mean_reward          | -1        |
| time/                   |           |
|    total_timesteps      | 5630000   |
| train/                  |           |
|    approx_kl            | 0.5561843 |
|    clip_fraction        | 0.486     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.745     |
|    explained_variance   | 0.827     |
|    learning_rate        | 0.000902  |
|    loss                 | -0.015    |
|    n_updates            | 27490     |
|    policy_gradient_loss | -0.00836  |
|    std                  | 0.164     |
|    value_loss           | 0.00973   |
---------------------------------------
box reached target
--------------------------------
| time/              |         |
|    fps             | 630     |
|    iterations      | 2750    |
|    time_elapsed    | 8927    |
|    total_timesteps | 5632000 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2751       |
|    time_elapsed         | 8930       |
|    total_timesteps      | 5634048    |
| train/                  |            |
|    approx_kl            | 0.62476736 |
|    clip_fraction        | 0.549      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.735      |
|    explained_variance   | 0.86       |
|    learning_rate        | 0.000902   |
|    loss                 | -0.00244   |
|    n_updates            | 27500      |
|    policy_gradient_loss | 0.0232     |
|    std                  | 0.168      |
|    value_loss           | 0.0183     |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2752       |
|    time_elapsed         | 8933       |
|    total_timesteps      | 5636096    |
| train/                  |            |
|    approx_kl            | 0.66349316 |
|    clip_fraction        | 0.478      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.733      |
|    explained_variance   | 0.0231     |
|    learning_rate        | 0.000901   |
|    loss                 | -0.0151    |
|    n_updates            | 27510      |
|    policy_gradient_loss | -0.00528   |
|    std                  | 0.165      |
|    value_loss           | 0.00325    |
----------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 630       |
|    iterations           | 2753      |
|    time_elapsed         | 8937      |
|    total_timesteps      | 5638144   |
| train/                  |           |
|    approx_kl            | 2.0188057 |
|    clip_fraction        | 0.508     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.76      |
|    explained_variance   | 0.787     |
|    learning_rate        | 0.000901  |
|    loss                 | -0.0338   |
|    n_updates            | 27520     |
|    policy_gradient_loss | -0.0261   |
|    std                  | 0.165     |
|    value_loss           | 0.00881   |
---------------------------------------
Eval num_timesteps=5640000, episode_reward=-0.13 +/- 0.71
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -0.127     |
| time/                   |            |
|    total_timesteps      | 5640000    |
| train/                  |            |
|    approx_kl            | 0.75912786 |
|    clip_fraction        | 0.531      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.793      |
|    explained_variance   | 0.627      |
|    learning_rate        | 0.000901   |
|    loss                 | 0.0258     |
|    n_updates            | 27530      |
|    policy_gradient_loss | 1.2e-06    |
|    std                  | 0.16       |
|    value_loss           | 0.0151     |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 630     |
|    iterations      | 2754    |
|    time_elapsed    | 8941    |
|    total_timesteps | 5640192 |
--------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2755       |
|    time_elapsed         | 8944       |
|    total_timesteps      | 5642240    |
| train/                  |            |
|    approx_kl            | 0.51544476 |
|    clip_fraction        | 0.488      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.864      |
|    explained_variance   | 0.325      |
|    learning_rate        | 0.0009     |
|    loss                 | 0.00564    |
|    n_updates            | 27540      |
|    policy_gradient_loss | 0.00377    |
|    std                  | 0.155      |
|    value_loss           | 0.0078     |
----------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 630       |
|    iterations           | 2756      |
|    time_elapsed         | 8947      |
|    total_timesteps      | 5644288   |
| train/                  |           |
|    approx_kl            | 1.9494395 |
|    clip_fraction        | 0.544     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.883     |
|    explained_variance   | 0.872     |
|    learning_rate        | 0.0009    |
|    loss                 | -0.00292  |
|    n_updates            | 27550     |
|    policy_gradient_loss | 0.0342    |
|    std                  | 0.155     |
|    value_loss           | 0.0154    |
---------------------------------------
box reached target
box reached target
box reached target
--------------------------------------
| time/                   |          |
|    fps                  | 630      |
|    iterations           | 2757     |
|    time_elapsed         | 8950     |
|    total_timesteps      | 5646336  |
| train/                  |          |
|    approx_kl            | 0.876524 |
|    clip_fraction        | 0.512    |
|    clip_range           | 0.2      |
|    entropy_loss         | 0.911    |
|    explained_variance   | 0.412    |
|    learning_rate        | 0.000899 |
|    loss                 | 0.128    |
|    n_updates            | 27560    |
|    policy_gradient_loss | 0.0326   |
|    std                  | 0.153    |
|    value_loss           | 0.0152   |
--------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2758       |
|    time_elapsed         | 8953       |
|    total_timesteps      | 5648384    |
| train/                  |            |
|    approx_kl            | 0.71978104 |
|    clip_fraction        | 0.551      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.927      |
|    explained_variance   | 0.531      |
|    learning_rate        | 0.000899   |
|    loss                 | 0.00911    |
|    n_updates            | 27570      |
|    policy_gradient_loss | 0.0196     |
|    std                  | 0.152      |
|    value_loss           | 0.0916     |
----------------------------------------
Eval num_timesteps=5650000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 300       |
|    mean_reward          | -1        |
| time/                   |           |
|    total_timesteps      | 5650000   |
| train/                  |           |
|    approx_kl            | 0.7795023 |
|    clip_fraction        | 0.485     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.92      |
|    explained_variance   | 0.918     |
|    learning_rate        | 0.000899  |
|    loss                 | -0.0112   |
|    n_updates            | 27580     |
|    policy_gradient_loss | 0.0212    |
|    std                  | 0.153     |
|    value_loss           | 0.00865   |
---------------------------------------
--------------------------------
| time/              |         |
|    fps             | 630     |
|    iterations      | 2759    |
|    time_elapsed    | 8957    |
|    total_timesteps | 5650432 |
--------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2760       |
|    time_elapsed         | 8960       |
|    total_timesteps      | 5652480    |
| train/                  |            |
|    approx_kl            | 0.48927957 |
|    clip_fraction        | 0.467      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.916      |
|    explained_variance   | 0.768      |
|    learning_rate        | 0.000898   |
|    loss                 | 0.00845    |
|    n_updates            | 27590      |
|    policy_gradient_loss | -0.00694   |
|    std                  | 0.151      |
|    value_loss           | 0.00759    |
----------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 630       |
|    iterations           | 2761      |
|    time_elapsed         | 8963      |
|    total_timesteps      | 5654528   |
| train/                  |           |
|    approx_kl            | 0.4427054 |
|    clip_fraction        | 0.464     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.912     |
|    explained_variance   | 0.724     |
|    learning_rate        | 0.000898  |
|    loss                 | -0.00283  |
|    n_updates            | 27600     |
|    policy_gradient_loss | 0.00571   |
|    std                  | 0.153     |
|    value_loss           | 0.0477    |
---------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 630         |
|    iterations           | 2762        |
|    time_elapsed         | 8966        |
|    total_timesteps      | 5656576     |
| train/                  |             |
|    approx_kl            | 0.100947246 |
|    clip_fraction        | 0.438       |
|    clip_range           | 0.2         |
|    entropy_loss         | 0.854       |
|    explained_variance   | 0.742       |
|    learning_rate        | 0.000897    |
|    loss                 | 0.0789      |
|    n_updates            | 27610       |
|    policy_gradient_loss | 0.00484     |
|    std                  | 0.162       |
|    value_loss           | 0.0258      |
-----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2763       |
|    time_elapsed         | 8969       |
|    total_timesteps      | 5658624    |
| train/                  |            |
|    approx_kl            | 0.25944912 |
|    clip_fraction        | 0.444      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.81       |
|    explained_variance   | 0.723      |
|    learning_rate        | 0.000897   |
|    loss                 | 0.00915    |
|    n_updates            | 27620      |
|    policy_gradient_loss | 0.0168     |
|    std                  | 0.161      |
|    value_loss           | 0.0116     |
----------------------------------------
Eval num_timesteps=5660000, episode_reward=-0.51 +/- 0.60
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -0.514     |
| time/                   |            |
|    total_timesteps      | 5660000    |
| train/                  |            |
|    approx_kl            | 0.22721702 |
|    clip_fraction        | 0.448      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.768      |
|    explained_variance   | 0.841      |
|    learning_rate        | 0.000897   |
|    loss                 | -0.00593   |
|    n_updates            | 27630      |
|    policy_gradient_loss | 0.0093     |
|    std                  | 0.167      |
|    value_loss           | 0.00584    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 630     |
|    iterations      | 2764    |
|    time_elapsed    | 8973    |
|    total_timesteps | 5660672 |
--------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 630       |
|    iterations           | 2765      |
|    time_elapsed         | 8976      |
|    total_timesteps      | 5662720   |
| train/                  |           |
|    approx_kl            | 0.8050238 |
|    clip_fraction        | 0.421     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.782     |
|    explained_variance   | 0.789     |
|    learning_rate        | 0.000896  |
|    loss                 | -0.0423   |
|    n_updates            | 27640     |
|    policy_gradient_loss | -0.014    |
|    std                  | 0.16      |
|    value_loss           | 0.0388    |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2766       |
|    time_elapsed         | 8979       |
|    total_timesteps      | 5664768    |
| train/                  |            |
|    approx_kl            | 0.43422472 |
|    clip_fraction        | 0.481      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.834      |
|    explained_variance   | 0.418      |
|    learning_rate        | 0.000896   |
|    loss                 | 0.0312     |
|    n_updates            | 27650      |
|    policy_gradient_loss | 0.0049     |
|    std                  | 0.158      |
|    value_loss           | 0.00965    |
----------------------------------------
box reached target
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 630       |
|    iterations           | 2767      |
|    time_elapsed         | 8982      |
|    total_timesteps      | 5666816   |
| train/                  |           |
|    approx_kl            | 0.2660348 |
|    clip_fraction        | 0.505     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.864     |
|    explained_variance   | 0.374     |
|    learning_rate        | 0.000895  |
|    loss                 | -0.00475  |
|    n_updates            | 27660     |
|    policy_gradient_loss | 0.0169    |
|    std                  | 0.156     |
|    value_loss           | 0.00335   |
---------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2768       |
|    time_elapsed         | 8985       |
|    total_timesteps      | 5668864    |
| train/                  |            |
|    approx_kl            | 0.24563044 |
|    clip_fraction        | 0.435      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.865      |
|    explained_variance   | 0.871      |
|    learning_rate        | 0.000895   |
|    loss                 | 0.00859    |
|    n_updates            | 27670      |
|    policy_gradient_loss | 0.00837    |
|    std                  | 0.157      |
|    value_loss           | 0.0195     |
----------------------------------------
box reached target
box reached target
Eval num_timesteps=5670000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1         |
| time/                   |            |
|    total_timesteps      | 5670000    |
| train/                  |            |
|    approx_kl            | 0.27363318 |
|    clip_fraction        | 0.434      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.836      |
|    explained_variance   | 0.746      |
|    learning_rate        | 0.000895   |
|    loss                 | -0.0503    |
|    n_updates            | 27680      |
|    policy_gradient_loss | 0.0143     |
|    std                  | 0.16       |
|    value_loss           | 0.0188     |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 630     |
|    iterations      | 2769    |
|    time_elapsed    | 8989    |
|    total_timesteps | 5670912 |
--------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 630       |
|    iterations           | 2770      |
|    time_elapsed         | 8992      |
|    total_timesteps      | 5672960   |
| train/                  |           |
|    approx_kl            | 0.2813984 |
|    clip_fraction        | 0.469     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.817     |
|    explained_variance   | 0.701     |
|    learning_rate        | 0.000894  |
|    loss                 | 0.0119    |
|    n_updates            | 27690     |
|    policy_gradient_loss | 0.0089    |
|    std                  | 0.162     |
|    value_loss           | 0.0211    |
---------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2771       |
|    time_elapsed         | 8995       |
|    total_timesteps      | 5675008    |
| train/                  |            |
|    approx_kl            | 0.39231074 |
|    clip_fraction        | 0.417      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.809      |
|    explained_variance   | 0.068      |
|    learning_rate        | 0.000894   |
|    loss                 | -0.0511    |
|    n_updates            | 27700      |
|    policy_gradient_loss | -0.00327   |
|    std                  | 0.16       |
|    value_loss           | 0.00289    |
----------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 630       |
|    iterations           | 2772      |
|    time_elapsed         | 8998      |
|    total_timesteps      | 5677056   |
| train/                  |           |
|    approx_kl            | 0.7766277 |
|    clip_fraction        | 0.525     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.823     |
|    explained_variance   | 0.0604    |
|    learning_rate        | 0.000893  |
|    loss                 | 0.0527    |
|    n_updates            | 27710     |
|    policy_gradient_loss | 0.0194    |
|    std                  | 0.16      |
|    value_loss           | 0.0838    |
---------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 630       |
|    iterations           | 2773      |
|    time_elapsed         | 9001      |
|    total_timesteps      | 5679104   |
| train/                  |           |
|    approx_kl            | 0.5352593 |
|    clip_fraction        | 0.472     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.841     |
|    explained_variance   | 0.426     |
|    learning_rate        | 0.000893  |
|    loss                 | 0.0348    |
|    n_updates            | 27720     |
|    policy_gradient_loss | 0.0175    |
|    std                  | 0.16      |
|    value_loss           | 0.0384    |
---------------------------------------
box reached target
Eval num_timesteps=5680000, episode_reward=0.29 +/- 2.58
Episode length: 282.80 +/- 34.40
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 283       |
|    mean_reward          | 0.291     |
| time/                   |           |
|    total_timesteps      | 5680000   |
| train/                  |           |
|    approx_kl            | 0.1502718 |
|    clip_fraction        | 0.407     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.85      |
|    explained_variance   | 0.711     |
|    learning_rate        | 0.000893  |
|    loss                 | 0.00452   |
|    n_updates            | 27730     |
|    policy_gradient_loss | -0.000381 |
|    std                  | 0.157     |
|    value_loss           | 0.0218    |
---------------------------------------
box reached target
--------------------------------
| time/              |         |
|    fps             | 630     |
|    iterations      | 2774    |
|    time_elapsed    | 9005    |
|    total_timesteps | 5681152 |
--------------------------------
--------------------------------------
| time/                   |          |
|    fps                  | 630      |
|    iterations           | 2775     |
|    time_elapsed         | 9008     |
|    total_timesteps      | 5683200  |
| train/                  |          |
|    approx_kl            | 0.768176 |
|    clip_fraction        | 0.555    |
|    clip_range           | 0.2      |
|    entropy_loss         | 0.854    |
|    explained_variance   | 0.545    |
|    learning_rate        | 0.000892 |
|    loss                 | 0.055    |
|    n_updates            | 27740    |
|    policy_gradient_loss | 0.0206   |
|    std                  | 0.157    |
|    value_loss           | 0.0892   |
--------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2776       |
|    time_elapsed         | 9011       |
|    total_timesteps      | 5685248    |
| train/                  |            |
|    approx_kl            | 0.54627275 |
|    clip_fraction        | 0.435      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.858      |
|    explained_variance   | 0.694      |
|    learning_rate        | 0.000892   |
|    loss                 | -0.0263    |
|    n_updates            | 27750      |
|    policy_gradient_loss | -0.00302   |
|    std                  | 0.158      |
|    value_loss           | 0.00659    |
----------------------------------------
box reached target
--------------------------------------
| time/                   |          |
|    fps                  | 630      |
|    iterations           | 2777     |
|    time_elapsed         | 9014     |
|    total_timesteps      | 5687296  |
| train/                  |          |
|    approx_kl            | 0.344331 |
|    clip_fraction        | 0.451    |
|    clip_range           | 0.2      |
|    entropy_loss         | 0.861    |
|    explained_variance   | 0.761    |
|    learning_rate        | 0.000891 |
|    loss                 | 0.00945  |
|    n_updates            | 27760    |
|    policy_gradient_loss | 0.00526  |
|    std                  | 0.156    |
|    value_loss           | 0.00749  |
--------------------------------------
box reached target
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 630       |
|    iterations           | 2778      |
|    time_elapsed         | 9017      |
|    total_timesteps      | 5689344   |
| train/                  |           |
|    approx_kl            | 1.0928053 |
|    clip_fraction        | 0.55      |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.878     |
|    explained_variance   | 0.841     |
|    learning_rate        | 0.000891  |
|    loss                 | 0.0208    |
|    n_updates            | 27770     |
|    policy_gradient_loss | 0.0134    |
|    std                  | 0.155     |
|    value_loss           | 0.0189    |
---------------------------------------
box reached target
Eval num_timesteps=5690000, episode_reward=0.27 +/- 2.53
Episode length: 284.80 +/- 30.40
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 285        |
|    mean_reward          | 0.265      |
| time/                   |            |
|    total_timesteps      | 5690000    |
| train/                  |            |
|    approx_kl            | 0.51108164 |
|    clip_fraction        | 0.522      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.907      |
|    explained_variance   | 0.68       |
|    learning_rate        | 0.000891   |
|    loss                 | 0.0087     |
|    n_updates            | 27780      |
|    policy_gradient_loss | 0.0258     |
|    std                  | 0.153      |
|    value_loss           | 0.053      |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 630     |
|    iterations      | 2779    |
|    time_elapsed    | 9021    |
|    total_timesteps | 5691392 |
--------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 630       |
|    iterations           | 2780      |
|    time_elapsed         | 9024      |
|    total_timesteps      | 5693440   |
| train/                  |           |
|    approx_kl            | 0.5976826 |
|    clip_fraction        | 0.526     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.885     |
|    explained_variance   | 0.605     |
|    learning_rate        | 0.00089   |
|    loss                 | -0.0099   |
|    n_updates            | 27790     |
|    policy_gradient_loss | 0.0252    |
|    std                  | 0.156     |
|    value_loss           | 0.0115    |
---------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 630       |
|    iterations           | 2781      |
|    time_elapsed         | 9027      |
|    total_timesteps      | 5695488   |
| train/                  |           |
|    approx_kl            | 0.7202945 |
|    clip_fraction        | 0.507     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.895     |
|    explained_variance   | 0.85      |
|    learning_rate        | 0.00089   |
|    loss                 | 0.0132    |
|    n_updates            | 27800     |
|    policy_gradient_loss | 0.00212   |
|    std                  | 0.152     |
|    value_loss           | 0.0148    |
---------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 630       |
|    iterations           | 2782      |
|    time_elapsed         | 9030      |
|    total_timesteps      | 5697536   |
| train/                  |           |
|    approx_kl            | 0.3512244 |
|    clip_fraction        | 0.517     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.951     |
|    explained_variance   | 0.798     |
|    learning_rate        | 0.000889  |
|    loss                 | 0.19      |
|    n_updates            | 27810     |
|    policy_gradient_loss | 0.021     |
|    std                  | 0.15      |
|    value_loss           | 0.00946   |
---------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 630       |
|    iterations           | 2783      |
|    time_elapsed         | 9033      |
|    total_timesteps      | 5699584   |
| train/                  |           |
|    approx_kl            | 0.4940796 |
|    clip_fraction        | 0.492     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.946     |
|    explained_variance   | 0.912     |
|    learning_rate        | 0.000889  |
|    loss                 | 0.0303    |
|    n_updates            | 27820     |
|    policy_gradient_loss | 0.0139    |
|    std                  | 0.151     |
|    value_loss           | 0.0097    |
---------------------------------------
Eval num_timesteps=5700000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 300       |
|    mean_reward          | -1        |
| time/                   |           |
|    total_timesteps      | 5700000   |
| train/                  |           |
|    approx_kl            | 0.5904023 |
|    clip_fraction        | 0.494     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.949     |
|    explained_variance   | 0.665     |
|    learning_rate        | 0.000889  |
|    loss                 | 0.0137    |
|    n_updates            | 27830     |
|    policy_gradient_loss | 0.0282    |
|    std                  | 0.151     |
|    value_loss           | 0.0205    |
---------------------------------------
--------------------------------
| time/              |         |
|    fps             | 630     |
|    iterations      | 2784    |
|    time_elapsed    | 9037    |
|    total_timesteps | 5701632 |
--------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2785       |
|    time_elapsed         | 9040       |
|    total_timesteps      | 5703680    |
| train/                  |            |
|    approx_kl            | 0.17945549 |
|    clip_fraction        | 0.443      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.943      |
|    explained_variance   | 0.84       |
|    learning_rate        | 0.000888   |
|    loss                 | 0.0322     |
|    n_updates            | 27840      |
|    policy_gradient_loss | 0.023      |
|    std                  | 0.153      |
|    value_loss           | 0.00631    |
----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 630       |
|    iterations           | 2786      |
|    time_elapsed         | 9043      |
|    total_timesteps      | 5705728   |
| train/                  |           |
|    approx_kl            | 0.8489549 |
|    clip_fraction        | 0.541     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.934     |
|    explained_variance   | 0.697     |
|    learning_rate        | 0.000888  |
|    loss                 | 0.0153    |
|    n_updates            | 27850     |
|    policy_gradient_loss | 0.0113    |
|    std                  | 0.152     |
|    value_loss           | 0.0106    |
---------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2787       |
|    time_elapsed         | 9047       |
|    total_timesteps      | 5707776    |
| train/                  |            |
|    approx_kl            | 0.21892516 |
|    clip_fraction        | 0.433      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.966      |
|    explained_variance   | 0.701      |
|    learning_rate        | 0.000887   |
|    loss                 | -0.0333    |
|    n_updates            | 27860      |
|    policy_gradient_loss | 0.024      |
|    std                  | 0.15       |
|    value_loss           | 0.00394    |
----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 630       |
|    iterations           | 2788      |
|    time_elapsed         | 9050      |
|    total_timesteps      | 5709824   |
| train/                  |           |
|    approx_kl            | 0.4194246 |
|    clip_fraction        | 0.482     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.974     |
|    explained_variance   | 0.787     |
|    learning_rate        | 0.000887  |
|    loss                 | 0.0453    |
|    n_updates            | 27870     |
|    policy_gradient_loss | 0.0116    |
|    std                  | 0.149     |
|    value_loss           | 0.0122    |
---------------------------------------
box reached target
Eval num_timesteps=5710000, episode_reward=-0.81 +/- 0.57
Episode length: 300.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 300       |
|    mean_reward          | -0.811    |
| time/                   |           |
|    total_timesteps      | 5710000   |
| train/                  |           |
|    approx_kl            | 0.6128543 |
|    clip_fraction        | 0.508     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.984     |
|    explained_variance   | 0.922     |
|    learning_rate        | 0.000887  |
|    loss                 | 0.00231   |
|    n_updates            | 27880     |
|    policy_gradient_loss | 0.0181    |
|    std                  | 0.148     |
|    value_loss           | 0.0104    |
---------------------------------------
box reached target
--------------------------------
| time/              |         |
|    fps             | 630     |
|    iterations      | 2789    |
|    time_elapsed    | 9054    |
|    total_timesteps | 5711872 |
--------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 630       |
|    iterations           | 2790      |
|    time_elapsed         | 9057      |
|    total_timesteps      | 5713920   |
| train/                  |           |
|    approx_kl            | 0.5702485 |
|    clip_fraction        | 0.458     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.997     |
|    explained_variance   | 0.434     |
|    learning_rate        | 0.000886  |
|    loss                 | -0.00308  |
|    n_updates            | 27890     |
|    policy_gradient_loss | 0.00684   |
|    std                  | 0.148     |
|    value_loss           | 0.0505    |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2791       |
|    time_elapsed         | 9060       |
|    total_timesteps      | 5715968    |
| train/                  |            |
|    approx_kl            | 0.68891746 |
|    clip_fraction        | 0.484      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.02       |
|    explained_variance   | 0.256      |
|    learning_rate        | 0.000886   |
|    loss                 | -0.0211    |
|    n_updates            | 27900      |
|    policy_gradient_loss | 0.0215     |
|    std                  | 0.144      |
|    value_loss           | 0.00806    |
----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 630       |
|    iterations           | 2792      |
|    time_elapsed         | 9063      |
|    total_timesteps      | 5718016   |
| train/                  |           |
|    approx_kl            | 1.9845054 |
|    clip_fraction        | 0.496     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.04      |
|    explained_variance   | 0.0864    |
|    learning_rate        | 0.000885  |
|    loss                 | 0.0664    |
|    n_updates            | 27910     |
|    policy_gradient_loss | 0.0403    |
|    std                  | 0.144     |
|    value_loss           | 0.00792   |
---------------------------------------
Eval num_timesteps=5720000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1         |
| time/                   |            |
|    total_timesteps      | 5720000    |
| train/                  |            |
|    approx_kl            | 0.48410034 |
|    clip_fraction        | 0.493      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.04       |
|    explained_variance   | 0.389      |
|    learning_rate        | 0.000885   |
|    loss                 | 0.00886    |
|    n_updates            | 27920      |
|    policy_gradient_loss | 0.0155     |
|    std                  | 0.142      |
|    value_loss           | 0.00776    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 630     |
|    iterations      | 2793    |
|    time_elapsed    | 9067    |
|    total_timesteps | 5720064 |
--------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 630       |
|    iterations           | 2794      |
|    time_elapsed         | 9070      |
|    total_timesteps      | 5722112   |
| train/                  |           |
|    approx_kl            | 0.3458746 |
|    clip_fraction        | 0.515     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.05      |
|    explained_variance   | 0.407     |
|    learning_rate        | 0.000885  |
|    loss                 | 0.0709    |
|    n_updates            | 27930     |
|    policy_gradient_loss | 0.0428    |
|    std                  | 0.144     |
|    value_loss           | 0.00936   |
---------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 630       |
|    iterations           | 2795      |
|    time_elapsed         | 9073      |
|    total_timesteps      | 5724160   |
| train/                  |           |
|    approx_kl            | 1.3686467 |
|    clip_fraction        | 0.562     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.04      |
|    explained_variance   | -0.273    |
|    learning_rate        | 0.000884  |
|    loss                 | 0.0526    |
|    n_updates            | 27940     |
|    policy_gradient_loss | 0.0217    |
|    std                  | 0.143     |
|    value_loss           | 0.0377    |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2796       |
|    time_elapsed         | 9076       |
|    total_timesteps      | 5726208    |
| train/                  |            |
|    approx_kl            | 0.49283153 |
|    clip_fraction        | 0.458      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.01       |
|    explained_variance   | -0.0163    |
|    learning_rate        | 0.000884   |
|    loss                 | -0.0391    |
|    n_updates            | 27950      |
|    policy_gradient_loss | 0.00865    |
|    std                  | 0.147      |
|    value_loss           | 0.00237    |
----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 630       |
|    iterations           | 2797      |
|    time_elapsed         | 9079      |
|    total_timesteps      | 5728256   |
| train/                  |           |
|    approx_kl            | 0.2908879 |
|    clip_fraction        | 0.461     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.976     |
|    explained_variance   | 0.752     |
|    learning_rate        | 0.000883  |
|    loss                 | 0.0388    |
|    n_updates            | 27960     |
|    policy_gradient_loss | 0.00974   |
|    std                  | 0.15      |
|    value_loss           | 0.00922   |
---------------------------------------
box reached target
Eval num_timesteps=5730000, episode_reward=0.23 +/- 2.46
Episode length: 269.40 +/- 61.20
--------------------------------------
| eval/                   |          |
|    mean_ep_length       | 269      |
|    mean_reward          | 0.232    |
| time/                   |          |
|    total_timesteps      | 5730000  |
| train/                  |          |
|    approx_kl            | 0.536505 |
|    clip_fraction        | 0.482    |
|    clip_range           | 0.2      |
|    entropy_loss         | 0.957    |
|    explained_variance   | 0.782    |
|    learning_rate        | 0.000883 |
|    loss                 | -0.0182  |
|    n_updates            | 27970    |
|    policy_gradient_loss | 0.0178   |
|    std                  | 0.149    |
|    value_loss           | 0.011    |
--------------------------------------
box reached target
--------------------------------
| time/              |         |
|    fps             | 630     |
|    iterations      | 2798    |
|    time_elapsed    | 9083    |
|    total_timesteps | 5730304 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2799       |
|    time_elapsed         | 9086       |
|    total_timesteps      | 5732352    |
| train/                  |            |
|    approx_kl            | 0.34822556 |
|    clip_fraction        | 0.453      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.928      |
|    explained_variance   | 0.123      |
|    learning_rate        | 0.000883   |
|    loss                 | 0.0233     |
|    n_updates            | 27980      |
|    policy_gradient_loss | 0.0257     |
|    std                  | 0.155      |
|    value_loss           | 0.0227     |
----------------------------------------
box reached target
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2800       |
|    time_elapsed         | 9089       |
|    total_timesteps      | 5734400    |
| train/                  |            |
|    approx_kl            | 0.20375149 |
|    clip_fraction        | 0.399      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.902      |
|    explained_variance   | -1.24      |
|    learning_rate        | 0.000882   |
|    loss                 | -0.0333    |
|    n_updates            | 27990      |
|    policy_gradient_loss | 0.0095     |
|    std                  | 0.152      |
|    value_loss           | 0.00312    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2801       |
|    time_elapsed         | 9092       |
|    total_timesteps      | 5736448    |
| train/                  |            |
|    approx_kl            | 0.35177565 |
|    clip_fraction        | 0.504      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.91       |
|    explained_variance   | 0.819      |
|    learning_rate        | 0.000882   |
|    loss                 | 0.0312     |
|    n_updates            | 28000      |
|    policy_gradient_loss | 0.0235     |
|    std                  | 0.155      |
|    value_loss           | 0.0978     |
----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 630         |
|    iterations           | 2802        |
|    time_elapsed         | 9095        |
|    total_timesteps      | 5738496     |
| train/                  |             |
|    approx_kl            | 0.095011026 |
|    clip_fraction        | 0.398       |
|    clip_range           | 0.2         |
|    entropy_loss         | 0.867       |
|    explained_variance   | 0.631       |
|    learning_rate        | 0.000881    |
|    loss                 | 0.0368      |
|    n_updates            | 28010       |
|    policy_gradient_loss | 0.00372     |
|    std                  | 0.159       |
|    value_loss           | 0.0416      |
-----------------------------------------
box reached target
Eval num_timesteps=5740000, episode_reward=0.25 +/- 2.50
Episode length: 267.40 +/- 65.20
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 267       |
|    mean_reward          | 0.252     |
| time/                   |           |
|    total_timesteps      | 5740000   |
| train/                  |           |
|    approx_kl            | 0.6626332 |
|    clip_fraction        | 0.448     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.829     |
|    explained_variance   | 0.686     |
|    learning_rate        | 0.000881  |
|    loss                 | 0.00252   |
|    n_updates            | 28020     |
|    policy_gradient_loss | -0.00127  |
|    std                  | 0.16      |
|    value_loss           | 0.00828   |
---------------------------------------
--------------------------------
| time/              |         |
|    fps             | 630     |
|    iterations      | 2803    |
|    time_elapsed    | 9099    |
|    total_timesteps | 5740544 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2804       |
|    time_elapsed         | 9102       |
|    total_timesteps      | 5742592    |
| train/                  |            |
|    approx_kl            | 0.16450292 |
|    clip_fraction        | 0.418      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.81       |
|    explained_variance   | 0.625      |
|    learning_rate        | 0.000881   |
|    loss                 | 0.0343     |
|    n_updates            | 28030      |
|    policy_gradient_loss | 0.00824    |
|    std                  | 0.163      |
|    value_loss           | 0.00646    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2805       |
|    time_elapsed         | 9105       |
|    total_timesteps      | 5744640    |
| train/                  |            |
|    approx_kl            | 0.28814057 |
|    clip_fraction        | 0.462      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.812      |
|    explained_variance   | 0.43       |
|    learning_rate        | 0.00088    |
|    loss                 | -0.00522   |
|    n_updates            | 28040      |
|    policy_gradient_loss | 0.027      |
|    std                  | 0.16       |
|    value_loss           | 0.00426    |
----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 630       |
|    iterations           | 2806      |
|    time_elapsed         | 9108      |
|    total_timesteps      | 5746688   |
| train/                  |           |
|    approx_kl            | 0.7024817 |
|    clip_fraction        | 0.512     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.82      |
|    explained_variance   | 0.561     |
|    learning_rate        | 0.00088   |
|    loss                 | -0.0429   |
|    n_updates            | 28050     |
|    policy_gradient_loss | 0.0142    |
|    std                  | 0.161     |
|    value_loss           | 0.00813   |
---------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 630       |
|    iterations           | 2807      |
|    time_elapsed         | 9111      |
|    total_timesteps      | 5748736   |
| train/                  |           |
|    approx_kl            | 0.4333469 |
|    clip_fraction        | 0.426     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.795     |
|    explained_variance   | 0.473     |
|    learning_rate        | 0.000879  |
|    loss                 | -0.0506   |
|    n_updates            | 28060     |
|    policy_gradient_loss | 0.00867   |
|    std                  | 0.162     |
|    value_loss           | 0.00499   |
---------------------------------------
box reached target
box reached target
Eval num_timesteps=5750000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1         |
| time/                   |            |
|    total_timesteps      | 5750000    |
| train/                  |            |
|    approx_kl            | 0.36074919 |
|    clip_fraction        | 0.454      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.777      |
|    explained_variance   | 0.645      |
|    learning_rate        | 0.000879   |
|    loss                 | -0.0121    |
|    n_updates            | 28070      |
|    policy_gradient_loss | 0.022      |
|    std                  | 0.166      |
|    value_loss           | 0.00991    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 630     |
|    iterations      | 2808    |
|    time_elapsed    | 9115    |
|    total_timesteps | 5750784 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2809       |
|    time_elapsed         | 9118       |
|    total_timesteps      | 5752832    |
| train/                  |            |
|    approx_kl            | 0.31844488 |
|    clip_fraction        | 0.451      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.763      |
|    explained_variance   | 0.661      |
|    learning_rate        | 0.000879   |
|    loss                 | 0.0301     |
|    n_updates            | 28080      |
|    policy_gradient_loss | 0.0209     |
|    std                  | 0.166      |
|    value_loss           | 0.0298     |
----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 630         |
|    iterations           | 2810        |
|    time_elapsed         | 9121        |
|    total_timesteps      | 5754880     |
| train/                  |             |
|    approx_kl            | 0.065100394 |
|    clip_fraction        | 0.358       |
|    clip_range           | 0.2         |
|    entropy_loss         | 0.717       |
|    explained_variance   | 0.52        |
|    learning_rate        | 0.000878    |
|    loss                 | 0.00489     |
|    n_updates            | 28090       |
|    policy_gradient_loss | 0.0114      |
|    std                  | 0.171       |
|    value_loss           | 0.0106      |
-----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2811       |
|    time_elapsed         | 9124       |
|    total_timesteps      | 5756928    |
| train/                  |            |
|    approx_kl            | 0.22238183 |
|    clip_fraction        | 0.403      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.698      |
|    explained_variance   | 0.501      |
|    learning_rate        | 0.000878   |
|    loss                 | 0.0257     |
|    n_updates            | 28100      |
|    policy_gradient_loss | 0.00787    |
|    std                  | 0.17       |
|    value_loss           | 0.00412    |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2812       |
|    time_elapsed         | 9127       |
|    total_timesteps      | 5758976    |
| train/                  |            |
|    approx_kl            | 0.24637413 |
|    clip_fraction        | 0.498      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.693      |
|    explained_variance   | 0.514      |
|    learning_rate        | 0.000877   |
|    loss                 | 0.0684     |
|    n_updates            | 28110      |
|    policy_gradient_loss | 0.0187     |
|    std                  | 0.171      |
|    value_loss           | 0.014      |
----------------------------------------
box reached target
box reached target
Eval num_timesteps=5760000, episode_reward=0.47 +/- 2.55
Episode length: 279.00 +/- 42.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 279       |
|    mean_reward          | 0.471     |
| time/                   |           |
|    total_timesteps      | 5760000   |
| train/                  |           |
|    approx_kl            | 0.2504323 |
|    clip_fraction        | 0.475     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.686     |
|    explained_variance   | 0.7       |
|    learning_rate        | 0.000877  |
|    loss                 | 0.0308    |
|    n_updates            | 28120     |
|    policy_gradient_loss | 0.0143    |
|    std                  | 0.171     |
|    value_loss           | 0.0514    |
---------------------------------------
--------------------------------
| time/              |         |
|    fps             | 630     |
|    iterations      | 2813    |
|    time_elapsed    | 9131    |
|    total_timesteps | 5761024 |
--------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 630       |
|    iterations           | 2814      |
|    time_elapsed         | 9134      |
|    total_timesteps      | 5763072   |
| train/                  |           |
|    approx_kl            | 0.3070292 |
|    clip_fraction        | 0.478     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.68      |
|    explained_variance   | 0.852     |
|    learning_rate        | 0.000877  |
|    loss                 | -0.0107   |
|    n_updates            | 28130     |
|    policy_gradient_loss | 0.0173    |
|    std                  | 0.172     |
|    value_loss           | 0.0314    |
---------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 630       |
|    iterations           | 2815      |
|    time_elapsed         | 9137      |
|    total_timesteps      | 5765120   |
| train/                  |           |
|    approx_kl            | 0.6911875 |
|    clip_fraction        | 0.492     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.692     |
|    explained_variance   | 0.895     |
|    learning_rate        | 0.000876  |
|    loss                 | 0.0155    |
|    n_updates            | 28140     |
|    policy_gradient_loss | 0.00998   |
|    std                  | 0.169     |
|    value_loss           | 0.0154    |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2816       |
|    time_elapsed         | 9140       |
|    total_timesteps      | 5767168    |
| train/                  |            |
|    approx_kl            | 0.41040277 |
|    clip_fraction        | 0.392      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.73       |
|    explained_variance   | 0.92       |
|    learning_rate        | 0.000876   |
|    loss                 | 0.0764     |
|    n_updates            | 28150      |
|    policy_gradient_loss | 0.00473    |
|    std                  | 0.167      |
|    value_loss           | 0.0348     |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2817       |
|    time_elapsed         | 9143       |
|    total_timesteps      | 5769216    |
| train/                  |            |
|    approx_kl            | 0.23844248 |
|    clip_fraction        | 0.414      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.713      |
|    explained_variance   | 0.758      |
|    learning_rate        | 0.000875   |
|    loss                 | 0.0156     |
|    n_updates            | 28160      |
|    policy_gradient_loss | 0.00894    |
|    std                  | 0.172      |
|    value_loss           | 0.021      |
----------------------------------------
box reached target
Eval num_timesteps=5770000, episode_reward=0.35 +/- 2.39
Episode length: 275.00 +/- 50.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 275        |
|    mean_reward          | 0.347      |
| time/                   |            |
|    total_timesteps      | 5770000    |
| train/                  |            |
|    approx_kl            | 0.28908798 |
|    clip_fraction        | 0.415      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.677      |
|    explained_variance   | 0.797      |
|    learning_rate        | 0.000875   |
|    loss                 | 0.0392     |
|    n_updates            | 28170      |
|    policy_gradient_loss | 0.0134     |
|    std                  | 0.173      |
|    value_loss           | 0.0267     |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 630     |
|    iterations      | 2818    |
|    time_elapsed    | 9147    |
|    total_timesteps | 5771264 |
--------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 630       |
|    iterations           | 2819      |
|    time_elapsed         | 9150      |
|    total_timesteps      | 5773312   |
| train/                  |           |
|    approx_kl            | 0.2738605 |
|    clip_fraction        | 0.381     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.706     |
|    explained_variance   | 0.84      |
|    learning_rate        | 0.000875  |
|    loss                 | -0.00291  |
|    n_updates            | 28180     |
|    policy_gradient_loss | 0.00296   |
|    std                  | 0.17      |
|    value_loss           | 0.0116    |
---------------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2820       |
|    time_elapsed         | 9153       |
|    total_timesteps      | 5775360    |
| train/                  |            |
|    approx_kl            | 0.14435649 |
|    clip_fraction        | 0.361      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.711      |
|    explained_variance   | 0.786      |
|    learning_rate        | 0.000874   |
|    loss                 | 0.0625     |
|    n_updates            | 28190      |
|    policy_gradient_loss | 0.00859    |
|    std                  | 0.171      |
|    value_loss           | 0.00521    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2821       |
|    time_elapsed         | 9156       |
|    total_timesteps      | 5777408    |
| train/                  |            |
|    approx_kl            | 0.17383382 |
|    clip_fraction        | 0.426      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.711      |
|    explained_variance   | 0.682      |
|    learning_rate        | 0.000874   |
|    loss                 | 0.0221     |
|    n_updates            | 28200      |
|    policy_gradient_loss | 0.0184     |
|    std                  | 0.169      |
|    value_loss           | 0.106      |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2822       |
|    time_elapsed         | 9159       |
|    total_timesteps      | 5779456    |
| train/                  |            |
|    approx_kl            | 0.35763764 |
|    clip_fraction        | 0.379      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.726      |
|    explained_variance   | 0.808      |
|    learning_rate        | 0.000873   |
|    loss                 | 0.0352     |
|    n_updates            | 28210      |
|    policy_gradient_loss | 0.00997    |
|    std                  | 0.168      |
|    value_loss           | 0.0043     |
----------------------------------------
box reached target
Eval num_timesteps=5780000, episode_reward=0.42 +/- 2.44
Episode length: 281.20 +/- 37.60
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 281        |
|    mean_reward          | 0.423      |
| time/                   |            |
|    total_timesteps      | 5780000    |
| train/                  |            |
|    approx_kl            | 0.49752975 |
|    clip_fraction        | 0.502      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.73       |
|    explained_variance   | 0.731      |
|    learning_rate        | 0.000873   |
|    loss                 | 0.0177     |
|    n_updates            | 28220      |
|    policy_gradient_loss | 0.0295     |
|    std                  | 0.167      |
|    value_loss           | 0.0086     |
----------------------------------------
box reached target
--------------------------------
| time/              |         |
|    fps             | 630     |
|    iterations      | 2823    |
|    time_elapsed    | 9163    |
|    total_timesteps | 5781504 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2824       |
|    time_elapsed         | 9166       |
|    total_timesteps      | 5783552    |
| train/                  |            |
|    approx_kl            | 0.34208173 |
|    clip_fraction        | 0.481      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.717      |
|    explained_variance   | 0.578      |
|    learning_rate        | 0.000873   |
|    loss                 | -0.0286    |
|    n_updates            | 28230      |
|    policy_gradient_loss | 0.0148     |
|    std                  | 0.17       |
|    value_loss           | 0.0238     |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2825       |
|    time_elapsed         | 9169       |
|    total_timesteps      | 5785600    |
| train/                  |            |
|    approx_kl            | 0.33280104 |
|    clip_fraction        | 0.486      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.686      |
|    explained_variance   | 0.597      |
|    learning_rate        | 0.000872   |
|    loss                 | 0.0489     |
|    n_updates            | 28240      |
|    policy_gradient_loss | 0.00338    |
|    std                  | 0.171      |
|    value_loss           | 0.0112     |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2826       |
|    time_elapsed         | 9172       |
|    total_timesteps      | 5787648    |
| train/                  |            |
|    approx_kl            | 0.27521992 |
|    clip_fraction        | 0.435      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.681      |
|    explained_variance   | 0.885      |
|    learning_rate        | 0.000872   |
|    loss                 | -0.0271    |
|    n_updates            | 28250      |
|    policy_gradient_loss | 4.48e-05   |
|    std                  | 0.174      |
|    value_loss           | 0.0235     |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2827       |
|    time_elapsed         | 9175       |
|    total_timesteps      | 5789696    |
| train/                  |            |
|    approx_kl            | 0.28829768 |
|    clip_fraction        | 0.395      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.657      |
|    explained_variance   | 0.675      |
|    learning_rate        | 0.000871   |
|    loss                 | -0.000437  |
|    n_updates            | 28260      |
|    policy_gradient_loss | -0.00886   |
|    std                  | 0.173      |
|    value_loss           | 0.00344    |
----------------------------------------
Eval num_timesteps=5790000, episode_reward=-0.89 +/- 0.22
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -0.889     |
| time/                   |            |
|    total_timesteps      | 5790000    |
| train/                  |            |
|    approx_kl            | 0.31621227 |
|    clip_fraction        | 0.428      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.659      |
|    explained_variance   | 0.669      |
|    learning_rate        | 0.000871   |
|    loss                 | -0.0224    |
|    n_updates            | 28270      |
|    policy_gradient_loss | -0.0025    |
|    std                  | 0.172      |
|    value_loss           | 0.0143     |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 630     |
|    iterations      | 2828    |
|    time_elapsed    | 9179    |
|    total_timesteps | 5791744 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2829       |
|    time_elapsed         | 9182       |
|    total_timesteps      | 5793792    |
| train/                  |            |
|    approx_kl            | 0.57545596 |
|    clip_fraction        | 0.379      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.693      |
|    explained_variance   | 0.514      |
|    learning_rate        | 0.000871   |
|    loss                 | 0.0209     |
|    n_updates            | 28280      |
|    policy_gradient_loss | -0.00305   |
|    std                  | 0.168      |
|    value_loss           | 0.00367    |
----------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 630       |
|    iterations           | 2830      |
|    time_elapsed         | 9185      |
|    total_timesteps      | 5795840   |
| train/                  |           |
|    approx_kl            | 0.3347575 |
|    clip_fraction        | 0.404     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.744     |
|    explained_variance   | 0.521     |
|    learning_rate        | 0.00087   |
|    loss                 | -0.024    |
|    n_updates            | 28290     |
|    policy_gradient_loss | -0.00276  |
|    std                  | 0.165     |
|    value_loss           | 0.00343   |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2831       |
|    time_elapsed         | 9189       |
|    total_timesteps      | 5797888    |
| train/                  |            |
|    approx_kl            | 0.29710054 |
|    clip_fraction        | 0.473      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.769      |
|    explained_variance   | 0.879      |
|    learning_rate        | 0.00087    |
|    loss                 | 0.0233     |
|    n_updates            | 28300      |
|    policy_gradient_loss | 0.0116     |
|    std                  | 0.163      |
|    value_loss           | 0.00576    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2832       |
|    time_elapsed         | 9192       |
|    total_timesteps      | 5799936    |
| train/                  |            |
|    approx_kl            | 0.35373488 |
|    clip_fraction        | 0.423      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.8        |
|    explained_variance   | 0.712      |
|    learning_rate        | 0.000869   |
|    loss                 | -0.0189    |
|    n_updates            | 28310      |
|    policy_gradient_loss | -0.00619   |
|    std                  | 0.159      |
|    value_loss           | 0.0162     |
----------------------------------------
Eval num_timesteps=5800000, episode_reward=-0.19 +/- 0.73
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -0.187     |
| time/                   |            |
|    total_timesteps      | 5800000    |
| train/                  |            |
|    approx_kl            | 0.19844742 |
|    clip_fraction        | 0.431      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.826      |
|    explained_variance   | 0.713      |
|    learning_rate        | 0.000869   |
|    loss                 | 0.0188     |
|    n_updates            | 28320      |
|    policy_gradient_loss | 0.0108     |
|    std                  | 0.159      |
|    value_loss           | 0.00398    |
----------------------------------------
box reached target
--------------------------------
| time/              |         |
|    fps             | 630     |
|    iterations      | 2833    |
|    time_elapsed    | 9196    |
|    total_timesteps | 5801984 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2834       |
|    time_elapsed         | 9199       |
|    total_timesteps      | 5804032    |
| train/                  |            |
|    approx_kl            | 0.16826874 |
|    clip_fraction        | 0.452      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.833      |
|    explained_variance   | 0.839      |
|    learning_rate        | 0.000869   |
|    loss                 | -0.0156    |
|    n_updates            | 28330      |
|    policy_gradient_loss | 0.00472    |
|    std                  | 0.158      |
|    value_loss           | 0.0232     |
----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 630       |
|    iterations           | 2835      |
|    time_elapsed         | 9202      |
|    total_timesteps      | 5806080   |
| train/                  |           |
|    approx_kl            | 0.8417356 |
|    clip_fraction        | 0.489     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.858     |
|    explained_variance   | 0.354     |
|    learning_rate        | 0.000868  |
|    loss                 | -0.0348   |
|    n_updates            | 28340     |
|    policy_gradient_loss | 0.00401   |
|    std                  | 0.154     |
|    value_loss           | 0.0303    |
---------------------------------------
box reached target
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 630       |
|    iterations           | 2836      |
|    time_elapsed         | 9205      |
|    total_timesteps      | 5808128   |
| train/                  |           |
|    approx_kl            | 0.5189931 |
|    clip_fraction        | 0.448     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.891     |
|    explained_variance   | 0.458     |
|    learning_rate        | 0.000868  |
|    loss                 | -0.0149   |
|    n_updates            | 28350     |
|    policy_gradient_loss | 0.00145   |
|    std                  | 0.155     |
|    value_loss           | 0.00383   |
---------------------------------------
box reached target
Eval num_timesteps=5810000, episode_reward=0.24 +/- 2.48
Episode length: 271.80 +/- 56.40
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 272       |
|    mean_reward          | 0.238     |
| time/                   |           |
|    total_timesteps      | 5810000   |
| train/                  |           |
|    approx_kl            | 0.7803962 |
|    clip_fraction        | 0.518     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.89      |
|    explained_variance   | 0.767     |
|    learning_rate        | 0.000867  |
|    loss                 | -0.0115   |
|    n_updates            | 28360     |
|    policy_gradient_loss | 0.0166    |
|    std                  | 0.154     |
|    value_loss           | 0.093     |
---------------------------------------
--------------------------------
| time/              |         |
|    fps             | 630     |
|    iterations      | 2837    |
|    time_elapsed    | 9209    |
|    total_timesteps | 5810176 |
--------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 630       |
|    iterations           | 2838      |
|    time_elapsed         | 9212      |
|    total_timesteps      | 5812224   |
| train/                  |           |
|    approx_kl            | 0.5278369 |
|    clip_fraction        | 0.497     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.914     |
|    explained_variance   | 0.833     |
|    learning_rate        | 0.000867  |
|    loss                 | -0.0229   |
|    n_updates            | 28370     |
|    policy_gradient_loss | -0.0168   |
|    std                  | 0.151     |
|    value_loss           | 0.00373   |
---------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 630       |
|    iterations           | 2839      |
|    time_elapsed         | 9215      |
|    total_timesteps      | 5814272   |
| train/                  |           |
|    approx_kl            | 1.1408808 |
|    clip_fraction        | 0.513     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.918     |
|    explained_variance   | 0.191     |
|    learning_rate        | 0.000867  |
|    loss                 | 0.0357    |
|    n_updates            | 28380     |
|    policy_gradient_loss | 0.0192    |
|    std                  | 0.154     |
|    value_loss           | 0.0198    |
---------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 630       |
|    iterations           | 2840      |
|    time_elapsed         | 9218      |
|    total_timesteps      | 5816320   |
| train/                  |           |
|    approx_kl            | 0.2521979 |
|    clip_fraction        | 0.459     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.892     |
|    explained_variance   | 0.348     |
|    learning_rate        | 0.000866  |
|    loss                 | 0.0264    |
|    n_updates            | 28390     |
|    policy_gradient_loss | 0.0248    |
|    std                  | 0.155     |
|    value_loss           | 0.0276    |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2841       |
|    time_elapsed         | 9221       |
|    total_timesteps      | 5818368    |
| train/                  |            |
|    approx_kl            | 0.56151235 |
|    clip_fraction        | 0.458      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.876      |
|    explained_variance   | -0.104     |
|    learning_rate        | 0.000866   |
|    loss                 | 0.0204     |
|    n_updates            | 28400      |
|    policy_gradient_loss | 0.00547    |
|    std                  | 0.156      |
|    value_loss           | 0.00479    |
----------------------------------------
box reached target
Eval num_timesteps=5820000, episode_reward=0.48 +/- 2.50
Episode length: 276.80 +/- 46.40
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 277       |
|    mean_reward          | 0.481     |
| time/                   |           |
|    total_timesteps      | 5820000   |
| train/                  |           |
|    approx_kl            | 0.3495665 |
|    clip_fraction        | 0.442     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.871     |
|    explained_variance   | 0.722     |
|    learning_rate        | 0.000865  |
|    loss                 | -0.0116   |
|    n_updates            | 28410     |
|    policy_gradient_loss | -0.00311  |
|    std                  | 0.156     |
|    value_loss           | 0.00971   |
---------------------------------------
box reached target
--------------------------------
| time/              |         |
|    fps             | 630     |
|    iterations      | 2842    |
|    time_elapsed    | 9225    |
|    total_timesteps | 5820416 |
--------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2843       |
|    time_elapsed         | 9228       |
|    total_timesteps      | 5822464    |
| train/                  |            |
|    approx_kl            | 0.25658342 |
|    clip_fraction        | 0.476      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.882      |
|    explained_variance   | 0.763      |
|    learning_rate        | 0.000865   |
|    loss                 | 0.0138     |
|    n_updates            | 28420      |
|    policy_gradient_loss | 0.0176     |
|    std                  | 0.155      |
|    value_loss           | 0.0252     |
----------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 630       |
|    iterations           | 2844      |
|    time_elapsed         | 9231      |
|    total_timesteps      | 5824512   |
| train/                  |           |
|    approx_kl            | 0.5062197 |
|    clip_fraction        | 0.472     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.879     |
|    explained_variance   | 0.655     |
|    learning_rate        | 0.000865  |
|    loss                 | -0.0573   |
|    n_updates            | 28430     |
|    policy_gradient_loss | 0.000113  |
|    std                  | 0.156     |
|    value_loss           | 0.0795    |
---------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 630       |
|    iterations           | 2845      |
|    time_elapsed         | 9234      |
|    total_timesteps      | 5826560   |
| train/                  |           |
|    approx_kl            | 0.4240889 |
|    clip_fraction        | 0.457     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.866     |
|    explained_variance   | 0.853     |
|    learning_rate        | 0.000864  |
|    loss                 | 0.0396    |
|    n_updates            | 28440     |
|    policy_gradient_loss | -0.00207  |
|    std                  | 0.155     |
|    value_loss           | 0.0262    |
---------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 630       |
|    iterations           | 2846      |
|    time_elapsed         | 9237      |
|    total_timesteps      | 5828608   |
| train/                  |           |
|    approx_kl            | 0.9111196 |
|    clip_fraction        | 0.453     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.917     |
|    explained_variance   | 0.892     |
|    learning_rate        | 0.000864  |
|    loss                 | -0.0178   |
|    n_updates            | 28450     |
|    policy_gradient_loss | 0.00154   |
|    std                  | 0.152     |
|    value_loss           | 0.00848   |
---------------------------------------
box reached target
Eval num_timesteps=5830000, episode_reward=-1.02 +/- 0.13
Episode length: 300.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 300       |
|    mean_reward          | -1.02     |
| time/                   |           |
|    total_timesteps      | 5830000   |
| train/                  |           |
|    approx_kl            | 0.2856614 |
|    clip_fraction        | 0.475     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.879     |
|    explained_variance   | 0.757     |
|    learning_rate        | 0.000863  |
|    loss                 | 0.0261    |
|    n_updates            | 28460     |
|    policy_gradient_loss | 0.0296    |
|    std                  | 0.158     |
|    value_loss           | 0.00493   |
---------------------------------------
--------------------------------
| time/              |         |
|    fps             | 630     |
|    iterations      | 2847    |
|    time_elapsed    | 9241    |
|    total_timesteps | 5830656 |
--------------------------------
box reached target
--------------------------------------
| time/                   |          |
|    fps                  | 630      |
|    iterations           | 2848     |
|    time_elapsed         | 9244     |
|    total_timesteps      | 5832704  |
| train/                  |          |
|    approx_kl            | 0.750172 |
|    clip_fraction        | 0.429    |
|    clip_range           | 0.2      |
|    entropy_loss         | 0.863    |
|    explained_variance   | 0.854    |
|    learning_rate        | 0.000863 |
|    loss                 | -0.0515  |
|    n_updates            | 28470    |
|    policy_gradient_loss | 0.00391  |
|    std                  | 0.156    |
|    value_loss           | 0.0242   |
--------------------------------------
box reached target
--------------------------------------
| time/                   |          |
|    fps                  | 630      |
|    iterations           | 2849     |
|    time_elapsed         | 9247     |
|    total_timesteps      | 5834752  |
| train/                  |          |
|    approx_kl            | 3.141014 |
|    clip_fraction        | 0.507    |
|    clip_range           | 0.2      |
|    entropy_loss         | 0.899    |
|    explained_variance   | 0.785    |
|    learning_rate        | 0.000863 |
|    loss                 | -0.0107  |
|    n_updates            | 28480    |
|    policy_gradient_loss | -0.00177 |
|    std                  | 0.153    |
|    value_loss           | 0.04     |
--------------------------------------
--------------------------------------
| time/                   |          |
|    fps                  | 630      |
|    iterations           | 2850     |
|    time_elapsed         | 9250     |
|    total_timesteps      | 5836800  |
| train/                  |          |
|    approx_kl            | 0.825935 |
|    clip_fraction        | 0.465    |
|    clip_range           | 0.2      |
|    entropy_loss         | 0.897    |
|    explained_variance   | 0.89     |
|    learning_rate        | 0.000862 |
|    loss                 | -0.0202  |
|    n_updates            | 28490    |
|    policy_gradient_loss | 0.0176   |
|    std                  | 0.154    |
|    value_loss           | 0.0124   |
--------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 630       |
|    iterations           | 2851      |
|    time_elapsed         | 9253      |
|    total_timesteps      | 5838848   |
| train/                  |           |
|    approx_kl            | 0.1993774 |
|    clip_fraction        | 0.451     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.9       |
|    explained_variance   | 0.332     |
|    learning_rate        | 0.000862  |
|    loss                 | 0.0391    |
|    n_updates            | 28500     |
|    policy_gradient_loss | 0.0166    |
|    std                  | 0.154     |
|    value_loss           | 0.0231    |
---------------------------------------
Eval num_timesteps=5840000, episode_reward=-0.72 +/- 0.57
Episode length: 300.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 300       |
|    mean_reward          | -0.716    |
| time/                   |           |
|    total_timesteps      | 5840000   |
| train/                  |           |
|    approx_kl            | 0.5246228 |
|    clip_fraction        | 0.528     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.906     |
|    explained_variance   | 0.759     |
|    learning_rate        | 0.000861  |
|    loss                 | -0.0298   |
|    n_updates            | 28510     |
|    policy_gradient_loss | 0.027     |
|    std                  | 0.154     |
|    value_loss           | 0.0123    |
---------------------------------------
box reached target
--------------------------------
| time/              |         |
|    fps             | 630     |
|    iterations      | 2852    |
|    time_elapsed    | 9257    |
|    total_timesteps | 5840896 |
--------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 630       |
|    iterations           | 2853      |
|    time_elapsed         | 9260      |
|    total_timesteps      | 5842944   |
| train/                  |           |
|    approx_kl            | 0.5505694 |
|    clip_fraction        | 0.533     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.914     |
|    explained_variance   | 0.732     |
|    learning_rate        | 0.000861  |
|    loss                 | 0.00249   |
|    n_updates            | 28520     |
|    policy_gradient_loss | 0.000886  |
|    std                  | 0.152     |
|    value_loss           | 0.0204    |
---------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 630       |
|    iterations           | 2854      |
|    time_elapsed         | 9263      |
|    total_timesteps      | 5844992   |
| train/                  |           |
|    approx_kl            | 0.1652407 |
|    clip_fraction        | 0.455     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.91      |
|    explained_variance   | 0.804     |
|    learning_rate        | 0.000861  |
|    loss                 | -0.0152   |
|    n_updates            | 28530     |
|    policy_gradient_loss | 0.0183    |
|    std                  | 0.154     |
|    value_loss           | 0.0186    |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2855       |
|    time_elapsed         | 9266       |
|    total_timesteps      | 5847040    |
| train/                  |            |
|    approx_kl            | 0.19041456 |
|    clip_fraction        | 0.428      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.878      |
|    explained_variance   | 0.73       |
|    learning_rate        | 0.00086    |
|    loss                 | 0.0147     |
|    n_updates            | 28540      |
|    policy_gradient_loss | 0.00649    |
|    std                  | 0.157      |
|    value_loss           | 0.00949    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2856       |
|    time_elapsed         | 9269       |
|    total_timesteps      | 5849088    |
| train/                  |            |
|    approx_kl            | 0.38746417 |
|    clip_fraction        | 0.469      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.885      |
|    explained_variance   | 0.591      |
|    learning_rate        | 0.00086    |
|    loss                 | -0.0188    |
|    n_updates            | 28550      |
|    policy_gradient_loss | -0.00475   |
|    std                  | 0.153      |
|    value_loss           | 0.00333    |
----------------------------------------
box reached target
Eval num_timesteps=5850000, episode_reward=0.24 +/- 2.48
Episode length: 272.60 +/- 54.80
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 273        |
|    mean_reward          | 0.24       |
| time/                   |            |
|    total_timesteps      | 5850000    |
| train/                  |            |
|    approx_kl            | 0.95695347 |
|    clip_fraction        | 0.443      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.922      |
|    explained_variance   | 0.5        |
|    learning_rate        | 0.000859   |
|    loss                 | 0.00324    |
|    n_updates            | 28560      |
|    policy_gradient_loss | 0.00807    |
|    std                  | 0.152      |
|    value_loss           | 0.00445    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 630     |
|    iterations      | 2857    |
|    time_elapsed    | 9273    |
|    total_timesteps | 5851136 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2858       |
|    time_elapsed         | 9276       |
|    total_timesteps      | 5853184    |
| train/                  |            |
|    approx_kl            | 0.26087776 |
|    clip_fraction        | 0.402      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.916      |
|    explained_variance   | 0.425      |
|    learning_rate        | 0.000859   |
|    loss                 | 0.0781     |
|    n_updates            | 28570      |
|    policy_gradient_loss | 0.00674    |
|    std                  | 0.152      |
|    value_loss           | 0.00203    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2859       |
|    time_elapsed         | 9279       |
|    total_timesteps      | 5855232    |
| train/                  |            |
|    approx_kl            | 0.30661047 |
|    clip_fraction        | 0.43       |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.942      |
|    explained_variance   | 0.123      |
|    learning_rate        | 0.000859   |
|    loss                 | -0.0268    |
|    n_updates            | 28580      |
|    policy_gradient_loss | -0.000242  |
|    std                  | 0.15       |
|    value_loss           | 0.00373    |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2860       |
|    time_elapsed         | 9282       |
|    total_timesteps      | 5857280    |
| train/                  |            |
|    approx_kl            | 0.22323501 |
|    clip_fraction        | 0.419      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.963      |
|    explained_variance   | 0.133      |
|    learning_rate        | 0.000858   |
|    loss                 | 0.0195     |
|    n_updates            | 28590      |
|    policy_gradient_loss | 0.0143     |
|    std                  | 0.148      |
|    value_loss           | 0.0035     |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2861       |
|    time_elapsed         | 9285       |
|    total_timesteps      | 5859328    |
| train/                  |            |
|    approx_kl            | 0.42595893 |
|    clip_fraction        | 0.499      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.972      |
|    explained_variance   | 0.706      |
|    learning_rate        | 0.000858   |
|    loss                 | 0.00419    |
|    n_updates            | 28600      |
|    policy_gradient_loss | 0.0104     |
|    std                  | 0.148      |
|    value_loss           | 0.07       |
----------------------------------------
box reached target
Eval num_timesteps=5860000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 300       |
|    mean_reward          | -1        |
| time/                   |           |
|    total_timesteps      | 5860000   |
| train/                  |           |
|    approx_kl            | 0.3452235 |
|    clip_fraction        | 0.469     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.971     |
|    explained_variance   | 0.619     |
|    learning_rate        | 0.000857  |
|    loss                 | 0.011     |
|    n_updates            | 28610     |
|    policy_gradient_loss | 0.032     |
|    std                  | 0.15      |
|    value_loss           | 0.015     |
---------------------------------------
--------------------------------
| time/              |         |
|    fps             | 630     |
|    iterations      | 2862    |
|    time_elapsed    | 9289    |
|    total_timesteps | 5861376 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2863       |
|    time_elapsed         | 9292       |
|    total_timesteps      | 5863424    |
| train/                  |            |
|    approx_kl            | 0.20783868 |
|    clip_fraction        | 0.439      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.928      |
|    explained_variance   | 0.481      |
|    learning_rate        | 0.000857   |
|    loss                 | -0.0162    |
|    n_updates            | 28620      |
|    policy_gradient_loss | 0.0323     |
|    std                  | 0.153      |
|    value_loss           | 0.0238     |
----------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 630       |
|    iterations           | 2864      |
|    time_elapsed         | 9295      |
|    total_timesteps      | 5865472   |
| train/                  |           |
|    approx_kl            | 0.1315119 |
|    clip_fraction        | 0.408     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.918     |
|    explained_variance   | 0.466     |
|    learning_rate        | 0.000857  |
|    loss                 | 0.00366   |
|    n_updates            | 28630     |
|    policy_gradient_loss | 0.0133    |
|    std                  | 0.154     |
|    value_loss           | 0.0126    |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2865       |
|    time_elapsed         | 9298       |
|    total_timesteps      | 5867520    |
| train/                  |            |
|    approx_kl            | 0.27879912 |
|    clip_fraction        | 0.428      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.905      |
|    explained_variance   | 0.477      |
|    learning_rate        | 0.000856   |
|    loss                 | -0.0316    |
|    n_updates            | 28640      |
|    policy_gradient_loss | 0.0113     |
|    std                  | 0.155      |
|    value_loss           | 0.0184     |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2866       |
|    time_elapsed         | 9302       |
|    total_timesteps      | 5869568    |
| train/                  |            |
|    approx_kl            | 0.30065894 |
|    clip_fraction        | 0.387      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.866      |
|    explained_variance   | 0.801      |
|    learning_rate        | 0.000856   |
|    loss                 | -0.0183    |
|    n_updates            | 28650      |
|    policy_gradient_loss | 0.0136     |
|    std                  | 0.157      |
|    value_loss           | 0.00501    |
----------------------------------------
Eval num_timesteps=5870000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1         |
| time/                   |            |
|    total_timesteps      | 5870000    |
| train/                  |            |
|    approx_kl            | 0.23367506 |
|    clip_fraction        | 0.445      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.863      |
|    explained_variance   | 0.352      |
|    learning_rate        | 0.000855   |
|    loss                 | 0.00509    |
|    n_updates            | 28660      |
|    policy_gradient_loss | 0.0181     |
|    std                  | 0.158      |
|    value_loss           | 0.036      |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 630     |
|    iterations      | 2867    |
|    time_elapsed    | 9306    |
|    total_timesteps | 5871616 |
--------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2868       |
|    time_elapsed         | 9309       |
|    total_timesteps      | 5873664    |
| train/                  |            |
|    approx_kl            | 0.43568027 |
|    clip_fraction        | 0.455      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.88       |
|    explained_variance   | 0.827      |
|    learning_rate        | 0.000855   |
|    loss                 | 0.0445     |
|    n_updates            | 28670      |
|    policy_gradient_loss | 0.0117     |
|    std                  | 0.155      |
|    value_loss           | 0.0156     |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2869       |
|    time_elapsed         | 9312       |
|    total_timesteps      | 5875712    |
| train/                  |            |
|    approx_kl            | 0.41292235 |
|    clip_fraction        | 0.505      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.89       |
|    explained_variance   | 0.873      |
|    learning_rate        | 0.000855   |
|    loss                 | -0.0226    |
|    n_updates            | 28680      |
|    policy_gradient_loss | 0.0156     |
|    std                  | 0.156      |
|    value_loss           | 0.00982    |
----------------------------------------
box reached target
box reached target
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2870       |
|    time_elapsed         | 9315       |
|    total_timesteps      | 5877760    |
| train/                  |            |
|    approx_kl            | 0.78403324 |
|    clip_fraction        | 0.469      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.886      |
|    explained_variance   | 0.656      |
|    learning_rate        | 0.000854   |
|    loss                 | -0.00218   |
|    n_updates            | 28690      |
|    policy_gradient_loss | 0.0119     |
|    std                  | 0.155      |
|    value_loss           | 0.023      |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 2871       |
|    time_elapsed         | 9318       |
|    total_timesteps      | 5879808    |
| train/                  |            |
|    approx_kl            | 0.34766218 |
|    clip_fraction        | 0.467      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.886      |
|    explained_variance   | 0.734      |
|    learning_rate        | 0.000854   |
|    loss                 | 0.106      |
|    n_updates            | 28700      |
|    policy_gradient_loss | 0.0171     |
|    std                  | 0.157      |
|    value_loss           | 0.0779     |
----------------------------------------
Eval num_timesteps=5880000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1         |
| time/                   |            |
|    total_timesteps      | 5880000    |
| train/                  |            |
|    approx_kl            | 0.31579462 |
|    clip_fraction        | 0.388      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.853      |
|    explained_variance   | 0.288      |
|    learning_rate        | 0.000853   |
|    loss                 | 0.125      |
|    n_updates            | 28710      |
|    policy_gradient_loss | 0.0113     |
|    std                  | 0.159      |
|    value_loss           | 0.00487    |
----------------------------------------
box reached target
--------------------------------
| time/              |         |
|    fps             | 630     |
|    iterations      | 2872    |
|    time_elapsed    | 9322    |
|    total_timesteps | 5881856 |
--------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 630       |
|    iterations           | 2873      |
|    time_elapsed         | 9325      |
|    total_timesteps      | 5883904   |
| train/                  |           |
|    approx_kl            | 3.4339514 |
|    clip_fraction        | 0.544     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.847     |
|    explained_variance   | 0.865     |
|    learning_rate        | 0.000853  |
|    loss                 | -0.0554   |
|    n_updates            | 28720     |
|    policy_gradient_loss | -0.000596 |
|    std                  | 0.157     |
|    value_loss           | 0.0139    |
---------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 630       |
|    iterations           | 2874      |
|    time_elapsed         | 9328      |
|    total_timesteps      | 5885952   |
| train/                  |           |
|    approx_kl            | 0.3103854 |
|    clip_fraction        | 0.506     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.832     |
|    explained_variance   | 0.914     |
|    learning_rate        | 0.000853  |
|    loss                 | 0.0679    |
|    n_updates            | 28730     |
|    policy_gradient_loss | 0.0154    |
|    std                  | 0.162     |
|    value_loss           | 0.00721   |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2875       |
|    time_elapsed         | 9331       |
|    total_timesteps      | 5888000    |
| train/                  |            |
|    approx_kl            | 0.22513652 |
|    clip_fraction        | 0.408      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.804      |
|    explained_variance   | 0.698      |
|    learning_rate        | 0.000852   |
|    loss                 | -0.000999  |
|    n_updates            | 28740      |
|    policy_gradient_loss | 0.00347    |
|    std                  | 0.163      |
|    value_loss           | 0.00984    |
----------------------------------------
Eval num_timesteps=5890000, episode_reward=-0.91 +/- 0.19
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -0.905     |
| time/                   |            |
|    total_timesteps      | 5890000    |
| train/                  |            |
|    approx_kl            | 0.24594069 |
|    clip_fraction        | 0.418      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.814      |
|    explained_variance   | 0.615      |
|    learning_rate        | 0.000852   |
|    loss                 | 0.0189     |
|    n_updates            | 28750      |
|    policy_gradient_loss | 0.0131     |
|    std                  | 0.16       |
|    value_loss           | 0.0119     |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 630     |
|    iterations      | 2876    |
|    time_elapsed    | 9335    |
|    total_timesteps | 5890048 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2877       |
|    time_elapsed         | 9338       |
|    total_timesteps      | 5892096    |
| train/                  |            |
|    approx_kl            | 0.31728876 |
|    clip_fraction        | 0.419      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.858      |
|    explained_variance   | -0.443     |
|    learning_rate        | 0.000851   |
|    loss                 | 0.00443    |
|    n_updates            | 28760      |
|    policy_gradient_loss | 0.000799   |
|    std                  | 0.156      |
|    value_loss           | 0.00641    |
----------------------------------------
box reached target
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 630       |
|    iterations           | 2878      |
|    time_elapsed         | 9341      |
|    total_timesteps      | 5894144   |
| train/                  |           |
|    approx_kl            | 0.5034839 |
|    clip_fraction        | 0.403     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.866     |
|    explained_variance   | 0.635     |
|    learning_rate        | 0.000851  |
|    loss                 | -0.0203   |
|    n_updates            | 28770     |
|    policy_gradient_loss | -0.00399  |
|    std                  | 0.156     |
|    value_loss           | 0.00453   |
---------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2879       |
|    time_elapsed         | 9344       |
|    total_timesteps      | 5896192    |
| train/                  |            |
|    approx_kl            | 0.39517152 |
|    clip_fraction        | 0.485      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.888      |
|    explained_variance   | 0.416      |
|    learning_rate        | 0.000851   |
|    loss                 | 0.0327     |
|    n_updates            | 28780      |
|    policy_gradient_loss | 0.0361     |
|    std                  | 0.154      |
|    value_loss           | 0.0681     |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2880       |
|    time_elapsed         | 9347       |
|    total_timesteps      | 5898240    |
| train/                  |            |
|    approx_kl            | 0.84900427 |
|    clip_fraction        | 0.462      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.884      |
|    explained_variance   | 0.765      |
|    learning_rate        | 0.00085    |
|    loss                 | 0.00471    |
|    n_updates            | 28790      |
|    policy_gradient_loss | 0.000953   |
|    std                  | 0.155      |
|    value_loss           | 0.0291     |
----------------------------------------
box reached target
box reached target
Eval num_timesteps=5900000, episode_reward=0.27 +/- 2.55
Episode length: 276.60 +/- 46.80
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 277        |
|    mean_reward          | 0.273      |
| time/                   |            |
|    total_timesteps      | 5900000    |
| train/                  |            |
|    approx_kl            | 0.48090804 |
|    clip_fraction        | 0.452      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.906      |
|    explained_variance   | 0.54       |
|    learning_rate        | 0.00085    |
|    loss                 | 0.00754    |
|    n_updates            | 28800      |
|    policy_gradient_loss | -0.00322   |
|    std                  | 0.152      |
|    value_loss           | 0.126      |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 630     |
|    iterations      | 2881    |
|    time_elapsed    | 9351    |
|    total_timesteps | 5900288 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2882       |
|    time_elapsed         | 9354       |
|    total_timesteps      | 5902336    |
| train/                  |            |
|    approx_kl            | 0.41605282 |
|    clip_fraction        | 0.499      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.984      |
|    explained_variance   | 0.458      |
|    learning_rate        | 0.000849   |
|    loss                 | -0.0425    |
|    n_updates            | 28810      |
|    policy_gradient_loss | -0.0075    |
|    std                  | 0.145      |
|    value_loss           | 0.0239     |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2883       |
|    time_elapsed         | 9357       |
|    total_timesteps      | 5904384    |
| train/                  |            |
|    approx_kl            | 0.28882456 |
|    clip_fraction        | 0.431      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.01       |
|    explained_variance   | 0.652      |
|    learning_rate        | 0.000849   |
|    loss                 | 0.0366     |
|    n_updates            | 28820      |
|    policy_gradient_loss | 0.000884   |
|    std                  | 0.148      |
|    value_loss           | 0.0101     |
----------------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2884       |
|    time_elapsed         | 9360       |
|    total_timesteps      | 5906432    |
| train/                  |            |
|    approx_kl            | 0.37662762 |
|    clip_fraction        | 0.482      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.01       |
|    explained_variance   | 0.556      |
|    learning_rate        | 0.000849   |
|    loss                 | -0.0146    |
|    n_updates            | 28830      |
|    policy_gradient_loss | 0.00788    |
|    std                  | 0.144      |
|    value_loss           | 0.0529     |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 2885       |
|    time_elapsed         | 9363       |
|    total_timesteps      | 5908480    |
| train/                  |            |
|    approx_kl            | 0.34036916 |
|    clip_fraction        | 0.521      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.07       |
|    explained_variance   | 0.806      |
|    learning_rate        | 0.000848   |
|    loss                 | -0.063     |
|    n_updates            | 28840      |
|    policy_gradient_loss | 0.0191     |
|    std                  | 0.141      |
|    value_loss           | 0.0376     |
----------------------------------------
box reached target
box reached target
Eval num_timesteps=5910000, episode_reward=-1.02 +/- 0.03
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1.02      |
| time/                   |            |
|    total_timesteps      | 5910000    |
| train/                  |            |
|    approx_kl            | 0.21971527 |
|    clip_fraction        | 0.432      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.07       |
|    explained_variance   | 0.712      |
|    learning_rate        | 0.000848   |
|    loss                 | 0.00314    |
|    n_updates            | 28850      |
|    policy_gradient_loss | 0.0147     |
|    std                  | 0.143      |
|    value_loss           | 0.0106     |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 630     |
|    iterations      | 2886    |
|    time_elapsed    | 9367    |
|    total_timesteps | 5910528 |
--------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 630       |
|    iterations           | 2887      |
|    time_elapsed         | 9370      |
|    total_timesteps      | 5912576   |
| train/                  |           |
|    approx_kl            | 0.2881841 |
|    clip_fraction        | 0.487     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.04      |
|    explained_variance   | 0.644     |
|    learning_rate        | 0.000847  |
|    loss                 | 0.156     |
|    n_updates            | 28860     |
|    policy_gradient_loss | 0.0242    |
|    std                  | 0.145     |
|    value_loss           | 0.0563    |
---------------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 630        |
|    iterations           | 2888       |
|    time_elapsed         | 9373       |
|    total_timesteps      | 5914624    |
| train/                  |            |
|    approx_kl            | 0.32805628 |
|    clip_fraction        | 0.471      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.04       |
|    explained_variance   | 0.745      |
|    learning_rate        | 0.000847   |
|    loss                 | 0.013      |
|    n_updates            | 28870      |
|    policy_gradient_loss | 0.0134     |
|    std                  | 0.144      |
|    value_loss           | 0.0156     |
----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 630       |
|    iterations           | 2889      |
|    time_elapsed         | 9376      |
|    total_timesteps      | 5916672   |
| train/                  |           |
|    approx_kl            | 0.3771327 |
|    clip_fraction        | 0.479     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.01      |
|    explained_variance   | 0.656     |
|    learning_rate        | 0.000847  |
|    loss                 | 0.0431    |
|    n_updates            | 28880     |
|    policy_gradient_loss | 0.012     |
|    std                  | 0.148     |
|    value_loss           | 0.0769    |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 2890       |
|    time_elapsed         | 9379       |
|    total_timesteps      | 5918720    |
| train/                  |            |
|    approx_kl            | 0.55841565 |
|    clip_fraction        | 0.457      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.995      |
|    explained_variance   | 0.574      |
|    learning_rate        | 0.000846   |
|    loss                 | -0.0429    |
|    n_updates            | 28890      |
|    policy_gradient_loss | 0.014      |
|    std                  | 0.147      |
|    value_loss           | 0.00457    |
----------------------------------------
box reached target
box reached target
Eval num_timesteps=5920000, episode_reward=1.74 +/- 2.93
Episode length: 242.20 +/- 70.88
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 242       |
|    mean_reward          | 1.74      |
| time/                   |           |
|    total_timesteps      | 5920000   |
| train/                  |           |
|    approx_kl            | 0.4134099 |
|    clip_fraction        | 0.434     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.02      |
|    explained_variance   | 0.664     |
|    learning_rate        | 0.000846  |
|    loss                 | -0.0553   |
|    n_updates            | 28900     |
|    policy_gradient_loss | -0.00951  |
|    std                  | 0.145     |
|    value_loss           | 0.00897   |
---------------------------------------
--------------------------------
| time/              |         |
|    fps             | 630     |
|    iterations      | 2891    |
|    time_elapsed    | 9383    |
|    total_timesteps | 5920768 |
--------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 630       |
|    iterations           | 2892      |
|    time_elapsed         | 9386      |
|    total_timesteps      | 5922816   |
| train/                  |           |
|    approx_kl            | 0.5642116 |
|    clip_fraction        | 0.481     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.04      |
|    explained_variance   | 0.87      |
|    learning_rate        | 0.000845  |
|    loss                 | -0.0229   |
|    n_updates            | 28910     |
|    policy_gradient_loss | 0.0194    |
|    std                  | 0.145     |
|    value_loss           | 0.00599   |
---------------------------------------
box reached target
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 2893      |
|    time_elapsed         | 9389      |
|    total_timesteps      | 5924864   |
| train/                  |           |
|    approx_kl            | 0.2050587 |
|    clip_fraction        | 0.47      |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.04      |
|    explained_variance   | 0.683     |
|    learning_rate        | 0.000845  |
|    loss                 | 0.0221    |
|    n_updates            | 28920     |
|    policy_gradient_loss | 0.0243    |
|    std                  | 0.145     |
|    value_loss           | 0.0133    |
---------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 2894      |
|    time_elapsed         | 9392      |
|    total_timesteps      | 5926912   |
| train/                  |           |
|    approx_kl            | 0.1999293 |
|    clip_fraction        | 0.441     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.06      |
|    explained_variance   | 0.696     |
|    learning_rate        | 0.000845  |
|    loss                 | 0.0877    |
|    n_updates            | 28930     |
|    policy_gradient_loss | 0.0194    |
|    std                  | 0.142     |
|    value_loss           | 0.0328    |
---------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 2895      |
|    time_elapsed         | 9395      |
|    total_timesteps      | 5928960   |
| train/                  |           |
|    approx_kl            | 0.4185741 |
|    clip_fraction        | 0.457     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.02      |
|    explained_variance   | 0.694     |
|    learning_rate        | 0.000844  |
|    loss                 | -0.0219   |
|    n_updates            | 28940     |
|    policy_gradient_loss | 0.0282    |
|    std                  | 0.148     |
|    value_loss           | 0.0144    |
---------------------------------------
box reached target
Eval num_timesteps=5930000, episode_reward=0.79 +/- 2.29
Episode length: 277.60 +/- 44.80
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 278       |
|    mean_reward          | 0.793     |
| time/                   |           |
|    total_timesteps      | 5930000   |
| train/                  |           |
|    approx_kl            | 0.4856657 |
|    clip_fraction        | 0.523     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.954     |
|    explained_variance   | 0.805     |
|    learning_rate        | 0.000844  |
|    loss                 | -0.0655   |
|    n_updates            | 28950     |
|    policy_gradient_loss | 0.0225    |
|    std                  | 0.152     |
|    value_loss           | 0.0258    |
---------------------------------------
--------------------------------
| time/              |         |
|    fps             | 630     |
|    iterations      | 2896    |
|    time_elapsed    | 9399    |
|    total_timesteps | 5931008 |
--------------------------------
box reached target
--------------------------------------
| time/                   |          |
|    fps                  | 630      |
|    iterations           | 2897     |
|    time_elapsed         | 9402     |
|    total_timesteps      | 5933056  |
| train/                  |          |
|    approx_kl            | 0.542759 |
|    clip_fraction        | 0.458    |
|    clip_range           | 0.2      |
|    entropy_loss         | 0.935    |
|    explained_variance   | 0.617    |
|    learning_rate        | 0.000843 |
|    loss                 | 0.0256   |
|    n_updates            | 28960    |
|    policy_gradient_loss | 0.00482  |
|    std                  | 0.151    |
|    value_loss           | 0.00763  |
--------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 2898      |
|    time_elapsed         | 9405      |
|    total_timesteps      | 5935104   |
| train/                  |           |
|    approx_kl            | 0.4814198 |
|    clip_fraction        | 0.464     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.928     |
|    explained_variance   | 0.763     |
|    learning_rate        | 0.000843  |
|    loss                 | -0.011    |
|    n_updates            | 28970     |
|    policy_gradient_loss | 0.0303    |
|    std                  | 0.152     |
|    value_loss           | 0.0223    |
---------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 2899      |
|    time_elapsed         | 9408      |
|    total_timesteps      | 5937152   |
| train/                  |           |
|    approx_kl            | 0.3059628 |
|    clip_fraction        | 0.429     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.932     |
|    explained_variance   | 0.891     |
|    learning_rate        | 0.000843  |
|    loss                 | -0.0111   |
|    n_updates            | 28980     |
|    policy_gradient_loss | 0.0106    |
|    std                  | 0.153     |
|    value_loss           | 0.0131    |
---------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 2900       |
|    time_elapsed         | 9411       |
|    total_timesteps      | 5939200    |
| train/                  |            |
|    approx_kl            | 0.23866084 |
|    clip_fraction        | 0.406      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.916      |
|    explained_variance   | 0.79       |
|    learning_rate        | 0.000842   |
|    loss                 | 0.0969     |
|    n_updates            | 28990      |
|    policy_gradient_loss | 0.0181     |
|    std                  | 0.154      |
|    value_loss           | 0.0208     |
----------------------------------------
box reached target
Eval num_timesteps=5940000, episode_reward=0.27 +/- 2.55
Episode length: 280.20 +/- 39.60
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 280        |
|    mean_reward          | 0.274      |
| time/                   |            |
|    total_timesteps      | 5940000    |
| train/                  |            |
|    approx_kl            | 0.54767007 |
|    clip_fraction        | 0.508      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.885      |
|    explained_variance   | 0.853      |
|    learning_rate        | 0.000842   |
|    loss                 | 0.234      |
|    n_updates            | 29000      |
|    policy_gradient_loss | 0.0165     |
|    std                  | 0.155      |
|    value_loss           | 0.071      |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 630     |
|    iterations      | 2901    |
|    time_elapsed    | 9415    |
|    total_timesteps | 5941248 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 2902       |
|    time_elapsed         | 9418       |
|    total_timesteps      | 5943296    |
| train/                  |            |
|    approx_kl            | 0.26070443 |
|    clip_fraction        | 0.47       |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.861      |
|    explained_variance   | 0.778      |
|    learning_rate        | 0.000841   |
|    loss                 | -0.0349    |
|    n_updates            | 29010      |
|    policy_gradient_loss | 0.0112     |
|    std                  | 0.159      |
|    value_loss           | 0.0237     |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 2903       |
|    time_elapsed         | 9421       |
|    total_timesteps      | 5945344    |
| train/                  |            |
|    approx_kl            | 0.50768805 |
|    clip_fraction        | 0.431      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.823      |
|    explained_variance   | 0.63       |
|    learning_rate        | 0.000841   |
|    loss                 | 0.0709     |
|    n_updates            | 29020      |
|    policy_gradient_loss | 0.00389    |
|    std                  | 0.161      |
|    value_loss           | 0.00634    |
----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 2904      |
|    time_elapsed         | 9424      |
|    total_timesteps      | 5947392   |
| train/                  |           |
|    approx_kl            | 0.2783569 |
|    clip_fraction        | 0.427     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.824     |
|    explained_variance   | 0.857     |
|    learning_rate        | 0.000841  |
|    loss                 | -0.0336   |
|    n_updates            | 29030     |
|    policy_gradient_loss | 0.0132    |
|    std                  | 0.16      |
|    value_loss           | 0.018     |
---------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 2905      |
|    time_elapsed         | 9427      |
|    total_timesteps      | 5949440   |
| train/                  |           |
|    approx_kl            | 0.4090081 |
|    clip_fraction        | 0.43      |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.828     |
|    explained_variance   | 0.498     |
|    learning_rate        | 0.00084   |
|    loss                 | -0.0374   |
|    n_updates            | 29040     |
|    policy_gradient_loss | -0.0102   |
|    std                  | 0.16      |
|    value_loss           | 0.0109    |
---------------------------------------
box reached target
box reached target
Eval num_timesteps=5950000, episode_reward=1.45 +/- 3.01
Episode length: 262.60 +/- 58.49
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 263        |
|    mean_reward          | 1.45       |
| time/                   |            |
|    total_timesteps      | 5950000    |
| train/                  |            |
|    approx_kl            | 0.25811327 |
|    clip_fraction        | 0.441      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.833      |
|    explained_variance   | 0.921      |
|    learning_rate        | 0.00084    |
|    loss                 | 0.00737    |
|    n_updates            | 29050      |
|    policy_gradient_loss | 0.00779    |
|    std                  | 0.161      |
|    value_loss           | 0.0166     |
----------------------------------------
box reached target
box reached target
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 2906    |
|    time_elapsed    | 9431    |
|    total_timesteps | 5951488 |
--------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 2907      |
|    time_elapsed         | 9434      |
|    total_timesteps      | 5953536   |
| train/                  |           |
|    approx_kl            | 0.2432809 |
|    clip_fraction        | 0.46      |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.841     |
|    explained_variance   | 0.836     |
|    learning_rate        | 0.000839  |
|    loss                 | -0.0228   |
|    n_updates            | 29060     |
|    policy_gradient_loss | 0.0058    |
|    std                  | 0.159     |
|    value_loss           | 0.0189    |
---------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 2908       |
|    time_elapsed         | 9437       |
|    total_timesteps      | 5955584    |
| train/                  |            |
|    approx_kl            | 0.41627055 |
|    clip_fraction        | 0.476      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.896      |
|    explained_variance   | 0.667      |
|    learning_rate        | 0.000839   |
|    loss                 | 0.0844     |
|    n_updates            | 29070      |
|    policy_gradient_loss | 0.00917    |
|    std                  | 0.153      |
|    value_loss           | 0.0351     |
----------------------------------------
box reached target
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 2909       |
|    time_elapsed         | 9440       |
|    total_timesteps      | 5957632    |
| train/                  |            |
|    approx_kl            | 0.24834949 |
|    clip_fraction        | 0.433      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.913      |
|    explained_variance   | 0.933      |
|    learning_rate        | 0.000839   |
|    loss                 | 0.00228    |
|    n_updates            | 29080      |
|    policy_gradient_loss | 0.00308    |
|    std                  | 0.154      |
|    value_loss           | 0.0127     |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 2910       |
|    time_elapsed         | 9444       |
|    total_timesteps      | 5959680    |
| train/                  |            |
|    approx_kl            | 0.47080007 |
|    clip_fraction        | 0.487      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.944      |
|    explained_variance   | 0.672      |
|    learning_rate        | 0.000838   |
|    loss                 | -0.0477    |
|    n_updates            | 29090      |
|    policy_gradient_loss | 0.0216     |
|    std                  | 0.149      |
|    value_loss           | 0.148      |
----------------------------------------
box reached target
Eval num_timesteps=5960000, episode_reward=0.25 +/- 2.51
Episode length: 279.20 +/- 41.60
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 279        |
|    mean_reward          | 0.255      |
| time/                   |            |
|    total_timesteps      | 5960000    |
| train/                  |            |
|    approx_kl            | 0.38977027 |
|    clip_fraction        | 0.435      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.952      |
|    explained_variance   | 0.77       |
|    learning_rate        | 0.000838   |
|    loss                 | 0.0409     |
|    n_updates            | 29100      |
|    policy_gradient_loss | 0.0128     |
|    std                  | 0.152      |
|    value_loss           | 0.0138     |
----------------------------------------
box reached target
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 2911    |
|    time_elapsed    | 9447    |
|    total_timesteps | 5961728 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 2912       |
|    time_elapsed         | 9450       |
|    total_timesteps      | 5963776    |
| train/                  |            |
|    approx_kl            | 0.25588176 |
|    clip_fraction        | 0.431      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.954      |
|    explained_variance   | 0.856      |
|    learning_rate        | 0.000837   |
|    loss                 | -0.00276   |
|    n_updates            | 29110      |
|    policy_gradient_loss | 0.00933    |
|    std                  | 0.151      |
|    value_loss           | 0.0162     |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 2913       |
|    time_elapsed         | 9453       |
|    total_timesteps      | 5965824    |
| train/                  |            |
|    approx_kl            | 0.31638956 |
|    clip_fraction        | 0.426      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.966      |
|    explained_variance   | 0.724      |
|    learning_rate        | 0.000837   |
|    loss                 | 0.0799     |
|    n_updates            | 29120      |
|    policy_gradient_loss | 0.0121     |
|    std                  | 0.15       |
|    value_loss           | 0.00532    |
----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 2914      |
|    time_elapsed         | 9457      |
|    total_timesteps      | 5967872   |
| train/                  |           |
|    approx_kl            | 0.5684197 |
|    clip_fraction        | 0.454     |
|    clip_range           | 0.2       |
|    entropy_loss         | 0.964     |
|    explained_variance   | 0.609     |
|    learning_rate        | 0.000837  |
|    loss                 | -0.0382   |
|    n_updates            | 29130     |
|    policy_gradient_loss | 0.006     |
|    std                  | 0.15      |
|    value_loss           | 0.0086    |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 2915       |
|    time_elapsed         | 9460       |
|    total_timesteps      | 5969920    |
| train/                  |            |
|    approx_kl            | 0.40571302 |
|    clip_fraction        | 0.382      |
|    clip_range           | 0.2        |
|    entropy_loss         | 0.978      |
|    explained_variance   | 0.727      |
|    learning_rate        | 0.000836   |
|    loss                 | 0.0238     |
|    n_updates            | 29140      |
|    policy_gradient_loss | 0.0049     |
|    std                  | 0.149      |
|    value_loss           | 0.00793    |
----------------------------------------
box reached target
box reached target
Eval num_timesteps=5970000, episode_reward=1.43 +/- 3.10
Episode length: 252.80 +/- 57.86
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 253       |
|    mean_reward          | 1.43      |
| time/                   |           |
|    total_timesteps      | 5970000   |
| train/                  |           |
|    approx_kl            | 0.6100488 |
|    clip_fraction        | 0.444     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.01      |
|    explained_variance   | 0.374     |
|    learning_rate        | 0.000836  |
|    loss                 | 0.0868    |
|    n_updates            | 29150     |
|    policy_gradient_loss | 0.0142    |
|    std                  | 0.146     |
|    value_loss           | 0.00878   |
---------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 2916    |
|    time_elapsed    | 9463    |
|    total_timesteps | 5971968 |
--------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 2917      |
|    time_elapsed         | 9466      |
|    total_timesteps      | 5974016   |
| train/                  |           |
|    approx_kl            | 1.1445159 |
|    clip_fraction        | 0.528     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.03      |
|    explained_variance   | 0.722     |
|    learning_rate        | 0.000835  |
|    loss                 | 0.00649   |
|    n_updates            | 29160     |
|    policy_gradient_loss | 0.0269    |
|    std                  | 0.145     |
|    value_loss           | 0.00549   |
---------------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 2918       |
|    time_elapsed         | 9470       |
|    total_timesteps      | 5976064    |
| train/                  |            |
|    approx_kl            | 0.28351703 |
|    clip_fraction        | 0.465      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.02       |
|    explained_variance   | 0.745      |
|    learning_rate        | 0.000835   |
|    loss                 | 0.0536     |
|    n_updates            | 29170      |
|    policy_gradient_loss | 0.0166     |
|    std                  | 0.146      |
|    value_loss           | 0.0023     |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 2919       |
|    time_elapsed         | 9473       |
|    total_timesteps      | 5978112    |
| train/                  |            |
|    approx_kl            | 0.31325084 |
|    clip_fraction        | 0.513      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.03       |
|    explained_variance   | 0.487      |
|    learning_rate        | 0.000835   |
|    loss                 | 0.0292     |
|    n_updates            | 29180      |
|    policy_gradient_loss | 0.0312     |
|    std                  | 0.146      |
|    value_loss           | 0.0309     |
----------------------------------------
box reached target
Eval num_timesteps=5980000, episode_reward=-0.76 +/- 0.48
Episode length: 300.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 300       |
|    mean_reward          | -0.762    |
| time/                   |           |
|    total_timesteps      | 5980000   |
| train/                  |           |
|    approx_kl            | 0.1377708 |
|    clip_fraction        | 0.409     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.04      |
|    explained_variance   | 0.905     |
|    learning_rate        | 0.000834  |
|    loss                 | -0.00309  |
|    n_updates            | 29190     |
|    policy_gradient_loss | 0.00893   |
|    std                  | 0.145     |
|    value_loss           | 0.0154    |
---------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 2920    |
|    time_elapsed    | 9477    |
|    total_timesteps | 5980160 |
--------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 2921      |
|    time_elapsed         | 9480      |
|    total_timesteps      | 5982208   |
| train/                  |           |
|    approx_kl            | 0.2689969 |
|    clip_fraction        | 0.465     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.07      |
|    explained_variance   | 0.391     |
|    learning_rate        | 0.000834  |
|    loss                 | -0.022    |
|    n_updates            | 29200     |
|    policy_gradient_loss | 0.0104    |
|    std                  | 0.14      |
|    value_loss           | 0.0343    |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 2922       |
|    time_elapsed         | 9483       |
|    total_timesteps      | 5984256    |
| train/                  |            |
|    approx_kl            | 0.29591477 |
|    clip_fraction        | 0.417      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.1        |
|    explained_variance   | 0.856      |
|    learning_rate        | 0.000833   |
|    loss                 | -0.0223    |
|    n_updates            | 29210      |
|    policy_gradient_loss | 0.0119     |
|    std                  | 0.141      |
|    value_loss           | 0.00984    |
----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 2923      |
|    time_elapsed         | 9486      |
|    total_timesteps      | 5986304   |
| train/                  |           |
|    approx_kl            | 1.0022212 |
|    clip_fraction        | 0.469     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.07      |
|    explained_variance   | 0.747     |
|    learning_rate        | 0.000833  |
|    loss                 | -0.0395   |
|    n_updates            | 29220     |
|    policy_gradient_loss | 0.00896   |
|    std                  | 0.142     |
|    value_loss           | 0.0111    |
---------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 2924      |
|    time_elapsed         | 9489      |
|    total_timesteps      | 5988352   |
| train/                  |           |
|    approx_kl            | 0.8580556 |
|    clip_fraction        | 0.445     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.09      |
|    explained_variance   | 0.806     |
|    learning_rate        | 0.000833  |
|    loss                 | -0.0325   |
|    n_updates            | 29230     |
|    policy_gradient_loss | -0.00882  |
|    std                  | 0.139     |
|    value_loss           | 0.0032    |
---------------------------------------
box reached target
box reached target
box reached target
Eval num_timesteps=5990000, episode_reward=1.46 +/- 3.02
Episode length: 248.80 +/- 62.96
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 249        |
|    mean_reward          | 1.46       |
| time/                   |            |
|    total_timesteps      | 5990000    |
| train/                  |            |
|    approx_kl            | 0.47390366 |
|    clip_fraction        | 0.446      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.13       |
|    explained_variance   | 0.737      |
|    learning_rate        | 0.000832   |
|    loss                 | -0.0542    |
|    n_updates            | 29240      |
|    policy_gradient_loss | -0.00573   |
|    std                  | 0.138      |
|    value_loss           | 0.00358    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 2925    |
|    time_elapsed    | 9493    |
|    total_timesteps | 5990400 |
--------------------------------
box reached target
box reached target
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 2926      |
|    time_elapsed         | 9496      |
|    total_timesteps      | 5992448   |
| train/                  |           |
|    approx_kl            | 1.2495124 |
|    clip_fraction        | 0.546     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.12      |
|    explained_variance   | 0.9       |
|    learning_rate        | 0.000832  |
|    loss                 | 0.00186   |
|    n_updates            | 29250     |
|    policy_gradient_loss | 0.0294    |
|    std                  | 0.139     |
|    value_loss           | 0.00778   |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 2927       |
|    time_elapsed         | 9499       |
|    total_timesteps      | 5994496    |
| train/                  |            |
|    approx_kl            | 0.17049503 |
|    clip_fraction        | 0.439      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.09       |
|    explained_variance   | 0.914      |
|    learning_rate        | 0.000831   |
|    loss                 | 0.01       |
|    n_updates            | 29260      |
|    policy_gradient_loss | 0.0171     |
|    std                  | 0.142      |
|    value_loss           | 0.017      |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 2928       |
|    time_elapsed         | 9502       |
|    total_timesteps      | 5996544    |
| train/                  |            |
|    approx_kl            | 0.34529722 |
|    clip_fraction        | 0.476      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.07       |
|    explained_variance   | 0.825      |
|    learning_rate        | 0.000831   |
|    loss                 | 0.0196     |
|    n_updates            | 29270      |
|    policy_gradient_loss | 0.00209    |
|    std                  | 0.141      |
|    value_loss           | 0.0239     |
----------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 2929      |
|    time_elapsed         | 9505      |
|    total_timesteps      | 5998592   |
| train/                  |           |
|    approx_kl            | 0.5007464 |
|    clip_fraction        | 0.469     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.09      |
|    explained_variance   | 0.925     |
|    learning_rate        | 0.000831  |
|    loss                 | -0.0234   |
|    n_updates            | 29280     |
|    policy_gradient_loss | 0.000293  |
|    std                  | 0.14      |
|    value_loss           | 0.00846   |
---------------------------------------
box reached target
Eval num_timesteps=6000000, episode_reward=0.21 +/- 2.43
Episode length: 273.20 +/- 53.60
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 273        |
|    mean_reward          | 0.214      |
| time/                   |            |
|    total_timesteps      | 6000000    |
| train/                  |            |
|    approx_kl            | 0.36609358 |
|    clip_fraction        | 0.497      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.1        |
|    explained_variance   | 0.626      |
|    learning_rate        | 0.00083    |
|    loss                 | -0.044     |
|    n_updates            | 29290      |
|    policy_gradient_loss | 0.0199     |
|    std                  | 0.14       |
|    value_loss           | 0.0245     |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 2930    |
|    time_elapsed    | 9509    |
|    total_timesteps | 6000640 |
--------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 2931      |
|    time_elapsed         | 9512      |
|    total_timesteps      | 6002688   |
| train/                  |           |
|    approx_kl            | 1.6133761 |
|    clip_fraction        | 0.539     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.12      |
|    explained_variance   | 0.678     |
|    learning_rate        | 0.00083   |
|    loss                 | 0.0373    |
|    n_updates            | 29300     |
|    policy_gradient_loss | 0.0129    |
|    std                  | 0.136     |
|    value_loss           | 0.0062    |
---------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 2932       |
|    time_elapsed         | 9515       |
|    total_timesteps      | 6004736    |
| train/                  |            |
|    approx_kl            | 0.21642652 |
|    clip_fraction        | 0.456      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.16       |
|    explained_variance   | 0.696      |
|    learning_rate        | 0.000829   |
|    loss                 | 0.0054     |
|    n_updates            | 29310      |
|    policy_gradient_loss | 0.0181     |
|    std                  | 0.135      |
|    value_loss           | 0.0164     |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 2933       |
|    time_elapsed         | 9518       |
|    total_timesteps      | 6006784    |
| train/                  |            |
|    approx_kl            | 0.23771065 |
|    clip_fraction        | 0.489      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.16       |
|    explained_variance   | 0.752      |
|    learning_rate        | 0.000829   |
|    loss                 | 0.0134     |
|    n_updates            | 29320      |
|    policy_gradient_loss | 0.0206     |
|    std                  | 0.136      |
|    value_loss           | 0.0323     |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 2934       |
|    time_elapsed         | 9521       |
|    total_timesteps      | 6008832    |
| train/                  |            |
|    approx_kl            | 0.28729704 |
|    clip_fraction        | 0.456      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.11       |
|    explained_variance   | -0.54      |
|    learning_rate        | 0.000829   |
|    loss                 | -0.0146    |
|    n_updates            | 29330      |
|    policy_gradient_loss | 0.0152     |
|    std                  | 0.142      |
|    value_loss           | 0.00618    |
----------------------------------------
Eval num_timesteps=6010000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 300       |
|    mean_reward          | -1        |
| time/                   |           |
|    total_timesteps      | 6010000   |
| train/                  |           |
|    approx_kl            | 0.5489762 |
|    clip_fraction        | 0.414     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.08      |
|    explained_variance   | 0.692     |
|    learning_rate        | 0.000828  |
|    loss                 | -0.0439   |
|    n_updates            | 29340     |
|    policy_gradient_loss | -0.00344  |
|    std                  | 0.14      |
|    value_loss           | 0.00405   |
---------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 2935    |
|    time_elapsed    | 9525    |
|    total_timesteps | 6010880 |
--------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 2936      |
|    time_elapsed         | 9528      |
|    total_timesteps      | 6012928   |
| train/                  |           |
|    approx_kl            | 0.5582974 |
|    clip_fraction        | 0.44      |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.12      |
|    explained_variance   | 0.547     |
|    learning_rate        | 0.000828  |
|    loss                 | -0.0104   |
|    n_updates            | 29350     |
|    policy_gradient_loss | -0.0134   |
|    std                  | 0.137     |
|    value_loss           | 0.00457   |
---------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 2937      |
|    time_elapsed         | 9531      |
|    total_timesteps      | 6014976   |
| train/                  |           |
|    approx_kl            | 1.5411515 |
|    clip_fraction        | 0.511     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.17      |
|    explained_variance   | 0.564     |
|    learning_rate        | 0.000827  |
|    loss                 | -0.0222   |
|    n_updates            | 29360     |
|    policy_gradient_loss | -0.00972  |
|    std                  | 0.132     |
|    value_loss           | 0.0725    |
---------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 2938      |
|    time_elapsed         | 9534      |
|    total_timesteps      | 6017024   |
| train/                  |           |
|    approx_kl            | 0.6964802 |
|    clip_fraction        | 0.495     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.22      |
|    explained_variance   | 0.62      |
|    learning_rate        | 0.000827  |
|    loss                 | 0.0592    |
|    n_updates            | 29370     |
|    policy_gradient_loss | 0.0258    |
|    std                  | 0.131     |
|    value_loss           | 0.017     |
---------------------------------------
--------------------------------------
| time/                   |          |
|    fps                  | 631      |
|    iterations           | 2939     |
|    time_elapsed         | 9537     |
|    total_timesteps      | 6019072  |
| train/                  |          |
|    approx_kl            | 3.279019 |
|    clip_fraction        | 0.561    |
|    clip_range           | 0.2      |
|    entropy_loss         | 1.22     |
|    explained_variance   | 0.91     |
|    learning_rate        | 0.000827 |
|    loss                 | 0.0557   |
|    n_updates            | 29380    |
|    policy_gradient_loss | 0.0209   |
|    std                  | 0.131    |
|    value_loss           | 0.0101   |
--------------------------------------
box reached target
Eval num_timesteps=6020000, episode_reward=-0.61 +/- 0.50
Episode length: 300.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 300       |
|    mean_reward          | -0.606    |
| time/                   |           |
|    total_timesteps      | 6020000   |
| train/                  |           |
|    approx_kl            | 1.0120078 |
|    clip_fraction        | 0.456     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.21      |
|    explained_variance   | 0.74      |
|    learning_rate        | 0.000826  |
|    loss                 | 0.058     |
|    n_updates            | 29390     |
|    policy_gradient_loss | 0.00924   |
|    std                  | 0.133     |
|    value_loss           | 0.0116    |
---------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 2940    |
|    time_elapsed    | 9541    |
|    total_timesteps | 6021120 |
--------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 2941       |
|    time_elapsed         | 9544       |
|    total_timesteps      | 6023168    |
| train/                  |            |
|    approx_kl            | 0.54791826 |
|    clip_fraction        | 0.491      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.18       |
|    explained_variance   | 0.258      |
|    learning_rate        | 0.000826   |
|    loss                 | -0.0134    |
|    n_updates            | 29400      |
|    policy_gradient_loss | 0.0297     |
|    std                  | 0.135      |
|    value_loss           | 0.0665     |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 2942       |
|    time_elapsed         | 9547       |
|    total_timesteps      | 6025216    |
| train/                  |            |
|    approx_kl            | 0.49396712 |
|    clip_fraction        | 0.487      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.16       |
|    explained_variance   | 0.845      |
|    learning_rate        | 0.000825   |
|    loss                 | 0.0152     |
|    n_updates            | 29410      |
|    policy_gradient_loss | 0.0137     |
|    std                  | 0.135      |
|    value_loss           | 0.0236     |
----------------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 2943       |
|    time_elapsed         | 9550       |
|    total_timesteps      | 6027264    |
| train/                  |            |
|    approx_kl            | 0.43860412 |
|    clip_fraction        | 0.444      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.19       |
|    explained_variance   | 0.905      |
|    learning_rate        | 0.000825   |
|    loss                 | -0.0283    |
|    n_updates            | 29420      |
|    policy_gradient_loss | 0.00393    |
|    std                  | 0.133      |
|    value_loss           | 0.0105     |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 2944       |
|    time_elapsed         | 9553       |
|    total_timesteps      | 6029312    |
| train/                  |            |
|    approx_kl            | 0.53292406 |
|    clip_fraction        | 0.531      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.17       |
|    explained_variance   | 0.706      |
|    learning_rate        | 0.000825   |
|    loss                 | 0.0167     |
|    n_updates            | 29430      |
|    policy_gradient_loss | 0.0382     |
|    std                  | 0.136      |
|    value_loss           | 0.0684     |
----------------------------------------
Eval num_timesteps=6030000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1         |
| time/                   |            |
|    total_timesteps      | 6030000    |
| train/                  |            |
|    approx_kl            | 0.43016288 |
|    clip_fraction        | 0.478      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.16       |
|    explained_variance   | 0.707      |
|    learning_rate        | 0.000824   |
|    loss                 | -0.00891   |
|    n_updates            | 29440      |
|    policy_gradient_loss | 0.0178     |
|    std                  | 0.136      |
|    value_loss           | 0.0221     |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 2945    |
|    time_elapsed    | 9557    |
|    total_timesteps | 6031360 |
--------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 2946       |
|    time_elapsed         | 9560       |
|    total_timesteps      | 6033408    |
| train/                  |            |
|    approx_kl            | 0.42619985 |
|    clip_fraction        | 0.49       |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.13       |
|    explained_variance   | 0.837      |
|    learning_rate        | 0.000824   |
|    loss                 | -0.0314    |
|    n_updates            | 29450      |
|    policy_gradient_loss | 0.0313     |
|    std                  | 0.14       |
|    value_loss           | 0.00406    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 2947       |
|    time_elapsed         | 9563       |
|    total_timesteps      | 6035456    |
| train/                  |            |
|    approx_kl            | 0.54776937 |
|    clip_fraction        | 0.498      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.1        |
|    explained_variance   | 0.873      |
|    learning_rate        | 0.000823   |
|    loss                 | -0.0176    |
|    n_updates            | 29460      |
|    policy_gradient_loss | 0.0154     |
|    std                  | 0.14       |
|    value_loss           | 0.00555    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 2948       |
|    time_elapsed         | 9566       |
|    total_timesteps      | 6037504    |
| train/                  |            |
|    approx_kl            | 0.34449577 |
|    clip_fraction        | 0.425      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.1        |
|    explained_variance   | 0.409      |
|    learning_rate        | 0.000823   |
|    loss                 | -0.0203    |
|    n_updates            | 29470      |
|    policy_gradient_loss | 0.00732    |
|    std                  | 0.14       |
|    value_loss           | 0.00526    |
----------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 2949      |
|    time_elapsed         | 9569      |
|    total_timesteps      | 6039552   |
| train/                  |           |
|    approx_kl            | 0.6592691 |
|    clip_fraction        | 0.469     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.1       |
|    explained_variance   | 0.0575    |
|    learning_rate        | 0.000823  |
|    loss                 | 0.00389   |
|    n_updates            | 29480     |
|    policy_gradient_loss | 0.0043    |
|    std                  | 0.139     |
|    value_loss           | 0.00447   |
---------------------------------------
box reached target
Eval num_timesteps=6040000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1         |
| time/                   |            |
|    total_timesteps      | 6040000    |
| train/                  |            |
|    approx_kl            | 0.21826959 |
|    clip_fraction        | 0.433      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.09       |
|    explained_variance   | 0.862      |
|    learning_rate        | 0.000822   |
|    loss                 | -0.0285    |
|    n_updates            | 29490      |
|    policy_gradient_loss | 0.0192     |
|    std                  | 0.142      |
|    value_loss           | 0.0128     |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 2950    |
|    time_elapsed    | 9573    |
|    total_timesteps | 6041600 |
--------------------------------
--------------------------------------
| time/                   |          |
|    fps                  | 631      |
|    iterations           | 2951     |
|    time_elapsed         | 9576     |
|    total_timesteps      | 6043648  |
| train/                  |          |
|    approx_kl            | 3.050346 |
|    clip_fraction        | 0.516    |
|    clip_range           | 0.2      |
|    entropy_loss         | 1.11     |
|    explained_variance   | 0.699    |
|    learning_rate        | 0.000822 |
|    loss                 | -0.0441  |
|    n_updates            | 29500    |
|    policy_gradient_loss | 0.0276   |
|    std                  | 0.138    |
|    value_loss           | 0.0143   |
--------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 2952      |
|    time_elapsed         | 9580      |
|    total_timesteps      | 6045696   |
| train/                  |           |
|    approx_kl            | 0.8929379 |
|    clip_fraction        | 0.546     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.16      |
|    explained_variance   | 0.754     |
|    learning_rate        | 0.000821  |
|    loss                 | 0.0468    |
|    n_updates            | 29510     |
|    policy_gradient_loss | -0.00799  |
|    std                  | 0.134     |
|    value_loss           | 0.00418   |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 2953       |
|    time_elapsed         | 9583       |
|    total_timesteps      | 6047744    |
| train/                  |            |
|    approx_kl            | 0.32962862 |
|    clip_fraction        | 0.503      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.17       |
|    explained_variance   | 0.696      |
|    learning_rate        | 0.000821   |
|    loss                 | -0.0282    |
|    n_updates            | 29520      |
|    policy_gradient_loss | 0.0207     |
|    std                  | 0.137      |
|    value_loss           | 0.00917    |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 2954       |
|    time_elapsed         | 9586       |
|    total_timesteps      | 6049792    |
| train/                  |            |
|    approx_kl            | 0.19955099 |
|    clip_fraction        | 0.427      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.13       |
|    explained_variance   | 0.686      |
|    learning_rate        | 0.000821   |
|    loss                 | -0.0118    |
|    n_updates            | 29530      |
|    policy_gradient_loss | 0.0134     |
|    std                  | 0.137      |
|    value_loss           | 0.00107    |
----------------------------------------
Eval num_timesteps=6050000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 300       |
|    mean_reward          | -1        |
| time/                   |           |
|    total_timesteps      | 6050000   |
| train/                  |           |
|    approx_kl            | 0.4819436 |
|    clip_fraction        | 0.516     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.13      |
|    explained_variance   | 0.616     |
|    learning_rate        | 0.00082   |
|    loss                 | -0.00258  |
|    n_updates            | 29540     |
|    policy_gradient_loss | 0.00944   |
|    std                  | 0.137     |
|    value_loss           | 0.0229    |
---------------------------------------
box reached target
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 2955    |
|    time_elapsed    | 9590    |
|    total_timesteps | 6051840 |
--------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 2956      |
|    time_elapsed         | 9593      |
|    total_timesteps      | 6053888   |
| train/                  |           |
|    approx_kl            | 2.7111118 |
|    clip_fraction        | 0.55      |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.15      |
|    explained_variance   | 0.455     |
|    learning_rate        | 0.00082   |
|    loss                 | 0.00447   |
|    n_updates            | 29550     |
|    policy_gradient_loss | 0.00104   |
|    std                  | 0.136     |
|    value_loss           | 0.115     |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 2957       |
|    time_elapsed         | 9596       |
|    total_timesteps      | 6055936    |
| train/                  |            |
|    approx_kl            | 0.15070562 |
|    clip_fraction        | 0.45       |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.16       |
|    explained_variance   | 0.616      |
|    learning_rate        | 0.000819   |
|    loss                 | 0.0763     |
|    n_updates            | 29560      |
|    policy_gradient_loss | 0.0125     |
|    std                  | 0.136      |
|    value_loss           | 0.065      |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 2958       |
|    time_elapsed         | 9599       |
|    total_timesteps      | 6057984    |
| train/                  |            |
|    approx_kl            | 0.06861158 |
|    clip_fraction        | 0.33       |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.16       |
|    explained_variance   | 0.686      |
|    learning_rate        | 0.000819   |
|    loss                 | -0.0101    |
|    n_updates            | 29570      |
|    policy_gradient_loss | 0.0116     |
|    std                  | 0.136      |
|    value_loss           | 0.0193     |
----------------------------------------
Eval num_timesteps=6060000, episode_reward=-0.70 +/- 0.37
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -0.702     |
| time/                   |            |
|    total_timesteps      | 6060000    |
| train/                  |            |
|    approx_kl            | 0.19956811 |
|    clip_fraction        | 0.398      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.16       |
|    explained_variance   | 0.592      |
|    learning_rate        | 0.000819   |
|    loss                 | -0.0124    |
|    n_updates            | 29580      |
|    policy_gradient_loss | 0.00747    |
|    std                  | 0.135      |
|    value_loss           | 0.0284     |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 2959    |
|    time_elapsed    | 9603    |
|    total_timesteps | 6060032 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 2960       |
|    time_elapsed         | 9606       |
|    total_timesteps      | 6062080    |
| train/                  |            |
|    approx_kl            | 0.27424127 |
|    clip_fraction        | 0.443      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.18       |
|    explained_variance   | 0.633      |
|    learning_rate        | 0.000818   |
|    loss                 | 0.00322    |
|    n_updates            | 29590      |
|    policy_gradient_loss | 0.0208     |
|    std                  | 0.134      |
|    value_loss           | 0.00573    |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 2961       |
|    time_elapsed         | 9609       |
|    total_timesteps      | 6064128    |
| train/                  |            |
|    approx_kl            | 0.18991384 |
|    clip_fraction        | 0.388      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.19       |
|    explained_variance   | 0.524      |
|    learning_rate        | 0.000818   |
|    loss                 | -0.000938  |
|    n_updates            | 29600      |
|    policy_gradient_loss | 0.006      |
|    std                  | 0.134      |
|    value_loss           | 0.00475    |
----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 2962      |
|    time_elapsed         | 9612      |
|    total_timesteps      | 6066176   |
| train/                  |           |
|    approx_kl            | 2.0593038 |
|    clip_fraction        | 0.518     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.2       |
|    explained_variance   | 0.835     |
|    learning_rate        | 0.000817  |
|    loss                 | 0.0424    |
|    n_updates            | 29610     |
|    policy_gradient_loss | -0.00105  |
|    std                  | 0.132     |
|    value_loss           | 0.0632    |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 2963       |
|    time_elapsed         | 9615       |
|    total_timesteps      | 6068224    |
| train/                  |            |
|    approx_kl            | 0.25597727 |
|    clip_fraction        | 0.441      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.23       |
|    explained_variance   | 0.731      |
|    learning_rate        | 0.000817   |
|    loss                 | -0.0244    |
|    n_updates            | 29620      |
|    policy_gradient_loss | 0.0244     |
|    std                  | 0.13       |
|    value_loss           | 0.0332     |
----------------------------------------
Eval num_timesteps=6070000, episode_reward=-1.01 +/- 0.03
Episode length: 300.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 300       |
|    mean_reward          | -1.01     |
| time/                   |           |
|    total_timesteps      | 6070000   |
| train/                  |           |
|    approx_kl            | 0.3686057 |
|    clip_fraction        | 0.495     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.23      |
|    explained_variance   | 0.61      |
|    learning_rate        | 0.000817  |
|    loss                 | 0.141     |
|    n_updates            | 29630     |
|    policy_gradient_loss | 0.0198    |
|    std                  | 0.132     |
|    value_loss           | 0.00435   |
---------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 2964    |
|    time_elapsed    | 9619    |
|    total_timesteps | 6070272 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 2965       |
|    time_elapsed         | 9622       |
|    total_timesteps      | 6072320    |
| train/                  |            |
|    approx_kl            | 0.58672225 |
|    clip_fraction        | 0.494      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.22       |
|    explained_variance   | 0.84       |
|    learning_rate        | 0.000816   |
|    loss                 | -0.0173    |
|    n_updates            | 29640      |
|    policy_gradient_loss | 0.00574    |
|    std                  | 0.131      |
|    value_loss           | 0.00948    |
----------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 2966      |
|    time_elapsed         | 9625      |
|    total_timesteps      | 6074368   |
| train/                  |           |
|    approx_kl            | 2.8396795 |
|    clip_fraction        | 0.476     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.23      |
|    explained_variance   | 0.78      |
|    learning_rate        | 0.000816  |
|    loss                 | -0.0279   |
|    n_updates            | 29650     |
|    policy_gradient_loss | -0.00366  |
|    std                  | 0.129     |
|    value_loss           | 0.00757   |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 2967       |
|    time_elapsed         | 9628       |
|    total_timesteps      | 6076416    |
| train/                  |            |
|    approx_kl            | 0.33522114 |
|    clip_fraction        | 0.464      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.22       |
|    explained_variance   | 0.871      |
|    learning_rate        | 0.000815   |
|    loss                 | -0.00865   |
|    n_updates            | 29660      |
|    policy_gradient_loss | 0.0251     |
|    std                  | 0.133      |
|    value_loss           | 0.00776    |
----------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 2968      |
|    time_elapsed         | 9631      |
|    total_timesteps      | 6078464   |
| train/                  |           |
|    approx_kl            | 0.2092179 |
|    clip_fraction        | 0.434     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.17      |
|    explained_variance   | 0.769     |
|    learning_rate        | 0.000815  |
|    loss                 | -0.0188   |
|    n_updates            | 29670     |
|    policy_gradient_loss | 0.00568   |
|    std                  | 0.135     |
|    value_loss           | 0.0056    |
---------------------------------------
box reached target
box reached target
Eval num_timesteps=6080000, episode_reward=-0.74 +/- 0.45
Episode length: 300.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 300       |
|    mean_reward          | -0.741    |
| time/                   |           |
|    total_timesteps      | 6080000   |
| train/                  |           |
|    approx_kl            | 0.3459009 |
|    clip_fraction        | 0.482     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.14      |
|    explained_variance   | 0.755     |
|    learning_rate        | 0.000815  |
|    loss                 | -0.00694  |
|    n_updates            | 29680     |
|    policy_gradient_loss | 0.0195    |
|    std                  | 0.138     |
|    value_loss           | 0.011     |
---------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 2969    |
|    time_elapsed    | 9635    |
|    total_timesteps | 6080512 |
--------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 2970      |
|    time_elapsed         | 9638      |
|    total_timesteps      | 6082560   |
| train/                  |           |
|    approx_kl            | 0.5377286 |
|    clip_fraction        | 0.548     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.1       |
|    explained_variance   | 0.536     |
|    learning_rate        | 0.000814  |
|    loss                 | 0.0115    |
|    n_updates            | 29690     |
|    policy_gradient_loss | 0.0493    |
|    std                  | 0.142     |
|    value_loss           | 0.0293    |
---------------------------------------
box reached target
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 2971       |
|    time_elapsed         | 9641       |
|    total_timesteps      | 6084608    |
| train/                  |            |
|    approx_kl            | 0.27214444 |
|    clip_fraction        | 0.437      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.07       |
|    explained_variance   | 0.059      |
|    learning_rate        | 0.000814   |
|    loss                 | -0.00616   |
|    n_updates            | 29700      |
|    policy_gradient_loss | 0.00651    |
|    std                  | 0.141      |
|    value_loss           | 0.00708    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 2972       |
|    time_elapsed         | 9644       |
|    total_timesteps      | 6086656    |
| train/                  |            |
|    approx_kl            | 0.72764325 |
|    clip_fraction        | 0.504      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.1        |
|    explained_variance   | 0.505      |
|    learning_rate        | 0.000814   |
|    loss                 | 0.00998    |
|    n_updates            | 29710      |
|    policy_gradient_loss | 0.02       |
|    std                  | 0.139      |
|    value_loss           | 0.064      |
----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 2973      |
|    time_elapsed         | 9647      |
|    total_timesteps      | 6088704   |
| train/                  |           |
|    approx_kl            | 0.2499296 |
|    clip_fraction        | 0.481     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.1       |
|    explained_variance   | 0.754     |
|    learning_rate        | 0.000813  |
|    loss                 | -0.0188   |
|    n_updates            | 29720     |
|    policy_gradient_loss | 0.0196    |
|    std                  | 0.141     |
|    value_loss           | 0.0251    |
---------------------------------------
box reached target
box reached target
box reached target
Eval num_timesteps=6090000, episode_reward=0.23 +/- 2.45
Episode length: 273.00 +/- 54.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 273        |
|    mean_reward          | 0.225      |
| time/                   |            |
|    total_timesteps      | 6090000    |
| train/                  |            |
|    approx_kl            | 0.23510808 |
|    clip_fraction        | 0.405      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.07       |
|    explained_variance   | 0.569      |
|    learning_rate        | 0.000813   |
|    loss                 | 0.0366     |
|    n_updates            | 29730      |
|    policy_gradient_loss | 0.0121     |
|    std                  | 0.142      |
|    value_loss           | 0.00399    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 2974    |
|    time_elapsed    | 9651    |
|    total_timesteps | 6090752 |
--------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 2975       |
|    time_elapsed         | 9654       |
|    total_timesteps      | 6092800    |
| train/                  |            |
|    approx_kl            | 0.52813816 |
|    clip_fraction        | 0.463      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.08       |
|    explained_variance   | 0.774      |
|    learning_rate        | 0.000812   |
|    loss                 | -0.016     |
|    n_updates            | 29740      |
|    policy_gradient_loss | 0.000345   |
|    std                  | 0.138      |
|    value_loss           | 0.0271     |
----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 2976      |
|    time_elapsed         | 9657      |
|    total_timesteps      | 6094848   |
| train/                  |           |
|    approx_kl            | 0.4482421 |
|    clip_fraction        | 0.468     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.14      |
|    explained_variance   | 0.774     |
|    learning_rate        | 0.000812  |
|    loss                 | 0.0314    |
|    n_updates            | 29750     |
|    policy_gradient_loss | 0.0122    |
|    std                  | 0.137     |
|    value_loss           | 0.0255    |
---------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 2977      |
|    time_elapsed         | 9660      |
|    total_timesteps      | 6096896   |
| train/                  |           |
|    approx_kl            | 0.9724062 |
|    clip_fraction        | 0.51      |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.16      |
|    explained_variance   | 0.75      |
|    learning_rate        | 0.000812  |
|    loss                 | -0.0392   |
|    n_updates            | 29760     |
|    policy_gradient_loss | -0.00812  |
|    std                  | 0.134     |
|    value_loss           | 0.0455    |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 2978       |
|    time_elapsed         | 9663       |
|    total_timesteps      | 6098944    |
| train/                  |            |
|    approx_kl            | 0.57199645 |
|    clip_fraction        | 0.499      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.19       |
|    explained_variance   | 0.428      |
|    learning_rate        | 0.000811   |
|    loss                 | -0.0284    |
|    n_updates            | 29770      |
|    policy_gradient_loss | 0.00264    |
|    std                  | 0.132      |
|    value_loss           | 0.0187     |
----------------------------------------
Eval num_timesteps=6100000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 300       |
|    mean_reward          | -1        |
| time/                   |           |
|    total_timesteps      | 6100000   |
| train/                  |           |
|    approx_kl            | 0.5933006 |
|    clip_fraction        | 0.489     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.18      |
|    explained_variance   | 0.814     |
|    learning_rate        | 0.000811  |
|    loss                 | -0.00213  |
|    n_updates            | 29780     |
|    policy_gradient_loss | 0.0148    |
|    std                  | 0.135     |
|    value_loss           | 0.00322   |
---------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 2979    |
|    time_elapsed    | 9667    |
|    total_timesteps | 6100992 |
--------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 2980      |
|    time_elapsed         | 9670      |
|    total_timesteps      | 6103040   |
| train/                  |           |
|    approx_kl            | 0.4684735 |
|    clip_fraction        | 0.465     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.18      |
|    explained_variance   | 0.77      |
|    learning_rate        | 0.00081   |
|    loss                 | -0.0295   |
|    n_updates            | 29790     |
|    policy_gradient_loss | -0.00408  |
|    std                  | 0.132     |
|    value_loss           | 0.00482   |
---------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 2981      |
|    time_elapsed         | 9673      |
|    total_timesteps      | 6105088   |
| train/                  |           |
|    approx_kl            | 0.3021683 |
|    clip_fraction        | 0.476     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.17      |
|    explained_variance   | 0.374     |
|    learning_rate        | 0.00081   |
|    loss                 | 0.0151    |
|    n_updates            | 29800     |
|    policy_gradient_loss | 0.0204    |
|    std                  | 0.137     |
|    value_loss           | 0.0854    |
---------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 2982      |
|    time_elapsed         | 9676      |
|    total_timesteps      | 6107136   |
| train/                  |           |
|    approx_kl            | 0.8125942 |
|    clip_fraction        | 0.557     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.18      |
|    explained_variance   | 0.563     |
|    learning_rate        | 0.00081   |
|    loss                 | 0.0328    |
|    n_updates            | 29810     |
|    policy_gradient_loss | 0.0132    |
|    std                  | 0.131     |
|    value_loss           | 0.00656   |
---------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 2983      |
|    time_elapsed         | 9679      |
|    total_timesteps      | 6109184   |
| train/                  |           |
|    approx_kl            | 0.5425787 |
|    clip_fraction        | 0.494     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.24      |
|    explained_variance   | 0.927     |
|    learning_rate        | 0.000809  |
|    loss                 | -0.0362   |
|    n_updates            | 29820     |
|    policy_gradient_loss | 0.01      |
|    std                  | 0.13      |
|    value_loss           | 0.00988   |
---------------------------------------
Eval num_timesteps=6110000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 300       |
|    mean_reward          | -1        |
| time/                   |           |
|    total_timesteps      | 6110000   |
| train/                  |           |
|    approx_kl            | 0.5201348 |
|    clip_fraction        | 0.449     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.24      |
|    explained_variance   | 0.905     |
|    learning_rate        | 0.000809  |
|    loss                 | -0.0128   |
|    n_updates            | 29830     |
|    policy_gradient_loss | 0.00321   |
|    std                  | 0.129     |
|    value_loss           | 0.0161    |
---------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 2984    |
|    time_elapsed    | 9683    |
|    total_timesteps | 6111232 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 2985       |
|    time_elapsed         | 9686       |
|    total_timesteps      | 6113280    |
| train/                  |            |
|    approx_kl            | 0.22897881 |
|    clip_fraction        | 0.418      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.26       |
|    explained_variance   | 0.59       |
|    learning_rate        | 0.000808   |
|    loss                 | 0.00515    |
|    n_updates            | 29840      |
|    policy_gradient_loss | 0.0179     |
|    std                  | 0.129      |
|    value_loss           | 0.00763    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 2986       |
|    time_elapsed         | 9690       |
|    total_timesteps      | 6115328    |
| train/                  |            |
|    approx_kl            | 0.35992712 |
|    clip_fraction        | 0.537      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.23       |
|    explained_variance   | 0.864      |
|    learning_rate        | 0.000808   |
|    loss                 | -0.00637   |
|    n_updates            | 29850      |
|    policy_gradient_loss | 0.0271     |
|    std                  | 0.132      |
|    value_loss           | 0.00434    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 2987       |
|    time_elapsed         | 9693       |
|    total_timesteps      | 6117376    |
| train/                  |            |
|    approx_kl            | 0.44407213 |
|    clip_fraction        | 0.438      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.21       |
|    explained_variance   | 0.694      |
|    learning_rate        | 0.000808   |
|    loss                 | -0.0164    |
|    n_updates            | 29860      |
|    policy_gradient_loss | 0.0163     |
|    std                  | 0.132      |
|    value_loss           | 0.00433    |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 2988       |
|    time_elapsed         | 9696       |
|    total_timesteps      | 6119424    |
| train/                  |            |
|    approx_kl            | 0.31321666 |
|    clip_fraction        | 0.47       |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.2        |
|    explained_variance   | 0.799      |
|    learning_rate        | 0.000807   |
|    loss                 | -0.00463   |
|    n_updates            | 29870      |
|    policy_gradient_loss | -0.000111  |
|    std                  | 0.133      |
|    value_loss           | 0.00398    |
----------------------------------------
box reached target
box reached target
Eval num_timesteps=6120000, episode_reward=0.18 +/- 2.47
Episode length: 271.20 +/- 57.60
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 271       |
|    mean_reward          | 0.176     |
| time/                   |           |
|    total_timesteps      | 6120000   |
| train/                  |           |
|    approx_kl            | 0.7150725 |
|    clip_fraction        | 0.515     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.19      |
|    explained_variance   | 0.666     |
|    learning_rate        | 0.000807  |
|    loss                 | 0.0757    |
|    n_updates            | 29880     |
|    policy_gradient_loss | 0.0176    |
|    std                  | 0.134     |
|    value_loss           | 0.0163    |
---------------------------------------
box reached target
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 2989    |
|    time_elapsed    | 9700    |
|    total_timesteps | 6121472 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 2990       |
|    time_elapsed         | 9703       |
|    total_timesteps      | 6123520    |
| train/                  |            |
|    approx_kl            | 0.53986824 |
|    clip_fraction        | 0.545      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.17       |
|    explained_variance   | 0.681      |
|    learning_rate        | 0.000806   |
|    loss                 | -0.0456    |
|    n_updates            | 29890      |
|    policy_gradient_loss | 0.0308     |
|    std                  | 0.134      |
|    value_loss           | 0.0393     |
----------------------------------------
box reached target
--------------------------------------
| time/                   |          |
|    fps                  | 631      |
|    iterations           | 2991     |
|    time_elapsed         | 9706     |
|    total_timesteps      | 6125568  |
| train/                  |          |
|    approx_kl            | 1.543748 |
|    clip_fraction        | 0.497    |
|    clip_range           | 0.2      |
|    entropy_loss         | 1.19     |
|    explained_variance   | 0.618    |
|    learning_rate        | 0.000806 |
|    loss                 | 0.0447   |
|    n_updates            | 29900    |
|    policy_gradient_loss | 0.00831  |
|    std                  | 0.132    |
|    value_loss           | 0.0216   |
--------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 2992      |
|    time_elapsed         | 9709      |
|    total_timesteps      | 6127616   |
| train/                  |           |
|    approx_kl            | 1.1574578 |
|    clip_fraction        | 0.535     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.21      |
|    explained_variance   | 0.737     |
|    learning_rate        | 0.000806  |
|    loss                 | 0.0409    |
|    n_updates            | 29910     |
|    policy_gradient_loss | 0.016     |
|    std                  | 0.131     |
|    value_loss           | 0.046     |
---------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 2993      |
|    time_elapsed         | 9712      |
|    total_timesteps      | 6129664   |
| train/                  |           |
|    approx_kl            | 4.2383723 |
|    clip_fraction        | 0.548     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.24      |
|    explained_variance   | 0.797     |
|    learning_rate        | 0.000805  |
|    loss                 | 0.0249    |
|    n_updates            | 29920     |
|    policy_gradient_loss | 0.00739   |
|    std                  | 0.129     |
|    value_loss           | 0.0134    |
---------------------------------------
Eval num_timesteps=6130000, episode_reward=-0.81 +/- 0.38
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -0.81      |
| time/                   |            |
|    total_timesteps      | 6130000    |
| train/                  |            |
|    approx_kl            | 0.33340204 |
|    clip_fraction        | 0.462      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.25       |
|    explained_variance   | 0.642      |
|    learning_rate        | 0.000805   |
|    loss                 | 0.00101    |
|    n_updates            | 29930      |
|    policy_gradient_loss | 0.000888   |
|    std                  | 0.129      |
|    value_loss           | 0.00563    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 2994    |
|    time_elapsed    | 9716    |
|    total_timesteps | 6131712 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 2995       |
|    time_elapsed         | 9719       |
|    total_timesteps      | 6133760    |
| train/                  |            |
|    approx_kl            | 0.26775032 |
|    clip_fraction        | 0.45       |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.23       |
|    explained_variance   | 0.53       |
|    learning_rate        | 0.000804   |
|    loss                 | -0.0229    |
|    n_updates            | 29940      |
|    policy_gradient_loss | 0.00373    |
|    std                  | 0.132      |
|    value_loss           | 0.00304    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 2996       |
|    time_elapsed         | 9722       |
|    total_timesteps      | 6135808    |
| train/                  |            |
|    approx_kl            | 0.24915326 |
|    clip_fraction        | 0.47       |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.19       |
|    explained_variance   | 0.102      |
|    learning_rate        | 0.000804   |
|    loss                 | 0.03       |
|    n_updates            | 29950      |
|    policy_gradient_loss | 0.0186     |
|    std                  | 0.134      |
|    value_loss           | 0.00896    |
----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 2997      |
|    time_elapsed         | 9725      |
|    total_timesteps      | 6137856   |
| train/                  |           |
|    approx_kl            | 0.6440953 |
|    clip_fraction        | 0.518     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.19      |
|    explained_variance   | 0.43      |
|    learning_rate        | 0.000804  |
|    loss                 | 0.00528   |
|    n_updates            | 29960     |
|    policy_gradient_loss | 0.0124    |
|    std                  | 0.132     |
|    value_loss           | 0.0129    |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 2998       |
|    time_elapsed         | 9728       |
|    total_timesteps      | 6139904    |
| train/                  |            |
|    approx_kl            | 0.26301247 |
|    clip_fraction        | 0.436      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.22       |
|    explained_variance   | -0.31      |
|    learning_rate        | 0.000803   |
|    loss                 | 0.0699     |
|    n_updates            | 29970      |
|    policy_gradient_loss | 0.00773    |
|    std                  | 0.13       |
|    value_loss           | 0.00595    |
----------------------------------------
box reached target
box reached target
Eval num_timesteps=6140000, episode_reward=1.67 +/- 2.94
Episode length: 237.00 +/- 77.30
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 237       |
|    mean_reward          | 1.67      |
| time/                   |           |
|    total_timesteps      | 6140000   |
| train/                  |           |
|    approx_kl            | 0.7824863 |
|    clip_fraction        | 0.512     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.23      |
|    explained_variance   | 0.79      |
|    learning_rate        | 0.000803  |
|    loss                 | -0.0317   |
|    n_updates            | 29980     |
|    policy_gradient_loss | 0.0164    |
|    std                  | 0.131     |
|    value_loss           | 0.00213   |
---------------------------------------
box reached target
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 2999    |
|    time_elapsed    | 9732    |
|    total_timesteps | 6141952 |
--------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3000      |
|    time_elapsed         | 9735      |
|    total_timesteps      | 6144000   |
| train/                  |           |
|    approx_kl            | 0.6372897 |
|    clip_fraction        | 0.541     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.24      |
|    explained_variance   | 0.617     |
|    learning_rate        | 0.000802  |
|    loss                 | 0.00232   |
|    n_updates            | 29990     |
|    policy_gradient_loss | 0.0264    |
|    std                  | 0.129     |
|    value_loss           | 0.0112    |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3001       |
|    time_elapsed         | 9738       |
|    total_timesteps      | 6146048    |
| train/                  |            |
|    approx_kl            | 0.66003406 |
|    clip_fraction        | 0.498      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.25       |
|    explained_variance   | 0.431      |
|    learning_rate        | 0.000802   |
|    loss                 | -0.0206    |
|    n_updates            | 30000      |
|    policy_gradient_loss | 0.0136     |
|    std                  | 0.129      |
|    value_loss           | 0.00163    |
----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3002      |
|    time_elapsed         | 9741      |
|    total_timesteps      | 6148096   |
| train/                  |           |
|    approx_kl            | 1.0383949 |
|    clip_fraction        | 0.498     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.29      |
|    explained_variance   | 0.441     |
|    learning_rate        | 0.000802  |
|    loss                 | 0.00197   |
|    n_updates            | 30010     |
|    policy_gradient_loss | 0.00341   |
|    std                  | 0.124     |
|    value_loss           | 0.00205   |
---------------------------------------
Eval num_timesteps=6150000, episode_reward=-1.05 +/- 0.11
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1.05      |
| time/                   |            |
|    total_timesteps      | 6150000    |
| train/                  |            |
|    approx_kl            | 0.23612376 |
|    clip_fraction        | 0.474      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.31       |
|    explained_variance   | 0.815      |
|    learning_rate        | 0.000801   |
|    loss                 | 0.00188    |
|    n_updates            | 30020      |
|    policy_gradient_loss | 0.0253     |
|    std                  | 0.126      |
|    value_loss           | 0.00875    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 3003    |
|    time_elapsed    | 9745    |
|    total_timesteps | 6150144 |
--------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3004      |
|    time_elapsed         | 9748      |
|    total_timesteps      | 6152192   |
| train/                  |           |
|    approx_kl            | 0.5614486 |
|    clip_fraction        | 0.477     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.29      |
|    explained_variance   | 0.249     |
|    learning_rate        | 0.000801  |
|    loss                 | 0.0748    |
|    n_updates            | 30030     |
|    policy_gradient_loss | 0.0411    |
|    std                  | 0.127     |
|    value_loss           | 0.00553   |
---------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3005       |
|    time_elapsed         | 9751       |
|    total_timesteps      | 6154240    |
| train/                  |            |
|    approx_kl            | 0.63700616 |
|    clip_fraction        | 0.448      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.31       |
|    explained_variance   | 0.715      |
|    learning_rate        | 0.0008     |
|    loss                 | -0.0467    |
|    n_updates            | 30040      |
|    policy_gradient_loss | 0.0027     |
|    std                  | 0.124      |
|    value_loss           | 0.0018     |
----------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3006      |
|    time_elapsed         | 9754      |
|    total_timesteps      | 6156288   |
| train/                  |           |
|    approx_kl            | 0.4950626 |
|    clip_fraction        | 0.503     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.33      |
|    explained_variance   | 0.387     |
|    learning_rate        | 0.0008    |
|    loss                 | 0.00324   |
|    n_updates            | 30050     |
|    policy_gradient_loss | 0.0125    |
|    std                  | 0.124     |
|    value_loss           | 0.00999   |
---------------------------------------
box reached target
--------------------------------------
| time/                   |          |
|    fps                  | 631      |
|    iterations           | 3007     |
|    time_elapsed         | 9757     |
|    total_timesteps      | 6158336  |
| train/                  |          |
|    approx_kl            | 2.447172 |
|    clip_fraction        | 0.492    |
|    clip_range           | 0.2      |
|    entropy_loss         | 1.34     |
|    explained_variance   | 0.725    |
|    learning_rate        | 0.0008   |
|    loss                 | 0.0802   |
|    n_updates            | 30060    |
|    policy_gradient_loss | 0.0218   |
|    std                  | 0.122    |
|    value_loss           | 0.0883   |
--------------------------------------
box reached target
Eval num_timesteps=6160000, episode_reward=0.26 +/- 2.52
Episode length: 277.80 +/- 44.40
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 278       |
|    mean_reward          | 0.259     |
| time/                   |           |
|    total_timesteps      | 6160000   |
| train/                  |           |
|    approx_kl            | 0.7140752 |
|    clip_fraction        | 0.457     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.34      |
|    explained_variance   | 0.498     |
|    learning_rate        | 0.000799  |
|    loss                 | 0.0352    |
|    n_updates            | 30070     |
|    policy_gradient_loss | 0.0279    |
|    std                  | 0.124     |
|    value_loss           | 0.0322    |
---------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 3008    |
|    time_elapsed    | 9761    |
|    total_timesteps | 6160384 |
--------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3009      |
|    time_elapsed         | 9764      |
|    total_timesteps      | 6162432   |
| train/                  |           |
|    approx_kl            | 6.8993874 |
|    clip_fraction        | 0.566     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.37      |
|    explained_variance   | 0.457     |
|    learning_rate        | 0.000799  |
|    loss                 | 0.00685   |
|    n_updates            | 30080     |
|    policy_gradient_loss | 0.0042    |
|    std                  | 0.119     |
|    value_loss           | 0.00265   |
---------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3010      |
|    time_elapsed         | 9767      |
|    total_timesteps      | 6164480   |
| train/                  |           |
|    approx_kl            | 0.5966233 |
|    clip_fraction        | 0.542     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.43      |
|    explained_variance   | 0.73      |
|    learning_rate        | 0.000798  |
|    loss                 | 0.0565    |
|    n_updates            | 30090     |
|    policy_gradient_loss | 0.0216    |
|    std                  | 0.118     |
|    value_loss           | 0.0281    |
---------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3011      |
|    time_elapsed         | 9770      |
|    total_timesteps      | 6166528   |
| train/                  |           |
|    approx_kl            | 1.6215732 |
|    clip_fraction        | 0.568     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.44      |
|    explained_variance   | 0.318     |
|    learning_rate        | 0.000798  |
|    loss                 | -0.0479   |
|    n_updates            | 30100     |
|    policy_gradient_loss | 0.0282    |
|    std                  | 0.116     |
|    value_loss           | 0.0868    |
---------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3012       |
|    time_elapsed         | 9773       |
|    total_timesteps      | 6168576    |
| train/                  |            |
|    approx_kl            | 0.39692461 |
|    clip_fraction        | 0.512      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.46       |
|    explained_variance   | 0.765      |
|    learning_rate        | 0.000798   |
|    loss                 | 0.0328     |
|    n_updates            | 30110      |
|    policy_gradient_loss | 0.0229     |
|    std                  | 0.117      |
|    value_loss           | 0.0131     |
----------------------------------------
Eval num_timesteps=6170000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 300       |
|    mean_reward          | -1        |
| time/                   |           |
|    total_timesteps      | 6170000   |
| train/                  |           |
|    approx_kl            | 0.4504573 |
|    clip_fraction        | 0.488     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.5       |
|    explained_variance   | -0.0844   |
|    learning_rate        | 0.000797  |
|    loss                 | 0.0535    |
|    n_updates            | 30120     |
|    policy_gradient_loss | 0.0146    |
|    std                  | 0.113     |
|    value_loss           | 0.0853    |
---------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 3013    |
|    time_elapsed    | 9777    |
|    total_timesteps | 6170624 |
--------------------------------
box reached target
--------------------------------------
| time/                   |          |
|    fps                  | 631      |
|    iterations           | 3014     |
|    time_elapsed         | 9780     |
|    total_timesteps      | 6172672  |
| train/                  |          |
|    approx_kl            | 0.866597 |
|    clip_fraction        | 0.542    |
|    clip_range           | 0.2      |
|    entropy_loss         | 1.53     |
|    explained_variance   | 0.598    |
|    learning_rate        | 0.000797 |
|    loss                 | 0.00119  |
|    n_updates            | 30130    |
|    policy_gradient_loss | 0.00582  |
|    std                  | 0.112    |
|    value_loss           | 0.0234   |
--------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3015      |
|    time_elapsed         | 9783      |
|    total_timesteps      | 6174720   |
| train/                  |           |
|    approx_kl            | 0.5716866 |
|    clip_fraction        | 0.51      |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.53      |
|    explained_variance   | 0.861     |
|    learning_rate        | 0.000796  |
|    loss                 | 0.00484   |
|    n_updates            | 30140     |
|    policy_gradient_loss | 0.00758   |
|    std                  | 0.113     |
|    value_loss           | 0.0297    |
---------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3016      |
|    time_elapsed         | 9786      |
|    total_timesteps      | 6176768   |
| train/                  |           |
|    approx_kl            | 0.5513565 |
|    clip_fraction        | 0.441     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.54      |
|    explained_variance   | -0.116    |
|    learning_rate        | 0.000796  |
|    loss                 | 0.117     |
|    n_updates            | 30150     |
|    policy_gradient_loss | 0.0149    |
|    std                  | 0.112     |
|    value_loss           | 0.00624   |
---------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3017      |
|    time_elapsed         | 9789      |
|    total_timesteps      | 6178816   |
| train/                  |           |
|    approx_kl            | 1.5204246 |
|    clip_fraction        | 0.524     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.55      |
|    explained_variance   | 0.395     |
|    learning_rate        | 0.000796  |
|    loss                 | 0.0382    |
|    n_updates            | 30160     |
|    policy_gradient_loss | 0.0206    |
|    std                  | 0.11      |
|    value_loss           | 0.00445   |
---------------------------------------
box reached target
Eval num_timesteps=6180000, episode_reward=0.23 +/- 2.60
Episode length: 275.40 +/- 49.20
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 275        |
|    mean_reward          | 0.231      |
| time/                   |            |
|    total_timesteps      | 6180000    |
| train/                  |            |
|    approx_kl            | 0.97473884 |
|    clip_fraction        | 0.534      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.56       |
|    explained_variance   | 0.717      |
|    learning_rate        | 0.000795   |
|    loss                 | 0.00403    |
|    n_updates            | 30170      |
|    policy_gradient_loss | 0.0218     |
|    std                  | 0.111      |
|    value_loss           | 0.00982    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 3018    |
|    time_elapsed    | 9793    |
|    total_timesteps | 6180864 |
--------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3019      |
|    time_elapsed         | 9796      |
|    total_timesteps      | 6182912   |
| train/                  |           |
|    approx_kl            | 2.0433793 |
|    clip_fraction        | 0.549     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.6       |
|    explained_variance   | 0.599     |
|    learning_rate        | 0.000795  |
|    loss                 | -0.0349   |
|    n_updates            | 30180     |
|    policy_gradient_loss | 0.0109    |
|    std                  | 0.107     |
|    value_loss           | 0.016     |
---------------------------------------
box reached target
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3020      |
|    time_elapsed         | 9799      |
|    total_timesteps      | 6184960   |
| train/                  |           |
|    approx_kl            | 0.4979776 |
|    clip_fraction        | 0.489     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.62      |
|    explained_variance   | 0.792     |
|    learning_rate        | 0.000794  |
|    loss                 | 0.0758    |
|    n_updates            | 30190     |
|    policy_gradient_loss | 0.0279    |
|    std                  | 0.109     |
|    value_loss           | 0.013     |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3021       |
|    time_elapsed         | 9802       |
|    total_timesteps      | 6187008    |
| train/                  |            |
|    approx_kl            | 0.33069336 |
|    clip_fraction        | 0.524      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.62       |
|    explained_variance   | 0.726      |
|    learning_rate        | 0.000794   |
|    loss                 | 0.0128     |
|    n_updates            | 30200      |
|    policy_gradient_loss | 0.0125     |
|    std                  | 0.107      |
|    value_loss           | 0.0825     |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3022       |
|    time_elapsed         | 9806       |
|    total_timesteps      | 6189056    |
| train/                  |            |
|    approx_kl            | 0.45094317 |
|    clip_fraction        | 0.463      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.61       |
|    explained_variance   | 0.891      |
|    learning_rate        | 0.000794   |
|    loss                 | -0.0354    |
|    n_updates            | 30210      |
|    policy_gradient_loss | 0.0102     |
|    std                  | 0.109      |
|    value_loss           | 0.0122     |
----------------------------------------
Eval num_timesteps=6190000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
--------------------------------------
| eval/                   |          |
|    mean_ep_length       | 300      |
|    mean_reward          | -1       |
| time/                   |          |
|    total_timesteps      | 6190000  |
| train/                  |          |
|    approx_kl            | 0.52772  |
|    clip_fraction        | 0.539    |
|    clip_range           | 0.2      |
|    entropy_loss         | 1.58     |
|    explained_variance   | 0.824    |
|    learning_rate        | 0.000793 |
|    loss                 | 0.00147  |
|    n_updates            | 30220    |
|    policy_gradient_loss | 0.0248   |
|    std                  | 0.109    |
|    value_loss           | 0.0149   |
--------------------------------------
box reached target
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 3023    |
|    time_elapsed    | 9809    |
|    total_timesteps | 6191104 |
--------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3024      |
|    time_elapsed         | 9813      |
|    total_timesteps      | 6193152   |
| train/                  |           |
|    approx_kl            | 1.9123898 |
|    clip_fraction        | 0.61      |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.61      |
|    explained_variance   | 0.123     |
|    learning_rate        | 0.000793  |
|    loss                 | 0.0295    |
|    n_updates            | 30230     |
|    policy_gradient_loss | 0.0174    |
|    std                  | 0.107     |
|    value_loss           | 0.0238    |
---------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3025      |
|    time_elapsed         | 9816      |
|    total_timesteps      | 6195200   |
| train/                  |           |
|    approx_kl            | 1.3464663 |
|    clip_fraction        | 0.536     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.61      |
|    explained_variance   | 0.563     |
|    learning_rate        | 0.000792  |
|    loss                 | 0.0091    |
|    n_updates            | 30240     |
|    policy_gradient_loss | 0.00945   |
|    std                  | 0.107     |
|    value_loss           | 0.0103    |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3026       |
|    time_elapsed         | 9819       |
|    total_timesteps      | 6197248    |
| train/                  |            |
|    approx_kl            | 0.20444234 |
|    clip_fraction        | 0.488      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.57       |
|    explained_variance   | 0.327      |
|    learning_rate        | 0.000792   |
|    loss                 | 0.0578     |
|    n_updates            | 30250      |
|    policy_gradient_loss | 0.0191     |
|    std                  | 0.112      |
|    value_loss           | 0.0083     |
----------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3027      |
|    time_elapsed         | 9822      |
|    total_timesteps      | 6199296   |
| train/                  |           |
|    approx_kl            | 0.4076729 |
|    clip_fraction        | 0.486     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.52      |
|    explained_variance   | -0.693    |
|    learning_rate        | 0.000792  |
|    loss                 | 0.067     |
|    n_updates            | 30260     |
|    policy_gradient_loss | 0.0163    |
|    std                  | 0.112     |
|    value_loss           | 0.00538   |
---------------------------------------
box reached target
Eval num_timesteps=6200000, episode_reward=-1.01 +/- 0.02
Episode length: 300.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 300       |
|    mean_reward          | -1.01     |
| time/                   |           |
|    total_timesteps      | 6200000   |
| train/                  |           |
|    approx_kl            | 0.6564987 |
|    clip_fraction        | 0.561     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.5       |
|    explained_variance   | 0.71      |
|    learning_rate        | 0.000791  |
|    loss                 | 0.0201    |
|    n_updates            | 30270     |
|    policy_gradient_loss | 0.0371    |
|    std                  | 0.116     |
|    value_loss           | 0.0224    |
---------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 3028    |
|    time_elapsed    | 9826    |
|    total_timesteps | 6201344 |
--------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3029      |
|    time_elapsed         | 9829      |
|    total_timesteps      | 6203392   |
| train/                  |           |
|    approx_kl            | 1.1257181 |
|    clip_fraction        | 0.571     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.44      |
|    explained_variance   | 0.536     |
|    learning_rate        | 0.000791  |
|    loss                 | 0.0209    |
|    n_updates            | 30280     |
|    policy_gradient_loss | 0.0334    |
|    std                  | 0.119     |
|    value_loss           | 0.0173    |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3030       |
|    time_elapsed         | 9832       |
|    total_timesteps      | 6205440    |
| train/                  |            |
|    approx_kl            | 0.32621038 |
|    clip_fraction        | 0.499      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.41       |
|    explained_variance   | -0.127     |
|    learning_rate        | 0.00079    |
|    loss                 | 0.117      |
|    n_updates            | 30290      |
|    policy_gradient_loss | 0.0258     |
|    std                  | 0.12       |
|    value_loss           | 0.0166     |
----------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3031      |
|    time_elapsed         | 9835      |
|    total_timesteps      | 6207488   |
| train/                  |           |
|    approx_kl            | 1.6746447 |
|    clip_fraction        | 0.468     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.44      |
|    explained_variance   | 0.679     |
|    learning_rate        | 0.00079   |
|    loss                 | -0.0155   |
|    n_updates            | 30300     |
|    policy_gradient_loss | 0.0333    |
|    std                  | 0.116     |
|    value_loss           | 0.0105    |
---------------------------------------
--------------------------------------
| time/                   |          |
|    fps                  | 631      |
|    iterations           | 3032     |
|    time_elapsed         | 9838     |
|    total_timesteps      | 6209536  |
| train/                  |          |
|    approx_kl            | 0.174409 |
|    clip_fraction        | 0.453    |
|    clip_range           | 0.2      |
|    entropy_loss         | 1.52     |
|    explained_variance   | 0.799    |
|    learning_rate        | 0.00079  |
|    loss                 | -0.00269 |
|    n_updates            | 30310    |
|    policy_gradient_loss | 0.0245   |
|    std                  | 0.113    |
|    value_loss           | 0.0154   |
--------------------------------------
box reached target
Eval num_timesteps=6210000, episode_reward=-0.81 +/- 0.28
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -0.814     |
| time/                   |            |
|    total_timesteps      | 6210000    |
| train/                  |            |
|    approx_kl            | 0.35775554 |
|    clip_fraction        | 0.488      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.54       |
|    explained_variance   | 0.703      |
|    learning_rate        | 0.000789   |
|    loss                 | 0.0706     |
|    n_updates            | 30320      |
|    policy_gradient_loss | 0.0354     |
|    std                  | 0.112      |
|    value_loss           | 0.00622    |
----------------------------------------
box reached target
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 3033    |
|    time_elapsed    | 9842    |
|    total_timesteps | 6211584 |
--------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3034      |
|    time_elapsed         | 9845      |
|    total_timesteps      | 6213632   |
| train/                  |           |
|    approx_kl            | 0.7161008 |
|    clip_fraction        | 0.58      |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.52      |
|    explained_variance   | 0.658     |
|    learning_rate        | 0.000789  |
|    loss                 | -0.0571   |
|    n_updates            | 30330     |
|    policy_gradient_loss | 0.0372    |
|    std                  | 0.113     |
|    value_loss           | 0.0739    |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3035       |
|    time_elapsed         | 9848       |
|    total_timesteps      | 6215680    |
| train/                  |            |
|    approx_kl            | 0.40287903 |
|    clip_fraction        | 0.48       |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.49       |
|    explained_variance   | 0.384      |
|    learning_rate        | 0.000788   |
|    loss                 | 0.0348     |
|    n_updates            | 30340      |
|    policy_gradient_loss | 0.0211     |
|    std                  | 0.116      |
|    value_loss           | 0.0114     |
----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3036      |
|    time_elapsed         | 9851      |
|    total_timesteps      | 6217728   |
| train/                  |           |
|    approx_kl            | 1.3388174 |
|    clip_fraction        | 0.543     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.47      |
|    explained_variance   | 0.174     |
|    learning_rate        | 0.000788  |
|    loss                 | -0.0251   |
|    n_updates            | 30350     |
|    policy_gradient_loss | 0.016     |
|    std                  | 0.115     |
|    value_loss           | 0.0049    |
---------------------------------------
box reached target
--------------------------------------
| time/                   |          |
|    fps                  | 631      |
|    iterations           | 3037     |
|    time_elapsed         | 9854     |
|    total_timesteps      | 6219776  |
| train/                  |          |
|    approx_kl            | 0.710279 |
|    clip_fraction        | 0.479    |
|    clip_range           | 0.2      |
|    entropy_loss         | 1.5      |
|    explained_variance   | 0.707    |
|    learning_rate        | 0.000788 |
|    loss                 | 0.183    |
|    n_updates            | 30360    |
|    policy_gradient_loss | 0.00853  |
|    std                  | 0.114    |
|    value_loss           | 0.0129   |
--------------------------------------
box reached target
box reached target
Eval num_timesteps=6220000, episode_reward=1.52 +/- 3.12
Episode length: 258.20 +/- 51.31
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 258        |
|    mean_reward          | 1.52       |
| time/                   |            |
|    total_timesteps      | 6220000    |
| train/                  |            |
|    approx_kl            | 0.41909176 |
|    clip_fraction        | 0.512      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.51       |
|    explained_variance   | 0.686      |
|    learning_rate        | 0.000787   |
|    loss                 | -0.0292    |
|    n_updates            | 30370      |
|    policy_gradient_loss | 0.0172     |
|    std                  | 0.113      |
|    value_loss           | 0.0145     |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 3038    |
|    time_elapsed    | 9858    |
|    total_timesteps | 6221824 |
--------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3039      |
|    time_elapsed         | 9861      |
|    total_timesteps      | 6223872   |
| train/                  |           |
|    approx_kl            | 0.9922688 |
|    clip_fraction        | 0.512     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.49      |
|    explained_variance   | 0.709     |
|    learning_rate        | 0.000787  |
|    loss                 | 0.00609   |
|    n_updates            | 30380     |
|    policy_gradient_loss | 0.0225    |
|    std                  | 0.115     |
|    value_loss           | 0.00607   |
---------------------------------------
--------------------------------------
| time/                   |          |
|    fps                  | 631      |
|    iterations           | 3040     |
|    time_elapsed         | 9864     |
|    total_timesteps      | 6225920  |
| train/                  |          |
|    approx_kl            | 0.322927 |
|    clip_fraction        | 0.49     |
|    clip_range           | 0.2      |
|    entropy_loss         | 1.47     |
|    explained_variance   | 0.476    |
|    learning_rate        | 0.000786 |
|    loss                 | -0.0287  |
|    n_updates            | 30390    |
|    policy_gradient_loss | 0.0325   |
|    std                  | 0.116    |
|    value_loss           | 0.0257   |
--------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3041      |
|    time_elapsed         | 9867      |
|    total_timesteps      | 6227968   |
| train/                  |           |
|    approx_kl            | 1.0370455 |
|    clip_fraction        | 0.485     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.46      |
|    explained_variance   | 0.591     |
|    learning_rate        | 0.000786  |
|    loss                 | -0.0371   |
|    n_updates            | 30400     |
|    policy_gradient_loss | 0.00757   |
|    std                  | 0.115     |
|    value_loss           | 0.00983   |
---------------------------------------
box reached target
Eval num_timesteps=6230000, episode_reward=0.30 +/- 2.59
Episode length: 276.00 +/- 48.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 276       |
|    mean_reward          | 0.297     |
| time/                   |           |
|    total_timesteps      | 6230000   |
| train/                  |           |
|    approx_kl            | 0.6877003 |
|    clip_fraction        | 0.534     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.47      |
|    explained_variance   | 0.697     |
|    learning_rate        | 0.000786  |
|    loss                 | 0.0589    |
|    n_updates            | 30410     |
|    policy_gradient_loss | 0.0289    |
|    std                  | 0.117     |
|    value_loss           | 0.00894   |
---------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 3042    |
|    time_elapsed    | 9871    |
|    total_timesteps | 6230016 |
--------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3043      |
|    time_elapsed         | 9874      |
|    total_timesteps      | 6232064   |
| train/                  |           |
|    approx_kl            | 0.6808491 |
|    clip_fraction        | 0.459     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.44      |
|    explained_variance   | 0.485     |
|    learning_rate        | 0.000785  |
|    loss                 | -0.0202   |
|    n_updates            | 30420     |
|    policy_gradient_loss | 0.00385   |
|    std                  | 0.118     |
|    value_loss           | 0.00568   |
---------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3044      |
|    time_elapsed         | 9877      |
|    total_timesteps      | 6234112   |
| train/                  |           |
|    approx_kl            | 0.5384084 |
|    clip_fraction        | 0.537     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.41      |
|    explained_variance   | 0.551     |
|    learning_rate        | 0.000785  |
|    loss                 | 0.00244   |
|    n_updates            | 30430     |
|    policy_gradient_loss | 0.0115    |
|    std                  | 0.119     |
|    value_loss           | 0.019     |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3045       |
|    time_elapsed         | 9880       |
|    total_timesteps      | 6236160    |
| train/                  |            |
|    approx_kl            | 0.33454618 |
|    clip_fraction        | 0.46       |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.42       |
|    explained_variance   | 0.654      |
|    learning_rate        | 0.000784   |
|    loss                 | -0.00226   |
|    n_updates            | 30440      |
|    policy_gradient_loss | 0.0157     |
|    std                  | 0.119      |
|    value_loss           | 0.00903    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3046       |
|    time_elapsed         | 9883       |
|    total_timesteps      | 6238208    |
| train/                  |            |
|    approx_kl            | 0.85386825 |
|    clip_fraction        | 0.466      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.45       |
|    explained_variance   | 0.812      |
|    learning_rate        | 0.000784   |
|    loss                 | 0.0249     |
|    n_updates            | 30450      |
|    policy_gradient_loss | -0.0146    |
|    std                  | 0.115      |
|    value_loss           | 0.00752    |
----------------------------------------
Eval num_timesteps=6240000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1         |
| time/                   |            |
|    total_timesteps      | 6240000    |
| train/                  |            |
|    approx_kl            | 0.40067276 |
|    clip_fraction        | 0.472      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.5        |
|    explained_variance   | 0.471      |
|    learning_rate        | 0.000784   |
|    loss                 | -0.0106    |
|    n_updates            | 30460      |
|    policy_gradient_loss | 0.00845    |
|    std                  | 0.114      |
|    value_loss           | 0.00944    |
----------------------------------------
box reached target
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 3047    |
|    time_elapsed    | 9887    |
|    total_timesteps | 6240256 |
--------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3048      |
|    time_elapsed         | 9890      |
|    total_timesteps      | 6242304   |
| train/                  |           |
|    approx_kl            | 1.0283179 |
|    clip_fraction        | 0.481     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.52      |
|    explained_variance   | 0.749     |
|    learning_rate        | 0.000783  |
|    loss                 | -0.0274   |
|    n_updates            | 30470     |
|    policy_gradient_loss | -0.00168  |
|    std                  | 0.111     |
|    value_loss           | 0.0233    |
---------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3049      |
|    time_elapsed         | 9893      |
|    total_timesteps      | 6244352   |
| train/                  |           |
|    approx_kl            | 1.0638037 |
|    clip_fraction        | 0.524     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.58      |
|    explained_variance   | 0.75      |
|    learning_rate        | 0.000783  |
|    loss                 | -0.0347   |
|    n_updates            | 30480     |
|    policy_gradient_loss | 0.00992   |
|    std                  | 0.108     |
|    value_loss           | 0.0121    |
---------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3050      |
|    time_elapsed         | 9896      |
|    total_timesteps      | 6246400   |
| train/                  |           |
|    approx_kl            | 0.4386219 |
|    clip_fraction        | 0.482     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.63      |
|    explained_variance   | 0.259     |
|    learning_rate        | 0.000782  |
|    loss                 | 0.00145   |
|    n_updates            | 30490     |
|    policy_gradient_loss | 0.0213    |
|    std                  | 0.106     |
|    value_loss           | 0.101     |
---------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3051      |
|    time_elapsed         | 9899      |
|    total_timesteps      | 6248448   |
| train/                  |           |
|    approx_kl            | 0.8050521 |
|    clip_fraction        | 0.503     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.62      |
|    explained_variance   | -1.36     |
|    learning_rate        | 0.000782  |
|    loss                 | -0.0253   |
|    n_updates            | 30500     |
|    policy_gradient_loss | 0.0157    |
|    std                  | 0.106     |
|    value_loss           | 0.00369   |
---------------------------------------
Eval num_timesteps=6250000, episode_reward=-1.09 +/- 0.18
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1.09      |
| time/                   |            |
|    total_timesteps      | 6250000    |
| train/                  |            |
|    approx_kl            | 0.49101037 |
|    clip_fraction        | 0.554      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.61       |
|    explained_variance   | 0.621      |
|    learning_rate        | 0.000782   |
|    loss                 | 0.0219     |
|    n_updates            | 30510      |
|    policy_gradient_loss | 0.0314     |
|    std                  | 0.109      |
|    value_loss           | 0.0311     |
----------------------------------------
box reached target
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 3052    |
|    time_elapsed    | 9903    |
|    total_timesteps | 6250496 |
--------------------------------
box reached target
--------------------------------------
| time/                   |          |
|    fps                  | 631      |
|    iterations           | 3053     |
|    time_elapsed         | 9906     |
|    total_timesteps      | 6252544  |
| train/                  |          |
|    approx_kl            | 1.112042 |
|    clip_fraction        | 0.508    |
|    clip_range           | 0.2      |
|    entropy_loss         | 1.58     |
|    explained_variance   | 0.367    |
|    learning_rate        | 0.000781 |
|    loss                 | -0.00306 |
|    n_updates            | 30520    |
|    policy_gradient_loss | 0.043    |
|    std                  | 0.11     |
|    value_loss           | 0.021    |
--------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3054       |
|    time_elapsed         | 9909       |
|    total_timesteps      | 6254592    |
| train/                  |            |
|    approx_kl            | 0.53134906 |
|    clip_fraction        | 0.522      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.58       |
|    explained_variance   | 0.821      |
|    learning_rate        | 0.000781   |
|    loss                 | 0.122      |
|    n_updates            | 30530      |
|    policy_gradient_loss | 0.0168     |
|    std                  | 0.109      |
|    value_loss           | 0.00706    |
----------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3055      |
|    time_elapsed         | 9912      |
|    total_timesteps      | 6256640   |
| train/                  |           |
|    approx_kl            | 3.3038905 |
|    clip_fraction        | 0.623     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.56      |
|    explained_variance   | 0.716     |
|    learning_rate        | 0.00078   |
|    loss                 | -0.00394  |
|    n_updates            | 30540     |
|    policy_gradient_loss | 0.0853    |
|    std                  | 0.111     |
|    value_loss           | 0.00459   |
---------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3056       |
|    time_elapsed         | 9915       |
|    total_timesteps      | 6258688    |
| train/                  |            |
|    approx_kl            | 0.67405057 |
|    clip_fraction        | 0.564      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.52       |
|    explained_variance   | 0.386      |
|    learning_rate        | 0.00078    |
|    loss                 | 0.00843    |
|    n_updates            | 30550      |
|    policy_gradient_loss | 0.0371     |
|    std                  | 0.114      |
|    value_loss           | 0.132      |
----------------------------------------
box reached target
Eval num_timesteps=6260000, episode_reward=0.49 +/- 2.50
Episode length: 274.80 +/- 50.40
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 275       |
|    mean_reward          | 0.49      |
| time/                   |           |
|    total_timesteps      | 6260000   |
| train/                  |           |
|    approx_kl            | 1.7099762 |
|    clip_fraction        | 0.57      |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.51      |
|    explained_variance   | 0.756     |
|    learning_rate        | 0.00078   |
|    loss                 | -0.0117   |
|    n_updates            | 30560     |
|    policy_gradient_loss | 0.00747   |
|    std                  | 0.113     |
|    value_loss           | 0.0158    |
---------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 3057    |
|    time_elapsed    | 9919    |
|    total_timesteps | 6260736 |
--------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3058      |
|    time_elapsed         | 9922      |
|    total_timesteps      | 6262784   |
| train/                  |           |
|    approx_kl            | 0.9891542 |
|    clip_fraction        | 0.563     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.53      |
|    explained_variance   | 0.74      |
|    learning_rate        | 0.000779  |
|    loss                 | -0.0361   |
|    n_updates            | 30570     |
|    policy_gradient_loss | 0.00216   |
|    std                  | 0.111     |
|    value_loss           | 0.00983   |
---------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3059      |
|    time_elapsed         | 9925      |
|    total_timesteps      | 6264832   |
| train/                  |           |
|    approx_kl            | 0.4194368 |
|    clip_fraction        | 0.484     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.48      |
|    explained_variance   | 0.163     |
|    learning_rate        | 0.000779  |
|    loss                 | 0.0728    |
|    n_updates            | 30580     |
|    policy_gradient_loss | 0.019     |
|    std                  | 0.117     |
|    value_loss           | 0.00294   |
---------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3060      |
|    time_elapsed         | 9928      |
|    total_timesteps      | 6266880   |
| train/                  |           |
|    approx_kl            | 1.5938016 |
|    clip_fraction        | 0.54      |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.44      |
|    explained_variance   | 0.235     |
|    learning_rate        | 0.000778  |
|    loss                 | 0.0212    |
|    n_updates            | 30590     |
|    policy_gradient_loss | 0.0144    |
|    std                  | 0.117     |
|    value_loss           | 0.00174   |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3061       |
|    time_elapsed         | 9932       |
|    total_timesteps      | 6268928    |
| train/                  |            |
|    approx_kl            | 0.89642227 |
|    clip_fraction        | 0.503      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.49       |
|    explained_variance   | 0.424      |
|    learning_rate        | 0.000778   |
|    loss                 | 0.0339     |
|    n_updates            | 30600      |
|    policy_gradient_loss | 0.0172     |
|    std                  | 0.114      |
|    value_loss           | 0.0136     |
----------------------------------------
Eval num_timesteps=6270000, episode_reward=-0.73 +/- 0.42
Episode length: 300.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 300       |
|    mean_reward          | -0.726    |
| time/                   |           |
|    total_timesteps      | 6270000   |
| train/                  |           |
|    approx_kl            | 0.8737291 |
|    clip_fraction        | 0.541     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.48      |
|    explained_variance   | 0.12      |
|    learning_rate        | 0.000778  |
|    loss                 | 0.0015    |
|    n_updates            | 30610     |
|    policy_gradient_loss | 0.0346    |
|    std                  | 0.116     |
|    value_loss           | 0.00281   |
---------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 3062    |
|    time_elapsed    | 9936    |
|    total_timesteps | 6270976 |
--------------------------------
box reached target
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3063      |
|    time_elapsed         | 9939      |
|    total_timesteps      | 6273024   |
| train/                  |           |
|    approx_kl            | 0.5954188 |
|    clip_fraction        | 0.514     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.45      |
|    explained_variance   | 0.728     |
|    learning_rate        | 0.000777  |
|    loss                 | 0.0796    |
|    n_updates            | 30620     |
|    policy_gradient_loss | 0.0159    |
|    std                  | 0.118     |
|    value_loss           | 0.00904   |
---------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3064      |
|    time_elapsed         | 9942      |
|    total_timesteps      | 6275072   |
| train/                  |           |
|    approx_kl            | 0.5772934 |
|    clip_fraction        | 0.57      |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.44      |
|    explained_variance   | 0.385     |
|    learning_rate        | 0.000777  |
|    loss                 | 0.00985   |
|    n_updates            | 30630     |
|    policy_gradient_loss | 0.0272    |
|    std                  | 0.117     |
|    value_loss           | 0.045     |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3065       |
|    time_elapsed         | 9945       |
|    total_timesteps      | 6277120    |
| train/                  |            |
|    approx_kl            | 0.45454213 |
|    clip_fraction        | 0.483      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.47       |
|    explained_variance   | 0.588      |
|    learning_rate        | 0.000776   |
|    loss                 | -0.00672   |
|    n_updates            | 30640      |
|    policy_gradient_loss | 0.0154     |
|    std                  | 0.115      |
|    value_loss           | 0.00673    |
----------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3066      |
|    time_elapsed         | 9948      |
|    total_timesteps      | 6279168   |
| train/                  |           |
|    approx_kl            | 0.6947756 |
|    clip_fraction        | 0.52      |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.48      |
|    explained_variance   | 0.812     |
|    learning_rate        | 0.000776  |
|    loss                 | -0.0246   |
|    n_updates            | 30650     |
|    policy_gradient_loss | 0.0187    |
|    std                  | 0.115     |
|    value_loss           | 0.0142    |
---------------------------------------
box reached target
Eval num_timesteps=6280000, episode_reward=0.26 +/- 2.52
Episode length: 267.80 +/- 64.40
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 268       |
|    mean_reward          | 0.261     |
| time/                   |           |
|    total_timesteps      | 6280000   |
| train/                  |           |
|    approx_kl            | 0.7824826 |
|    clip_fraction        | 0.503     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.46      |
|    explained_variance   | 0.827     |
|    learning_rate        | 0.000776  |
|    loss                 | 0.0396    |
|    n_updates            | 30660     |
|    policy_gradient_loss | 0.0306    |
|    std                  | 0.117     |
|    value_loss           | 0.0068    |
---------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 3067    |
|    time_elapsed    | 9952    |
|    total_timesteps | 6281216 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3068       |
|    time_elapsed         | 9955       |
|    total_timesteps      | 6283264    |
| train/                  |            |
|    approx_kl            | 0.49282795 |
|    clip_fraction        | 0.48       |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.47       |
|    explained_variance   | 0.716      |
|    learning_rate        | 0.000775   |
|    loss                 | -0.0433    |
|    n_updates            | 30670      |
|    policy_gradient_loss | -0.00688   |
|    std                  | 0.114      |
|    value_loss           | 0.0138     |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3069       |
|    time_elapsed         | 9958       |
|    total_timesteps      | 6285312    |
| train/                  |            |
|    approx_kl            | 0.74161434 |
|    clip_fraction        | 0.54       |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.47       |
|    explained_variance   | 0.499      |
|    learning_rate        | 0.000775   |
|    loss                 | -0.00834   |
|    n_updates            | 30680      |
|    policy_gradient_loss | 0.0124     |
|    std                  | 0.116      |
|    value_loss           | 0.0038     |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3070       |
|    time_elapsed         | 9961       |
|    total_timesteps      | 6287360    |
| train/                  |            |
|    approx_kl            | 0.39140356 |
|    clip_fraction        | 0.479      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.44       |
|    explained_variance   | 0.767      |
|    learning_rate        | 0.000774   |
|    loss                 | 0.00453    |
|    n_updates            | 30690      |
|    policy_gradient_loss | 0.00838    |
|    std                  | 0.118      |
|    value_loss           | 0.00563    |
----------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3071      |
|    time_elapsed         | 9964      |
|    total_timesteps      | 6289408   |
| train/                  |           |
|    approx_kl            | 0.4716475 |
|    clip_fraction        | 0.491     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.4       |
|    explained_variance   | -0.53     |
|    learning_rate        | 0.000774  |
|    loss                 | -0.0258   |
|    n_updates            | 30700     |
|    policy_gradient_loss | 0.00847   |
|    std                  | 0.119     |
|    value_loss           | 0.00706   |
---------------------------------------
box reached target
Eval num_timesteps=6290000, episode_reward=0.20 +/- 2.56
Episode length: 270.20 +/- 59.60
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 270        |
|    mean_reward          | 0.204      |
| time/                   |            |
|    total_timesteps      | 6290000    |
| train/                  |            |
|    approx_kl            | 0.41851497 |
|    clip_fraction        | 0.492      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.41       |
|    explained_variance   | 0.586      |
|    learning_rate        | 0.000774   |
|    loss                 | 0.0277     |
|    n_updates            | 30710      |
|    policy_gradient_loss | 0.0312     |
|    std                  | 0.119      |
|    value_loss           | 0.0219     |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 3072    |
|    time_elapsed    | 9968    |
|    total_timesteps | 6291456 |
--------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3073      |
|    time_elapsed         | 9971      |
|    total_timesteps      | 6293504   |
| train/                  |           |
|    approx_kl            | 0.4284234 |
|    clip_fraction        | 0.481     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.41      |
|    explained_variance   | -0.608    |
|    learning_rate        | 0.000773  |
|    loss                 | 0.0225    |
|    n_updates            | 30720     |
|    policy_gradient_loss | 0.114     |
|    std                  | 0.119     |
|    value_loss           | 0.00144   |
---------------------------------------
box reached target
--------------------------------------
| time/                   |          |
|    fps                  | 631      |
|    iterations           | 3074     |
|    time_elapsed         | 9974     |
|    total_timesteps      | 6295552  |
| train/                  |          |
|    approx_kl            | 0.355633 |
|    clip_fraction        | 0.5      |
|    clip_range           | 0.2      |
|    entropy_loss         | 1.4      |
|    explained_variance   | 0.399    |
|    learning_rate        | 0.000773 |
|    loss                 | 0.000215 |
|    n_updates            | 30730    |
|    policy_gradient_loss | 0.0144   |
|    std                  | 0.12     |
|    value_loss           | 0.00381  |
--------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3075      |
|    time_elapsed         | 9977      |
|    total_timesteps      | 6297600   |
| train/                  |           |
|    approx_kl            | 3.6377342 |
|    clip_fraction        | 0.523     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.41      |
|    explained_variance   | 0.667     |
|    learning_rate        | 0.000772  |
|    loss                 | 0.0316    |
|    n_updates            | 30740     |
|    policy_gradient_loss | 0.0294    |
|    std                  | 0.119     |
|    value_loss           | 0.0137    |
---------------------------------------
box reached target
--------------------------------------
| time/                   |          |
|    fps                  | 631      |
|    iterations           | 3076     |
|    time_elapsed         | 9980     |
|    total_timesteps      | 6299648  |
| train/                  |          |
|    approx_kl            | 0.571854 |
|    clip_fraction        | 0.48     |
|    clip_range           | 0.2      |
|    entropy_loss         | 1.42     |
|    explained_variance   | 0.17     |
|    learning_rate        | 0.000772 |
|    loss                 | 0.0721   |
|    n_updates            | 30750    |
|    policy_gradient_loss | 0.014    |
|    std                  | 0.118    |
|    value_loss           | 0.0125   |
--------------------------------------
Eval num_timesteps=6300000, episode_reward=-0.69 +/- 0.63
Episode length: 300.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 300       |
|    mean_reward          | -0.687    |
| time/                   |           |
|    total_timesteps      | 6300000   |
| train/                  |           |
|    approx_kl            | 0.8098761 |
|    clip_fraction        | 0.525     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.42      |
|    explained_variance   | 0.666     |
|    learning_rate        | 0.000772  |
|    loss                 | 0.0242    |
|    n_updates            | 30760     |
|    policy_gradient_loss | 0.024     |
|    std                  | 0.118     |
|    value_loss           | 0.0073    |
---------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 3077    |
|    time_elapsed    | 9984    |
|    total_timesteps | 6301696 |
--------------------------------
box reached target
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3078      |
|    time_elapsed         | 9987      |
|    total_timesteps      | 6303744   |
| train/                  |           |
|    approx_kl            | 1.7504699 |
|    clip_fraction        | 0.522     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.44      |
|    explained_variance   | 0.574     |
|    learning_rate        | 0.000771  |
|    loss                 | 0.0126    |
|    n_updates            | 30770     |
|    policy_gradient_loss | 0.00382   |
|    std                  | 0.116     |
|    value_loss           | 0.00203   |
---------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3079      |
|    time_elapsed         | 9990      |
|    total_timesteps      | 6305792   |
| train/                  |           |
|    approx_kl            | 0.3944661 |
|    clip_fraction        | 0.51      |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.45      |
|    explained_variance   | 0.789     |
|    learning_rate        | 0.000771  |
|    loss                 | 0.0435    |
|    n_updates            | 30780     |
|    policy_gradient_loss | 0.0366    |
|    std                  | 0.118     |
|    value_loss           | 0.0151    |
---------------------------------------
box reached target
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3080      |
|    time_elapsed         | 9993      |
|    total_timesteps      | 6307840   |
| train/                  |           |
|    approx_kl            | 0.3058892 |
|    clip_fraction        | 0.412     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.45      |
|    explained_variance   | 0.711     |
|    learning_rate        | 0.00077   |
|    loss                 | 0.0145    |
|    n_updates            | 30790     |
|    policy_gradient_loss | 0.00168   |
|    std                  | 0.115     |
|    value_loss           | 0.00657   |
---------------------------------------
--------------------------------------
| time/                   |          |
|    fps                  | 631      |
|    iterations           | 3081     |
|    time_elapsed         | 9996     |
|    total_timesteps      | 6309888  |
| train/                  |          |
|    approx_kl            | 1.755557 |
|    clip_fraction        | 0.599    |
|    clip_range           | 0.2      |
|    entropy_loss         | 1.43     |
|    explained_variance   | 0.66     |
|    learning_rate        | 0.00077  |
|    loss                 | -0.0366  |
|    n_updates            | 30800    |
|    policy_gradient_loss | 0.0367   |
|    std                  | 0.12     |
|    value_loss           | 0.0885   |
--------------------------------------
Eval num_timesteps=6310000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 300       |
|    mean_reward          | -1        |
| time/                   |           |
|    total_timesteps      | 6310000   |
| train/                  |           |
|    approx_kl            | 0.6254423 |
|    clip_fraction        | 0.484     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.4       |
|    explained_variance   | 0.721     |
|    learning_rate        | 0.00077   |
|    loss                 | 0.0812    |
|    n_updates            | 30810     |
|    policy_gradient_loss | 0.0176    |
|    std                  | 0.12      |
|    value_loss           | 0.0209    |
---------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 3082    |
|    time_elapsed    | 10000   |
|    total_timesteps | 6311936 |
--------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3083      |
|    time_elapsed         | 10003     |
|    total_timesteps      | 6313984   |
| train/                  |           |
|    approx_kl            | 0.2556656 |
|    clip_fraction        | 0.445     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.39      |
|    explained_variance   | 0.792     |
|    learning_rate        | 0.000769  |
|    loss                 | -0.0198   |
|    n_updates            | 30820     |
|    policy_gradient_loss | 0.0106    |
|    std                  | 0.121     |
|    value_loss           | 0.011     |
---------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3084      |
|    time_elapsed         | 10006     |
|    total_timesteps      | 6316032   |
| train/                  |           |
|    approx_kl            | 0.3773862 |
|    clip_fraction        | 0.453     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.39      |
|    explained_variance   | 0.802     |
|    learning_rate        | 0.000769  |
|    loss                 | 0.0257    |
|    n_updates            | 30830     |
|    policy_gradient_loss | 0.0129    |
|    std                  | 0.121     |
|    value_loss           | 0.00977   |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3085       |
|    time_elapsed         | 10009      |
|    total_timesteps      | 6318080    |
| train/                  |            |
|    approx_kl            | 0.32952136 |
|    clip_fraction        | 0.429      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.39       |
|    explained_variance   | 0.791      |
|    learning_rate        | 0.000768   |
|    loss                 | -0.0144    |
|    n_updates            | 30840      |
|    policy_gradient_loss | 0.0164     |
|    std                  | 0.12       |
|    value_loss           | 0.0167     |
----------------------------------------
box reached target
Eval num_timesteps=6320000, episode_reward=-0.66 +/- 0.68
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -0.661     |
| time/                   |            |
|    total_timesteps      | 6320000    |
| train/                  |            |
|    approx_kl            | 0.42563516 |
|    clip_fraction        | 0.447      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.36       |
|    explained_variance   | 0.72       |
|    learning_rate        | 0.000768   |
|    loss                 | -0.0221    |
|    n_updates            | 30850      |
|    policy_gradient_loss | 0.0273     |
|    std                  | 0.125      |
|    value_loss           | 0.011      |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 3086    |
|    time_elapsed    | 10013   |
|    total_timesteps | 6320128 |
--------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3087      |
|    time_elapsed         | 10016     |
|    total_timesteps      | 6322176   |
| train/                  |           |
|    approx_kl            | 0.4232095 |
|    clip_fraction        | 0.498     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.34      |
|    explained_variance   | 0.794     |
|    learning_rate        | 0.000768  |
|    loss                 | -0.0192   |
|    n_updates            | 30860     |
|    policy_gradient_loss | 0.0105    |
|    std                  | 0.124     |
|    value_loss           | 0.0197    |
---------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3088       |
|    time_elapsed         | 10019      |
|    total_timesteps      | 6324224    |
| train/                  |            |
|    approx_kl            | 0.57385135 |
|    clip_fraction        | 0.472      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.3        |
|    explained_variance   | 0.79       |
|    learning_rate        | 0.000767   |
|    loss                 | -0.0206    |
|    n_updates            | 30870      |
|    policy_gradient_loss | 0.0113     |
|    std                  | 0.127      |
|    value_loss           | 0.00157    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3089       |
|    time_elapsed         | 10023      |
|    total_timesteps      | 6326272    |
| train/                  |            |
|    approx_kl            | 0.47771308 |
|    clip_fraction        | 0.516      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.33       |
|    explained_variance   | 0.769      |
|    learning_rate        | 0.000767   |
|    loss                 | 0.0145     |
|    n_updates            | 30880      |
|    policy_gradient_loss | 0.011      |
|    std                  | 0.121      |
|    value_loss           | 0.00949    |
----------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3090      |
|    time_elapsed         | 10026     |
|    total_timesteps      | 6328320   |
| train/                  |           |
|    approx_kl            | 0.5634639 |
|    clip_fraction        | 0.45      |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.38      |
|    explained_variance   | 0.699     |
|    learning_rate        | 0.000766  |
|    loss                 | 0.0201    |
|    n_updates            | 30890     |
|    policy_gradient_loss | 0.0123    |
|    std                  | 0.12      |
|    value_loss           | 0.0142    |
---------------------------------------
box reached target
Eval num_timesteps=6330000, episode_reward=-0.93 +/- 0.13
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -0.934     |
| time/                   |            |
|    total_timesteps      | 6330000    |
| train/                  |            |
|    approx_kl            | 0.65181386 |
|    clip_fraction        | 0.582      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.4        |
|    explained_variance   | 0.762      |
|    learning_rate        | 0.000766   |
|    loss                 | 0.0619     |
|    n_updates            | 30900      |
|    policy_gradient_loss | 0.0213     |
|    std                  | 0.121      |
|    value_loss           | 0.0146     |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 3091    |
|    time_elapsed    | 10030   |
|    total_timesteps | 6330368 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3092       |
|    time_elapsed         | 10033      |
|    total_timesteps      | 6332416    |
| train/                  |            |
|    approx_kl            | 0.29760987 |
|    clip_fraction        | 0.456      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.4        |
|    explained_variance   | 0.19       |
|    learning_rate        | 0.000766   |
|    loss                 | -0.0051    |
|    n_updates            | 30910      |
|    policy_gradient_loss | 0.0304     |
|    std                  | 0.119      |
|    value_loss           | 0.025      |
----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3093      |
|    time_elapsed         | 10036     |
|    total_timesteps      | 6334464   |
| train/                  |           |
|    approx_kl            | 0.8399044 |
|    clip_fraction        | 0.519     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.43      |
|    explained_variance   | 0.439     |
|    learning_rate        | 0.000765  |
|    loss                 | 0.0444    |
|    n_updates            | 30920     |
|    policy_gradient_loss | 0.0206    |
|    std                  | 0.117     |
|    value_loss           | 0.00455   |
---------------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3094       |
|    time_elapsed         | 10039      |
|    total_timesteps      | 6336512    |
| train/                  |            |
|    approx_kl            | 0.37652344 |
|    clip_fraction        | 0.504      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.42       |
|    explained_variance   | 0.83       |
|    learning_rate        | 0.000765   |
|    loss                 | -0.0115    |
|    n_updates            | 30930      |
|    policy_gradient_loss | 0.00553    |
|    std                  | 0.119      |
|    value_loss           | 0.0268     |
----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3095      |
|    time_elapsed         | 10042     |
|    total_timesteps      | 6338560   |
| train/                  |           |
|    approx_kl            | 0.6656024 |
|    clip_fraction        | 0.552     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.4       |
|    explained_variance   | 0.555     |
|    learning_rate        | 0.000764  |
|    loss                 | 0.0319    |
|    n_updates            | 30940     |
|    policy_gradient_loss | 0.0449    |
|    std                  | 0.121     |
|    value_loss           | 0.07      |
---------------------------------------
box reached target
Eval num_timesteps=6340000, episode_reward=-0.93 +/- 0.14
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -0.931     |
| time/                   |            |
|    total_timesteps      | 6340000    |
| train/                  |            |
|    approx_kl            | 0.41305974 |
|    clip_fraction        | 0.45       |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.39       |
|    explained_variance   | 0.204      |
|    learning_rate        | 0.000764   |
|    loss                 | -0.011     |
|    n_updates            | 30950      |
|    policy_gradient_loss | 0.0198     |
|    std                  | 0.121      |
|    value_loss           | 0.00375    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 3096    |
|    time_elapsed    | 10046   |
|    total_timesteps | 6340608 |
--------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3097       |
|    time_elapsed         | 10049      |
|    total_timesteps      | 6342656    |
| train/                  |            |
|    approx_kl            | 0.77142715 |
|    clip_fraction        | 0.538      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.4        |
|    explained_variance   | 0.737      |
|    learning_rate        | 0.000764   |
|    loss                 | -0.0264    |
|    n_updates            | 30960      |
|    policy_gradient_loss | 0.0273     |
|    std                  | 0.119      |
|    value_loss           | 0.0475     |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3098       |
|    time_elapsed         | 10052      |
|    total_timesteps      | 6344704    |
| train/                  |            |
|    approx_kl            | 0.33818772 |
|    clip_fraction        | 0.471      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.38       |
|    explained_variance   | 0.683      |
|    learning_rate        | 0.000763   |
|    loss                 | 0.0471     |
|    n_updates            | 30970      |
|    policy_gradient_loss | 0.0131     |
|    std                  | 0.122      |
|    value_loss           | 0.0645     |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3099       |
|    time_elapsed         | 10055      |
|    total_timesteps      | 6346752    |
| train/                  |            |
|    approx_kl            | 0.46229792 |
|    clip_fraction        | 0.505      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.34       |
|    explained_variance   | 0.746      |
|    learning_rate        | 0.000763   |
|    loss                 | -0.0133    |
|    n_updates            | 30980      |
|    policy_gradient_loss | 0.0245     |
|    std                  | 0.124      |
|    value_loss           | 0.0232     |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3100       |
|    time_elapsed         | 10058      |
|    total_timesteps      | 6348800    |
| train/                  |            |
|    approx_kl            | 0.48995608 |
|    clip_fraction        | 0.472      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.34       |
|    explained_variance   | 0.823      |
|    learning_rate        | 0.000762   |
|    loss                 | -0.0139    |
|    n_updates            | 30990      |
|    policy_gradient_loss | 0.0151     |
|    std                  | 0.124      |
|    value_loss           | 0.0162     |
----------------------------------------
box reached target
Eval num_timesteps=6350000, episode_reward=0.23 +/- 2.46
Episode length: 274.20 +/- 51.60
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 274        |
|    mean_reward          | 0.232      |
| time/                   |            |
|    total_timesteps      | 6350000    |
| train/                  |            |
|    approx_kl            | 0.56031346 |
|    clip_fraction        | 0.511      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.33       |
|    explained_variance   | 0.724      |
|    learning_rate        | 0.000762   |
|    loss                 | -0.0427    |
|    n_updates            | 31000      |
|    policy_gradient_loss | 0.00764    |
|    std                  | 0.124      |
|    value_loss           | 0.0146     |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 3101    |
|    time_elapsed    | 10062   |
|    total_timesteps | 6350848 |
--------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3102      |
|    time_elapsed         | 10065     |
|    total_timesteps      | 6352896   |
| train/                  |           |
|    approx_kl            | 0.3800329 |
|    clip_fraction        | 0.432     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.32      |
|    explained_variance   | 0.768     |
|    learning_rate        | 0.000762  |
|    loss                 | -0.0143   |
|    n_updates            | 31010     |
|    policy_gradient_loss | 0.0119    |
|    std                  | 0.125     |
|    value_loss           | 0.0231    |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3103       |
|    time_elapsed         | 10068      |
|    total_timesteps      | 6354944    |
| train/                  |            |
|    approx_kl            | 0.18114886 |
|    clip_fraction        | 0.441      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.31       |
|    explained_variance   | 0.791      |
|    learning_rate        | 0.000761   |
|    loss                 | 0.0111     |
|    n_updates            | 31020      |
|    policy_gradient_loss | 0.0135     |
|    std                  | 0.126      |
|    value_loss           | 0.0145     |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3104       |
|    time_elapsed         | 10071      |
|    total_timesteps      | 6356992    |
| train/                  |            |
|    approx_kl            | 0.95786345 |
|    clip_fraction        | 0.437      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.3        |
|    explained_variance   | 0.00825    |
|    learning_rate        | 0.000761   |
|    loss                 | 0.04       |
|    n_updates            | 31030      |
|    policy_gradient_loss | 0.0121     |
|    std                  | 0.125      |
|    value_loss           | 0.006      |
----------------------------------------
--------------------------------------
| time/                   |          |
|    fps                  | 631      |
|    iterations           | 3105     |
|    time_elapsed         | 10074    |
|    total_timesteps      | 6359040  |
| train/                  |          |
|    approx_kl            | 0.472487 |
|    clip_fraction        | 0.501    |
|    clip_range           | 0.2      |
|    entropy_loss         | 1.31     |
|    explained_variance   | 0.856    |
|    learning_rate        | 0.00076  |
|    loss                 | 0.0117   |
|    n_updates            | 31040    |
|    policy_gradient_loss | 0.0194   |
|    std                  | 0.126    |
|    value_loss           | 0.0108   |
--------------------------------------
Eval num_timesteps=6360000, episode_reward=-1.04 +/- 0.05
Episode length: 300.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 300       |
|    mean_reward          | -1.04     |
| time/                   |           |
|    total_timesteps      | 6360000   |
| train/                  |           |
|    approx_kl            | 1.2569984 |
|    clip_fraction        | 0.487     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.33      |
|    explained_variance   | 0.492     |
|    learning_rate        | 0.00076   |
|    loss                 | -0.0655   |
|    n_updates            | 31050     |
|    policy_gradient_loss | -0.0113   |
|    std                  | 0.123     |
|    value_loss           | 0.00534   |
---------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 3106    |
|    time_elapsed    | 10078   |
|    total_timesteps | 6361088 |
--------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3107      |
|    time_elapsed         | 10081     |
|    total_timesteps      | 6363136   |
| train/                  |           |
|    approx_kl            | 0.3495466 |
|    clip_fraction        | 0.5       |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.33      |
|    explained_variance   | 0.514     |
|    learning_rate        | 0.00076   |
|    loss                 | 0.0701    |
|    n_updates            | 31060     |
|    policy_gradient_loss | 0.0124    |
|    std                  | 0.126     |
|    value_loss           | 0.00327   |
---------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3108      |
|    time_elapsed         | 10084     |
|    total_timesteps      | 6365184   |
| train/                  |           |
|    approx_kl            | 1.0317931 |
|    clip_fraction        | 0.507     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.3       |
|    explained_variance   | 0.616     |
|    learning_rate        | 0.000759  |
|    loss                 | 0.0219    |
|    n_updates            | 31070     |
|    policy_gradient_loss | 0.029     |
|    std                  | 0.126     |
|    value_loss           | 0.0566    |
---------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3109      |
|    time_elapsed         | 10087     |
|    total_timesteps      | 6367232   |
| train/                  |           |
|    approx_kl            | 0.4315272 |
|    clip_fraction        | 0.452     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.33      |
|    explained_variance   | 0.179     |
|    learning_rate        | 0.000759  |
|    loss                 | 0.0251    |
|    n_updates            | 31080     |
|    policy_gradient_loss | 0.0392    |
|    std                  | 0.123     |
|    value_loss           | 0.0099    |
---------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3110      |
|    time_elapsed         | 10090     |
|    total_timesteps      | 6369280   |
| train/                  |           |
|    approx_kl            | 0.6573187 |
|    clip_fraction        | 0.514     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.35      |
|    explained_variance   | 0.71      |
|    learning_rate        | 0.000758  |
|    loss                 | -0.0272   |
|    n_updates            | 31090     |
|    policy_gradient_loss | 0.0245    |
|    std                  | 0.123     |
|    value_loss           | 0.0168    |
---------------------------------------
Eval num_timesteps=6370000, episode_reward=-0.80 +/- 0.39
Episode length: 300.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 300       |
|    mean_reward          | -0.805    |
| time/                   |           |
|    total_timesteps      | 6370000   |
| train/                  |           |
|    approx_kl            | 0.4605173 |
|    clip_fraction        | 0.483     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.34      |
|    explained_variance   | 0.422     |
|    learning_rate        | 0.000758  |
|    loss                 | -0.0319   |
|    n_updates            | 31100     |
|    policy_gradient_loss | 0.0163    |
|    std                  | 0.125     |
|    value_loss           | 0.00965   |
---------------------------------------
box reached target
box reached target
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 3111    |
|    time_elapsed    | 10094   |
|    total_timesteps | 6371328 |
--------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3112       |
|    time_elapsed         | 10097      |
|    total_timesteps      | 6373376    |
| train/                  |            |
|    approx_kl            | 0.38877645 |
|    clip_fraction        | 0.464      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.3        |
|    explained_variance   | 0.668      |
|    learning_rate        | 0.000758   |
|    loss                 | 0.0172     |
|    n_updates            | 31110      |
|    policy_gradient_loss | 0.0153     |
|    std                  | 0.127      |
|    value_loss           | 0.0323     |
----------------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3113       |
|    time_elapsed         | 10100      |
|    total_timesteps      | 6375424    |
| train/                  |            |
|    approx_kl            | 0.59554243 |
|    clip_fraction        | 0.514      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.27       |
|    explained_variance   | 0.872      |
|    learning_rate        | 0.000757   |
|    loss                 | 0.0338     |
|    n_updates            | 31120      |
|    policy_gradient_loss | 0.0166     |
|    std                  | 0.129      |
|    value_loss           | 0.0207     |
----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3114      |
|    time_elapsed         | 10103     |
|    total_timesteps      | 6377472   |
| train/                  |           |
|    approx_kl            | 0.3964227 |
|    clip_fraction        | 0.477     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.25      |
|    explained_variance   | 0.363     |
|    learning_rate        | 0.000757  |
|    loss                 | 0.0742    |
|    n_updates            | 31130     |
|    policy_gradient_loss | 0.0176    |
|    std                  | 0.128     |
|    value_loss           | 0.158     |
---------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3115      |
|    time_elapsed         | 10106     |
|    total_timesteps      | 6379520   |
| train/                  |           |
|    approx_kl            | 0.8543931 |
|    clip_fraction        | 0.493     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.27      |
|    explained_variance   | 0.642     |
|    learning_rate        | 0.000756  |
|    loss                 | -0.043    |
|    n_updates            | 31140     |
|    policy_gradient_loss | 0.00219   |
|    std                  | 0.126     |
|    value_loss           | 0.0186    |
---------------------------------------
Eval num_timesteps=6380000, episode_reward=-0.54 +/- 0.57
Episode length: 300.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 300       |
|    mean_reward          | -0.538    |
| time/                   |           |
|    total_timesteps      | 6380000   |
| train/                  |           |
|    approx_kl            | 0.2229231 |
|    clip_fraction        | 0.431     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.3       |
|    explained_variance   | 0.341     |
|    learning_rate        | 0.000756  |
|    loss                 | -0.0026   |
|    n_updates            | 31150     |
|    policy_gradient_loss | 0.00777   |
|    std                  | 0.126     |
|    value_loss           | 0.00635   |
---------------------------------------
box reached target
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 3116    |
|    time_elapsed    | 10110   |
|    total_timesteps | 6381568 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3117       |
|    time_elapsed         | 10113      |
|    total_timesteps      | 6383616    |
| train/                  |            |
|    approx_kl            | 0.36989093 |
|    clip_fraction        | 0.504      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.31       |
|    explained_variance   | 0.804      |
|    learning_rate        | 0.000756   |
|    loss                 | -0.0375    |
|    n_updates            | 31160      |
|    policy_gradient_loss | 0.0019     |
|    std                  | 0.124      |
|    value_loss           | 0.0184     |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3118       |
|    time_elapsed         | 10117      |
|    total_timesteps      | 6385664    |
| train/                  |            |
|    approx_kl            | 0.40109444 |
|    clip_fraction        | 0.478      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.34       |
|    explained_variance   | 0.531      |
|    learning_rate        | 0.000755   |
|    loss                 | -0.00605   |
|    n_updates            | 31170      |
|    policy_gradient_loss | 0.00205    |
|    std                  | 0.123      |
|    value_loss           | 0.00685    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3119       |
|    time_elapsed         | 10120      |
|    total_timesteps      | 6387712    |
| train/                  |            |
|    approx_kl            | 0.39525485 |
|    clip_fraction        | 0.483      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.38       |
|    explained_variance   | 0.469      |
|    learning_rate        | 0.000755   |
|    loss                 | 0.11       |
|    n_updates            | 31180      |
|    policy_gradient_loss | 0.000215   |
|    std                  | 0.121      |
|    value_loss           | 0.0142     |
----------------------------------------
box reached target
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3120      |
|    time_elapsed         | 10123     |
|    total_timesteps      | 6389760   |
| train/                  |           |
|    approx_kl            | 3.4988854 |
|    clip_fraction        | 0.52      |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.38      |
|    explained_variance   | 0.161     |
|    learning_rate        | 0.000754  |
|    loss                 | 0.0608    |
|    n_updates            | 31190     |
|    policy_gradient_loss | 0.0294    |
|    std                  | 0.12      |
|    value_loss           | 0.00693   |
---------------------------------------
Eval num_timesteps=6390000, episode_reward=-0.91 +/- 0.53
Episode length: 300.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 300       |
|    mean_reward          | -0.907    |
| time/                   |           |
|    total_timesteps      | 6390000   |
| train/                  |           |
|    approx_kl            | 0.6691805 |
|    clip_fraction        | 0.508     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.44      |
|    explained_variance   | 0.803     |
|    learning_rate        | 0.000754  |
|    loss                 | -0.00109  |
|    n_updates            | 31200     |
|    policy_gradient_loss | 0.00379   |
|    std                  | 0.116     |
|    value_loss           | 0.032     |
---------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 3121    |
|    time_elapsed    | 10127   |
|    total_timesteps | 6391808 |
--------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3122       |
|    time_elapsed         | 10130      |
|    total_timesteps      | 6393856    |
| train/                  |            |
|    approx_kl            | 0.40286145 |
|    clip_fraction        | 0.485      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.47       |
|    explained_variance   | 0.335      |
|    learning_rate        | 0.000754   |
|    loss                 | 0.00997    |
|    n_updates            | 31210      |
|    policy_gradient_loss | 0.00593    |
|    std                  | 0.114      |
|    value_loss           | 0.00569    |
----------------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3123       |
|    time_elapsed         | 10133      |
|    total_timesteps      | 6395904    |
| train/                  |            |
|    approx_kl            | 0.36296543 |
|    clip_fraction        | 0.473      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.53       |
|    explained_variance   | 0.882      |
|    learning_rate        | 0.000753   |
|    loss                 | 0.0441     |
|    n_updates            | 31220      |
|    policy_gradient_loss | 0.0133     |
|    std                  | 0.112      |
|    value_loss           | 0.0263     |
----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3124      |
|    time_elapsed         | 10136     |
|    total_timesteps      | 6397952   |
| train/                  |           |
|    approx_kl            | 3.7579243 |
|    clip_fraction        | 0.558     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.55      |
|    explained_variance   | 0.896     |
|    learning_rate        | 0.000753  |
|    loss                 | 0.093     |
|    n_updates            | 31230     |
|    policy_gradient_loss | 0.00195   |
|    std                  | 0.11      |
|    value_loss           | 0.027     |
---------------------------------------
box reached target
Eval num_timesteps=6400000, episode_reward=0.53 +/- 2.40
Episode length: 275.60 +/- 48.80
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 276       |
|    mean_reward          | 0.533     |
| time/                   |           |
|    total_timesteps      | 6400000   |
| train/                  |           |
|    approx_kl            | 1.6656199 |
|    clip_fraction        | 0.497     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.57      |
|    explained_variance   | 0.347     |
|    learning_rate        | 0.000752  |
|    loss                 | 0.0987    |
|    n_updates            | 31240     |
|    policy_gradient_loss | 0.0298    |
|    std                  | 0.111     |
|    value_loss           | 0.00985   |
---------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 3125    |
|    time_elapsed    | 10140   |
|    total_timesteps | 6400000 |
--------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3126       |
|    time_elapsed         | 10143      |
|    total_timesteps      | 6402048    |
| train/                  |            |
|    approx_kl            | 0.63209903 |
|    clip_fraction        | 0.472      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.54       |
|    explained_variance   | 0.317      |
|    learning_rate        | 0.000752   |
|    loss                 | -0.00805   |
|    n_updates            | 31250      |
|    policy_gradient_loss | 0.0106     |
|    std                  | 0.113      |
|    value_loss           | 0.00678    |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3127       |
|    time_elapsed         | 10146      |
|    total_timesteps      | 6404096    |
| train/                  |            |
|    approx_kl            | 0.34353584 |
|    clip_fraction        | 0.508      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.54       |
|    explained_variance   | -0.000156  |
|    learning_rate        | 0.000752   |
|    loss                 | 0.00637    |
|    n_updates            | 31260      |
|    policy_gradient_loss | 0.0209     |
|    std                  | 0.113      |
|    value_loss           | 0.111      |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3128       |
|    time_elapsed         | 10149      |
|    total_timesteps      | 6406144    |
| train/                  |            |
|    approx_kl            | 0.38339883 |
|    clip_fraction        | 0.489      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.57       |
|    explained_variance   | 0.257      |
|    learning_rate        | 0.000751   |
|    loss                 | -0.0276    |
|    n_updates            | 31270      |
|    policy_gradient_loss | 0.00932    |
|    std                  | 0.109      |
|    value_loss           | 0.0335     |
----------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3129      |
|    time_elapsed         | 10152     |
|    total_timesteps      | 6408192   |
| train/                  |           |
|    approx_kl            | 0.6270766 |
|    clip_fraction        | 0.549     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.58      |
|    explained_variance   | -0.263    |
|    learning_rate        | 0.000751  |
|    loss                 | -0.00315  |
|    n_updates            | 31280     |
|    policy_gradient_loss | 0.013     |
|    std                  | 0.109     |
|    value_loss           | 0.0111    |
---------------------------------------
box reached target
Eval num_timesteps=6410000, episode_reward=-0.93 +/- 0.14
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -0.93      |
| time/                   |            |
|    total_timesteps      | 6410000    |
| train/                  |            |
|    approx_kl            | 0.27507854 |
|    clip_fraction        | 0.517      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.58       |
|    explained_variance   | 0.715      |
|    learning_rate        | 0.00075    |
|    loss                 | 0.00812    |
|    n_updates            | 31290      |
|    policy_gradient_loss | 0.0332     |
|    std                  | 0.111      |
|    value_loss           | 0.0174     |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 3130    |
|    time_elapsed    | 10156   |
|    total_timesteps | 6410240 |
--------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3131      |
|    time_elapsed         | 10159     |
|    total_timesteps      | 6412288   |
| train/                  |           |
|    approx_kl            | 0.3127309 |
|    clip_fraction        | 0.532     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.56      |
|    explained_variance   | 0.851     |
|    learning_rate        | 0.00075   |
|    loss                 | 0.0472    |
|    n_updates            | 31300     |
|    policy_gradient_loss | 0.0285    |
|    std                  | 0.111     |
|    value_loss           | 0.0161    |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3132       |
|    time_elapsed         | 10162      |
|    total_timesteps      | 6414336    |
| train/                  |            |
|    approx_kl            | 0.19956642 |
|    clip_fraction        | 0.45       |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.6        |
|    explained_variance   | -0.0765    |
|    learning_rate        | 0.00075    |
|    loss                 | -0.0109    |
|    n_updates            | 31310      |
|    policy_gradient_loss | 0.00181    |
|    std                  | 0.108      |
|    value_loss           | 0.0121     |
----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3133      |
|    time_elapsed         | 10165     |
|    total_timesteps      | 6416384   |
| train/                  |           |
|    approx_kl            | 0.5141581 |
|    clip_fraction        | 0.493     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.6       |
|    explained_variance   | 0.318     |
|    learning_rate        | 0.000749  |
|    loss                 | 0.0287    |
|    n_updates            | 31320     |
|    policy_gradient_loss | 0.0564    |
|    std                  | 0.109     |
|    value_loss           | 0.00381   |
---------------------------------------
box reached target
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3134      |
|    time_elapsed         | 10168     |
|    total_timesteps      | 6418432   |
| train/                  |           |
|    approx_kl            | 0.5005461 |
|    clip_fraction        | 0.483     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.61      |
|    explained_variance   | -0.543    |
|    learning_rate        | 0.000749  |
|    loss                 | 0.0238    |
|    n_updates            | 31330     |
|    policy_gradient_loss | 0.013     |
|    std                  | 0.107     |
|    value_loss           | 0.00313   |
---------------------------------------
Eval num_timesteps=6420000, episode_reward=-1.06 +/- 0.12
Episode length: 300.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 300       |
|    mean_reward          | -1.06     |
| time/                   |           |
|    total_timesteps      | 6420000   |
| train/                  |           |
|    approx_kl            | 0.8951435 |
|    clip_fraction        | 0.548     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.65      |
|    explained_variance   | 0.698     |
|    learning_rate        | 0.000748  |
|    loss                 | 0.01      |
|    n_updates            | 31340     |
|    policy_gradient_loss | 0.0254    |
|    std                  | 0.105     |
|    value_loss           | 0.0333    |
---------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 3135    |
|    time_elapsed    | 10172   |
|    total_timesteps | 6420480 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3136       |
|    time_elapsed         | 10175      |
|    total_timesteps      | 6422528    |
| train/                  |            |
|    approx_kl            | 0.37037453 |
|    clip_fraction        | 0.512      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.65       |
|    explained_variance   | 0.821      |
|    learning_rate        | 0.000748   |
|    loss                 | 0.0598     |
|    n_updates            | 31350      |
|    policy_gradient_loss | 0.0323     |
|    std                  | 0.107      |
|    value_loss           | 0.0118     |
----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3137      |
|    time_elapsed         | 10178     |
|    total_timesteps      | 6424576   |
| train/                  |           |
|    approx_kl            | 0.7428208 |
|    clip_fraction        | 0.548     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.64      |
|    explained_variance   | 0.671     |
|    learning_rate        | 0.000748  |
|    loss                 | -0.0302   |
|    n_updates            | 31360     |
|    policy_gradient_loss | 0.0063    |
|    std                  | 0.106     |
|    value_loss           | 0.0273    |
---------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3138      |
|    time_elapsed         | 10181     |
|    total_timesteps      | 6426624   |
| train/                  |           |
|    approx_kl            | 0.7101867 |
|    clip_fraction        | 0.461     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.67      |
|    explained_variance   | 0.522     |
|    learning_rate        | 0.000747  |
|    loss                 | 0.0111    |
|    n_updates            | 31370     |
|    policy_gradient_loss | 0.0128    |
|    std                  | 0.104     |
|    value_loss           | 0.00715   |
---------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3139      |
|    time_elapsed         | 10184     |
|    total_timesteps      | 6428672   |
| train/                  |           |
|    approx_kl            | 0.2100389 |
|    clip_fraction        | 0.459     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.69      |
|    explained_variance   | 0.725     |
|    learning_rate        | 0.000747  |
|    loss                 | 0.0352    |
|    n_updates            | 31380     |
|    policy_gradient_loss | 0.0121    |
|    std                  | 0.104     |
|    value_loss           | 0.0134    |
---------------------------------------
box reached target
Eval num_timesteps=6430000, episode_reward=0.56 +/- 2.30
Episode length: 276.80 +/- 46.40
--------------------------------------
| eval/                   |          |
|    mean_ep_length       | 277      |
|    mean_reward          | 0.561    |
| time/                   |          |
|    total_timesteps      | 6430000  |
| train/                  |          |
|    approx_kl            | 1.032504 |
|    clip_fraction        | 0.497    |
|    clip_range           | 0.2      |
|    entropy_loss         | 1.71     |
|    explained_variance   | 0.814    |
|    learning_rate        | 0.000746 |
|    loss                 | 0.0474   |
|    n_updates            | 31390    |
|    policy_gradient_loss | -0.00202 |
|    std                  | 0.101    |
|    value_loss           | 0.0135   |
--------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 3140    |
|    time_elapsed    | 10188   |
|    total_timesteps | 6430720 |
--------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3141      |
|    time_elapsed         | 10191     |
|    total_timesteps      | 6432768   |
| train/                  |           |
|    approx_kl            | 0.5533004 |
|    clip_fraction        | 0.498     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.72      |
|    explained_variance   | 0.779     |
|    learning_rate        | 0.000746  |
|    loss                 | -0.0148   |
|    n_updates            | 31400     |
|    policy_gradient_loss | 0.0142    |
|    std                  | 0.102     |
|    value_loss           | 0.00677   |
---------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3142      |
|    time_elapsed         | 10194     |
|    total_timesteps      | 6434816   |
| train/                  |           |
|    approx_kl            | 1.3793341 |
|    clip_fraction        | 0.56      |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.73      |
|    explained_variance   | 0.792     |
|    learning_rate        | 0.000746  |
|    loss                 | 0.00258   |
|    n_updates            | 31410     |
|    policy_gradient_loss | 0.0189    |
|    std                  | 0.102     |
|    value_loss           | 0.0109    |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3143       |
|    time_elapsed         | 10197      |
|    total_timesteps      | 6436864    |
| train/                  |            |
|    approx_kl            | 0.37597635 |
|    clip_fraction        | 0.482      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.75       |
|    explained_variance   | 0.762      |
|    learning_rate        | 0.000745   |
|    loss                 | 0.0257     |
|    n_updates            | 31420      |
|    policy_gradient_loss | 0.0049     |
|    std                  | 0.1        |
|    value_loss           | 0.0152     |
----------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3144      |
|    time_elapsed         | 10200     |
|    total_timesteps      | 6438912   |
| train/                  |           |
|    approx_kl            | 1.8812544 |
|    clip_fraction        | 0.484     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.74      |
|    explained_variance   | 0.335     |
|    learning_rate        | 0.000745  |
|    loss                 | -0.0561   |
|    n_updates            | 31430     |
|    policy_gradient_loss | 0.0134    |
|    std                  | 0.102     |
|    value_loss           | 0.00254   |
---------------------------------------
box reached target
Eval num_timesteps=6440000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1         |
| time/                   |            |
|    total_timesteps      | 6440000    |
| train/                  |            |
|    approx_kl            | 0.45321265 |
|    clip_fraction        | 0.536      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.7        |
|    explained_variance   | 0.608      |
|    learning_rate        | 0.000744   |
|    loss                 | 0.0565     |
|    n_updates            | 31440      |
|    policy_gradient_loss | 0.0193     |
|    std                  | 0.104      |
|    value_loss           | 0.0263     |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 3145    |
|    time_elapsed    | 10204   |
|    total_timesteps | 6440960 |
--------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3146      |
|    time_elapsed         | 10207     |
|    total_timesteps      | 6443008   |
| train/                  |           |
|    approx_kl            | 1.9267548 |
|    clip_fraction        | 0.59      |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.69      |
|    explained_variance   | 0.77      |
|    learning_rate        | 0.000744  |
|    loss                 | -0.00108  |
|    n_updates            | 31450     |
|    policy_gradient_loss | 0.0309    |
|    std                  | 0.105     |
|    value_loss           | 0.0293    |
---------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3147       |
|    time_elapsed         | 10210      |
|    total_timesteps      | 6445056    |
| train/                  |            |
|    approx_kl            | 0.39969233 |
|    clip_fraction        | 0.51       |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.67       |
|    explained_variance   | 0.453      |
|    learning_rate        | 0.000744   |
|    loss                 | -0.0115    |
|    n_updates            | 31460      |
|    policy_gradient_loss | 0.0271     |
|    std                  | 0.105      |
|    value_loss           | 0.0162     |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3148       |
|    time_elapsed         | 10213      |
|    total_timesteps      | 6447104    |
| train/                  |            |
|    approx_kl            | 0.59157693 |
|    clip_fraction        | 0.531      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.65       |
|    explained_variance   | 0.841      |
|    learning_rate        | 0.000743   |
|    loss                 | 0.0308     |
|    n_updates            | 31470      |
|    policy_gradient_loss | 0.0409     |
|    std                  | 0.106      |
|    value_loss           | 0.0257     |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3149       |
|    time_elapsed         | 10216      |
|    total_timesteps      | 6449152    |
| train/                  |            |
|    approx_kl            | 0.13930413 |
|    clip_fraction        | 0.457      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.61       |
|    explained_variance   | 0.789      |
|    learning_rate        | 0.000743   |
|    loss                 | -0.0109    |
|    n_updates            | 31480      |
|    policy_gradient_loss | 0.0243     |
|    std                  | 0.11       |
|    value_loss           | 0.0504     |
----------------------------------------
box reached target
Eval num_timesteps=6450000, episode_reward=-0.91 +/- 0.28
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -0.91      |
| time/                   |            |
|    total_timesteps      | 6450000    |
| train/                  |            |
|    approx_kl            | 0.57517153 |
|    clip_fraction        | 0.445      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.57       |
|    explained_variance   | 0.491      |
|    learning_rate        | 0.000742   |
|    loss                 | -0.0092    |
|    n_updates            | 31490      |
|    policy_gradient_loss | 0.00465    |
|    std                  | 0.11       |
|    value_loss           | 0.0133     |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 3150    |
|    time_elapsed    | 10220   |
|    total_timesteps | 6451200 |
--------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3151       |
|    time_elapsed         | 10223      |
|    total_timesteps      | 6453248    |
| train/                  |            |
|    approx_kl            | 0.25371465 |
|    clip_fraction        | 0.41       |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.6        |
|    explained_variance   | 0.853      |
|    learning_rate        | 0.000742   |
|    loss                 | 0.00494    |
|    n_updates            | 31500      |
|    policy_gradient_loss | 0.0067     |
|    std                  | 0.108      |
|    value_loss           | 0.0176     |
----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3152      |
|    time_elapsed         | 10227     |
|    total_timesteps      | 6455296   |
| train/                  |           |
|    approx_kl            | 2.0432048 |
|    clip_fraction        | 0.541     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.62      |
|    explained_variance   | 0.699     |
|    learning_rate        | 0.000742  |
|    loss                 | -0.064    |
|    n_updates            | 31510     |
|    policy_gradient_loss | 0.00913   |
|    std                  | 0.106     |
|    value_loss           | 0.0211    |
---------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3153       |
|    time_elapsed         | 10230      |
|    total_timesteps      | 6457344    |
| train/                  |            |
|    approx_kl            | 0.68939495 |
|    clip_fraction        | 0.467      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.67       |
|    explained_variance   | 0.732      |
|    learning_rate        | 0.000741   |
|    loss                 | -0.0132    |
|    n_updates            | 31520      |
|    policy_gradient_loss | -0.00875   |
|    std                  | 0.104      |
|    value_loss           | 0.00931    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3154       |
|    time_elapsed         | 10233      |
|    total_timesteps      | 6459392    |
| train/                  |            |
|    approx_kl            | 0.83740664 |
|    clip_fraction        | 0.556      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.7        |
|    explained_variance   | 0.863      |
|    learning_rate        | 0.000741   |
|    loss                 | -0.0174    |
|    n_updates            | 31530      |
|    policy_gradient_loss | 0.00236    |
|    std                  | 0.103      |
|    value_loss           | 0.0134     |
----------------------------------------
Eval num_timesteps=6460000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1         |
| time/                   |            |
|    total_timesteps      | 6460000    |
| train/                  |            |
|    approx_kl            | 0.24083713 |
|    clip_fraction        | 0.495      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.68       |
|    explained_variance   | 0.876      |
|    learning_rate        | 0.00074    |
|    loss                 | 0.0243     |
|    n_updates            | 31540      |
|    policy_gradient_loss | 0.0269     |
|    std                  | 0.106      |
|    value_loss           | 0.00891    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 3155    |
|    time_elapsed    | 10237   |
|    total_timesteps | 6461440 |
--------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3156      |
|    time_elapsed         | 10240     |
|    total_timesteps      | 6463488   |
| train/                  |           |
|    approx_kl            | 0.3159743 |
|    clip_fraction        | 0.454     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.63      |
|    explained_variance   | 0.796     |
|    learning_rate        | 0.00074   |
|    loss                 | 0.134     |
|    n_updates            | 31550     |
|    policy_gradient_loss | 0.0253    |
|    std                  | 0.108     |
|    value_loss           | 0.00516   |
---------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3157       |
|    time_elapsed         | 10243      |
|    total_timesteps      | 6465536    |
| train/                  |            |
|    approx_kl            | 0.49164435 |
|    clip_fraction        | 0.489      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.62       |
|    explained_variance   | 0.556      |
|    learning_rate        | 0.00074    |
|    loss                 | 0.0344     |
|    n_updates            | 31560      |
|    policy_gradient_loss | 0.00473    |
|    std                  | 0.107      |
|    value_loss           | 0.0181     |
----------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3158      |
|    time_elapsed         | 10246     |
|    total_timesteps      | 6467584   |
| train/                  |           |
|    approx_kl            | 0.9057486 |
|    clip_fraction        | 0.533     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.63      |
|    explained_variance   | 0.422     |
|    learning_rate        | 0.000739  |
|    loss                 | 0.0268    |
|    n_updates            | 31570     |
|    policy_gradient_loss | 0.0118    |
|    std                  | 0.106     |
|    value_loss           | 0.0604    |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3159       |
|    time_elapsed         | 10249      |
|    total_timesteps      | 6469632    |
| train/                  |            |
|    approx_kl            | 0.30546284 |
|    clip_fraction        | 0.458      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.61       |
|    explained_variance   | 0.694      |
|    learning_rate        | 0.000739   |
|    loss                 | 0.0343     |
|    n_updates            | 31580      |
|    policy_gradient_loss | 0.0166     |
|    std                  | 0.11       |
|    value_loss           | 0.0352     |
----------------------------------------
box reached target
box reached target
Eval num_timesteps=6470000, episode_reward=0.21 +/- 2.42
Episode length: 277.20 +/- 45.60
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 277       |
|    mean_reward          | 0.208     |
| time/                   |           |
|    total_timesteps      | 6470000   |
| train/                  |           |
|    approx_kl            | 0.3547567 |
|    clip_fraction        | 0.45      |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.57      |
|    explained_variance   | 0.581     |
|    learning_rate        | 0.000738  |
|    loss                 | 0.0606    |
|    n_updates            | 31590     |
|    policy_gradient_loss | -0.00394  |
|    std                  | 0.11      |
|    value_loss           | 0.0259    |
---------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 3160    |
|    time_elapsed    | 10253   |
|    total_timesteps | 6471680 |
--------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3161       |
|    time_elapsed         | 10256      |
|    total_timesteps      | 6473728    |
| train/                  |            |
|    approx_kl            | 0.27682257 |
|    clip_fraction        | 0.496      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.56       |
|    explained_variance   | 0.801      |
|    learning_rate        | 0.000738   |
|    loss                 | 0.0297     |
|    n_updates            | 31600      |
|    policy_gradient_loss | 0.0248     |
|    std                  | 0.111      |
|    value_loss           | 0.0283     |
----------------------------------------
box reached target
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3162      |
|    time_elapsed         | 10259     |
|    total_timesteps      | 6475776   |
| train/                  |           |
|    approx_kl            | 0.6708215 |
|    clip_fraction        | 0.513     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.54      |
|    explained_variance   | -0.0629   |
|    learning_rate        | 0.000738  |
|    loss                 | 0.108     |
|    n_updates            | 31610     |
|    policy_gradient_loss | 0.0599    |
|    std                  | 0.112     |
|    value_loss           | 0.0586    |
---------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3163      |
|    time_elapsed         | 10262     |
|    total_timesteps      | 6477824   |
| train/                  |           |
|    approx_kl            | 0.5231861 |
|    clip_fraction        | 0.512     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.52      |
|    explained_variance   | 0.533     |
|    learning_rate        | 0.000737  |
|    loss                 | 0.00372   |
|    n_updates            | 31620     |
|    policy_gradient_loss | 0.0286    |
|    std                  | 0.114     |
|    value_loss           | 0.0893    |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3164       |
|    time_elapsed         | 10265      |
|    total_timesteps      | 6479872    |
| train/                  |            |
|    approx_kl            | 0.57425773 |
|    clip_fraction        | 0.512      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.48       |
|    explained_variance   | 0.789      |
|    learning_rate        | 0.000737   |
|    loss                 | 0.0513     |
|    n_updates            | 31630      |
|    policy_gradient_loss | 0.0429     |
|    std                  | 0.115      |
|    value_loss           | 0.0141     |
----------------------------------------
box reached target
Eval num_timesteps=6480000, episode_reward=0.57 +/- 2.55
Episode length: 294.00 +/- 12.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 294       |
|    mean_reward          | 0.569     |
| time/                   |           |
|    total_timesteps      | 6480000   |
| train/                  |           |
|    approx_kl            | 0.5915287 |
|    clip_fraction        | 0.509     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.45      |
|    explained_variance   | 0.851     |
|    learning_rate        | 0.000736  |
|    loss                 | 0.059     |
|    n_updates            | 31640     |
|    policy_gradient_loss | 0.00545   |
|    std                  | 0.118     |
|    value_loss           | 0.00387   |
---------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 3165    |
|    time_elapsed    | 10269   |
|    total_timesteps | 6481920 |
--------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3166      |
|    time_elapsed         | 10272     |
|    total_timesteps      | 6483968   |
| train/                  |           |
|    approx_kl            | 0.3763753 |
|    clip_fraction        | 0.468     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.44      |
|    explained_variance   | 0.499     |
|    learning_rate        | 0.000736  |
|    loss                 | -0.0518   |
|    n_updates            | 31650     |
|    policy_gradient_loss | 0.0051    |
|    std                  | 0.117     |
|    value_loss           | 0.00905   |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3167       |
|    time_elapsed         | 10275      |
|    total_timesteps      | 6486016    |
| train/                  |            |
|    approx_kl            | 0.26294446 |
|    clip_fraction        | 0.424      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.44       |
|    explained_variance   | 0.414      |
|    learning_rate        | 0.000736   |
|    loss                 | 0.0473     |
|    n_updates            | 31660      |
|    policy_gradient_loss | 0.0127     |
|    std                  | 0.119      |
|    value_loss           | 0.0942     |
----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3168      |
|    time_elapsed         | 10278     |
|    total_timesteps      | 6488064   |
| train/                  |           |
|    approx_kl            | 0.2120753 |
|    clip_fraction        | 0.41      |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.4       |
|    explained_variance   | 0.244     |
|    learning_rate        | 0.000735  |
|    loss                 | -0.02     |
|    n_updates            | 31670     |
|    policy_gradient_loss | 0.0143    |
|    std                  | 0.121     |
|    value_loss           | 0.0112    |
---------------------------------------
box reached target
Eval num_timesteps=6490000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1         |
| time/                   |            |
|    total_timesteps      | 6490000    |
| train/                  |            |
|    approx_kl            | 0.37593836 |
|    clip_fraction        | 0.476      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.36       |
|    explained_variance   | -0.0925    |
|    learning_rate        | 0.000735   |
|    loss                 | -0.0246    |
|    n_updates            | 31680      |
|    policy_gradient_loss | -0.00151   |
|    std                  | 0.122      |
|    value_loss           | 0.0104     |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 3169    |
|    time_elapsed    | 10282   |
|    total_timesteps | 6490112 |
--------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3170      |
|    time_elapsed         | 10285     |
|    total_timesteps      | 6492160   |
| train/                  |           |
|    approx_kl            | 0.4645496 |
|    clip_fraction        | 0.485     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.38      |
|    explained_variance   | 0.583     |
|    learning_rate        | 0.000734  |
|    loss                 | -0.0192   |
|    n_updates            | 31690     |
|    policy_gradient_loss | 0.0118    |
|    std                  | 0.12      |
|    value_loss           | 0.0329    |
---------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3171      |
|    time_elapsed         | 10288     |
|    total_timesteps      | 6494208   |
| train/                  |           |
|    approx_kl            | 1.2909896 |
|    clip_fraction        | 0.494     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.41      |
|    explained_variance   | 0.624     |
|    learning_rate        | 0.000734  |
|    loss                 | -0.0207   |
|    n_updates            | 31700     |
|    policy_gradient_loss | 0.0234    |
|    std                  | 0.118     |
|    value_loss           | 0.00634   |
---------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3172      |
|    time_elapsed         | 10291     |
|    total_timesteps      | 6496256   |
| train/                  |           |
|    approx_kl            | 0.4570495 |
|    clip_fraction        | 0.463     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.44      |
|    explained_variance   | -0.00992  |
|    learning_rate        | 0.000734  |
|    loss                 | -0.051    |
|    n_updates            | 31710     |
|    policy_gradient_loss | -0.000205 |
|    std                  | 0.117     |
|    value_loss           | 0.0085    |
---------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3173       |
|    time_elapsed         | 10294      |
|    total_timesteps      | 6498304    |
| train/                  |            |
|    approx_kl            | 0.76479864 |
|    clip_fraction        | 0.511      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.46       |
|    explained_variance   | 0.639      |
|    learning_rate        | 0.000733   |
|    loss                 | -0.036     |
|    n_updates            | 31720      |
|    policy_gradient_loss | -0.00259   |
|    std                  | 0.115      |
|    value_loss           | 0.0105     |
----------------------------------------
box reached target
Eval num_timesteps=6500000, episode_reward=0.31 +/- 2.35
Episode length: 276.40 +/- 47.20
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 276        |
|    mean_reward          | 0.306      |
| time/                   |            |
|    total_timesteps      | 6500000    |
| train/                  |            |
|    approx_kl            | 0.67678356 |
|    clip_fraction        | 0.549      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.5        |
|    explained_variance   | 0.473      |
|    learning_rate        | 0.000733   |
|    loss                 | -0.0251    |
|    n_updates            | 31730      |
|    policy_gradient_loss | 0.0152     |
|    std                  | 0.113      |
|    value_loss           | 0.0432     |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 3174    |
|    time_elapsed    | 10298   |
|    total_timesteps | 6500352 |
--------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3175       |
|    time_elapsed         | 10301      |
|    total_timesteps      | 6502400    |
| train/                  |            |
|    approx_kl            | 0.63733983 |
|    clip_fraction        | 0.514      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.52       |
|    explained_variance   | 0.216      |
|    learning_rate        | 0.000732   |
|    loss                 | 0.0589     |
|    n_updates            | 31740      |
|    policy_gradient_loss | 0.0159     |
|    std                  | 0.112      |
|    value_loss           | 0.00668    |
----------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3176      |
|    time_elapsed         | 10304     |
|    total_timesteps      | 6504448   |
| train/                  |           |
|    approx_kl            | 0.4242004 |
|    clip_fraction        | 0.421     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.52      |
|    explained_variance   | 0.61      |
|    learning_rate        | 0.000732  |
|    loss                 | -0.02     |
|    n_updates            | 31750     |
|    policy_gradient_loss | 0.0284    |
|    std                  | 0.112     |
|    value_loss           | 0.0481    |
---------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3177      |
|    time_elapsed         | 10307     |
|    total_timesteps      | 6506496   |
| train/                  |           |
|    approx_kl            | 0.8057746 |
|    clip_fraction        | 0.518     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.54      |
|    explained_variance   | 0.745     |
|    learning_rate        | 0.000732  |
|    loss                 | 0.0117    |
|    n_updates            | 31760     |
|    policy_gradient_loss | 0.00559   |
|    std                  | 0.111     |
|    value_loss           | 0.0366    |
---------------------------------------
--------------------------------------
| time/                   |          |
|    fps                  | 631      |
|    iterations           | 3178     |
|    time_elapsed         | 10310    |
|    total_timesteps      | 6508544  |
| train/                  |          |
|    approx_kl            | 0.587446 |
|    clip_fraction        | 0.508    |
|    clip_range           | 0.2      |
|    entropy_loss         | 1.55     |
|    explained_variance   | 0.611    |
|    learning_rate        | 0.000731 |
|    loss                 | 0.0265   |
|    n_updates            | 31770    |
|    policy_gradient_loss | 0.00449  |
|    std                  | 0.111    |
|    value_loss           | 0.00483  |
--------------------------------------
box reached target
Eval num_timesteps=6510000, episode_reward=-0.95 +/- 0.10
Episode length: 300.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 300       |
|    mean_reward          | -0.949    |
| time/                   |           |
|    total_timesteps      | 6510000   |
| train/                  |           |
|    approx_kl            | 0.9469665 |
|    clip_fraction        | 0.522     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.54      |
|    explained_variance   | 0.209     |
|    learning_rate        | 0.000731  |
|    loss                 | 0.077     |
|    n_updates            | 31780     |
|    policy_gradient_loss | 0.019     |
|    std                  | 0.112     |
|    value_loss           | 0.0209    |
---------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 3179    |
|    time_elapsed    | 10314   |
|    total_timesteps | 6510592 |
--------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3180       |
|    time_elapsed         | 10317      |
|    total_timesteps      | 6512640    |
| train/                  |            |
|    approx_kl            | 0.62936145 |
|    clip_fraction        | 0.546      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.52       |
|    explained_variance   | 0.517      |
|    learning_rate        | 0.00073    |
|    loss                 | 0.0333     |
|    n_updates            | 31790      |
|    policy_gradient_loss | 0.0299     |
|    std                  | 0.114      |
|    value_loss           | 0.0603     |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3181       |
|    time_elapsed         | 10320      |
|    total_timesteps      | 6514688    |
| train/                  |            |
|    approx_kl            | 0.48068365 |
|    clip_fraction        | 0.449      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.54       |
|    explained_variance   | 0.522      |
|    learning_rate        | 0.00073    |
|    loss                 | 0.0469     |
|    n_updates            | 31800      |
|    policy_gradient_loss | 0.0132     |
|    std                  | 0.11       |
|    value_loss           | 0.0238     |
----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3182      |
|    time_elapsed         | 10323     |
|    total_timesteps      | 6516736   |
| train/                  |           |
|    approx_kl            | 1.1703527 |
|    clip_fraction        | 0.524     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.56      |
|    explained_variance   | 0.644     |
|    learning_rate        | 0.00073   |
|    loss                 | 0.0428    |
|    n_updates            | 31810     |
|    policy_gradient_loss | 0.0172    |
|    std                  | 0.11      |
|    value_loss           | 0.0245    |
---------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3183      |
|    time_elapsed         | 10326     |
|    total_timesteps      | 6518784   |
| train/                  |           |
|    approx_kl            | 0.7733855 |
|    clip_fraction        | 0.554     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.57      |
|    explained_variance   | 0.5       |
|    learning_rate        | 0.000729  |
|    loss                 | -0.0357   |
|    n_updates            | 31820     |
|    policy_gradient_loss | 0.00367   |
|    std                  | 0.109     |
|    value_loss           | 0.0233    |
---------------------------------------
box reached target
box reached target
Eval num_timesteps=6520000, episode_reward=0.27 +/- 2.54
Episode length: 272.60 +/- 54.80
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 273        |
|    mean_reward          | 0.268      |
| time/                   |            |
|    total_timesteps      | 6520000    |
| train/                  |            |
|    approx_kl            | 0.84962374 |
|    clip_fraction        | 0.542      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.58       |
|    explained_variance   | 0.587      |
|    learning_rate        | 0.000729   |
|    loss                 | 0.0528     |
|    n_updates            | 31830      |
|    policy_gradient_loss | 0.00319    |
|    std                  | 0.109      |
|    value_loss           | 0.0242     |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 3184    |
|    time_elapsed    | 10330   |
|    total_timesteps | 6520832 |
--------------------------------
--------------------------------------
| time/                   |          |
|    fps                  | 631      |
|    iterations           | 3185     |
|    time_elapsed         | 10333    |
|    total_timesteps      | 6522880  |
| train/                  |          |
|    approx_kl            | 0.557716 |
|    clip_fraction        | 0.466    |
|    clip_range           | 0.2      |
|    entropy_loss         | 1.6      |
|    explained_variance   | 0.224    |
|    learning_rate        | 0.000728 |
|    loss                 | -0.00748 |
|    n_updates            | 31840    |
|    policy_gradient_loss | 0.0113   |
|    std                  | 0.109    |
|    value_loss           | 0.0365   |
--------------------------------------
box reached target
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3186      |
|    time_elapsed         | 10336     |
|    total_timesteps      | 6524928   |
| train/                  |           |
|    approx_kl            | 0.4631623 |
|    clip_fraction        | 0.459     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.56      |
|    explained_variance   | 0.252     |
|    learning_rate        | 0.000728  |
|    loss                 | 0.0873    |
|    n_updates            | 31850     |
|    policy_gradient_loss | 0.00891   |
|    std                  | 0.112     |
|    value_loss           | 0.00771   |
---------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3187      |
|    time_elapsed         | 10339     |
|    total_timesteps      | 6526976   |
| train/                  |           |
|    approx_kl            | 0.4911521 |
|    clip_fraction        | 0.525     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.55      |
|    explained_variance   | 0.713     |
|    learning_rate        | 0.000728  |
|    loss                 | 0.0329    |
|    n_updates            | 31860     |
|    policy_gradient_loss | 0.0219    |
|    std                  | 0.111     |
|    value_loss           | 0.0273    |
---------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3188       |
|    time_elapsed         | 10342      |
|    total_timesteps      | 6529024    |
| train/                  |            |
|    approx_kl            | 0.40654555 |
|    clip_fraction        | 0.464      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.57       |
|    explained_variance   | 0.967      |
|    learning_rate        | 0.000727   |
|    loss                 | 0.0228     |
|    n_updates            | 31870      |
|    policy_gradient_loss | 0.00793    |
|    std                  | 0.11       |
|    value_loss           | 0.00864    |
----------------------------------------
Eval num_timesteps=6530000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1         |
| time/                   |            |
|    total_timesteps      | 6530000    |
| train/                  |            |
|    approx_kl            | 0.37352064 |
|    clip_fraction        | 0.505      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.54       |
|    explained_variance   | 0.743      |
|    learning_rate        | 0.000727   |
|    loss                 | 0.0575     |
|    n_updates            | 31880      |
|    policy_gradient_loss | 0.0241     |
|    std                  | 0.113      |
|    value_loss           | 0.0133     |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 3189    |
|    time_elapsed    | 10346   |
|    total_timesteps | 6531072 |
--------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3190      |
|    time_elapsed         | 10350     |
|    total_timesteps      | 6533120   |
| train/                  |           |
|    approx_kl            | 0.7424132 |
|    clip_fraction        | 0.504     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.51      |
|    explained_variance   | 0.231     |
|    learning_rate        | 0.000726  |
|    loss                 | -0.0449   |
|    n_updates            | 31890     |
|    policy_gradient_loss | 0.0008    |
|    std                  | 0.112     |
|    value_loss           | 0.00901   |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3191       |
|    time_elapsed         | 10353      |
|    total_timesteps      | 6535168    |
| train/                  |            |
|    approx_kl            | 0.40213734 |
|    clip_fraction        | 0.458      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.54       |
|    explained_variance   | 0.194      |
|    learning_rate        | 0.000726   |
|    loss                 | -0.022     |
|    n_updates            | 31900      |
|    policy_gradient_loss | 0.00301    |
|    std                  | 0.111      |
|    value_loss           | 0.00389    |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3192       |
|    time_elapsed         | 10356      |
|    total_timesteps      | 6537216    |
| train/                  |            |
|    approx_kl            | 0.63198245 |
|    clip_fraction        | 0.475      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.53       |
|    explained_variance   | 0.6        |
|    learning_rate        | 0.000726   |
|    loss                 | -0.0533    |
|    n_updates            | 31910      |
|    policy_gradient_loss | 0.0181     |
|    std                  | 0.113      |
|    value_loss           | 0.0122     |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3193       |
|    time_elapsed         | 10359      |
|    total_timesteps      | 6539264    |
| train/                  |            |
|    approx_kl            | 0.93766075 |
|    clip_fraction        | 0.496      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.57       |
|    explained_variance   | 0.648      |
|    learning_rate        | 0.000725   |
|    loss                 | -0.0112    |
|    n_updates            | 31920      |
|    policy_gradient_loss | 6.56e-05   |
|    std                  | 0.108      |
|    value_loss           | 0.036      |
----------------------------------------
box reached target
Eval num_timesteps=6540000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
--------------------------------------
| eval/                   |          |
|    mean_ep_length       | 300      |
|    mean_reward          | -1       |
| time/                   |          |
|    total_timesteps      | 6540000  |
| train/                  |          |
|    approx_kl            | 0.225528 |
|    clip_fraction        | 0.47     |
|    clip_range           | 0.2      |
|    entropy_loss         | 1.62     |
|    explained_variance   | 0.715    |
|    learning_rate        | 0.000725 |
|    loss                 | 0.103    |
|    n_updates            | 31930    |
|    policy_gradient_loss | 0.0157   |
|    std                  | 0.108    |
|    value_loss           | 0.0227   |
--------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 3194    |
|    time_elapsed    | 10363   |
|    total_timesteps | 6541312 |
--------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3195       |
|    time_elapsed         | 10366      |
|    total_timesteps      | 6543360    |
| train/                  |            |
|    approx_kl            | 0.40171957 |
|    clip_fraction        | 0.512      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.61       |
|    explained_variance   | 0.68       |
|    learning_rate        | 0.000724   |
|    loss                 | -0.00136   |
|    n_updates            | 31940      |
|    policy_gradient_loss | 0.0287     |
|    std                  | 0.109      |
|    value_loss           | 0.0132     |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3196       |
|    time_elapsed         | 10369      |
|    total_timesteps      | 6545408    |
| train/                  |            |
|    approx_kl            | 0.32359344 |
|    clip_fraction        | 0.511      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.57       |
|    explained_variance   | 0.814      |
|    learning_rate        | 0.000724   |
|    loss                 | 0.0169     |
|    n_updates            | 31950      |
|    policy_gradient_loss | 0.0217     |
|    std                  | 0.112      |
|    value_loss           | 0.0163     |
----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3197      |
|    time_elapsed         | 10372     |
|    total_timesteps      | 6547456   |
| train/                  |           |
|    approx_kl            | 2.2461178 |
|    clip_fraction        | 0.461     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.56      |
|    explained_variance   | 0.673     |
|    learning_rate        | 0.000724  |
|    loss                 | -0.0402   |
|    n_updates            | 31960     |
|    policy_gradient_loss | 0.0129    |
|    std                  | 0.11      |
|    value_loss           | 0.0384    |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3198       |
|    time_elapsed         | 10375      |
|    total_timesteps      | 6549504    |
| train/                  |            |
|    approx_kl            | 0.61847365 |
|    clip_fraction        | 0.446      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.6        |
|    explained_variance   | 0.491      |
|    learning_rate        | 0.000723   |
|    loss                 | -0.00675   |
|    n_updates            | 31970      |
|    policy_gradient_loss | 0.0141     |
|    std                  | 0.107      |
|    value_loss           | 0.0152     |
----------------------------------------
box reached target
box reached target
Eval num_timesteps=6550000, episode_reward=0.26 +/- 2.51
Episode length: 283.40 +/- 33.20
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 283        |
|    mean_reward          | 0.257      |
| time/                   |            |
|    total_timesteps      | 6550000    |
| train/                  |            |
|    approx_kl            | 0.45938706 |
|    clip_fraction        | 0.517      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.59       |
|    explained_variance   | 0.314      |
|    learning_rate        | 0.000723   |
|    loss                 | -0.0295    |
|    n_updates            | 31980      |
|    policy_gradient_loss | -0.000491  |
|    std                  | 0.11       |
|    value_loss           | 0.00841    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 3199    |
|    time_elapsed    | 10379   |
|    total_timesteps | 6551552 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3200       |
|    time_elapsed         | 10382      |
|    total_timesteps      | 6553600    |
| train/                  |            |
|    approx_kl            | 0.32191527 |
|    clip_fraction        | 0.488      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.54       |
|    explained_variance   | 0.607      |
|    learning_rate        | 0.000722   |
|    loss                 | 0.0291     |
|    n_updates            | 31990      |
|    policy_gradient_loss | 0.0217     |
|    std                  | 0.113      |
|    value_loss           | 0.0165     |
----------------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3201       |
|    time_elapsed         | 10385      |
|    total_timesteps      | 6555648    |
| train/                  |            |
|    approx_kl            | 0.60069966 |
|    clip_fraction        | 0.511      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.53       |
|    explained_variance   | 0.648      |
|    learning_rate        | 0.000722   |
|    loss                 | 0.0226     |
|    n_updates            | 32000      |
|    policy_gradient_loss | 0.0258     |
|    std                  | 0.112      |
|    value_loss           | 0.0149     |
----------------------------------------
--------------------------------------
| time/                   |          |
|    fps                  | 631      |
|    iterations           | 3202     |
|    time_elapsed         | 10388    |
|    total_timesteps      | 6557696  |
| train/                  |          |
|    approx_kl            | 0.64177  |
|    clip_fraction        | 0.557    |
|    clip_range           | 0.2      |
|    entropy_loss         | 1.52     |
|    explained_variance   | -0.548   |
|    learning_rate        | 0.000722 |
|    loss                 | 0.0782   |
|    n_updates            | 32010    |
|    policy_gradient_loss | 0.0449   |
|    std                  | 0.114    |
|    value_loss           | 0.0621   |
--------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3203      |
|    time_elapsed         | 10391     |
|    total_timesteps      | 6559744   |
| train/                  |           |
|    approx_kl            | 0.5887085 |
|    clip_fraction        | 0.446     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.51      |
|    explained_variance   | 0.456     |
|    learning_rate        | 0.000721  |
|    loss                 | -0.0218   |
|    n_updates            | 32020     |
|    policy_gradient_loss | 0.00656   |
|    std                  | 0.114     |
|    value_loss           | 0.0101    |
---------------------------------------
box reached target
Eval num_timesteps=6560000, episode_reward=0.38 +/- 2.51
Episode length: 282.40 +/- 35.20
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 282        |
|    mean_reward          | 0.378      |
| time/                   |            |
|    total_timesteps      | 6560000    |
| train/                  |            |
|    approx_kl            | 0.52774715 |
|    clip_fraction        | 0.486      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.51       |
|    explained_variance   | 0.861      |
|    learning_rate        | 0.000721   |
|    loss                 | 0.00323    |
|    n_updates            | 32030      |
|    policy_gradient_loss | 0.00222    |
|    std                  | 0.113      |
|    value_loss           | 0.0133     |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 3204    |
|    time_elapsed    | 10395   |
|    total_timesteps | 6561792 |
--------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3205      |
|    time_elapsed         | 10398     |
|    total_timesteps      | 6563840   |
| train/                  |           |
|    approx_kl            | 0.6458739 |
|    clip_fraction        | 0.525     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.53      |
|    explained_variance   | 0.187     |
|    learning_rate        | 0.00072   |
|    loss                 | -0.0443   |
|    n_updates            | 32040     |
|    policy_gradient_loss | 0.0131    |
|    std                  | 0.112     |
|    value_loss           | 0.00654   |
---------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3206      |
|    time_elapsed         | 10401     |
|    total_timesteps      | 6565888   |
| train/                  |           |
|    approx_kl            | 0.8449861 |
|    clip_fraction        | 0.513     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.55      |
|    explained_variance   | 0.747     |
|    learning_rate        | 0.00072   |
|    loss                 | 0.0296    |
|    n_updates            | 32050     |
|    policy_gradient_loss | 0.0169    |
|    std                  | 0.112     |
|    value_loss           | 0.0225    |
---------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3207      |
|    time_elapsed         | 10404     |
|    total_timesteps      | 6567936   |
| train/                  |           |
|    approx_kl            | 0.6661231 |
|    clip_fraction        | 0.536     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.54      |
|    explained_variance   | 0.244     |
|    learning_rate        | 0.00072   |
|    loss                 | -0.000245 |
|    n_updates            | 32060     |
|    policy_gradient_loss | 0.0247    |
|    std                  | 0.112     |
|    value_loss           | 0.00453   |
---------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3208      |
|    time_elapsed         | 10407     |
|    total_timesteps      | 6569984   |
| train/                  |           |
|    approx_kl            | 3.1101606 |
|    clip_fraction        | 0.523     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.55      |
|    explained_variance   | 0.372     |
|    learning_rate        | 0.000719  |
|    loss                 | -0.0111   |
|    n_updates            | 32070     |
|    policy_gradient_loss | 0.00665   |
|    std                  | 0.111     |
|    value_loss           | 0.0087    |
---------------------------------------
Eval num_timesteps=6570000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1         |
| time/                   |            |
|    total_timesteps      | 6570000    |
| train/                  |            |
|    approx_kl            | 0.72607416 |
|    clip_fraction        | 0.497      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.55       |
|    explained_variance   | 0.482      |
|    learning_rate        | 0.000719   |
|    loss                 | 0.458      |
|    n_updates            | 32080      |
|    policy_gradient_loss | 0.0418     |
|    std                  | 0.112      |
|    value_loss           | 0.00807    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 3209    |
|    time_elapsed    | 10411   |
|    total_timesteps | 6572032 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3210       |
|    time_elapsed         | 10414      |
|    total_timesteps      | 6574080    |
| train/                  |            |
|    approx_kl            | 0.20463476 |
|    clip_fraction        | 0.443      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.54       |
|    explained_variance   | 0.445      |
|    learning_rate        | 0.000718   |
|    loss                 | 0.00282    |
|    n_updates            | 32090      |
|    policy_gradient_loss | 0.0258     |
|    std                  | 0.112      |
|    value_loss           | 0.00655    |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3211       |
|    time_elapsed         | 10418      |
|    total_timesteps      | 6576128    |
| train/                  |            |
|    approx_kl            | 0.46487844 |
|    clip_fraction        | 0.451      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.54       |
|    explained_variance   | 0.574      |
|    learning_rate        | 0.000718   |
|    loss                 | 0.0698     |
|    n_updates            | 32100      |
|    policy_gradient_loss | 0.0168     |
|    std                  | 0.112      |
|    value_loss           | 0.00457    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3212       |
|    time_elapsed         | 10421      |
|    total_timesteps      | 6578176    |
| train/                  |            |
|    approx_kl            | 0.46211672 |
|    clip_fraction        | 0.5        |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.56       |
|    explained_variance   | 0.9        |
|    learning_rate        | 0.000718   |
|    loss                 | -0.0383    |
|    n_updates            | 32110      |
|    policy_gradient_loss | 0.0187     |
|    std                  | 0.111      |
|    value_loss           | 0.0114     |
----------------------------------------
Eval num_timesteps=6580000, episode_reward=-0.22 +/- 0.50
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -0.22      |
| time/                   |            |
|    total_timesteps      | 6580000    |
| train/                  |            |
|    approx_kl            | 0.33605146 |
|    clip_fraction        | 0.428      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.54       |
|    explained_variance   | 0.0474     |
|    learning_rate        | 0.000717   |
|    loss                 | 0.0613     |
|    n_updates            | 32120      |
|    policy_gradient_loss | 0.0137     |
|    std                  | 0.114      |
|    value_loss           | 0.00672    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 3213    |
|    time_elapsed    | 10426   |
|    total_timesteps | 6580224 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3214       |
|    time_elapsed         | 10429      |
|    total_timesteps      | 6582272    |
| train/                  |            |
|    approx_kl            | 0.35001886 |
|    clip_fraction        | 0.488      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.5        |
|    explained_variance   | 0.201      |
|    learning_rate        | 0.000717   |
|    loss                 | 0.0322     |
|    n_updates            | 32130      |
|    policy_gradient_loss | 0.00581    |
|    std                  | 0.115      |
|    value_loss           | 0.0022     |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3215       |
|    time_elapsed         | 10432      |
|    total_timesteps      | 6584320    |
| train/                  |            |
|    approx_kl            | 0.44738173 |
|    clip_fraction        | 0.487      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.52       |
|    explained_variance   | 0.8        |
|    learning_rate        | 0.000716   |
|    loss                 | -0.000628  |
|    n_updates            | 32140      |
|    policy_gradient_loss | -0.0081    |
|    std                  | 0.112      |
|    value_loss           | 0.00457    |
----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3216      |
|    time_elapsed         | 10435     |
|    total_timesteps      | 6586368   |
| train/                  |           |
|    approx_kl            | 0.6065625 |
|    clip_fraction        | 0.472     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.53      |
|    explained_variance   | 0.531     |
|    learning_rate        | 0.000716  |
|    loss                 | -0.0154   |
|    n_updates            | 32150     |
|    policy_gradient_loss | 0.0162    |
|    std                  | 0.113     |
|    value_loss           | 0.0038    |
---------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3217      |
|    time_elapsed         | 10438     |
|    total_timesteps      | 6588416   |
| train/                  |           |
|    approx_kl            | 0.2221507 |
|    clip_fraction        | 0.474     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.53      |
|    explained_variance   | -0.467    |
|    learning_rate        | 0.000716  |
|    loss                 | 0.0324    |
|    n_updates            | 32160     |
|    policy_gradient_loss | 0.0216    |
|    std                  | 0.112     |
|    value_loss           | 0.00702   |
---------------------------------------
Eval num_timesteps=6590000, episode_reward=-0.66 +/- 0.67
Episode length: 300.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 300       |
|    mean_reward          | -0.664    |
| time/                   |           |
|    total_timesteps      | 6590000   |
| train/                  |           |
|    approx_kl            | 0.4136882 |
|    clip_fraction        | 0.475     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.55      |
|    explained_variance   | 0.714     |
|    learning_rate        | 0.000715  |
|    loss                 | -0.0202   |
|    n_updates            | 32170     |
|    policy_gradient_loss | 0.0194    |
|    std                  | 0.111     |
|    value_loss           | 0.0239    |
---------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 3218    |
|    time_elapsed    | 10442   |
|    total_timesteps | 6590464 |
--------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3219      |
|    time_elapsed         | 10445     |
|    total_timesteps      | 6592512   |
| train/                  |           |
|    approx_kl            | 1.4264522 |
|    clip_fraction        | 0.494     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.59      |
|    explained_variance   | 0.502     |
|    learning_rate        | 0.000715  |
|    loss                 | -0.0182   |
|    n_updates            | 32180     |
|    policy_gradient_loss | 0.00366   |
|    std                  | 0.108     |
|    value_loss           | 0.0108    |
---------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3220       |
|    time_elapsed         | 10448      |
|    total_timesteps      | 6594560    |
| train/                  |            |
|    approx_kl            | 0.19058122 |
|    clip_fraction        | 0.436      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.61       |
|    explained_variance   | 0.0843     |
|    learning_rate        | 0.000714   |
|    loss                 | 0.0253     |
|    n_updates            | 32190      |
|    policy_gradient_loss | 0.00854    |
|    std                  | 0.109      |
|    value_loss           | 0.00514    |
----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3221      |
|    time_elapsed         | 10451     |
|    total_timesteps      | 6596608   |
| train/                  |           |
|    approx_kl            | 1.0542841 |
|    clip_fraction        | 0.526     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.63      |
|    explained_variance   | 0.637     |
|    learning_rate        | 0.000714  |
|    loss                 | 0.0175    |
|    n_updates            | 32200     |
|    policy_gradient_loss | 0.00128   |
|    std                  | 0.105     |
|    value_loss           | 0.0192    |
---------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3222      |
|    time_elapsed         | 10454     |
|    total_timesteps      | 6598656   |
| train/                  |           |
|    approx_kl            | 0.6491351 |
|    clip_fraction        | 0.478     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.66      |
|    explained_variance   | 0.732     |
|    learning_rate        | 0.000714  |
|    loss                 | -0.0408   |
|    n_updates            | 32210     |
|    policy_gradient_loss | 0.0107    |
|    std                  | 0.106     |
|    value_loss           | 0.0124    |
---------------------------------------
Eval num_timesteps=6600000, episode_reward=-1.03 +/- 0.06
Episode length: 300.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 300       |
|    mean_reward          | -1.03     |
| time/                   |           |
|    total_timesteps      | 6600000   |
| train/                  |           |
|    approx_kl            | 0.9087852 |
|    clip_fraction        | 0.539     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.64      |
|    explained_variance   | 0.696     |
|    learning_rate        | 0.000713  |
|    loss                 | -0.0244   |
|    n_updates            | 32220     |
|    policy_gradient_loss | 0.0507    |
|    std                  | 0.107     |
|    value_loss           | 0.00501   |
---------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 3223    |
|    time_elapsed    | 10458   |
|    total_timesteps | 6600704 |
--------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3224      |
|    time_elapsed         | 10461     |
|    total_timesteps      | 6602752   |
| train/                  |           |
|    approx_kl            | 1.1226536 |
|    clip_fraction        | 0.475     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.65      |
|    explained_variance   | 0.64      |
|    learning_rate        | 0.000713  |
|    loss                 | -0.0639   |
|    n_updates            | 32230     |
|    policy_gradient_loss | 0.0007    |
|    std                  | 0.106     |
|    value_loss           | 0.00616   |
---------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3225      |
|    time_elapsed         | 10464     |
|    total_timesteps      | 6604800   |
| train/                  |           |
|    approx_kl            | 0.4179563 |
|    clip_fraction        | 0.495     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.65      |
|    explained_variance   | 0.751     |
|    learning_rate        | 0.000712  |
|    loss                 | -0.0561   |
|    n_updates            | 32240     |
|    policy_gradient_loss | 0.0199    |
|    std                  | 0.106     |
|    value_loss           | 0.00357   |
---------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3226      |
|    time_elapsed         | 10467     |
|    total_timesteps      | 6606848   |
| train/                  |           |
|    approx_kl            | 0.8903067 |
|    clip_fraction        | 0.547     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.65      |
|    explained_variance   | 0.609     |
|    learning_rate        | 0.000712  |
|    loss                 | 0.0138    |
|    n_updates            | 32250     |
|    policy_gradient_loss | 0.0436    |
|    std                  | 0.106     |
|    value_loss           | 0.0198    |
---------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3227      |
|    time_elapsed         | 10470     |
|    total_timesteps      | 6608896   |
| train/                  |           |
|    approx_kl            | 0.7098914 |
|    clip_fraction        | 0.559     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.65      |
|    explained_variance   | 0.631     |
|    learning_rate        | 0.000712  |
|    loss                 | 0.00902   |
|    n_updates            | 32260     |
|    policy_gradient_loss | 0.0239    |
|    std                  | 0.107     |
|    value_loss           | 0.0033    |
---------------------------------------
Eval num_timesteps=6610000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1         |
| time/                   |            |
|    total_timesteps      | 6610000    |
| train/                  |            |
|    approx_kl            | 0.43963566 |
|    clip_fraction        | 0.471      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.63       |
|    explained_variance   | 0.0674     |
|    learning_rate        | 0.000711   |
|    loss                 | 0.0786     |
|    n_updates            | 32270      |
|    policy_gradient_loss | 0.0124     |
|    std                  | 0.108      |
|    value_loss           | 0.0872     |
----------------------------------------
box reached target
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 3228    |
|    time_elapsed    | 10474   |
|    total_timesteps | 6610944 |
--------------------------------
box reached target
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3229      |
|    time_elapsed         | 10477     |
|    total_timesteps      | 6612992   |
| train/                  |           |
|    approx_kl            | 0.5748803 |
|    clip_fraction        | 0.524     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.61      |
|    explained_variance   | 0.437     |
|    learning_rate        | 0.000711  |
|    loss                 | -0.0396   |
|    n_updates            | 32280     |
|    policy_gradient_loss | 0.02      |
|    std                  | 0.11      |
|    value_loss           | 0.0118    |
---------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3230      |
|    time_elapsed         | 10480     |
|    total_timesteps      | 6615040   |
| train/                  |           |
|    approx_kl            | 0.6315062 |
|    clip_fraction        | 0.497     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.6       |
|    explained_variance   | 0.559     |
|    learning_rate        | 0.00071   |
|    loss                 | 0.0222    |
|    n_updates            | 32290     |
|    policy_gradient_loss | 0.00555   |
|    std                  | 0.109     |
|    value_loss           | 0.0456    |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3231       |
|    time_elapsed         | 10483      |
|    total_timesteps      | 6617088    |
| train/                  |            |
|    approx_kl            | 0.40216127 |
|    clip_fraction        | 0.466      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.6        |
|    explained_variance   | 0.593      |
|    learning_rate        | 0.00071    |
|    loss                 | 0.0313     |
|    n_updates            | 32300      |
|    policy_gradient_loss | 0.0156     |
|    std                  | 0.108      |
|    value_loss           | 0.0143     |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3232       |
|    time_elapsed         | 10486      |
|    total_timesteps      | 6619136    |
| train/                  |            |
|    approx_kl            | 0.45510292 |
|    clip_fraction        | 0.495      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.58       |
|    explained_variance   | 0.83       |
|    learning_rate        | 0.00071    |
|    loss                 | -0.00523   |
|    n_updates            | 32310      |
|    policy_gradient_loss | 0.00921    |
|    std                  | 0.109      |
|    value_loss           | 0.00459    |
----------------------------------------
Eval num_timesteps=6620000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 300       |
|    mean_reward          | -1        |
| time/                   |           |
|    total_timesteps      | 6620000   |
| train/                  |           |
|    approx_kl            | 1.0899915 |
|    clip_fraction        | 0.55      |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.59      |
|    explained_variance   | 0.603     |
|    learning_rate        | 0.000709  |
|    loss                 | -0.0265   |
|    n_updates            | 32320     |
|    policy_gradient_loss | 0.00707   |
|    std                  | 0.109     |
|    value_loss           | 0.0156    |
---------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 3233    |
|    time_elapsed    | 10490   |
|    total_timesteps | 6621184 |
--------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3234      |
|    time_elapsed         | 10493     |
|    total_timesteps      | 6623232   |
| train/                  |           |
|    approx_kl            | 0.2104326 |
|    clip_fraction        | 0.472     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.59      |
|    explained_variance   | 0.534     |
|    learning_rate        | 0.000709  |
|    loss                 | -0.0212   |
|    n_updates            | 32330     |
|    policy_gradient_loss | 0.00908   |
|    std                  | 0.109     |
|    value_loss           | 0.00467   |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3235       |
|    time_elapsed         | 10497      |
|    total_timesteps      | 6625280    |
| train/                  |            |
|    approx_kl            | 0.79369044 |
|    clip_fraction        | 0.496      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.61       |
|    explained_variance   | 0.511      |
|    learning_rate        | 0.000708   |
|    loss                 | -0.0257    |
|    n_updates            | 32340      |
|    policy_gradient_loss | 0.0196     |
|    std                  | 0.109      |
|    value_loss           | 0.00603    |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3236       |
|    time_elapsed         | 10500      |
|    total_timesteps      | 6627328    |
| train/                  |            |
|    approx_kl            | 0.99676466 |
|    clip_fraction        | 0.518      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.63       |
|    explained_variance   | 0.608      |
|    learning_rate        | 0.000708   |
|    loss                 | -0.00447   |
|    n_updates            | 32350      |
|    policy_gradient_loss | 0.00352    |
|    std                  | 0.106      |
|    value_loss           | 0.00845    |
----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3237      |
|    time_elapsed         | 10503     |
|    total_timesteps      | 6629376   |
| train/                  |           |
|    approx_kl            | 0.7727411 |
|    clip_fraction        | 0.519     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.64      |
|    explained_variance   | 0.636     |
|    learning_rate        | 0.000708  |
|    loss                 | -0.0091   |
|    n_updates            | 32360     |
|    policy_gradient_loss | 0.0116    |
|    std                  | 0.106     |
|    value_loss           | 0.0302    |
---------------------------------------
box reached target
box reached target
Eval num_timesteps=6630000, episode_reward=1.49 +/- 3.05
Episode length: 259.00 +/- 50.24
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 259        |
|    mean_reward          | 1.49       |
| time/                   |            |
|    total_timesteps      | 6630000    |
| train/                  |            |
|    approx_kl            | 0.26008147 |
|    clip_fraction        | 0.406      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.63       |
|    explained_variance   | 0.0714     |
|    learning_rate        | 0.000707   |
|    loss                 | -0.022     |
|    n_updates            | 32370      |
|    policy_gradient_loss | -0.000449  |
|    std                  | 0.107      |
|    value_loss           | 0.00421    |
----------------------------------------
box reached target
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 3238    |
|    time_elapsed    | 10506   |
|    total_timesteps | 6631424 |
--------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3239      |
|    time_elapsed         | 10510     |
|    total_timesteps      | 6633472   |
| train/                  |           |
|    approx_kl            | 0.3760572 |
|    clip_fraction        | 0.524     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.66      |
|    explained_variance   | -0.00876  |
|    learning_rate        | 0.000707  |
|    loss                 | -0.00545  |
|    n_updates            | 32380     |
|    policy_gradient_loss | 0.00713   |
|    std                  | 0.105     |
|    value_loss           | 0.091     |
---------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3240       |
|    time_elapsed         | 10513      |
|    total_timesteps      | 6635520    |
| train/                  |            |
|    approx_kl            | 0.28277847 |
|    clip_fraction        | 0.494      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.65       |
|    explained_variance   | 0.507      |
|    learning_rate        | 0.000706   |
|    loss                 | -0.0242    |
|    n_updates            | 32390      |
|    policy_gradient_loss | 0.0159     |
|    std                  | 0.106      |
|    value_loss           | 0.0116     |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3241       |
|    time_elapsed         | 10516      |
|    total_timesteps      | 6637568    |
| train/                  |            |
|    approx_kl            | 0.33902055 |
|    clip_fraction        | 0.482      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.62       |
|    explained_variance   | 0.822      |
|    learning_rate        | 0.000706   |
|    loss                 | 0.0427     |
|    n_updates            | 32400      |
|    policy_gradient_loss | 0.00487    |
|    std                  | 0.109      |
|    value_loss           | 0.0184     |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3242       |
|    time_elapsed         | 10519      |
|    total_timesteps      | 6639616    |
| train/                  |            |
|    approx_kl            | 0.38989586 |
|    clip_fraction        | 0.493      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.61       |
|    explained_variance   | 0.522      |
|    learning_rate        | 0.000706   |
|    loss                 | 0.00978    |
|    n_updates            | 32410      |
|    policy_gradient_loss | 0.0157     |
|    std                  | 0.108      |
|    value_loss           | 0.015      |
----------------------------------------
box reached target
Eval num_timesteps=6640000, episode_reward=0.22 +/- 2.43
Episode length: 277.80 +/- 44.40
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 278       |
|    mean_reward          | 0.215     |
| time/                   |           |
|    total_timesteps      | 6640000   |
| train/                  |           |
|    approx_kl            | 0.5109149 |
|    clip_fraction        | 0.484     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.58      |
|    explained_variance   | 0.532     |
|    learning_rate        | 0.000705  |
|    loss                 | 0.0125    |
|    n_updates            | 32420     |
|    policy_gradient_loss | 0.0212    |
|    std                  | 0.11      |
|    value_loss           | 0.0322    |
---------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 3243    |
|    time_elapsed    | 10523   |
|    total_timesteps | 6641664 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3244       |
|    time_elapsed         | 10526      |
|    total_timesteps      | 6643712    |
| train/                  |            |
|    approx_kl            | 0.60841566 |
|    clip_fraction        | 0.478      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.56       |
|    explained_variance   | 0.672      |
|    learning_rate        | 0.000705   |
|    loss                 | 0.00533    |
|    n_updates            | 32430      |
|    policy_gradient_loss | 0.00346    |
|    std                  | 0.11       |
|    value_loss           | 0.019      |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3245       |
|    time_elapsed         | 10529      |
|    total_timesteps      | 6645760    |
| train/                  |            |
|    approx_kl            | 0.50571775 |
|    clip_fraction        | 0.476      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.57       |
|    explained_variance   | 0.63       |
|    learning_rate        | 0.000704   |
|    loss                 | 0.0333     |
|    n_updates            | 32440      |
|    policy_gradient_loss | 0.0317     |
|    std                  | 0.11       |
|    value_loss           | 0.0109     |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3246       |
|    time_elapsed         | 10532      |
|    total_timesteps      | 6647808    |
| train/                  |            |
|    approx_kl            | 0.42796475 |
|    clip_fraction        | 0.479      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.57       |
|    explained_variance   | 0.189      |
|    learning_rate        | 0.000704   |
|    loss                 | -0.0157    |
|    n_updates            | 32450      |
|    policy_gradient_loss | 0.0118     |
|    std                  | 0.11       |
|    value_loss           | 0.12       |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3247       |
|    time_elapsed         | 10535      |
|    total_timesteps      | 6649856    |
| train/                  |            |
|    approx_kl            | 0.29648256 |
|    clip_fraction        | 0.505      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.55       |
|    explained_variance   | 0.474      |
|    learning_rate        | 0.000704   |
|    loss                 | 0.11       |
|    n_updates            | 32460      |
|    policy_gradient_loss | 0.0216     |
|    std                  | 0.112      |
|    value_loss           | 0.00517    |
----------------------------------------
Eval num_timesteps=6650000, episode_reward=-0.67 +/- 0.65
Episode length: 300.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 300       |
|    mean_reward          | -0.673    |
| time/                   |           |
|    total_timesteps      | 6650000   |
| train/                  |           |
|    approx_kl            | 0.3524857 |
|    clip_fraction        | 0.491     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.52      |
|    explained_variance   | -0.223    |
|    learning_rate        | 0.000703  |
|    loss                 | -0.0189   |
|    n_updates            | 32470     |
|    policy_gradient_loss | 0.0282    |
|    std                  | 0.114     |
|    value_loss           | 0.039     |
---------------------------------------
box reached target
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 3248    |
|    time_elapsed    | 10539   |
|    total_timesteps | 6651904 |
--------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3249      |
|    time_elapsed         | 10543     |
|    total_timesteps      | 6653952   |
| train/                  |           |
|    approx_kl            | 1.4806093 |
|    clip_fraction        | 0.555     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.51      |
|    explained_variance   | 0.704     |
|    learning_rate        | 0.000703  |
|    loss                 | -0.0262   |
|    n_updates            | 32480     |
|    policy_gradient_loss | 0.0157    |
|    std                  | 0.113     |
|    value_loss           | 0.0163    |
---------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3250      |
|    time_elapsed         | 10546     |
|    total_timesteps      | 6656000   |
| train/                  |           |
|    approx_kl            | 0.5177315 |
|    clip_fraction        | 0.511     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.52      |
|    explained_variance   | 0.49      |
|    learning_rate        | 0.000702  |
|    loss                 | 0.0519    |
|    n_updates            | 32490     |
|    policy_gradient_loss | 0.0201    |
|    std                  | 0.113     |
|    value_loss           | 0.0108    |
---------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3251      |
|    time_elapsed         | 10549     |
|    total_timesteps      | 6658048   |
| train/                  |           |
|    approx_kl            | 0.7550944 |
|    clip_fraction        | 0.523     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.51      |
|    explained_variance   | 0.0959    |
|    learning_rate        | 0.000702  |
|    loss                 | -0.0109   |
|    n_updates            | 32500     |
|    policy_gradient_loss | 0.0172    |
|    std                  | 0.114     |
|    value_loss           | 0.00352   |
---------------------------------------
Eval num_timesteps=6660000, episode_reward=-0.65 +/- 0.71
Episode length: 300.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 300       |
|    mean_reward          | -0.647    |
| time/                   |           |
|    total_timesteps      | 6660000   |
| train/                  |           |
|    approx_kl            | 0.5743719 |
|    clip_fraction        | 0.49      |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.51      |
|    explained_variance   | -0.413    |
|    learning_rate        | 0.000702  |
|    loss                 | -0.0177   |
|    n_updates            | 32510     |
|    policy_gradient_loss | 0.0156    |
|    std                  | 0.114     |
|    value_loss           | 0.00453   |
---------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 3252    |
|    time_elapsed    | 10554   |
|    total_timesteps | 6660096 |
--------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3253       |
|    time_elapsed         | 10557      |
|    total_timesteps      | 6662144    |
| train/                  |            |
|    approx_kl            | 0.29615283 |
|    clip_fraction        | 0.431      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.52       |
|    explained_variance   | 0.0261     |
|    learning_rate        | 0.000701   |
|    loss                 | 0.0205     |
|    n_updates            | 32520      |
|    policy_gradient_loss | 0.00813    |
|    std                  | 0.112      |
|    value_loss           | 0.00221    |
----------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3254      |
|    time_elapsed         | 10560     |
|    total_timesteps      | 6664192   |
| train/                  |           |
|    approx_kl            | 1.1610123 |
|    clip_fraction        | 0.494     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.52      |
|    explained_variance   | 0.602     |
|    learning_rate        | 0.000701  |
|    loss                 | 0.00372   |
|    n_updates            | 32530     |
|    policy_gradient_loss | 0.0352    |
|    std                  | 0.113     |
|    value_loss           | 0.0182    |
---------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3255      |
|    time_elapsed         | 10563     |
|    total_timesteps      | 6666240   |
| train/                  |           |
|    approx_kl            | 1.4855293 |
|    clip_fraction        | 0.558     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.5       |
|    explained_variance   | 0.786     |
|    learning_rate        | 0.0007    |
|    loss                 | -0.0495   |
|    n_updates            | 32540     |
|    policy_gradient_loss | 0.0283    |
|    std                  | 0.114     |
|    value_loss           | 0.0144    |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3256       |
|    time_elapsed         | 10566      |
|    total_timesteps      | 6668288    |
| train/                  |            |
|    approx_kl            | 0.36705944 |
|    clip_fraction        | 0.437      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.45       |
|    explained_variance   | 0.758      |
|    learning_rate        | 0.0007     |
|    loss                 | 0.0129     |
|    n_updates            | 32550      |
|    policy_gradient_loss | 0.00985    |
|    std                  | 0.118      |
|    value_loss           | 0.0188     |
----------------------------------------
box reached target
Eval num_timesteps=6670000, episode_reward=-0.73 +/- 0.53
Episode length: 300.00 +/- 0.00
--------------------------------------
| eval/                   |          |
|    mean_ep_length       | 300      |
|    mean_reward          | -0.735   |
| time/                   |          |
|    total_timesteps      | 6670000  |
| train/                  |          |
|    approx_kl            | 0.310755 |
|    clip_fraction        | 0.416    |
|    clip_range           | 0.2      |
|    entropy_loss         | 1.42     |
|    explained_variance   | -0.0162  |
|    learning_rate        | 0.0007   |
|    loss                 | 0.0363   |
|    n_updates            | 32560    |
|    policy_gradient_loss | -0.00166 |
|    std                  | 0.119    |
|    value_loss           | 0.00617  |
--------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 3257    |
|    time_elapsed    | 10570   |
|    total_timesteps | 6670336 |
--------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3258      |
|    time_elapsed         | 10573     |
|    total_timesteps      | 6672384   |
| train/                  |           |
|    approx_kl            | 0.8540025 |
|    clip_fraction        | 0.503     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.44      |
|    explained_variance   | 0.806     |
|    learning_rate        | 0.000699  |
|    loss                 | 0.0171    |
|    n_updates            | 32570     |
|    policy_gradient_loss | 0.0299    |
|    std                  | 0.117     |
|    value_loss           | 0.0152    |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3259       |
|    time_elapsed         | 10576      |
|    total_timesteps      | 6674432    |
| train/                  |            |
|    approx_kl            | 0.41026884 |
|    clip_fraction        | 0.454      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.47       |
|    explained_variance   | 0.744      |
|    learning_rate        | 0.000699   |
|    loss                 | -0.00724   |
|    n_updates            | 32580      |
|    policy_gradient_loss | 0.013      |
|    std                  | 0.115      |
|    value_loss           | 0.00786    |
----------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3260      |
|    time_elapsed         | 10579     |
|    total_timesteps      | 6676480   |
| train/                  |           |
|    approx_kl            | 1.6440172 |
|    clip_fraction        | 0.497     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.51      |
|    explained_variance   | 0.726     |
|    learning_rate        | 0.000698  |
|    loss                 | -0.0473   |
|    n_updates            | 32590     |
|    policy_gradient_loss | 0.00441   |
|    std                  | 0.112     |
|    value_loss           | 0.00382   |
---------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3261      |
|    time_elapsed         | 10582     |
|    total_timesteps      | 6678528   |
| train/                  |           |
|    approx_kl            | 0.6857408 |
|    clip_fraction        | 0.491     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.52      |
|    explained_variance   | 0.00691   |
|    learning_rate        | 0.000698  |
|    loss                 | 0.135     |
|    n_updates            | 32600     |
|    policy_gradient_loss | 0.0312    |
|    std                  | 0.113     |
|    value_loss           | 0.0561    |
---------------------------------------
Eval num_timesteps=6680000, episode_reward=-1.01 +/- 0.02
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1.01      |
| time/                   |            |
|    total_timesteps      | 6680000    |
| train/                  |            |
|    approx_kl            | 0.88409853 |
|    clip_fraction        | 0.486      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.52       |
|    explained_variance   | 0.279      |
|    learning_rate        | 0.000698   |
|    loss                 | -0.0111    |
|    n_updates            | 32610      |
|    policy_gradient_loss | 0.014      |
|    std                  | 0.113      |
|    value_loss           | 0.0314     |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 3262    |
|    time_elapsed    | 10586   |
|    total_timesteps | 6680576 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3263       |
|    time_elapsed         | 10589      |
|    total_timesteps      | 6682624    |
| train/                  |            |
|    approx_kl            | 0.23316865 |
|    clip_fraction        | 0.416      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.53       |
|    explained_variance   | -0.586     |
|    learning_rate        | 0.000697   |
|    loss                 | -0.00898   |
|    n_updates            | 32620      |
|    policy_gradient_loss | 0.00832    |
|    std                  | 0.111      |
|    value_loss           | 0.00864    |
----------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3264      |
|    time_elapsed         | 10592     |
|    total_timesteps      | 6684672   |
| train/                  |           |
|    approx_kl            | 1.1818621 |
|    clip_fraction        | 0.466     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.54      |
|    explained_variance   | 0.54      |
|    learning_rate        | 0.000697  |
|    loss                 | -0.0347   |
|    n_updates            | 32630     |
|    policy_gradient_loss | 0.0135    |
|    std                  | 0.111     |
|    value_loss           | 0.00827   |
---------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3265       |
|    time_elapsed         | 10596      |
|    total_timesteps      | 6686720    |
| train/                  |            |
|    approx_kl            | 0.66866064 |
|    clip_fraction        | 0.56       |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.53       |
|    explained_variance   | 0.741      |
|    learning_rate        | 0.000696   |
|    loss                 | -0.0307    |
|    n_updates            | 32640      |
|    policy_gradient_loss | 0.0424     |
|    std                  | 0.114      |
|    value_loss           | 0.0188     |
----------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3266      |
|    time_elapsed         | 10599     |
|    total_timesteps      | 6688768   |
| train/                  |           |
|    approx_kl            | 0.6351211 |
|    clip_fraction        | 0.449     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.49      |
|    explained_variance   | -0.0792   |
|    learning_rate        | 0.000696  |
|    loss                 | -0.037    |
|    n_updates            | 32650     |
|    policy_gradient_loss | 0.00966   |
|    std                  | 0.114     |
|    value_loss           | 0.0627    |
---------------------------------------
box reached target
Eval num_timesteps=6690000, episode_reward=-0.67 +/- 0.65
Episode length: 300.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 300       |
|    mean_reward          | -0.675    |
| time/                   |           |
|    total_timesteps      | 6690000   |
| train/                  |           |
|    approx_kl            | 0.6747626 |
|    clip_fraction        | 0.53      |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.47      |
|    explained_variance   | 0.671     |
|    learning_rate        | 0.000696  |
|    loss                 | 0.000258  |
|    n_updates            | 32660     |
|    policy_gradient_loss | 0.0414    |
|    std                  | 0.117     |
|    value_loss           | 0.00768   |
---------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 3267    |
|    time_elapsed    | 10603   |
|    total_timesteps | 6690816 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3268       |
|    time_elapsed         | 10606      |
|    total_timesteps      | 6692864    |
| train/                  |            |
|    approx_kl            | 0.34482536 |
|    clip_fraction        | 0.485      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.47       |
|    explained_variance   | 0.358      |
|    learning_rate        | 0.000695   |
|    loss                 | 0.204      |
|    n_updates            | 32670      |
|    policy_gradient_loss | 0.00512    |
|    std                  | 0.115      |
|    value_loss           | 0.119      |
----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3269      |
|    time_elapsed         | 10609     |
|    total_timesteps      | 6694912   |
| train/                  |           |
|    approx_kl            | 1.6546966 |
|    clip_fraction        | 0.497     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.49      |
|    explained_variance   | 0.797     |
|    learning_rate        | 0.000695  |
|    loss                 | -0.00917  |
|    n_updates            | 32680     |
|    policy_gradient_loss | 0.0333    |
|    std                  | 0.112     |
|    value_loss           | 0.0168    |
---------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3270       |
|    time_elapsed         | 10612      |
|    total_timesteps      | 6696960    |
| train/                  |            |
|    approx_kl            | 0.36348158 |
|    clip_fraction        | 0.453      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.54       |
|    explained_variance   | 0.408      |
|    learning_rate        | 0.000694   |
|    loss                 | -0.042     |
|    n_updates            | 32690      |
|    policy_gradient_loss | 0.0153     |
|    std                  | 0.111      |
|    value_loss           | 0.00842    |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3271       |
|    time_elapsed         | 10615      |
|    total_timesteps      | 6699008    |
| train/                  |            |
|    approx_kl            | 0.99079573 |
|    clip_fraction        | 0.543      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.57       |
|    explained_variance   | 0.594      |
|    learning_rate        | 0.000694   |
|    loss                 | 0.0582     |
|    n_updates            | 32700      |
|    policy_gradient_loss | 0.00979    |
|    std                  | 0.109      |
|    value_loss           | 0.0184     |
----------------------------------------
Eval num_timesteps=6700000, episode_reward=-0.67 +/- 0.66
Episode length: 300.00 +/- 0.00
--------------------------------------
| eval/                   |          |
|    mean_ep_length       | 300      |
|    mean_reward          | -0.672   |
| time/                   |          |
|    total_timesteps      | 6700000  |
| train/                  |          |
|    approx_kl            | 4.270285 |
|    clip_fraction        | 0.553    |
|    clip_range           | 0.2      |
|    entropy_loss         | 1.59     |
|    explained_variance   | 0.909    |
|    learning_rate        | 0.000694 |
|    loss                 | 0.0502   |
|    n_updates            | 32710    |
|    policy_gradient_loss | 0.0311   |
|    std                  | 0.108    |
|    value_loss           | 0.0141   |
--------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 3272    |
|    time_elapsed    | 10619   |
|    total_timesteps | 6701056 |
--------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3273      |
|    time_elapsed         | 10622     |
|    total_timesteps      | 6703104   |
| train/                  |           |
|    approx_kl            | 1.0197104 |
|    clip_fraction        | 0.47      |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.62      |
|    explained_variance   | 0.655     |
|    learning_rate        | 0.000693  |
|    loss                 | -0.0338   |
|    n_updates            | 32720     |
|    policy_gradient_loss | -0.00499  |
|    std                  | 0.106     |
|    value_loss           | 0.0184    |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3274       |
|    time_elapsed         | 10625      |
|    total_timesteps      | 6705152    |
| train/                  |            |
|    approx_kl            | 0.37725645 |
|    clip_fraction        | 0.496      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.63       |
|    explained_variance   | 0.549      |
|    learning_rate        | 0.000693   |
|    loss                 | 0.0382     |
|    n_updates            | 32730      |
|    policy_gradient_loss | 0.0221     |
|    std                  | 0.108      |
|    value_loss           | 0.0818     |
----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3275      |
|    time_elapsed         | 10628     |
|    total_timesteps      | 6707200   |
| train/                  |           |
|    approx_kl            | 0.4367199 |
|    clip_fraction        | 0.505     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.62      |
|    explained_variance   | 0.132     |
|    learning_rate        | 0.000692  |
|    loss                 | -0.0149   |
|    n_updates            | 32740     |
|    policy_gradient_loss | 0.0174    |
|    std                  | 0.106     |
|    value_loss           | 0.0124    |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3276       |
|    time_elapsed         | 10631      |
|    total_timesteps      | 6709248    |
| train/                  |            |
|    approx_kl            | 0.33111233 |
|    clip_fraction        | 0.462      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.62       |
|    explained_variance   | 0.379      |
|    learning_rate        | 0.000692   |
|    loss                 | 0.0114     |
|    n_updates            | 32750      |
|    policy_gradient_loss | 0.0322     |
|    std                  | 0.109      |
|    value_loss           | 0.00614    |
----------------------------------------
Eval num_timesteps=6710000, episode_reward=-0.70 +/- 0.60
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -0.7       |
| time/                   |            |
|    total_timesteps      | 6710000    |
| train/                  |            |
|    approx_kl            | 0.48418558 |
|    clip_fraction        | 0.471      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.58       |
|    explained_variance   | 0.551      |
|    learning_rate        | 0.000692   |
|    loss                 | -0.00971   |
|    n_updates            | 32760      |
|    policy_gradient_loss | 0.0131     |
|    std                  | 0.11       |
|    value_loss           | 0.0109     |
----------------------------------------
box reached target
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 3277    |
|    time_elapsed    | 10635   |
|    total_timesteps | 6711296 |
--------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3278      |
|    time_elapsed         | 10638     |
|    total_timesteps      | 6713344   |
| train/                  |           |
|    approx_kl            | 0.7780845 |
|    clip_fraction        | 0.544     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.58      |
|    explained_variance   | 0.379     |
|    learning_rate        | 0.000691  |
|    loss                 | 0.0874    |
|    n_updates            | 32770     |
|    policy_gradient_loss | 0.0126    |
|    std                  | 0.108     |
|    value_loss           | 0.032     |
---------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3279      |
|    time_elapsed         | 10641     |
|    total_timesteps      | 6715392   |
| train/                  |           |
|    approx_kl            | 2.4424083 |
|    clip_fraction        | 0.613     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.6       |
|    explained_variance   | 0.736     |
|    learning_rate        | 0.000691  |
|    loss                 | -0.0288   |
|    n_updates            | 32780     |
|    policy_gradient_loss | 0.0129    |
|    std                  | 0.109     |
|    value_loss           | 0.0117    |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3280       |
|    time_elapsed         | 10644      |
|    total_timesteps      | 6717440    |
| train/                  |            |
|    approx_kl            | 0.44541433 |
|    clip_fraction        | 0.461      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.59       |
|    explained_variance   | 0.2        |
|    learning_rate        | 0.00069    |
|    loss                 | 0.0592     |
|    n_updates            | 32790      |
|    policy_gradient_loss | 0.00319    |
|    std                  | 0.109      |
|    value_loss           | 0.00538    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3281       |
|    time_elapsed         | 10647      |
|    total_timesteps      | 6719488    |
| train/                  |            |
|    approx_kl            | 0.89707345 |
|    clip_fraction        | 0.461      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.59       |
|    explained_variance   | 0.551      |
|    learning_rate        | 0.00069    |
|    loss                 | -0.0475    |
|    n_updates            | 32800      |
|    policy_gradient_loss | 0.000526   |
|    std                  | 0.109      |
|    value_loss           | 0.0131     |
----------------------------------------
Eval num_timesteps=6720000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 300       |
|    mean_reward          | -1        |
| time/                   |           |
|    total_timesteps      | 6720000   |
| train/                  |           |
|    approx_kl            | 0.3032895 |
|    clip_fraction        | 0.463     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.6       |
|    explained_variance   | 0.408     |
|    learning_rate        | 0.00069   |
|    loss                 | -0.00104  |
|    n_updates            | 32810     |
|    policy_gradient_loss | 0.015     |
|    std                  | 0.109     |
|    value_loss           | 0.00559   |
---------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 3282    |
|    time_elapsed    | 10651   |
|    total_timesteps | 6721536 |
--------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3283       |
|    time_elapsed         | 10654      |
|    total_timesteps      | 6723584    |
| train/                  |            |
|    approx_kl            | 0.49718338 |
|    clip_fraction        | 0.477      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.6        |
|    explained_variance   | 0.5        |
|    learning_rate        | 0.000689   |
|    loss                 | 0.0053     |
|    n_updates            | 32820      |
|    policy_gradient_loss | 0.00432    |
|    std                  | 0.108      |
|    value_loss           | 0.0193     |
----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3284      |
|    time_elapsed         | 10657     |
|    total_timesteps      | 6725632   |
| train/                  |           |
|    approx_kl            | 1.1797755 |
|    clip_fraction        | 0.518     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.61      |
|    explained_variance   | 0.436     |
|    learning_rate        | 0.000689  |
|    loss                 | -0.0317   |
|    n_updates            | 32830     |
|    policy_gradient_loss | 0.0147    |
|    std                  | 0.107     |
|    value_loss           | 0.0218    |
---------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3285      |
|    time_elapsed         | 10660     |
|    total_timesteps      | 6727680   |
| train/                  |           |
|    approx_kl            | 0.9641614 |
|    clip_fraction        | 0.503     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.61      |
|    explained_variance   | 0.47      |
|    learning_rate        | 0.000689  |
|    loss                 | -0.0403   |
|    n_updates            | 32840     |
|    policy_gradient_loss | -0.00628  |
|    std                  | 0.109     |
|    value_loss           | 0.00391   |
---------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3286      |
|    time_elapsed         | 10664     |
|    total_timesteps      | 6729728   |
| train/                  |           |
|    approx_kl            | 0.9393138 |
|    clip_fraction        | 0.509     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.6       |
|    explained_variance   | 0.324     |
|    learning_rate        | 0.000688  |
|    loss                 | -0.00202  |
|    n_updates            | 32850     |
|    policy_gradient_loss | 0.0185    |
|    std                  | 0.108     |
|    value_loss           | 0.00595   |
---------------------------------------
Eval num_timesteps=6730000, episode_reward=-1.07 +/- 0.13
Episode length: 300.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 300       |
|    mean_reward          | -1.07     |
| time/                   |           |
|    total_timesteps      | 6730000   |
| train/                  |           |
|    approx_kl            | 3.0516198 |
|    clip_fraction        | 0.605     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.63      |
|    explained_variance   | 0.458     |
|    learning_rate        | 0.000688  |
|    loss                 | -0.0434   |
|    n_updates            | 32860     |
|    policy_gradient_loss | -0.00491  |
|    std                  | 0.106     |
|    value_loss           | 0.00277   |
---------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 3287    |
|    time_elapsed    | 10667   |
|    total_timesteps | 6731776 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3288       |
|    time_elapsed         | 10671      |
|    total_timesteps      | 6733824    |
| train/                  |            |
|    approx_kl            | 0.65204453 |
|    clip_fraction        | 0.501      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.63       |
|    explained_variance   | -0.0769    |
|    learning_rate        | 0.000687   |
|    loss                 | -0.00556   |
|    n_updates            | 32870      |
|    policy_gradient_loss | 0.0306     |
|    std                  | 0.108      |
|    value_loss           | 0.0046     |
----------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3289      |
|    time_elapsed         | 10674     |
|    total_timesteps      | 6735872   |
| train/                  |           |
|    approx_kl            | 0.3430003 |
|    clip_fraction        | 0.495     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.58      |
|    explained_variance   | 0.152     |
|    learning_rate        | 0.000687  |
|    loss                 | 0.0808    |
|    n_updates            | 32880     |
|    policy_gradient_loss | 0.00449   |
|    std                  | 0.11      |
|    value_loss           | 0.00407   |
---------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3290       |
|    time_elapsed         | 10677      |
|    total_timesteps      | 6737920    |
| train/                  |            |
|    approx_kl            | 0.37928376 |
|    clip_fraction        | 0.472      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.59       |
|    explained_variance   | 0.404      |
|    learning_rate        | 0.000687   |
|    loss                 | -0.0108    |
|    n_updates            | 32890      |
|    policy_gradient_loss | 0.00483    |
|    std                  | 0.108      |
|    value_loss           | 0.0319     |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3291       |
|    time_elapsed         | 10680      |
|    total_timesteps      | 6739968    |
| train/                  |            |
|    approx_kl            | 0.85926944 |
|    clip_fraction        | 0.503      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.57       |
|    explained_variance   | 0.835      |
|    learning_rate        | 0.000686   |
|    loss                 | 0.0139     |
|    n_updates            | 32900      |
|    policy_gradient_loss | 0.0281     |
|    std                  | 0.111      |
|    value_loss           | 0.0127     |
----------------------------------------
Eval num_timesteps=6740000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1         |
| time/                   |            |
|    total_timesteps      | 6740000    |
| train/                  |            |
|    approx_kl            | 0.46605098 |
|    clip_fraction        | 0.446      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.56       |
|    explained_variance   | 0.485      |
|    learning_rate        | 0.000686   |
|    loss                 | 0.0877     |
|    n_updates            | 32910      |
|    policy_gradient_loss | 0.0256     |
|    std                  | 0.11       |
|    value_loss           | 0.00571    |
----------------------------------------
box reached target
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 3292    |
|    time_elapsed    | 10684   |
|    total_timesteps | 6742016 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3293       |
|    time_elapsed         | 10687      |
|    total_timesteps      | 6744064    |
| train/                  |            |
|    approx_kl            | 0.36323363 |
|    clip_fraction        | 0.483      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.55       |
|    explained_variance   | 0.123      |
|    learning_rate        | 0.000685   |
|    loss                 | 0.0517     |
|    n_updates            | 32920      |
|    policy_gradient_loss | 0.0111     |
|    std                  | 0.113      |
|    value_loss           | 0.122      |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3294       |
|    time_elapsed         | 10690      |
|    total_timesteps      | 6746112    |
| train/                  |            |
|    approx_kl            | 0.32808965 |
|    clip_fraction        | 0.469      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.53       |
|    explained_variance   | 0.453      |
|    learning_rate        | 0.000685   |
|    loss                 | 0.00547    |
|    n_updates            | 32930      |
|    policy_gradient_loss | 0.0217     |
|    std                  | 0.112      |
|    value_loss           | 0.00186    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3295       |
|    time_elapsed         | 10693      |
|    total_timesteps      | 6748160    |
| train/                  |            |
|    approx_kl            | 0.50489146 |
|    clip_fraction        | 0.471      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.53       |
|    explained_variance   | 0.929      |
|    learning_rate        | 0.000685   |
|    loss                 | -0.0305    |
|    n_updates            | 32940      |
|    policy_gradient_loss | 0.00879    |
|    std                  | 0.112      |
|    value_loss           | 0.0134     |
----------------------------------------
box reached target
Eval num_timesteps=6750000, episode_reward=0.27 +/- 2.45
Episode length: 277.20 +/- 45.60
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 277        |
|    mean_reward          | 0.267      |
| time/                   |            |
|    total_timesteps      | 6750000    |
| train/                  |            |
|    approx_kl            | 0.16403605 |
|    clip_fraction        | 0.426      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.54       |
|    explained_variance   | 0.711      |
|    learning_rate        | 0.000684   |
|    loss                 | -0.00237   |
|    n_updates            | 32950      |
|    policy_gradient_loss | 0.0155     |
|    std                  | 0.113      |
|    value_loss           | 0.0155     |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 3296    |
|    time_elapsed    | 10697   |
|    total_timesteps | 6750208 |
--------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3297      |
|    time_elapsed         | 10700     |
|    total_timesteps      | 6752256   |
| train/                  |           |
|    approx_kl            | 0.3872713 |
|    clip_fraction        | 0.423     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.56      |
|    explained_variance   | -0.465    |
|    learning_rate        | 0.000684  |
|    loss                 | -0.0216   |
|    n_updates            | 32960     |
|    policy_gradient_loss | 9.91e-05  |
|    std                  | 0.109     |
|    value_loss           | 0.00383   |
---------------------------------------
box reached target
--------------------------------------
| time/                   |          |
|    fps                  | 631      |
|    iterations           | 3298     |
|    time_elapsed         | 10703    |
|    total_timesteps      | 6754304  |
| train/                  |          |
|    approx_kl            | 0.665673 |
|    clip_fraction        | 0.496    |
|    clip_range           | 0.2      |
|    entropy_loss         | 1.59     |
|    explained_variance   | -0.507   |
|    learning_rate        | 0.000683 |
|    loss                 | 0.0689   |
|    n_updates            | 32970    |
|    policy_gradient_loss | 0.0116   |
|    std                  | 0.108    |
|    value_loss           | 0.00337  |
--------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3299       |
|    time_elapsed         | 10706      |
|    total_timesteps      | 6756352    |
| train/                  |            |
|    approx_kl            | 0.34735543 |
|    clip_fraction        | 0.523      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.58       |
|    explained_variance   | 0.143      |
|    learning_rate        | 0.000683   |
|    loss                 | 0.045      |
|    n_updates            | 32980      |
|    policy_gradient_loss | 0.0343     |
|    std                  | 0.111      |
|    value_loss           | 0.0355     |
----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3300      |
|    time_elapsed         | 10709     |
|    total_timesteps      | 6758400   |
| train/                  |           |
|    approx_kl            | 1.0647005 |
|    clip_fraction        | 0.547     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.56      |
|    explained_variance   | 0.481     |
|    learning_rate        | 0.000683  |
|    loss                 | 0.0262    |
|    n_updates            | 32990     |
|    policy_gradient_loss | 0.0101    |
|    std                  | 0.11      |
|    value_loss           | 0.0295    |
---------------------------------------
box reached target
Eval num_timesteps=6760000, episode_reward=-0.52 +/- 0.46
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -0.52      |
| time/                   |            |
|    total_timesteps      | 6760000    |
| train/                  |            |
|    approx_kl            | 0.26763052 |
|    clip_fraction        | 0.444      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.6        |
|    explained_variance   | 0.0926     |
|    learning_rate        | 0.000682   |
|    loss                 | 0.0443     |
|    n_updates            | 33000      |
|    policy_gradient_loss | 0.0123     |
|    std                  | 0.107      |
|    value_loss           | 0.00204    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 3301    |
|    time_elapsed    | 10713   |
|    total_timesteps | 6760448 |
--------------------------------
--------------------------------------
| time/                   |          |
|    fps                  | 631      |
|    iterations           | 3302     |
|    time_elapsed         | 10716    |
|    total_timesteps      | 6762496  |
| train/                  |          |
|    approx_kl            | 0.674682 |
|    clip_fraction        | 0.492    |
|    clip_range           | 0.2      |
|    entropy_loss         | 1.63     |
|    explained_variance   | 0.834    |
|    learning_rate        | 0.000682 |
|    loss                 | 0.0147   |
|    n_updates            | 33010    |
|    policy_gradient_loss | 0.0162   |
|    std                  | 0.106    |
|    value_loss           | 0.0162   |
--------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3303       |
|    time_elapsed         | 10719      |
|    total_timesteps      | 6764544    |
| train/                  |            |
|    approx_kl            | 0.23460728 |
|    clip_fraction        | 0.5        |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.61       |
|    explained_variance   | 0.697      |
|    learning_rate        | 0.000681   |
|    loss                 | 0.0132     |
|    n_updates            | 33020      |
|    policy_gradient_loss | 0.0316     |
|    std                  | 0.109      |
|    value_loss           | 0.0118     |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3304       |
|    time_elapsed         | 10722      |
|    total_timesteps      | 6766592    |
| train/                  |            |
|    approx_kl            | 0.70634556 |
|    clip_fraction        | 0.504      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.59       |
|    explained_variance   | -0.566     |
|    learning_rate        | 0.000681   |
|    loss                 | 0.00333    |
|    n_updates            | 33030      |
|    policy_gradient_loss | 0.0128     |
|    std                  | 0.108      |
|    value_loss           | 0.00373    |
----------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3305      |
|    time_elapsed         | 10725     |
|    total_timesteps      | 6768640   |
| train/                  |           |
|    approx_kl            | 0.5686847 |
|    clip_fraction        | 0.509     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.6       |
|    explained_variance   | 0.74      |
|    learning_rate        | 0.000681  |
|    loss                 | -0.00934  |
|    n_updates            | 33040     |
|    policy_gradient_loss | 0.0144    |
|    std                  | 0.109     |
|    value_loss           | 0.00527   |
---------------------------------------
box reached target
box reached target
Eval num_timesteps=6770000, episode_reward=-0.66 +/- 0.56
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -0.659     |
| time/                   |            |
|    total_timesteps      | 6770000    |
| train/                  |            |
|    approx_kl            | 0.39471743 |
|    clip_fraction        | 0.447      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.59       |
|    explained_variance   | 0.394      |
|    learning_rate        | 0.00068    |
|    loss                 | 0.00831    |
|    n_updates            | 33050      |
|    policy_gradient_loss | 0.0215     |
|    std                  | 0.11       |
|    value_loss           | 0.0167     |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 3306    |
|    time_elapsed    | 10729   |
|    total_timesteps | 6770688 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3307       |
|    time_elapsed         | 10732      |
|    total_timesteps      | 6772736    |
| train/                  |            |
|    approx_kl            | 0.68903846 |
|    clip_fraction        | 0.578      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.6        |
|    explained_variance   | 0.715      |
|    learning_rate        | 0.00068    |
|    loss                 | -0.0297    |
|    n_updates            | 33060      |
|    policy_gradient_loss | 0.00557    |
|    std                  | 0.109      |
|    value_loss           | 0.126      |
----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3308      |
|    time_elapsed         | 10735     |
|    total_timesteps      | 6774784   |
| train/                  |           |
|    approx_kl            | 1.3009814 |
|    clip_fraction        | 0.466     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.62      |
|    explained_variance   | 0.793     |
|    learning_rate        | 0.000679  |
|    loss                 | 0.05      |
|    n_updates            | 33070     |
|    policy_gradient_loss | -0.0186   |
|    std                  | 0.107     |
|    value_loss           | 0.0182    |
---------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3309      |
|    time_elapsed         | 10738     |
|    total_timesteps      | 6776832   |
| train/                  |           |
|    approx_kl            | 0.6206534 |
|    clip_fraction        | 0.474     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.64      |
|    explained_variance   | 0.233     |
|    learning_rate        | 0.000679  |
|    loss                 | 0.0566    |
|    n_updates            | 33080     |
|    policy_gradient_loss | 0.00684   |
|    std                  | 0.106     |
|    value_loss           | 0.00273   |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3310       |
|    time_elapsed         | 10741      |
|    total_timesteps      | 6778880    |
| train/                  |            |
|    approx_kl            | 0.31640944 |
|    clip_fraction        | 0.464      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.65       |
|    explained_variance   | 0.571      |
|    learning_rate        | 0.000679   |
|    loss                 | -0.0266    |
|    n_updates            | 33090      |
|    policy_gradient_loss | 0.0112     |
|    std                  | 0.106      |
|    value_loss           | 0.00192    |
----------------------------------------
Eval num_timesteps=6780000, episode_reward=-0.90 +/- 0.33
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -0.899     |
| time/                   |            |
|    total_timesteps      | 6780000    |
| train/                  |            |
|    approx_kl            | 0.32717288 |
|    clip_fraction        | 0.47       |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.65       |
|    explained_variance   | 0.676      |
|    learning_rate        | 0.000678   |
|    loss                 | 0.0323     |
|    n_updates            | 33100      |
|    policy_gradient_loss | 0.0208     |
|    std                  | 0.107      |
|    value_loss           | 0.00304    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 3311    |
|    time_elapsed    | 10745   |
|    total_timesteps | 6780928 |
--------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3312      |
|    time_elapsed         | 10748     |
|    total_timesteps      | 6782976   |
| train/                  |           |
|    approx_kl            | 0.7764317 |
|    clip_fraction        | 0.481     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.68      |
|    explained_variance   | 0.521     |
|    learning_rate        | 0.000678  |
|    loss                 | -0.0126   |
|    n_updates            | 33110     |
|    policy_gradient_loss | 0.00359   |
|    std                  | 0.102     |
|    value_loss           | 0.00798   |
---------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3313      |
|    time_elapsed         | 10751     |
|    total_timesteps      | 6785024   |
| train/                  |           |
|    approx_kl            | 2.6007957 |
|    clip_fraction        | 0.527     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.74      |
|    explained_variance   | 0.423     |
|    learning_rate        | 0.000677  |
|    loss                 | -0.0578   |
|    n_updates            | 33120     |
|    policy_gradient_loss | -0.00163  |
|    std                  | 0.101     |
|    value_loss           | 0.0031    |
---------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3314      |
|    time_elapsed         | 10754     |
|    total_timesteps      | 6787072   |
| train/                  |           |
|    approx_kl            | 0.5770227 |
|    clip_fraction        | 0.457     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.78      |
|    explained_variance   | -1.08     |
|    learning_rate        | 0.000677  |
|    loss                 | -0.0135   |
|    n_updates            | 33130     |
|    policy_gradient_loss | -0.00269  |
|    std                  | 0.0985    |
|    value_loss           | 0.00347   |
---------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3315      |
|    time_elapsed         | 10757     |
|    total_timesteps      | 6789120   |
| train/                  |           |
|    approx_kl            | 0.4993594 |
|    clip_fraction        | 0.473     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.81      |
|    explained_variance   | 0.757     |
|    learning_rate        | 0.000677  |
|    loss                 | 0.00592   |
|    n_updates            | 33140     |
|    policy_gradient_loss | 0.0443    |
|    std                  | 0.0978    |
|    value_loss           | 0.00451   |
---------------------------------------
Eval num_timesteps=6790000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1         |
| time/                   |            |
|    total_timesteps      | 6790000    |
| train/                  |            |
|    approx_kl            | 0.73667383 |
|    clip_fraction        | 0.523      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.83       |
|    explained_variance   | -0.278     |
|    learning_rate        | 0.000676   |
|    loss                 | -0.00894   |
|    n_updates            | 33150      |
|    policy_gradient_loss | 0.00272    |
|    std                  | 0.0972     |
|    value_loss           | 0.0019     |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 3316    |
|    time_elapsed    | 10761   |
|    total_timesteps | 6791168 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3317       |
|    time_elapsed         | 10764      |
|    total_timesteps      | 6793216    |
| train/                  |            |
|    approx_kl            | 0.48704487 |
|    clip_fraction        | 0.524      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.8        |
|    explained_variance   | 0.545      |
|    learning_rate        | 0.000676   |
|    loss                 | 0.0797     |
|    n_updates            | 33160      |
|    policy_gradient_loss | 0.0302     |
|    std                  | 0.099      |
|    value_loss           | 0.00302    |
----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3318      |
|    time_elapsed         | 10767     |
|    total_timesteps      | 6795264   |
| train/                  |           |
|    approx_kl            | 3.3901625 |
|    clip_fraction        | 0.54      |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.78      |
|    explained_variance   | -0.202    |
|    learning_rate        | 0.000675  |
|    loss                 | -0.0327   |
|    n_updates            | 33170     |
|    policy_gradient_loss | 0.0175    |
|    std                  | 0.0994    |
|    value_loss           | 0.00392   |
---------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3319      |
|    time_elapsed         | 10770     |
|    total_timesteps      | 6797312   |
| train/                  |           |
|    approx_kl            | 0.5822241 |
|    clip_fraction        | 0.485     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.76      |
|    explained_variance   | -0.181    |
|    learning_rate        | 0.000675  |
|    loss                 | 0.0507    |
|    n_updates            | 33180     |
|    policy_gradient_loss | 0.00739   |
|    std                  | 0.1       |
|    value_loss           | 0.00491   |
---------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3320       |
|    time_elapsed         | 10773      |
|    total_timesteps      | 6799360    |
| train/                  |            |
|    approx_kl            | 0.44050488 |
|    clip_fraction        | 0.475      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.75       |
|    explained_variance   | 0.186      |
|    learning_rate        | 0.000675   |
|    loss                 | 0.0376     |
|    n_updates            | 33190      |
|    policy_gradient_loss | 0.0107     |
|    std                  | 0.1        |
|    value_loss           | 0.00198    |
----------------------------------------
box reached target
Eval num_timesteps=6800000, episode_reward=-0.77 +/- 0.45
Episode length: 300.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 300       |
|    mean_reward          | -0.774    |
| time/                   |           |
|    total_timesteps      | 6800000   |
| train/                  |           |
|    approx_kl            | 0.5693846 |
|    clip_fraction        | 0.471     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.75      |
|    explained_variance   | 0.857     |
|    learning_rate        | 0.000674  |
|    loss                 | -0.0128   |
|    n_updates            | 33200     |
|    policy_gradient_loss | 0.03      |
|    std                  | 0.1       |
|    value_loss           | 0.0154    |
---------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 3321    |
|    time_elapsed    | 10777   |
|    total_timesteps | 6801408 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3322       |
|    time_elapsed         | 10780      |
|    total_timesteps      | 6803456    |
| train/                  |            |
|    approx_kl            | 0.31394655 |
|    clip_fraction        | 0.502      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.73       |
|    explained_variance   | 0.483      |
|    learning_rate        | 0.000674   |
|    loss                 | 0.0106     |
|    n_updates            | 33210      |
|    policy_gradient_loss | 0.0204     |
|    std                  | 0.102      |
|    value_loss           | 0.0867     |
----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3323      |
|    time_elapsed         | 10784     |
|    total_timesteps      | 6805504   |
| train/                  |           |
|    approx_kl            | 0.2425262 |
|    clip_fraction        | 0.45      |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.7       |
|    explained_variance   | 0.668     |
|    learning_rate        | 0.000673  |
|    loss                 | 0.0645    |
|    n_updates            | 33220     |
|    policy_gradient_loss | 0.00938   |
|    std                  | 0.104     |
|    value_loss           | 0.014     |
---------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3324      |
|    time_elapsed         | 10787     |
|    total_timesteps      | 6807552   |
| train/                  |           |
|    approx_kl            | 0.5301807 |
|    clip_fraction        | 0.496     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.64      |
|    explained_variance   | 0.217     |
|    learning_rate        | 0.000673  |
|    loss                 | 0.0316    |
|    n_updates            | 33230     |
|    policy_gradient_loss | 0.0291    |
|    std                  | 0.108     |
|    value_loss           | 0.00218   |
---------------------------------------
box reached target
--------------------------------------
| time/                   |          |
|    fps                  | 631      |
|    iterations           | 3325     |
|    time_elapsed         | 10790    |
|    total_timesteps      | 6809600  |
| train/                  |          |
|    approx_kl            | 1.440676 |
|    clip_fraction        | 0.519    |
|    clip_range           | 0.2      |
|    entropy_loss         | 1.63     |
|    explained_variance   | 0.945    |
|    learning_rate        | 0.000673 |
|    loss                 | -0.00927 |
|    n_updates            | 33240    |
|    policy_gradient_loss | 0.031    |
|    std                  | 0.106    |
|    value_loss           | 0.00601  |
--------------------------------------
Eval num_timesteps=6810000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1         |
| time/                   |            |
|    total_timesteps      | 6810000    |
| train/                  |            |
|    approx_kl            | 0.23943159 |
|    clip_fraction        | 0.487      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.63       |
|    explained_variance   | 0.97       |
|    learning_rate        | 0.000672   |
|    loss                 | -0.0382    |
|    n_updates            | 33250      |
|    policy_gradient_loss | 0.025      |
|    std                  | 0.108      |
|    value_loss           | 0.00338    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 3326    |
|    time_elapsed    | 10794   |
|    total_timesteps | 6811648 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3327       |
|    time_elapsed         | 10797      |
|    total_timesteps      | 6813696    |
| train/                  |            |
|    approx_kl            | 0.14403719 |
|    clip_fraction        | 0.428      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.6        |
|    explained_variance   | 0.698      |
|    learning_rate        | 0.000672   |
|    loss                 | 0.0247     |
|    n_updates            | 33260      |
|    policy_gradient_loss | 0.00364    |
|    std                  | 0.109      |
|    value_loss           | 0.0076     |
----------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3328      |
|    time_elapsed         | 10800     |
|    total_timesteps      | 6815744   |
| train/                  |           |
|    approx_kl            | 0.6696257 |
|    clip_fraction        | 0.474     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.61      |
|    explained_variance   | -0.41     |
|    learning_rate        | 0.000671  |
|    loss                 | 0.0309    |
|    n_updates            | 33270     |
|    policy_gradient_loss | 0.00853   |
|    std                  | 0.107     |
|    value_loss           | 0.00316   |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3329       |
|    time_elapsed         | 10803      |
|    total_timesteps      | 6817792    |
| train/                  |            |
|    approx_kl            | 0.25371242 |
|    clip_fraction        | 0.461      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.63       |
|    explained_variance   | -0.199     |
|    learning_rate        | 0.000671   |
|    loss                 | 0.0108     |
|    n_updates            | 33280      |
|    policy_gradient_loss | 0.00776    |
|    std                  | 0.108      |
|    value_loss           | 0.0895     |
----------------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3330       |
|    time_elapsed         | 10806      |
|    total_timesteps      | 6819840    |
| train/                  |            |
|    approx_kl            | 0.37256503 |
|    clip_fraction        | 0.48       |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.57       |
|    explained_variance   | 0.46       |
|    learning_rate        | 0.000671   |
|    loss                 | -0.0349    |
|    n_updates            | 33290      |
|    policy_gradient_loss | 0.00669    |
|    std                  | 0.11       |
|    value_loss           | 0.018      |
----------------------------------------
Eval num_timesteps=6820000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 300       |
|    mean_reward          | -1        |
| time/                   |           |
|    total_timesteps      | 6820000   |
| train/                  |           |
|    approx_kl            | 0.5270249 |
|    clip_fraction        | 0.471     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.59      |
|    explained_variance   | 0.597     |
|    learning_rate        | 0.00067   |
|    loss                 | 0.0229    |
|    n_updates            | 33300     |
|    policy_gradient_loss | 0.011     |
|    std                  | 0.109     |
|    value_loss           | 0.0615    |
---------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 3331    |
|    time_elapsed    | 10810   |
|    total_timesteps | 6821888 |
--------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3332      |
|    time_elapsed         | 10813     |
|    total_timesteps      | 6823936   |
| train/                  |           |
|    approx_kl            | 0.4944263 |
|    clip_fraction        | 0.438     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.61      |
|    explained_variance   | -0.0221   |
|    learning_rate        | 0.00067   |
|    loss                 | 0.00519   |
|    n_updates            | 33310     |
|    policy_gradient_loss | 0.00147   |
|    std                  | 0.108     |
|    value_loss           | 0.01      |
---------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3333      |
|    time_elapsed         | 10816     |
|    total_timesteps      | 6825984   |
| train/                  |           |
|    approx_kl            | 0.6989633 |
|    clip_fraction        | 0.508     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.62      |
|    explained_variance   | 0.457     |
|    learning_rate        | 0.000669  |
|    loss                 | 0.0275    |
|    n_updates            | 33320     |
|    policy_gradient_loss | 0.00439   |
|    std                  | 0.107     |
|    value_loss           | 0.0172    |
---------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3334      |
|    time_elapsed         | 10819     |
|    total_timesteps      | 6828032   |
| train/                  |           |
|    approx_kl            | 0.4710735 |
|    clip_fraction        | 0.46      |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.65      |
|    explained_variance   | 0.749     |
|    learning_rate        | 0.000669  |
|    loss                 | 0.0144    |
|    n_updates            | 33330     |
|    policy_gradient_loss | 0.015     |
|    std                  | 0.105     |
|    value_loss           | 0.00347   |
---------------------------------------
Eval num_timesteps=6830000, episode_reward=-0.48 +/- 0.70
Episode length: 300.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 300       |
|    mean_reward          | -0.476    |
| time/                   |           |
|    total_timesteps      | 6830000   |
| train/                  |           |
|    approx_kl            | 0.5121095 |
|    clip_fraction        | 0.483     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.64      |
|    explained_variance   | 0.649     |
|    learning_rate        | 0.000669  |
|    loss                 | -0.0158   |
|    n_updates            | 33340     |
|    policy_gradient_loss | 0.0296    |
|    std                  | 0.108     |
|    value_loss           | 0.00896   |
---------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 3335    |
|    time_elapsed    | 10823   |
|    total_timesteps | 6830080 |
--------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3336      |
|    time_elapsed         | 10826     |
|    total_timesteps      | 6832128   |
| train/                  |           |
|    approx_kl            | 0.5681163 |
|    clip_fraction        | 0.471     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.63      |
|    explained_variance   | 0.285     |
|    learning_rate        | 0.000668  |
|    loss                 | -0.0254   |
|    n_updates            | 33350     |
|    policy_gradient_loss | -0.0015   |
|    std                  | 0.106     |
|    value_loss           | 0.00486   |
---------------------------------------
box reached target
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3337      |
|    time_elapsed         | 10829     |
|    total_timesteps      | 6834176   |
| train/                  |           |
|    approx_kl            | 0.7944511 |
|    clip_fraction        | 0.568     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.62      |
|    explained_variance   | 0.66      |
|    learning_rate        | 0.000668  |
|    loss                 | -0.014    |
|    n_updates            | 33360     |
|    policy_gradient_loss | 0.0252    |
|    std                  | 0.108     |
|    value_loss           | 0.00205   |
---------------------------------------
--------------------------------------
| time/                   |          |
|    fps                  | 631      |
|    iterations           | 3338     |
|    time_elapsed         | 10832    |
|    total_timesteps      | 6836224  |
| train/                  |          |
|    approx_kl            | 2.26166  |
|    clip_fraction        | 0.532    |
|    clip_range           | 0.2      |
|    entropy_loss         | 1.62     |
|    explained_variance   | 0.754    |
|    learning_rate        | 0.000667 |
|    loss                 | 0.0317   |
|    n_updates            | 33370    |
|    policy_gradient_loss | 0.0136   |
|    std                  | 0.107    |
|    value_loss           | 0.144    |
--------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3339      |
|    time_elapsed         | 10835     |
|    total_timesteps      | 6838272   |
| train/                  |           |
|    approx_kl            | 0.4180345 |
|    clip_fraction        | 0.495     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.63      |
|    explained_variance   | 0.358     |
|    learning_rate        | 0.000667  |
|    loss                 | -0.0159   |
|    n_updates            | 33380     |
|    policy_gradient_loss | 0.024     |
|    std                  | 0.106     |
|    value_loss           | 0.0104    |
---------------------------------------
box reached target
box reached target
Eval num_timesteps=6840000, episode_reward=0.26 +/- 2.46
Episode length: 271.60 +/- 56.80
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 272        |
|    mean_reward          | 0.265      |
| time/                   |            |
|    total_timesteps      | 6840000    |
| train/                  |            |
|    approx_kl            | 0.41505492 |
|    clip_fraction        | 0.536      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.63       |
|    explained_variance   | 0.449      |
|    learning_rate        | 0.000667   |
|    loss                 | 0.00118    |
|    n_updates            | 33390      |
|    policy_gradient_loss | 0.0366     |
|    std                  | 0.108      |
|    value_loss           | 0.00554    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 3340    |
|    time_elapsed    | 10839   |
|    total_timesteps | 6840320 |
--------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3341       |
|    time_elapsed         | 10842      |
|    total_timesteps      | 6842368    |
| train/                  |            |
|    approx_kl            | 0.38043627 |
|    clip_fraction        | 0.494      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.61       |
|    explained_variance   | 0.846      |
|    learning_rate        | 0.000666   |
|    loss                 | 0.0891     |
|    n_updates            | 33400      |
|    policy_gradient_loss | 0.0262     |
|    std                  | 0.107      |
|    value_loss           | 0.00567    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3342       |
|    time_elapsed         | 10845      |
|    total_timesteps      | 6844416    |
| train/                  |            |
|    approx_kl            | 0.41036898 |
|    clip_fraction        | 0.506      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.65       |
|    explained_variance   | 0.721      |
|    learning_rate        | 0.000666   |
|    loss                 | -0.0313    |
|    n_updates            | 33410      |
|    policy_gradient_loss | 0.0169     |
|    std                  | 0.105      |
|    value_loss           | 0.0191     |
----------------------------------------
box reached target
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3343      |
|    time_elapsed         | 10848     |
|    total_timesteps      | 6846464   |
| train/                  |           |
|    approx_kl            | 3.6754894 |
|    clip_fraction        | 0.481     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.67      |
|    explained_variance   | 0.31      |
|    learning_rate        | 0.000665  |
|    loss                 | -0.0114   |
|    n_updates            | 33420     |
|    policy_gradient_loss | 0.00991   |
|    std                  | 0.104     |
|    value_loss           | 0.006     |
---------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3344      |
|    time_elapsed         | 10851     |
|    total_timesteps      | 6848512   |
| train/                  |           |
|    approx_kl            | 2.7946587 |
|    clip_fraction        | 0.607     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.66      |
|    explained_variance   | 0.824     |
|    learning_rate        | 0.000665  |
|    loss                 | 0.00135   |
|    n_updates            | 33430     |
|    policy_gradient_loss | 0.0216    |
|    std                  | 0.107     |
|    value_loss           | 0.041     |
---------------------------------------
box reached target
Eval num_timesteps=6850000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 300       |
|    mean_reward          | -1        |
| time/                   |           |
|    total_timesteps      | 6850000   |
| train/                  |           |
|    approx_kl            | 2.1476378 |
|    clip_fraction        | 0.545     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.65      |
|    explained_variance   | 0.316     |
|    learning_rate        | 0.000665  |
|    loss                 | 0.0911    |
|    n_updates            | 33440     |
|    policy_gradient_loss | 0.0115    |
|    std                  | 0.105     |
|    value_loss           | 0.119     |
---------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 3345    |
|    time_elapsed    | 10855   |
|    total_timesteps | 6850560 |
--------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3346      |
|    time_elapsed         | 10858     |
|    total_timesteps      | 6852608   |
| train/                  |           |
|    approx_kl            | 2.3684878 |
|    clip_fraction        | 0.524     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.67      |
|    explained_variance   | 0.953     |
|    learning_rate        | 0.000664  |
|    loss                 | -0.000506 |
|    n_updates            | 33450     |
|    policy_gradient_loss | 0.0233    |
|    std                  | 0.105     |
|    value_loss           | 0.007     |
---------------------------------------
box reached target
--------------------------------------
| time/                   |          |
|    fps                  | 631      |
|    iterations           | 3347     |
|    time_elapsed         | 10861    |
|    total_timesteps      | 6854656  |
| train/                  |          |
|    approx_kl            | 4.205326 |
|    clip_fraction        | 0.546    |
|    clip_range           | 0.2      |
|    entropy_loss         | 1.69     |
|    explained_variance   | 0.51     |
|    learning_rate        | 0.000664 |
|    loss                 | -0.0299  |
|    n_updates            | 33460    |
|    policy_gradient_loss | 0.0132   |
|    std                  | 0.103    |
|    value_loss           | 0.0407   |
--------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3348      |
|    time_elapsed         | 10864     |
|    total_timesteps      | 6856704   |
| train/                  |           |
|    approx_kl            | 0.4336477 |
|    clip_fraction        | 0.498     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.7       |
|    explained_variance   | 0.876     |
|    learning_rate        | 0.000663  |
|    loss                 | 0.0611    |
|    n_updates            | 33470     |
|    policy_gradient_loss | 0.0144    |
|    std                  | 0.104     |
|    value_loss           | 0.0114    |
---------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3349      |
|    time_elapsed         | 10867     |
|    total_timesteps      | 6858752   |
| train/                  |           |
|    approx_kl            | 0.9259239 |
|    clip_fraction        | 0.536     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.71      |
|    explained_variance   | 0.256     |
|    learning_rate        | 0.000663  |
|    loss                 | -0.0175   |
|    n_updates            | 33480     |
|    policy_gradient_loss | 0.00505   |
|    std                  | 0.103     |
|    value_loss           | 0.0363    |
---------------------------------------
box reached target
Eval num_timesteps=6860000, episode_reward=0.21 +/- 2.41
Episode length: 280.00 +/- 40.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 280       |
|    mean_reward          | 0.206     |
| time/                   |           |
|    total_timesteps      | 6860000   |
| train/                  |           |
|    approx_kl            | 1.1112089 |
|    clip_fraction        | 0.485     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.73      |
|    explained_variance   | 0.593     |
|    learning_rate        | 0.000663  |
|    loss                 | 0.00578   |
|    n_updates            | 33490     |
|    policy_gradient_loss | 0.00717   |
|    std                  | 0.101     |
|    value_loss           | 0.00817   |
---------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 3350    |
|    time_elapsed    | 10871   |
|    total_timesteps | 6860800 |
--------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3351      |
|    time_elapsed         | 10874     |
|    total_timesteps      | 6862848   |
| train/                  |           |
|    approx_kl            | 2.8727946 |
|    clip_fraction        | 0.541     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.74      |
|    explained_variance   | 0.867     |
|    learning_rate        | 0.000662  |
|    loss                 | -0.0197   |
|    n_updates            | 33500     |
|    policy_gradient_loss | 0.0156    |
|    std                  | 0.102     |
|    value_loss           | 0.00626   |
---------------------------------------
box reached target
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3352      |
|    time_elapsed         | 10877     |
|    total_timesteps      | 6864896   |
| train/                  |           |
|    approx_kl            | 0.8371145 |
|    clip_fraction        | 0.461     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.7       |
|    explained_variance   | 0.75      |
|    learning_rate        | 0.000662  |
|    loss                 | -0.0115   |
|    n_updates            | 33510     |
|    policy_gradient_loss | 0.0214    |
|    std                  | 0.105     |
|    value_loss           | 0.0219    |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3353       |
|    time_elapsed         | 10880      |
|    total_timesteps      | 6866944    |
| train/                  |            |
|    approx_kl            | 0.44066286 |
|    clip_fraction        | 0.488      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.69       |
|    explained_variance   | 0.849      |
|    learning_rate        | 0.000661   |
|    loss                 | 0.0499     |
|    n_updates            | 33520      |
|    policy_gradient_loss | 0.0233     |
|    std                  | 0.105      |
|    value_loss           | 0.0183     |
----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3354      |
|    time_elapsed         | 10883     |
|    total_timesteps      | 6868992   |
| train/                  |           |
|    approx_kl            | 1.0088778 |
|    clip_fraction        | 0.486     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.71      |
|    explained_variance   | 0.404     |
|    learning_rate        | 0.000661  |
|    loss                 | -0.0363   |
|    n_updates            | 33530     |
|    policy_gradient_loss | -0.00301  |
|    std                  | 0.103     |
|    value_loss           | 0.0065    |
---------------------------------------
Eval num_timesteps=6870000, episode_reward=-0.70 +/- 0.59
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -0.703     |
| time/                   |            |
|    total_timesteps      | 6870000    |
| train/                  |            |
|    approx_kl            | 0.38868374 |
|    clip_fraction        | 0.475      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.73       |
|    explained_variance   | 0.687      |
|    learning_rate        | 0.000661   |
|    loss                 | 0.00889    |
|    n_updates            | 33540      |
|    policy_gradient_loss | 0.0124     |
|    std                  | 0.103      |
|    value_loss           | 0.00305    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 3355    |
|    time_elapsed    | 10887   |
|    total_timesteps | 6871040 |
--------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3356      |
|    time_elapsed         | 10890     |
|    total_timesteps      | 6873088   |
| train/                  |           |
|    approx_kl            | 0.2974224 |
|    clip_fraction        | 0.443     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.73      |
|    explained_variance   | 0.577     |
|    learning_rate        | 0.00066   |
|    loss                 | -0.0247   |
|    n_updates            | 33550     |
|    policy_gradient_loss | 0.00814   |
|    std                  | 0.103     |
|    value_loss           | 0.0113    |
---------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3357       |
|    time_elapsed         | 10893      |
|    total_timesteps      | 6875136    |
| train/                  |            |
|    approx_kl            | 0.21535219 |
|    clip_fraction        | 0.391      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.72       |
|    explained_variance   | 0.576      |
|    learning_rate        | 0.00066    |
|    loss                 | 0.0375     |
|    n_updates            | 33560      |
|    policy_gradient_loss | -0.00063   |
|    std                  | 0.103      |
|    value_loss           | 0.00268    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3358       |
|    time_elapsed         | 10896      |
|    total_timesteps      | 6877184    |
| train/                  |            |
|    approx_kl            | 0.24591525 |
|    clip_fraction        | 0.492      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.73       |
|    explained_variance   | 0.833      |
|    learning_rate        | 0.000659   |
|    loss                 | 0.0688     |
|    n_updates            | 33570      |
|    policy_gradient_loss | 0.0243     |
|    std                  | 0.103      |
|    value_loss           | 0.0206     |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3359       |
|    time_elapsed         | 10899      |
|    total_timesteps      | 6879232    |
| train/                  |            |
|    approx_kl            | 0.25780502 |
|    clip_fraction        | 0.457      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.71       |
|    explained_variance   | -1.19      |
|    learning_rate        | 0.000659   |
|    loss                 | 0.344      |
|    n_updates            | 33580      |
|    policy_gradient_loss | 0.0119     |
|    std                  | 0.103      |
|    value_loss           | 0.00376    |
----------------------------------------
Eval num_timesteps=6880000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1         |
| time/                   |            |
|    total_timesteps      | 6880000    |
| train/                  |            |
|    approx_kl            | 0.26754484 |
|    clip_fraction        | 0.458      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.71       |
|    explained_variance   | -0.0499    |
|    learning_rate        | 0.000659   |
|    loss                 | -0.0232    |
|    n_updates            | 33590      |
|    policy_gradient_loss | 0.00761    |
|    std                  | 0.104      |
|    value_loss           | 0.00184    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 3360    |
|    time_elapsed    | 10903   |
|    total_timesteps | 6881280 |
--------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3361      |
|    time_elapsed         | 10906     |
|    total_timesteps      | 6883328   |
| train/                  |           |
|    approx_kl            | 1.1660125 |
|    clip_fraction        | 0.499     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.68      |
|    explained_variance   | 0.00915   |
|    learning_rate        | 0.000658  |
|    loss                 | 0.0797    |
|    n_updates            | 33600     |
|    policy_gradient_loss | 0.0208    |
|    std                  | 0.106     |
|    value_loss           | 0.00176   |
---------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3362      |
|    time_elapsed         | 10909     |
|    total_timesteps      | 6885376   |
| train/                  |           |
|    approx_kl            | 1.1197035 |
|    clip_fraction        | 0.5       |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.67      |
|    explained_variance   | 0.344     |
|    learning_rate        | 0.000658  |
|    loss                 | -0.00523  |
|    n_updates            | 33610     |
|    policy_gradient_loss | 0.0215    |
|    std                  | 0.105     |
|    value_loss           | 0.00425   |
---------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3363      |
|    time_elapsed         | 10913     |
|    total_timesteps      | 6887424   |
| train/                  |           |
|    approx_kl            | 0.7906534 |
|    clip_fraction        | 0.474     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.67      |
|    explained_variance   | 0.126     |
|    learning_rate        | 0.000657  |
|    loss                 | 0.00502   |
|    n_updates            | 33620     |
|    policy_gradient_loss | 0.0117    |
|    std                  | 0.105     |
|    value_loss           | 0.00432   |
---------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3364      |
|    time_elapsed         | 10916     |
|    total_timesteps      | 6889472   |
| train/                  |           |
|    approx_kl            | 0.5296941 |
|    clip_fraction        | 0.439     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.69      |
|    explained_variance   | 0.528     |
|    learning_rate        | 0.000657  |
|    loss                 | -0.0194   |
|    n_updates            | 33630     |
|    policy_gradient_loss | 0.00231   |
|    std                  | 0.104     |
|    value_loss           | 0.00685   |
---------------------------------------
box reached target
Eval num_timesteps=6890000, episode_reward=0.23 +/- 2.46
Episode length: 273.80 +/- 52.40
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 274        |
|    mean_reward          | 0.232      |
| time/                   |            |
|    total_timesteps      | 6890000    |
| train/                  |            |
|    approx_kl            | 0.18538404 |
|    clip_fraction        | 0.428      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.71       |
|    explained_variance   | 0.479      |
|    learning_rate        | 0.000657   |
|    loss                 | 0.00102    |
|    n_updates            | 33640      |
|    policy_gradient_loss | 0.0129     |
|    std                  | 0.104      |
|    value_loss           | 0.000871   |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 3365    |
|    time_elapsed    | 10920   |
|    total_timesteps | 6891520 |
--------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3366      |
|    time_elapsed         | 10923     |
|    total_timesteps      | 6893568   |
| train/                  |           |
|    approx_kl            | 0.4289985 |
|    clip_fraction        | 0.494     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.7       |
|    explained_variance   | 0.652     |
|    learning_rate        | 0.000656  |
|    loss                 | -0.0285   |
|    n_updates            | 33650     |
|    policy_gradient_loss | 0.00777   |
|    std                  | 0.104     |
|    value_loss           | 0.00573   |
---------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3367      |
|    time_elapsed         | 10926     |
|    total_timesteps      | 6895616   |
| train/                  |           |
|    approx_kl            | 0.6517007 |
|    clip_fraction        | 0.452     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.68      |
|    explained_variance   | 0.683     |
|    learning_rate        | 0.000656  |
|    loss                 | 0.0935    |
|    n_updates            | 33660     |
|    policy_gradient_loss | 0.0181    |
|    std                  | 0.106     |
|    value_loss           | 0.00277   |
---------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3368      |
|    time_elapsed         | 10929     |
|    total_timesteps      | 6897664   |
| train/                  |           |
|    approx_kl            | 0.8304633 |
|    clip_fraction        | 0.485     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.68      |
|    explained_variance   | 0.415     |
|    learning_rate        | 0.000655  |
|    loss                 | 0.0421    |
|    n_updates            | 33670     |
|    policy_gradient_loss | 0.00648   |
|    std                  | 0.105     |
|    value_loss           | 0.00166   |
---------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3369      |
|    time_elapsed         | 10932     |
|    total_timesteps      | 6899712   |
| train/                  |           |
|    approx_kl            | 1.0959921 |
|    clip_fraction        | 0.526     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.71      |
|    explained_variance   | 0.861     |
|    learning_rate        | 0.000655  |
|    loss                 | 0.00348   |
|    n_updates            | 33680     |
|    policy_gradient_loss | 0.0277    |
|    std                  | 0.105     |
|    value_loss           | 0.015     |
---------------------------------------
Eval num_timesteps=6900000, episode_reward=-0.98 +/- 0.04
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -0.98      |
| time/                   |            |
|    total_timesteps      | 6900000    |
| train/                  |            |
|    approx_kl            | 0.26165515 |
|    clip_fraction        | 0.394      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.7        |
|    explained_variance   | -0.109     |
|    learning_rate        | 0.000655   |
|    loss                 | 0.0537     |
|    n_updates            | 33690      |
|    policy_gradient_loss | 0.0107     |
|    std                  | 0.105      |
|    value_loss           | 0.00316    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 3370    |
|    time_elapsed    | 10936   |
|    total_timesteps | 6901760 |
--------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3371      |
|    time_elapsed         | 10939     |
|    total_timesteps      | 6903808   |
| train/                  |           |
|    approx_kl            | 0.5620111 |
|    clip_fraction        | 0.453     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.7       |
|    explained_variance   | 0.428     |
|    learning_rate        | 0.000654  |
|    loss                 | -0.0219   |
|    n_updates            | 33700     |
|    policy_gradient_loss | 0.00438   |
|    std                  | 0.104     |
|    value_loss           | 0.00303   |
---------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3372       |
|    time_elapsed         | 10942      |
|    total_timesteps      | 6905856    |
| train/                  |            |
|    approx_kl            | 0.35252792 |
|    clip_fraction        | 0.429      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.72       |
|    explained_variance   | 0.314      |
|    learning_rate        | 0.000654   |
|    loss                 | 0.0313     |
|    n_updates            | 33710      |
|    policy_gradient_loss | 0.0146     |
|    std                  | 0.104      |
|    value_loss           | 0.00123    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3373       |
|    time_elapsed         | 10945      |
|    total_timesteps      | 6907904    |
| train/                  |            |
|    approx_kl            | 0.95521224 |
|    clip_fraction        | 0.536      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.72       |
|    explained_variance   | 0.825      |
|    learning_rate        | 0.000653   |
|    loss                 | -0.0331    |
|    n_updates            | 33720      |
|    policy_gradient_loss | 0.0151     |
|    std                  | 0.103      |
|    value_loss           | 0.00762    |
----------------------------------------
--------------------------------------
| time/                   |          |
|    fps                  | 631      |
|    iterations           | 3374     |
|    time_elapsed         | 10948    |
|    total_timesteps      | 6909952  |
| train/                  |          |
|    approx_kl            | 0.491467 |
|    clip_fraction        | 0.502    |
|    clip_range           | 0.2      |
|    entropy_loss         | 1.74     |
|    explained_variance   | 0.906    |
|    learning_rate        | 0.000653 |
|    loss                 | -0.0117  |
|    n_updates            | 33730    |
|    policy_gradient_loss | 0.00747  |
|    std                  | 0.101    |
|    value_loss           | 0.0104   |
--------------------------------------
Eval num_timesteps=6910000, episode_reward=-0.97 +/- 0.05
Episode length: 300.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 300       |
|    mean_reward          | -0.974    |
| time/                   |           |
|    total_timesteps      | 6910000   |
| train/                  |           |
|    approx_kl            | 1.5771059 |
|    clip_fraction        | 0.394     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.78      |
|    explained_variance   | 0.455     |
|    learning_rate        | 0.000653  |
|    loss                 | -0.0185   |
|    n_updates            | 33740     |
|    policy_gradient_loss | -0.0218   |
|    std                  | 0.0994    |
|    value_loss           | 0.00554   |
---------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 3375    |
|    time_elapsed    | 10952   |
|    total_timesteps | 6912000 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3376       |
|    time_elapsed         | 10955      |
|    total_timesteps      | 6914048    |
| train/                  |            |
|    approx_kl            | 0.18296498 |
|    clip_fraction        | 0.434      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.8        |
|    explained_variance   | 0.0483     |
|    learning_rate        | 0.000652   |
|    loss                 | 0.0133     |
|    n_updates            | 33750      |
|    policy_gradient_loss | 0.00302    |
|    std                  | 0.099      |
|    value_loss           | 0.00268    |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3377       |
|    time_elapsed         | 10958      |
|    total_timesteps      | 6916096    |
| train/                  |            |
|    approx_kl            | 0.37053525 |
|    clip_fraction        | 0.487      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.79       |
|    explained_variance   | 0.473      |
|    learning_rate        | 0.000652   |
|    loss                 | -0.0248    |
|    n_updates            | 33760      |
|    policy_gradient_loss | 0.016      |
|    std                  | 0.1        |
|    value_loss           | 0.00551    |
----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3378      |
|    time_elapsed         | 10961     |
|    total_timesteps      | 6918144   |
| train/                  |           |
|    approx_kl            | 13.775732 |
|    clip_fraction        | 0.633     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.81      |
|    explained_variance   | 0.526     |
|    learning_rate        | 0.000651  |
|    loss                 | -0.0313   |
|    n_updates            | 33770     |
|    policy_gradient_loss | 0.00725   |
|    std                  | 0.0974    |
|    value_loss           | 0.012     |
---------------------------------------
Eval num_timesteps=6920000, episode_reward=-1.11 +/- 0.14
Episode length: 300.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 300       |
|    mean_reward          | -1.11     |
| time/                   |           |
|    total_timesteps      | 6920000   |
| train/                  |           |
|    approx_kl            | 3.7657971 |
|    clip_fraction        | 0.492     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.87      |
|    explained_variance   | 0.809     |
|    learning_rate        | 0.000651  |
|    loss                 | -0.0571   |
|    n_updates            | 33780     |
|    policy_gradient_loss | -0.0212   |
|    std                  | 0.0943    |
|    value_loss           | 0.00609   |
---------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 3379    |
|    time_elapsed    | 10965   |
|    total_timesteps | 6920192 |
--------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3380      |
|    time_elapsed         | 10968     |
|    total_timesteps      | 6922240   |
| train/                  |           |
|    approx_kl            | 0.6051562 |
|    clip_fraction        | 0.473     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.91      |
|    explained_variance   | 0.0756    |
|    learning_rate        | 0.000651  |
|    loss                 | -0.0139   |
|    n_updates            | 33790     |
|    policy_gradient_loss | 0.00347   |
|    std                  | 0.0933    |
|    value_loss           | 0.00247   |
---------------------------------------
box reached target
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3381      |
|    time_elapsed         | 10971     |
|    total_timesteps      | 6924288   |
| train/                  |           |
|    approx_kl            | 1.3420391 |
|    clip_fraction        | 0.523     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.93      |
|    explained_variance   | 0.748     |
|    learning_rate        | 0.00065   |
|    loss                 | 0.00161   |
|    n_updates            | 33800     |
|    policy_gradient_loss | -0.00669  |
|    std                  | 0.0919    |
|    value_loss           | 0.00482   |
---------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3382      |
|    time_elapsed         | 10974     |
|    total_timesteps      | 6926336   |
| train/                  |           |
|    approx_kl            | 0.6179126 |
|    clip_fraction        | 0.501     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.94      |
|    explained_variance   | 0.364     |
|    learning_rate        | 0.00065   |
|    loss                 | -0.0306   |
|    n_updates            | 33810     |
|    policy_gradient_loss | 0.0423    |
|    std                  | 0.0934    |
|    value_loss           | 0.0537    |
---------------------------------------
--------------------------------------
| time/                   |          |
|    fps                  | 631      |
|    iterations           | 3383     |
|    time_elapsed         | 10977    |
|    total_timesteps      | 6928384  |
| train/                  |          |
|    approx_kl            | 0.528048 |
|    clip_fraction        | 0.475    |
|    clip_range           | 0.2      |
|    entropy_loss         | 1.9      |
|    explained_variance   | 0.803    |
|    learning_rate        | 0.000649 |
|    loss                 | -0.0293  |
|    n_updates            | 33820    |
|    policy_gradient_loss | 0.0247   |
|    std                  | 0.0941   |
|    value_loss           | 0.00946  |
--------------------------------------
Eval num_timesteps=6930000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1         |
| time/                   |            |
|    total_timesteps      | 6930000    |
| train/                  |            |
|    approx_kl            | 0.34732068 |
|    clip_fraction        | 0.476      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.9        |
|    explained_variance   | 0.585      |
|    learning_rate        | 0.000649   |
|    loss                 | 0.0285     |
|    n_updates            | 33830      |
|    policy_gradient_loss | 0.00737    |
|    std                  | 0.094      |
|    value_loss           | 0.00353    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 3384    |
|    time_elapsed    | 10981   |
|    total_timesteps | 6930432 |
--------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3385      |
|    time_elapsed         | 10984     |
|    total_timesteps      | 6932480   |
| train/                  |           |
|    approx_kl            | 2.7981436 |
|    clip_fraction        | 0.488     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.93      |
|    explained_variance   | 0.776     |
|    learning_rate        | 0.000649  |
|    loss                 | -0.0226   |
|    n_updates            | 33840     |
|    policy_gradient_loss | -0.0272   |
|    std                  | 0.0921    |
|    value_loss           | 0.0114    |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3386       |
|    time_elapsed         | 10987      |
|    total_timesteps      | 6934528    |
| train/                  |            |
|    approx_kl            | 0.36542612 |
|    clip_fraction        | 0.513      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.95       |
|    explained_variance   | 0.745      |
|    learning_rate        | 0.000648   |
|    loss                 | 0.0499     |
|    n_updates            | 33850      |
|    policy_gradient_loss | 0.0268     |
|    std                  | 0.0916     |
|    value_loss           | 0.00195    |
----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3387      |
|    time_elapsed         | 10990     |
|    total_timesteps      | 6936576   |
| train/                  |           |
|    approx_kl            | 1.1458983 |
|    clip_fraction        | 0.493     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.94      |
|    explained_variance   | 0.535     |
|    learning_rate        | 0.000648  |
|    loss                 | 0.0312    |
|    n_updates            | 33860     |
|    policy_gradient_loss | 0.0144    |
|    std                  | 0.0939    |
|    value_loss           | 0.00943   |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3388       |
|    time_elapsed         | 10993      |
|    total_timesteps      | 6938624    |
| train/                  |            |
|    approx_kl            | 0.57517606 |
|    clip_fraction        | 0.499      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.91       |
|    explained_variance   | 0.705      |
|    learning_rate        | 0.000647   |
|    loss                 | 0.00267    |
|    n_updates            | 33870      |
|    policy_gradient_loss | 0.0157     |
|    std                  | 0.0942     |
|    value_loss           | 0.0125     |
----------------------------------------
box reached target
Eval num_timesteps=6940000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 300       |
|    mean_reward          | -1        |
| time/                   |           |
|    total_timesteps      | 6940000   |
| train/                  |           |
|    approx_kl            | 0.4076547 |
|    clip_fraction        | 0.478     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.91      |
|    explained_variance   | -0.204    |
|    learning_rate        | 0.000647  |
|    loss                 | 0.0225    |
|    n_updates            | 33880     |
|    policy_gradient_loss | 0.00837   |
|    std                  | 0.0922    |
|    value_loss           | 0.00264   |
---------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 3389    |
|    time_elapsed    | 10997   |
|    total_timesteps | 6940672 |
--------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3390      |
|    time_elapsed         | 11000     |
|    total_timesteps      | 6942720   |
| train/                  |           |
|    approx_kl            | 0.3159219 |
|    clip_fraction        | 0.501     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.94      |
|    explained_variance   | 0.715     |
|    learning_rate        | 0.000647  |
|    loss                 | 0.0576    |
|    n_updates            | 33890     |
|    policy_gradient_loss | 0.037     |
|    std                  | 0.0924    |
|    value_loss           | 0.0122    |
---------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3391      |
|    time_elapsed         | 11003     |
|    total_timesteps      | 6944768   |
| train/                  |           |
|    approx_kl            | 0.8184695 |
|    clip_fraction        | 0.454     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.94      |
|    explained_variance   | 0.598     |
|    learning_rate        | 0.000646  |
|    loss                 | -0.0406   |
|    n_updates            | 33900     |
|    policy_gradient_loss | -0.000992 |
|    std                  | 0.0929    |
|    value_loss           | 0.00661   |
---------------------------------------
--------------------------------------
| time/                   |          |
|    fps                  | 631      |
|    iterations           | 3392     |
|    time_elapsed         | 11006    |
|    total_timesteps      | 6946816  |
| train/                  |          |
|    approx_kl            | 35.043   |
|    clip_fraction        | 0.578    |
|    clip_range           | 0.2      |
|    entropy_loss         | 1.97     |
|    explained_variance   | 0.824    |
|    learning_rate        | 0.000646 |
|    loss                 | -0.00811 |
|    n_updates            | 33910    |
|    policy_gradient_loss | -0.0242  |
|    std                  | 0.0904   |
|    value_loss           | 0.00647  |
--------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3393      |
|    time_elapsed         | 11009     |
|    total_timesteps      | 6948864   |
| train/                  |           |
|    approx_kl            | 2.7874603 |
|    clip_fraction        | 0.598     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.99      |
|    explained_variance   | 0.31      |
|    learning_rate        | 0.000645  |
|    loss                 | -0.039    |
|    n_updates            | 33920     |
|    policy_gradient_loss | 0.0112    |
|    std                  | 0.0895    |
|    value_loss           | 0.00457   |
---------------------------------------
box reached target
Eval num_timesteps=6950000, episode_reward=0.48 +/- 2.50
Episode length: 289.40 +/- 21.20
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 289       |
|    mean_reward          | 0.475     |
| time/                   |           |
|    total_timesteps      | 6950000   |
| train/                  |           |
|    approx_kl            | 0.3935089 |
|    clip_fraction        | 0.492     |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.02      |
|    explained_variance   | 0.801     |
|    learning_rate        | 0.000645  |
|    loss                 | 0.0117    |
|    n_updates            | 33930     |
|    policy_gradient_loss | 0.0175    |
|    std                  | 0.0892    |
|    value_loss           | 0.0124    |
---------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 3394    |
|    time_elapsed    | 11013   |
|    total_timesteps | 6950912 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3395       |
|    time_elapsed         | 11016      |
|    total_timesteps      | 6952960    |
| train/                  |            |
|    approx_kl            | 0.31391272 |
|    clip_fraction        | 0.449      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.02       |
|    explained_variance   | 0.437      |
|    learning_rate        | 0.000645   |
|    loss                 | 0.0565     |
|    n_updates            | 33940      |
|    policy_gradient_loss | 0.0194     |
|    std                  | 0.0891     |
|    value_loss           | 0.000785   |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3396       |
|    time_elapsed         | 11019      |
|    total_timesteps      | 6955008    |
| train/                  |            |
|    approx_kl            | 0.55121315 |
|    clip_fraction        | 0.532      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.99       |
|    explained_variance   | 0.64       |
|    learning_rate        | 0.000644   |
|    loss                 | 0.0203     |
|    n_updates            | 33950      |
|    policy_gradient_loss | 0.0289     |
|    std                  | 0.0906     |
|    value_loss           | 0.00294    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3397       |
|    time_elapsed         | 11022      |
|    total_timesteps      | 6957056    |
| train/                  |            |
|    approx_kl            | 0.89792025 |
|    clip_fraction        | 0.526      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.96       |
|    explained_variance   | 0.106      |
|    learning_rate        | 0.000644   |
|    loss                 | 0.00244    |
|    n_updates            | 33960      |
|    policy_gradient_loss | 0.0127     |
|    std                  | 0.0927     |
|    value_loss           | 0.00337    |
----------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3398      |
|    time_elapsed         | 11025     |
|    total_timesteps      | 6959104   |
| train/                  |           |
|    approx_kl            | 0.5694941 |
|    clip_fraction        | 0.553     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.9       |
|    explained_variance   | 0.602     |
|    learning_rate        | 0.000643  |
|    loss                 | -0.00162  |
|    n_updates            | 33970     |
|    policy_gradient_loss | 0.0248    |
|    std                  | 0.0954    |
|    value_loss           | 0.0047    |
---------------------------------------
Eval num_timesteps=6960000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 300       |
|    mean_reward          | -1        |
| time/                   |           |
|    total_timesteps      | 6960000   |
| train/                  |           |
|    approx_kl            | 2.1297946 |
|    clip_fraction        | 0.562     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.9       |
|    explained_variance   | -0.0729   |
|    learning_rate        | 0.000643  |
|    loss                 | -0.0178   |
|    n_updates            | 33980     |
|    policy_gradient_loss | 0.0282    |
|    std                  | 0.0939    |
|    value_loss           | 0.115     |
---------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 3399    |
|    time_elapsed    | 11029   |
|    total_timesteps | 6961152 |
--------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3400      |
|    time_elapsed         | 11032     |
|    total_timesteps      | 6963200   |
| train/                  |           |
|    approx_kl            | 1.3087518 |
|    clip_fraction        | 0.531     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.92      |
|    explained_variance   | 0.72      |
|    learning_rate        | 0.000643  |
|    loss                 | 0.0292    |
|    n_updates            | 33990     |
|    policy_gradient_loss | 0.0103    |
|    std                  | 0.0939    |
|    value_loss           | 0.00921   |
---------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3401      |
|    time_elapsed         | 11036     |
|    total_timesteps      | 6965248   |
| train/                  |           |
|    approx_kl            | 0.4074606 |
|    clip_fraction        | 0.48      |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.93      |
|    explained_variance   | 0.906     |
|    learning_rate        | 0.000642  |
|    loss                 | 0.0357    |
|    n_updates            | 34000     |
|    policy_gradient_loss | 0.0273    |
|    std                  | 0.0933    |
|    value_loss           | 0.00488   |
---------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3402      |
|    time_elapsed         | 11039     |
|    total_timesteps      | 6967296   |
| train/                  |           |
|    approx_kl            | 0.8547338 |
|    clip_fraction        | 0.504     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.91      |
|    explained_variance   | 0.716     |
|    learning_rate        | 0.000642  |
|    loss                 | 0.00192   |
|    n_updates            | 34010     |
|    policy_gradient_loss | 0.0176    |
|    std                  | 0.0939    |
|    value_loss           | 0.00218   |
---------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3403      |
|    time_elapsed         | 11042     |
|    total_timesteps      | 6969344   |
| train/                  |           |
|    approx_kl            | 1.2775652 |
|    clip_fraction        | 0.494     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.93      |
|    explained_variance   | 0.749     |
|    learning_rate        | 0.000641  |
|    loss                 | -0.0416   |
|    n_updates            | 34020     |
|    policy_gradient_loss | 0.0214    |
|    std                  | 0.0926    |
|    value_loss           | 0.0138    |
---------------------------------------
Eval num_timesteps=6970000, episode_reward=-0.73 +/- 0.54
Episode length: 300.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 300       |
|    mean_reward          | -0.731    |
| time/                   |           |
|    total_timesteps      | 6970000   |
| train/                  |           |
|    approx_kl            | 0.4707708 |
|    clip_fraction        | 0.45      |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.95      |
|    explained_variance   | 0.234     |
|    learning_rate        | 0.000641  |
|    loss                 | 0.0157    |
|    n_updates            | 34030     |
|    policy_gradient_loss | 0.0129    |
|    std                  | 0.092     |
|    value_loss           | 0.00371   |
---------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 3404    |
|    time_elapsed    | 11046   |
|    total_timesteps | 6971392 |
--------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3405      |
|    time_elapsed         | 11049     |
|    total_timesteps      | 6973440   |
| train/                  |           |
|    approx_kl            | 0.5945838 |
|    clip_fraction        | 0.537     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.97      |
|    explained_variance   | 0.562     |
|    learning_rate        | 0.000641  |
|    loss                 | 0.0111    |
|    n_updates            | 34040     |
|    policy_gradient_loss | 0.0176    |
|    std                  | 0.091     |
|    value_loss           | 0.00258   |
---------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3406      |
|    time_elapsed         | 11052     |
|    total_timesteps      | 6975488   |
| train/                  |           |
|    approx_kl            | 2.6128898 |
|    clip_fraction        | 0.554     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.96      |
|    explained_variance   | 0.762     |
|    learning_rate        | 0.00064   |
|    loss                 | -0.0406   |
|    n_updates            | 34050     |
|    policy_gradient_loss | -0.0122   |
|    std                  | 0.0903    |
|    value_loss           | 0.00598   |
---------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3407      |
|    time_elapsed         | 11055     |
|    total_timesteps      | 6977536   |
| train/                  |           |
|    approx_kl            | 2.0149033 |
|    clip_fraction        | 0.506     |
|    clip_range           | 0.2       |
|    entropy_loss         | 2         |
|    explained_variance   | -0.0617   |
|    learning_rate        | 0.00064   |
|    loss                 | -0.0157   |
|    n_updates            | 34060     |
|    policy_gradient_loss | 0.00291   |
|    std                  | 0.0889    |
|    value_loss           | 0.00278   |
---------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3408       |
|    time_elapsed         | 11058      |
|    total_timesteps      | 6979584    |
| train/                  |            |
|    approx_kl            | 0.55292106 |
|    clip_fraction        | 0.483      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2          |
|    explained_variance   | 0.593      |
|    learning_rate        | 0.000639   |
|    loss                 | -0.023     |
|    n_updates            | 34070      |
|    policy_gradient_loss | 0.0216     |
|    std                  | 0.0896     |
|    value_loss           | 0.00412    |
----------------------------------------
box reached target
box reached target
Eval num_timesteps=6980000, episode_reward=1.59 +/- 3.20
Episode length: 260.40 +/- 52.55
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 260       |
|    mean_reward          | 1.59      |
| time/                   |           |
|    total_timesteps      | 6980000   |
| train/                  |           |
|    approx_kl            | 1.6864271 |
|    clip_fraction        | 0.563     |
|    clip_range           | 0.2       |
|    entropy_loss         | 2         |
|    explained_variance   | 0.32      |
|    learning_rate        | 0.000639  |
|    loss                 | 0.0832    |
|    n_updates            | 34080     |
|    policy_gradient_loss | 0.00836   |
|    std                  | 0.0895    |
|    value_loss           | 0.118     |
---------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 3409    |
|    time_elapsed    | 11062   |
|    total_timesteps | 6981632 |
--------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3410      |
|    time_elapsed         | 11065     |
|    total_timesteps      | 6983680   |
| train/                  |           |
|    approx_kl            | 3.5408792 |
|    clip_fraction        | 0.595     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.99      |
|    explained_variance   | 0.12      |
|    learning_rate        | 0.000639  |
|    loss                 | -0.0311   |
|    n_updates            | 34090     |
|    policy_gradient_loss | 0.0122    |
|    std                  | 0.0902    |
|    value_loss           | 0.00182   |
---------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3411      |
|    time_elapsed         | 11068     |
|    total_timesteps      | 6985728   |
| train/                  |           |
|    approx_kl            | 0.3095643 |
|    clip_fraction        | 0.469     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.97      |
|    explained_variance   | 0.00407   |
|    learning_rate        | 0.000638  |
|    loss                 | -0.00419  |
|    n_updates            | 34100     |
|    policy_gradient_loss | 0.02      |
|    std                  | 0.0912    |
|    value_loss           | 0.00167   |
---------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3412      |
|    time_elapsed         | 11071     |
|    total_timesteps      | 6987776   |
| train/                  |           |
|    approx_kl            | 1.6192861 |
|    clip_fraction        | 0.563     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.95      |
|    explained_variance   | 0.759     |
|    learning_rate        | 0.000638  |
|    loss                 | -0.0209   |
|    n_updates            | 34110     |
|    policy_gradient_loss | -0.00167  |
|    std                  | 0.0913    |
|    value_loss           | 0.00328   |
---------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3413      |
|    time_elapsed         | 11074     |
|    total_timesteps      | 6989824   |
| train/                  |           |
|    approx_kl            | 2.1639566 |
|    clip_fraction        | 0.508     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.97      |
|    explained_variance   | 0.838     |
|    learning_rate        | 0.000637  |
|    loss                 | 0.00256   |
|    n_updates            | 34120     |
|    policy_gradient_loss | -0.0182   |
|    std                  | 0.0896    |
|    value_loss           | 0.00662   |
---------------------------------------
Eval num_timesteps=6990000, episode_reward=-0.75 +/- 0.64
Episode length: 300.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 300       |
|    mean_reward          | -0.753    |
| time/                   |           |
|    total_timesteps      | 6990000   |
| train/                  |           |
|    approx_kl            | 0.5138511 |
|    clip_fraction        | 0.501     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.99      |
|    explained_variance   | -0.2      |
|    learning_rate        | 0.000637  |
|    loss                 | -0.0108   |
|    n_updates            | 34130     |
|    policy_gradient_loss | 0.0102    |
|    std                  | 0.0901    |
|    value_loss           | 0.00229   |
---------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 3414    |
|    time_elapsed    | 11078   |
|    total_timesteps | 6991872 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3415       |
|    time_elapsed         | 11081      |
|    total_timesteps      | 6993920    |
| train/                  |            |
|    approx_kl            | 0.78657615 |
|    clip_fraction        | 0.508      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.97       |
|    explained_variance   | 0.495      |
|    learning_rate        | 0.000637   |
|    loss                 | -0.00245   |
|    n_updates            | 34140      |
|    policy_gradient_loss | 0.0281     |
|    std                  | 0.0921     |
|    value_loss           | 0.00614    |
----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3416      |
|    time_elapsed         | 11084     |
|    total_timesteps      | 6995968   |
| train/                  |           |
|    approx_kl            | 3.8472033 |
|    clip_fraction        | 0.565     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.94      |
|    explained_variance   | 0.595     |
|    learning_rate        | 0.000636  |
|    loss                 | -0.042    |
|    n_updates            | 34150     |
|    policy_gradient_loss | 0.00786   |
|    std                  | 0.0916    |
|    value_loss           | 0.00333   |
---------------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3417       |
|    time_elapsed         | 11087      |
|    total_timesteps      | 6998016    |
| train/                  |            |
|    approx_kl            | 0.68215334 |
|    clip_fraction        | 0.519      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.95       |
|    explained_variance   | 0.792      |
|    learning_rate        | 0.000636   |
|    loss                 | -0.0155    |
|    n_updates            | 34160      |
|    policy_gradient_loss | -0.00862   |
|    std                  | 0.0908     |
|    value_loss           | 0.00176    |
----------------------------------------
Eval num_timesteps=7000000, episode_reward=-0.86 +/- 0.27
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -0.865     |
| time/                   |            |
|    total_timesteps      | 7000000    |
| train/                  |            |
|    approx_kl            | 0.76798403 |
|    clip_fraction        | 0.578      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.97       |
|    explained_variance   | 0.521      |
|    learning_rate        | 0.000635   |
|    loss                 | 0.157      |
|    n_updates            | 34170      |
|    policy_gradient_loss | 0.0193     |
|    std                  | 0.0905     |
|    value_loss           | 0.0228     |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 3418    |
|    time_elapsed    | 11091   |
|    total_timesteps | 7000064 |
--------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3419      |
|    time_elapsed         | 11094     |
|    total_timesteps      | 7002112   |
| train/                  |           |
|    approx_kl            | 0.8235914 |
|    clip_fraction        | 0.523     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.98      |
|    explained_variance   | 0.255     |
|    learning_rate        | 0.000635  |
|    loss                 | -0.00799  |
|    n_updates            | 34180     |
|    policy_gradient_loss | 0.011     |
|    std                  | 0.0899    |
|    value_loss           | 0.00964   |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3420       |
|    time_elapsed         | 11097      |
|    total_timesteps      | 7004160    |
| train/                  |            |
|    approx_kl            | 0.77602863 |
|    clip_fraction        | 0.524      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.02       |
|    explained_variance   | 0.349      |
|    learning_rate        | 0.000635   |
|    loss                 | 0.0315     |
|    n_updates            | 34190      |
|    policy_gradient_loss | 0.0156     |
|    std                  | 0.0877     |
|    value_loss           | 0.0506     |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3421       |
|    time_elapsed         | 11100      |
|    total_timesteps      | 7006208    |
| train/                  |            |
|    approx_kl            | 0.50833523 |
|    clip_fraction        | 0.463      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.01       |
|    explained_variance   | 0.759      |
|    learning_rate        | 0.000634   |
|    loss                 | -0.0446    |
|    n_updates            | 34200      |
|    policy_gradient_loss | 0.00455    |
|    std                  | 0.0895     |
|    value_loss           | 0.00923    |
----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3422      |
|    time_elapsed         | 11103     |
|    total_timesteps      | 7008256   |
| train/                  |           |
|    approx_kl            | 1.0344951 |
|    clip_fraction        | 0.525     |
|    clip_range           | 0.2       |
|    entropy_loss         | 2         |
|    explained_variance   | 0.598     |
|    learning_rate        | 0.000634  |
|    loss                 | -0.045    |
|    n_updates            | 34210     |
|    policy_gradient_loss | 0.0174    |
|    std                  | 0.089     |
|    value_loss           | 0.00566   |
---------------------------------------
Eval num_timesteps=7010000, episode_reward=-0.93 +/- 0.14
Episode length: 300.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 300       |
|    mean_reward          | -0.929    |
| time/                   |           |
|    total_timesteps      | 7010000   |
| train/                  |           |
|    approx_kl            | 0.4751637 |
|    clip_fraction        | 0.501     |
|    clip_range           | 0.2       |
|    entropy_loss         | 2         |
|    explained_variance   | 0.647     |
|    learning_rate        | 0.000633  |
|    loss                 | 0.0113    |
|    n_updates            | 34220     |
|    policy_gradient_loss | 0.0172    |
|    std                  | 0.0891    |
|    value_loss           | 0.00658   |
---------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 3423    |
|    time_elapsed    | 11107   |
|    total_timesteps | 7010304 |
--------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3424      |
|    time_elapsed         | 11110     |
|    total_timesteps      | 7012352   |
| train/                  |           |
|    approx_kl            | 0.5006394 |
|    clip_fraction        | 0.527     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.99      |
|    explained_variance   | 0.728     |
|    learning_rate        | 0.000633  |
|    loss                 | 0.0439    |
|    n_updates            | 34230     |
|    policy_gradient_loss | 0.0217    |
|    std                  | 0.0894    |
|    value_loss           | 0.00752   |
---------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3425       |
|    time_elapsed         | 11113      |
|    total_timesteps      | 7014400    |
| train/                  |            |
|    approx_kl            | 0.73187006 |
|    clip_fraction        | 0.567      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.96       |
|    explained_variance   | 0.569      |
|    learning_rate        | 0.000633   |
|    loss                 | -0.0397    |
|    n_updates            | 34240      |
|    policy_gradient_loss | 0.0129     |
|    std                  | 0.0916     |
|    value_loss           | 0.00787    |
----------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3426      |
|    time_elapsed         | 11116     |
|    total_timesteps      | 7016448   |
| train/                  |           |
|    approx_kl            | 0.6492008 |
|    clip_fraction        | 0.492     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.96      |
|    explained_variance   | 0.304     |
|    learning_rate        | 0.000632  |
|    loss                 | -0.00364  |
|    n_updates            | 34250     |
|    policy_gradient_loss | 0.0144    |
|    std                  | 0.0905    |
|    value_loss           | 0.0256    |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3427       |
|    time_elapsed         | 11119      |
|    total_timesteps      | 7018496    |
| train/                  |            |
|    approx_kl            | 0.37274107 |
|    clip_fraction        | 0.497      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.95       |
|    explained_variance   | 0.253      |
|    learning_rate        | 0.000632   |
|    loss                 | 0.0563     |
|    n_updates            | 34260      |
|    policy_gradient_loss | 0.0273     |
|    std                  | 0.0923     |
|    value_loss           | 0.0934     |
----------------------------------------
box reached target
Eval num_timesteps=7020000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1         |
| time/                   |            |
|    total_timesteps      | 7020000    |
| train/                  |            |
|    approx_kl            | 0.29328457 |
|    clip_fraction        | 0.433      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.92       |
|    explained_variance   | 0.412      |
|    learning_rate        | 0.000631   |
|    loss                 | -0.0357    |
|    n_updates            | 34270      |
|    policy_gradient_loss | 0.00628    |
|    std                  | 0.0929     |
|    value_loss           | 0.00364    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 3428    |
|    time_elapsed    | 11123   |
|    total_timesteps | 7020544 |
--------------------------------
--------------------------------------
| time/                   |          |
|    fps                  | 631      |
|    iterations           | 3429     |
|    time_elapsed         | 11126    |
|    total_timesteps      | 7022592  |
| train/                  |          |
|    approx_kl            | 6.382267 |
|    clip_fraction        | 0.659    |
|    clip_range           | 0.2      |
|    entropy_loss         | 1.96     |
|    explained_variance   | 0.536    |
|    learning_rate        | 0.000631 |
|    loss                 | -0.0168  |
|    n_updates            | 34280    |
|    policy_gradient_loss | 0.00623  |
|    std                  | 0.0887   |
|    value_loss           | 0.0485   |
--------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3430      |
|    time_elapsed         | 11129     |
|    total_timesteps      | 7024640   |
| train/                  |           |
|    approx_kl            | 1.1829139 |
|    clip_fraction        | 0.546     |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.01      |
|    explained_variance   | 0.641     |
|    learning_rate        | 0.000631  |
|    loss                 | -0.0492   |
|    n_updates            | 34290     |
|    policy_gradient_loss | 0.0199    |
|    std                  | 0.088     |
|    value_loss           | 0.0178    |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3431       |
|    time_elapsed         | 11132      |
|    total_timesteps      | 7026688    |
| train/                  |            |
|    approx_kl            | 0.36805552 |
|    clip_fraction        | 0.501      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2          |
|    explained_variance   | 0.565      |
|    learning_rate        | 0.00063    |
|    loss                 | -0.0539    |
|    n_updates            | 34300      |
|    policy_gradient_loss | 0.0179     |
|    std                  | 0.0893     |
|    value_loss           | 0.0125     |
----------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3432      |
|    time_elapsed         | 11135     |
|    total_timesteps      | 7028736   |
| train/                  |           |
|    approx_kl            | 0.4365368 |
|    clip_fraction        | 0.472     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.98      |
|    explained_variance   | 0.728     |
|    learning_rate        | 0.00063   |
|    loss                 | 0.0586    |
|    n_updates            | 34310     |
|    policy_gradient_loss | 0.0239    |
|    std                  | 0.0907    |
|    value_loss           | 0.00601   |
---------------------------------------
box reached target
box reached target
Eval num_timesteps=7030000, episode_reward=-0.79 +/- 0.42
Episode length: 300.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 300       |
|    mean_reward          | -0.79     |
| time/                   |           |
|    total_timesteps      | 7030000   |
| train/                  |           |
|    approx_kl            | 0.9510516 |
|    clip_fraction        | 0.494     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.96      |
|    explained_variance   | 0.558     |
|    learning_rate        | 0.000629  |
|    loss                 | 0.0528    |
|    n_updates            | 34320     |
|    policy_gradient_loss | 0.0026    |
|    std                  | 0.0911    |
|    value_loss           | 0.03      |
---------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 3433    |
|    time_elapsed    | 11139   |
|    total_timesteps | 7030784 |
--------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3434      |
|    time_elapsed         | 11142     |
|    total_timesteps      | 7032832   |
| train/                  |           |
|    approx_kl            | 0.6949307 |
|    clip_fraction        | 0.547     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.96      |
|    explained_variance   | 0.8       |
|    learning_rate        | 0.000629  |
|    loss                 | -0.0219   |
|    n_updates            | 34330     |
|    policy_gradient_loss | 0.0345    |
|    std                  | 0.0906    |
|    value_loss           | 0.0187    |
---------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3435      |
|    time_elapsed         | 11145     |
|    total_timesteps      | 7034880   |
| train/                  |           |
|    approx_kl            | 0.2166464 |
|    clip_fraction        | 0.439     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.94      |
|    explained_variance   | 0.69      |
|    learning_rate        | 0.000629  |
|    loss                 | -0.0285   |
|    n_updates            | 34340     |
|    policy_gradient_loss | 0.0116    |
|    std                  | 0.0933    |
|    value_loss           | 0.0113    |
---------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3436      |
|    time_elapsed         | 11148     |
|    total_timesteps      | 7036928   |
| train/                  |           |
|    approx_kl            | 0.9627843 |
|    clip_fraction        | 0.447     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.93      |
|    explained_variance   | 0.337     |
|    learning_rate        | 0.000628  |
|    loss                 | -0.00223  |
|    n_updates            | 34350     |
|    policy_gradient_loss | 0.0189    |
|    std                  | 0.0909    |
|    value_loss           | 0.00937   |
---------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3437       |
|    time_elapsed         | 11152      |
|    total_timesteps      | 7038976    |
| train/                  |            |
|    approx_kl            | 0.42851847 |
|    clip_fraction        | 0.513      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.93       |
|    explained_variance   | 0.751      |
|    learning_rate        | 0.000628   |
|    loss                 | 0.0283     |
|    n_updates            | 34360      |
|    policy_gradient_loss | 0.0128     |
|    std                  | 0.0924     |
|    value_loss           | 0.0091     |
----------------------------------------
box reached target
box reached target
Eval num_timesteps=7040000, episode_reward=0.26 +/- 2.51
Episode length: 276.80 +/- 46.40
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 277        |
|    mean_reward          | 0.256      |
| time/                   |            |
|    total_timesteps      | 7040000    |
| train/                  |            |
|    approx_kl            | 0.36673617 |
|    clip_fraction        | 0.449      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.92       |
|    explained_variance   | 0.746      |
|    learning_rate        | 0.000627   |
|    loss                 | 0.0941     |
|    n_updates            | 34370      |
|    policy_gradient_loss | 0.015      |
|    std                  | 0.0937     |
|    value_loss           | 0.0103     |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 3438    |
|    time_elapsed    | 11155   |
|    total_timesteps | 7041024 |
--------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3439      |
|    time_elapsed         | 11158     |
|    total_timesteps      | 7043072   |
| train/                  |           |
|    approx_kl            | 3.9656072 |
|    clip_fraction        | 0.535     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.93      |
|    explained_variance   | 0.757     |
|    learning_rate        | 0.000627  |
|    loss                 | -0.0293   |
|    n_updates            | 34380     |
|    policy_gradient_loss | -0.00692  |
|    std                  | 0.0908    |
|    value_loss           | 0.0187    |
---------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3440      |
|    time_elapsed         | 11162     |
|    total_timesteps      | 7045120   |
| train/                  |           |
|    approx_kl            | 0.4686142 |
|    clip_fraction        | 0.474     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.98      |
|    explained_variance   | 0.796     |
|    learning_rate        | 0.000627  |
|    loss                 | -0.00808  |
|    n_updates            | 34390     |
|    policy_gradient_loss | 0.0171    |
|    std                  | 0.089     |
|    value_loss           | 0.0116    |
---------------------------------------
box reached target
--------------------------------------
| time/                   |          |
|    fps                  | 631      |
|    iterations           | 3441     |
|    time_elapsed         | 11165    |
|    total_timesteps      | 7047168  |
| train/                  |          |
|    approx_kl            | 5.794847 |
|    clip_fraction        | 0.564    |
|    clip_range           | 0.2      |
|    entropy_loss         | 2.01     |
|    explained_variance   | 0.795    |
|    learning_rate        | 0.000626 |
|    loss                 | 0.0665   |
|    n_updates            | 34400    |
|    policy_gradient_loss | -0.00873 |
|    std                  | 0.0878   |
|    value_loss           | 0.00283  |
--------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3442      |
|    time_elapsed         | 11168     |
|    total_timesteps      | 7049216   |
| train/                  |           |
|    approx_kl            | 1.1693528 |
|    clip_fraction        | 0.515     |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.04      |
|    explained_variance   | 0.697     |
|    learning_rate        | 0.000626  |
|    loss                 | -0.0111   |
|    n_updates            | 34410     |
|    policy_gradient_loss | 0.00157   |
|    std                  | 0.0857    |
|    value_loss           | 0.0384    |
---------------------------------------
Eval num_timesteps=7050000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1         |
| time/                   |            |
|    total_timesteps      | 7050000    |
| train/                  |            |
|    approx_kl            | 0.24014533 |
|    clip_fraction        | 0.483      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.06       |
|    explained_variance   | 0.275      |
|    learning_rate        | 0.000625   |
|    loss                 | 0.00269    |
|    n_updates            | 34420      |
|    policy_gradient_loss | 0.0177     |
|    std                  | 0.0871     |
|    value_loss           | 0.00451    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 3443    |
|    time_elapsed    | 11172   |
|    total_timesteps | 7051264 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3444       |
|    time_elapsed         | 11175      |
|    total_timesteps      | 7053312    |
| train/                  |            |
|    approx_kl            | 0.49386632 |
|    clip_fraction        | 0.521      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.04       |
|    explained_variance   | 0.788      |
|    learning_rate        | 0.000625   |
|    loss                 | 0.104      |
|    n_updates            | 34430      |
|    policy_gradient_loss | 0.0168     |
|    std                  | 0.087      |
|    value_loss           | 0.00864    |
----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3445      |
|    time_elapsed         | 11178     |
|    total_timesteps      | 7055360   |
| train/                  |           |
|    approx_kl            | 1.6363177 |
|    clip_fraction        | 0.548     |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.03      |
|    explained_variance   | 0.736     |
|    learning_rate        | 0.000625  |
|    loss                 | -0.0601   |
|    n_updates            | 34440     |
|    policy_gradient_loss | 0.00894   |
|    std                  | 0.088     |
|    value_loss           | 0.00429   |
---------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3446      |
|    time_elapsed         | 11181     |
|    total_timesteps      | 7057408   |
| train/                  |           |
|    approx_kl            | 0.6946293 |
|    clip_fraction        | 0.547     |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.03      |
|    explained_variance   | 0.411     |
|    learning_rate        | 0.000624  |
|    loss                 | -0.032    |
|    n_updates            | 34450     |
|    policy_gradient_loss | 0.0196    |
|    std                  | 0.0876    |
|    value_loss           | 0.00488   |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3447       |
|    time_elapsed         | 11184      |
|    total_timesteps      | 7059456    |
| train/                  |            |
|    approx_kl            | 0.91111934 |
|    clip_fraction        | 0.541      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.02       |
|    explained_variance   | 0.774      |
|    learning_rate        | 0.000624   |
|    loss                 | -0.0305    |
|    n_updates            | 34460      |
|    policy_gradient_loss | 0.0284     |
|    std                  | 0.0887     |
|    value_loss           | 0.00654    |
----------------------------------------
Eval num_timesteps=7060000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1         |
| time/                   |            |
|    total_timesteps      | 7060000    |
| train/                  |            |
|    approx_kl            | 0.18793571 |
|    clip_fraction        | 0.437      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.02       |
|    explained_variance   | 0.558      |
|    learning_rate        | 0.000623   |
|    loss                 | -0.0384    |
|    n_updates            | 34470      |
|    policy_gradient_loss | 0.0196     |
|    std                  | 0.0879     |
|    value_loss           | 0.00267    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 3448    |
|    time_elapsed    | 11188   |
|    total_timesteps | 7061504 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3449       |
|    time_elapsed         | 11191      |
|    total_timesteps      | 7063552    |
| train/                  |            |
|    approx_kl            | 0.40819222 |
|    clip_fraction        | 0.461      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.03       |
|    explained_variance   | 0.648      |
|    learning_rate        | 0.000623   |
|    loss                 | 0.0309     |
|    n_updates            | 34480      |
|    policy_gradient_loss | -0.00507   |
|    std                  | 0.0879     |
|    value_loss           | 0.00513    |
----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3450      |
|    time_elapsed         | 11194     |
|    total_timesteps      | 7065600   |
| train/                  |           |
|    approx_kl            | 0.3141358 |
|    clip_fraction        | 0.469     |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.02      |
|    explained_variance   | -0.527    |
|    learning_rate        | 0.000623  |
|    loss                 | 0.0659    |
|    n_updates            | 34490     |
|    policy_gradient_loss | 0.0171    |
|    std                  | 0.0873    |
|    value_loss           | 0.00433   |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3451       |
|    time_elapsed         | 11197      |
|    total_timesteps      | 7067648    |
| train/                  |            |
|    approx_kl            | 0.29885447 |
|    clip_fraction        | 0.443      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.05       |
|    explained_variance   | 0.409      |
|    learning_rate        | 0.000622   |
|    loss                 | -0.000514  |
|    n_updates            | 34500      |
|    policy_gradient_loss | 0.0235     |
|    std                  | 0.0871     |
|    value_loss           | 0.00489    |
----------------------------------------
--------------------------------------
| time/                   |          |
|    fps                  | 631      |
|    iterations           | 3452     |
|    time_elapsed         | 11200    |
|    total_timesteps      | 7069696  |
| train/                  |          |
|    approx_kl            | 2.779292 |
|    clip_fraction        | 0.536    |
|    clip_range           | 0.2      |
|    entropy_loss         | 2.06     |
|    explained_variance   | 0.755    |
|    learning_rate        | 0.000622 |
|    loss                 | -0.0298  |
|    n_updates            | 34510    |
|    policy_gradient_loss | -0.0139  |
|    std                  | 0.0848   |
|    value_loss           | 0.00253  |
--------------------------------------
Eval num_timesteps=7070000, episode_reward=-0.81 +/- 0.38
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -0.809     |
| time/                   |            |
|    total_timesteps      | 7070000    |
| train/                  |            |
|    approx_kl            | 0.39649606 |
|    clip_fraction        | 0.452      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.1        |
|    explained_variance   | 0.573      |
|    learning_rate        | 0.000621   |
|    loss                 | -0.0141    |
|    n_updates            | 34520      |
|    policy_gradient_loss | 0.0117     |
|    std                  | 0.0847     |
|    value_loss           | 0.003      |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 3453    |
|    time_elapsed    | 11204   |
|    total_timesteps | 7071744 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3454       |
|    time_elapsed         | 11207      |
|    total_timesteps      | 7073792    |
| train/                  |            |
|    approx_kl            | 0.50742865 |
|    clip_fraction        | 0.507      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.1        |
|    explained_variance   | 0.717      |
|    learning_rate        | 0.000621   |
|    loss                 | -0.0068    |
|    n_updates            | 34530      |
|    policy_gradient_loss | 0.019      |
|    std                  | 0.084      |
|    value_loss           | 0.00435    |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3455       |
|    time_elapsed         | 11210      |
|    total_timesteps      | 7075840    |
| train/                  |            |
|    approx_kl            | 0.44226128 |
|    clip_fraction        | 0.51       |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.12       |
|    explained_variance   | 0.346      |
|    learning_rate        | 0.000621   |
|    loss                 | -0.0111    |
|    n_updates            | 34540      |
|    policy_gradient_loss | 0.0315     |
|    std                  | 0.0839     |
|    value_loss           | 0.00356    |
----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3456      |
|    time_elapsed         | 11213     |
|    total_timesteps      | 7077888   |
| train/                  |           |
|    approx_kl            | 0.3712539 |
|    clip_fraction        | 0.506     |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.12      |
|    explained_variance   | 0.0706    |
|    learning_rate        | 0.00062   |
|    loss                 | 0.0308    |
|    n_updates            | 34550     |
|    policy_gradient_loss | 0.00926   |
|    std                  | 0.0848    |
|    value_loss           | 0.118     |
---------------------------------------
--------------------------------------
| time/                   |          |
|    fps                  | 631      |
|    iterations           | 3457     |
|    time_elapsed         | 11216    |
|    total_timesteps      | 7079936  |
| train/                  |          |
|    approx_kl            | 0.625308 |
|    clip_fraction        | 0.48     |
|    clip_range           | 0.2      |
|    entropy_loss         | 2.1      |
|    explained_variance   | 0.418    |
|    learning_rate        | 0.00062  |
|    loss                 | 0.0745   |
|    n_updates            | 34560    |
|    policy_gradient_loss | 0.0325   |
|    std                  | 0.085    |
|    value_loss           | 0.00253  |
--------------------------------------
Eval num_timesteps=7080000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 300       |
|    mean_reward          | -1        |
| time/                   |           |
|    total_timesteps      | 7080000   |
| train/                  |           |
|    approx_kl            | 2.5506616 |
|    clip_fraction        | 0.583     |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.1       |
|    explained_variance   | 0.477     |
|    learning_rate        | 0.000619  |
|    loss                 | -0.0492   |
|    n_updates            | 34570     |
|    policy_gradient_loss | 0.00619   |
|    std                  | 0.0835    |
|    value_loss           | 0.00922   |
---------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 3458    |
|    time_elapsed    | 11220   |
|    total_timesteps | 7081984 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3459       |
|    time_elapsed         | 11223      |
|    total_timesteps      | 7084032    |
| train/                  |            |
|    approx_kl            | 0.33699474 |
|    clip_fraction        | 0.513      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.11       |
|    explained_variance   | -0.236     |
|    learning_rate        | 0.000619   |
|    loss                 | 0.0864     |
|    n_updates            | 34580      |
|    policy_gradient_loss | 0.0211     |
|    std                  | 0.0855     |
|    value_loss           | 0.0034     |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3460       |
|    time_elapsed         | 11226      |
|    total_timesteps      | 7086080    |
| train/                  |            |
|    approx_kl            | 0.23838782 |
|    clip_fraction        | 0.462      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.07       |
|    explained_variance   | 0.346      |
|    learning_rate        | 0.000619   |
|    loss                 | -0.0152    |
|    n_updates            | 34590      |
|    policy_gradient_loss | 0.00834    |
|    std                  | 0.0859     |
|    value_loss           | 0.00367    |
----------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3461      |
|    time_elapsed         | 11229     |
|    total_timesteps      | 7088128   |
| train/                  |           |
|    approx_kl            | 0.2382579 |
|    clip_fraction        | 0.469     |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.08      |
|    explained_variance   | 0.237     |
|    learning_rate        | 0.000618  |
|    loss                 | -0.00508  |
|    n_updates            | 34600     |
|    policy_gradient_loss | 0.028     |
|    std                  | 0.0857    |
|    value_loss           | 0.00128   |
---------------------------------------
Eval num_timesteps=7090000, episode_reward=-0.72 +/- 0.56
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -0.716     |
| time/                   |            |
|    total_timesteps      | 7090000    |
| train/                  |            |
|    approx_kl            | 0.85275435 |
|    clip_fraction        | 0.503      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.11       |
|    explained_variance   | 0.765      |
|    learning_rate        | 0.000618   |
|    loss                 | -0.00491   |
|    n_updates            | 34610      |
|    policy_gradient_loss | 0.151      |
|    std                  | 0.0836     |
|    value_loss           | 0.0178     |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 3462    |
|    time_elapsed    | 11233   |
|    total_timesteps | 7090176 |
--------------------------------
--------------------------------------
| time/                   |          |
|    fps                  | 631      |
|    iterations           | 3463     |
|    time_elapsed         | 11236    |
|    total_timesteps      | 7092224  |
| train/                  |          |
|    approx_kl            | 1.107249 |
|    clip_fraction        | 0.513    |
|    clip_range           | 0.2      |
|    entropy_loss         | 2.15     |
|    explained_variance   | 0.776    |
|    learning_rate        | 0.000617 |
|    loss                 | -0.0165  |
|    n_updates            | 34620    |
|    policy_gradient_loss | 0.00272  |
|    std                  | 0.0818   |
|    value_loss           | 0.011    |
--------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3464      |
|    time_elapsed         | 11239     |
|    total_timesteps      | 7094272   |
| train/                  |           |
|    approx_kl            | 0.9843867 |
|    clip_fraction        | 0.508     |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.17      |
|    explained_variance   | 0.599     |
|    learning_rate        | 0.000617  |
|    loss                 | -0.0345   |
|    n_updates            | 34630     |
|    policy_gradient_loss | 0.0184    |
|    std                  | 0.082     |
|    value_loss           | 0.00507   |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3465       |
|    time_elapsed         | 11242      |
|    total_timesteps      | 7096320    |
| train/                  |            |
|    approx_kl            | 0.16598141 |
|    clip_fraction        | 0.425      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.15       |
|    explained_variance   | 0.444      |
|    learning_rate        | 0.000617   |
|    loss                 | -0.0344    |
|    n_updates            | 34640      |
|    policy_gradient_loss | 0.0181     |
|    std                  | 0.0836     |
|    value_loss           | 0.00205    |
----------------------------------------
box reached target
--------------------------------------
| time/                   |          |
|    fps                  | 631      |
|    iterations           | 3466     |
|    time_elapsed         | 11245    |
|    total_timesteps      | 7098368  |
| train/                  |          |
|    approx_kl            | 0.442528 |
|    clip_fraction        | 0.452    |
|    clip_range           | 0.2      |
|    entropy_loss         | 2.17     |
|    explained_variance   | 0.536    |
|    learning_rate        | 0.000616 |
|    loss                 | -0.00283 |
|    n_updates            | 34650    |
|    policy_gradient_loss | 0.0121   |
|    std                  | 0.081    |
|    value_loss           | 0.00315  |
--------------------------------------
box reached target
Eval num_timesteps=7100000, episode_reward=-0.88 +/- 0.23
Episode length: 300.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 300       |
|    mean_reward          | -0.884    |
| time/                   |           |
|    total_timesteps      | 7100000   |
| train/                  |           |
|    approx_kl            | 3.7472734 |
|    clip_fraction        | 0.592     |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.2       |
|    explained_variance   | 0.143     |
|    learning_rate        | 0.000616  |
|    loss                 | -0.0564   |
|    n_updates            | 34660     |
|    policy_gradient_loss | 0.00107   |
|    std                  | 0.0808    |
|    value_loss           | 0.0741    |
---------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 3467    |
|    time_elapsed    | 11249   |
|    total_timesteps | 7100416 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3468       |
|    time_elapsed         | 11252      |
|    total_timesteps      | 7102464    |
| train/                  |            |
|    approx_kl            | 0.46867532 |
|    clip_fraction        | 0.51       |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.19       |
|    explained_variance   | 0.55       |
|    learning_rate        | 0.000615   |
|    loss                 | -0.0341    |
|    n_updates            | 34670      |
|    policy_gradient_loss | 0.0189     |
|    std                  | 0.0812     |
|    value_loss           | 0.0503     |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3469       |
|    time_elapsed         | 11255      |
|    total_timesteps      | 7104512    |
| train/                  |            |
|    approx_kl            | 0.90437156 |
|    clip_fraction        | 0.514      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.18       |
|    explained_variance   | 0.422      |
|    learning_rate        | 0.000615   |
|    loss                 | -0.05      |
|    n_updates            | 34680      |
|    policy_gradient_loss | 0.0352     |
|    std                  | 0.0819     |
|    value_loss           | 0.0074     |
----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3470      |
|    time_elapsed         | 11258     |
|    total_timesteps      | 7106560   |
| train/                  |           |
|    approx_kl            | 0.4632861 |
|    clip_fraction        | 0.495     |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.17      |
|    explained_variance   | 0.827     |
|    learning_rate        | 0.000615  |
|    loss                 | -0.00868  |
|    n_updates            | 34690     |
|    policy_gradient_loss | 0.0229    |
|    std                  | 0.0817    |
|    value_loss           | 0.00747   |
---------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3471      |
|    time_elapsed         | 11261     |
|    total_timesteps      | 7108608   |
| train/                  |           |
|    approx_kl            | 0.5403482 |
|    clip_fraction        | 0.462     |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.18      |
|    explained_variance   | -0.0187   |
|    learning_rate        | 0.000614  |
|    loss                 | -0.0133   |
|    n_updates            | 34700     |
|    policy_gradient_loss | 0.0242    |
|    std                  | 0.0819    |
|    value_loss           | 0.00514   |
---------------------------------------
Eval num_timesteps=7110000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1         |
| time/                   |            |
|    total_timesteps      | 7110000    |
| train/                  |            |
|    approx_kl            | 0.71238434 |
|    clip_fraction        | 0.49       |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.16       |
|    explained_variance   | 0.205      |
|    learning_rate        | 0.000614   |
|    loss                 | 0.0156     |
|    n_updates            | 34710      |
|    policy_gradient_loss | 0.0171     |
|    std                  | 0.083      |
|    value_loss           | 0.0033     |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 3472    |
|    time_elapsed    | 11265   |
|    total_timesteps | 7110656 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3473       |
|    time_elapsed         | 11269      |
|    total_timesteps      | 7112704    |
| train/                  |            |
|    approx_kl            | 0.85829127 |
|    clip_fraction        | 0.485      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.14       |
|    explained_variance   | -0.0946    |
|    learning_rate        | 0.000613   |
|    loss                 | 0.0682     |
|    n_updates            | 34720      |
|    policy_gradient_loss | 0.0291     |
|    std                  | 0.0832     |
|    value_loss           | 0.00399    |
----------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3474      |
|    time_elapsed         | 11272     |
|    total_timesteps      | 7114752   |
| train/                  |           |
|    approx_kl            | 0.2930601 |
|    clip_fraction        | 0.465     |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.12      |
|    explained_variance   | 0.572     |
|    learning_rate        | 0.000613  |
|    loss                 | 0.0672    |
|    n_updates            | 34730     |
|    policy_gradient_loss | 0.0154    |
|    std                  | 0.0842    |
|    value_loss           | 0.00499   |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3475       |
|    time_elapsed         | 11275      |
|    total_timesteps      | 7116800    |
| train/                  |            |
|    approx_kl            | 0.72640646 |
|    clip_fraction        | 0.517      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.11       |
|    explained_variance   | 0.378      |
|    learning_rate        | 0.000613   |
|    loss                 | 0.00665    |
|    n_updates            | 34740      |
|    policy_gradient_loss | 0.00788    |
|    std                  | 0.0849     |
|    value_loss           | 0.0831     |
----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3476      |
|    time_elapsed         | 11278     |
|    total_timesteps      | 7118848   |
| train/                  |           |
|    approx_kl            | 0.3351    |
|    clip_fraction        | 0.456     |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.08      |
|    explained_variance   | 0.433     |
|    learning_rate        | 0.000612  |
|    loss                 | -0.000456 |
|    n_updates            | 34750     |
|    policy_gradient_loss | 0.00201   |
|    std                  | 0.0867    |
|    value_loss           | 0.00368   |
---------------------------------------
box reached target
Eval num_timesteps=7120000, episode_reward=0.24 +/- 2.48
Episode length: 274.00 +/- 52.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 274        |
|    mean_reward          | 0.244      |
| time/                   |            |
|    total_timesteps      | 7120000    |
| train/                  |            |
|    approx_kl            | 0.27932745 |
|    clip_fraction        | 0.47       |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.06       |
|    explained_variance   | 0.631      |
|    learning_rate        | 0.000612   |
|    loss                 | 0.029      |
|    n_updates            | 34760      |
|    policy_gradient_loss | 0.0207     |
|    std                  | 0.087      |
|    value_loss           | 0.00688    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 3477    |
|    time_elapsed    | 11282   |
|    total_timesteps | 7120896 |
--------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3478       |
|    time_elapsed         | 11285      |
|    total_timesteps      | 7122944    |
| train/                  |            |
|    approx_kl            | 0.89631397 |
|    clip_fraction        | 0.54       |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.05       |
|    explained_variance   | 0.607      |
|    learning_rate        | 0.000611   |
|    loss                 | -0.0354    |
|    n_updates            | 34770      |
|    policy_gradient_loss | 0.0208     |
|    std                  | 0.0868     |
|    value_loss           | 0.00373    |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3479       |
|    time_elapsed         | 11288      |
|    total_timesteps      | 7124992    |
| train/                  |            |
|    approx_kl            | 0.32615876 |
|    clip_fraction        | 0.465      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.04       |
|    explained_variance   | 0.801      |
|    learning_rate        | 0.000611   |
|    loss                 | 0.00792    |
|    n_updates            | 34780      |
|    policy_gradient_loss | 0.0243     |
|    std                  | 0.0883     |
|    value_loss           | 0.0161     |
----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3480      |
|    time_elapsed         | 11291     |
|    total_timesteps      | 7127040   |
| train/                  |           |
|    approx_kl            | 0.4613466 |
|    clip_fraction        | 0.478     |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.03      |
|    explained_variance   | 0.857     |
|    learning_rate        | 0.000611  |
|    loss                 | 0.0185    |
|    n_updates            | 34790     |
|    policy_gradient_loss | 0.0252    |
|    std                  | 0.0879    |
|    value_loss           | 0.016     |
---------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3481      |
|    time_elapsed         | 11294     |
|    total_timesteps      | 7129088   |
| train/                  |           |
|    approx_kl            | 0.6955535 |
|    clip_fraction        | 0.527     |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.02      |
|    explained_variance   | 0.761     |
|    learning_rate        | 0.00061   |
|    loss                 | -0.0328   |
|    n_updates            | 34800     |
|    policy_gradient_loss | 0.0192    |
|    std                  | 0.0881    |
|    value_loss           | 0.00572   |
---------------------------------------
Eval num_timesteps=7130000, episode_reward=-0.55 +/- 0.61
Episode length: 300.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 300       |
|    mean_reward          | -0.55     |
| time/                   |           |
|    total_timesteps      | 7130000   |
| train/                  |           |
|    approx_kl            | 0.3124023 |
|    clip_fraction        | 0.46      |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.01      |
|    explained_variance   | 0.846     |
|    learning_rate        | 0.00061   |
|    loss                 | -0.017    |
|    n_updates            | 34810     |
|    policy_gradient_loss | 0.00749   |
|    std                  | 0.0886    |
|    value_loss           | 0.00341   |
---------------------------------------
box reached target
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 3482    |
|    time_elapsed    | 11298   |
|    total_timesteps | 7131136 |
--------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3483      |
|    time_elapsed         | 11301     |
|    total_timesteps      | 7133184   |
| train/                  |           |
|    approx_kl            | 0.6571709 |
|    clip_fraction        | 0.532     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.98      |
|    explained_variance   | 0.84      |
|    learning_rate        | 0.000609  |
|    loss                 | -0.0195   |
|    n_updates            | 34820     |
|    policy_gradient_loss | 0.0393    |
|    std                  | 0.0919    |
|    value_loss           | 0.00836   |
---------------------------------------
box reached target
box reached target
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3484      |
|    time_elapsed         | 11304     |
|    total_timesteps      | 7135232   |
| train/                  |           |
|    approx_kl            | 0.7499422 |
|    clip_fraction        | 0.511     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.95      |
|    explained_variance   | 0.621     |
|    learning_rate        | 0.000609  |
|    loss                 | -0.0487   |
|    n_updates            | 34830     |
|    policy_gradient_loss | 0.00797   |
|    std                  | 0.0917    |
|    value_loss           | 0.00667   |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3485       |
|    time_elapsed         | 11307      |
|    total_timesteps      | 7137280    |
| train/                  |            |
|    approx_kl            | 0.23481889 |
|    clip_fraction        | 0.477      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.94       |
|    explained_variance   | 0.895      |
|    learning_rate        | 0.000609   |
|    loss                 | -0.0285    |
|    n_updates            | 34840      |
|    policy_gradient_loss | 0.0207     |
|    std                  | 0.0921     |
|    value_loss           | 0.024      |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3486       |
|    time_elapsed         | 11310      |
|    total_timesteps      | 7139328    |
| train/                  |            |
|    approx_kl            | 0.22806269 |
|    clip_fraction        | 0.444      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.93       |
|    explained_variance   | 0.407      |
|    learning_rate        | 0.000608   |
|    loss                 | 0.0553     |
|    n_updates            | 34850      |
|    policy_gradient_loss | 0.00936    |
|    std                  | 0.0937     |
|    value_loss           | 0.0067     |
----------------------------------------
Eval num_timesteps=7140000, episode_reward=-0.75 +/- 0.32
Episode length: 300.00 +/- 0.00
--------------------------------------
| eval/                   |          |
|    mean_ep_length       | 300      |
|    mean_reward          | -0.749   |
| time/                   |          |
|    total_timesteps      | 7140000  |
| train/                  |          |
|    approx_kl            | 4.335367 |
|    clip_fraction        | 0.556    |
|    clip_range           | 0.2      |
|    entropy_loss         | 1.92     |
|    explained_variance   | 0.463    |
|    learning_rate        | 0.000608 |
|    loss                 | 0.0303   |
|    n_updates            | 34860    |
|    policy_gradient_loss | 0.0184   |
|    std                  | 0.0926   |
|    value_loss           | 0.00164  |
--------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 3487    |
|    time_elapsed    | 11314   |
|    total_timesteps | 7141376 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3488       |
|    time_elapsed         | 11317      |
|    total_timesteps      | 7143424    |
| train/                  |            |
|    approx_kl            | 0.32334578 |
|    clip_fraction        | 0.415      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.94       |
|    explained_variance   | 0.34       |
|    learning_rate        | 0.000607   |
|    loss                 | -0.0313    |
|    n_updates            | 34870      |
|    policy_gradient_loss | 0.0077     |
|    std                  | 0.0909     |
|    value_loss           | 0.00242    |
----------------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3489       |
|    time_elapsed         | 11320      |
|    total_timesteps      | 7145472    |
| train/                  |            |
|    approx_kl            | 0.39616525 |
|    clip_fraction        | 0.423      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.95       |
|    explained_variance   | 0.379      |
|    learning_rate        | 0.000607   |
|    loss                 | -0.0218    |
|    n_updates            | 34880      |
|    policy_gradient_loss | 0.00879    |
|    std                  | 0.0922     |
|    value_loss           | 0.00272    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3490       |
|    time_elapsed         | 11323      |
|    total_timesteps      | 7147520    |
| train/                  |            |
|    approx_kl            | 0.43407685 |
|    clip_fraction        | 0.485      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.95       |
|    explained_variance   | 0.652      |
|    learning_rate        | 0.000607   |
|    loss                 | 0.0591     |
|    n_updates            | 34890      |
|    policy_gradient_loss | 0.0321     |
|    std                  | 0.0913     |
|    value_loss           | 0.0623     |
----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3491      |
|    time_elapsed         | 11326     |
|    total_timesteps      | 7149568   |
| train/                  |           |
|    approx_kl            | 3.3457775 |
|    clip_fraction        | 0.529     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.96      |
|    explained_variance   | 0.432     |
|    learning_rate        | 0.000606  |
|    loss                 | 0.0717    |
|    n_updates            | 34900     |
|    policy_gradient_loss | 0.238     |
|    std                  | 0.0911    |
|    value_loss           | 0.00264   |
---------------------------------------
Eval num_timesteps=7150000, episode_reward=-0.95 +/- 0.11
Episode length: 300.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 300       |
|    mean_reward          | -0.946    |
| time/                   |           |
|    total_timesteps      | 7150000   |
| train/                  |           |
|    approx_kl            | 0.6982672 |
|    clip_fraction        | 0.497     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.94      |
|    explained_variance   | -0.778    |
|    learning_rate        | 0.000606  |
|    loss                 | 0.00457   |
|    n_updates            | 34910     |
|    policy_gradient_loss | 0.081     |
|    std                  | 0.093     |
|    value_loss           | 0.00521   |
---------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 3492    |
|    time_elapsed    | 11330   |
|    total_timesteps | 7151616 |
--------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3493      |
|    time_elapsed         | 11333     |
|    total_timesteps      | 7153664   |
| train/                  |           |
|    approx_kl            | 1.2984405 |
|    clip_fraction        | 0.481     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.92      |
|    explained_variance   | 0.827     |
|    learning_rate        | 0.000605  |
|    loss                 | -0.0292   |
|    n_updates            | 34920     |
|    policy_gradient_loss | -0.00839  |
|    std                  | 0.0921    |
|    value_loss           | 0.0107    |
---------------------------------------
box reached target
--------------------------------------
| time/                   |          |
|    fps                  | 631      |
|    iterations           | 3494     |
|    time_elapsed         | 11336    |
|    total_timesteps      | 7155712  |
| train/                  |          |
|    approx_kl            | 0.171132 |
|    clip_fraction        | 0.453    |
|    clip_range           | 0.2      |
|    entropy_loss         | 1.94     |
|    explained_variance   | 0.809    |
|    learning_rate        | 0.000605 |
|    loss                 | -0.0172  |
|    n_updates            | 34930    |
|    policy_gradient_loss | 0.0119   |
|    std                  | 0.0927   |
|    value_loss           | 0.00594  |
--------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3495       |
|    time_elapsed         | 11339      |
|    total_timesteps      | 7157760    |
| train/                  |            |
|    approx_kl            | 0.31582734 |
|    clip_fraction        | 0.492      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.93       |
|    explained_variance   | 0.631      |
|    learning_rate        | 0.000605   |
|    loss                 | 0.0406     |
|    n_updates            | 34940      |
|    policy_gradient_loss | 0.0177     |
|    std                  | 0.093      |
|    value_loss           | 0.105      |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3496       |
|    time_elapsed         | 11342      |
|    total_timesteps      | 7159808    |
| train/                  |            |
|    approx_kl            | 0.16658947 |
|    clip_fraction        | 0.437      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.91       |
|    explained_variance   | 0.275      |
|    learning_rate        | 0.000604   |
|    loss                 | 0.000885   |
|    n_updates            | 34950      |
|    policy_gradient_loss | 0.0265     |
|    std                  | 0.0945     |
|    value_loss           | 0.00384    |
----------------------------------------
box reached target
Eval num_timesteps=7160000, episode_reward=0.25 +/- 2.31
Episode length: 287.20 +/- 25.60
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 287        |
|    mean_reward          | 0.247      |
| time/                   |            |
|    total_timesteps      | 7160000    |
| train/                  |            |
|    approx_kl            | 0.58093953 |
|    clip_fraction        | 0.439      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.92       |
|    explained_variance   | 0.101      |
|    learning_rate        | 0.000604   |
|    loss                 | -0.0337    |
|    n_updates            | 34960      |
|    policy_gradient_loss | -0.00481   |
|    std                  | 0.0919     |
|    value_loss           | 0.00208    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 3497    |
|    time_elapsed    | 11346   |
|    total_timesteps | 7161856 |
--------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3498      |
|    time_elapsed         | 11349     |
|    total_timesteps      | 7163904   |
| train/                  |           |
|    approx_kl            | 1.0742252 |
|    clip_fraction        | 0.503     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.96      |
|    explained_variance   | 0.64      |
|    learning_rate        | 0.000603  |
|    loss                 | -0.00591  |
|    n_updates            | 34970     |
|    policy_gradient_loss | 0.0081    |
|    std                  | 0.0909    |
|    value_loss           | 0.00183   |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3499       |
|    time_elapsed         | 11352      |
|    total_timesteps      | 7165952    |
| train/                  |            |
|    approx_kl            | 0.29904914 |
|    clip_fraction        | 0.536      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.96       |
|    explained_variance   | 0.781      |
|    learning_rate        | 0.000603   |
|    loss                 | 0.0442     |
|    n_updates            | 34980      |
|    policy_gradient_loss | 0.00871    |
|    std                  | 0.092      |
|    value_loss           | 0.00334    |
----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3500      |
|    time_elapsed         | 11355     |
|    total_timesteps      | 7168000   |
| train/                  |           |
|    approx_kl            | 0.3958055 |
|    clip_fraction        | 0.427     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.94      |
|    explained_variance   | 0.0782    |
|    learning_rate        | 0.000603  |
|    loss                 | -0.0509   |
|    n_updates            | 34990     |
|    policy_gradient_loss | 0.0158    |
|    std                  | 0.0917    |
|    value_loss           | 0.00406   |
---------------------------------------
Eval num_timesteps=7170000, episode_reward=-0.73 +/- 0.41
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -0.734     |
| time/                   |            |
|    total_timesteps      | 7170000    |
| train/                  |            |
|    approx_kl            | 0.41579753 |
|    clip_fraction        | 0.501      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.92       |
|    explained_variance   | 0.562      |
|    learning_rate        | 0.000602   |
|    loss                 | 0.0172     |
|    n_updates            | 35000      |
|    policy_gradient_loss | 0.0268     |
|    std                  | 0.0938     |
|    value_loss           | 0.0014     |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 3501    |
|    time_elapsed    | 11359   |
|    total_timesteps | 7170048 |
--------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3502      |
|    time_elapsed         | 11362     |
|    total_timesteps      | 7172096   |
| train/                  |           |
|    approx_kl            | 0.2280405 |
|    clip_fraction        | 0.487     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.88      |
|    explained_variance   | 0.793     |
|    learning_rate        | 0.000602  |
|    loss                 | -0.0479   |
|    n_updates            | 35010     |
|    policy_gradient_loss | 0.0114    |
|    std                  | 0.0954    |
|    value_loss           | 0.00306   |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3503       |
|    time_elapsed         | 11366      |
|    total_timesteps      | 7174144    |
| train/                  |            |
|    approx_kl            | 0.24226455 |
|    clip_fraction        | 0.456      |
|    clip_range           | 0.2        |
|    entropy_loss         | 1.87       |
|    explained_variance   | 0.685      |
|    learning_rate        | 0.000601   |
|    loss                 | 0.0273     |
|    n_updates            | 35020      |
|    policy_gradient_loss | 0.0211     |
|    std                  | 0.0956     |
|    value_loss           | 0.00925    |
----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3504      |
|    time_elapsed         | 11369     |
|    total_timesteps      | 7176192   |
| train/                  |           |
|    approx_kl            | 1.2611405 |
|    clip_fraction        | 0.484     |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.9       |
|    explained_variance   | 0.822     |
|    learning_rate        | 0.000601  |
|    loss                 | -0.0141   |
|    n_updates            | 35030     |
|    policy_gradient_loss | -0.0181   |
|    std                  | 0.0923    |
|    value_loss           | 0.00586   |
---------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3505      |
|    time_elapsed         | 11372     |
|    total_timesteps      | 7178240   |
| train/                  |           |
|    approx_kl            | 0.3684176 |
|    clip_fraction        | 0.43      |
|    clip_range           | 0.2       |
|    entropy_loss         | 1.94      |
|    explained_variance   | 0.651     |
|    learning_rate        | 0.000601  |
|    loss                 | -0.0135   |
|    n_updates            | 35040     |
|    policy_gradient_loss | -0.00231  |
|    std                  | 0.0912    |
|    value_loss           | 0.00335   |
---------------------------------------
Eval num_timesteps=7180000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1         |
| time/                   |            |
|    total_timesteps      | 7180000    |
| train/                  |            |
|    approx_kl            | 0.24278486 |
|    clip_fraction        | 0.458      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.01       |
|    explained_variance   | 0.888      |
|    learning_rate        | 0.0006     |
|    loss                 | -0.0173    |
|    n_updates            | 35050      |
|    policy_gradient_loss | 0.0116     |
|    std                  | 0.0881     |
|    value_loss           | 0.00463    |
----------------------------------------
box reached target
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 3506    |
|    time_elapsed    | 11376   |
|    total_timesteps | 7180288 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3507       |
|    time_elapsed         | 11379      |
|    total_timesteps      | 7182336    |
| train/                  |            |
|    approx_kl            | 0.40222508 |
|    clip_fraction        | 0.478      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.05       |
|    explained_variance   | 0.814      |
|    learning_rate        | 0.0006     |
|    loss                 | 0.0714     |
|    n_updates            | 35060      |
|    policy_gradient_loss | 0.0123     |
|    std                  | 0.087      |
|    value_loss           | 0.0115     |
----------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3508      |
|    time_elapsed         | 11382     |
|    total_timesteps      | 7184384   |
| train/                  |           |
|    approx_kl            | 1.2919738 |
|    clip_fraction        | 0.5       |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.06      |
|    explained_variance   | 0.43      |
|    learning_rate        | 0.000599  |
|    loss                 | -0.0276   |
|    n_updates            | 35070     |
|    policy_gradient_loss | 0.00613   |
|    std                  | 0.0861    |
|    value_loss           | 0.00222   |
---------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3509      |
|    time_elapsed         | 11385     |
|    total_timesteps      | 7186432   |
| train/                  |           |
|    approx_kl            | 0.5902584 |
|    clip_fraction        | 0.527     |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.1       |
|    explained_variance   | -0.0115   |
|    learning_rate        | 0.000599  |
|    loss                 | 0.0743    |
|    n_updates            | 35080     |
|    policy_gradient_loss | 0.0186    |
|    std                  | 0.0845    |
|    value_loss           | 0.0312    |
---------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3510      |
|    time_elapsed         | 11388     |
|    total_timesteps      | 7188480   |
| train/                  |           |
|    approx_kl            | 0.7965982 |
|    clip_fraction        | 0.468     |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.12      |
|    explained_variance   | 0.0934    |
|    learning_rate        | 0.000599  |
|    loss                 | 0.0224    |
|    n_updates            | 35090     |
|    policy_gradient_loss | 0.00294   |
|    std                  | 0.0834    |
|    value_loss           | 0.00312   |
---------------------------------------
Eval num_timesteps=7190000, episode_reward=-0.66 +/- 0.68
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -0.658     |
| time/                   |            |
|    total_timesteps      | 7190000    |
| train/                  |            |
|    approx_kl            | 0.38780037 |
|    clip_fraction        | 0.457      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.14       |
|    explained_variance   | 0.576      |
|    learning_rate        | 0.000598   |
|    loss                 | -0.0381    |
|    n_updates            | 35100      |
|    policy_gradient_loss | 0.0102     |
|    std                  | 0.0827     |
|    value_loss           | 0.0055     |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 3511    |
|    time_elapsed    | 11392   |
|    total_timesteps | 7190528 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3512       |
|    time_elapsed         | 11395      |
|    total_timesteps      | 7192576    |
| train/                  |            |
|    approx_kl            | 0.30434322 |
|    clip_fraction        | 0.475      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.16       |
|    explained_variance   | 0.702      |
|    learning_rate        | 0.000598   |
|    loss                 | -0.0074    |
|    n_updates            | 35110      |
|    policy_gradient_loss | 0.0109     |
|    std                  | 0.0821     |
|    value_loss           | 0.0136     |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3513       |
|    time_elapsed         | 11398      |
|    total_timesteps      | 7194624    |
| train/                  |            |
|    approx_kl            | 0.81164277 |
|    clip_fraction        | 0.519      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.16       |
|    explained_variance   | 0.609      |
|    learning_rate        | 0.000597   |
|    loss                 | -0.017     |
|    n_updates            | 35120      |
|    policy_gradient_loss | 0.0218     |
|    std                  | 0.082      |
|    value_loss           | 0.0196     |
----------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3514      |
|    time_elapsed         | 11401     |
|    total_timesteps      | 7196672   |
| train/                  |           |
|    approx_kl            | 4.2579613 |
|    clip_fraction        | 0.521     |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.2       |
|    explained_variance   | 0.84      |
|    learning_rate        | 0.000597  |
|    loss                 | 0.0031    |
|    n_updates            | 35130     |
|    policy_gradient_loss | -0.0213   |
|    std                  | 0.0789    |
|    value_loss           | 0.00518   |
---------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3515      |
|    time_elapsed         | 11404     |
|    total_timesteps      | 7198720   |
| train/                  |           |
|    approx_kl            | 0.9407451 |
|    clip_fraction        | 0.551     |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.2       |
|    explained_variance   | 0.646     |
|    learning_rate        | 0.000597  |
|    loss                 | 0.121     |
|    n_updates            | 35140     |
|    policy_gradient_loss | 0.0913    |
|    std                  | 0.082     |
|    value_loss           | 0.0209    |
---------------------------------------
Eval num_timesteps=7200000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 300       |
|    mean_reward          | -1        |
| time/                   |           |
|    total_timesteps      | 7200000   |
| train/                  |           |
|    approx_kl            | 1.0148822 |
|    clip_fraction        | 0.511     |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.15      |
|    explained_variance   | 0.847     |
|    learning_rate        | 0.000596  |
|    loss                 | -0.0035   |
|    n_updates            | 35150     |
|    policy_gradient_loss | 0.00803   |
|    std                  | 0.0835    |
|    value_loss           | 0.0125    |
---------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 3516    |
|    time_elapsed    | 11408   |
|    total_timesteps | 7200768 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3517       |
|    time_elapsed         | 11411      |
|    total_timesteps      | 7202816    |
| train/                  |            |
|    approx_kl            | 0.67208683 |
|    clip_fraction        | 0.45       |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.15       |
|    explained_variance   | 0.276      |
|    learning_rate        | 0.000596   |
|    loss                 | 0.0046     |
|    n_updates            | 35160      |
|    policy_gradient_loss | 0.0159     |
|    std                  | 0.0822     |
|    value_loss           | 0.00367    |
----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3518      |
|    time_elapsed         | 11414     |
|    total_timesteps      | 7204864   |
| train/                  |           |
|    approx_kl            | 0.7782314 |
|    clip_fraction        | 0.402     |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.18      |
|    explained_variance   | 0.382     |
|    learning_rate        | 0.000595  |
|    loss                 | -0.0317   |
|    n_updates            | 35170     |
|    policy_gradient_loss | 0.00397   |
|    std                  | 0.0806    |
|    value_loss           | 0.00224   |
---------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3519      |
|    time_elapsed         | 11417     |
|    total_timesteps      | 7206912   |
| train/                  |           |
|    approx_kl            | 1.1187336 |
|    clip_fraction        | 0.533     |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.21      |
|    explained_variance   | -0.315    |
|    learning_rate        | 0.000595  |
|    loss                 | 0.0928    |
|    n_updates            | 35180     |
|    policy_gradient_loss | 0.0317    |
|    std                  | 0.08      |
|    value_loss           | 0.00136   |
---------------------------------------
--------------------------------------
| time/                   |          |
|    fps                  | 631      |
|    iterations           | 3520     |
|    time_elapsed         | 11421    |
|    total_timesteps      | 7208960  |
| train/                  |          |
|    approx_kl            | 0.836271 |
|    clip_fraction        | 0.47     |
|    clip_range           | 0.2      |
|    entropy_loss         | 2.21     |
|    explained_variance   | 0.202    |
|    learning_rate        | 0.000595 |
|    loss                 | 0.123    |
|    n_updates            | 35190    |
|    policy_gradient_loss | 0.0195   |
|    std                  | 0.0807   |
|    value_loss           | 0.00431  |
--------------------------------------
Eval num_timesteps=7210000, episode_reward=-0.70 +/- 0.61
Episode length: 300.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 300       |
|    mean_reward          | -0.696    |
| time/                   |           |
|    total_timesteps      | 7210000   |
| train/                  |           |
|    approx_kl            | 0.5662812 |
|    clip_fraction        | 0.532     |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.21      |
|    explained_variance   | 0.43      |
|    learning_rate        | 0.000594  |
|    loss                 | -0.0219   |
|    n_updates            | 35200     |
|    policy_gradient_loss | -0.00233  |
|    std                  | 0.0799    |
|    value_loss           | 0.00864   |
---------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 3521    |
|    time_elapsed    | 11425   |
|    total_timesteps | 7211008 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3522       |
|    time_elapsed         | 11428      |
|    total_timesteps      | 7213056    |
| train/                  |            |
|    approx_kl            | 0.35592842 |
|    clip_fraction        | 0.546      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.21       |
|    explained_variance   | 0.701      |
|    learning_rate        | 0.000594   |
|    loss                 | 0.0594     |
|    n_updates            | 35210      |
|    policy_gradient_loss | 0.0401     |
|    std                  | 0.0811     |
|    value_loss           | 0.00444    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3523       |
|    time_elapsed         | 11431      |
|    total_timesteps      | 7215104    |
| train/                  |            |
|    approx_kl            | 0.41183275 |
|    clip_fraction        | 0.49       |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.21       |
|    explained_variance   | 0.645      |
|    learning_rate        | 0.000593   |
|    loss                 | -0.00961   |
|    n_updates            | 35220      |
|    policy_gradient_loss | 0.0231     |
|    std                  | 0.0797     |
|    value_loss           | 0.0038     |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3524       |
|    time_elapsed         | 11434      |
|    total_timesteps      | 7217152    |
| train/                  |            |
|    approx_kl            | 0.49098742 |
|    clip_fraction        | 0.474      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.2        |
|    explained_variance   | 0.535      |
|    learning_rate        | 0.000593   |
|    loss                 | -0.0253    |
|    n_updates            | 35230      |
|    policy_gradient_loss | 0.0196     |
|    std                  | 0.0815     |
|    value_loss           | 0.0031     |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3525       |
|    time_elapsed         | 11437      |
|    total_timesteps      | 7219200    |
| train/                  |            |
|    approx_kl            | 0.19261731 |
|    clip_fraction        | 0.474      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.17       |
|    explained_variance   | 0.418      |
|    learning_rate        | 0.000593   |
|    loss                 | 0.0821     |
|    n_updates            | 35240      |
|    policy_gradient_loss | 0.0179     |
|    std                  | 0.0822     |
|    value_loss           | 0.00144    |
----------------------------------------
Eval num_timesteps=7220000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 300       |
|    mean_reward          | -1        |
| time/                   |           |
|    total_timesteps      | 7220000   |
| train/                  |           |
|    approx_kl            | 0.4631489 |
|    clip_fraction        | 0.481     |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.19      |
|    explained_variance   | 0.461     |
|    learning_rate        | 0.000592  |
|    loss                 | -0.0471   |
|    n_updates            | 35250     |
|    policy_gradient_loss | 0.0111    |
|    std                  | 0.0803    |
|    value_loss           | 0.00202   |
---------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 3526    |
|    time_elapsed    | 11441   |
|    total_timesteps | 7221248 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3527       |
|    time_elapsed         | 11444      |
|    total_timesteps      | 7223296    |
| train/                  |            |
|    approx_kl            | 0.53388995 |
|    clip_fraction        | 0.486      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.2        |
|    explained_variance   | 0.218      |
|    learning_rate        | 0.000592   |
|    loss                 | 0.0042     |
|    n_updates            | 35260      |
|    policy_gradient_loss | 0.0259     |
|    std                  | 0.0812     |
|    value_loss           | 0.0018     |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3528       |
|    time_elapsed         | 11447      |
|    total_timesteps      | 7225344    |
| train/                  |            |
|    approx_kl            | 0.23748326 |
|    clip_fraction        | 0.461      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.18       |
|    explained_variance   | 0.395      |
|    learning_rate        | 0.000591   |
|    loss                 | 0.0129     |
|    n_updates            | 35270      |
|    policy_gradient_loss | 0.0297     |
|    std                  | 0.0821     |
|    value_loss           | 0.00156    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3529       |
|    time_elapsed         | 11450      |
|    total_timesteps      | 7227392    |
| train/                  |            |
|    approx_kl            | 0.30451626 |
|    clip_fraction        | 0.432      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.18       |
|    explained_variance   | 0.329      |
|    learning_rate        | 0.000591   |
|    loss                 | 0.000169   |
|    n_updates            | 35280      |
|    policy_gradient_loss | 0.00925    |
|    std                  | 0.0817     |
|    value_loss           | 0.00282    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3530       |
|    time_elapsed         | 11453      |
|    total_timesteps      | 7229440    |
| train/                  |            |
|    approx_kl            | 0.49069178 |
|    clip_fraction        | 0.485      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.2        |
|    explained_variance   | 0.241      |
|    learning_rate        | 0.000591   |
|    loss                 | -0.0426    |
|    n_updates            | 35290      |
|    policy_gradient_loss | 0.0177     |
|    std                  | 0.0801     |
|    value_loss           | 0.0019     |
----------------------------------------
Eval num_timesteps=7230000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1         |
| time/                   |            |
|    total_timesteps      | 7230000    |
| train/                  |            |
|    approx_kl            | 0.39065233 |
|    clip_fraction        | 0.467      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.25       |
|    explained_variance   | 0.345      |
|    learning_rate        | 0.00059    |
|    loss                 | -0.0224    |
|    n_updates            | 35300      |
|    policy_gradient_loss | 0.0046     |
|    std                  | 0.0781     |
|    value_loss           | 0.00135    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 3531    |
|    time_elapsed    | 11457   |
|    total_timesteps | 7231488 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3532       |
|    time_elapsed         | 11460      |
|    total_timesteps      | 7233536    |
| train/                  |            |
|    approx_kl            | 0.51579964 |
|    clip_fraction        | 0.459      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.27       |
|    explained_variance   | 0.227      |
|    learning_rate        | 0.00059    |
|    loss                 | 0.0963     |
|    n_updates            | 35310      |
|    policy_gradient_loss | 0.00703    |
|    std                  | 0.0779     |
|    value_loss           | 0.00179    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3533       |
|    time_elapsed         | 11463      |
|    total_timesteps      | 7235584    |
| train/                  |            |
|    approx_kl            | 0.80421996 |
|    clip_fraction        | 0.477      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.29       |
|    explained_variance   | 0.254      |
|    learning_rate        | 0.000589   |
|    loss                 | 0.0707     |
|    n_updates            | 35320      |
|    policy_gradient_loss | 0.0107     |
|    std                  | 0.0774     |
|    value_loss           | 0.0016     |
----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3534      |
|    time_elapsed         | 11466     |
|    total_timesteps      | 7237632   |
| train/                  |           |
|    approx_kl            | 0.6760807 |
|    clip_fraction        | 0.501     |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.31      |
|    explained_variance   | 0.25      |
|    learning_rate        | 0.000589  |
|    loss                 | 0.0565    |
|    n_updates            | 35330     |
|    policy_gradient_loss | 0.0231    |
|    std                  | 0.0759    |
|    value_loss           | 0.00179   |
---------------------------------------
box reached target
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3535       |
|    time_elapsed         | 11469      |
|    total_timesteps      | 7239680    |
| train/                  |            |
|    approx_kl            | 0.73469746 |
|    clip_fraction        | 0.527      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.33       |
|    explained_variance   | 0.263      |
|    learning_rate        | 0.000589   |
|    loss                 | 0.0737     |
|    n_updates            | 35340      |
|    policy_gradient_loss | 0.0334     |
|    std                  | 0.0762     |
|    value_loss           | 0.00161    |
----------------------------------------
Eval num_timesteps=7240000, episode_reward=-0.83 +/- 0.34
Episode length: 300.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 300       |
|    mean_reward          | -0.83     |
| time/                   |           |
|    total_timesteps      | 7240000   |
| train/                  |           |
|    approx_kl            | 0.7719805 |
|    clip_fraction        | 0.576     |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.32      |
|    explained_variance   | 0.855     |
|    learning_rate        | 0.000588  |
|    loss                 | 0.0486    |
|    n_updates            | 35350     |
|    policy_gradient_loss | 0.0356    |
|    std                  | 0.0764    |
|    value_loss           | 0.0246    |
---------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 3536    |
|    time_elapsed    | 11473   |
|    total_timesteps | 7241728 |
--------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3537      |
|    time_elapsed         | 11476     |
|    total_timesteps      | 7243776   |
| train/                  |           |
|    approx_kl            | 0.4108198 |
|    clip_fraction        | 0.48      |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.33      |
|    explained_variance   | 0.706     |
|    learning_rate        | 0.000588  |
|    loss                 | 0.0523    |
|    n_updates            | 35360     |
|    policy_gradient_loss | 0.0119    |
|    std                  | 0.0757    |
|    value_loss           | 0.00431   |
---------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3538      |
|    time_elapsed         | 11479     |
|    total_timesteps      | 7245824   |
| train/                  |           |
|    approx_kl            | 3.2137413 |
|    clip_fraction        | 0.546     |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.34      |
|    explained_variance   | 0.341     |
|    learning_rate        | 0.000587  |
|    loss                 | 0.00445   |
|    n_updates            | 35370     |
|    policy_gradient_loss | 0.0208    |
|    std                  | 0.0762    |
|    value_loss           | 0.00145   |
---------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3539      |
|    time_elapsed         | 11483     |
|    total_timesteps      | 7247872   |
| train/                  |           |
|    approx_kl            | 2.1162229 |
|    clip_fraction        | 0.55      |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.33      |
|    explained_variance   | 0.972     |
|    learning_rate        | 0.000587  |
|    loss                 | 0.0513    |
|    n_updates            | 35380     |
|    policy_gradient_loss | 0.0183    |
|    std                  | 0.0765    |
|    value_loss           | 0.0065    |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3540       |
|    time_elapsed         | 11486      |
|    total_timesteps      | 7249920    |
| train/                  |            |
|    approx_kl            | 0.43301374 |
|    clip_fraction        | 0.504      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.33       |
|    explained_variance   | 0.0311     |
|    learning_rate        | 0.000587   |
|    loss                 | 0.0741     |
|    n_updates            | 35390      |
|    policy_gradient_loss | 0.0111     |
|    std                  | 0.0767     |
|    value_loss           | 0.00175    |
----------------------------------------
Eval num_timesteps=7250000, episode_reward=-0.95 +/- 0.10
Episode length: 300.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 300       |
|    mean_reward          | -0.95     |
| time/                   |           |
|    total_timesteps      | 7250000   |
| train/                  |           |
|    approx_kl            | 1.2106643 |
|    clip_fraction        | 0.586     |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.3       |
|    explained_variance   | 0.262     |
|    learning_rate        | 0.000586  |
|    loss                 | 0.0788    |
|    n_updates            | 35400     |
|    policy_gradient_loss | 0.0526    |
|    std                  | 0.0772    |
|    value_loss           | 0.00233   |
---------------------------------------
box reached target
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 3541    |
|    time_elapsed    | 11490   |
|    total_timesteps | 7251968 |
--------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3542      |
|    time_elapsed         | 11493     |
|    total_timesteps      | 7254016   |
| train/                  |           |
|    approx_kl            | 13.703891 |
|    clip_fraction        | 0.661     |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.32      |
|    explained_variance   | 0.954     |
|    learning_rate        | 0.000586  |
|    loss                 | 0.0221    |
|    n_updates            | 35410     |
|    policy_gradient_loss | 0.0128    |
|    std                  | 0.0759    |
|    value_loss           | 0.00341   |
---------------------------------------
--------------------------------------
| time/                   |          |
|    fps                  | 631      |
|    iterations           | 3543     |
|    time_elapsed         | 11496    |
|    total_timesteps      | 7256064  |
| train/                  |          |
|    approx_kl            | 0.619622 |
|    clip_fraction        | 0.537    |
|    clip_range           | 0.2      |
|    entropy_loss         | 2.33     |
|    explained_variance   | 0.883    |
|    learning_rate        | 0.000585 |
|    loss                 | -0.03    |
|    n_updates            | 35420    |
|    policy_gradient_loss | 0.0117   |
|    std                  | 0.0773   |
|    value_loss           | 0.0118   |
--------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3544      |
|    time_elapsed         | 11499     |
|    total_timesteps      | 7258112   |
| train/                  |           |
|    approx_kl            | 0.5908181 |
|    clip_fraction        | 0.491     |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.32      |
|    explained_variance   | 0.535     |
|    learning_rate        | 0.000585  |
|    loss                 | -0.00103  |
|    n_updates            | 35430     |
|    policy_gradient_loss | 0.00315   |
|    std                  | 0.0767    |
|    value_loss           | 0.00418   |
---------------------------------------
box reached target
box reached target
Eval num_timesteps=7260000, episode_reward=0.24 +/- 2.47
Episode length: 275.00 +/- 50.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 275        |
|    mean_reward          | 0.235      |
| time/                   |            |
|    total_timesteps      | 7260000    |
| train/                  |            |
|    approx_kl            | 0.46809596 |
|    clip_fraction        | 0.511      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.31       |
|    explained_variance   | 0.0232     |
|    learning_rate        | 0.000585   |
|    loss                 | 0.0305     |
|    n_updates            | 35440      |
|    policy_gradient_loss | 0.0217     |
|    std                  | 0.0775     |
|    value_loss           | 0.0497     |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 3545    |
|    time_elapsed    | 11503   |
|    total_timesteps | 7260160 |
--------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3546       |
|    time_elapsed         | 11506      |
|    total_timesteps      | 7262208    |
| train/                  |            |
|    approx_kl            | 0.12863496 |
|    clip_fraction        | 0.381      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.32       |
|    explained_variance   | 0.707      |
|    learning_rate        | 0.000584   |
|    loss                 | 0.127      |
|    n_updates            | 35450      |
|    policy_gradient_loss | 0.0138     |
|    std                  | 0.077      |
|    value_loss           | 0.152      |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3547       |
|    time_elapsed         | 11509      |
|    total_timesteps      | 7264256    |
| train/                  |            |
|    approx_kl            | 0.19345184 |
|    clip_fraction        | 0.422      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.3        |
|    explained_variance   | 0.652      |
|    learning_rate        | 0.000584   |
|    loss                 | -0.0435    |
|    n_updates            | 35460      |
|    policy_gradient_loss | 0.0119     |
|    std                  | 0.0784     |
|    value_loss           | 0.0508     |
----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3548      |
|    time_elapsed         | 11512     |
|    total_timesteps      | 7266304   |
| train/                  |           |
|    approx_kl            | 0.9280466 |
|    clip_fraction        | 0.525     |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.24      |
|    explained_variance   | 0.889     |
|    learning_rate        | 0.000583  |
|    loss                 | 0.081     |
|    n_updates            | 35470     |
|    policy_gradient_loss | 0.031     |
|    std                  | 0.081     |
|    value_loss           | 0.0219    |
---------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3549      |
|    time_elapsed         | 11515     |
|    total_timesteps      | 7268352   |
| train/                  |           |
|    approx_kl            | 0.8343208 |
|    clip_fraction        | 0.556     |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.21      |
|    explained_variance   | 0.662     |
|    learning_rate        | 0.000583  |
|    loss                 | 0.00418   |
|    n_updates            | 35480     |
|    policy_gradient_loss | 0.00967   |
|    std                  | 0.0813    |
|    value_loss           | 0.00434   |
---------------------------------------
box reached target
Eval num_timesteps=7270000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1         |
| time/                   |            |
|    total_timesteps      | 7270000    |
| train/                  |            |
|    approx_kl            | 0.23126754 |
|    clip_fraction        | 0.496      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.2        |
|    explained_variance   | 0.773      |
|    learning_rate        | 0.000583   |
|    loss                 | -0.00332   |
|    n_updates            | 35490      |
|    policy_gradient_loss | 0.0251     |
|    std                  | 0.0823     |
|    value_loss           | 0.00776    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 3550    |
|    time_elapsed    | 11519   |
|    total_timesteps | 7270400 |
--------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3551       |
|    time_elapsed         | 11522      |
|    total_timesteps      | 7272448    |
| train/                  |            |
|    approx_kl            | 0.14527538 |
|    clip_fraction        | 0.482      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.14       |
|    explained_variance   | 0.507      |
|    learning_rate        | 0.000582   |
|    loss                 | 0.00749    |
|    n_updates            | 35500      |
|    policy_gradient_loss | 0.0161     |
|    std                  | 0.0846     |
|    value_loss           | 0.0391     |
----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3552      |
|    time_elapsed         | 11525     |
|    total_timesteps      | 7274496   |
| train/                  |           |
|    approx_kl            | 0.1666219 |
|    clip_fraction        | 0.427     |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.12      |
|    explained_variance   | 0.916     |
|    learning_rate        | 0.000582  |
|    loss                 | 0.0729    |
|    n_updates            | 35510     |
|    policy_gradient_loss | 0.02      |
|    std                  | 0.0849    |
|    value_loss           | 0.00787   |
---------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3553       |
|    time_elapsed         | 11528      |
|    total_timesteps      | 7276544    |
| train/                  |            |
|    approx_kl            | 0.28656387 |
|    clip_fraction        | 0.463      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.09       |
|    explained_variance   | 0.537      |
|    learning_rate        | 0.000581   |
|    loss                 | -0.0333    |
|    n_updates            | 35520      |
|    policy_gradient_loss | 0.01       |
|    std                  | 0.0864     |
|    value_loss           | 0.00481    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3554       |
|    time_elapsed         | 11531      |
|    total_timesteps      | 7278592    |
| train/                  |            |
|    approx_kl            | 0.36904627 |
|    clip_fraction        | 0.478      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.06       |
|    explained_variance   | 0.948      |
|    learning_rate        | 0.000581   |
|    loss                 | 0.00428    |
|    n_updates            | 35530      |
|    policy_gradient_loss | 0.0151     |
|    std                  | 0.0877     |
|    value_loss           | 0.00431    |
----------------------------------------
Eval num_timesteps=7280000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 300       |
|    mean_reward          | -1        |
| time/                   |           |
|    total_timesteps      | 7280000   |
| train/                  |           |
|    approx_kl            | 2.0616379 |
|    clip_fraction        | 0.535     |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.04      |
|    explained_variance   | 0.115     |
|    learning_rate        | 0.000581  |
|    loss                 | -0.0217   |
|    n_updates            | 35540     |
|    policy_gradient_loss | 0.00874   |
|    std                  | 0.0879    |
|    value_loss           | 0.00268   |
---------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 3555    |
|    time_elapsed    | 11535   |
|    total_timesteps | 7280640 |
--------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3556      |
|    time_elapsed         | 11538     |
|    total_timesteps      | 7282688   |
| train/                  |           |
|    approx_kl            | 0.7040039 |
|    clip_fraction        | 0.513     |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.06      |
|    explained_variance   | 0.316     |
|    learning_rate        | 0.00058   |
|    loss                 | -0.0263   |
|    n_updates            | 35550     |
|    policy_gradient_loss | 0.00191   |
|    std                  | 0.0861    |
|    value_loss           | 0.00437   |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3557       |
|    time_elapsed         | 11541      |
|    total_timesteps      | 7284736    |
| train/                  |            |
|    approx_kl            | 0.29020992 |
|    clip_fraction        | 0.43       |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.09       |
|    explained_variance   | 0.572      |
|    learning_rate        | 0.00058    |
|    loss                 | -0.00416   |
|    n_updates            | 35560      |
|    policy_gradient_loss | 0.00811    |
|    std                  | 0.085      |
|    value_loss           | 0.00152    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3558       |
|    time_elapsed         | 11544      |
|    total_timesteps      | 7286784    |
| train/                  |            |
|    approx_kl            | 0.23931211 |
|    clip_fraction        | 0.435      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.09       |
|    explained_variance   | 0.272      |
|    learning_rate        | 0.000579   |
|    loss                 | -0.0247    |
|    n_updates            | 35570      |
|    policy_gradient_loss | 0.0213     |
|    std                  | 0.0862     |
|    value_loss           | 0.00246    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3559       |
|    time_elapsed         | 11547      |
|    total_timesteps      | 7288832    |
| train/                  |            |
|    approx_kl            | 0.25830907 |
|    clip_fraction        | 0.427      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.07       |
|    explained_variance   | 0.166      |
|    learning_rate        | 0.000579   |
|    loss                 | 0.0665     |
|    n_updates            | 35580      |
|    policy_gradient_loss | 0.0158     |
|    std                  | 0.086      |
|    value_loss           | 0.00178    |
----------------------------------------
box reached target
Eval num_timesteps=7290000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1         |
| time/                   |            |
|    total_timesteps      | 7290000    |
| train/                  |            |
|    approx_kl            | 0.23462664 |
|    clip_fraction        | 0.477      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.1        |
|    explained_variance   | 0.761      |
|    learning_rate        | 0.000579   |
|    loss                 | 0.00405    |
|    n_updates            | 35590      |
|    policy_gradient_loss | 0.0131     |
|    std                  | 0.0844     |
|    value_loss           | 0.00778    |
----------------------------------------
box reached target
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 3560    |
|    time_elapsed    | 11551   |
|    total_timesteps | 7290880 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3561       |
|    time_elapsed         | 11554      |
|    total_timesteps      | 7292928    |
| train/                  |            |
|    approx_kl            | 0.20813107 |
|    clip_fraction        | 0.49       |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.13       |
|    explained_variance   | 0.373      |
|    learning_rate        | 0.000578   |
|    loss                 | 0.103      |
|    n_updates            | 35600      |
|    policy_gradient_loss | 0.0279     |
|    std                  | 0.0835     |
|    value_loss           | 0.17       |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3562       |
|    time_elapsed         | 11557      |
|    total_timesteps      | 7294976    |
| train/                  |            |
|    approx_kl            | 0.15211648 |
|    clip_fraction        | 0.454      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.14       |
|    explained_variance   | -0.00509   |
|    learning_rate        | 0.000578   |
|    loss                 | -0.0158    |
|    n_updates            | 35610      |
|    policy_gradient_loss | 0.0187     |
|    std                  | 0.0837     |
|    value_loss           | 0.00373    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3563       |
|    time_elapsed         | 11560      |
|    total_timesteps      | 7297024    |
| train/                  |            |
|    approx_kl            | 0.27001727 |
|    clip_fraction        | 0.452      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.13       |
|    explained_variance   | 0.108      |
|    learning_rate        | 0.000577   |
|    loss                 | -0.0266    |
|    n_updates            | 35620      |
|    policy_gradient_loss | 0.0156     |
|    std                  | 0.0837     |
|    value_loss           | 0.00458    |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3564       |
|    time_elapsed         | 11563      |
|    total_timesteps      | 7299072    |
| train/                  |            |
|    approx_kl            | 0.48065284 |
|    clip_fraction        | 0.476      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.12       |
|    explained_variance   | 0.135      |
|    learning_rate        | 0.000577   |
|    loss                 | -0.0218    |
|    n_updates            | 35630      |
|    policy_gradient_loss | 0.0646     |
|    std                  | 0.0842     |
|    value_loss           | 0.00324    |
----------------------------------------
box reached target
Eval num_timesteps=7300000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1         |
| time/                   |            |
|    total_timesteps      | 7300000    |
| train/                  |            |
|    approx_kl            | 0.86497056 |
|    clip_fraction        | 0.537      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.13       |
|    explained_variance   | 0.496      |
|    learning_rate        | 0.000577   |
|    loss                 | 0.0781     |
|    n_updates            | 35640      |
|    policy_gradient_loss | 0.0196     |
|    std                  | 0.0833     |
|    value_loss           | 0.0243     |
----------------------------------------
box reached target
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 3565    |
|    time_elapsed    | 11567   |
|    total_timesteps | 7301120 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3566       |
|    time_elapsed         | 11570      |
|    total_timesteps      | 7303168    |
| train/                  |            |
|    approx_kl            | 0.46563834 |
|    clip_fraction        | 0.49       |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.16       |
|    explained_variance   | 0.732      |
|    learning_rate        | 0.000576   |
|    loss                 | -0.0359    |
|    n_updates            | 35650      |
|    policy_gradient_loss | 0.03       |
|    std                  | 0.0819     |
|    value_loss           | 0.0553     |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3567       |
|    time_elapsed         | 11573      |
|    total_timesteps      | 7305216    |
| train/                  |            |
|    approx_kl            | 0.19953346 |
|    clip_fraction        | 0.462      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.16       |
|    explained_variance   | 0.791      |
|    learning_rate        | 0.000576   |
|    loss                 | 0.0255     |
|    n_updates            | 35660      |
|    policy_gradient_loss | 0.0148     |
|    std                  | 0.083      |
|    value_loss           | 0.0149     |
----------------------------------------
box reached target
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3568      |
|    time_elapsed         | 11576     |
|    total_timesteps      | 7307264   |
| train/                  |           |
|    approx_kl            | 0.6695776 |
|    clip_fraction        | 0.516     |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.13      |
|    explained_variance   | 0.812     |
|    learning_rate        | 0.000575  |
|    loss                 | -0.054    |
|    n_updates            | 35670     |
|    policy_gradient_loss | 0.0202    |
|    std                  | 0.0829    |
|    value_loss           | 0.00328   |
---------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3569      |
|    time_elapsed         | 11579     |
|    total_timesteps      | 7309312   |
| train/                  |           |
|    approx_kl            | 0.3404044 |
|    clip_fraction        | 0.512     |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.13      |
|    explained_variance   | 0.768     |
|    learning_rate        | 0.000575  |
|    loss                 | 0.0222    |
|    n_updates            | 35680     |
|    policy_gradient_loss | 0.0181    |
|    std                  | 0.0836    |
|    value_loss           | 0.0294    |
---------------------------------------
Eval num_timesteps=7310000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1         |
| time/                   |            |
|    total_timesteps      | 7310000    |
| train/                  |            |
|    approx_kl            | 0.56881565 |
|    clip_fraction        | 0.509      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.12       |
|    explained_variance   | 0.758      |
|    learning_rate        | 0.000575   |
|    loss                 | 0.0319     |
|    n_updates            | 35690      |
|    policy_gradient_loss | 0.0268     |
|    std                  | 0.0838     |
|    value_loss           | 0.0039     |
----------------------------------------
box reached target
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 3570    |
|    time_elapsed    | 11583   |
|    total_timesteps | 7311360 |
--------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3571      |
|    time_elapsed         | 11587     |
|    total_timesteps      | 7313408   |
| train/                  |           |
|    approx_kl            | 0.5058747 |
|    clip_fraction        | 0.511     |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.13      |
|    explained_variance   | 0.945     |
|    learning_rate        | 0.000574  |
|    loss                 | 0.0612    |
|    n_updates            | 35700     |
|    policy_gradient_loss | 0.0359    |
|    std                  | 0.083     |
|    value_loss           | 0.01      |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3572       |
|    time_elapsed         | 11590      |
|    total_timesteps      | 7315456    |
| train/                  |            |
|    approx_kl            | 0.43699914 |
|    clip_fraction        | 0.506      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.14       |
|    explained_variance   | -0.482     |
|    learning_rate        | 0.000574   |
|    loss                 | -0.0427    |
|    n_updates            | 35710      |
|    policy_gradient_loss | 0.0331     |
|    std                  | 0.0824     |
|    value_loss           | 0.002      |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3573       |
|    time_elapsed         | 11593      |
|    total_timesteps      | 7317504    |
| train/                  |            |
|    approx_kl            | 0.44973937 |
|    clip_fraction        | 0.466      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.14       |
|    explained_variance   | 0.628      |
|    learning_rate        | 0.000573   |
|    loss                 | -0.0113    |
|    n_updates            | 35720      |
|    policy_gradient_loss | 0.0143     |
|    std                  | 0.0826     |
|    value_loss           | 0.00254    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3574       |
|    time_elapsed         | 11596      |
|    total_timesteps      | 7319552    |
| train/                  |            |
|    approx_kl            | 0.31962764 |
|    clip_fraction        | 0.489      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.14       |
|    explained_variance   | 0.93       |
|    learning_rate        | 0.000573   |
|    loss                 | 0.0298     |
|    n_updates            | 35730      |
|    policy_gradient_loss | 0.0223     |
|    std                  | 0.0826     |
|    value_loss           | 0.0105     |
----------------------------------------
box reached target
Eval num_timesteps=7320000, episode_reward=0.21 +/- 2.43
Episode length: 274.80 +/- 50.40
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 275        |
|    mean_reward          | 0.214      |
| time/                   |            |
|    total_timesteps      | 7320000    |
| train/                  |            |
|    approx_kl            | 0.29145014 |
|    clip_fraction        | 0.466      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.17       |
|    explained_variance   | -0.709     |
|    learning_rate        | 0.000573   |
|    loss                 | -0.0375    |
|    n_updates            | 35740      |
|    policy_gradient_loss | 0.0288     |
|    std                  | 0.081      |
|    value_loss           | 0.00242    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 3575    |
|    time_elapsed    | 11600   |
|    total_timesteps | 7321600 |
--------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3576      |
|    time_elapsed         | 11603     |
|    total_timesteps      | 7323648   |
| train/                  |           |
|    approx_kl            | 0.5017661 |
|    clip_fraction        | 0.48      |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.2       |
|    explained_variance   | 0.0861    |
|    learning_rate        | 0.000572  |
|    loss                 | 0.0941    |
|    n_updates            | 35750     |
|    policy_gradient_loss | 0.00169   |
|    std                  | 0.0794    |
|    value_loss           | 0.013     |
---------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3577       |
|    time_elapsed         | 11606      |
|    total_timesteps      | 7325696    |
| train/                  |            |
|    approx_kl            | 0.29124987 |
|    clip_fraction        | 0.518      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.23       |
|    explained_variance   | 0.328      |
|    learning_rate        | 0.000572   |
|    loss                 | -0.0217    |
|    n_updates            | 35760      |
|    policy_gradient_loss | 0.0331     |
|    std                  | 0.079      |
|    value_loss           | 0.00199    |
----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3578      |
|    time_elapsed         | 11609     |
|    total_timesteps      | 7327744   |
| train/                  |           |
|    approx_kl            | 0.6298841 |
|    clip_fraction        | 0.492     |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.22      |
|    explained_variance   | 0.915     |
|    learning_rate        | 0.000571  |
|    loss                 | 0.0217    |
|    n_updates            | 35770     |
|    policy_gradient_loss | 0.0192    |
|    std                  | 0.0795    |
|    value_loss           | 0.0062    |
---------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3579      |
|    time_elapsed         | 11612     |
|    total_timesteps      | 7329792   |
| train/                  |           |
|    approx_kl            | 0.2572607 |
|    clip_fraction        | 0.479     |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.24      |
|    explained_variance   | -0.561    |
|    learning_rate        | 0.000571  |
|    loss                 | 0.0668    |
|    n_updates            | 35780     |
|    policy_gradient_loss | 0.0226    |
|    std                  | 0.0788    |
|    value_loss           | 0.00302   |
---------------------------------------
Eval num_timesteps=7330000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 300       |
|    mean_reward          | -1        |
| time/                   |           |
|    total_timesteps      | 7330000   |
| train/                  |           |
|    approx_kl            | 3.1134818 |
|    clip_fraction        | 0.572     |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.22      |
|    explained_variance   | 0.16      |
|    learning_rate        | 0.000571  |
|    loss                 | -0.0141   |
|    n_updates            | 35790     |
|    policy_gradient_loss | 0.0137    |
|    std                  | 0.0796    |
|    value_loss           | 0.00163   |
---------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 3580    |
|    time_elapsed    | 11616   |
|    total_timesteps | 7331840 |
--------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3581      |
|    time_elapsed         | 11619     |
|    total_timesteps      | 7333888   |
| train/                  |           |
|    approx_kl            | 1.8587768 |
|    clip_fraction        | 0.464     |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.23      |
|    explained_variance   | -0.251    |
|    learning_rate        | 0.00057   |
|    loss                 | 0.0111    |
|    n_updates            | 35800     |
|    policy_gradient_loss | 0.0128    |
|    std                  | 0.0792    |
|    value_loss           | 0.00323   |
---------------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3582       |
|    time_elapsed         | 11622      |
|    total_timesteps      | 7335936    |
| train/                  |            |
|    approx_kl            | 0.28837246 |
|    clip_fraction        | 0.501      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.22       |
|    explained_variance   | 0.854      |
|    learning_rate        | 0.00057    |
|    loss                 | -0.0184    |
|    n_updates            | 35810      |
|    policy_gradient_loss | 0.0209     |
|    std                  | 0.0799     |
|    value_loss           | 0.0134     |
----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3583      |
|    time_elapsed         | 11625     |
|    total_timesteps      | 7337984   |
| train/                  |           |
|    approx_kl            | 0.7156184 |
|    clip_fraction        | 0.459     |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.23      |
|    explained_variance   | 0.814     |
|    learning_rate        | 0.000569  |
|    loss                 | 0.0234    |
|    n_updates            | 35820     |
|    policy_gradient_loss | 0.0165    |
|    std                  | 0.0785    |
|    value_loss           | 0.02      |
---------------------------------------
box reached target
Eval num_timesteps=7340000, episode_reward=0.23 +/- 2.47
Episode length: 272.20 +/- 55.60
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 272       |
|    mean_reward          | 0.233     |
| time/                   |           |
|    total_timesteps      | 7340000   |
| train/                  |           |
|    approx_kl            | 0.5015049 |
|    clip_fraction        | 0.472     |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.23      |
|    explained_variance   | 0.596     |
|    learning_rate        | 0.000569  |
|    loss                 | -0.0465   |
|    n_updates            | 35830     |
|    policy_gradient_loss | 0.0119    |
|    std                  | 0.079     |
|    value_loss           | 0.00256   |
---------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 3584    |
|    time_elapsed    | 11629   |
|    total_timesteps | 7340032 |
--------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3585       |
|    time_elapsed         | 11632      |
|    total_timesteps      | 7342080    |
| train/                  |            |
|    approx_kl            | 0.41323796 |
|    clip_fraction        | 0.458      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.23       |
|    explained_variance   | -0.496     |
|    learning_rate        | 0.000569   |
|    loss                 | 0.0747     |
|    n_updates            | 35840      |
|    policy_gradient_loss | 0.031      |
|    std                  | 0.0798     |
|    value_loss           | 0.00279    |
----------------------------------------
box reached target
--------------------------------------
| time/                   |          |
|    fps                  | 631      |
|    iterations           | 3586     |
|    time_elapsed         | 11635    |
|    total_timesteps      | 7344128  |
| train/                  |          |
|    approx_kl            | 1.558595 |
|    clip_fraction        | 0.547    |
|    clip_range           | 0.2      |
|    entropy_loss         | 2.21     |
|    explained_variance   | 0.147    |
|    learning_rate        | 0.000568 |
|    loss                 | 0.0589   |
|    n_updates            | 35850    |
|    policy_gradient_loss | 0.0187   |
|    std                  | 0.0803   |
|    value_loss           | 0.0909   |
--------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3587      |
|    time_elapsed         | 11638     |
|    total_timesteps      | 7346176   |
| train/                  |           |
|    approx_kl            | 0.9224209 |
|    clip_fraction        | 0.502     |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.21      |
|    explained_variance   | 0.864     |
|    learning_rate        | 0.000568  |
|    loss                 | -0.00861  |
|    n_updates            | 35860     |
|    policy_gradient_loss | 0.0103    |
|    std                  | 0.0792    |
|    value_loss           | 0.0169    |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3588       |
|    time_elapsed         | 11641      |
|    total_timesteps      | 7348224    |
| train/                  |            |
|    approx_kl            | 0.38063997 |
|    clip_fraction        | 0.477      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.21       |
|    explained_variance   | 0.91       |
|    learning_rate        | 0.000567   |
|    loss                 | -0.0128    |
|    n_updates            | 35870      |
|    policy_gradient_loss | 0.0253     |
|    std                  | 0.0801     |
|    value_loss           | 0.0138     |
----------------------------------------
box reached target
box reached target
Eval num_timesteps=7350000, episode_reward=0.22 +/- 2.44
Episode length: 277.80 +/- 44.40
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 278       |
|    mean_reward          | 0.222     |
| time/                   |           |
|    total_timesteps      | 7350000   |
| train/                  |           |
|    approx_kl            | 0.7019652 |
|    clip_fraction        | 0.499     |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.22      |
|    explained_variance   | -0.25     |
|    learning_rate        | 0.000567  |
|    loss                 | -0.00869  |
|    n_updates            | 35880     |
|    policy_gradient_loss | -0.000503 |
|    std                  | 0.0787    |
|    value_loss           | 0.0138    |
---------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 3589    |
|    time_elapsed    | 11645   |
|    total_timesteps | 7350272 |
--------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3590      |
|    time_elapsed         | 11648     |
|    total_timesteps      | 7352320   |
| train/                  |           |
|    approx_kl            | 1.0561866 |
|    clip_fraction        | 0.502     |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.26      |
|    explained_variance   | 0.872     |
|    learning_rate        | 0.000567  |
|    loss                 | -0.0167   |
|    n_updates            | 35890     |
|    policy_gradient_loss | -0.000534 |
|    std                  | 0.0772    |
|    value_loss           | 0.00759   |
---------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3591      |
|    time_elapsed         | 11651     |
|    total_timesteps      | 7354368   |
| train/                  |           |
|    approx_kl            | 1.1467547 |
|    clip_fraction        | 0.505     |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.28      |
|    explained_variance   | 0.807     |
|    learning_rate        | 0.000566  |
|    loss                 | -0.0474   |
|    n_updates            | 35900     |
|    policy_gradient_loss | 0.00633   |
|    std                  | 0.0773    |
|    value_loss           | 0.0131    |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3592       |
|    time_elapsed         | 11654      |
|    total_timesteps      | 7356416    |
| train/                  |            |
|    approx_kl            | 0.67695266 |
|    clip_fraction        | 0.506      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.27       |
|    explained_variance   | -0.0183    |
|    learning_rate        | 0.000566   |
|    loss                 | 0.0973     |
|    n_updates            | 35910      |
|    policy_gradient_loss | 0.0184     |
|    std                  | 0.0783     |
|    value_loss           | 0.00736    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3593       |
|    time_elapsed         | 11657      |
|    total_timesteps      | 7358464    |
| train/                  |            |
|    approx_kl            | 0.22836879 |
|    clip_fraction        | 0.465      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.24       |
|    explained_variance   | 0.706      |
|    learning_rate        | 0.000565   |
|    loss                 | 0.0116     |
|    n_updates            | 35920      |
|    policy_gradient_loss | 0.0315     |
|    std                  | 0.0791     |
|    value_loss           | 0.00451    |
----------------------------------------
Eval num_timesteps=7360000, episode_reward=-0.74 +/- 0.52
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -0.738     |
| time/                   |            |
|    total_timesteps      | 7360000    |
| train/                  |            |
|    approx_kl            | 0.62461674 |
|    clip_fraction        | 0.491      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.24       |
|    explained_variance   | -0.000922  |
|    learning_rate        | 0.000565   |
|    loss                 | 0.00497    |
|    n_updates            | 35930      |
|    policy_gradient_loss | 0.0174     |
|    std                  | 0.0788     |
|    value_loss           | 0.00202    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 3594    |
|    time_elapsed    | 11661   |
|    total_timesteps | 7360512 |
--------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3595      |
|    time_elapsed         | 11664     |
|    total_timesteps      | 7362560   |
| train/                  |           |
|    approx_kl            | 1.2545195 |
|    clip_fraction        | 0.552     |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.23      |
|    explained_variance   | 0.413     |
|    learning_rate        | 0.000565  |
|    loss                 | -0.0192   |
|    n_updates            | 35940     |
|    policy_gradient_loss | 0.0247    |
|    std                  | 0.0789    |
|    value_loss           | 0.00461   |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3596       |
|    time_elapsed         | 11667      |
|    total_timesteps      | 7364608    |
| train/                  |            |
|    approx_kl            | 0.48267388 |
|    clip_fraction        | 0.473      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.27       |
|    explained_variance   | -0.298     |
|    learning_rate        | 0.000564   |
|    loss                 | 0.0322     |
|    n_updates            | 35950      |
|    policy_gradient_loss | 0.0116     |
|    std                  | 0.0765     |
|    value_loss           | 0.00325    |
----------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3597      |
|    time_elapsed         | 11670     |
|    total_timesteps      | 7366656   |
| train/                  |           |
|    approx_kl            | 0.5851035 |
|    clip_fraction        | 0.443     |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.29      |
|    explained_variance   | -0.0348   |
|    learning_rate        | 0.000564  |
|    loss                 | -0.0173   |
|    n_updates            | 35960     |
|    policy_gradient_loss | 0.0187    |
|    std                  | 0.0769    |
|    value_loss           | 0.00253   |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3598       |
|    time_elapsed         | 11673      |
|    total_timesteps      | 7368704    |
| train/                  |            |
|    approx_kl            | 0.42842337 |
|    clip_fraction        | 0.525      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.28       |
|    explained_variance   | 0.884      |
|    learning_rate        | 0.000564   |
|    loss                 | -0.0611    |
|    n_updates            | 35970      |
|    policy_gradient_loss | 0.0291     |
|    std                  | 0.077      |
|    value_loss           | 0.00608    |
----------------------------------------
Eval num_timesteps=7370000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
--------------------------------------
| eval/                   |          |
|    mean_ep_length       | 300      |
|    mean_reward          | -1       |
| time/                   |          |
|    total_timesteps      | 7370000  |
| train/                  |          |
|    approx_kl            | 0.829172 |
|    clip_fraction        | 0.489    |
|    clip_range           | 0.2      |
|    entropy_loss         | 2.28     |
|    explained_variance   | 0.45     |
|    learning_rate        | 0.000563 |
|    loss                 | -0.0552  |
|    n_updates            | 35980    |
|    policy_gradient_loss | 0.0198   |
|    std                  | 0.0768   |
|    value_loss           | 0.00308  |
--------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 3599    |
|    time_elapsed    | 11677   |
|    total_timesteps | 7370752 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3600       |
|    time_elapsed         | 11680      |
|    total_timesteps      | 7372800    |
| train/                  |            |
|    approx_kl            | 0.96887493 |
|    clip_fraction        | 0.55       |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.28       |
|    explained_variance   | 0.00134    |
|    learning_rate        | 0.000563   |
|    loss                 | 0.04       |
|    n_updates            | 35990      |
|    policy_gradient_loss | 0.0167     |
|    std                  | 0.0778     |
|    value_loss           | 0.00331    |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3601       |
|    time_elapsed         | 11683      |
|    total_timesteps      | 7374848    |
| train/                  |            |
|    approx_kl            | 0.30183405 |
|    clip_fraction        | 0.455      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.26       |
|    explained_variance   | 0.436      |
|    learning_rate        | 0.000562   |
|    loss                 | 0.00351    |
|    n_updates            | 36000      |
|    policy_gradient_loss | 0.00645    |
|    std                  | 0.0782     |
|    value_loss           | 0.00176    |
----------------------------------------
--------------------------------------
| time/                   |          |
|    fps                  | 631      |
|    iterations           | 3602     |
|    time_elapsed         | 11687    |
|    total_timesteps      | 7376896  |
| train/                  |          |
|    approx_kl            | 0.927513 |
|    clip_fraction        | 0.517    |
|    clip_range           | 0.2      |
|    entropy_loss         | 2.24     |
|    explained_variance   | 0.934    |
|    learning_rate        | 0.000562 |
|    loss                 | 0.0109   |
|    n_updates            | 36010    |
|    policy_gradient_loss | 0.00219  |
|    std                  | 0.0793   |
|    value_loss           | 0.00854  |
--------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3603      |
|    time_elapsed         | 11690     |
|    total_timesteps      | 7378944   |
| train/                  |           |
|    approx_kl            | 0.8385633 |
|    clip_fraction        | 0.503     |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.24      |
|    explained_variance   | 0.461     |
|    learning_rate        | 0.000562  |
|    loss                 | 0.0104    |
|    n_updates            | 36020     |
|    policy_gradient_loss | 0.0153    |
|    std                  | 0.0782    |
|    value_loss           | 0.00205   |
---------------------------------------
box reached target
Eval num_timesteps=7380000, episode_reward=-0.97 +/- 0.05
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -0.973     |
| time/                   |            |
|    total_timesteps      | 7380000    |
| train/                  |            |
|    approx_kl            | 0.22633989 |
|    clip_fraction        | 0.448      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.25       |
|    explained_variance   | 0.713      |
|    learning_rate        | 0.000561   |
|    loss                 | -0.00435   |
|    n_updates            | 36030      |
|    policy_gradient_loss | 0.0245     |
|    std                  | 0.0785     |
|    value_loss           | 0.00214    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 3604    |
|    time_elapsed    | 11694   |
|    total_timesteps | 7380992 |
--------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3605      |
|    time_elapsed         | 11697     |
|    total_timesteps      | 7383040   |
| train/                  |           |
|    approx_kl            | 1.1863587 |
|    clip_fraction        | 0.529     |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.24      |
|    explained_variance   | 0.731     |
|    learning_rate        | 0.000561  |
|    loss                 | -0.0133   |
|    n_updates            | 36040     |
|    policy_gradient_loss | 0.0221    |
|    std                  | 0.0797    |
|    value_loss           | 0.0109    |
---------------------------------------
--------------------------------------
| time/                   |          |
|    fps                  | 631      |
|    iterations           | 3606     |
|    time_elapsed         | 11700    |
|    total_timesteps      | 7385088  |
| train/                  |          |
|    approx_kl            | 3.089623 |
|    clip_fraction        | 0.531    |
|    clip_range           | 0.2      |
|    entropy_loss         | 2.22     |
|    explained_variance   | 0.42     |
|    learning_rate        | 0.00056  |
|    loss                 | -0.00756 |
|    n_updates            | 36050    |
|    policy_gradient_loss | 0.02     |
|    std                  | 0.0789   |
|    value_loss           | 0.00368  |
--------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3607       |
|    time_elapsed         | 11703      |
|    total_timesteps      | 7387136    |
| train/                  |            |
|    approx_kl            | 0.45335668 |
|    clip_fraction        | 0.514      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.25       |
|    explained_variance   | 0.672      |
|    learning_rate        | 0.00056    |
|    loss                 | 0.0141     |
|    n_updates            | 36060      |
|    policy_gradient_loss | 0.0237     |
|    std                  | 0.0782     |
|    value_loss           | 0.00188    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3608       |
|    time_elapsed         | 11706      |
|    total_timesteps      | 7389184    |
| train/                  |            |
|    approx_kl            | 0.38295478 |
|    clip_fraction        | 0.502      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.25       |
|    explained_variance   | -0.363     |
|    learning_rate        | 0.00056    |
|    loss                 | -0.031     |
|    n_updates            | 36070      |
|    policy_gradient_loss | 0.00633    |
|    std                  | 0.0784     |
|    value_loss           | 0.00461    |
----------------------------------------
box reached target
Eval num_timesteps=7390000, episode_reward=0.22 +/- 2.44
Episode length: 275.00 +/- 50.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 275        |
|    mean_reward          | 0.221      |
| time/                   |            |
|    total_timesteps      | 7390000    |
| train/                  |            |
|    approx_kl            | 0.49654275 |
|    clip_fraction        | 0.426      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.28       |
|    explained_variance   | -0.151     |
|    learning_rate        | 0.000559   |
|    loss                 | 0.00125    |
|    n_updates            | 36080      |
|    policy_gradient_loss | -0.00274   |
|    std                  | 0.0767     |
|    value_loss           | 0.00336    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 3609    |
|    time_elapsed    | 11710   |
|    total_timesteps | 7391232 |
--------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3610      |
|    time_elapsed         | 11713     |
|    total_timesteps      | 7393280   |
| train/                  |           |
|    approx_kl            | 1.0354955 |
|    clip_fraction        | 0.534     |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.27      |
|    explained_variance   | 0.0718    |
|    learning_rate        | 0.000559  |
|    loss                 | 0.131     |
|    n_updates            | 36090     |
|    policy_gradient_loss | 0.0318    |
|    std                  | 0.0782    |
|    value_loss           | 0.00305   |
---------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3611       |
|    time_elapsed         | 11716      |
|    total_timesteps      | 7395328    |
| train/                  |            |
|    approx_kl            | 0.47540992 |
|    clip_fraction        | 0.47       |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.26       |
|    explained_variance   | -0.0228    |
|    learning_rate        | 0.000558   |
|    loss                 | -0.0119    |
|    n_updates            | 36100      |
|    policy_gradient_loss | 0.00756    |
|    std                  | 0.0779     |
|    value_loss           | 0.00183    |
----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3612      |
|    time_elapsed         | 11719     |
|    total_timesteps      | 7397376   |
| train/                  |           |
|    approx_kl            | 0.3302176 |
|    clip_fraction        | 0.466     |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.25      |
|    explained_variance   | 0.926     |
|    learning_rate        | 0.000558  |
|    loss                 | -0.00747  |
|    n_updates            | 36110     |
|    policy_gradient_loss | 0.0217    |
|    std                  | 0.0793    |
|    value_loss           | 0.00609   |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3613       |
|    time_elapsed         | 11722      |
|    total_timesteps      | 7399424    |
| train/                  |            |
|    approx_kl            | 0.24003017 |
|    clip_fraction        | 0.388      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.25       |
|    explained_variance   | 0.171      |
|    learning_rate        | 0.000558   |
|    loss                 | 0.0425     |
|    n_updates            | 36120      |
|    policy_gradient_loss | 0.0132     |
|    std                  | 0.0779     |
|    value_loss           | 0.00117    |
----------------------------------------
Eval num_timesteps=7400000, episode_reward=-0.71 +/- 0.57
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -0.715     |
| time/                   |            |
|    total_timesteps      | 7400000    |
| train/                  |            |
|    approx_kl            | 0.32772207 |
|    clip_fraction        | 0.457      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.26       |
|    explained_variance   | 0.415      |
|    learning_rate        | 0.000557   |
|    loss                 | -0.0284    |
|    n_updates            | 36130      |
|    policy_gradient_loss | 0.0183     |
|    std                  | 0.0784     |
|    value_loss           | 0.0011     |
----------------------------------------
box reached target
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 3614    |
|    time_elapsed    | 11726   |
|    total_timesteps | 7401472 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3615       |
|    time_elapsed         | 11729      |
|    total_timesteps      | 7403520    |
| train/                  |            |
|    approx_kl            | 0.59296983 |
|    clip_fraction        | 0.517      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.26       |
|    explained_variance   | 0.92       |
|    learning_rate        | 0.000557   |
|    loss                 | -0.0246    |
|    n_updates            | 36140      |
|    policy_gradient_loss | 0.0265     |
|    std                  | 0.0776     |
|    value_loss           | 0.00524    |
----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3616      |
|    time_elapsed         | 11732     |
|    total_timesteps      | 7405568   |
| train/                  |           |
|    approx_kl            | 0.4284922 |
|    clip_fraction        | 0.475     |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.28      |
|    explained_variance   | 0.374     |
|    learning_rate        | 0.000556  |
|    loss                 | -0.0227   |
|    n_updates            | 36150     |
|    policy_gradient_loss | 0.0107    |
|    std                  | 0.0773    |
|    value_loss           | 0.000819  |
---------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3617      |
|    time_elapsed         | 11735     |
|    total_timesteps      | 7407616   |
| train/                  |           |
|    approx_kl            | 0.3288051 |
|    clip_fraction        | 0.488     |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.25      |
|    explained_variance   | -1        |
|    learning_rate        | 0.000556  |
|    loss                 | -0.0306   |
|    n_updates            | 36160     |
|    policy_gradient_loss | 0.0202    |
|    std                  | 0.0799    |
|    value_loss           | 0.00378   |
---------------------------------------
box reached target
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3618      |
|    time_elapsed         | 11738     |
|    total_timesteps      | 7409664   |
| train/                  |           |
|    approx_kl            | 0.7456775 |
|    clip_fraction        | 0.549     |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.2       |
|    explained_variance   | 0.613     |
|    learning_rate        | 0.000556  |
|    loss                 | 0.0197    |
|    n_updates            | 36170     |
|    policy_gradient_loss | 0.0342    |
|    std                  | 0.0813    |
|    value_loss           | 0.00317   |
---------------------------------------
Eval num_timesteps=7410000, episode_reward=-0.74 +/- 0.52
Episode length: 300.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 300       |
|    mean_reward          | -0.742    |
| time/                   |           |
|    total_timesteps      | 7410000   |
| train/                  |           |
|    approx_kl            | 0.1744154 |
|    clip_fraction        | 0.438     |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.17      |
|    explained_variance   | 0.953     |
|    learning_rate        | 0.000555  |
|    loss                 | -0.0244   |
|    n_updates            | 36180     |
|    policy_gradient_loss | 0.0234    |
|    std                  | 0.0818    |
|    value_loss           | 0.00557   |
---------------------------------------
box reached target
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 3619    |
|    time_elapsed    | 11742   |
|    total_timesteps | 7411712 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3620       |
|    time_elapsed         | 11745      |
|    total_timesteps      | 7413760    |
| train/                  |            |
|    approx_kl            | 0.37739486 |
|    clip_fraction        | 0.477      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.2        |
|    explained_variance   | 0.5        |
|    learning_rate        | 0.000555   |
|    loss                 | -0.0348    |
|    n_updates            | 36190      |
|    policy_gradient_loss | 0.0214     |
|    std                  | 0.0804     |
|    value_loss           | 0.0188     |
----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3621      |
|    time_elapsed         | 11748     |
|    total_timesteps      | 7415808   |
| train/                  |           |
|    approx_kl            | 0.3388608 |
|    clip_fraction        | 0.501     |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.2       |
|    explained_variance   | 0.554     |
|    learning_rate        | 0.000554  |
|    loss                 | 0.0247    |
|    n_updates            | 36200     |
|    policy_gradient_loss | 0.0299    |
|    std                  | 0.0809    |
|    value_loss           | 0.0039    |
---------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3622      |
|    time_elapsed         | 11751     |
|    total_timesteps      | 7417856   |
| train/                  |           |
|    approx_kl            | 1.1793382 |
|    clip_fraction        | 0.509     |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.22      |
|    explained_variance   | 0.509     |
|    learning_rate        | 0.000554  |
|    loss                 | -0.0215   |
|    n_updates            | 36210     |
|    policy_gradient_loss | 0.00705   |
|    std                  | 0.0793    |
|    value_loss           | 0.00176   |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3623       |
|    time_elapsed         | 11754      |
|    total_timesteps      | 7419904    |
| train/                  |            |
|    approx_kl            | 0.39841032 |
|    clip_fraction        | 0.422      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.25       |
|    explained_variance   | -0.049     |
|    learning_rate        | 0.000554   |
|    loss                 | 0.145      |
|    n_updates            | 36220      |
|    policy_gradient_loss | 0.0116     |
|    std                  | 0.0781     |
|    value_loss           | 0.00249    |
----------------------------------------
Eval num_timesteps=7420000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1         |
| time/                   |            |
|    total_timesteps      | 7420000    |
| train/                  |            |
|    approx_kl            | 0.33028167 |
|    clip_fraction        | 0.513      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.26       |
|    explained_variance   | 0.738      |
|    learning_rate        | 0.000553   |
|    loss                 | -0.0342    |
|    n_updates            | 36230      |
|    policy_gradient_loss | 0.00572    |
|    std                  | 0.0776     |
|    value_loss           | 0.00312    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 3624    |
|    time_elapsed    | 11758   |
|    total_timesteps | 7421952 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3625       |
|    time_elapsed         | 11761      |
|    total_timesteps      | 7424000    |
| train/                  |            |
|    approx_kl            | 0.28236866 |
|    clip_fraction        | 0.494      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.25       |
|    explained_variance   | 0.389      |
|    learning_rate        | 0.000553   |
|    loss                 | 0.0469     |
|    n_updates            | 36240      |
|    policy_gradient_loss | 0.0271     |
|    std                  | 0.0799     |
|    value_loss           | 0.00246    |
----------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3626      |
|    time_elapsed         | 11764     |
|    total_timesteps      | 7426048   |
| train/                  |           |
|    approx_kl            | 0.4149794 |
|    clip_fraction        | 0.439     |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.18      |
|    explained_variance   | 0.157     |
|    learning_rate        | 0.000552  |
|    loss                 | -0.0453   |
|    n_updates            | 36250     |
|    policy_gradient_loss | 0.031     |
|    std                  | 0.082     |
|    value_loss           | 0.00121   |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3627       |
|    time_elapsed         | 11767      |
|    total_timesteps      | 7428096    |
| train/                  |            |
|    approx_kl            | 0.31929082 |
|    clip_fraction        | 0.481      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.16       |
|    explained_variance   | 0.882      |
|    learning_rate        | 0.000552   |
|    loss                 | -0.049     |
|    n_updates            | 36260      |
|    policy_gradient_loss | 0.0282     |
|    std                  | 0.0821     |
|    value_loss           | 0.00475    |
----------------------------------------
box reached target
Eval num_timesteps=7430000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1         |
| time/                   |            |
|    total_timesteps      | 7430000    |
| train/                  |            |
|    approx_kl            | 0.35492024 |
|    clip_fraction        | 0.476      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.14       |
|    explained_variance   | 0.195      |
|    learning_rate        | 0.000552   |
|    loss                 | 0.0478     |
|    n_updates            | 36270      |
|    policy_gradient_loss | 0.0157     |
|    std                  | 0.0838     |
|    value_loss           | 0.00177    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 3628    |
|    time_elapsed    | 11771   |
|    total_timesteps | 7430144 |
--------------------------------
box reached target
box reached target
--------------------------------------
| time/                   |          |
|    fps                  | 631      |
|    iterations           | 3629     |
|    time_elapsed         | 11775    |
|    total_timesteps      | 7432192  |
| train/                  |          |
|    approx_kl            | 0.590901 |
|    clip_fraction        | 0.534    |
|    clip_range           | 0.2      |
|    entropy_loss         | 2.14     |
|    explained_variance   | 0.782    |
|    learning_rate        | 0.000551 |
|    loss                 | 0.0223   |
|    n_updates            | 36280    |
|    policy_gradient_loss | 0.01     |
|    std                  | 0.0816   |
|    value_loss           | 0.0117   |
--------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3630       |
|    time_elapsed         | 11778      |
|    total_timesteps      | 7434240    |
| train/                  |            |
|    approx_kl            | 0.40108258 |
|    clip_fraction        | 0.499      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.17       |
|    explained_variance   | 0.899      |
|    learning_rate        | 0.000551   |
|    loss                 | 0.00619    |
|    n_updates            | 36290      |
|    policy_gradient_loss | 0.0655     |
|    std                  | 0.0815     |
|    value_loss           | 0.0235     |
----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3631      |
|    time_elapsed         | 11781     |
|    total_timesteps      | 7436288   |
| train/                  |           |
|    approx_kl            | 1.7598369 |
|    clip_fraction        | 0.579     |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.19      |
|    explained_variance   | 0.725     |
|    learning_rate        | 0.00055   |
|    loss                 | -0.0262   |
|    n_updates            | 36300     |
|    policy_gradient_loss | 0.00559   |
|    std                  | 0.0798    |
|    value_loss           | 0.00729   |
---------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3632      |
|    time_elapsed         | 11784     |
|    total_timesteps      | 7438336   |
| train/                  |           |
|    approx_kl            | 0.4893856 |
|    clip_fraction        | 0.445     |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.23      |
|    explained_variance   | 0.704     |
|    learning_rate        | 0.00055   |
|    loss                 | 0.0821    |
|    n_updates            | 36310     |
|    policy_gradient_loss | 0.0175    |
|    std                  | 0.0789    |
|    value_loss           | 0.000877  |
---------------------------------------
Eval num_timesteps=7440000, episode_reward=-0.70 +/- 0.60
Episode length: 300.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 300       |
|    mean_reward          | -0.699    |
| time/                   |           |
|    total_timesteps      | 7440000   |
| train/                  |           |
|    approx_kl            | 1.2882322 |
|    clip_fraction        | 0.577     |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.24      |
|    explained_variance   | 0.914     |
|    learning_rate        | 0.00055   |
|    loss                 | -0.00691  |
|    n_updates            | 36320     |
|    policy_gradient_loss | 0.0117    |
|    std                  | 0.0789    |
|    value_loss           | 0.00676   |
---------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 3633    |
|    time_elapsed    | 11788   |
|    total_timesteps | 7440384 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3634       |
|    time_elapsed         | 11791      |
|    total_timesteps      | 7442432    |
| train/                  |            |
|    approx_kl            | 0.18772447 |
|    clip_fraction        | 0.435      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.24       |
|    explained_variance   | 0.475      |
|    learning_rate        | 0.000549   |
|    loss                 | -0.0478    |
|    n_updates            | 36330      |
|    policy_gradient_loss | 0.00451    |
|    std                  | 0.0799     |
|    value_loss           | 0.00279    |
----------------------------------------
--------------------------------------
| time/                   |          |
|    fps                  | 631      |
|    iterations           | 3635     |
|    time_elapsed         | 11794    |
|    total_timesteps      | 7444480  |
| train/                  |          |
|    approx_kl            | 1.438093 |
|    clip_fraction        | 0.467    |
|    clip_range           | 0.2      |
|    entropy_loss         | 2.23     |
|    explained_variance   | 0.309    |
|    learning_rate        | 0.000549 |
|    loss                 | -0.0426  |
|    n_updates            | 36340    |
|    policy_gradient_loss | -0.00736 |
|    std                  | 0.0784   |
|    value_loss           | 0.00322  |
--------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3636       |
|    time_elapsed         | 11797      |
|    total_timesteps      | 7446528    |
| train/                  |            |
|    approx_kl            | 0.64735466 |
|    clip_fraction        | 0.506      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.24       |
|    explained_variance   | 0.216      |
|    learning_rate        | 0.000548   |
|    loss                 | -0.0371    |
|    n_updates            | 36350      |
|    policy_gradient_loss | 0.0373     |
|    std                  | 0.0797     |
|    value_loss           | 0.00122    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3637       |
|    time_elapsed         | 11800      |
|    total_timesteps      | 7448576    |
| train/                  |            |
|    approx_kl            | 0.32819292 |
|    clip_fraction        | 0.408      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.21       |
|    explained_variance   | 0.393      |
|    learning_rate        | 0.000548   |
|    loss                 | -0.0133    |
|    n_updates            | 36360      |
|    policy_gradient_loss | 0.00458    |
|    std                  | 0.0805     |
|    value_loss           | 0.00166    |
----------------------------------------
Eval num_timesteps=7450000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1         |
| time/                   |            |
|    total_timesteps      | 7450000    |
| train/                  |            |
|    approx_kl            | 0.49205437 |
|    clip_fraction        | 0.438      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.21       |
|    explained_variance   | 0.614      |
|    learning_rate        | 0.000548   |
|    loss                 | 0.0258     |
|    n_updates            | 36370      |
|    policy_gradient_loss | 0.0199     |
|    std                  | 0.08       |
|    value_loss           | 0.00105    |
----------------------------------------
box reached target
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 3638    |
|    time_elapsed    | 11804   |
|    total_timesteps | 7450624 |
--------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3639      |
|    time_elapsed         | 11807     |
|    total_timesteps      | 7452672   |
| train/                  |           |
|    approx_kl            | 1.2814491 |
|    clip_fraction        | 0.463     |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.26      |
|    explained_variance   | 0.831     |
|    learning_rate        | 0.000547  |
|    loss                 | -0.0308   |
|    n_updates            | 36380     |
|    policy_gradient_loss | -0.0157   |
|    std                  | 0.0768    |
|    value_loss           | 0.0371    |
---------------------------------------
box reached target
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3640      |
|    time_elapsed         | 11810     |
|    total_timesteps      | 7454720   |
| train/                  |           |
|    approx_kl            | 0.9527915 |
|    clip_fraction        | 0.46      |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.3       |
|    explained_variance   | 0.932     |
|    learning_rate        | 0.000547  |
|    loss                 | 0.00665   |
|    n_updates            | 36390     |
|    policy_gradient_loss | 0.0257    |
|    std                  | 0.0764    |
|    value_loss           | 0.0104    |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3641       |
|    time_elapsed         | 11813      |
|    total_timesteps      | 7456768    |
| train/                  |            |
|    approx_kl            | 0.71711314 |
|    clip_fraction        | 0.55       |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.31       |
|    explained_variance   | 0.919      |
|    learning_rate        | 0.000546   |
|    loss                 | -0.02      |
|    n_updates            | 36400      |
|    policy_gradient_loss | 0.0226     |
|    std                  | 0.0757     |
|    value_loss           | 0.0138     |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3642       |
|    time_elapsed         | 11816      |
|    total_timesteps      | 7458816    |
| train/                  |            |
|    approx_kl            | 0.33646065 |
|    clip_fraction        | 0.411      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.33       |
|    explained_variance   | 0.804      |
|    learning_rate        | 0.000546   |
|    loss                 | 0.0265     |
|    n_updates            | 36410      |
|    policy_gradient_loss | 0.000523   |
|    std                  | 0.0751     |
|    value_loss           | 0.00312    |
----------------------------------------
Eval num_timesteps=7460000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
--------------------------------------
| eval/                   |          |
|    mean_ep_length       | 300      |
|    mean_reward          | -1       |
| time/                   |          |
|    total_timesteps      | 7460000  |
| train/                  |          |
|    approx_kl            | 9.345575 |
|    clip_fraction        | 0.562    |
|    clip_range           | 0.2      |
|    entropy_loss         | 2.35     |
|    explained_variance   | 0.609    |
|    learning_rate        | 0.000546 |
|    loss                 | 0.00338  |
|    n_updates            | 36420    |
|    policy_gradient_loss | 0.00674  |
|    std                  | 0.074    |
|    value_loss           | 0.00302  |
--------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 3643    |
|    time_elapsed    | 11820   |
|    total_timesteps | 7460864 |
--------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3644      |
|    time_elapsed         | 11823     |
|    total_timesteps      | 7462912   |
| train/                  |           |
|    approx_kl            | 0.7534225 |
|    clip_fraction        | 0.478     |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.37      |
|    explained_variance   | 0.177     |
|    learning_rate        | 0.000545  |
|    loss                 | 0.0449    |
|    n_updates            | 36430     |
|    policy_gradient_loss | 0.0234    |
|    std                  | 0.0739    |
|    value_loss           | 0.00363   |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3645       |
|    time_elapsed         | 11826      |
|    total_timesteps      | 7464960    |
| train/                  |            |
|    approx_kl            | 0.46610978 |
|    clip_fraction        | 0.544      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.35       |
|    explained_variance   | 0.382      |
|    learning_rate        | 0.000545   |
|    loss                 | 0.0316     |
|    n_updates            | 36440      |
|    policy_gradient_loss | 0.0565     |
|    std                  | 0.0753     |
|    value_loss           | 0.00426    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3646       |
|    time_elapsed         | 11829      |
|    total_timesteps      | 7467008    |
| train/                  |            |
|    approx_kl            | 0.19690521 |
|    clip_fraction        | 0.406      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.35       |
|    explained_variance   | -0.586     |
|    learning_rate        | 0.000544   |
|    loss                 | 0.0128     |
|    n_updates            | 36450      |
|    policy_gradient_loss | 0.0327     |
|    std                  | 0.0741     |
|    value_loss           | 0.00362    |
----------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3647      |
|    time_elapsed         | 11832     |
|    total_timesteps      | 7469056   |
| train/                  |           |
|    approx_kl            | 2.3781652 |
|    clip_fraction        | 0.539     |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.37      |
|    explained_variance   | 0.416     |
|    learning_rate        | 0.000544  |
|    loss                 | -0.0141   |
|    n_updates            | 36460     |
|    policy_gradient_loss | 0.0125    |
|    std                  | 0.0736    |
|    value_loss           | 0.00136   |
---------------------------------------
Eval num_timesteps=7470000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1         |
| time/                   |            |
|    total_timesteps      | 7470000    |
| train/                  |            |
|    approx_kl            | 0.41082805 |
|    clip_fraction        | 0.523      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.38       |
|    explained_variance   | 0.923      |
|    learning_rate        | 0.000544   |
|    loss                 | 0.00922    |
|    n_updates            | 36470      |
|    policy_gradient_loss | 0.00802    |
|    std                  | 0.0734     |
|    value_loss           | 0.0117     |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 3648    |
|    time_elapsed    | 11836   |
|    total_timesteps | 7471104 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3649       |
|    time_elapsed         | 11839      |
|    total_timesteps      | 7473152    |
| train/                  |            |
|    approx_kl            | 0.29296058 |
|    clip_fraction        | 0.431      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.38       |
|    explained_variance   | -0.539     |
|    learning_rate        | 0.000543   |
|    loss                 | -0.0271    |
|    n_updates            | 36480      |
|    policy_gradient_loss | 0.0121     |
|    std                  | 0.0731     |
|    value_loss           | 0.00235    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3650       |
|    time_elapsed         | 11842      |
|    total_timesteps      | 7475200    |
| train/                  |            |
|    approx_kl            | 0.81210244 |
|    clip_fraction        | 0.529      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.37       |
|    explained_variance   | 0.434      |
|    learning_rate        | 0.000543   |
|    loss                 | 0.00109    |
|    n_updates            | 36490      |
|    policy_gradient_loss | 0.0202     |
|    std                  | 0.0742     |
|    value_loss           | 0.00395    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3651       |
|    time_elapsed         | 11845      |
|    total_timesteps      | 7477248    |
| train/                  |            |
|    approx_kl            | 0.40130794 |
|    clip_fraction        | 0.403      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.37       |
|    explained_variance   | 0.0352     |
|    learning_rate        | 0.000542   |
|    loss                 | -0.00604   |
|    n_updates            | 36500      |
|    policy_gradient_loss | -0.00327   |
|    std                  | 0.0736     |
|    value_loss           | 0.00173    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3652       |
|    time_elapsed         | 11848      |
|    total_timesteps      | 7479296    |
| train/                  |            |
|    approx_kl            | 0.59982413 |
|    clip_fraction        | 0.52       |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.4        |
|    explained_variance   | 0.351      |
|    learning_rate        | 0.000542   |
|    loss                 | 0.0243     |
|    n_updates            | 36510      |
|    policy_gradient_loss | 0.0139     |
|    std                  | 0.0721     |
|    value_loss           | 0.00843    |
----------------------------------------
Eval num_timesteps=7480000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1         |
| time/                   |            |
|    total_timesteps      | 7480000    |
| train/                  |            |
|    approx_kl            | 0.30468535 |
|    clip_fraction        | 0.413      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.44       |
|    explained_variance   | 0.493      |
|    learning_rate        | 0.000542   |
|    loss                 | 0.00137    |
|    n_updates            | 36520      |
|    policy_gradient_loss | 0.0136     |
|    std                  | 0.0709     |
|    value_loss           | 0.00122    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 3653    |
|    time_elapsed    | 11852   |
|    total_timesteps | 7481344 |
--------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3654       |
|    time_elapsed         | 11855      |
|    total_timesteps      | 7483392    |
| train/                  |            |
|    approx_kl            | 0.82664216 |
|    clip_fraction        | 0.495      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.46       |
|    explained_variance   | -0.256     |
|    learning_rate        | 0.000541   |
|    loss                 | 0.131      |
|    n_updates            | 36530      |
|    policy_gradient_loss | 0.025      |
|    std                  | 0.0702     |
|    value_loss           | 0.00572    |
----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3655      |
|    time_elapsed         | 11858     |
|    total_timesteps      | 7485440   |
| train/                  |           |
|    approx_kl            | 0.8363216 |
|    clip_fraction        | 0.613     |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.46      |
|    explained_variance   | 0.192     |
|    learning_rate        | 0.000541  |
|    loss                 | 0.0367    |
|    n_updates            | 36540     |
|    policy_gradient_loss | 0.0526    |
|    std                  | 0.0714    |
|    value_loss           | 0.0467    |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3656       |
|    time_elapsed         | 11862      |
|    total_timesteps      | 7487488    |
| train/                  |            |
|    approx_kl            | 0.25960356 |
|    clip_fraction        | 0.462      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.4        |
|    explained_variance   | 0.268      |
|    learning_rate        | 0.00054    |
|    loss                 | 0.0109     |
|    n_updates            | 36550      |
|    policy_gradient_loss | 0.0311     |
|    std                  | 0.0738     |
|    value_loss           | 0.00156    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3657       |
|    time_elapsed         | 11865      |
|    total_timesteps      | 7489536    |
| train/                  |            |
|    approx_kl            | 0.97969264 |
|    clip_fraction        | 0.588      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.35       |
|    explained_variance   | 0.634      |
|    learning_rate        | 0.00054    |
|    loss                 | -0.0159    |
|    n_updates            | 36560      |
|    policy_gradient_loss | 0.0582     |
|    std                  | 0.0751     |
|    value_loss           | 0.00214    |
----------------------------------------
Eval num_timesteps=7490000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 300       |
|    mean_reward          | -1        |
| time/                   |           |
|    total_timesteps      | 7490000   |
| train/                  |           |
|    approx_kl            | 0.4214744 |
|    clip_fraction        | 0.469     |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.34      |
|    explained_variance   | 0.331     |
|    learning_rate        | 0.00054   |
|    loss                 | 0.0743    |
|    n_updates            | 36570     |
|    policy_gradient_loss | 0.019     |
|    std                  | 0.0751    |
|    value_loss           | 0.00198   |
---------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 3658    |
|    time_elapsed    | 11869   |
|    total_timesteps | 7491584 |
--------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3659      |
|    time_elapsed         | 11872     |
|    total_timesteps      | 7493632   |
| train/                  |           |
|    approx_kl            | 0.5077281 |
|    clip_fraction        | 0.464     |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.36      |
|    explained_variance   | 0.108     |
|    learning_rate        | 0.000539  |
|    loss                 | 0.00929   |
|    n_updates            | 36580     |
|    policy_gradient_loss | 0.0133    |
|    std                  | 0.0736    |
|    value_loss           | 0.00175   |
---------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3660      |
|    time_elapsed         | 11875     |
|    total_timesteps      | 7495680   |
| train/                  |           |
|    approx_kl            | 3.1944985 |
|    clip_fraction        | 0.566     |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.36      |
|    explained_variance   | 0.254     |
|    learning_rate        | 0.000539  |
|    loss                 | 0.0582    |
|    n_updates            | 36590     |
|    policy_gradient_loss | 0.0129    |
|    std                  | 0.0745    |
|    value_loss           | 0.00197   |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3661       |
|    time_elapsed         | 11878      |
|    total_timesteps      | 7497728    |
| train/                  |            |
|    approx_kl            | 0.25989377 |
|    clip_fraction        | 0.457      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.33       |
|    explained_variance   | 0.468      |
|    learning_rate        | 0.000538   |
|    loss                 | 0.0433     |
|    n_updates            | 36600      |
|    policy_gradient_loss | 0.026      |
|    std                  | 0.0758     |
|    value_loss           | 0.00126    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3662       |
|    time_elapsed         | 11881      |
|    total_timesteps      | 7499776    |
| train/                  |            |
|    approx_kl            | 0.56544375 |
|    clip_fraction        | 0.494      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.28       |
|    explained_variance   | 0.38       |
|    learning_rate        | 0.000538   |
|    loss                 | -0.0096    |
|    n_updates            | 36610      |
|    policy_gradient_loss | 0.0172     |
|    std                  | 0.0777     |
|    value_loss           | 0.00267    |
----------------------------------------
Eval num_timesteps=7500000, episode_reward=-0.95 +/- 0.09
Episode length: 300.00 +/- 0.00
--------------------------------------
| eval/                   |          |
|    mean_ep_length       | 300      |
|    mean_reward          | -0.953   |
| time/                   |          |
|    total_timesteps      | 7500000  |
| train/                  |          |
|    approx_kl            | 4.626685 |
|    clip_fraction        | 0.465    |
|    clip_range           | 0.2      |
|    entropy_loss         | 2.27     |
|    explained_variance   | -0.257   |
|    learning_rate        | 0.000538 |
|    loss                 | -0.00253 |
|    n_updates            | 36620    |
|    policy_gradient_loss | 0.00662  |
|    std                  | 0.0771   |
|    value_loss           | 0.00161  |
--------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 3663    |
|    time_elapsed    | 11885   |
|    total_timesteps | 7501824 |
--------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3664      |
|    time_elapsed         | 11888     |
|    total_timesteps      | 7503872   |
| train/                  |           |
|    approx_kl            | 0.4080218 |
|    clip_fraction        | 0.43      |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.28      |
|    explained_variance   | 0.532     |
|    learning_rate        | 0.000537  |
|    loss                 | -0.0226   |
|    n_updates            | 36630     |
|    policy_gradient_loss | 0.017     |
|    std                  | 0.0774    |
|    value_loss           | 0.00124   |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3665       |
|    time_elapsed         | 11891      |
|    total_timesteps      | 7505920    |
| train/                  |            |
|    approx_kl            | 0.37263143 |
|    clip_fraction        | 0.486      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.28       |
|    explained_variance   | 0.403      |
|    learning_rate        | 0.000537   |
|    loss                 | -0.0305    |
|    n_updates            | 36640      |
|    policy_gradient_loss | 0.0365     |
|    std                  | 0.0763     |
|    value_loss           | 0.00157    |
----------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3666      |
|    time_elapsed         | 11894     |
|    total_timesteps      | 7507968   |
| train/                  |           |
|    approx_kl            | 2.8509388 |
|    clip_fraction        | 0.506     |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.31      |
|    explained_variance   | 0.76      |
|    learning_rate        | 0.000536  |
|    loss                 | 0.00666   |
|    n_updates            | 36650     |
|    policy_gradient_loss | 0.00728   |
|    std                  | 0.0758    |
|    value_loss           | 0.00092   |
---------------------------------------
box reached target
box reached target
Eval num_timesteps=7510000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1         |
| time/                   |            |
|    total_timesteps      | 7510000    |
| train/                  |            |
|    approx_kl            | 0.38029072 |
|    clip_fraction        | 0.563      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.3        |
|    explained_variance   | 0.397      |
|    learning_rate        | 0.000536   |
|    loss                 | 0.00478    |
|    n_updates            | 36660      |
|    policy_gradient_loss | 0.0174     |
|    std                  | 0.0764     |
|    value_loss           | 0.0283     |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 3667    |
|    time_elapsed    | 11898   |
|    total_timesteps | 7510016 |
--------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3668       |
|    time_elapsed         | 11901      |
|    total_timesteps      | 7512064    |
| train/                  |            |
|    approx_kl            | 0.26567024 |
|    clip_fraction        | 0.47       |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.31       |
|    explained_variance   | 0.958      |
|    learning_rate        | 0.000536   |
|    loss                 | 0.136      |
|    n_updates            | 36670      |
|    policy_gradient_loss | 0.0238     |
|    std                  | 0.0763     |
|    value_loss           | 0.0137     |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3669       |
|    time_elapsed         | 11904      |
|    total_timesteps      | 7514112    |
| train/                  |            |
|    approx_kl            | 0.17575888 |
|    clip_fraction        | 0.497      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.3        |
|    explained_variance   | 0.965      |
|    learning_rate        | 0.000535   |
|    loss                 | -0.0525    |
|    n_updates            | 36680      |
|    policy_gradient_loss | 0.0252     |
|    std                  | 0.077      |
|    value_loss           | 0.00365    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3670       |
|    time_elapsed         | 11907      |
|    total_timesteps      | 7516160    |
| train/                  |            |
|    approx_kl            | 0.53995854 |
|    clip_fraction        | 0.457      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.26       |
|    explained_variance   | 0.241      |
|    learning_rate        | 0.000535   |
|    loss                 | -0.0195    |
|    n_updates            | 36690      |
|    policy_gradient_loss | 0.0115     |
|    std                  | 0.0784     |
|    value_loss           | 0.00308    |
----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3671      |
|    time_elapsed         | 11910     |
|    total_timesteps      | 7518208   |
| train/                  |           |
|    approx_kl            | 0.2531186 |
|    clip_fraction        | 0.371     |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.25      |
|    explained_variance   | 0.375     |
|    learning_rate        | 0.000534  |
|    loss                 | 0.0233    |
|    n_updates            | 36700     |
|    policy_gradient_loss | 0.00787   |
|    std                  | 0.0788    |
|    value_loss           | 0.00136   |
---------------------------------------
Eval num_timesteps=7520000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1         |
| time/                   |            |
|    total_timesteps      | 7520000    |
| train/                  |            |
|    approx_kl            | 0.30569065 |
|    clip_fraction        | 0.395      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.25       |
|    explained_variance   | 0.744      |
|    learning_rate        | 0.000534   |
|    loss                 | 0.0399     |
|    n_updates            | 36710      |
|    policy_gradient_loss | 0.0107     |
|    std                  | 0.0783     |
|    value_loss           | 0.000752   |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 3672    |
|    time_elapsed    | 11914   |
|    total_timesteps | 7520256 |
--------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3673      |
|    time_elapsed         | 11917     |
|    total_timesteps      | 7522304   |
| train/                  |           |
|    approx_kl            | 0.5630065 |
|    clip_fraction        | 0.38      |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.28      |
|    explained_variance   | -1.29     |
|    learning_rate        | 0.000534  |
|    loss                 | -0.0368   |
|    n_updates            | 36720     |
|    policy_gradient_loss | -0.0043   |
|    std                  | 0.0758    |
|    value_loss           | 0.00255   |
---------------------------------------
box reached target
box reached target
--------------------------------------
| time/                   |          |
|    fps                  | 631      |
|    iterations           | 3674     |
|    time_elapsed         | 11920    |
|    total_timesteps      | 7524352  |
| train/                  |          |
|    approx_kl            | 0.556034 |
|    clip_fraction        | 0.42     |
|    clip_range           | 0.2      |
|    entropy_loss         | 2.32     |
|    explained_variance   | 0.4      |
|    learning_rate        | 0.000533 |
|    loss                 | 0.117    |
|    n_updates            | 36730    |
|    policy_gradient_loss | 0.011    |
|    std                  | 0.0754   |
|    value_loss           | 0.00113  |
--------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3675       |
|    time_elapsed         | 11923      |
|    total_timesteps      | 7526400    |
| train/                  |            |
|    approx_kl            | 0.74974895 |
|    clip_fraction        | 0.546      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.32       |
|    explained_variance   | 0.909      |
|    learning_rate        | 0.000533   |
|    loss                 | -0.015     |
|    n_updates            | 36740      |
|    policy_gradient_loss | 0.0275     |
|    std                  | 0.0762     |
|    value_loss           | 0.0136     |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3676       |
|    time_elapsed         | 11926      |
|    total_timesteps      | 7528448    |
| train/                  |            |
|    approx_kl            | 0.33666185 |
|    clip_fraction        | 0.461      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.31       |
|    explained_variance   | 0.694      |
|    learning_rate        | 0.000532   |
|    loss                 | 0.0911     |
|    n_updates            | 36750      |
|    policy_gradient_loss | 0.0211     |
|    std                  | 0.076      |
|    value_loss           | 0.00163    |
----------------------------------------
Eval num_timesteps=7530000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 300       |
|    mean_reward          | -1        |
| time/                   |           |
|    total_timesteps      | 7530000   |
| train/                  |           |
|    approx_kl            | 0.6357769 |
|    clip_fraction        | 0.425     |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.31      |
|    explained_variance   | 0.157     |
|    learning_rate        | 0.000532  |
|    loss                 | 0.0014    |
|    n_updates            | 36760     |
|    policy_gradient_loss | 0.00984   |
|    std                  | 0.0761    |
|    value_loss           | 0.00209   |
---------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 3677    |
|    time_elapsed    | 11930   |
|    total_timesteps | 7530496 |
--------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3678      |
|    time_elapsed         | 11933     |
|    total_timesteps      | 7532544   |
| train/                  |           |
|    approx_kl            | 0.3997949 |
|    clip_fraction        | 0.516     |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.3       |
|    explained_variance   | -0.145    |
|    learning_rate        | 0.000532  |
|    loss                 | -0.0347   |
|    n_updates            | 36770     |
|    policy_gradient_loss | 0.00902   |
|    std                  | 0.0762    |
|    value_loss           | 0.00301   |
---------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3679      |
|    time_elapsed         | 11936     |
|    total_timesteps      | 7534592   |
| train/                  |           |
|    approx_kl            | 1.7692344 |
|    clip_fraction        | 0.422     |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.3       |
|    explained_variance   | 0.416     |
|    learning_rate        | 0.000531  |
|    loss                 | -0.00753  |
|    n_updates            | 36780     |
|    policy_gradient_loss | -0.00315  |
|    std                  | 0.0764    |
|    value_loss           | 0.0028    |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3680       |
|    time_elapsed         | 11939      |
|    total_timesteps      | 7536640    |
| train/                  |            |
|    approx_kl            | 0.24956863 |
|    clip_fraction        | 0.424      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.3        |
|    explained_variance   | -0.0683    |
|    learning_rate        | 0.000531   |
|    loss                 | -0.0199    |
|    n_updates            | 36790      |
|    policy_gradient_loss | 0.0249     |
|    std                  | 0.077      |
|    value_loss           | 0.00153    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3681       |
|    time_elapsed         | 11943      |
|    total_timesteps      | 7538688    |
| train/                  |            |
|    approx_kl            | 0.28466225 |
|    clip_fraction        | 0.441      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.27       |
|    explained_variance   | -0.783     |
|    learning_rate        | 0.00053    |
|    loss                 | 0.00426    |
|    n_updates            | 36800      |
|    policy_gradient_loss | 0.0463     |
|    std                  | 0.0785     |
|    value_loss           | 0.00464    |
----------------------------------------
Eval num_timesteps=7540000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 300       |
|    mean_reward          | -1        |
| time/                   |           |
|    total_timesteps      | 7540000   |
| train/                  |           |
|    approx_kl            | 0.5186536 |
|    clip_fraction        | 0.424     |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.23      |
|    explained_variance   | 0.057     |
|    learning_rate        | 0.00053   |
|    loss                 | 0.0141    |
|    n_updates            | 36810     |
|    policy_gradient_loss | 0.0268    |
|    std                  | 0.0794    |
|    value_loss           | 0.000978  |
---------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 3682    |
|    time_elapsed    | 11947   |
|    total_timesteps | 7540736 |
--------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3683      |
|    time_elapsed         | 11950     |
|    total_timesteps      | 7542784   |
| train/                  |           |
|    approx_kl            | 0.3164182 |
|    clip_fraction        | 0.432     |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.22      |
|    explained_variance   | 0.306     |
|    learning_rate        | 0.00053   |
|    loss                 | -0.0471   |
|    n_updates            | 36820     |
|    policy_gradient_loss | 0.000835  |
|    std                  | 0.0795    |
|    value_loss           | 0.00116   |
---------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3684       |
|    time_elapsed         | 11953      |
|    total_timesteps      | 7544832    |
| train/                  |            |
|    approx_kl            | 0.20390244 |
|    clip_fraction        | 0.422      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.22       |
|    explained_variance   | 0.209      |
|    learning_rate        | 0.000529   |
|    loss                 | -0.0136    |
|    n_updates            | 36830      |
|    policy_gradient_loss | 0.0197     |
|    std                  | 0.08       |
|    value_loss           | 0.00151    |
----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3685      |
|    time_elapsed         | 11956     |
|    total_timesteps      | 7546880   |
| train/                  |           |
|    approx_kl            | 0.1856459 |
|    clip_fraction        | 0.453     |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.23      |
|    explained_variance   | 0.721     |
|    learning_rate        | 0.000529  |
|    loss                 | 0.018     |
|    n_updates            | 36840     |
|    policy_gradient_loss | 0.0149    |
|    std                  | 0.0793    |
|    value_loss           | 0.0153    |
---------------------------------------
--------------------------------------
| time/                   |          |
|    fps                  | 631      |
|    iterations           | 3686     |
|    time_elapsed         | 11959    |
|    total_timesteps      | 7548928  |
| train/                  |          |
|    approx_kl            | 0.414172 |
|    clip_fraction        | 0.507    |
|    clip_range           | 0.2      |
|    entropy_loss         | 2.24     |
|    explained_variance   | 0.506    |
|    learning_rate        | 0.000528 |
|    loss                 | 0.0239   |
|    n_updates            | 36850    |
|    policy_gradient_loss | 0.0345   |
|    std                  | 0.0784   |
|    value_loss           | 0.004    |
--------------------------------------
box reached target
Eval num_timesteps=7550000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 300       |
|    mean_reward          | -1        |
| time/                   |           |
|    total_timesteps      | 7550000   |
| train/                  |           |
|    approx_kl            | 0.4854916 |
|    clip_fraction        | 0.44      |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.27      |
|    explained_variance   | 0.299     |
|    learning_rate        | 0.000528  |
|    loss                 | 0.0589    |
|    n_updates            | 36860     |
|    policy_gradient_loss | 0.00208   |
|    std                  | 0.0769    |
|    value_loss           | 0.00285   |
---------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 3687    |
|    time_elapsed    | 11963   |
|    total_timesteps | 7550976 |
--------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3688      |
|    time_elapsed         | 11966     |
|    total_timesteps      | 7553024   |
| train/                  |           |
|    approx_kl            | 1.7556354 |
|    clip_fraction        | 0.459     |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.33      |
|    explained_variance   | 0.959     |
|    learning_rate        | 0.000528  |
|    loss                 | 0.154     |
|    n_updates            | 36870     |
|    policy_gradient_loss | 0.0172    |
|    std                  | 0.0746    |
|    value_loss           | 0.00643   |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3689       |
|    time_elapsed         | 11969      |
|    total_timesteps      | 7555072    |
| train/                  |            |
|    approx_kl            | 0.44315708 |
|    clip_fraction        | 0.432      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.36       |
|    explained_variance   | -0.506     |
|    learning_rate        | 0.000527   |
|    loss                 | 0.124      |
|    n_updates            | 36880      |
|    policy_gradient_loss | 0.0154     |
|    std                  | 0.0746     |
|    value_loss           | 0.00256    |
----------------------------------------
--------------------------------------
| time/                   |          |
|    fps                  | 631      |
|    iterations           | 3690     |
|    time_elapsed         | 11972    |
|    total_timesteps      | 7557120  |
| train/                  |          |
|    approx_kl            | 4.625353 |
|    clip_fraction        | 0.456    |
|    clip_range           | 0.2      |
|    entropy_loss         | 2.35     |
|    explained_variance   | 0.539    |
|    learning_rate        | 0.000527 |
|    loss                 | -0.0446  |
|    n_updates            | 36890    |
|    policy_gradient_loss | 0.0106   |
|    std                  | 0.0741   |
|    value_loss           | 0.00184  |
--------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3691       |
|    time_elapsed         | 11975      |
|    total_timesteps      | 7559168    |
| train/                  |            |
|    approx_kl            | 0.20569575 |
|    clip_fraction        | 0.477      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.35       |
|    explained_variance   | 0.196      |
|    learning_rate        | 0.000526   |
|    loss                 | 0.0945     |
|    n_updates            | 36900      |
|    policy_gradient_loss | 0.0129     |
|    std                  | 0.075      |
|    value_loss           | 0.00532    |
----------------------------------------
Eval num_timesteps=7560000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 300       |
|    mean_reward          | -1        |
| time/                   |           |
|    total_timesteps      | 7560000   |
| train/                  |           |
|    approx_kl            | 0.3211078 |
|    clip_fraction        | 0.442     |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.33      |
|    explained_variance   | -0.0842   |
|    learning_rate        | 0.000526  |
|    loss                 | -0.0328   |
|    n_updates            | 36910     |
|    policy_gradient_loss | 0.0342    |
|    std                  | 0.076     |
|    value_loss           | 0.00156   |
---------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 3692    |
|    time_elapsed    | 11979   |
|    total_timesteps | 7561216 |
--------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3693      |
|    time_elapsed         | 11982     |
|    total_timesteps      | 7563264   |
| train/                  |           |
|    approx_kl            | 0.3007038 |
|    clip_fraction        | 0.434     |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.3       |
|    explained_variance   | -0.499    |
|    learning_rate        | 0.000526  |
|    loss                 | -0.00438  |
|    n_updates            | 36920     |
|    policy_gradient_loss | 0.0104    |
|    std                  | 0.0773    |
|    value_loss           | 0.00821   |
---------------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3694       |
|    time_elapsed         | 11985      |
|    total_timesteps      | 7565312    |
| train/                  |            |
|    approx_kl            | 0.24439627 |
|    clip_fraction        | 0.489      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.3        |
|    explained_variance   | 0.674      |
|    learning_rate        | 0.000525   |
|    loss                 | 0.0487     |
|    n_updates            | 36930      |
|    policy_gradient_loss | 0.0179     |
|    std                  | 0.0763     |
|    value_loss           | 0.0145     |
----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3695      |
|    time_elapsed         | 11988     |
|    total_timesteps      | 7567360   |
| train/                  |           |
|    approx_kl            | 0.3667767 |
|    clip_fraction        | 0.47      |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.33      |
|    explained_variance   | 0.845     |
|    learning_rate        | 0.000525  |
|    loss                 | -0.000364 |
|    n_updates            | 36940     |
|    policy_gradient_loss | 0.021     |
|    std                  | 0.0754    |
|    value_loss           | 0.0219    |
---------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3696      |
|    time_elapsed         | 11991     |
|    total_timesteps      | 7569408   |
| train/                  |           |
|    approx_kl            | 0.8414781 |
|    clip_fraction        | 0.456     |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.35      |
|    explained_variance   | 0.517     |
|    learning_rate        | 0.000524  |
|    loss                 | -0.0222   |
|    n_updates            | 36950     |
|    policy_gradient_loss | 0.0067    |
|    std                  | 0.0747    |
|    value_loss           | 0.00645   |
---------------------------------------
box reached target
Eval num_timesteps=7570000, episode_reward=0.24 +/- 2.47
Episode length: 271.00 +/- 58.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 271        |
|    mean_reward          | 0.237      |
| time/                   |            |
|    total_timesteps      | 7570000    |
| train/                  |            |
|    approx_kl            | 0.23404959 |
|    clip_fraction        | 0.47       |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.34       |
|    explained_variance   | 0.579      |
|    learning_rate        | 0.000524   |
|    loss                 | -0.031     |
|    n_updates            | 36960      |
|    policy_gradient_loss | 0.0166     |
|    std                  | 0.0756     |
|    value_loss           | 0.00372    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 3697    |
|    time_elapsed    | 11995   |
|    total_timesteps | 7571456 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3698       |
|    time_elapsed         | 11998      |
|    total_timesteps      | 7573504    |
| train/                  |            |
|    approx_kl            | 0.37687865 |
|    clip_fraction        | 0.47       |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.32       |
|    explained_variance   | 0.487      |
|    learning_rate        | 0.000524   |
|    loss                 | 0.0104     |
|    n_updates            | 36970      |
|    policy_gradient_loss | 0.00607    |
|    std                  | 0.0757     |
|    value_loss           | 0.00289    |
----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3699      |
|    time_elapsed         | 12001     |
|    total_timesteps      | 7575552   |
| train/                  |           |
|    approx_kl            | 1.2452264 |
|    clip_fraction        | 0.537     |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.33      |
|    explained_variance   | 0.838     |
|    learning_rate        | 0.000523  |
|    loss                 | 0.0342    |
|    n_updates            | 36980     |
|    policy_gradient_loss | 0.00181   |
|    std                  | 0.0747    |
|    value_loss           | 0.00229   |
---------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3700      |
|    time_elapsed         | 12004     |
|    total_timesteps      | 7577600   |
| train/                  |           |
|    approx_kl            | 1.0760801 |
|    clip_fraction        | 0.409     |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.36      |
|    explained_variance   | 0.66      |
|    learning_rate        | 0.000523  |
|    loss                 | -0.0212   |
|    n_updates            | 36990     |
|    policy_gradient_loss | 0.000865  |
|    std                  | 0.0746    |
|    value_loss           | 0.00194   |
---------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3701       |
|    time_elapsed         | 12007      |
|    total_timesteps      | 7579648    |
| train/                  |            |
|    approx_kl            | 0.43921003 |
|    clip_fraction        | 0.53       |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.35       |
|    explained_variance   | 0.831      |
|    learning_rate        | 0.000522   |
|    loss                 | 0.034      |
|    n_updates            | 37000      |
|    policy_gradient_loss | 0.0147     |
|    std                  | 0.0747     |
|    value_loss           | 0.00351    |
----------------------------------------
Eval num_timesteps=7580000, episode_reward=-0.67 +/- 0.66
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -0.669     |
| time/                   |            |
|    total_timesteps      | 7580000    |
| train/                  |            |
|    approx_kl            | 0.34803167 |
|    clip_fraction        | 0.493      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.36       |
|    explained_variance   | 0.921      |
|    learning_rate        | 0.000522   |
|    loss                 | -0.00594   |
|    n_updates            | 37010      |
|    policy_gradient_loss | 0.0373     |
|    std                  | 0.0739     |
|    value_loss           | 0.00309    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 3702    |
|    time_elapsed    | 12011   |
|    total_timesteps | 7581696 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3703       |
|    time_elapsed         | 12014      |
|    total_timesteps      | 7583744    |
| train/                  |            |
|    approx_kl            | 0.27258542 |
|    clip_fraction        | 0.44       |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.37       |
|    explained_variance   | -0.275     |
|    learning_rate        | 0.000522   |
|    loss                 | -3.83e-05  |
|    n_updates            | 37020      |
|    policy_gradient_loss | 0.00682    |
|    std                  | 0.0742     |
|    value_loss           | 0.00146    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3704       |
|    time_elapsed         | 12017      |
|    total_timesteps      | 7585792    |
| train/                  |            |
|    approx_kl            | 0.30417722 |
|    clip_fraction        | 0.441      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.36       |
|    explained_variance   | -0.0242    |
|    learning_rate        | 0.000521   |
|    loss                 | -0.028     |
|    n_updates            | 37030      |
|    policy_gradient_loss | 0.00524    |
|    std                  | 0.0749     |
|    value_loss           | 0.00209    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3705       |
|    time_elapsed         | 12020      |
|    total_timesteps      | 7587840    |
| train/                  |            |
|    approx_kl            | 0.48025548 |
|    clip_fraction        | 0.464      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.34       |
|    explained_variance   | 0.157      |
|    learning_rate        | 0.000521   |
|    loss                 | -0.0299    |
|    n_updates            | 37040      |
|    policy_gradient_loss | 0.0229     |
|    std                  | 0.0754     |
|    value_loss           | 0.00214    |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3706       |
|    time_elapsed         | 12023      |
|    total_timesteps      | 7589888    |
| train/                  |            |
|    approx_kl            | 0.49861097 |
|    clip_fraction        | 0.44       |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.34       |
|    explained_variance   | 0.313      |
|    learning_rate        | 0.00052    |
|    loss                 | 0.0124     |
|    n_updates            | 37050      |
|    policy_gradient_loss | 0.0233     |
|    std                  | 0.075      |
|    value_loss           | 0.00179    |
----------------------------------------
Eval num_timesteps=7590000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 300       |
|    mean_reward          | -1        |
| time/                   |           |
|    total_timesteps      | 7590000   |
| train/                  |           |
|    approx_kl            | 1.2489612 |
|    clip_fraction        | 0.504     |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.36      |
|    explained_variance   | 0.206     |
|    learning_rate        | 0.00052   |
|    loss                 | 0.0283    |
|    n_updates            | 37060     |
|    policy_gradient_loss | 0.0208    |
|    std                  | 0.0738    |
|    value_loss           | 0.0543    |
---------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 3707    |
|    time_elapsed    | 12027   |
|    total_timesteps | 7591936 |
--------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3708      |
|    time_elapsed         | 12030     |
|    total_timesteps      | 7593984   |
| train/                  |           |
|    approx_kl            | 0.5297261 |
|    clip_fraction        | 0.468     |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.37      |
|    explained_variance   | 0.263     |
|    learning_rate        | 0.00052   |
|    loss                 | -0.034    |
|    n_updates            | 37070     |
|    policy_gradient_loss | 0.0207    |
|    std                  | 0.0741    |
|    value_loss           | 0.00298   |
---------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3709      |
|    time_elapsed         | 12033     |
|    total_timesteps      | 7596032   |
| train/                  |           |
|    approx_kl            | 0.4025135 |
|    clip_fraction        | 0.465     |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.37      |
|    explained_variance   | 0.367     |
|    learning_rate        | 0.000519  |
|    loss                 | 0.00382   |
|    n_updates            | 37080     |
|    policy_gradient_loss | 0.0144    |
|    std                  | 0.0738    |
|    value_loss           | 0.00175   |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3710       |
|    time_elapsed         | 12037      |
|    total_timesteps      | 7598080    |
| train/                  |            |
|    approx_kl            | 0.11901645 |
|    clip_fraction        | 0.423      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.36       |
|    explained_variance   | 0.571      |
|    learning_rate        | 0.000519   |
|    loss                 | -0.00752   |
|    n_updates            | 37090      |
|    policy_gradient_loss | 0.0116     |
|    std                  | 0.0743     |
|    value_loss           | 0.00165    |
----------------------------------------
Eval num_timesteps=7600000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1         |
| time/                   |            |
|    total_timesteps      | 7600000    |
| train/                  |            |
|    approx_kl            | 0.36649978 |
|    clip_fraction        | 0.443      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.37       |
|    explained_variance   | 0.654      |
|    learning_rate        | 0.000518   |
|    loss                 | 0.0812     |
|    n_updates            | 37100      |
|    policy_gradient_loss | 0.0225     |
|    std                  | 0.074      |
|    value_loss           | 0.00141    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 3711    |
|    time_elapsed    | 12040   |
|    total_timesteps | 7600128 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3712       |
|    time_elapsed         | 12044      |
|    total_timesteps      | 7602176    |
| train/                  |            |
|    approx_kl            | 0.27739355 |
|    clip_fraction        | 0.385      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.37       |
|    explained_variance   | -0.35      |
|    learning_rate        | 0.000518   |
|    loss                 | -0.0389    |
|    n_updates            | 37110      |
|    policy_gradient_loss | 0.0129     |
|    std                  | 0.0738     |
|    value_loss           | 0.00216    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3713       |
|    time_elapsed         | 12047      |
|    total_timesteps      | 7604224    |
| train/                  |            |
|    approx_kl            | 0.18051979 |
|    clip_fraction        | 0.412      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.38       |
|    explained_variance   | 0.251      |
|    learning_rate        | 0.000518   |
|    loss                 | 0.0385     |
|    n_updates            | 37120      |
|    policy_gradient_loss | 0.00116    |
|    std                  | 0.0737     |
|    value_loss           | 0.00148    |
----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3714      |
|    time_elapsed         | 12050     |
|    total_timesteps      | 7606272   |
| train/                  |           |
|    approx_kl            | 0.2930959 |
|    clip_fraction        | 0.409     |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.37      |
|    explained_variance   | 0.768     |
|    learning_rate        | 0.000517  |
|    loss                 | -0.0048   |
|    n_updates            | 37130     |
|    policy_gradient_loss | 0.028     |
|    std                  | 0.0738    |
|    value_loss           | 0.00342   |
---------------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3715       |
|    time_elapsed         | 12053      |
|    total_timesteps      | 7608320    |
| train/                  |            |
|    approx_kl            | 0.23389703 |
|    clip_fraction        | 0.436      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.35       |
|    explained_variance   | 0.582      |
|    learning_rate        | 0.000517   |
|    loss                 | -0.00843   |
|    n_updates            | 37140      |
|    policy_gradient_loss | 0.024      |
|    std                  | 0.0753     |
|    value_loss           | 0.00106    |
----------------------------------------
Eval num_timesteps=7610000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 300       |
|    mean_reward          | -1        |
| time/                   |           |
|    total_timesteps      | 7610000   |
| train/                  |           |
|    approx_kl            | 0.2351951 |
|    clip_fraction        | 0.477     |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.33      |
|    explained_variance   | 0.698     |
|    learning_rate        | 0.000516  |
|    loss                 | -0.00742  |
|    n_updates            | 37150     |
|    policy_gradient_loss | 0.0319    |
|    std                  | 0.0754    |
|    value_loss           | 0.0177    |
---------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 3716    |
|    time_elapsed    | 12057   |
|    total_timesteps | 7610368 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3717       |
|    time_elapsed         | 12060      |
|    total_timesteps      | 7612416    |
| train/                  |            |
|    approx_kl            | 0.73446417 |
|    clip_fraction        | 0.477      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.32       |
|    explained_variance   | 0.137      |
|    learning_rate        | 0.000516   |
|    loss                 | 0.0121     |
|    n_updates            | 37160      |
|    policy_gradient_loss | 0.00299    |
|    std                  | 0.0764     |
|    value_loss           | 0.00222    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3718       |
|    time_elapsed         | 12063      |
|    total_timesteps      | 7614464    |
| train/                  |            |
|    approx_kl            | 0.42360428 |
|    clip_fraction        | 0.472      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.29       |
|    explained_variance   | 0.81       |
|    learning_rate        | 0.000516   |
|    loss                 | 0.0736     |
|    n_updates            | 37170      |
|    policy_gradient_loss | 0.0134     |
|    std                  | 0.0774     |
|    value_loss           | 0.00534    |
----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3719      |
|    time_elapsed         | 12066     |
|    total_timesteps      | 7616512   |
| train/                  |           |
|    approx_kl            | 0.2969566 |
|    clip_fraction        | 0.471     |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.28      |
|    explained_variance   | -0.139    |
|    learning_rate        | 0.000515  |
|    loss                 | 0.00491   |
|    n_updates            | 37180     |
|    policy_gradient_loss | 0.00829   |
|    std                  | 0.0768    |
|    value_loss           | 0.00156   |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3720       |
|    time_elapsed         | 12069      |
|    total_timesteps      | 7618560    |
| train/                  |            |
|    approx_kl            | 0.50283146 |
|    clip_fraction        | 0.43       |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.31       |
|    explained_variance   | 0.0737     |
|    learning_rate        | 0.000515   |
|    loss                 | 0.0465     |
|    n_updates            | 37190      |
|    policy_gradient_loss | 0.0178     |
|    std                  | 0.0761     |
|    value_loss           | 0.00142    |
----------------------------------------
Eval num_timesteps=7620000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1         |
| time/                   |            |
|    total_timesteps      | 7620000    |
| train/                  |            |
|    approx_kl            | 0.39493656 |
|    clip_fraction        | 0.422      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.33       |
|    explained_variance   | 0.408      |
|    learning_rate        | 0.000514   |
|    loss                 | -0.005     |
|    n_updates            | 37200      |
|    policy_gradient_loss | 0.00919    |
|    std                  | 0.0746     |
|    value_loss           | 0.00138    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 3721    |
|    time_elapsed    | 12073   |
|    total_timesteps | 7620608 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3722       |
|    time_elapsed         | 12076      |
|    total_timesteps      | 7622656    |
| train/                  |            |
|    approx_kl            | 0.39083934 |
|    clip_fraction        | 0.468      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.35       |
|    explained_variance   | -0.526     |
|    learning_rate        | 0.000514   |
|    loss                 | -0.0388    |
|    n_updates            | 37210      |
|    policy_gradient_loss | 0.0202     |
|    std                  | 0.0747     |
|    value_loss           | 0.00178    |
----------------------------------------
--------------------------------------
| time/                   |          |
|    fps                  | 631      |
|    iterations           | 3723     |
|    time_elapsed         | 12080    |
|    total_timesteps      | 7624704  |
| train/                  |          |
|    approx_kl            | 0.340423 |
|    clip_fraction        | 0.447    |
|    clip_range           | 0.2      |
|    entropy_loss         | 2.34     |
|    explained_variance   | 0.579    |
|    learning_rate        | 0.000514 |
|    loss                 | -0.037   |
|    n_updates            | 37220    |
|    policy_gradient_loss | 0.00573  |
|    std                  | 0.0758   |
|    value_loss           | 0.00113  |
--------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3724       |
|    time_elapsed         | 12083      |
|    total_timesteps      | 7626752    |
| train/                  |            |
|    approx_kl            | 0.21239889 |
|    clip_fraction        | 0.391      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.33       |
|    explained_variance   | 0.273      |
|    learning_rate        | 0.000513   |
|    loss                 | -0.00789   |
|    n_updates            | 37230      |
|    policy_gradient_loss | 0.00804    |
|    std                  | 0.0752     |
|    value_loss           | 0.000915   |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3725       |
|    time_elapsed         | 12086      |
|    total_timesteps      | 7628800    |
| train/                  |            |
|    approx_kl            | 0.23316565 |
|    clip_fraction        | 0.422      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.36       |
|    explained_variance   | 0.926      |
|    learning_rate        | 0.000513   |
|    loss                 | 0.0194     |
|    n_updates            | 37240      |
|    policy_gradient_loss | 0.022      |
|    std                  | 0.0739     |
|    value_loss           | 0.00682    |
----------------------------------------
Eval num_timesteps=7630000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 300       |
|    mean_reward          | -1        |
| time/                   |           |
|    total_timesteps      | 7630000   |
| train/                  |           |
|    approx_kl            | 0.3852753 |
|    clip_fraction        | 0.445     |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.37      |
|    explained_variance   | 0.531     |
|    learning_rate        | 0.000512  |
|    loss                 | -0.00406  |
|    n_updates            | 37250     |
|    policy_gradient_loss | 0.017     |
|    std                  | 0.0742    |
|    value_loss           | 0.00379   |
---------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 3726    |
|    time_elapsed    | 12090   |
|    total_timesteps | 7630848 |
--------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3727       |
|    time_elapsed         | 12093      |
|    total_timesteps      | 7632896    |
| train/                  |            |
|    approx_kl            | 0.17401955 |
|    clip_fraction        | 0.451      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.38       |
|    explained_variance   | 0.458      |
|    learning_rate        | 0.000512   |
|    loss                 | 0.0351     |
|    n_updates            | 37260      |
|    policy_gradient_loss | 0.0159     |
|    std                  | 0.0736     |
|    value_loss           | 0.000963   |
----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3728      |
|    time_elapsed         | 12096     |
|    total_timesteps      | 7634944   |
| train/                  |           |
|    approx_kl            | 0.3070605 |
|    clip_fraction        | 0.496     |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.39      |
|    explained_variance   | 0.493     |
|    learning_rate        | 0.000512  |
|    loss                 | 0.0236    |
|    n_updates            | 37270     |
|    policy_gradient_loss | 0.0154    |
|    std                  | 0.0735    |
|    value_loss           | 0.0178    |
---------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3729       |
|    time_elapsed         | 12099      |
|    total_timesteps      | 7636992    |
| train/                  |            |
|    approx_kl            | 0.47847652 |
|    clip_fraction        | 0.424      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.39       |
|    explained_variance   | 0.518      |
|    learning_rate        | 0.000511   |
|    loss                 | 0.0112     |
|    n_updates            | 37280      |
|    policy_gradient_loss | 0.00707    |
|    std                  | 0.0734     |
|    value_loss           | 0.00238    |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3730       |
|    time_elapsed         | 12102      |
|    total_timesteps      | 7639040    |
| train/                  |            |
|    approx_kl            | 0.77510154 |
|    clip_fraction        | 0.538      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.39       |
|    explained_variance   | 0.607      |
|    learning_rate        | 0.000511   |
|    loss                 | 0.046      |
|    n_updates            | 37290      |
|    policy_gradient_loss | 0.0212     |
|    std                  | 0.0731     |
|    value_loss           | 0.0377     |
----------------------------------------
Eval num_timesteps=7640000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1         |
| time/                   |            |
|    total_timesteps      | 7640000    |
| train/                  |            |
|    approx_kl            | 0.26644605 |
|    clip_fraction        | 0.481      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.39       |
|    explained_variance   | 0.793      |
|    learning_rate        | 0.00051    |
|    loss                 | 0.0298     |
|    n_updates            | 37300      |
|    policy_gradient_loss | 0.0118     |
|    std                  | 0.0729     |
|    value_loss           | 0.0159     |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 3731    |
|    time_elapsed    | 12106   |
|    total_timesteps | 7641088 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3732       |
|    time_elapsed         | 12109      |
|    total_timesteps      | 7643136    |
| train/                  |            |
|    approx_kl            | 0.44346738 |
|    clip_fraction        | 0.486      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.35       |
|    explained_variance   | 0.736      |
|    learning_rate        | 0.00051    |
|    loss                 | -0.0015    |
|    n_updates            | 37310      |
|    policy_gradient_loss | 0.0125     |
|    std                  | 0.076      |
|    value_loss           | 0.00447    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3733       |
|    time_elapsed         | 12112      |
|    total_timesteps      | 7645184    |
| train/                  |            |
|    approx_kl            | 0.33856085 |
|    clip_fraction        | 0.432      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.31       |
|    explained_variance   | 0.785      |
|    learning_rate        | 0.00051    |
|    loss                 | -0.0258    |
|    n_updates            | 37320      |
|    policy_gradient_loss | 0.00949    |
|    std                  | 0.0766     |
|    value_loss           | 0.00234    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3734       |
|    time_elapsed         | 12115      |
|    total_timesteps      | 7647232    |
| train/                  |            |
|    approx_kl            | 0.27056777 |
|    clip_fraction        | 0.462      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.3        |
|    explained_variance   | 0.771      |
|    learning_rate        | 0.000509   |
|    loss                 | 0.0962     |
|    n_updates            | 37330      |
|    policy_gradient_loss | 0.00768    |
|    std                  | 0.0768     |
|    value_loss           | 0.00452    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3735       |
|    time_elapsed         | 12118      |
|    total_timesteps      | 7649280    |
| train/                  |            |
|    approx_kl            | 0.40971732 |
|    clip_fraction        | 0.412      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.31       |
|    explained_variance   | 0.637      |
|    learning_rate        | 0.000509   |
|    loss                 | 0.0042     |
|    n_updates            | 37340      |
|    policy_gradient_loss | 0.0124     |
|    std                  | 0.0763     |
|    value_loss           | 0.00143    |
----------------------------------------
Eval num_timesteps=7650000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 300       |
|    mean_reward          | -1        |
| time/                   |           |
|    total_timesteps      | 7650000   |
| train/                  |           |
|    approx_kl            | 0.2151377 |
|    clip_fraction        | 0.41      |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.33      |
|    explained_variance   | 0.504     |
|    learning_rate        | 0.000508  |
|    loss                 | 0.017     |
|    n_updates            | 37350     |
|    policy_gradient_loss | 0.00198   |
|    std                  | 0.0753    |
|    value_loss           | 0.00162   |
---------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 3736    |
|    time_elapsed    | 12122   |
|    total_timesteps | 7651328 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3737       |
|    time_elapsed         | 12125      |
|    total_timesteps      | 7653376    |
| train/                  |            |
|    approx_kl            | 0.74456954 |
|    clip_fraction        | 0.45       |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.33       |
|    explained_variance   | 0.04       |
|    learning_rate        | 0.000508   |
|    loss                 | 0.0465     |
|    n_updates            | 37360      |
|    policy_gradient_loss | 0.0174     |
|    std                  | 0.0755     |
|    value_loss           | 0.00203    |
----------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3738      |
|    time_elapsed         | 12128     |
|    total_timesteps      | 7655424   |
| train/                  |           |
|    approx_kl            | 0.3145901 |
|    clip_fraction        | 0.437     |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.34      |
|    explained_variance   | 0.166     |
|    learning_rate        | 0.000508  |
|    loss                 | -0.0372   |
|    n_updates            | 37370     |
|    policy_gradient_loss | 0.00716   |
|    std                  | 0.0754    |
|    value_loss           | 0.00393   |
---------------------------------------
box reached target
--------------------------------------
| time/                   |          |
|    fps                  | 631      |
|    iterations           | 3739     |
|    time_elapsed         | 12131    |
|    total_timesteps      | 7657472  |
| train/                  |          |
|    approx_kl            | 5.504177 |
|    clip_fraction        | 0.535    |
|    clip_range           | 0.2      |
|    entropy_loss         | 2.35     |
|    explained_variance   | -0.019   |
|    learning_rate        | 0.000507 |
|    loss                 | 0.0655   |
|    n_updates            | 37380    |
|    policy_gradient_loss | 0.0149   |
|    std                  | 0.0746   |
|    value_loss           | 0.118    |
--------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3740       |
|    time_elapsed         | 12134      |
|    total_timesteps      | 7659520    |
| train/                  |            |
|    approx_kl            | 0.20144895 |
|    clip_fraction        | 0.425      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.36       |
|    explained_variance   | 0.382      |
|    learning_rate        | 0.000507   |
|    loss                 | -0.00949   |
|    n_updates            | 37390      |
|    policy_gradient_loss | 0.0306     |
|    std                  | 0.0753     |
|    value_loss           | 0.0153     |
----------------------------------------
Eval num_timesteps=7660000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 300       |
|    mean_reward          | -1        |
| time/                   |           |
|    total_timesteps      | 7660000   |
| train/                  |           |
|    approx_kl            | 0.7658174 |
|    clip_fraction        | 0.488     |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.33      |
|    explained_variance   | 0.414     |
|    learning_rate        | 0.000506  |
|    loss                 | -0.00792  |
|    n_updates            | 37400     |
|    policy_gradient_loss | 0.00444   |
|    std                  | 0.0756    |
|    value_loss           | 0.0143    |
---------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 3741    |
|    time_elapsed    | 12138   |
|    total_timesteps | 7661568 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3742       |
|    time_elapsed         | 12141      |
|    total_timesteps      | 7663616    |
| train/                  |            |
|    approx_kl            | 0.40757245 |
|    clip_fraction        | 0.489      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.31       |
|    explained_variance   | 0.822      |
|    learning_rate        | 0.000506   |
|    loss                 | -0.000758  |
|    n_updates            | 37410      |
|    policy_gradient_loss | 0.0241     |
|    std                  | 0.0767     |
|    value_loss           | 0.00653    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3743       |
|    time_elapsed         | 12144      |
|    total_timesteps      | 7665664    |
| train/                  |            |
|    approx_kl            | 0.21712372 |
|    clip_fraction        | 0.442      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.31       |
|    explained_variance   | -0.534     |
|    learning_rate        | 0.000506   |
|    loss                 | 0.0469     |
|    n_updates            | 37420      |
|    policy_gradient_loss | 0.0326     |
|    std                  | 0.0759     |
|    value_loss           | 0.00163    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3744       |
|    time_elapsed         | 12147      |
|    total_timesteps      | 7667712    |
| train/                  |            |
|    approx_kl            | 0.18898118 |
|    clip_fraction        | 0.383      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.31       |
|    explained_variance   | 0.39       |
|    learning_rate        | 0.000505   |
|    loss                 | -0.0378    |
|    n_updates            | 37430      |
|    policy_gradient_loss | 0.0266     |
|    std                  | 0.077      |
|    value_loss           | 0.0013     |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3745       |
|    time_elapsed         | 12150      |
|    total_timesteps      | 7669760    |
| train/                  |            |
|    approx_kl            | 0.81227005 |
|    clip_fraction        | 0.436      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.3        |
|    explained_variance   | 0.407      |
|    learning_rate        | 0.000505   |
|    loss                 | -0.0257    |
|    n_updates            | 37440      |
|    policy_gradient_loss | 0.0125     |
|    std                  | 0.0769     |
|    value_loss           | 0.00127    |
----------------------------------------
Eval num_timesteps=7670000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1         |
| time/                   |            |
|    total_timesteps      | 7670000    |
| train/                  |            |
|    approx_kl            | 0.38097733 |
|    clip_fraction        | 0.49       |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.27       |
|    explained_variance   | 0.364      |
|    learning_rate        | 0.000504   |
|    loss                 | -0.0237    |
|    n_updates            | 37450      |
|    policy_gradient_loss | 0.0189     |
|    std                  | 0.0789     |
|    value_loss           | 0.00226    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 3746    |
|    time_elapsed    | 12154   |
|    total_timesteps | 7671808 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3747       |
|    time_elapsed         | 12157      |
|    total_timesteps      | 7673856    |
| train/                  |            |
|    approx_kl            | 0.17918628 |
|    clip_fraction        | 0.449      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.24       |
|    explained_variance   | 0.423      |
|    learning_rate        | 0.000504   |
|    loss                 | -0.0343    |
|    n_updates            | 37460      |
|    policy_gradient_loss | 0.00893    |
|    std                  | 0.08       |
|    value_loss           | 0.00867    |
----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3748      |
|    time_elapsed         | 12160     |
|    total_timesteps      | 7675904   |
| train/                  |           |
|    approx_kl            | 0.4798288 |
|    clip_fraction        | 0.448     |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.24      |
|    explained_variance   | 0.209     |
|    learning_rate        | 0.000504  |
|    loss                 | 0.0246    |
|    n_updates            | 37470     |
|    policy_gradient_loss | 0.0226    |
|    std                  | 0.0787    |
|    value_loss           | 0.00205   |
---------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3749      |
|    time_elapsed         | 12163     |
|    total_timesteps      | 7677952   |
| train/                  |           |
|    approx_kl            | 0.2588333 |
|    clip_fraction        | 0.446     |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.24      |
|    explained_variance   | -0.265    |
|    learning_rate        | 0.000503  |
|    loss                 | 0.0186    |
|    n_updates            | 37480     |
|    policy_gradient_loss | 0.0275    |
|    std                  | 0.0799    |
|    value_loss           | 0.00191   |
---------------------------------------
box reached target
Eval num_timesteps=7680000, episode_reward=-0.72 +/- 0.55
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -0.725     |
| time/                   |            |
|    total_timesteps      | 7680000    |
| train/                  |            |
|    approx_kl            | 0.17486289 |
|    clip_fraction        | 0.433      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.22       |
|    explained_variance   | 0.657      |
|    learning_rate        | 0.000503   |
|    loss                 | 0.034      |
|    n_updates            | 37490      |
|    policy_gradient_loss | 0.0142     |
|    std                  | 0.0804     |
|    value_loss           | 0.0125     |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 3750    |
|    time_elapsed    | 12167   |
|    total_timesteps | 7680000 |
--------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3751      |
|    time_elapsed         | 12171     |
|    total_timesteps      | 7682048   |
| train/                  |           |
|    approx_kl            | 0.4270758 |
|    clip_fraction        | 0.51      |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.22      |
|    explained_variance   | 0.883     |
|    learning_rate        | 0.000502  |
|    loss                 | -0.0359   |
|    n_updates            | 37500     |
|    policy_gradient_loss | 0.0132    |
|    std                  | 0.0795    |
|    value_loss           | 0.00861   |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3752       |
|    time_elapsed         | 12174      |
|    total_timesteps      | 7684096    |
| train/                  |            |
|    approx_kl            | 0.36667317 |
|    clip_fraction        | 0.439      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.21       |
|    explained_variance   | 0.572      |
|    learning_rate        | 0.000502   |
|    loss                 | 0.0552     |
|    n_updates            | 37510      |
|    policy_gradient_loss | 0.0134     |
|    std                  | 0.0807     |
|    value_loss           | 0.00175    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3753       |
|    time_elapsed         | 12177      |
|    total_timesteps      | 7686144    |
| train/                  |            |
|    approx_kl            | 0.11657983 |
|    clip_fraction        | 0.425      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.22       |
|    explained_variance   | 0.804      |
|    learning_rate        | 0.000502   |
|    loss                 | -0.016     |
|    n_updates            | 37520      |
|    policy_gradient_loss | 0.0141     |
|    std                  | 0.0795     |
|    value_loss           | 0.00768    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3754       |
|    time_elapsed         | 12180      |
|    total_timesteps      | 7688192    |
| train/                  |            |
|    approx_kl            | 0.22241527 |
|    clip_fraction        | 0.431      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.23       |
|    explained_variance   | 0.541      |
|    learning_rate        | 0.000501   |
|    loss                 | -0.0202    |
|    n_updates            | 37530      |
|    policy_gradient_loss | -0.000616  |
|    std                  | 0.0796     |
|    value_loss           | 0.00195    |
----------------------------------------
Eval num_timesteps=7690000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1         |
| time/                   |            |
|    total_timesteps      | 7690000    |
| train/                  |            |
|    approx_kl            | 0.31564555 |
|    clip_fraction        | 0.44       |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.23       |
|    explained_variance   | 0.409      |
|    learning_rate        | 0.000501   |
|    loss                 | -0.00681   |
|    n_updates            | 37540      |
|    policy_gradient_loss | 0.0105     |
|    std                  | 0.0793     |
|    value_loss           | 0.00515    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 3755    |
|    time_elapsed    | 12184   |
|    total_timesteps | 7690240 |
--------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3756       |
|    time_elapsed         | 12187      |
|    total_timesteps      | 7692288    |
| train/                  |            |
|    approx_kl            | 0.63443524 |
|    clip_fraction        | 0.473      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.24       |
|    explained_variance   | 0.645      |
|    learning_rate        | 0.0005     |
|    loss                 | 0.0135     |
|    n_updates            | 37550      |
|    policy_gradient_loss | -0.000681  |
|    std                  | 0.0791     |
|    value_loss           | 0.00128    |
----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3757      |
|    time_elapsed         | 12190     |
|    total_timesteps      | 7694336   |
| train/                  |           |
|    approx_kl            | 2.9836788 |
|    clip_fraction        | 0.574     |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.23      |
|    explained_variance   | 0.833     |
|    learning_rate        | 0.0005    |
|    loss                 | -0.0229   |
|    n_updates            | 37560     |
|    policy_gradient_loss | 0.00436   |
|    std                  | 0.0795    |
|    value_loss           | 0.0137    |
---------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3758      |
|    time_elapsed         | 12193     |
|    total_timesteps      | 7696384   |
| train/                  |           |
|    approx_kl            | 0.1991399 |
|    clip_fraction        | 0.476     |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.24      |
|    explained_variance   | -0.023    |
|    learning_rate        | 0.0005    |
|    loss                 | -0.0137   |
|    n_updates            | 37570     |
|    policy_gradient_loss | 0.0147    |
|    std                  | 0.0786    |
|    value_loss           | 0.00159   |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3759       |
|    time_elapsed         | 12196      |
|    total_timesteps      | 7698432    |
| train/                  |            |
|    approx_kl            | 0.18038608 |
|    clip_fraction        | 0.419      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.23       |
|    explained_variance   | 0.561      |
|    learning_rate        | 0.000499   |
|    loss                 | -0.0265    |
|    n_updates            | 37580      |
|    policy_gradient_loss | 0.0166     |
|    std                  | 0.0797     |
|    value_loss           | 0.00341    |
----------------------------------------
box reached target
Eval num_timesteps=7700000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 300       |
|    mean_reward          | -1        |
| time/                   |           |
|    total_timesteps      | 7700000   |
| train/                  |           |
|    approx_kl            | 0.4069344 |
|    clip_fraction        | 0.487     |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.22      |
|    explained_variance   | -0.153    |
|    learning_rate        | 0.000499  |
|    loss                 | -0.000866 |
|    n_updates            | 37590     |
|    policy_gradient_loss | 0.0108    |
|    std                  | 0.0795    |
|    value_loss           | 0.0025    |
---------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 3760    |
|    time_elapsed    | 12200   |
|    total_timesteps | 7700480 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3761       |
|    time_elapsed         | 12203      |
|    total_timesteps      | 7702528    |
| train/                  |            |
|    approx_kl            | 0.20252118 |
|    clip_fraction        | 0.464      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.24       |
|    explained_variance   | 0.385      |
|    learning_rate        | 0.000498   |
|    loss                 | -0.0075    |
|    n_updates            | 37600      |
|    policy_gradient_loss | 0.00749    |
|    std                  | 0.0794     |
|    value_loss           | 0.0375     |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3762       |
|    time_elapsed         | 12206      |
|    total_timesteps      | 7704576    |
| train/                  |            |
|    approx_kl            | 0.29800278 |
|    clip_fraction        | 0.42       |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.22       |
|    explained_variance   | -0.552     |
|    learning_rate        | 0.000498   |
|    loss                 | 0.0276     |
|    n_updates            | 37610      |
|    policy_gradient_loss | 0.017      |
|    std                  | 0.0801     |
|    value_loss           | 0.00213    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3763       |
|    time_elapsed         | 12209      |
|    total_timesteps      | 7706624    |
| train/                  |            |
|    approx_kl            | 0.36005372 |
|    clip_fraction        | 0.508      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.21       |
|    explained_variance   | 0.84       |
|    learning_rate        | 0.000498   |
|    loss                 | 0.108      |
|    n_updates            | 37620      |
|    policy_gradient_loss | 0.0273     |
|    std                  | 0.0805     |
|    value_loss           | 0.00672    |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3764       |
|    time_elapsed         | 12212      |
|    total_timesteps      | 7708672    |
| train/                  |            |
|    approx_kl            | 0.15212402 |
|    clip_fraction        | 0.354      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.22       |
|    explained_variance   | -0.701     |
|    learning_rate        | 0.000497   |
|    loss                 | -0.0364    |
|    n_updates            | 37630      |
|    policy_gradient_loss | 0.00334    |
|    std                  | 0.0789     |
|    value_loss           | 0.00299    |
----------------------------------------
Eval num_timesteps=7710000, episode_reward=-0.72 +/- 0.55
Episode length: 300.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 300       |
|    mean_reward          | -0.725    |
| time/                   |           |
|    total_timesteps      | 7710000   |
| train/                  |           |
|    approx_kl            | 0.4898607 |
|    clip_fraction        | 0.444     |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.25      |
|    explained_variance   | 0.941     |
|    learning_rate        | 0.000497  |
|    loss                 | -0.0245   |
|    n_updates            | 37640     |
|    policy_gradient_loss | 0.00282   |
|    std                  | 0.0786    |
|    value_loss           | 0.00356   |
---------------------------------------
box reached target
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 3765    |
|    time_elapsed    | 12216   |
|    total_timesteps | 7710720 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3766       |
|    time_elapsed         | 12219      |
|    total_timesteps      | 7712768    |
| train/                  |            |
|    approx_kl            | 0.18372093 |
|    clip_fraction        | 0.479      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.26       |
|    explained_variance   | 0.363      |
|    learning_rate        | 0.000496   |
|    loss                 | 0.083      |
|    n_updates            | 37650      |
|    policy_gradient_loss | 0.0216     |
|    std                  | 0.0778     |
|    value_loss           | 0.13       |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3767       |
|    time_elapsed         | 12222      |
|    total_timesteps      | 7714816    |
| train/                  |            |
|    approx_kl            | 0.22886422 |
|    clip_fraction        | 0.434      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.27       |
|    explained_variance   | 0.0221     |
|    learning_rate        | 0.000496   |
|    loss                 | -0.00715   |
|    n_updates            | 37660      |
|    policy_gradient_loss | 0.0016     |
|    std                  | 0.0779     |
|    value_loss           | 0.00182    |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3768       |
|    time_elapsed         | 12225      |
|    total_timesteps      | 7716864    |
| train/                  |            |
|    approx_kl            | 0.19771776 |
|    clip_fraction        | 0.462      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.26       |
|    explained_variance   | 0.48       |
|    learning_rate        | 0.000496   |
|    loss                 | 0.00451    |
|    n_updates            | 37670      |
|    policy_gradient_loss | 0.0281     |
|    std                  | 0.0787     |
|    value_loss           | 0.00222    |
----------------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3769       |
|    time_elapsed         | 12228      |
|    total_timesteps      | 7718912    |
| train/                  |            |
|    approx_kl            | 0.16925885 |
|    clip_fraction        | 0.419      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.24       |
|    explained_variance   | 0.96       |
|    learning_rate        | 0.000495   |
|    loss                 | 0.0158     |
|    n_updates            | 37680      |
|    policy_gradient_loss | 0.0187     |
|    std                  | 0.0794     |
|    value_loss           | 0.00609    |
----------------------------------------
Eval num_timesteps=7720000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 300       |
|    mean_reward          | -1        |
| time/                   |           |
|    total_timesteps      | 7720000   |
| train/                  |           |
|    approx_kl            | 0.2720892 |
|    clip_fraction        | 0.478     |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.21      |
|    explained_variance   | 0.849     |
|    learning_rate        | 0.000495  |
|    loss                 | -0.00768  |
|    n_updates            | 37690     |
|    policy_gradient_loss | 0.0149    |
|    std                  | 0.0806    |
|    value_loss           | 0.0148    |
---------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 3770    |
|    time_elapsed    | 12232   |
|    total_timesteps | 7720960 |
--------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3771      |
|    time_elapsed         | 12235     |
|    total_timesteps      | 7723008   |
| train/                  |           |
|    approx_kl            | 0.2651746 |
|    clip_fraction        | 0.455     |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.19      |
|    explained_variance   | 0.237     |
|    learning_rate        | 0.000494  |
|    loss                 | 0.0729    |
|    n_updates            | 37700     |
|    policy_gradient_loss | 0.0173    |
|    std                  | 0.0812    |
|    value_loss           | 0.00145   |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3772       |
|    time_elapsed         | 12238      |
|    total_timesteps      | 7725056    |
| train/                  |            |
|    approx_kl            | 0.27297908 |
|    clip_fraction        | 0.412      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.17       |
|    explained_variance   | 0.549      |
|    learning_rate        | 0.000494   |
|    loss                 | -0.0173    |
|    n_updates            | 37710      |
|    policy_gradient_loss | 0.0142     |
|    std                  | 0.0816     |
|    value_loss           | 0.00222    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3773       |
|    time_elapsed         | 12241      |
|    total_timesteps      | 7727104    |
| train/                  |            |
|    approx_kl            | 0.18011488 |
|    clip_fraction        | 0.418      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.17       |
|    explained_variance   | 0.332      |
|    learning_rate        | 0.000494   |
|    loss                 | 0.084      |
|    n_updates            | 37720      |
|    policy_gradient_loss | 0.0103     |
|    std                  | 0.0821     |
|    value_loss           | 0.00148    |
----------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3774      |
|    time_elapsed         | 12244     |
|    total_timesteps      | 7729152   |
| train/                  |           |
|    approx_kl            | 0.1522981 |
|    clip_fraction        | 0.452     |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.21      |
|    explained_variance   | 0.422     |
|    learning_rate        | 0.000493  |
|    loss                 | -0.0234   |
|    n_updates            | 37730     |
|    policy_gradient_loss | 0.00127   |
|    std                  | 0.0792    |
|    value_loss           | 0.00129   |
---------------------------------------
Eval num_timesteps=7730000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 300       |
|    mean_reward          | -1        |
| time/                   |           |
|    total_timesteps      | 7730000   |
| train/                  |           |
|    approx_kl            | 0.1709922 |
|    clip_fraction        | 0.509     |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.22      |
|    explained_variance   | 0.783     |
|    learning_rate        | 0.000493  |
|    loss                 | 0.00815   |
|    n_updates            | 37740     |
|    policy_gradient_loss | 0.0332    |
|    std                  | 0.0805    |
|    value_loss           | 0.0393    |
---------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 3775    |
|    time_elapsed    | 12248   |
|    total_timesteps | 7731200 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3776       |
|    time_elapsed         | 12251      |
|    total_timesteps      | 7733248    |
| train/                  |            |
|    approx_kl            | 0.18046556 |
|    clip_fraction        | 0.453      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.21       |
|    explained_variance   | 0.372      |
|    learning_rate        | 0.000492   |
|    loss                 | -0.039     |
|    n_updates            | 37750      |
|    policy_gradient_loss | 0.0149     |
|    std                  | 0.0803     |
|    value_loss           | 0.00134    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3777       |
|    time_elapsed         | 12255      |
|    total_timesteps      | 7735296    |
| train/                  |            |
|    approx_kl            | 0.14233868 |
|    clip_fraction        | 0.397      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.21       |
|    explained_variance   | 0.623      |
|    learning_rate        | 0.000492   |
|    loss                 | 0.0043     |
|    n_updates            | 37760      |
|    policy_gradient_loss | 0.0137     |
|    std                  | 0.0805     |
|    value_loss           | 0.00124    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3778       |
|    time_elapsed         | 12258      |
|    total_timesteps      | 7737344    |
| train/                  |            |
|    approx_kl            | 0.15676013 |
|    clip_fraction        | 0.404      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.19       |
|    explained_variance   | 0.667      |
|    learning_rate        | 0.000492   |
|    loss                 | -0.0252    |
|    n_updates            | 37770      |
|    policy_gradient_loss | 0.00932    |
|    std                  | 0.0812     |
|    value_loss           | 0.000827   |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3779       |
|    time_elapsed         | 12261      |
|    total_timesteps      | 7739392    |
| train/                  |            |
|    approx_kl            | 0.24782884 |
|    clip_fraction        | 0.372      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.17       |
|    explained_variance   | 0.521      |
|    learning_rate        | 0.000491   |
|    loss                 | -0.00415   |
|    n_updates            | 37780      |
|    policy_gradient_loss | 0.0204     |
|    std                  | 0.0821     |
|    value_loss           | 0.00134    |
----------------------------------------
Eval num_timesteps=7740000, episode_reward=-0.67 +/- 0.66
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -0.671     |
| time/                   |            |
|    total_timesteps      | 7740000    |
| train/                  |            |
|    approx_kl            | 0.22725074 |
|    clip_fraction        | 0.394      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.18       |
|    explained_variance   | 0.651      |
|    learning_rate        | 0.000491   |
|    loss                 | -0.0162    |
|    n_updates            | 37790      |
|    policy_gradient_loss | 0.0079     |
|    std                  | 0.0811     |
|    value_loss           | 0.00104    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 3780    |
|    time_elapsed    | 12265   |
|    total_timesteps | 7741440 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3781       |
|    time_elapsed         | 12268      |
|    total_timesteps      | 7743488    |
| train/                  |            |
|    approx_kl            | 0.43644318 |
|    clip_fraction        | 0.498      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.2        |
|    explained_variance   | 0.467      |
|    learning_rate        | 0.00049    |
|    loss                 | 0.039      |
|    n_updates            | 37800      |
|    policy_gradient_loss | 0.00882    |
|    std                  | 0.0804     |
|    value_loss           | 0.00122    |
----------------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3782       |
|    time_elapsed         | 12271      |
|    total_timesteps      | 7745536    |
| train/                  |            |
|    approx_kl            | 0.66309345 |
|    clip_fraction        | 0.497      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.21       |
|    explained_variance   | 0.248      |
|    learning_rate        | 0.00049    |
|    loss                 | -0.00507   |
|    n_updates            | 37810      |
|    policy_gradient_loss | 0.0078     |
|    std                  | 0.08       |
|    value_loss           | 0.00246    |
----------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3783      |
|    time_elapsed         | 12274     |
|    total_timesteps      | 7747584   |
| train/                  |           |
|    approx_kl            | 0.3172413 |
|    clip_fraction        | 0.443     |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.22      |
|    explained_variance   | 0.645     |
|    learning_rate        | 0.00049   |
|    loss                 | 0.0727    |
|    n_updates            | 37820     |
|    policy_gradient_loss | 0.012     |
|    std                  | 0.0803    |
|    value_loss           | 0.0241    |
---------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3784      |
|    time_elapsed         | 12277     |
|    total_timesteps      | 7749632   |
| train/                  |           |
|    approx_kl            | 0.5162132 |
|    clip_fraction        | 0.442     |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.2       |
|    explained_variance   | 0.791     |
|    learning_rate        | 0.000489  |
|    loss                 | 0.049     |
|    n_updates            | 37830     |
|    policy_gradient_loss | 0.0137    |
|    std                  | 0.0804    |
|    value_loss           | 0.0174    |
---------------------------------------
Eval num_timesteps=7750000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1         |
| time/                   |            |
|    total_timesteps      | 7750000    |
| train/                  |            |
|    approx_kl            | 0.23816109 |
|    clip_fraction        | 0.398      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.19       |
|    explained_variance   | 0.165      |
|    learning_rate        | 0.000489   |
|    loss                 | -0.02      |
|    n_updates            | 37840      |
|    policy_gradient_loss | 0.00251    |
|    std                  | 0.0808     |
|    value_loss           | 0.00247    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 3785    |
|    time_elapsed    | 12281   |
|    total_timesteps | 7751680 |
--------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3786      |
|    time_elapsed         | 12284     |
|    total_timesteps      | 7753728   |
| train/                  |           |
|    approx_kl            | 0.3829863 |
|    clip_fraction        | 0.401     |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.2       |
|    explained_variance   | 0.12      |
|    learning_rate        | 0.000488  |
|    loss                 | -0.0436   |
|    n_updates            | 37850     |
|    policy_gradient_loss | -0.00781  |
|    std                  | 0.0801    |
|    value_loss           | 0.00219   |
---------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3787       |
|    time_elapsed         | 12287      |
|    total_timesteps      | 7755776    |
| train/                  |            |
|    approx_kl            | 0.11905995 |
|    clip_fraction        | 0.456      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.2        |
|    explained_variance   | 0.419      |
|    learning_rate        | 0.000488   |
|    loss                 | 0.0875     |
|    n_updates            | 37860      |
|    policy_gradient_loss | 0.0166     |
|    std                  | 0.081      |
|    value_loss           | 0.00265    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3788       |
|    time_elapsed         | 12290      |
|    total_timesteps      | 7757824    |
| train/                  |            |
|    approx_kl            | 0.25860637 |
|    clip_fraction        | 0.424      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.17       |
|    explained_variance   | 0.941      |
|    learning_rate        | 0.000488   |
|    loss                 | 0.0256     |
|    n_updates            | 37870      |
|    policy_gradient_loss | 0.0215     |
|    std                  | 0.0819     |
|    value_loss           | 0.00474    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3789       |
|    time_elapsed         | 12293      |
|    total_timesteps      | 7759872    |
| train/                  |            |
|    approx_kl            | 0.87162066 |
|    clip_fraction        | 0.456      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.15       |
|    explained_variance   | 0.551      |
|    learning_rate        | 0.000487   |
|    loss                 | -0.0467    |
|    n_updates            | 37880      |
|    policy_gradient_loss | 0.00352    |
|    std                  | 0.0827     |
|    value_loss           | 0.00198    |
----------------------------------------
box reached target
Eval num_timesteps=7760000, episode_reward=0.27 +/- 2.55
Episode length: 285.00 +/- 30.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 285        |
|    mean_reward          | 0.274      |
| time/                   |            |
|    total_timesteps      | 7760000    |
| train/                  |            |
|    approx_kl            | 0.29475132 |
|    clip_fraction        | 0.41       |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.16       |
|    explained_variance   | 0.406      |
|    learning_rate        | 0.000487   |
|    loss                 | -0.00245   |
|    n_updates            | 37890      |
|    policy_gradient_loss | 0.00807    |
|    std                  | 0.0821     |
|    value_loss           | 0.00237    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 3790    |
|    time_elapsed    | 12297   |
|    total_timesteps | 7761920 |
--------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3791      |
|    time_elapsed         | 12300     |
|    total_timesteps      | 7763968   |
| train/                  |           |
|    approx_kl            | 0.3005901 |
|    clip_fraction        | 0.426     |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.15      |
|    explained_variance   | 0.445     |
|    learning_rate        | 0.000486  |
|    loss                 | 0.00981   |
|    n_updates            | 37900     |
|    policy_gradient_loss | 0.0162    |
|    std                  | 0.0832    |
|    value_loss           | 0.00233   |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3792       |
|    time_elapsed         | 12303      |
|    total_timesteps      | 7766016    |
| train/                  |            |
|    approx_kl            | 0.24249601 |
|    clip_fraction        | 0.402      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.16       |
|    explained_variance   | 0.622      |
|    learning_rate        | 0.000486   |
|    loss                 | -0.0142    |
|    n_updates            | 37910      |
|    policy_gradient_loss | 0.0148     |
|    std                  | 0.0813     |
|    value_loss           | 0.0145     |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3793       |
|    time_elapsed         | 12306      |
|    total_timesteps      | 7768064    |
| train/                  |            |
|    approx_kl            | 0.24755476 |
|    clip_fraction        | 0.399      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.2        |
|    explained_variance   | 0.0954     |
|    learning_rate        | 0.000486   |
|    loss                 | 0.0146     |
|    n_updates            | 37920      |
|    policy_gradient_loss | 0.0106     |
|    std                  | 0.0803     |
|    value_loss           | 0.00155    |
----------------------------------------
Eval num_timesteps=7770000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1         |
| time/                   |            |
|    total_timesteps      | 7770000    |
| train/                  |            |
|    approx_kl            | 0.21604022 |
|    clip_fraction        | 0.377      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.21       |
|    explained_variance   | 0.37       |
|    learning_rate        | 0.000485   |
|    loss                 | 0.0202     |
|    n_updates            | 37930      |
|    policy_gradient_loss | 0.000585   |
|    std                  | 0.08       |
|    value_loss           | 0.00117    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 3794    |
|    time_elapsed    | 12310   |
|    total_timesteps | 7770112 |
--------------------------------
box reached target
box reached target
--------------------------------------
| time/                   |          |
|    fps                  | 631      |
|    iterations           | 3795     |
|    time_elapsed         | 12313    |
|    total_timesteps      | 7772160  |
| train/                  |          |
|    approx_kl            | 4.442289 |
|    clip_fraction        | 0.585    |
|    clip_range           | 0.2      |
|    entropy_loss         | 2.22     |
|    explained_variance   | 0.392    |
|    learning_rate        | 0.000485 |
|    loss                 | 0.00173  |
|    n_updates            | 37940    |
|    policy_gradient_loss | 0.0341   |
|    std                  | 0.0797   |
|    value_loss           | 0.00148  |
--------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3796       |
|    time_elapsed         | 12316      |
|    total_timesteps      | 7774208    |
| train/                  |            |
|    approx_kl            | 0.23567083 |
|    clip_fraction        | 0.417      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.25       |
|    explained_variance   | 0.884      |
|    learning_rate        | 0.000484   |
|    loss                 | 0.0389     |
|    n_updates            | 37950      |
|    policy_gradient_loss | 0.017      |
|    std                  | 0.0781     |
|    value_loss           | 0.0122     |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3797       |
|    time_elapsed         | 12319      |
|    total_timesteps      | 7776256    |
| train/                  |            |
|    approx_kl            | 0.63186526 |
|    clip_fraction        | 0.423      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.26       |
|    explained_variance   | 0.119      |
|    learning_rate        | 0.000484   |
|    loss                 | 0.0394     |
|    n_updates            | 37960      |
|    policy_gradient_loss | 0.00983    |
|    std                  | 0.0784     |
|    value_loss           | 0.0022     |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3798       |
|    time_elapsed         | 12322      |
|    total_timesteps      | 7778304    |
| train/                  |            |
|    approx_kl            | 0.17373651 |
|    clip_fraction        | 0.424      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.27       |
|    explained_variance   | 0.608      |
|    learning_rate        | 0.000484   |
|    loss                 | 0.00731    |
|    n_updates            | 37970      |
|    policy_gradient_loss | 0.00822    |
|    std                  | 0.0781     |
|    value_loss           | 0.00199    |
----------------------------------------
Eval num_timesteps=7780000, episode_reward=-0.83 +/- 0.34
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -0.828     |
| time/                   |            |
|    total_timesteps      | 7780000    |
| train/                  |            |
|    approx_kl            | 0.28700274 |
|    clip_fraction        | 0.393      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.28       |
|    explained_variance   | 0.326      |
|    learning_rate        | 0.000483   |
|    loss                 | -0.0323    |
|    n_updates            | 37980      |
|    policy_gradient_loss | 0.0333     |
|    std                  | 0.0777     |
|    value_loss           | 0.0013     |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 3799    |
|    time_elapsed    | 12326   |
|    total_timesteps | 7780352 |
--------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3800      |
|    time_elapsed         | 12329     |
|    total_timesteps      | 7782400   |
| train/                  |           |
|    approx_kl            | 0.436447  |
|    clip_fraction        | 0.415     |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.27      |
|    explained_variance   | 0.363     |
|    learning_rate        | 0.000483  |
|    loss                 | -0.0233   |
|    n_updates            | 37990     |
|    policy_gradient_loss | -0.000467 |
|    std                  | 0.0778    |
|    value_loss           | 0.00265   |
---------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3801       |
|    time_elapsed         | 12332      |
|    total_timesteps      | 7784448    |
| train/                  |            |
|    approx_kl            | 0.48116955 |
|    clip_fraction        | 0.412      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.3        |
|    explained_variance   | -0.0505    |
|    learning_rate        | 0.000482   |
|    loss                 | 0.0214     |
|    n_updates            | 38000      |
|    policy_gradient_loss | 8.58e-05   |
|    std                  | 0.0761     |
|    value_loss           | 0.00221    |
----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3802      |
|    time_elapsed         | 12335     |
|    total_timesteps      | 7786496   |
| train/                  |           |
|    approx_kl            | 0.4609406 |
|    clip_fraction        | 0.492     |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.34      |
|    explained_variance   | 0.274     |
|    learning_rate        | 0.000482  |
|    loss                 | -0.000156 |
|    n_updates            | 38010     |
|    policy_gradient_loss | 0.0104    |
|    std                  | 0.0747    |
|    value_loss           | 0.0757    |
---------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3803      |
|    time_elapsed         | 12338     |
|    total_timesteps      | 7788544   |
| train/                  |           |
|    approx_kl            | 1.1143911 |
|    clip_fraction        | 0.449     |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.36      |
|    explained_variance   | 0.487     |
|    learning_rate        | 0.000482  |
|    loss                 | 0.0293    |
|    n_updates            | 38020     |
|    policy_gradient_loss | 0.0119    |
|    std                  | 0.0751    |
|    value_loss           | 0.00384   |
---------------------------------------
Eval num_timesteps=7790000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
--------------------------------------
| eval/                   |          |
|    mean_ep_length       | 300      |
|    mean_reward          | -1       |
| time/                   |          |
|    total_timesteps      | 7790000  |
| train/                  |          |
|    approx_kl            | 0.370854 |
|    clip_fraction        | 0.427    |
|    clip_range           | 0.2      |
|    entropy_loss         | 2.35     |
|    explained_variance   | 0.381    |
|    learning_rate        | 0.000481 |
|    loss                 | -0.0284  |
|    n_updates            | 38030    |
|    policy_gradient_loss | 0.0109   |
|    std                  | 0.0752   |
|    value_loss           | 0.00229  |
--------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 3804    |
|    time_elapsed    | 12342   |
|    total_timesteps | 7790592 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3805       |
|    time_elapsed         | 12345      |
|    total_timesteps      | 7792640    |
| train/                  |            |
|    approx_kl            | 0.24733208 |
|    clip_fraction        | 0.433      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.36       |
|    explained_variance   | 0.401      |
|    learning_rate        | 0.000481   |
|    loss                 | -0.000268  |
|    n_updates            | 38040      |
|    policy_gradient_loss | 0.00951    |
|    std                  | 0.0741     |
|    value_loss           | 0.00157    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3806       |
|    time_elapsed         | 12349      |
|    total_timesteps      | 7794688    |
| train/                  |            |
|    approx_kl            | 0.21652438 |
|    clip_fraction        | 0.466      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.37       |
|    explained_variance   | 0.121      |
|    learning_rate        | 0.00048    |
|    loss                 | 0.0035     |
|    n_updates            | 38050      |
|    policy_gradient_loss | 0.0157     |
|    std                  | 0.0744     |
|    value_loss           | 0.00143    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3807       |
|    time_elapsed         | 12352      |
|    total_timesteps      | 7796736    |
| train/                  |            |
|    approx_kl            | 0.33258742 |
|    clip_fraction        | 0.409      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.37       |
|    explained_variance   | 0.503      |
|    learning_rate        | 0.00048    |
|    loss                 | 0.0192     |
|    n_updates            | 38060      |
|    policy_gradient_loss | 0.0229     |
|    std                  | 0.0747     |
|    value_loss           | 0.00223    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3808       |
|    time_elapsed         | 12355      |
|    total_timesteps      | 7798784    |
| train/                  |            |
|    approx_kl            | 0.22720602 |
|    clip_fraction        | 0.364      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.36       |
|    explained_variance   | 0.264      |
|    learning_rate        | 0.00048    |
|    loss                 | -0.00633   |
|    n_updates            | 38070      |
|    policy_gradient_loss | 0.00218    |
|    std                  | 0.0745     |
|    value_loss           | 0.00198    |
----------------------------------------
box reached target
Eval num_timesteps=7800000, episode_reward=0.23 +/- 2.46
Episode length: 272.80 +/- 54.40
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 273        |
|    mean_reward          | 0.23       |
| time/                   |            |
|    total_timesteps      | 7800000    |
| train/                  |            |
|    approx_kl            | 0.17442945 |
|    clip_fraction        | 0.421      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.37       |
|    explained_variance   | 0.0584     |
|    learning_rate        | 0.000479   |
|    loss                 | -0.0256    |
|    n_updates            | 38080      |
|    policy_gradient_loss | 0.0348     |
|    std                  | 0.0742     |
|    value_loss           | 0.00146    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 3809    |
|    time_elapsed    | 12359   |
|    total_timesteps | 7800832 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3810       |
|    time_elapsed         | 12362      |
|    total_timesteps      | 7802880    |
| train/                  |            |
|    approx_kl            | 0.18804085 |
|    clip_fraction        | 0.39       |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.36       |
|    explained_variance   | 0.225      |
|    learning_rate        | 0.000479   |
|    loss                 | 0.0183     |
|    n_updates            | 38090      |
|    policy_gradient_loss | 0.0186     |
|    std                  | 0.0753     |
|    value_loss           | 0.00105    |
----------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3811      |
|    time_elapsed         | 12366     |
|    total_timesteps      | 7804928   |
| train/                  |           |
|    approx_kl            | 0.3198319 |
|    clip_fraction        | 0.363     |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.36      |
|    explained_variance   | 0.287     |
|    learning_rate        | 0.000478  |
|    loss                 | -0.022    |
|    n_updates            | 38100     |
|    policy_gradient_loss | 0.0109    |
|    std                  | 0.0744    |
|    value_loss           | 0.0015    |
---------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3812       |
|    time_elapsed         | 12369      |
|    total_timesteps      | 7806976    |
| train/                  |            |
|    approx_kl            | 0.11786478 |
|    clip_fraction        | 0.42       |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.38       |
|    explained_variance   | 0.552      |
|    learning_rate        | 0.000478   |
|    loss                 | -0.0217    |
|    n_updates            | 38110      |
|    policy_gradient_loss | 0.0125     |
|    std                  | 0.0737     |
|    value_loss           | 0.0192     |
----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3813      |
|    time_elapsed         | 12372     |
|    total_timesteps      | 7809024   |
| train/                  |           |
|    approx_kl            | 0.3180308 |
|    clip_fraction        | 0.48      |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.4       |
|    explained_variance   | 0.88      |
|    learning_rate        | 0.000478  |
|    loss                 | -0.00906  |
|    n_updates            | 38120     |
|    policy_gradient_loss | 0.0165    |
|    std                  | 0.0733    |
|    value_loss           | 0.00823   |
---------------------------------------
box reached target
Eval num_timesteps=7810000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1         |
| time/                   |            |
|    total_timesteps      | 7810000    |
| train/                  |            |
|    approx_kl            | 0.09536485 |
|    clip_fraction        | 0.407      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.39       |
|    explained_variance   | 0.724      |
|    learning_rate        | 0.000477   |
|    loss                 | 0.00786    |
|    n_updates            | 38130      |
|    policy_gradient_loss | 0.0148     |
|    std                  | 0.074      |
|    value_loss           | 0.0152     |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 3814    |
|    time_elapsed    | 12376   |
|    total_timesteps | 7811072 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3815       |
|    time_elapsed         | 12379      |
|    total_timesteps      | 7813120    |
| train/                  |            |
|    approx_kl            | 0.20766889 |
|    clip_fraction        | 0.491      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.37       |
|    explained_variance   | 0.797      |
|    learning_rate        | 0.000477   |
|    loss                 | 0.0474     |
|    n_updates            | 38140      |
|    policy_gradient_loss | 0.0351     |
|    std                  | 0.0755     |
|    value_loss           | 0.0223     |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3816       |
|    time_elapsed         | 12382      |
|    total_timesteps      | 7815168    |
| train/                  |            |
|    approx_kl            | 0.30198658 |
|    clip_fraction        | 0.448      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.33       |
|    explained_variance   | 0.695      |
|    learning_rate        | 0.000476   |
|    loss                 | 0.00689    |
|    n_updates            | 38150      |
|    policy_gradient_loss | 0.00494    |
|    std                  | 0.0765     |
|    value_loss           | 0.0058     |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3817       |
|    time_elapsed         | 12385      |
|    total_timesteps      | 7817216    |
| train/                  |            |
|    approx_kl            | 0.26412404 |
|    clip_fraction        | 0.428      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.32       |
|    explained_variance   | 0.403      |
|    learning_rate        | 0.000476   |
|    loss                 | -0.0305    |
|    n_updates            | 38160      |
|    policy_gradient_loss | 0.00762    |
|    std                  | 0.0765     |
|    value_loss           | 0.00171    |
----------------------------------------
--------------------------------------
| time/                   |          |
|    fps                  | 631      |
|    iterations           | 3818     |
|    time_elapsed         | 12388    |
|    total_timesteps      | 7819264  |
| train/                  |          |
|    approx_kl            | 0.459934 |
|    clip_fraction        | 0.473    |
|    clip_range           | 0.2      |
|    entropy_loss         | 2.31     |
|    explained_variance   | 0.774    |
|    learning_rate        | 0.000476 |
|    loss                 | 0.0279   |
|    n_updates            | 38170    |
|    policy_gradient_loss | 0.0244   |
|    std                  | 0.0761   |
|    value_loss           | 0.00538  |
--------------------------------------
Eval num_timesteps=7820000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 300       |
|    mean_reward          | -1        |
| time/                   |           |
|    total_timesteps      | 7820000   |
| train/                  |           |
|    approx_kl            | 1.3960907 |
|    clip_fraction        | 0.489     |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.31      |
|    explained_variance   | 0.608     |
|    learning_rate        | 0.000475  |
|    loss                 | -0.00936  |
|    n_updates            | 38180     |
|    policy_gradient_loss | 0.0166    |
|    std                  | 0.0769    |
|    value_loss           | 0.00311   |
---------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 3819    |
|    time_elapsed    | 12392   |
|    total_timesteps | 7821312 |
--------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3820      |
|    time_elapsed         | 12395     |
|    total_timesteps      | 7823360   |
| train/                  |           |
|    approx_kl            | 0.2130402 |
|    clip_fraction        | 0.42      |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.28      |
|    explained_variance   | 0.598     |
|    learning_rate        | 0.000475  |
|    loss                 | 0.00704   |
|    n_updates            | 38190     |
|    policy_gradient_loss | 0.0133    |
|    std                  | 0.0779    |
|    value_loss           | 0.00367   |
---------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3821      |
|    time_elapsed         | 12398     |
|    total_timesteps      | 7825408   |
| train/                  |           |
|    approx_kl            | 0.3757087 |
|    clip_fraction        | 0.408     |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.27      |
|    explained_variance   | 0.825     |
|    learning_rate        | 0.000474  |
|    loss                 | 0.00273   |
|    n_updates            | 38200     |
|    policy_gradient_loss | 0.00158   |
|    std                  | 0.0781    |
|    value_loss           | 0.00207   |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3822       |
|    time_elapsed         | 12401      |
|    total_timesteps      | 7827456    |
| train/                  |            |
|    approx_kl            | 0.26688236 |
|    clip_fraction        | 0.445      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.27       |
|    explained_variance   | 0.846      |
|    learning_rate        | 0.000474   |
|    loss                 | -0.00609   |
|    n_updates            | 38210      |
|    policy_gradient_loss | 0.0112     |
|    std                  | 0.0784     |
|    value_loss           | 0.00881    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3823       |
|    time_elapsed         | 12404      |
|    total_timesteps      | 7829504    |
| train/                  |            |
|    approx_kl            | 0.23409165 |
|    clip_fraction        | 0.459      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.25       |
|    explained_variance   | 0.81       |
|    learning_rate        | 0.000474   |
|    loss                 | 0.0117     |
|    n_updates            | 38220      |
|    policy_gradient_loss | 0.00797    |
|    std                  | 0.0792     |
|    value_loss           | 0.00935    |
----------------------------------------
box reached target
Eval num_timesteps=7830000, episode_reward=0.22 +/- 2.45
Episode length: 270.60 +/- 58.80
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 271       |
|    mean_reward          | 0.223     |
| time/                   |           |
|    total_timesteps      | 7830000   |
| train/                  |           |
|    approx_kl            | 0.3961013 |
|    clip_fraction        | 0.377     |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.24      |
|    explained_variance   | 0.71      |
|    learning_rate        | 0.000473  |
|    loss                 | -0.0067   |
|    n_updates            | 38230     |
|    policy_gradient_loss | 0.00913   |
|    std                  | 0.079     |
|    value_loss           | 0.00241   |
---------------------------------------
box reached target
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 3824    |
|    time_elapsed    | 12408   |
|    total_timesteps | 7831552 |
--------------------------------
box reached target
--------------------------------------
| time/                   |          |
|    fps                  | 631      |
|    iterations           | 3825     |
|    time_elapsed         | 12411    |
|    total_timesteps      | 7833600  |
| train/                  |          |
|    approx_kl            | 1.507161 |
|    clip_fraction        | 0.432    |
|    clip_range           | 0.2      |
|    entropy_loss         | 2.24     |
|    explained_variance   | 0.948    |
|    learning_rate        | 0.000473 |
|    loss                 | -0.027   |
|    n_updates            | 38240    |
|    policy_gradient_loss | 0.00829  |
|    std                  | 0.0788   |
|    value_loss           | 0.00778  |
--------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3826      |
|    time_elapsed         | 12414     |
|    total_timesteps      | 7835648   |
| train/                  |           |
|    approx_kl            | 0.2629759 |
|    clip_fraction        | 0.39      |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.25      |
|    explained_variance   | 0.835     |
|    learning_rate        | 0.000472  |
|    loss                 | -0.000251 |
|    n_updates            | 38250     |
|    policy_gradient_loss | 0.00604   |
|    std                  | 0.0785    |
|    value_loss           | 0.00558   |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3827       |
|    time_elapsed         | 12417      |
|    total_timesteps      | 7837696    |
| train/                  |            |
|    approx_kl            | 0.20832758 |
|    clip_fraction        | 0.439      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.25       |
|    explained_variance   | 0.845      |
|    learning_rate        | 0.000472   |
|    loss                 | 0.064      |
|    n_updates            | 38260      |
|    policy_gradient_loss | 0.0109     |
|    std                  | 0.0789     |
|    value_loss           | 0.0258     |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3828       |
|    time_elapsed         | 12420      |
|    total_timesteps      | 7839744    |
| train/                  |            |
|    approx_kl            | 0.49814206 |
|    clip_fraction        | 0.374      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.22       |
|    explained_variance   | 0.415      |
|    learning_rate        | 0.000472   |
|    loss                 | 0.0228     |
|    n_updates            | 38270      |
|    policy_gradient_loss | -0.000475  |
|    std                  | 0.0804     |
|    value_loss           | 0.00181    |
----------------------------------------
Eval num_timesteps=7840000, episode_reward=-0.76 +/- 0.49
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -0.757     |
| time/                   |            |
|    total_timesteps      | 7840000    |
| train/                  |            |
|    approx_kl            | 0.41976255 |
|    clip_fraction        | 0.392      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.2        |
|    explained_variance   | 0.269      |
|    learning_rate        | 0.000471   |
|    loss                 | -0.0119    |
|    n_updates            | 38280      |
|    policy_gradient_loss | 0.00288    |
|    std                  | 0.0804     |
|    value_loss           | 0.00258    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 3829    |
|    time_elapsed    | 12424   |
|    total_timesteps | 7841792 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3830       |
|    time_elapsed         | 12427      |
|    total_timesteps      | 7843840    |
| train/                  |            |
|    approx_kl            | 0.23964675 |
|    clip_fraction        | 0.394      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.19       |
|    explained_variance   | 0.568      |
|    learning_rate        | 0.000471   |
|    loss                 | 0.317      |
|    n_updates            | 38290      |
|    policy_gradient_loss | 0.0173     |
|    std                  | 0.0812     |
|    value_loss           | 0.00381    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3831       |
|    time_elapsed         | 12430      |
|    total_timesteps      | 7845888    |
| train/                  |            |
|    approx_kl            | 0.29854086 |
|    clip_fraction        | 0.354      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.19       |
|    explained_variance   | 0.0515     |
|    learning_rate        | 0.00047    |
|    loss                 | -0.00169   |
|    n_updates            | 38300      |
|    policy_gradient_loss | -0.00671   |
|    std                  | 0.0802     |
|    value_loss           | 0.0016     |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3832       |
|    time_elapsed         | 12433      |
|    total_timesteps      | 7847936    |
| train/                  |            |
|    approx_kl            | 0.24835765 |
|    clip_fraction        | 0.394      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.2        |
|    explained_variance   | -0.0991    |
|    learning_rate        | 0.00047    |
|    loss                 | -0.0134    |
|    n_updates            | 38310      |
|    policy_gradient_loss | 0.0206     |
|    std                  | 0.0806     |
|    value_loss           | 0.0011     |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3833       |
|    time_elapsed         | 12437      |
|    total_timesteps      | 7849984    |
| train/                  |            |
|    approx_kl            | 0.31935912 |
|    clip_fraction        | 0.366      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.19       |
|    explained_variance   | 0.475      |
|    learning_rate        | 0.00047    |
|    loss                 | 0.0105     |
|    n_updates            | 38320      |
|    policy_gradient_loss | 0.00772    |
|    std                  | 0.0809     |
|    value_loss           | 0.00183    |
----------------------------------------
Eval num_timesteps=7850000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
--------------------------------------
| eval/                   |          |
|    mean_ep_length       | 300      |
|    mean_reward          | -1       |
| time/                   |          |
|    total_timesteps      | 7850000  |
| train/                  |          |
|    approx_kl            | 0.479037 |
|    clip_fraction        | 0.516    |
|    clip_range           | 0.2      |
|    entropy_loss         | 2.19     |
|    explained_variance   | 0.784    |
|    learning_rate        | 0.000469 |
|    loss                 | 0.052    |
|    n_updates            | 38330    |
|    policy_gradient_loss | 0.00071  |
|    std                  | 0.0807   |
|    value_loss           | 0.00318  |
--------------------------------------
box reached target
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 3834    |
|    time_elapsed    | 12441   |
|    total_timesteps | 7852032 |
--------------------------------
box reached target
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3835      |
|    time_elapsed         | 12444     |
|    total_timesteps      | 7854080   |
| train/                  |           |
|    approx_kl            | 0.5018993 |
|    clip_fraction        | 0.45      |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.2       |
|    explained_variance   | 0.734     |
|    learning_rate        | 0.000469  |
|    loss                 | 0.00633   |
|    n_updates            | 38340     |
|    policy_gradient_loss | 0.0233    |
|    std                  | 0.0808    |
|    value_loss           | 0.00952   |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3836       |
|    time_elapsed         | 12447      |
|    total_timesteps      | 7856128    |
| train/                  |            |
|    approx_kl            | 0.17614466 |
|    clip_fraction        | 0.432      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.18       |
|    explained_variance   | 0.818      |
|    learning_rate        | 0.000468   |
|    loss                 | 0.049      |
|    n_updates            | 38350      |
|    policy_gradient_loss | 0.00969    |
|    std                  | 0.0815     |
|    value_loss           | 0.013      |
----------------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3837       |
|    time_elapsed         | 12450      |
|    total_timesteps      | 7858176    |
| train/                  |            |
|    approx_kl            | 0.09484485 |
|    clip_fraction        | 0.343      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.17       |
|    explained_variance   | 0.667      |
|    learning_rate        | 0.000468   |
|    loss                 | 0.108      |
|    n_updates            | 38360      |
|    policy_gradient_loss | 0.0381     |
|    std                  | 0.0823     |
|    value_loss           | 0.00136    |
----------------------------------------
box reached target
Eval num_timesteps=7860000, episode_reward=0.25 +/- 2.50
Episode length: 279.20 +/- 41.60
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 279        |
|    mean_reward          | 0.249      |
| time/                   |            |
|    total_timesteps      | 7860000    |
| train/                  |            |
|    approx_kl            | 0.13345326 |
|    clip_fraction        | 0.425      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.16       |
|    explained_variance   | 0.776      |
|    learning_rate        | 0.000468   |
|    loss                 | 0.0158     |
|    n_updates            | 38370      |
|    policy_gradient_loss | 0.0237     |
|    std                  | 0.0816     |
|    value_loss           | 0.012      |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 3838    |
|    time_elapsed    | 12454   |
|    total_timesteps | 7860224 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3839       |
|    time_elapsed         | 12457      |
|    total_timesteps      | 7862272    |
| train/                  |            |
|    approx_kl            | 0.17369008 |
|    clip_fraction        | 0.363      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.17       |
|    explained_variance   | -0.575     |
|    learning_rate        | 0.000467   |
|    loss                 | -0.0242    |
|    n_updates            | 38380      |
|    policy_gradient_loss | 0.00776    |
|    std                  | 0.0824     |
|    value_loss           | 0.00168    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3840       |
|    time_elapsed         | 12460      |
|    total_timesteps      | 7864320    |
| train/                  |            |
|    approx_kl            | 0.18727869 |
|    clip_fraction        | 0.442      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.14       |
|    explained_variance   | 0.777      |
|    learning_rate        | 0.000467   |
|    loss                 | -0.0106    |
|    n_updates            | 38390      |
|    policy_gradient_loss | 0.0225     |
|    std                  | 0.0833     |
|    value_loss           | 0.00326    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3841       |
|    time_elapsed         | 12463      |
|    total_timesteps      | 7866368    |
| train/                  |            |
|    approx_kl            | 0.26546317 |
|    clip_fraction        | 0.402      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.16       |
|    explained_variance   | 0.335      |
|    learning_rate        | 0.000466   |
|    loss                 | 0.00191    |
|    n_updates            | 38400      |
|    policy_gradient_loss | 0.00523    |
|    std                  | 0.0816     |
|    value_loss           | 0.00172    |
----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3842      |
|    time_elapsed         | 12466     |
|    total_timesteps      | 7868416   |
| train/                  |           |
|    approx_kl            | 0.1751072 |
|    clip_fraction        | 0.414     |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.15      |
|    explained_variance   | 0.7       |
|    learning_rate        | 0.000466  |
|    loss                 | 0.0426    |
|    n_updates            | 38410     |
|    policy_gradient_loss | 0.00197   |
|    std                  | 0.083     |
|    value_loss           | 0.00122   |
---------------------------------------
Eval num_timesteps=7870000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 300       |
|    mean_reward          | -1        |
| time/                   |           |
|    total_timesteps      | 7870000   |
| train/                  |           |
|    approx_kl            | 0.9347012 |
|    clip_fraction        | 0.399     |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.15      |
|    explained_variance   | 0.46      |
|    learning_rate        | 0.000466  |
|    loss                 | 0.0177    |
|    n_updates            | 38420     |
|    policy_gradient_loss | 0.00268   |
|    std                  | 0.0825    |
|    value_loss           | 0.00124   |
---------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 3843    |
|    time_elapsed    | 12470   |
|    total_timesteps | 7870464 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3844       |
|    time_elapsed         | 12473      |
|    total_timesteps      | 7872512    |
| train/                  |            |
|    approx_kl            | 0.18445326 |
|    clip_fraction        | 0.411      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.16       |
|    explained_variance   | 0.443      |
|    learning_rate        | 0.000465   |
|    loss                 | 0.092      |
|    n_updates            | 38430      |
|    policy_gradient_loss | 0.0205     |
|    std                  | 0.0815     |
|    value_loss           | 0.000792   |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3845       |
|    time_elapsed         | 12476      |
|    total_timesteps      | 7874560    |
| train/                  |            |
|    approx_kl            | 0.12667523 |
|    clip_fraction        | 0.393      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.19       |
|    explained_variance   | 0.533      |
|    learning_rate        | 0.000465   |
|    loss                 | 0.0565     |
|    n_updates            | 38440      |
|    policy_gradient_loss | 0.0141     |
|    std                  | 0.0803     |
|    value_loss           | 0.00108    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3846       |
|    time_elapsed         | 12479      |
|    total_timesteps      | 7876608    |
| train/                  |            |
|    approx_kl            | 0.52539504 |
|    clip_fraction        | 0.411      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.22       |
|    explained_variance   | 0.574      |
|    learning_rate        | 0.000464   |
|    loss                 | -0.0238    |
|    n_updates            | 38450      |
|    policy_gradient_loss | 0.00295    |
|    std                  | 0.0791     |
|    value_loss           | 0.00144    |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3847       |
|    time_elapsed         | 12482      |
|    total_timesteps      | 7878656    |
| train/                  |            |
|    approx_kl            | 0.38704237 |
|    clip_fraction        | 0.42       |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.25       |
|    explained_variance   | 0.573      |
|    learning_rate        | 0.000464   |
|    loss                 | 0.0163     |
|    n_updates            | 38460      |
|    policy_gradient_loss | 0.0132     |
|    std                  | 0.0778     |
|    value_loss           | 0.0019     |
----------------------------------------
box reached target
Eval num_timesteps=7880000, episode_reward=0.30 +/- 2.60
Episode length: 287.60 +/- 24.80
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 288        |
|    mean_reward          | 0.302      |
| time/                   |            |
|    total_timesteps      | 7880000    |
| train/                  |            |
|    approx_kl            | 0.19379064 |
|    clip_fraction        | 0.425      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.29       |
|    explained_variance   | 0.935      |
|    learning_rate        | 0.000464   |
|    loss                 | 0.0434     |
|    n_updates            | 38470      |
|    policy_gradient_loss | 0.0181     |
|    std                  | 0.0763     |
|    value_loss           | 0.00775    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 3848    |
|    time_elapsed    | 12486   |
|    total_timesteps | 7880704 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3849       |
|    time_elapsed         | 12489      |
|    total_timesteps      | 7882752    |
| train/                  |            |
|    approx_kl            | 0.34385425 |
|    clip_fraction        | 0.418      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.3        |
|    explained_variance   | 0.741      |
|    learning_rate        | 0.000463   |
|    loss                 | -0.00113   |
|    n_updates            | 38480      |
|    policy_gradient_loss | 0.00586    |
|    std                  | 0.0767     |
|    value_loss           | 0.00442    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3850       |
|    time_elapsed         | 12492      |
|    total_timesteps      | 7884800    |
| train/                  |            |
|    approx_kl            | 0.08682882 |
|    clip_fraction        | 0.351      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.29       |
|    explained_variance   | 0.704      |
|    learning_rate        | 0.000463   |
|    loss                 | 0.033      |
|    n_updates            | 38490      |
|    policy_gradient_loss | 0.0177     |
|    std                  | 0.0771     |
|    value_loss           | 0.000941   |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3851       |
|    time_elapsed         | 12495      |
|    total_timesteps      | 7886848    |
| train/                  |            |
|    approx_kl            | 0.28337055 |
|    clip_fraction        | 0.419      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.29       |
|    explained_variance   | 0.462      |
|    learning_rate        | 0.000462   |
|    loss                 | 0.00388    |
|    n_updates            | 38500      |
|    policy_gradient_loss | 0.0225     |
|    std                  | 0.0768     |
|    value_loss           | 0.00161    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3852       |
|    time_elapsed         | 12498      |
|    total_timesteps      | 7888896    |
| train/                  |            |
|    approx_kl            | 0.35238722 |
|    clip_fraction        | 0.433      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.31       |
|    explained_variance   | 0.899      |
|    learning_rate        | 0.000462   |
|    loss                 | 0.118      |
|    n_updates            | 38510      |
|    policy_gradient_loss | 0.0172     |
|    std                  | 0.0761     |
|    value_loss           | 0.00859    |
----------------------------------------
Eval num_timesteps=7890000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1         |
| time/                   |            |
|    total_timesteps      | 7890000    |
| train/                  |            |
|    approx_kl            | 0.23084767 |
|    clip_fraction        | 0.481      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.29       |
|    explained_variance   | 0.684      |
|    learning_rate        | 0.000462   |
|    loss                 | -0.016     |
|    n_updates            | 38520      |
|    policy_gradient_loss | 0.0226     |
|    std                  | 0.0781     |
|    value_loss           | 0.00278    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 3853    |
|    time_elapsed    | 12502   |
|    total_timesteps | 7890944 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3854       |
|    time_elapsed         | 12505      |
|    total_timesteps      | 7892992    |
| train/                  |            |
|    approx_kl            | 0.48107472 |
|    clip_fraction        | 0.495      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.25       |
|    explained_variance   | 0.487      |
|    learning_rate        | 0.000461   |
|    loss                 | 0.00295    |
|    n_updates            | 38530      |
|    policy_gradient_loss | 0.0274     |
|    std                  | 0.0789     |
|    value_loss           | 0.00165    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3855       |
|    time_elapsed         | 12508      |
|    total_timesteps      | 7895040    |
| train/                  |            |
|    approx_kl            | 0.31835413 |
|    clip_fraction        | 0.443      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.23       |
|    explained_variance   | 0.367      |
|    learning_rate        | 0.000461   |
|    loss                 | -0.00441   |
|    n_updates            | 38540      |
|    policy_gradient_loss | 0.00579    |
|    std                  | 0.0796     |
|    value_loss           | 0.00138    |
----------------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3856       |
|    time_elapsed         | 12511      |
|    total_timesteps      | 7897088    |
| train/                  |            |
|    approx_kl            | 0.18242463 |
|    clip_fraction        | 0.382      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.21       |
|    explained_variance   | 0.595      |
|    learning_rate        | 0.00046    |
|    loss                 | 0.013      |
|    n_updates            | 38550      |
|    policy_gradient_loss | 0.000347   |
|    std                  | 0.0802     |
|    value_loss           | 0.00117    |
----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3857      |
|    time_elapsed         | 12514     |
|    total_timesteps      | 7899136   |
| train/                  |           |
|    approx_kl            | 0.1892971 |
|    clip_fraction        | 0.424     |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.21      |
|    explained_variance   | 0.952     |
|    learning_rate        | 0.00046   |
|    loss                 | 0.0395    |
|    n_updates            | 38560     |
|    policy_gradient_loss | 0.00971   |
|    std                  | 0.0797    |
|    value_loss           | 0.00859   |
---------------------------------------
Eval num_timesteps=7900000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1         |
| time/                   |            |
|    total_timesteps      | 7900000    |
| train/                  |            |
|    approx_kl            | 0.21776974 |
|    clip_fraction        | 0.433      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.22       |
|    explained_variance   | 0.696      |
|    learning_rate        | 0.00046    |
|    loss                 | -0.0254    |
|    n_updates            | 38570      |
|    policy_gradient_loss | -0.00582   |
|    std                  | 0.079      |
|    value_loss           | 0.00132    |
----------------------------------------
box reached target
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 3858    |
|    time_elapsed    | 12518   |
|    total_timesteps | 7901184 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3859       |
|    time_elapsed         | 12521      |
|    total_timesteps      | 7903232    |
| train/                  |            |
|    approx_kl            | 0.14008075 |
|    clip_fraction        | 0.414      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.25       |
|    explained_variance   | 0.838      |
|    learning_rate        | 0.000459   |
|    loss                 | 0.0346     |
|    n_updates            | 38580      |
|    policy_gradient_loss | 0.0163     |
|    std                  | 0.0786     |
|    value_loss           | 0.0122     |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3860       |
|    time_elapsed         | 12524      |
|    total_timesteps      | 7905280    |
| train/                  |            |
|    approx_kl            | 0.21218234 |
|    clip_fraction        | 0.494      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.23       |
|    explained_variance   | 0.611      |
|    learning_rate        | 0.000459   |
|    loss                 | 0.0231     |
|    n_updates            | 38590      |
|    policy_gradient_loss | 0.0207     |
|    std                  | 0.0795     |
|    value_loss           | 0.00152    |
----------------------------------------
--------------------------------------
| time/                   |          |
|    fps                  | 631      |
|    iterations           | 3861     |
|    time_elapsed         | 12527    |
|    total_timesteps      | 7907328  |
| train/                  |          |
|    approx_kl            | 3.785569 |
|    clip_fraction        | 0.495    |
|    clip_range           | 0.2      |
|    entropy_loss         | 2.22     |
|    explained_variance   | 0.379    |
|    learning_rate        | 0.000458 |
|    loss                 | -0.00907 |
|    n_updates            | 38600    |
|    policy_gradient_loss | 0.00457  |
|    std                  | 0.0795   |
|    value_loss           | 0.00445  |
--------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3862       |
|    time_elapsed         | 12530      |
|    total_timesteps      | 7909376    |
| train/                  |            |
|    approx_kl            | 0.21358211 |
|    clip_fraction        | 0.389      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.21       |
|    explained_variance   | 0.325      |
|    learning_rate        | 0.000458   |
|    loss                 | 0.0324     |
|    n_updates            | 38610      |
|    policy_gradient_loss | 0.0127     |
|    std                  | 0.0802     |
|    value_loss           | 0.0021     |
----------------------------------------
Eval num_timesteps=7910000, episode_reward=-0.64 +/- 0.50
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -0.638     |
| time/                   |            |
|    total_timesteps      | 7910000    |
| train/                  |            |
|    approx_kl            | 0.23069307 |
|    clip_fraction        | 0.388      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.22       |
|    explained_variance   | 0.68       |
|    learning_rate        | 0.000458   |
|    loss                 | 0.0135     |
|    n_updates            | 38620      |
|    policy_gradient_loss | 0.00589    |
|    std                  | 0.0791     |
|    value_loss           | 0.000806   |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 3863    |
|    time_elapsed    | 12534   |
|    total_timesteps | 7911424 |
--------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3864       |
|    time_elapsed         | 12537      |
|    total_timesteps      | 7913472    |
| train/                  |            |
|    approx_kl            | 0.24413732 |
|    clip_fraction        | 0.428      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.22       |
|    explained_variance   | 0.791      |
|    learning_rate        | 0.000457   |
|    loss                 | -0.0235    |
|    n_updates            | 38630      |
|    policy_gradient_loss | 0.0055     |
|    std                  | 0.0795     |
|    value_loss           | 0.00428    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3865       |
|    time_elapsed         | 12541      |
|    total_timesteps      | 7915520    |
| train/                  |            |
|    approx_kl            | 0.26566225 |
|    clip_fraction        | 0.44       |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.23       |
|    explained_variance   | 0.164      |
|    learning_rate        | 0.000457   |
|    loss                 | 0.0697     |
|    n_updates            | 38640      |
|    policy_gradient_loss | 0.0253     |
|    std                  | 0.079      |
|    value_loss           | 0.0834     |
----------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3866      |
|    time_elapsed         | 12544     |
|    total_timesteps      | 7917568   |
| train/                  |           |
|    approx_kl            | 0.4081987 |
|    clip_fraction        | 0.411     |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.24      |
|    explained_variance   | -0.142    |
|    learning_rate        | 0.000456  |
|    loss                 | 0.0258    |
|    n_updates            | 38650     |
|    policy_gradient_loss | 0.0151    |
|    std                  | 0.0789    |
|    value_loss           | 0.00162   |
---------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3867      |
|    time_elapsed         | 12547     |
|    total_timesteps      | 7919616   |
| train/                  |           |
|    approx_kl            | 0.1673338 |
|    clip_fraction        | 0.397     |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.24      |
|    explained_variance   | 0.139     |
|    learning_rate        | 0.000456  |
|    loss                 | 0.0452    |
|    n_updates            | 38660     |
|    policy_gradient_loss | 0.0284    |
|    std                  | 0.0786    |
|    value_loss           | 0.0274    |
---------------------------------------
Eval num_timesteps=7920000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 300       |
|    mean_reward          | -1        |
| time/                   |           |
|    total_timesteps      | 7920000   |
| train/                  |           |
|    approx_kl            | 0.1926631 |
|    clip_fraction        | 0.42      |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.23      |
|    explained_variance   | 0.531     |
|    learning_rate        | 0.000456  |
|    loss                 | 0.0194    |
|    n_updates            | 38670     |
|    policy_gradient_loss | 0.015     |
|    std                  | 0.0794    |
|    value_loss           | 0.00206   |
---------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 3868    |
|    time_elapsed    | 12551   |
|    total_timesteps | 7921664 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3869       |
|    time_elapsed         | 12554      |
|    total_timesteps      | 7923712    |
| train/                  |            |
|    approx_kl            | 0.20322686 |
|    clip_fraction        | 0.413      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.22       |
|    explained_variance   | 0.593      |
|    learning_rate        | 0.000455   |
|    loss                 | 0.026      |
|    n_updates            | 38680      |
|    policy_gradient_loss | 0.0151     |
|    std                  | 0.0806     |
|    value_loss           | 0.00213    |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3870       |
|    time_elapsed         | 12557      |
|    total_timesteps      | 7925760    |
| train/                  |            |
|    approx_kl            | 0.26264322 |
|    clip_fraction        | 0.439      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.19       |
|    explained_variance   | 0.496      |
|    learning_rate        | 0.000455   |
|    loss                 | -0.021     |
|    n_updates            | 38690      |
|    policy_gradient_loss | 0.00109    |
|    std                  | 0.0809     |
|    value_loss           | 0.00186    |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3871       |
|    time_elapsed         | 12560      |
|    total_timesteps      | 7927808    |
| train/                  |            |
|    approx_kl            | 0.44284713 |
|    clip_fraction        | 0.423      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.22       |
|    explained_variance   | 0.881      |
|    learning_rate        | 0.000454   |
|    loss                 | 0.115      |
|    n_updates            | 38700      |
|    policy_gradient_loss | 0.00117    |
|    std                  | 0.0787     |
|    value_loss           | 0.0104     |
----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3872      |
|    time_elapsed         | 12563     |
|    total_timesteps      | 7929856   |
| train/                  |           |
|    approx_kl            | 0.2739631 |
|    clip_fraction        | 0.449     |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.25      |
|    explained_variance   | 0.869     |
|    learning_rate        | 0.000454  |
|    loss                 | -0.0117   |
|    n_updates            | 38710     |
|    policy_gradient_loss | 0.013     |
|    std                  | 0.0779    |
|    value_loss           | 0.0123    |
---------------------------------------
Eval num_timesteps=7930000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1         |
| time/                   |            |
|    total_timesteps      | 7930000    |
| train/                  |            |
|    approx_kl            | 0.53419614 |
|    clip_fraction        | 0.407      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.27       |
|    explained_variance   | 0.563      |
|    learning_rate        | 0.000454   |
|    loss                 | -0.0121    |
|    n_updates            | 38720      |
|    policy_gradient_loss | 0.00653    |
|    std                  | 0.0774     |
|    value_loss           | 0.00164    |
----------------------------------------
box reached target
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 3873    |
|    time_elapsed    | 12567   |
|    total_timesteps | 7931904 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3874       |
|    time_elapsed         | 12570      |
|    total_timesteps      | 7933952    |
| train/                  |            |
|    approx_kl            | 0.16229197 |
|    clip_fraction        | 0.444      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.28       |
|    explained_variance   | 0.95       |
|    learning_rate        | 0.000453   |
|    loss                 | 0.0504     |
|    n_updates            | 38730      |
|    policy_gradient_loss | 0.023      |
|    std                  | 0.078      |
|    value_loss           | 0.00458    |
----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3875      |
|    time_elapsed         | 12573     |
|    total_timesteps      | 7936000   |
| train/                  |           |
|    approx_kl            | 0.5305002 |
|    clip_fraction        | 0.403     |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.29      |
|    explained_variance   | 0.341     |
|    learning_rate        | 0.000453  |
|    loss                 | -0.0446   |
|    n_updates            | 38740     |
|    policy_gradient_loss | -0.00327  |
|    std                  | 0.0759    |
|    value_loss           | 0.00228   |
---------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3876      |
|    time_elapsed         | 12576     |
|    total_timesteps      | 7938048   |
| train/                  |           |
|    approx_kl            | 0.4885638 |
|    clip_fraction        | 0.461     |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.32      |
|    explained_variance   | 0.586     |
|    learning_rate        | 0.000452  |
|    loss                 | -0.0179   |
|    n_updates            | 38750     |
|    policy_gradient_loss | 0.0164    |
|    std                  | 0.0752    |
|    value_loss           | 0.0019    |
---------------------------------------
box reached target
Eval num_timesteps=7940000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1         |
| time/                   |            |
|    total_timesteps      | 7940000    |
| train/                  |            |
|    approx_kl            | 0.32918078 |
|    clip_fraction        | 0.374      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.34       |
|    explained_variance   | 0.556      |
|    learning_rate        | 0.000452   |
|    loss                 | 0.0341     |
|    n_updates            | 38760      |
|    policy_gradient_loss | 1.67e-05   |
|    std                  | 0.0746     |
|    value_loss           | 0.000971   |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 3877    |
|    time_elapsed    | 12580   |
|    total_timesteps | 7940096 |
--------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3878      |
|    time_elapsed         | 12583     |
|    total_timesteps      | 7942144   |
| train/                  |           |
|    approx_kl            | 0.2225922 |
|    clip_fraction        | 0.408     |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.35      |
|    explained_variance   | 0.969     |
|    learning_rate        | 0.000452  |
|    loss                 | -0.018    |
|    n_updates            | 38770     |
|    policy_gradient_loss | 0.0161    |
|    std                  | 0.0748    |
|    value_loss           | 0.00338   |
---------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3879      |
|    time_elapsed         | 12586     |
|    total_timesteps      | 7944192   |
| train/                  |           |
|    approx_kl            | 0.8213228 |
|    clip_fraction        | 0.435     |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.35      |
|    explained_variance   | 0.451     |
|    learning_rate        | 0.000451  |
|    loss                 | -0.0378   |
|    n_updates            | 38780     |
|    policy_gradient_loss | -0.000269 |
|    std                  | 0.0747    |
|    value_loss           | 0.00161   |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3880       |
|    time_elapsed         | 12589      |
|    total_timesteps      | 7946240    |
| train/                  |            |
|    approx_kl            | 0.13939008 |
|    clip_fraction        | 0.429      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.35       |
|    explained_variance   | 0.73       |
|    learning_rate        | 0.000451   |
|    loss                 | 0.0044     |
|    n_updates            | 38790      |
|    policy_gradient_loss | 0.0244     |
|    std                  | 0.0743     |
|    value_loss           | 0.001      |
----------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3881      |
|    time_elapsed         | 12592     |
|    total_timesteps      | 7948288   |
| train/                  |           |
|    approx_kl            | 0.1694678 |
|    clip_fraction        | 0.397     |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.36      |
|    explained_variance   | 0.438     |
|    learning_rate        | 0.00045   |
|    loss                 | 0.034     |
|    n_updates            | 38800     |
|    policy_gradient_loss | 0.0237    |
|    std                  | 0.0744    |
|    value_loss           | 0.00121   |
---------------------------------------
Eval num_timesteps=7950000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1         |
| time/                   |            |
|    total_timesteps      | 7950000    |
| train/                  |            |
|    approx_kl            | 0.74745286 |
|    clip_fraction        | 0.488      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.37       |
|    explained_variance   | 0.613      |
|    learning_rate        | 0.00045    |
|    loss                 | -0.0155    |
|    n_updates            | 38810      |
|    policy_gradient_loss | 0.0253     |
|    std                  | 0.0735     |
|    value_loss           | 0.019      |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 3882    |
|    time_elapsed    | 12596   |
|    total_timesteps | 7950336 |
--------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3883      |
|    time_elapsed         | 12599     |
|    total_timesteps      | 7952384   |
| train/                  |           |
|    approx_kl            | 0.5704639 |
|    clip_fraction        | 0.472     |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.37      |
|    explained_variance   | 0.317     |
|    learning_rate        | 0.00045   |
|    loss                 | -0.00427  |
|    n_updates            | 38820     |
|    policy_gradient_loss | 0.0213    |
|    std                  | 0.0745    |
|    value_loss           | 0.00138   |
---------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3884      |
|    time_elapsed         | 12602     |
|    total_timesteps      | 7954432   |
| train/                  |           |
|    approx_kl            | 0.3434388 |
|    clip_fraction        | 0.487     |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.33      |
|    explained_variance   | 0.648     |
|    learning_rate        | 0.000449  |
|    loss                 | -0.00763  |
|    n_updates            | 38830     |
|    policy_gradient_loss | 0.00933   |
|    std                  | 0.0763    |
|    value_loss           | 0.00331   |
---------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3885       |
|    time_elapsed         | 12605      |
|    total_timesteps      | 7956480    |
| train/                  |            |
|    approx_kl            | 0.22896571 |
|    clip_fraction        | 0.393      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.31       |
|    explained_variance   | 0.628      |
|    learning_rate        | 0.000449   |
|    loss                 | 0.0124     |
|    n_updates            | 38840      |
|    policy_gradient_loss | 0.0112     |
|    std                  | 0.0759     |
|    value_loss           | 0.00595    |
----------------------------------------
box reached target
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3886      |
|    time_elapsed         | 12608     |
|    total_timesteps      | 7958528   |
| train/                  |           |
|    approx_kl            | 0.1772688 |
|    clip_fraction        | 0.425     |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.33      |
|    explained_variance   | 0.938     |
|    learning_rate        | 0.000448  |
|    loss                 | -0.0288   |
|    n_updates            | 38850     |
|    policy_gradient_loss | 0.012     |
|    std                  | 0.0752    |
|    value_loss           | 0.00389   |
---------------------------------------
box reached target
box reached target
Eval num_timesteps=7960000, episode_reward=0.24 +/- 2.48
Episode length: 269.00 +/- 62.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 269        |
|    mean_reward          | 0.239      |
| time/                   |            |
|    total_timesteps      | 7960000    |
| train/                  |            |
|    approx_kl            | 0.11019467 |
|    clip_fraction        | 0.446      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.3        |
|    explained_variance   | 0.846      |
|    learning_rate        | 0.000448   |
|    loss                 | 0.0189     |
|    n_updates            | 38860      |
|    policy_gradient_loss | 0.0148     |
|    std                  | 0.0782     |
|    value_loss           | 0.0644     |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 3887    |
|    time_elapsed    | 12612   |
|    total_timesteps | 7960576 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3888       |
|    time_elapsed         | 12615      |
|    total_timesteps      | 7962624    |
| train/                  |            |
|    approx_kl            | 0.25355834 |
|    clip_fraction        | 0.459      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.23       |
|    explained_variance   | 0.94       |
|    learning_rate        | 0.000448   |
|    loss                 | -0.00657   |
|    n_updates            | 38870      |
|    policy_gradient_loss | 0.0279     |
|    std                  | 0.0798     |
|    value_loss           | 0.00854    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3889       |
|    time_elapsed         | 12619      |
|    total_timesteps      | 7964672    |
| train/                  |            |
|    approx_kl            | 0.18531898 |
|    clip_fraction        | 0.412      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.2        |
|    explained_variance   | 0.532      |
|    learning_rate        | 0.000447   |
|    loss                 | 0.0616     |
|    n_updates            | 38880      |
|    policy_gradient_loss | 0.00431    |
|    std                  | 0.0803     |
|    value_loss           | 0.00504    |
----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3890      |
|    time_elapsed         | 12622     |
|    total_timesteps      | 7966720   |
| train/                  |           |
|    approx_kl            | 0.1463589 |
|    clip_fraction        | 0.424     |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.2       |
|    explained_variance   | 0.584     |
|    learning_rate        | 0.000447  |
|    loss                 | 0.0459    |
|    n_updates            | 38890     |
|    policy_gradient_loss | 0.0273    |
|    std                  | 0.0803    |
|    value_loss           | 0.00645   |
---------------------------------------
box reached target
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3891      |
|    time_elapsed         | 12625     |
|    total_timesteps      | 7968768   |
| train/                  |           |
|    approx_kl            | 0.2160462 |
|    clip_fraction        | 0.378     |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.21      |
|    explained_variance   | 0.404     |
|    learning_rate        | 0.000446  |
|    loss                 | -0.0333   |
|    n_updates            | 38900     |
|    policy_gradient_loss | -0.00482  |
|    std                  | 0.0798    |
|    value_loss           | 0.00274   |
---------------------------------------
Eval num_timesteps=7970000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1         |
| time/                   |            |
|    total_timesteps      | 7970000    |
| train/                  |            |
|    approx_kl            | 0.11617535 |
|    clip_fraction        | 0.379      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.22       |
|    explained_variance   | 0.981      |
|    learning_rate        | 0.000446   |
|    loss                 | 0.0286     |
|    n_updates            | 38910      |
|    policy_gradient_loss | 0.0152     |
|    std                  | 0.0798     |
|    value_loss           | 0.00634    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 3892    |
|    time_elapsed    | 12629   |
|    total_timesteps | 7970816 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3893       |
|    time_elapsed         | 12632      |
|    total_timesteps      | 7972864    |
| train/                  |            |
|    approx_kl            | 0.19243738 |
|    clip_fraction        | 0.403      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.21       |
|    explained_variance   | -0.0592    |
|    learning_rate        | 0.000446   |
|    loss                 | -0.0322    |
|    n_updates            | 38920      |
|    policy_gradient_loss | -0.00011   |
|    std                  | 0.0798     |
|    value_loss           | 0.00471    |
----------------------------------------
--------------------------------------
| time/                   |          |
|    fps                  | 631      |
|    iterations           | 3894     |
|    time_elapsed         | 12635    |
|    total_timesteps      | 7974912  |
| train/                  |          |
|    approx_kl            | 0.516806 |
|    clip_fraction        | 0.42     |
|    clip_range           | 0.2      |
|    entropy_loss         | 2.22     |
|    explained_variance   | 0.62     |
|    learning_rate        | 0.000445 |
|    loss                 | -0.0385  |
|    n_updates            | 38930    |
|    policy_gradient_loss | 0.00358  |
|    std                  | 0.0792   |
|    value_loss           | 0.00321  |
--------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3895       |
|    time_elapsed         | 12638      |
|    total_timesteps      | 7976960    |
| train/                  |            |
|    approx_kl            | 0.11999039 |
|    clip_fraction        | 0.394      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.23       |
|    explained_variance   | 0.546      |
|    learning_rate        | 0.000445   |
|    loss                 | 0.0234     |
|    n_updates            | 38940      |
|    policy_gradient_loss | 0.00993    |
|    std                  | 0.0791     |
|    value_loss           | 0.0014     |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3896       |
|    time_elapsed         | 12641      |
|    total_timesteps      | 7979008    |
| train/                  |            |
|    approx_kl            | 0.44315836 |
|    clip_fraction        | 0.378      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.24       |
|    explained_variance   | 0.524      |
|    learning_rate        | 0.000444   |
|    loss                 | -0.0445    |
|    n_updates            | 38950      |
|    policy_gradient_loss | -0.00736   |
|    std                  | 0.0781     |
|    value_loss           | 0.00178    |
----------------------------------------
Eval num_timesteps=7980000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1         |
| time/                   |            |
|    total_timesteps      | 7980000    |
| train/                  |            |
|    approx_kl            | 0.22300133 |
|    clip_fraction        | 0.399      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.26       |
|    explained_variance   | 0.649      |
|    learning_rate        | 0.000444   |
|    loss                 | -0.0272    |
|    n_updates            | 38960      |
|    policy_gradient_loss | 0.00618    |
|    std                  | 0.0781     |
|    value_loss           | 0.00108    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 3897    |
|    time_elapsed    | 12645   |
|    total_timesteps | 7981056 |
--------------------------------
--------------------------------------
| time/                   |          |
|    fps                  | 631      |
|    iterations           | 3898     |
|    time_elapsed         | 12648    |
|    total_timesteps      | 7983104  |
| train/                  |          |
|    approx_kl            | 0.202257 |
|    clip_fraction        | 0.405    |
|    clip_range           | 0.2      |
|    entropy_loss         | 2.27     |
|    explained_variance   | 0.741    |
|    learning_rate        | 0.000444 |
|    loss                 | 0.00891  |
|    n_updates            | 38970    |
|    policy_gradient_loss | 0.0136   |
|    std                  | 0.0773   |
|    value_loss           | 0.00093  |
--------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3899      |
|    time_elapsed         | 12651     |
|    total_timesteps      | 7985152   |
| train/                  |           |
|    approx_kl            | 1.8587918 |
|    clip_fraction        | 0.532     |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.28      |
|    explained_variance   | 0.414     |
|    learning_rate        | 0.000443  |
|    loss                 | -0.0361   |
|    n_updates            | 38980     |
|    policy_gradient_loss | 0.468     |
|    std                  | 0.0768    |
|    value_loss           | 0.00806   |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3900       |
|    time_elapsed         | 12654      |
|    total_timesteps      | 7987200    |
| train/                  |            |
|    approx_kl            | 0.06532396 |
|    clip_fraction        | 0.37       |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.29       |
|    explained_variance   | 0.741      |
|    learning_rate        | 0.000443   |
|    loss                 | -0.0448    |
|    n_updates            | 38990      |
|    policy_gradient_loss | 0.0177     |
|    std                  | 0.0776     |
|    value_loss           | 0.00309    |
----------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3901      |
|    time_elapsed         | 12657     |
|    total_timesteps      | 7989248   |
| train/                  |           |
|    approx_kl            | 0.2055783 |
|    clip_fraction        | 0.46      |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.27      |
|    explained_variance   | 0.639     |
|    learning_rate        | 0.000442  |
|    loss                 | -0.0533   |
|    n_updates            | 39000     |
|    policy_gradient_loss | 0.0188    |
|    std                  | 0.0779    |
|    value_loss           | 0.000891  |
---------------------------------------
Eval num_timesteps=7990000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1         |
| time/                   |            |
|    total_timesteps      | 7990000    |
| train/                  |            |
|    approx_kl            | 0.28683043 |
|    clip_fraction        | 0.44       |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.28       |
|    explained_variance   | 0.955      |
|    learning_rate        | 0.000442   |
|    loss                 | -0.00583   |
|    n_updates            | 39010      |
|    policy_gradient_loss | 0.00768    |
|    std                  | 0.0765     |
|    value_loss           | 0.0026     |
----------------------------------------
box reached target
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 3902    |
|    time_elapsed    | 12662   |
|    total_timesteps | 7991296 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3903       |
|    time_elapsed         | 12665      |
|    total_timesteps      | 7993344    |
| train/                  |            |
|    approx_kl            | 0.49911967 |
|    clip_fraction        | 0.459      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.3        |
|    explained_variance   | 0.647      |
|    learning_rate        | 0.000442   |
|    loss                 | 0.0385     |
|    n_updates            | 39020      |
|    policy_gradient_loss | 0.0124     |
|    std                  | 0.076      |
|    value_loss           | 0.0139     |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3904       |
|    time_elapsed         | 12668      |
|    total_timesteps      | 7995392    |
| train/                  |            |
|    approx_kl            | 0.33394197 |
|    clip_fraction        | 0.408      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.3        |
|    explained_variance   | 0.697      |
|    learning_rate        | 0.000441   |
|    loss                 | -0.055     |
|    n_updates            | 39030      |
|    policy_gradient_loss | -0.00791   |
|    std                  | 0.0765     |
|    value_loss           | 0.00286    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3905       |
|    time_elapsed         | 12671      |
|    total_timesteps      | 7997440    |
| train/                  |            |
|    approx_kl            | 0.19980597 |
|    clip_fraction        | 0.451      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.31       |
|    explained_variance   | 0.472      |
|    learning_rate        | 0.000441   |
|    loss                 | 0.0064     |
|    n_updates            | 39040      |
|    policy_gradient_loss | 0.0111     |
|    std                  | 0.0757     |
|    value_loss           | 0.0016     |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3906       |
|    time_elapsed         | 12674      |
|    total_timesteps      | 7999488    |
| train/                  |            |
|    approx_kl            | 0.34244066 |
|    clip_fraction        | 0.394      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.33       |
|    explained_variance   | 0.754      |
|    learning_rate        | 0.00044    |
|    loss                 | -0.0197    |
|    n_updates            | 39050      |
|    policy_gradient_loss | 0.00367    |
|    std                  | 0.0751     |
|    value_loss           | 0.000697   |
----------------------------------------
Eval num_timesteps=8000000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1         |
| time/                   |            |
|    total_timesteps      | 8000000    |
| train/                  |            |
|    approx_kl            | 0.30820826 |
|    clip_fraction        | 0.405      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.36       |
|    explained_variance   | 0.275      |
|    learning_rate        | 0.00044    |
|    loss                 | -0.0263    |
|    n_updates            | 39060      |
|    policy_gradient_loss | 0.00652    |
|    std                  | 0.0733     |
|    value_loss           | 0.00256    |
----------------------------------------
box reached target
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 3907    |
|    time_elapsed    | 12678   |
|    total_timesteps | 8001536 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3908       |
|    time_elapsed         | 12681      |
|    total_timesteps      | 8003584    |
| train/                  |            |
|    approx_kl            | 0.34960175 |
|    clip_fraction        | 0.492      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.4        |
|    explained_variance   | 0.901      |
|    learning_rate        | 0.00044    |
|    loss                 | -0.00572   |
|    n_updates            | 39070      |
|    policy_gradient_loss | 0.0132     |
|    std                  | 0.0722     |
|    value_loss           | 0.0114     |
----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3909      |
|    time_elapsed         | 12684     |
|    total_timesteps      | 8005632   |
| train/                  |           |
|    approx_kl            | 0.3487128 |
|    clip_fraction        | 0.43      |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.42      |
|    explained_variance   | 0.616     |
|    learning_rate        | 0.000439  |
|    loss                 | 0.0324    |
|    n_updates            | 39080     |
|    policy_gradient_loss | 0.000973  |
|    std                  | 0.0719    |
|    value_loss           | 0.00128   |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3910       |
|    time_elapsed         | 12687      |
|    total_timesteps      | 8007680    |
| train/                  |            |
|    approx_kl            | 0.45016578 |
|    clip_fraction        | 0.447      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.44       |
|    explained_variance   | 0.539      |
|    learning_rate        | 0.000439   |
|    loss                 | 0.026      |
|    n_updates            | 39090      |
|    policy_gradient_loss | 0.0329     |
|    std                  | 0.0708     |
|    value_loss           | 0.000785   |
----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3911      |
|    time_elapsed         | 12691     |
|    total_timesteps      | 8009728   |
| train/                  |           |
|    approx_kl            | 0.4617148 |
|    clip_fraction        | 0.42      |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.46      |
|    explained_variance   | 0.112     |
|    learning_rate        | 0.000439  |
|    loss                 | 0.0354    |
|    n_updates            | 39100     |
|    policy_gradient_loss | 0.0237    |
|    std                  | 0.0706    |
|    value_loss           | 0.00204   |
---------------------------------------
Eval num_timesteps=8010000, episode_reward=-0.81 +/- 0.38
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -0.811     |
| time/                   |            |
|    total_timesteps      | 8010000    |
| train/                  |            |
|    approx_kl            | 0.21609813 |
|    clip_fraction        | 0.388      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.47       |
|    explained_variance   | 0.38       |
|    learning_rate        | 0.000438   |
|    loss                 | -0.0224    |
|    n_updates            | 39110      |
|    policy_gradient_loss | 0.0157     |
|    std                  | 0.07       |
|    value_loss           | 0.00105    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 3912    |
|    time_elapsed    | 12695   |
|    total_timesteps | 8011776 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3913       |
|    time_elapsed         | 12698      |
|    total_timesteps      | 8013824    |
| train/                  |            |
|    approx_kl            | 0.20437075 |
|    clip_fraction        | 0.494      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.48       |
|    explained_variance   | 0.495      |
|    learning_rate        | 0.000438   |
|    loss                 | 0.0865     |
|    n_updates            | 39120      |
|    policy_gradient_loss | 0.0325     |
|    std                  | 0.0698     |
|    value_loss           | 0.00142    |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3914       |
|    time_elapsed         | 12701      |
|    total_timesteps      | 8015872    |
| train/                  |            |
|    approx_kl            | 0.22354084 |
|    clip_fraction        | 0.405      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.51       |
|    explained_variance   | 0.703      |
|    learning_rate        | 0.000437   |
|    loss                 | -0.00295   |
|    n_updates            | 39130      |
|    policy_gradient_loss | 0.00982    |
|    std                  | 0.0684     |
|    value_loss           | 0.000875   |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3915       |
|    time_elapsed         | 12704      |
|    total_timesteps      | 8017920    |
| train/                  |            |
|    approx_kl            | 0.23028553 |
|    clip_fraction        | 0.446      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.55       |
|    explained_variance   | 0.928      |
|    learning_rate        | 0.000437   |
|    loss                 | 0.114      |
|    n_updates            | 39140      |
|    policy_gradient_loss | 0.0169     |
|    std                  | 0.0674     |
|    value_loss           | 0.00478    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3916       |
|    time_elapsed         | 12707      |
|    total_timesteps      | 8019968    |
| train/                  |            |
|    approx_kl            | 0.35063326 |
|    clip_fraction        | 0.422      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.56       |
|    explained_variance   | 0.406      |
|    learning_rate        | 0.000437   |
|    loss                 | -0.0308    |
|    n_updates            | 39150      |
|    policy_gradient_loss | 0.0103     |
|    std                  | 0.0672     |
|    value_loss           | 0.00306    |
----------------------------------------
box reached target
Eval num_timesteps=8020000, episode_reward=0.25 +/- 2.50
Episode length: 274.60 +/- 50.80
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 275        |
|    mean_reward          | 0.248      |
| time/                   |            |
|    total_timesteps      | 8020000    |
| train/                  |            |
|    approx_kl            | 0.29844883 |
|    clip_fraction        | 0.478      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.55       |
|    explained_variance   | 0.631      |
|    learning_rate        | 0.000436   |
|    loss                 | -0.0243    |
|    n_updates            | 39160      |
|    policy_gradient_loss | 0.0105     |
|    std                  | 0.0679     |
|    value_loss           | 0.00155    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 3917    |
|    time_elapsed    | 12711   |
|    total_timesteps | 8022016 |
--------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3918       |
|    time_elapsed         | 12714      |
|    total_timesteps      | 8024064    |
| train/                  |            |
|    approx_kl            | 0.18117288 |
|    clip_fraction        | 0.467      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.54       |
|    explained_variance   | 0.323      |
|    learning_rate        | 0.000436   |
|    loss                 | -0.012     |
|    n_updates            | 39170      |
|    policy_gradient_loss | 0.0147     |
|    std                  | 0.0679     |
|    value_loss           | 0.00145    |
----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3919      |
|    time_elapsed         | 12717     |
|    total_timesteps      | 8026112   |
| train/                  |           |
|    approx_kl            | 0.2790765 |
|    clip_fraction        | 0.451     |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.54      |
|    explained_variance   | 0.745     |
|    learning_rate        | 0.000435  |
|    loss                 | -0.00995  |
|    n_updates            | 39180     |
|    policy_gradient_loss | 0.00206   |
|    std                  | 0.0678    |
|    value_loss           | 0.0158    |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3920       |
|    time_elapsed         | 12720      |
|    total_timesteps      | 8028160    |
| train/                  |            |
|    approx_kl            | 0.25278705 |
|    clip_fraction        | 0.387      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.58       |
|    explained_variance   | -0.902     |
|    learning_rate        | 0.000435   |
|    loss                 | -0.0284    |
|    n_updates            | 39190      |
|    policy_gradient_loss | 0.000549   |
|    std                  | 0.0656     |
|    value_loss           | 0.00319    |
----------------------------------------
Eval num_timesteps=8030000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 300       |
|    mean_reward          | -1        |
| time/                   |           |
|    total_timesteps      | 8030000   |
| train/                  |           |
|    approx_kl            | 0.4131699 |
|    clip_fraction        | 0.451     |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.61      |
|    explained_variance   | 0.529     |
|    learning_rate        | 0.000435  |
|    loss                 | -0.0179   |
|    n_updates            | 39200     |
|    policy_gradient_loss | 0.00197   |
|    std                  | 0.0659    |
|    value_loss           | 0.00114   |
---------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 3921    |
|    time_elapsed    | 12724   |
|    total_timesteps | 8030208 |
--------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3922       |
|    time_elapsed         | 12727      |
|    total_timesteps      | 8032256    |
| train/                  |            |
|    approx_kl            | 0.16800171 |
|    clip_fraction        | 0.431      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.6        |
|    explained_variance   | 0.673      |
|    learning_rate        | 0.000434   |
|    loss                 | -0.00185   |
|    n_updates            | 39210      |
|    policy_gradient_loss | 0.0226     |
|    std                  | 0.0662     |
|    value_loss           | 0.00125    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3923       |
|    time_elapsed         | 12730      |
|    total_timesteps      | 8034304    |
| train/                  |            |
|    approx_kl            | 0.24782394 |
|    clip_fraction        | 0.411      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.59       |
|    explained_variance   | 0.921      |
|    learning_rate        | 0.000434   |
|    loss                 | -0.0157    |
|    n_updates            | 39220      |
|    policy_gradient_loss | 0.0317     |
|    std                  | 0.0664     |
|    value_loss           | 0.00677    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3924       |
|    time_elapsed         | 12733      |
|    total_timesteps      | 8036352    |
| train/                  |            |
|    approx_kl            | 0.35620314 |
|    clip_fraction        | 0.469      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.58       |
|    explained_variance   | 0.441      |
|    learning_rate        | 0.000433   |
|    loss                 | -0.00493   |
|    n_updates            | 39230      |
|    policy_gradient_loss | 0.0224     |
|    std                  | 0.0663     |
|    value_loss           | 0.00117    |
----------------------------------------
--------------------------------------
| time/                   |          |
|    fps                  | 631      |
|    iterations           | 3925     |
|    time_elapsed         | 12736    |
|    total_timesteps      | 8038400  |
| train/                  |          |
|    approx_kl            | 0.556485 |
|    clip_fraction        | 0.482    |
|    clip_range           | 0.2      |
|    entropy_loss         | 2.58     |
|    explained_variance   | 0.678    |
|    learning_rate        | 0.000433 |
|    loss                 | 0.0628   |
|    n_updates            | 39240    |
|    policy_gradient_loss | 0.0092   |
|    std                  | 0.0671   |
|    value_loss           | 0.0104   |
--------------------------------------
box reached target
Eval num_timesteps=8040000, episode_reward=-0.70 +/- 0.60
Episode length: 300.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 300       |
|    mean_reward          | -0.702    |
| time/                   |           |
|    total_timesteps      | 8040000   |
| train/                  |           |
|    approx_kl            | 0.3255132 |
|    clip_fraction        | 0.485     |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.57      |
|    explained_variance   | 0.89      |
|    learning_rate        | 0.000433  |
|    loss                 | -0.0207   |
|    n_updates            | 39250     |
|    policy_gradient_loss | 0.0169    |
|    std                  | 0.0667    |
|    value_loss           | 0.0119    |
---------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 3926    |
|    time_elapsed    | 12740   |
|    total_timesteps | 8040448 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3927       |
|    time_elapsed         | 12743      |
|    total_timesteps      | 8042496    |
| train/                  |            |
|    approx_kl            | 0.45992613 |
|    clip_fraction        | 0.431      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.57       |
|    explained_variance   | 0.955      |
|    learning_rate        | 0.000432   |
|    loss                 | 0.136      |
|    n_updates            | 39260      |
|    policy_gradient_loss | 0.00617    |
|    std                  | 0.0672     |
|    value_loss           | 0.00638    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3928       |
|    time_elapsed         | 12746      |
|    total_timesteps      | 8044544    |
| train/                  |            |
|    approx_kl            | 0.22446796 |
|    clip_fraction        | 0.444      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.56       |
|    explained_variance   | 0.757      |
|    learning_rate        | 0.000432   |
|    loss                 | -0.00407   |
|    n_updates            | 39270      |
|    policy_gradient_loss | 0.0191     |
|    std                  | 0.067      |
|    value_loss           | 0.00598    |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3929       |
|    time_elapsed         | 12749      |
|    total_timesteps      | 8046592    |
| train/                  |            |
|    approx_kl            | 0.20374511 |
|    clip_fraction        | 0.409      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.55       |
|    explained_variance   | 0.842      |
|    learning_rate        | 0.000431   |
|    loss                 | 0.0643     |
|    n_updates            | 39280      |
|    policy_gradient_loss | 0.00921    |
|    std                  | 0.068      |
|    value_loss           | 0.00374    |
----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3930      |
|    time_elapsed         | 12752     |
|    total_timesteps      | 8048640   |
| train/                  |           |
|    approx_kl            | 0.1267659 |
|    clip_fraction        | 0.467     |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.54      |
|    explained_variance   | 0.935     |
|    learning_rate        | 0.000431  |
|    loss                 | -0.0482   |
|    n_updates            | 39290     |
|    policy_gradient_loss | 0.00578   |
|    std                  | 0.0676    |
|    value_loss           | 0.00384   |
---------------------------------------
Eval num_timesteps=8050000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1         |
| time/                   |            |
|    total_timesteps      | 8050000    |
| train/                  |            |
|    approx_kl            | 0.33787203 |
|    clip_fraction        | 0.459      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.55       |
|    explained_variance   | 0.679      |
|    learning_rate        | 0.000431   |
|    loss                 | 0.0126     |
|    n_updates            | 39300      |
|    policy_gradient_loss | 0.00152    |
|    std                  | 0.0674     |
|    value_loss           | 0.00253    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 3931    |
|    time_elapsed    | 12756   |
|    total_timesteps | 8050688 |
--------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3932      |
|    time_elapsed         | 12759     |
|    total_timesteps      | 8052736   |
| train/                  |           |
|    approx_kl            | 0.1586965 |
|    clip_fraction        | 0.437     |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.54      |
|    explained_variance   | 0.561     |
|    learning_rate        | 0.00043   |
|    loss                 | -0.046    |
|    n_updates            | 39310     |
|    policy_gradient_loss | 0.00684   |
|    std                  | 0.068     |
|    value_loss           | 0.00222   |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3933       |
|    time_elapsed         | 12762      |
|    total_timesteps      | 8054784    |
| train/                  |            |
|    approx_kl            | 0.48646235 |
|    clip_fraction        | 0.447      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.53       |
|    explained_variance   | 0.649      |
|    learning_rate        | 0.00043    |
|    loss                 | 0.0725     |
|    n_updates            | 39320      |
|    policy_gradient_loss | 0.0355     |
|    std                  | 0.0684     |
|    value_loss           | 0.0156     |
----------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3934      |
|    time_elapsed         | 12765     |
|    total_timesteps      | 8056832   |
| train/                  |           |
|    approx_kl            | 0.3075509 |
|    clip_fraction        | 0.461     |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.53      |
|    explained_variance   | 0.0407    |
|    learning_rate        | 0.000429  |
|    loss                 | -0.0355   |
|    n_updates            | 39330     |
|    policy_gradient_loss | -0.002    |
|    std                  | 0.0673    |
|    value_loss           | 0.00156   |
---------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3935       |
|    time_elapsed         | 12768      |
|    total_timesteps      | 8058880    |
| train/                  |            |
|    approx_kl            | 0.41360086 |
|    clip_fraction        | 0.489      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.58       |
|    explained_variance   | 0.881      |
|    learning_rate        | 0.000429   |
|    loss                 | -0.0411    |
|    n_updates            | 39340      |
|    policy_gradient_loss | 0.0122     |
|    std                  | 0.0665     |
|    value_loss           | 0.0312     |
----------------------------------------
Eval num_timesteps=8060000, episode_reward=-0.56 +/- 0.54
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -0.56      |
| time/                   |            |
|    total_timesteps      | 8060000    |
| train/                  |            |
|    approx_kl            | 0.47759315 |
|    clip_fraction        | 0.471      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.61       |
|    explained_variance   | 0.825      |
|    learning_rate        | 0.000429   |
|    loss                 | -0.00642   |
|    n_updates            | 39350      |
|    policy_gradient_loss | 0.0145     |
|    std                  | 0.0653     |
|    value_loss           | 0.0105     |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 3936    |
|    time_elapsed    | 12772   |
|    total_timesteps | 8060928 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3937       |
|    time_elapsed         | 12775      |
|    total_timesteps      | 8062976    |
| train/                  |            |
|    approx_kl            | 0.13274868 |
|    clip_fraction        | 0.454      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.61       |
|    explained_variance   | 0.503      |
|    learning_rate        | 0.000428   |
|    loss                 | -0.0087    |
|    n_updates            | 39360      |
|    policy_gradient_loss | 0.0128     |
|    std                  | 0.0658     |
|    value_loss           | 0.00255    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3938       |
|    time_elapsed         | 12778      |
|    total_timesteps      | 8065024    |
| train/                  |            |
|    approx_kl            | 0.73536325 |
|    clip_fraction        | 0.41       |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.6        |
|    explained_variance   | 0.691      |
|    learning_rate        | 0.000428   |
|    loss                 | -0.0307    |
|    n_updates            | 39370      |
|    policy_gradient_loss | 0.0197     |
|    std                  | 0.0657     |
|    value_loss           | 0.00109    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3939       |
|    time_elapsed         | 12781      |
|    total_timesteps      | 8067072    |
| train/                  |            |
|    approx_kl            | 0.51242226 |
|    clip_fraction        | 0.5        |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.61       |
|    explained_variance   | 0.64       |
|    learning_rate        | 0.000427   |
|    loss                 | -0.0289    |
|    n_updates            | 39380      |
|    policy_gradient_loss | 0.0142     |
|    std                  | 0.065      |
|    value_loss           | 0.00094    |
----------------------------------------
--------------------------------------
| time/                   |          |
|    fps                  | 631      |
|    iterations           | 3940     |
|    time_elapsed         | 12785    |
|    total_timesteps      | 8069120  |
| train/                  |          |
|    approx_kl            | 4.166229 |
|    clip_fraction        | 0.471    |
|    clip_range           | 0.2      |
|    entropy_loss         | 2.64     |
|    explained_variance   | 0.196    |
|    learning_rate        | 0.000427 |
|    loss                 | 0.00527  |
|    n_updates            | 39390    |
|    policy_gradient_loss | 0.0143   |
|    std                  | 0.0641   |
|    value_loss           | 0.0016   |
--------------------------------------
Eval num_timesteps=8070000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 300       |
|    mean_reward          | -1        |
| time/                   |           |
|    total_timesteps      | 8070000   |
| train/                  |           |
|    approx_kl            | 0.4781392 |
|    clip_fraction        | 0.406     |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.68      |
|    explained_variance   | 0.443     |
|    learning_rate        | 0.000427  |
|    loss                 | 0.00926   |
|    n_updates            | 39400     |
|    policy_gradient_loss | 0.0154    |
|    std                  | 0.0629    |
|    value_loss           | 0.00104   |
---------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 3941    |
|    time_elapsed    | 12789   |
|    total_timesteps | 8071168 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3942       |
|    time_elapsed         | 12792      |
|    total_timesteps      | 8073216    |
| train/                  |            |
|    approx_kl            | 0.34201503 |
|    clip_fraction        | 0.431      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.67       |
|    explained_variance   | 0.487      |
|    learning_rate        | 0.000426   |
|    loss                 | -0.0378    |
|    n_updates            | 39410      |
|    policy_gradient_loss | 0.0105     |
|    std                  | 0.0637     |
|    value_loss           | 0.00131    |
----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3943      |
|    time_elapsed         | 12795     |
|    total_timesteps      | 8075264   |
| train/                  |           |
|    approx_kl            | 4.7464356 |
|    clip_fraction        | 0.494     |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.68      |
|    explained_variance   | 0.456     |
|    learning_rate        | 0.000426  |
|    loss                 | 0.0279    |
|    n_updates            | 39420     |
|    policy_gradient_loss | 0.0134    |
|    std                  | 0.0624    |
|    value_loss           | 0.00129   |
---------------------------------------
box reached target
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3944      |
|    time_elapsed         | 12798     |
|    total_timesteps      | 8077312   |
| train/                  |           |
|    approx_kl            | 2.8480327 |
|    clip_fraction        | 0.493     |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.7       |
|    explained_variance   | 0.858     |
|    learning_rate        | 0.000425  |
|    loss                 | 0.00148   |
|    n_updates            | 39430     |
|    policy_gradient_loss | 0.0119    |
|    std                  | 0.0628    |
|    value_loss           | 0.00246   |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3945       |
|    time_elapsed         | 12801      |
|    total_timesteps      | 8079360    |
| train/                  |            |
|    approx_kl            | 0.18073472 |
|    clip_fraction        | 0.469      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.72       |
|    explained_variance   | 0.526      |
|    learning_rate        | 0.000425   |
|    loss                 | 0.093      |
|    n_updates            | 39440      |
|    policy_gradient_loss | 0.0127     |
|    std                  | 0.0614     |
|    value_loss           | 0.151      |
----------------------------------------
Eval num_timesteps=8080000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1         |
| time/                   |            |
|    total_timesteps      | 8080000    |
| train/                  |            |
|    approx_kl            | 0.52928764 |
|    clip_fraction        | 0.445      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.74       |
|    explained_variance   | 0.547      |
|    learning_rate        | 0.000425   |
|    loss                 | -0.0381    |
|    n_updates            | 39450      |
|    policy_gradient_loss | -0.0009    |
|    std                  | 0.0619     |
|    value_loss           | 0.00294    |
----------------------------------------
box reached target
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 3946    |
|    time_elapsed    | 12805   |
|    total_timesteps | 8081408 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3947       |
|    time_elapsed         | 12808      |
|    total_timesteps      | 8083456    |
| train/                  |            |
|    approx_kl            | 0.24850872 |
|    clip_fraction        | 0.47       |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.74       |
|    explained_variance   | 0.341      |
|    learning_rate        | 0.000424   |
|    loss                 | 0.00816    |
|    n_updates            | 39460      |
|    policy_gradient_loss | 0.0803     |
|    std                  | 0.0614     |
|    value_loss           | 0.0564     |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3948       |
|    time_elapsed         | 12811      |
|    total_timesteps      | 8085504    |
| train/                  |            |
|    approx_kl            | 0.21765497 |
|    clip_fraction        | 0.465      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.76       |
|    explained_variance   | 0.489      |
|    learning_rate        | 0.000424   |
|    loss                 | -0.0151    |
|    n_updates            | 39470      |
|    policy_gradient_loss | 0.0124     |
|    std                  | 0.0607     |
|    value_loss           | 0.00272    |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3949       |
|    time_elapsed         | 12814      |
|    total_timesteps      | 8087552    |
| train/                  |            |
|    approx_kl            | 0.52775645 |
|    clip_fraction        | 0.54       |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.76       |
|    explained_variance   | 0.639      |
|    learning_rate        | 0.000423   |
|    loss                 | 0.128      |
|    n_updates            | 39480      |
|    policy_gradient_loss | 0.0213     |
|    std                  | 0.0609     |
|    value_loss           | 0.0318     |
----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3950      |
|    time_elapsed         | 12817     |
|    total_timesteps      | 8089600   |
| train/                  |           |
|    approx_kl            | 0.5124073 |
|    clip_fraction        | 0.417     |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.77      |
|    explained_variance   | 0.966     |
|    learning_rate        | 0.000423  |
|    loss                 | 0.0512    |
|    n_updates            | 39490     |
|    policy_gradient_loss | 0.0151    |
|    std                  | 0.0608    |
|    value_loss           | 0.00491   |
---------------------------------------
Eval num_timesteps=8090000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1         |
| time/                   |            |
|    total_timesteps      | 8090000    |
| train/                  |            |
|    approx_kl            | 0.30488077 |
|    clip_fraction        | 0.503      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.77       |
|    explained_variance   | 0.607      |
|    learning_rate        | 0.000423   |
|    loss                 | 0.17       |
|    n_updates            | 39500      |
|    policy_gradient_loss | 0.033      |
|    std                  | 0.0606     |
|    value_loss           | 0.00533    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 3951    |
|    time_elapsed    | 12821   |
|    total_timesteps | 8091648 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3952       |
|    time_elapsed         | 12824      |
|    total_timesteps      | 8093696    |
| train/                  |            |
|    approx_kl            | 0.41846663 |
|    clip_fraction        | 0.445      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.77       |
|    explained_variance   | 0.846      |
|    learning_rate        | 0.000422   |
|    loss                 | -0.00714   |
|    n_updates            | 39510      |
|    policy_gradient_loss | 0.0194     |
|    std                  | 0.0607     |
|    value_loss           | 0.00683    |
----------------------------------------
box reached target
--------------------------------------
| time/                   |          |
|    fps                  | 631      |
|    iterations           | 3953     |
|    time_elapsed         | 12827    |
|    total_timesteps      | 8095744  |
| train/                  |          |
|    approx_kl            | 5.933688 |
|    clip_fraction        | 0.523    |
|    clip_range           | 0.2      |
|    entropy_loss         | 2.78     |
|    explained_variance   | 0.582    |
|    learning_rate        | 0.000422 |
|    loss                 | -0.0468  |
|    n_updates            | 39520    |
|    policy_gradient_loss | -0.00535 |
|    std                  | 0.0594   |
|    value_loss           | 0.00391  |
--------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3954      |
|    time_elapsed         | 12830     |
|    total_timesteps      | 8097792   |
| train/                  |           |
|    approx_kl            | 0.6409546 |
|    clip_fraction        | 0.517     |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.82      |
|    explained_variance   | 0.495     |
|    learning_rate        | 0.000421  |
|    loss                 | 0.0194    |
|    n_updates            | 39530     |
|    policy_gradient_loss | 0.000154  |
|    std                  | 0.0587    |
|    value_loss           | 0.0593    |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3955       |
|    time_elapsed         | 12833      |
|    total_timesteps      | 8099840    |
| train/                  |            |
|    approx_kl            | 0.40580368 |
|    clip_fraction        | 0.486      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.83       |
|    explained_variance   | 0.709      |
|    learning_rate        | 0.000421   |
|    loss                 | 0.01       |
|    n_updates            | 39540      |
|    policy_gradient_loss | 0.0139     |
|    std                  | 0.0594     |
|    value_loss           | 0.0258     |
----------------------------------------
box reached target
box reached target
Eval num_timesteps=8100000, episode_reward=0.29 +/- 2.59
Episode length: 285.20 +/- 29.60
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 285       |
|    mean_reward          | 0.295     |
| time/                   |           |
|    total_timesteps      | 8100000   |
| train/                  |           |
|    approx_kl            | 0.4572833 |
|    clip_fraction        | 0.48      |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.8       |
|    explained_variance   | 0.835     |
|    learning_rate        | 0.000421  |
|    loss                 | 0.0519    |
|    n_updates            | 39550     |
|    policy_gradient_loss | 0.0273    |
|    std                  | 0.0601    |
|    value_loss           | 0.0093    |
---------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 3956    |
|    time_elapsed    | 12837   |
|    total_timesteps | 8101888 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3957       |
|    time_elapsed         | 12840      |
|    total_timesteps      | 8103936    |
| train/                  |            |
|    approx_kl            | 0.16865648 |
|    clip_fraction        | 0.418      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.81       |
|    explained_variance   | 0.833      |
|    learning_rate        | 0.00042    |
|    loss                 | -0.0215    |
|    n_updates            | 39560      |
|    policy_gradient_loss | 0.0146     |
|    std                  | 0.0594     |
|    value_loss           | 0.00684    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3958       |
|    time_elapsed         | 12843      |
|    total_timesteps      | 8105984    |
| train/                  |            |
|    approx_kl            | 0.46654367 |
|    clip_fraction        | 0.463      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.82       |
|    explained_variance   | 0.47       |
|    learning_rate        | 0.00042    |
|    loss                 | 0.00883    |
|    n_updates            | 39570      |
|    policy_gradient_loss | 0.0157     |
|    std                  | 0.0595     |
|    value_loss           | 0.00338    |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3959       |
|    time_elapsed         | 12846      |
|    total_timesteps      | 8108032    |
| train/                  |            |
|    approx_kl            | 0.26281178 |
|    clip_fraction        | 0.448      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.81       |
|    explained_variance   | 0.241      |
|    learning_rate        | 0.000419   |
|    loss                 | -0.00701   |
|    n_updates            | 39580      |
|    policy_gradient_loss | 0.0116     |
|    std                  | 0.0596     |
|    value_loss           | 0.00157    |
----------------------------------------
box reached target
Eval num_timesteps=8110000, episode_reward=0.32 +/- 2.65
Episode length: 297.00 +/- 6.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 297       |
|    mean_reward          | 0.324     |
| time/                   |           |
|    total_timesteps      | 8110000   |
| train/                  |           |
|    approx_kl            | 0.3257494 |
|    clip_fraction        | 0.511     |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.8       |
|    explained_variance   | 0.795     |
|    learning_rate        | 0.000419  |
|    loss                 | 0.148     |
|    n_updates            | 39590     |
|    policy_gradient_loss | 0.0142    |
|    std                  | 0.0603    |
|    value_loss           | 0.0707    |
---------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 3960    |
|    time_elapsed    | 12850   |
|    total_timesteps | 8110080 |
--------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3961      |
|    time_elapsed         | 12854     |
|    total_timesteps      | 8112128   |
| train/                  |           |
|    approx_kl            | 0.3549546 |
|    clip_fraction        | 0.461     |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.79      |
|    explained_variance   | 0.562     |
|    learning_rate        | 0.000419  |
|    loss                 | -0.00769  |
|    n_updates            | 39600     |
|    policy_gradient_loss | 0.014     |
|    std                  | 0.0604    |
|    value_loss           | 0.00343   |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3962       |
|    time_elapsed         | 12857      |
|    total_timesteps      | 8114176    |
| train/                  |            |
|    approx_kl            | 0.48013374 |
|    clip_fraction        | 0.427      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.77       |
|    explained_variance   | 0.408      |
|    learning_rate        | 0.000418   |
|    loss                 | 0.0341     |
|    n_updates            | 39610      |
|    policy_gradient_loss | 0.00868    |
|    std                  | 0.0609     |
|    value_loss           | 0.00205    |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3963       |
|    time_elapsed         | 12860      |
|    total_timesteps      | 8116224    |
| train/                  |            |
|    approx_kl            | 0.22145692 |
|    clip_fraction        | 0.431      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.76       |
|    explained_variance   | 0.605      |
|    learning_rate        | 0.000418   |
|    loss                 | -0.0112    |
|    n_updates            | 39620      |
|    policy_gradient_loss | 0.0213     |
|    std                  | 0.0614     |
|    value_loss           | 0.0017     |
----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3964      |
|    time_elapsed         | 12863     |
|    total_timesteps      | 8118272   |
| train/                  |           |
|    approx_kl            | 0.5702443 |
|    clip_fraction        | 0.456     |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.77      |
|    explained_variance   | 0.888     |
|    learning_rate        | 0.000417  |
|    loss                 | -0.0441   |
|    n_updates            | 39630     |
|    policy_gradient_loss | 0.00653   |
|    std                  | 0.0601    |
|    value_loss           | 0.0113    |
---------------------------------------
box reached target
box reached target
box reached target
Eval num_timesteps=8120000, episode_reward=0.24 +/- 2.49
Episode length: 275.80 +/- 48.40
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 276        |
|    mean_reward          | 0.243      |
| time/                   |            |
|    total_timesteps      | 8120000    |
| train/                  |            |
|    approx_kl            | 0.27895632 |
|    clip_fraction        | 0.474      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.78       |
|    explained_variance   | -0.858     |
|    learning_rate        | 0.000417   |
|    loss                 | 0.00652    |
|    n_updates            | 39640      |
|    policy_gradient_loss | 0.0219     |
|    std                  | 0.0602     |
|    value_loss           | 0.00292    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 3965    |
|    time_elapsed    | 12867   |
|    total_timesteps | 8120320 |
--------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3966      |
|    time_elapsed         | 12870     |
|    total_timesteps      | 8122368   |
| train/                  |           |
|    approx_kl            | 0.6423141 |
|    clip_fraction        | 0.487     |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.8       |
|    explained_variance   | 0.891     |
|    learning_rate        | 0.000417  |
|    loss                 | -0.0131   |
|    n_updates            | 39650     |
|    policy_gradient_loss | 0.0235    |
|    std                  | 0.0597    |
|    value_loss           | 0.0165    |
---------------------------------------
box reached target
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3967      |
|    time_elapsed         | 12873     |
|    total_timesteps      | 8124416   |
| train/                  |           |
|    approx_kl            | 0.9170356 |
|    clip_fraction        | 0.454     |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.81      |
|    explained_variance   | 0.894     |
|    learning_rate        | 0.000416  |
|    loss                 | -0.0317   |
|    n_updates            | 39660     |
|    policy_gradient_loss | 0.0018    |
|    std                  | 0.0595    |
|    value_loss           | 0.0161    |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3968       |
|    time_elapsed         | 12876      |
|    total_timesteps      | 8126464    |
| train/                  |            |
|    approx_kl            | 0.39529425 |
|    clip_fraction        | 0.488      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.8        |
|    explained_variance   | 0.864      |
|    learning_rate        | 0.000416   |
|    loss                 | -0.00907   |
|    n_updates            | 39670      |
|    policy_gradient_loss | 0.0261     |
|    std                  | 0.06       |
|    value_loss           | 0.0316     |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3969       |
|    time_elapsed         | 12879      |
|    total_timesteps      | 8128512    |
| train/                  |            |
|    approx_kl            | 0.20506024 |
|    clip_fraction        | 0.431      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.81       |
|    explained_variance   | 0.763      |
|    learning_rate        | 0.000415   |
|    loss                 | -0.0112    |
|    n_updates            | 39680      |
|    policy_gradient_loss | 0.0193     |
|    std                  | 0.0596     |
|    value_loss           | 0.0111     |
----------------------------------------
Eval num_timesteps=8130000, episode_reward=-0.70 +/- 0.60
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -0.701     |
| time/                   |            |
|    total_timesteps      | 8130000    |
| train/                  |            |
|    approx_kl            | 0.19094071 |
|    clip_fraction        | 0.391      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.8        |
|    explained_variance   | 0.595      |
|    learning_rate        | 0.000415   |
|    loss                 | 0.0343     |
|    n_updates            | 39690      |
|    policy_gradient_loss | -0.000998  |
|    std                  | 0.0598     |
|    value_loss           | 0.00289    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 3970    |
|    time_elapsed    | 12883   |
|    total_timesteps | 8130560 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3971       |
|    time_elapsed         | 12886      |
|    total_timesteps      | 8132608    |
| train/                  |            |
|    approx_kl            | 0.50237906 |
|    clip_fraction        | 0.505      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.79       |
|    explained_variance   | 0.883      |
|    learning_rate        | 0.000415   |
|    loss                 | 0.0543     |
|    n_updates            | 39700      |
|    policy_gradient_loss | 0.0197     |
|    std                  | 0.0603     |
|    value_loss           | 0.00483    |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3972       |
|    time_elapsed         | 12889      |
|    total_timesteps      | 8134656    |
| train/                  |            |
|    approx_kl            | 0.46928006 |
|    clip_fraction        | 0.421      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.79       |
|    explained_variance   | 0.0304     |
|    learning_rate        | 0.000414   |
|    loss                 | -0.0122    |
|    n_updates            | 39710      |
|    policy_gradient_loss | -0.00176   |
|    std                  | 0.0595     |
|    value_loss           | 0.00414    |
----------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3973      |
|    time_elapsed         | 12892     |
|    total_timesteps      | 8136704   |
| train/                  |           |
|    approx_kl            | 0.3549365 |
|    clip_fraction        | 0.499     |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.81      |
|    explained_variance   | 0.72      |
|    learning_rate        | 0.000414  |
|    loss                 | -0.0103   |
|    n_updates            | 39720     |
|    policy_gradient_loss | 0.0274    |
|    std                  | 0.0591    |
|    value_loss           | 0.0154    |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3974       |
|    time_elapsed         | 12895      |
|    total_timesteps      | 8138752    |
| train/                  |            |
|    approx_kl            | 0.30699378 |
|    clip_fraction        | 0.476      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.81       |
|    explained_variance   | 0.948      |
|    learning_rate        | 0.000413   |
|    loss                 | 0.0129     |
|    n_updates            | 39730      |
|    policy_gradient_loss | 0.0238     |
|    std                  | 0.0602     |
|    value_loss           | 0.0068     |
----------------------------------------
Eval num_timesteps=8140000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1         |
| time/                   |            |
|    total_timesteps      | 8140000    |
| train/                  |            |
|    approx_kl            | 0.52103806 |
|    clip_fraction        | 0.442      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.79       |
|    explained_variance   | 0.403      |
|    learning_rate        | 0.000413   |
|    loss                 | 0.0213     |
|    n_updates            | 39740      |
|    policy_gradient_loss | 0.0107     |
|    std                  | 0.0598     |
|    value_loss           | 0.00154    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 3975    |
|    time_elapsed    | 12899   |
|    total_timesteps | 8140800 |
--------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3976      |
|    time_elapsed         | 12902     |
|    total_timesteps      | 8142848   |
| train/                  |           |
|    approx_kl            | 0.2761675 |
|    clip_fraction        | 0.445     |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.78      |
|    explained_variance   | -0.435    |
|    learning_rate        | 0.000413  |
|    loss                 | 0.0208    |
|    n_updates            | 39750     |
|    policy_gradient_loss | 0.0119    |
|    std                  | 0.0608    |
|    value_loss           | 0.00541   |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3977       |
|    time_elapsed         | 12905      |
|    total_timesteps      | 8144896    |
| train/                  |            |
|    approx_kl            | 0.16909285 |
|    clip_fraction        | 0.429      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.75       |
|    explained_variance   | 0.962      |
|    learning_rate        | 0.000412   |
|    loss                 | -0.0399    |
|    n_updates            | 39760      |
|    policy_gradient_loss | 0.0215     |
|    std                  | 0.0617     |
|    value_loss           | 0.00436    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3978       |
|    time_elapsed         | 12908      |
|    total_timesteps      | 8146944    |
| train/                  |            |
|    approx_kl            | 0.11907854 |
|    clip_fraction        | 0.435      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.73       |
|    explained_variance   | 0.202      |
|    learning_rate        | 0.000412   |
|    loss                 | 0.00423    |
|    n_updates            | 39770      |
|    policy_gradient_loss | 0.016      |
|    std                  | 0.0624     |
|    value_loss           | 0.00191    |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3979       |
|    time_elapsed         | 12911      |
|    total_timesteps      | 8148992    |
| train/                  |            |
|    approx_kl            | 0.15107754 |
|    clip_fraction        | 0.409      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.72       |
|    explained_variance   | 0.565      |
|    learning_rate        | 0.000411   |
|    loss                 | -0.00294   |
|    n_updates            | 39780      |
|    policy_gradient_loss | 0.0145     |
|    std                  | 0.0625     |
|    value_loss           | 0.00128    |
----------------------------------------
Eval num_timesteps=8150000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1         |
| time/                   |            |
|    total_timesteps      | 8150000    |
| train/                  |            |
|    approx_kl            | 0.25025466 |
|    clip_fraction        | 0.454      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.73       |
|    explained_variance   | 0.736      |
|    learning_rate        | 0.000411   |
|    loss                 | -0.00516   |
|    n_updates            | 39790      |
|    policy_gradient_loss | 0.0205     |
|    std                  | 0.0614     |
|    value_loss           | 0.0113     |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 3980    |
|    time_elapsed    | 12915   |
|    total_timesteps | 8151040 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3981       |
|    time_elapsed         | 12918      |
|    total_timesteps      | 8153088    |
| train/                  |            |
|    approx_kl            | 0.17297472 |
|    clip_fraction        | 0.391      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.75       |
|    explained_variance   | 0.187      |
|    learning_rate        | 0.000411   |
|    loss                 | -0.016     |
|    n_updates            | 39800      |
|    policy_gradient_loss | 0.00721    |
|    std                  | 0.061      |
|    value_loss           | 0.00173    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3982       |
|    time_elapsed         | 12921      |
|    total_timesteps      | 8155136    |
| train/                  |            |
|    approx_kl            | 0.32736605 |
|    clip_fraction        | 0.468      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.75       |
|    explained_variance   | 0.76       |
|    learning_rate        | 0.00041    |
|    loss                 | -0.0155    |
|    n_updates            | 39810      |
|    policy_gradient_loss | 0.0157     |
|    std                  | 0.0613     |
|    value_loss           | 0.00181    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3983       |
|    time_elapsed         | 12924      |
|    total_timesteps      | 8157184    |
| train/                  |            |
|    approx_kl            | 0.25892246 |
|    clip_fraction        | 0.468      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.75       |
|    explained_variance   | 0.799      |
|    learning_rate        | 0.00041    |
|    loss                 | 0.000347   |
|    n_updates            | 39820      |
|    policy_gradient_loss | 0.0146     |
|    std                  | 0.0613     |
|    value_loss           | 0.00629    |
----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3984      |
|    time_elapsed         | 12927     |
|    total_timesteps      | 8159232   |
| train/                  |           |
|    approx_kl            | 0.4051771 |
|    clip_fraction        | 0.475     |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.75      |
|    explained_variance   | 0.674     |
|    learning_rate        | 0.000409  |
|    loss                 | -0.0139   |
|    n_updates            | 39830     |
|    policy_gradient_loss | 0.04      |
|    std                  | 0.061     |
|    value_loss           | 0.00169   |
---------------------------------------
box reached target
Eval num_timesteps=8160000, episode_reward=0.29 +/- 2.57
Episode length: 272.00 +/- 56.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 272       |
|    mean_reward          | 0.286     |
| time/                   |           |
|    total_timesteps      | 8160000   |
| train/                  |           |
|    approx_kl            | 0.3778153 |
|    clip_fraction        | 0.417     |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.77      |
|    explained_variance   | 0.621     |
|    learning_rate        | 0.000409  |
|    loss                 | 0.00272   |
|    n_updates            | 39840     |
|    policy_gradient_loss | 0.00144   |
|    std                  | 0.0604    |
|    value_loss           | 0.00132   |
---------------------------------------
box reached target
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 3985    |
|    time_elapsed    | 12931   |
|    total_timesteps | 8161280 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3986       |
|    time_elapsed         | 12934      |
|    total_timesteps      | 8163328    |
| train/                  |            |
|    approx_kl            | 0.30349064 |
|    clip_fraction        | 0.491      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.78       |
|    explained_variance   | 0.675      |
|    learning_rate        | 0.000409   |
|    loss                 | -0.0691    |
|    n_updates            | 39850      |
|    policy_gradient_loss | 0.0166     |
|    std                  | 0.0605     |
|    value_loss           | 0.0232     |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3987       |
|    time_elapsed         | 12937      |
|    total_timesteps      | 8165376    |
| train/                  |            |
|    approx_kl            | 0.67351645 |
|    clip_fraction        | 0.516      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.77       |
|    explained_variance   | 0.514      |
|    learning_rate        | 0.000408   |
|    loss                 | 0.0476     |
|    n_updates            | 39860      |
|    policy_gradient_loss | 0.0202     |
|    std                  | 0.0606     |
|    value_loss           | 0.00154    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3988       |
|    time_elapsed         | 12940      |
|    total_timesteps      | 8167424    |
| train/                  |            |
|    approx_kl            | 0.36046886 |
|    clip_fraction        | 0.394      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.78       |
|    explained_variance   | 0.19       |
|    learning_rate        | 0.000408   |
|    loss                 | 0.0944     |
|    n_updates            | 39870      |
|    policy_gradient_loss | 0.000922   |
|    std                  | 0.0604     |
|    value_loss           | 0.00212    |
----------------------------------------
--------------------------------------
| time/                   |          |
|    fps                  | 631      |
|    iterations           | 3989     |
|    time_elapsed         | 12943    |
|    total_timesteps      | 8169472  |
| train/                  |          |
|    approx_kl            | 2.802741 |
|    clip_fraction        | 0.428    |
|    clip_range           | 0.2      |
|    entropy_loss         | 2.78     |
|    explained_variance   | 0.561    |
|    learning_rate        | 0.000407 |
|    loss                 | 0.0169   |
|    n_updates            | 39880    |
|    policy_gradient_loss | 0.00985  |
|    std                  | 0.06     |
|    value_loss           | 0.0015   |
--------------------------------------
Eval num_timesteps=8170000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1         |
| time/                   |            |
|    total_timesteps      | 8170000    |
| train/                  |            |
|    approx_kl            | 0.21072868 |
|    clip_fraction        | 0.398      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.81       |
|    explained_variance   | 0.114      |
|    learning_rate        | 0.000407   |
|    loss                 | -0.0522    |
|    n_updates            | 39890      |
|    policy_gradient_loss | 0.00358    |
|    std                  | 0.0589     |
|    value_loss           | 0.00137    |
----------------------------------------
box reached target
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 3990    |
|    time_elapsed    | 12947   |
|    total_timesteps | 8171520 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3991       |
|    time_elapsed         | 12950      |
|    total_timesteps      | 8173568    |
| train/                  |            |
|    approx_kl            | 0.17412263 |
|    clip_fraction        | 0.468      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.83       |
|    explained_variance   | 0.942      |
|    learning_rate        | 0.000407   |
|    loss                 | 0.0144     |
|    n_updates            | 39900      |
|    policy_gradient_loss | 0.0131     |
|    std                  | 0.059      |
|    value_loss           | 0.00776    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3992       |
|    time_elapsed         | 12954      |
|    total_timesteps      | 8175616    |
| train/                  |            |
|    approx_kl            | 0.20314285 |
|    clip_fraction        | 0.386      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.82       |
|    explained_variance   | -0.0947    |
|    learning_rate        | 0.000406   |
|    loss                 | -0.0563    |
|    n_updates            | 39910      |
|    policy_gradient_loss | 0.0108     |
|    std                  | 0.0593     |
|    value_loss           | 0.00201    |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3993       |
|    time_elapsed         | 12957      |
|    total_timesteps      | 8177664    |
| train/                  |            |
|    approx_kl            | 0.24345401 |
|    clip_fraction        | 0.428      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.82       |
|    explained_variance   | 0.749      |
|    learning_rate        | 0.000406   |
|    loss                 | 0.00842    |
|    n_updates            | 39920      |
|    policy_gradient_loss | 0.0198     |
|    std                  | 0.059      |
|    value_loss           | 0.00308    |
----------------------------------------
box reached target
box reached target
box reached target
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3994      |
|    time_elapsed         | 12960     |
|    total_timesteps      | 8179712   |
| train/                  |           |
|    approx_kl            | 0.5014781 |
|    clip_fraction        | 0.464     |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.84      |
|    explained_variance   | 0.926     |
|    learning_rate        | 0.000405  |
|    loss                 | -0.0159   |
|    n_updates            | 39930     |
|    policy_gradient_loss | 0.03      |
|    std                  | 0.0587    |
|    value_loss           | 0.00335   |
---------------------------------------
box reached target
Eval num_timesteps=8180000, episode_reward=-0.82 +/- 0.35
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -0.825     |
| time/                   |            |
|    total_timesteps      | 8180000    |
| train/                  |            |
|    approx_kl            | 0.15008089 |
|    clip_fraction        | 0.424      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.87       |
|    explained_variance   | 0.915      |
|    learning_rate        | 0.000405   |
|    loss                 | 0.017      |
|    n_updates            | 39940      |
|    policy_gradient_loss | 0.0163     |
|    std                  | 0.0575     |
|    value_loss           | 0.0329     |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 3995    |
|    time_elapsed    | 12964   |
|    total_timesteps | 8181760 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3996       |
|    time_elapsed         | 12967      |
|    total_timesteps      | 8183808    |
| train/                  |            |
|    approx_kl            | 0.31055433 |
|    clip_fraction        | 0.492      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.88       |
|    explained_variance   | 0.675      |
|    learning_rate        | 0.000405   |
|    loss                 | 0.00939    |
|    n_updates            | 39950      |
|    policy_gradient_loss | 0.0131     |
|    std                  | 0.0579     |
|    value_loss           | 0.0132     |
----------------------------------------
box reached target
--------------------------------------
| time/                   |          |
|    fps                  | 631      |
|    iterations           | 3997     |
|    time_elapsed         | 12970    |
|    total_timesteps      | 8185856  |
| train/                  |          |
|    approx_kl            | 1.297925 |
|    clip_fraction        | 0.474    |
|    clip_range           | 0.2      |
|    entropy_loss         | 2.88     |
|    explained_variance   | 0.752    |
|    learning_rate        | 0.000404 |
|    loss                 | -0.0229  |
|    n_updates            | 39960    |
|    policy_gradient_loss | 0.0113   |
|    std                  | 0.0568   |
|    value_loss           | 0.00229  |
--------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 3998       |
|    time_elapsed         | 12973      |
|    total_timesteps      | 8187904    |
| train/                  |            |
|    approx_kl            | 0.14543748 |
|    clip_fraction        | 0.414      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.91       |
|    explained_variance   | 0.956      |
|    learning_rate        | 0.000404   |
|    loss                 | -0.0391    |
|    n_updates            | 39970      |
|    policy_gradient_loss | 0.0146     |
|    std                  | 0.0565     |
|    value_loss           | 0.00257    |
----------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 3999      |
|    time_elapsed         | 12976     |
|    total_timesteps      | 8189952   |
| train/                  |           |
|    approx_kl            | 2.0299335 |
|    clip_fraction        | 0.542     |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.91      |
|    explained_variance   | 0.918     |
|    learning_rate        | 0.000403  |
|    loss                 | -0.046    |
|    n_updates            | 39980     |
|    policy_gradient_loss | 0.0245    |
|    std                  | 0.0569    |
|    value_loss           | 0.018     |
---------------------------------------
Eval num_timesteps=8190000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 300       |
|    mean_reward          | -1        |
| time/                   |           |
|    total_timesteps      | 8190000   |
| train/                  |           |
|    approx_kl            | 1.1804273 |
|    clip_fraction        | 0.491     |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.9       |
|    explained_variance   | 0.975     |
|    learning_rate        | 0.000403  |
|    loss                 | 0.0592    |
|    n_updates            | 39990     |
|    policy_gradient_loss | 0.00965   |
|    std                  | 0.0571    |
|    value_loss           | 0.00537   |
---------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 4000    |
|    time_elapsed    | 12980   |
|    total_timesteps | 8192000 |
--------------------------------
box reached target
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 4001      |
|    time_elapsed         | 12983     |
|    total_timesteps      | 8194048   |
| train/                  |           |
|    approx_kl            | 0.3588887 |
|    clip_fraction        | 0.459     |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.88      |
|    explained_variance   | 0.12      |
|    learning_rate        | 0.000403  |
|    loss                 | -0.0205   |
|    n_updates            | 40000     |
|    policy_gradient_loss | 0.00763   |
|    std                  | 0.0574    |
|    value_loss           | 0.0021    |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4002       |
|    time_elapsed         | 12987      |
|    total_timesteps      | 8196096    |
| train/                  |            |
|    approx_kl            | 0.13700786 |
|    clip_fraction        | 0.455      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.89       |
|    explained_variance   | 0.968      |
|    learning_rate        | 0.000402   |
|    loss                 | 0.0257     |
|    n_updates            | 40010      |
|    policy_gradient_loss | 0.0177     |
|    std                  | 0.0567     |
|    value_loss           | 0.00698    |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4003       |
|    time_elapsed         | 12990      |
|    total_timesteps      | 8198144    |
| train/                  |            |
|    approx_kl            | 0.30826783 |
|    clip_fraction        | 0.448      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.92       |
|    explained_variance   | 0.771      |
|    learning_rate        | 0.000402   |
|    loss                 | -0.0428    |
|    n_updates            | 40020      |
|    policy_gradient_loss | 0.0222     |
|    std                  | 0.0561     |
|    value_loss           | 0.0131     |
----------------------------------------
box reached target
Eval num_timesteps=8200000, episode_reward=0.24 +/- 2.49
Episode length: 281.60 +/- 36.80
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 282        |
|    mean_reward          | 0.244      |
| time/                   |            |
|    total_timesteps      | 8200000    |
| train/                  |            |
|    approx_kl            | 0.36717585 |
|    clip_fraction        | 0.513      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.94       |
|    explained_variance   | 0.971      |
|    learning_rate        | 0.000401   |
|    loss                 | 0.199      |
|    n_updates            | 40030      |
|    policy_gradient_loss | 0.0215     |
|    std                  | 0.0562     |
|    value_loss           | 0.0067     |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 4004    |
|    time_elapsed    | 12993   |
|    total_timesteps | 8200192 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4005       |
|    time_elapsed         | 12997      |
|    total_timesteps      | 8202240    |
| train/                  |            |
|    approx_kl            | 0.27098852 |
|    clip_fraction        | 0.456      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.92       |
|    explained_variance   | 0.15       |
|    learning_rate        | 0.000401   |
|    loss                 | 0.0389     |
|    n_updates            | 40040      |
|    policy_gradient_loss | 0.0263     |
|    std                  | 0.0565     |
|    value_loss           | 0.00168    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4006       |
|    time_elapsed         | 13000      |
|    total_timesteps      | 8204288    |
| train/                  |            |
|    approx_kl            | 0.20222738 |
|    clip_fraction        | 0.481      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.9        |
|    explained_variance   | 0.793      |
|    learning_rate        | 0.000401   |
|    loss                 | 0.105      |
|    n_updates            | 40050      |
|    policy_gradient_loss | 0.0143     |
|    std                  | 0.0575     |
|    value_loss           | 0.0061     |
----------------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4007       |
|    time_elapsed         | 13003      |
|    total_timesteps      | 8206336    |
| train/                  |            |
|    approx_kl            | 0.23088223 |
|    clip_fraction        | 0.489      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.89       |
|    explained_variance   | 0.843      |
|    learning_rate        | 0.0004     |
|    loss                 | 0.0226     |
|    n_updates            | 40060      |
|    policy_gradient_loss | 0.02       |
|    std                  | 0.0571     |
|    value_loss           | 0.00497    |
----------------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4008       |
|    time_elapsed         | 13006      |
|    total_timesteps      | 8208384    |
| train/                  |            |
|    approx_kl            | 0.27530566 |
|    clip_fraction        | 0.499      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.9        |
|    explained_variance   | 0.59       |
|    learning_rate        | 0.0004     |
|    loss                 | 0.0638     |
|    n_updates            | 40070      |
|    policy_gradient_loss | 0.0165     |
|    std                  | 0.0573     |
|    value_loss           | 0.0521     |
----------------------------------------
box reached target
Eval num_timesteps=8210000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 300       |
|    mean_reward          | -1        |
| time/                   |           |
|    total_timesteps      | 8210000   |
| train/                  |           |
|    approx_kl            | 0.5909101 |
|    clip_fraction        | 0.476     |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.9       |
|    explained_variance   | 0.972     |
|    learning_rate        | 0.000399  |
|    loss                 | -0.00571  |
|    n_updates            | 40080     |
|    policy_gradient_loss | 0.0127    |
|    std                  | 0.057     |
|    value_loss           | 0.0132    |
---------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 4009    |
|    time_elapsed    | 13010   |
|    total_timesteps | 8210432 |
--------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4010       |
|    time_elapsed         | 13013      |
|    total_timesteps      | 8212480    |
| train/                  |            |
|    approx_kl            | 0.39966643 |
|    clip_fraction        | 0.457      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.89       |
|    explained_variance   | 0.889      |
|    learning_rate        | 0.000399   |
|    loss                 | 0.0385     |
|    n_updates            | 40090      |
|    policy_gradient_loss | 0.019      |
|    std                  | 0.058      |
|    value_loss           | 0.0219     |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4011       |
|    time_elapsed         | 13016      |
|    total_timesteps      | 8214528    |
| train/                  |            |
|    approx_kl            | 0.34831864 |
|    clip_fraction        | 0.396      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.87       |
|    explained_variance   | 0.98       |
|    learning_rate        | 0.000399   |
|    loss                 | 0.00357    |
|    n_updates            | 40100      |
|    policy_gradient_loss | 0.00125    |
|    std                  | 0.0576     |
|    value_loss           | 0.00645    |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4012       |
|    time_elapsed         | 13019      |
|    total_timesteps      | 8216576    |
| train/                  |            |
|    approx_kl            | 0.52581865 |
|    clip_fraction        | 0.412      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.87       |
|    explained_variance   | 0.822      |
|    learning_rate        | 0.000398   |
|    loss                 | 0.0114     |
|    n_updates            | 40110      |
|    policy_gradient_loss | 0.0173     |
|    std                  | 0.0583     |
|    value_loss           | 0.00637    |
----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 4013      |
|    time_elapsed         | 13022     |
|    total_timesteps      | 8218624   |
| train/                  |           |
|    approx_kl            | 0.5422219 |
|    clip_fraction        | 0.523     |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.83      |
|    explained_variance   | 0.559     |
|    learning_rate        | 0.000398  |
|    loss                 | 0.0222    |
|    n_updates            | 40120     |
|    policy_gradient_loss | 0.0111    |
|    std                  | 0.0598    |
|    value_loss           | 0.127     |
---------------------------------------
box reached target
box reached target
Eval num_timesteps=8220000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 300       |
|    mean_reward          | -1        |
| time/                   |           |
|    total_timesteps      | 8220000   |
| train/                  |           |
|    approx_kl            | 0.6633059 |
|    clip_fraction        | 0.429     |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.8       |
|    explained_variance   | 0.389     |
|    learning_rate        | 0.000397  |
|    loss                 | 0.0687    |
|    n_updates            | 40130     |
|    policy_gradient_loss | 0.00752   |
|    std                  | 0.0606    |
|    value_loss           | 0.0036    |
---------------------------------------
box reached target
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 4014    |
|    time_elapsed    | 13026   |
|    total_timesteps | 8220672 |
--------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 4015      |
|    time_elapsed         | 13029     |
|    total_timesteps      | 8222720   |
| train/                  |           |
|    approx_kl            | 7.8022013 |
|    clip_fraction        | 0.523     |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.81      |
|    explained_variance   | 0.856     |
|    learning_rate        | 0.000397  |
|    loss                 | -0.0222   |
|    n_updates            | 40140     |
|    policy_gradient_loss | -0.00784  |
|    std                  | 0.0594    |
|    value_loss           | 0.128     |
---------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 4016      |
|    time_elapsed         | 13032     |
|    total_timesteps      | 8224768   |
| train/                  |           |
|    approx_kl            | 0.7916806 |
|    clip_fraction        | 0.519     |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.83      |
|    explained_variance   | 0.846     |
|    learning_rate        | 0.000397  |
|    loss                 | -0.0352   |
|    n_updates            | 40150     |
|    policy_gradient_loss | 0.026     |
|    std                  | 0.0592    |
|    value_loss           | 0.0102    |
---------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4017       |
|    time_elapsed         | 13035      |
|    total_timesteps      | 8226816    |
| train/                  |            |
|    approx_kl            | 0.28025278 |
|    clip_fraction        | 0.453      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.86       |
|    explained_variance   | 0.271      |
|    learning_rate        | 0.000396   |
|    loss                 | 0.000323   |
|    n_updates            | 40160      |
|    policy_gradient_loss | 0.0182     |
|    std                  | 0.058      |
|    value_loss           | 0.123      |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4018       |
|    time_elapsed         | 13038      |
|    total_timesteps      | 8228864    |
| train/                  |            |
|    approx_kl            | 0.22312179 |
|    clip_fraction        | 0.465      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.88       |
|    explained_variance   | 0.695      |
|    learning_rate        | 0.000396   |
|    loss                 | 0.0415     |
|    n_updates            | 40170      |
|    policy_gradient_loss | 0.0154     |
|    std                  | 0.0588     |
|    value_loss           | 0.0149     |
----------------------------------------
box reached target
Eval num_timesteps=8230000, episode_reward=0.30 +/- 2.60
Episode length: 280.00 +/- 40.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 280        |
|    mean_reward          | 0.298      |
| time/                   |            |
|    total_timesteps      | 8230000    |
| train/                  |            |
|    approx_kl            | 0.49409527 |
|    clip_fraction        | 0.413      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.87       |
|    explained_variance   | -0.699     |
|    learning_rate        | 0.000395   |
|    loss                 | 0.0546     |
|    n_updates            | 40180      |
|    policy_gradient_loss | -0.00216   |
|    std                  | 0.0582     |
|    value_loss           | 0.00294    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 4019    |
|    time_elapsed    | 13042   |
|    total_timesteps | 8230912 |
--------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4020       |
|    time_elapsed         | 13045      |
|    total_timesteps      | 8232960    |
| train/                  |            |
|    approx_kl            | 0.45829755 |
|    clip_fraction        | 0.395      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.89       |
|    explained_variance   | -0.731     |
|    learning_rate        | 0.000395   |
|    loss                 | 0.0914     |
|    n_updates            | 40190      |
|    policy_gradient_loss | -0.00089   |
|    std                  | 0.0571     |
|    value_loss           | 0.00121    |
----------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 4021      |
|    time_elapsed         | 13048     |
|    total_timesteps      | 8235008   |
| train/                  |           |
|    approx_kl            | 0.4825073 |
|    clip_fraction        | 0.512     |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.91      |
|    explained_variance   | 0.962     |
|    learning_rate        | 0.000395  |
|    loss                 | -0.00677  |
|    n_updates            | 40200     |
|    policy_gradient_loss | 0.0293    |
|    std                  | 0.0575    |
|    value_loss           | 0.00392   |
---------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 4022      |
|    time_elapsed         | 13051     |
|    total_timesteps      | 8237056   |
| train/                  |           |
|    approx_kl            | 1.9910607 |
|    clip_fraction        | 0.502     |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.9       |
|    explained_variance   | 0.959     |
|    learning_rate        | 0.000394  |
|    loss                 | 0.0917    |
|    n_updates            | 40210     |
|    policy_gradient_loss | 0.015     |
|    std                  | 0.0577    |
|    value_loss           | 0.00878   |
---------------------------------------
--------------------------------------
| time/                   |          |
|    fps                  | 631      |
|    iterations           | 4023     |
|    time_elapsed         | 13054    |
|    total_timesteps      | 8239104  |
| train/                  |          |
|    approx_kl            | 8.296322 |
|    clip_fraction        | 0.556    |
|    clip_range           | 0.2      |
|    entropy_loss         | 2.88     |
|    explained_variance   | 0.811    |
|    learning_rate        | 0.000394 |
|    loss                 | 0.0169   |
|    n_updates            | 40220    |
|    policy_gradient_loss | 0.022    |
|    std                  | 0.0584   |
|    value_loss           | 0.00502  |
--------------------------------------
Eval num_timesteps=8240000, episode_reward=-0.75 +/- 0.50
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -0.751     |
| time/                   |            |
|    total_timesteps      | 8240000    |
| train/                  |            |
|    approx_kl            | 0.25073987 |
|    clip_fraction        | 0.456      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.86       |
|    explained_variance   | 0.688      |
|    learning_rate        | 0.000393   |
|    loss                 | -0.0115    |
|    n_updates            | 40230      |
|    policy_gradient_loss | 0.0169     |
|    std                  | 0.0592     |
|    value_loss           | 0.00324    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 4024    |
|    time_elapsed    | 13058   |
|    total_timesteps | 8241152 |
--------------------------------
--------------------------------------
| time/                   |          |
|    fps                  | 631      |
|    iterations           | 4025     |
|    time_elapsed         | 13061    |
|    total_timesteps      | 8243200  |
| train/                  |          |
|    approx_kl            | 0.424079 |
|    clip_fraction        | 0.453    |
|    clip_range           | 0.2      |
|    entropy_loss         | 2.84     |
|    explained_variance   | 0.656    |
|    learning_rate        | 0.000393 |
|    loss                 | -0.0403  |
|    n_updates            | 40240    |
|    policy_gradient_loss | 0.00655  |
|    std                  | 0.0597   |
|    value_loss           | 0.00774  |
--------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 4026      |
|    time_elapsed         | 13064     |
|    total_timesteps      | 8245248   |
| train/                  |           |
|    approx_kl            | 0.4197389 |
|    clip_fraction        | 0.454     |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.84      |
|    explained_variance   | 0.608     |
|    learning_rate        | 0.000393  |
|    loss                 | 0.0209    |
|    n_updates            | 40250     |
|    policy_gradient_loss | 0.0065    |
|    std                  | 0.0591    |
|    value_loss           | 0.00408   |
---------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4027       |
|    time_elapsed         | 13067      |
|    total_timesteps      | 8247296    |
| train/                  |            |
|    approx_kl            | 0.20410042 |
|    clip_fraction        | 0.469      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.83       |
|    explained_variance   | 0.876      |
|    learning_rate        | 0.000392   |
|    loss                 | -0.00144   |
|    n_updates            | 40260      |
|    policy_gradient_loss | 0.0132     |
|    std                  | 0.0603     |
|    value_loss           | 0.0179     |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4028       |
|    time_elapsed         | 13070      |
|    total_timesteps      | 8249344    |
| train/                  |            |
|    approx_kl            | 0.38424388 |
|    clip_fraction        | 0.462      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.8        |
|    explained_variance   | 0.929      |
|    learning_rate        | 0.000392   |
|    loss                 | -0.0231    |
|    n_updates            | 40270      |
|    policy_gradient_loss | 0.0182     |
|    std                  | 0.0608     |
|    value_loss           | 0.00914    |
----------------------------------------
box reached target
Eval num_timesteps=8250000, episode_reward=0.25 +/- 2.50
Episode length: 270.40 +/- 59.20
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 270       |
|    mean_reward          | 0.252     |
| time/                   |           |
|    total_timesteps      | 8250000   |
| train/                  |           |
|    approx_kl            | 0.3853609 |
|    clip_fraction        | 0.45      |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.79      |
|    explained_variance   | 0.493     |
|    learning_rate        | 0.000391  |
|    loss                 | 0.0368    |
|    n_updates            | 40280     |
|    policy_gradient_loss | 0.0126    |
|    std                  | 0.0611    |
|    value_loss           | 0.00113   |
---------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 4029    |
|    time_elapsed    | 13074   |
|    total_timesteps | 8251392 |
--------------------------------
--------------------------------------
| time/                   |          |
|    fps                  | 631      |
|    iterations           | 4030     |
|    time_elapsed         | 13077    |
|    total_timesteps      | 8253440  |
| train/                  |          |
|    approx_kl            | 5.627962 |
|    clip_fraction        | 0.522    |
|    clip_range           | 0.2      |
|    entropy_loss         | 2.78     |
|    explained_variance   | 0.766    |
|    learning_rate        | 0.000391 |
|    loss                 | 0.0631   |
|    n_updates            | 40290    |
|    policy_gradient_loss | 0.00912  |
|    std                  | 0.0613   |
|    value_loss           | 0.00149  |
--------------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4031       |
|    time_elapsed         | 13080      |
|    total_timesteps      | 8255488    |
| train/                  |            |
|    approx_kl            | 0.84288585 |
|    clip_fraction        | 0.463      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.78       |
|    explained_variance   | 0.131      |
|    learning_rate        | 0.000391   |
|    loss                 | -0.00948   |
|    n_updates            | 40300      |
|    policy_gradient_loss | 0.0125     |
|    std                  | 0.0614     |
|    value_loss           | 0.00288    |
----------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 4032      |
|    time_elapsed         | 13083     |
|    total_timesteps      | 8257536   |
| train/                  |           |
|    approx_kl            | 0.4233517 |
|    clip_fraction        | 0.478     |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.79      |
|    explained_variance   | 0.919     |
|    learning_rate        | 0.00039   |
|    loss                 | 0.00819   |
|    n_updates            | 40310     |
|    policy_gradient_loss | 0.0127    |
|    std                  | 0.0601    |
|    value_loss           | 0.0149    |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4033       |
|    time_elapsed         | 13087      |
|    total_timesteps      | 8259584    |
| train/                  |            |
|    approx_kl            | 0.22196558 |
|    clip_fraction        | 0.438      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.83       |
|    explained_variance   | 0.974      |
|    learning_rate        | 0.00039    |
|    loss                 | 0.049      |
|    n_updates            | 40320      |
|    policy_gradient_loss | 0.0117     |
|    std                  | 0.0594     |
|    value_loss           | 0.003      |
----------------------------------------
box reached target
Eval num_timesteps=8260000, episode_reward=0.20 +/- 2.40
Episode length: 278.20 +/- 43.60
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 278        |
|    mean_reward          | 0.202      |
| time/                   |            |
|    total_timesteps      | 8260000    |
| train/                  |            |
|    approx_kl            | 0.23059346 |
|    clip_fraction        | 0.434      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.82       |
|    explained_variance   | 0.931      |
|    learning_rate        | 0.000389   |
|    loss                 | -0.00568   |
|    n_updates            | 40330      |
|    policy_gradient_loss | 0.00361    |
|    std                  | 0.0597     |
|    value_loss           | 0.00278    |
----------------------------------------
box reached target
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 4034    |
|    time_elapsed    | 13090   |
|    total_timesteps | 8261632 |
--------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4035       |
|    time_elapsed         | 13094      |
|    total_timesteps      | 8263680    |
| train/                  |            |
|    approx_kl            | 0.31995162 |
|    clip_fraction        | 0.449      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.82       |
|    explained_variance   | 0.97       |
|    learning_rate        | 0.000389   |
|    loss                 | -0.0641    |
|    n_updates            | 40340      |
|    policy_gradient_loss | 0.0157     |
|    std                  | 0.0599     |
|    value_loss           | 0.00533    |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4036       |
|    time_elapsed         | 13097      |
|    total_timesteps      | 8265728    |
| train/                  |            |
|    approx_kl            | 0.20079434 |
|    clip_fraction        | 0.46       |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.79       |
|    explained_variance   | 0.904      |
|    learning_rate        | 0.000389   |
|    loss                 | 0.0984     |
|    n_updates            | 40350      |
|    policy_gradient_loss | 0.0232     |
|    std                  | 0.0609     |
|    value_loss           | 0.0149     |
----------------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4037       |
|    time_elapsed         | 13100      |
|    total_timesteps      | 8267776    |
| train/                  |            |
|    approx_kl            | 0.44654882 |
|    clip_fraction        | 0.511      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.77       |
|    explained_variance   | 0.936      |
|    learning_rate        | 0.000388   |
|    loss                 | 0.0952     |
|    n_updates            | 40360      |
|    policy_gradient_loss | 0.0335     |
|    std                  | 0.0611     |
|    value_loss           | 0.0149     |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4038       |
|    time_elapsed         | 13103      |
|    total_timesteps      | 8269824    |
| train/                  |            |
|    approx_kl            | 0.17116714 |
|    clip_fraction        | 0.422      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.76       |
|    explained_variance   | 0.966      |
|    learning_rate        | 0.000388   |
|    loss                 | -0.0256    |
|    n_updates            | 40370      |
|    policy_gradient_loss | 0.000866   |
|    std                  | 0.0617     |
|    value_loss           | 0.00713    |
----------------------------------------
Eval num_timesteps=8270000, episode_reward=-0.68 +/- 0.63
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -0.684     |
| time/                   |            |
|    total_timesteps      | 8270000    |
| train/                  |            |
|    approx_kl            | 0.27908432 |
|    clip_fraction        | 0.394      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.75       |
|    explained_variance   | 0.858      |
|    learning_rate        | 0.000387   |
|    loss                 | -0.0265    |
|    n_updates            | 40380      |
|    policy_gradient_loss | 0.0147     |
|    std                  | 0.0615     |
|    value_loss           | 0.00684    |
----------------------------------------
box reached target
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 4039    |
|    time_elapsed    | 13107   |
|    total_timesteps | 8271872 |
--------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4040       |
|    time_elapsed         | 13110      |
|    total_timesteps      | 8273920    |
| train/                  |            |
|    approx_kl            | 0.87564945 |
|    clip_fraction        | 0.448      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.77       |
|    explained_variance   | 0.96       |
|    learning_rate        | 0.000387   |
|    loss                 | -0.0443    |
|    n_updates            | 40390      |
|    policy_gradient_loss | -0.00323   |
|    std                  | 0.0611     |
|    value_loss           | 0.00693    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4041       |
|    time_elapsed         | 13113      |
|    total_timesteps      | 8275968    |
| train/                  |            |
|    approx_kl            | 0.24731264 |
|    clip_fraction        | 0.449      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.77       |
|    explained_variance   | 0.932      |
|    learning_rate        | 0.000387   |
|    loss                 | -0.00321   |
|    n_updates            | 40400      |
|    policy_gradient_loss | 0.0121     |
|    std                  | 0.0615     |
|    value_loss           | 0.0063     |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4042       |
|    time_elapsed         | 13116      |
|    total_timesteps      | 8278016    |
| train/                  |            |
|    approx_kl            | 0.24287724 |
|    clip_fraction        | 0.395      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.76       |
|    explained_variance   | 0.523      |
|    learning_rate        | 0.000386   |
|    loss                 | -0.00501   |
|    n_updates            | 40410      |
|    policy_gradient_loss | 0.00782    |
|    std                  | 0.0612     |
|    value_loss           | 0.00221    |
----------------------------------------
Eval num_timesteps=8280000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1         |
| time/                   |            |
|    total_timesteps      | 8280000    |
| train/                  |            |
|    approx_kl            | 0.79561126 |
|    clip_fraction        | 0.457      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.75       |
|    explained_variance   | 0.207      |
|    learning_rate        | 0.000386   |
|    loss                 | 0.0532     |
|    n_updates            | 40420      |
|    policy_gradient_loss | 0.0383     |
|    std                  | 0.0627     |
|    value_loss           | 0.00171    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 4043    |
|    time_elapsed    | 13120   |
|    total_timesteps | 8280064 |
--------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4044       |
|    time_elapsed         | 13123      |
|    total_timesteps      | 8282112    |
| train/                  |            |
|    approx_kl            | 0.18227795 |
|    clip_fraction        | 0.4        |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.74       |
|    explained_variance   | 0.759      |
|    learning_rate        | 0.000385   |
|    loss                 | 0.00432    |
|    n_updates            | 40430      |
|    policy_gradient_loss | 0.0178     |
|    std                  | 0.0618     |
|    value_loss           | 0.00262    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4045       |
|    time_elapsed         | 13126      |
|    total_timesteps      | 8284160    |
| train/                  |            |
|    approx_kl            | 0.32607904 |
|    clip_fraction        | 0.474      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.75       |
|    explained_variance   | 0.961      |
|    learning_rate        | 0.000385   |
|    loss                 | -0.0302    |
|    n_updates            | 40440      |
|    policy_gradient_loss | 0.00292    |
|    std                  | 0.0618     |
|    value_loss           | 0.00577    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4046       |
|    time_elapsed         | 13129      |
|    total_timesteps      | 8286208    |
| train/                  |            |
|    approx_kl            | 0.30307364 |
|    clip_fraction        | 0.436      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.73       |
|    explained_variance   | 0.86       |
|    learning_rate        | 0.000385   |
|    loss                 | -0.0261    |
|    n_updates            | 40450      |
|    policy_gradient_loss | 0.00451    |
|    std                  | 0.0624     |
|    value_loss           | 0.00408    |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4047       |
|    time_elapsed         | 13132      |
|    total_timesteps      | 8288256    |
| train/                  |            |
|    approx_kl            | 0.21871904 |
|    clip_fraction        | 0.437      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.72       |
|    explained_variance   | 0.716      |
|    learning_rate        | 0.000384   |
|    loss                 | 0.00385    |
|    n_updates            | 40460      |
|    policy_gradient_loss | 0.0113     |
|    std                  | 0.0631     |
|    value_loss           | 0.00295    |
----------------------------------------
Eval num_timesteps=8290000, episode_reward=-0.54 +/- 0.64
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -0.54      |
| time/                   |            |
|    total_timesteps      | 8290000    |
| train/                  |            |
|    approx_kl            | 0.46692723 |
|    clip_fraction        | 0.49       |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.7        |
|    explained_variance   | 0.928      |
|    learning_rate        | 0.000384   |
|    loss                 | 0.0469     |
|    n_updates            | 40470      |
|    policy_gradient_loss | 0.012      |
|    std                  | 0.0634     |
|    value_loss           | 0.00531    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 4048    |
|    time_elapsed    | 13136   |
|    total_timesteps | 8290304 |
--------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4049       |
|    time_elapsed         | 13139      |
|    total_timesteps      | 8292352    |
| train/                  |            |
|    approx_kl            | 0.28882003 |
|    clip_fraction        | 0.403      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.73       |
|    explained_variance   | 0.541      |
|    learning_rate        | 0.000383   |
|    loss                 | 0.00506    |
|    n_updates            | 40480      |
|    policy_gradient_loss | -0.000927  |
|    std                  | 0.0622     |
|    value_loss           | 0.00162    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4050       |
|    time_elapsed         | 13142      |
|    total_timesteps      | 8294400    |
| train/                  |            |
|    approx_kl            | 0.14066681 |
|    clip_fraction        | 0.466      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.73       |
|    explained_variance   | 0.971      |
|    learning_rate        | 0.000383   |
|    loss                 | -0.00645   |
|    n_updates            | 40490      |
|    policy_gradient_loss | 0.00787    |
|    std                  | 0.0627     |
|    value_loss           | 0.0043     |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4051       |
|    time_elapsed         | 13145      |
|    total_timesteps      | 8296448    |
| train/                  |            |
|    approx_kl            | 0.16452149 |
|    clip_fraction        | 0.378      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.72       |
|    explained_variance   | 0.699      |
|    learning_rate        | 0.000383   |
|    loss                 | 0.0144     |
|    n_updates            | 40500      |
|    policy_gradient_loss | 0.0237     |
|    std                  | 0.0634     |
|    value_loss           | 0.000883   |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4052       |
|    time_elapsed         | 13148      |
|    total_timesteps      | 8298496    |
| train/                  |            |
|    approx_kl            | 0.18385419 |
|    clip_fraction        | 0.377      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.7        |
|    explained_variance   | 0.482      |
|    learning_rate        | 0.000382   |
|    loss                 | -0.0136    |
|    n_updates            | 40510      |
|    policy_gradient_loss | 0.0126     |
|    std                  | 0.0633     |
|    value_loss           | 0.000921   |
----------------------------------------
box reached target
Eval num_timesteps=8300000, episode_reward=0.55 +/- 2.44
Episode length: 278.00 +/- 44.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 278        |
|    mean_reward          | 0.548      |
| time/                   |            |
|    total_timesteps      | 8300000    |
| train/                  |            |
|    approx_kl            | 0.47387892 |
|    clip_fraction        | 0.411      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.7        |
|    explained_variance   | 0.984      |
|    learning_rate        | 0.000382   |
|    loss                 | -0.0171    |
|    n_updates            | 40520      |
|    policy_gradient_loss | 0.0115     |
|    std                  | 0.0633     |
|    value_loss           | 0.00263    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 4053    |
|    time_elapsed    | 13152   |
|    total_timesteps | 8300544 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4054       |
|    time_elapsed         | 13155      |
|    total_timesteps      | 8302592    |
| train/                  |            |
|    approx_kl            | 0.14304993 |
|    clip_fraction        | 0.453      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.69       |
|    explained_variance   | 0.802      |
|    learning_rate        | 0.000381   |
|    loss                 | 0.0152     |
|    n_updates            | 40530      |
|    policy_gradient_loss | 0.0167     |
|    std                  | 0.0643     |
|    value_loss           | 0.0112     |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4055       |
|    time_elapsed         | 13158      |
|    total_timesteps      | 8304640    |
| train/                  |            |
|    approx_kl            | 0.14430124 |
|    clip_fraction        | 0.362      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.68       |
|    explained_variance   | 0.609      |
|    learning_rate        | 0.000381   |
|    loss                 | 0.00415    |
|    n_updates            | 40540      |
|    policy_gradient_loss | 0.0103     |
|    std                  | 0.0636     |
|    value_loss           | 0.001      |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4056       |
|    time_elapsed         | 13161      |
|    total_timesteps      | 8306688    |
| train/                  |            |
|    approx_kl            | 0.18960711 |
|    clip_fraction        | 0.403      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.69       |
|    explained_variance   | 0.8        |
|    learning_rate        | 0.000381   |
|    loss                 | 0.0324     |
|    n_updates            | 40550      |
|    policy_gradient_loss | 0.0137     |
|    std                  | 0.0639     |
|    value_loss           | 0.000795   |
----------------------------------------
box reached target
box reached target
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4057       |
|    time_elapsed         | 13164      |
|    total_timesteps      | 8308736    |
| train/                  |            |
|    approx_kl            | 0.17152697 |
|    clip_fraction        | 0.419      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.67       |
|    explained_variance   | 0.902      |
|    learning_rate        | 0.00038    |
|    loss                 | -0.0257    |
|    n_updates            | 40560      |
|    policy_gradient_loss | -0.00232   |
|    std                  | 0.0642     |
|    value_loss           | 0.00308    |
----------------------------------------
Eval num_timesteps=8310000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1         |
| time/                   |            |
|    total_timesteps      | 8310000    |
| train/                  |            |
|    approx_kl            | 0.24184111 |
|    clip_fraction        | 0.49       |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.66       |
|    explained_variance   | 0.932      |
|    learning_rate        | 0.00038    |
|    loss                 | 0.0731     |
|    n_updates            | 40570      |
|    policy_gradient_loss | 0.0165     |
|    std                  | 0.0647     |
|    value_loss           | 0.0219     |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 4058    |
|    time_elapsed    | 13168   |
|    total_timesteps | 8310784 |
--------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 4059      |
|    time_elapsed         | 13171     |
|    total_timesteps      | 8312832   |
| train/                  |           |
|    approx_kl            | 0.2695663 |
|    clip_fraction        | 0.398     |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.65      |
|    explained_variance   | 0.27      |
|    learning_rate        | 0.000379  |
|    loss                 | -0.0337   |
|    n_updates            | 40580     |
|    policy_gradient_loss | 0.00705   |
|    std                  | 0.0649    |
|    value_loss           | 0.00178   |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4060       |
|    time_elapsed         | 13175      |
|    total_timesteps      | 8314880    |
| train/                  |            |
|    approx_kl            | 0.40608287 |
|    clip_fraction        | 0.408      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.66       |
|    explained_variance   | 0.186      |
|    learning_rate        | 0.000379   |
|    loss                 | -0.000312  |
|    n_updates            | 40590      |
|    policy_gradient_loss | 0.0114     |
|    std                  | 0.0645     |
|    value_loss           | 0.00143    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4061       |
|    time_elapsed         | 13178      |
|    total_timesteps      | 8316928    |
| train/                  |            |
|    approx_kl            | 0.27776432 |
|    clip_fraction        | 0.485      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.65       |
|    explained_variance   | 0.868      |
|    learning_rate        | 0.000379   |
|    loss                 | -0.00423   |
|    n_updates            | 40600      |
|    policy_gradient_loss | 0.0204     |
|    std                  | 0.0653     |
|    value_loss           | 0.00288    |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4062       |
|    time_elapsed         | 13181      |
|    total_timesteps      | 8318976    |
| train/                  |            |
|    approx_kl            | 0.22922024 |
|    clip_fraction        | 0.473      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.63       |
|    explained_variance   | 0.727      |
|    learning_rate        | 0.000378   |
|    loss                 | -0.00232   |
|    n_updates            | 40610      |
|    policy_gradient_loss | 0.0857     |
|    std                  | 0.0654     |
|    value_loss           | 0.00258    |
----------------------------------------
box reached target
Eval num_timesteps=8320000, episode_reward=0.24 +/- 2.47
Episode length: 276.80 +/- 46.40
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 277       |
|    mean_reward          | 0.235     |
| time/                   |           |
|    total_timesteps      | 8320000   |
| train/                  |           |
|    approx_kl            | 0.3386925 |
|    clip_fraction        | 0.467     |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.6       |
|    explained_variance   | 0.928     |
|    learning_rate        | 0.000378  |
|    loss                 | -0.0587   |
|    n_updates            | 40620     |
|    policy_gradient_loss | 0.0094    |
|    std                  | 0.0668    |
|    value_loss           | 0.013     |
---------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 4063    |
|    time_elapsed    | 13185   |
|    total_timesteps | 8321024 |
--------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 631         |
|    iterations           | 4064        |
|    time_elapsed         | 13188       |
|    total_timesteps      | 8323072     |
| train/                  |             |
|    approx_kl            | 0.094253704 |
|    clip_fraction        | 0.445       |
|    clip_range           | 0.2         |
|    entropy_loss         | 2.57        |
|    explained_variance   | 0.729       |
|    learning_rate        | 0.000377    |
|    loss                 | 0.00383     |
|    n_updates            | 40630       |
|    policy_gradient_loss | 0.0146      |
|    std                  | 0.0677      |
|    value_loss           | 0.0103      |
-----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4065       |
|    time_elapsed         | 13191      |
|    total_timesteps      | 8325120    |
| train/                  |            |
|    approx_kl            | 0.15554364 |
|    clip_fraction        | 0.38       |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.56       |
|    explained_variance   | 0.147      |
|    learning_rate        | 0.000377   |
|    loss                 | -0.0262    |
|    n_updates            | 40640      |
|    policy_gradient_loss | -0.00324   |
|    std                  | 0.0677     |
|    value_loss           | 0.00152    |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4066       |
|    time_elapsed         | 13194      |
|    total_timesteps      | 8327168    |
| train/                  |            |
|    approx_kl            | 0.29650545 |
|    clip_fraction        | 0.434      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.55       |
|    explained_variance   | 0.869      |
|    learning_rate        | 0.000377   |
|    loss                 | 0.00433    |
|    n_updates            | 40650      |
|    policy_gradient_loss | 0.00937    |
|    std                  | 0.0684     |
|    value_loss           | 0.00244    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4067       |
|    time_elapsed         | 13197      |
|    total_timesteps      | 8329216    |
| train/                  |            |
|    approx_kl            | 0.08979251 |
|    clip_fraction        | 0.421      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.55       |
|    explained_variance   | 0.978      |
|    learning_rate        | 0.000376   |
|    loss                 | -0.0074    |
|    n_updates            | 40660      |
|    policy_gradient_loss | 0.0136     |
|    std                  | 0.0677     |
|    value_loss           | 0.00201    |
----------------------------------------
box reached target
Eval num_timesteps=8330000, episode_reward=-0.71 +/- 0.57
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -0.714     |
| time/                   |            |
|    total_timesteps      | 8330000    |
| train/                  |            |
|    approx_kl            | 0.80788255 |
|    clip_fraction        | 0.415      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.56       |
|    explained_variance   | 0.711      |
|    learning_rate        | 0.000376   |
|    loss                 | -0.00753   |
|    n_updates            | 40670      |
|    policy_gradient_loss | -0.0147    |
|    std                  | 0.0673     |
|    value_loss           | 0.00403    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 4068    |
|    time_elapsed    | 13201   |
|    total_timesteps | 8331264 |
--------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4069       |
|    time_elapsed         | 13204      |
|    total_timesteps      | 8333312    |
| train/                  |            |
|    approx_kl            | 0.17900881 |
|    clip_fraction        | 0.439      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.56       |
|    explained_variance   | 0.928      |
|    learning_rate        | 0.000375   |
|    loss                 | -0.0077    |
|    n_updates            | 40680      |
|    policy_gradient_loss | 0.0116     |
|    std                  | 0.0682     |
|    value_loss           | 0.00825    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4070       |
|    time_elapsed         | 13207      |
|    total_timesteps      | 8335360    |
| train/                  |            |
|    approx_kl            | 0.26716602 |
|    clip_fraction        | 0.455      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.56       |
|    explained_variance   | 0.969      |
|    learning_rate        | 0.000375   |
|    loss                 | 0.0377     |
|    n_updates            | 40690      |
|    policy_gradient_loss | 0.0149     |
|    std                  | 0.0676     |
|    value_loss           | 0.00402    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4071       |
|    time_elapsed         | 13210      |
|    total_timesteps      | 8337408    |
| train/                  |            |
|    approx_kl            | 0.17504422 |
|    clip_fraction        | 0.38       |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.58       |
|    explained_variance   | 0.382      |
|    learning_rate        | 0.000375   |
|    loss                 | -0.0398    |
|    n_updates            | 40700      |
|    policy_gradient_loss | -0.00404   |
|    std                  | 0.0667     |
|    value_loss           | 0.00148    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4072       |
|    time_elapsed         | 13213      |
|    total_timesteps      | 8339456    |
| train/                  |            |
|    approx_kl            | 0.12889905 |
|    clip_fraction        | 0.45       |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.6        |
|    explained_variance   | 0.769      |
|    learning_rate        | 0.000374   |
|    loss                 | 0.0176     |
|    n_updates            | 40710      |
|    policy_gradient_loss | 0.02       |
|    std                  | 0.0661     |
|    value_loss           | 0.00161    |
----------------------------------------
Eval num_timesteps=8340000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1         |
| time/                   |            |
|    total_timesteps      | 8340000    |
| train/                  |            |
|    approx_kl            | 0.17855324 |
|    clip_fraction        | 0.433      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.61       |
|    explained_variance   | 0.67       |
|    learning_rate        | 0.000374   |
|    loss                 | -0.0236    |
|    n_updates            | 40720      |
|    policy_gradient_loss | 0.00897    |
|    std                  | 0.0662     |
|    value_loss           | 0.00175    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 4073    |
|    time_elapsed    | 13217   |
|    total_timesteps | 8341504 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4074       |
|    time_elapsed         | 13220      |
|    total_timesteps      | 8343552    |
| train/                  |            |
|    approx_kl            | 0.17197113 |
|    clip_fraction        | 0.355      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.62       |
|    explained_variance   | 0.598      |
|    learning_rate        | 0.000373   |
|    loss                 | -0.018     |
|    n_updates            | 40730      |
|    policy_gradient_loss | 0.00493    |
|    std                  | 0.0659     |
|    value_loss           | 0.000865   |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4075       |
|    time_elapsed         | 13223      |
|    total_timesteps      | 8345600    |
| train/                  |            |
|    approx_kl            | 0.38402736 |
|    clip_fraction        | 0.352      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.64       |
|    explained_variance   | 0.119      |
|    learning_rate        | 0.000373   |
|    loss                 | -0.0641    |
|    n_updates            | 40740      |
|    policy_gradient_loss | 0.00282    |
|    std                  | 0.0646     |
|    value_loss           | 0.00226    |
----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 4076      |
|    time_elapsed         | 13226     |
|    total_timesteps      | 8347648   |
| train/                  |           |
|    approx_kl            | 0.2152709 |
|    clip_fraction        | 0.381     |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.65      |
|    explained_variance   | 0.489     |
|    learning_rate        | 0.000373  |
|    loss                 | -0.0282   |
|    n_updates            | 40750     |
|    policy_gradient_loss | 0.00834   |
|    std                  | 0.0649    |
|    value_loss           | 0.00111   |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4077       |
|    time_elapsed         | 13229      |
|    total_timesteps      | 8349696    |
| train/                  |            |
|    approx_kl            | 0.14250591 |
|    clip_fraction        | 0.397      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.65       |
|    explained_variance   | 0.723      |
|    learning_rate        | 0.000372   |
|    loss                 | 0.0155     |
|    n_updates            | 40760      |
|    policy_gradient_loss | 0.0031     |
|    std                  | 0.0651     |
|    value_loss           | 0.00093    |
----------------------------------------
Eval num_timesteps=8350000, episode_reward=-0.73 +/- 0.54
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -0.732     |
| time/                   |            |
|    total_timesteps      | 8350000    |
| train/                  |            |
|    approx_kl            | 0.12557341 |
|    clip_fraction        | 0.373      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.63       |
|    explained_variance   | 0.67       |
|    learning_rate        | 0.000372   |
|    loss                 | -0.0157    |
|    n_updates            | 40770      |
|    policy_gradient_loss | 0.0126     |
|    std                  | 0.066      |
|    value_loss           | 0.00114    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 4078    |
|    time_elapsed    | 13233   |
|    total_timesteps | 8351744 |
--------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4079       |
|    time_elapsed         | 13236      |
|    total_timesteps      | 8353792    |
| train/                  |            |
|    approx_kl            | 0.35143954 |
|    clip_fraction        | 0.423      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.64       |
|    explained_variance   | 0.432      |
|    learning_rate        | 0.000371   |
|    loss                 | 0.0297     |
|    n_updates            | 40780      |
|    policy_gradient_loss | 0.0175     |
|    std                  | 0.0652     |
|    value_loss           | 0.00112    |
----------------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 631         |
|    iterations           | 4080        |
|    time_elapsed         | 13239       |
|    total_timesteps      | 8355840     |
| train/                  |             |
|    approx_kl            | 0.107186094 |
|    clip_fraction        | 0.439       |
|    clip_range           | 0.2         |
|    entropy_loss         | 2.64        |
|    explained_variance   | 0.725       |
|    learning_rate        | 0.000371    |
|    loss                 | -0.00983    |
|    n_updates            | 40790       |
|    policy_gradient_loss | 0.0123      |
|    std                  | 0.0656      |
|    value_loss           | 0.128       |
-----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4081       |
|    time_elapsed         | 13242      |
|    total_timesteps      | 8357888    |
| train/                  |            |
|    approx_kl            | 0.16599838 |
|    clip_fraction        | 0.39       |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.64       |
|    explained_variance   | 0.975      |
|    learning_rate        | 0.000371   |
|    loss                 | -0.0169    |
|    n_updates            | 40800      |
|    policy_gradient_loss | 0.0295     |
|    std                  | 0.0654     |
|    value_loss           | 0.00198    |
----------------------------------------
box reached target
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4082       |
|    time_elapsed         | 13245      |
|    total_timesteps      | 8359936    |
| train/                  |            |
|    approx_kl            | 0.16115081 |
|    clip_fraction        | 0.332      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.67       |
|    explained_variance   | 0.56       |
|    learning_rate        | 0.00037    |
|    loss                 | 0.0472     |
|    n_updates            | 40810      |
|    policy_gradient_loss | 0.000747   |
|    std                  | 0.0641     |
|    value_loss           | 0.000853   |
----------------------------------------
Eval num_timesteps=8360000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
--------------------------------------
| eval/                   |          |
|    mean_ep_length       | 300      |
|    mean_reward          | -1       |
| time/                   |          |
|    total_timesteps      | 8360000  |
| train/                  |          |
|    approx_kl            | 3.921748 |
|    clip_fraction        | 0.569    |
|    clip_range           | 0.2      |
|    entropy_loss         | 2.69     |
|    explained_variance   | 0.849    |
|    learning_rate        | 0.00037  |
|    loss                 | 0.0275   |
|    n_updates            | 40820    |
|    policy_gradient_loss | 0.0424   |
|    std                  | 0.0639   |
|    value_loss           | 0.141    |
--------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 4083    |
|    time_elapsed    | 13249   |
|    total_timesteps | 8361984 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4084       |
|    time_elapsed         | 13252      |
|    total_timesteps      | 8364032    |
| train/                  |            |
|    approx_kl            | 0.50015736 |
|    clip_fraction        | 0.382      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.69       |
|    explained_variance   | 0.668      |
|    learning_rate        | 0.000369   |
|    loss                 | -0.0367    |
|    n_updates            | 40830      |
|    policy_gradient_loss | 0.0113     |
|    std                  | 0.064      |
|    value_loss           | 0.00155    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4085       |
|    time_elapsed         | 13255      |
|    total_timesteps      | 8366080    |
| train/                  |            |
|    approx_kl            | 0.13470323 |
|    clip_fraction        | 0.444      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.69       |
|    explained_variance   | 0.776      |
|    learning_rate        | 0.000369   |
|    loss                 | 0.026      |
|    n_updates            | 40840      |
|    policy_gradient_loss | 0.0224     |
|    std                  | 0.0642     |
|    value_loss           | 0.00282    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4086       |
|    time_elapsed         | 13259      |
|    total_timesteps      | 8368128    |
| train/                  |            |
|    approx_kl            | 0.33701742 |
|    clip_fraction        | 0.417      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.67       |
|    explained_variance   | 0.498      |
|    learning_rate        | 0.000369   |
|    loss                 | 0.0613     |
|    n_updates            | 40850      |
|    policy_gradient_loss | 0.0236     |
|    std                  | 0.065      |
|    value_loss           | 0.00102    |
----------------------------------------
box reached target
Eval num_timesteps=8370000, episode_reward=0.24 +/- 2.48
Episode length: 268.80 +/- 62.40
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 269        |
|    mean_reward          | 0.238      |
| time/                   |            |
|    total_timesteps      | 8370000    |
| train/                  |            |
|    approx_kl            | 0.42750967 |
|    clip_fraction        | 0.407      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.66       |
|    explained_variance   | 0.562      |
|    learning_rate        | 0.000368   |
|    loss                 | -0.0644    |
|    n_updates            | 40860      |
|    policy_gradient_loss | -0.00996   |
|    std                  | 0.0647     |
|    value_loss           | 0.00115    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 4087    |
|    time_elapsed    | 13262   |
|    total_timesteps | 8370176 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4088       |
|    time_elapsed         | 13265      |
|    total_timesteps      | 8372224    |
| train/                  |            |
|    approx_kl            | 0.22525336 |
|    clip_fraction        | 0.426      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.67       |
|    explained_variance   | 0.544      |
|    learning_rate        | 0.000368   |
|    loss                 | 0.00913    |
|    n_updates            | 40870      |
|    policy_gradient_loss | 0.0184     |
|    std                  | 0.0643     |
|    value_loss           | 0.000741   |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4089       |
|    time_elapsed         | 13269      |
|    total_timesteps      | 8374272    |
| train/                  |            |
|    approx_kl            | 0.12323762 |
|    clip_fraction        | 0.381      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.66       |
|    explained_variance   | 0.528      |
|    learning_rate        | 0.000367   |
|    loss                 | -0.0163    |
|    n_updates            | 40880      |
|    policy_gradient_loss | 0.00793    |
|    std                  | 0.0649     |
|    value_loss           | 0.00125    |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4090       |
|    time_elapsed         | 13272      |
|    total_timesteps      | 8376320    |
| train/                  |            |
|    approx_kl            | 0.14171845 |
|    clip_fraction        | 0.481      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.65       |
|    explained_variance   | 0.719      |
|    learning_rate        | 0.000367   |
|    loss                 | 0.0558     |
|    n_updates            | 40890      |
|    policy_gradient_loss | 0.0175     |
|    std                  | 0.0651     |
|    value_loss           | 0.045      |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4091       |
|    time_elapsed         | 13275      |
|    total_timesteps      | 8378368    |
| train/                  |            |
|    approx_kl            | 0.17872795 |
|    clip_fraction        | 0.413      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.66       |
|    explained_variance   | 0.949      |
|    learning_rate        | 0.000367   |
|    loss                 | -0.0366    |
|    n_updates            | 40900      |
|    policy_gradient_loss | 0.00298    |
|    std                  | 0.0647     |
|    value_loss           | 0.00469    |
----------------------------------------
Eval num_timesteps=8380000, episode_reward=-0.74 +/- 0.51
Episode length: 300.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 300       |
|    mean_reward          | -0.743    |
| time/                   |           |
|    total_timesteps      | 8380000   |
| train/                  |           |
|    approx_kl            | 0.1942147 |
|    clip_fraction        | 0.4       |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.66      |
|    explained_variance   | 0.547     |
|    learning_rate        | 0.000366  |
|    loss                 | 0.0146    |
|    n_updates            | 40910     |
|    policy_gradient_loss | 0.026     |
|    std                  | 0.065     |
|    value_loss           | 0.00151   |
---------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 4092    |
|    time_elapsed    | 13279   |
|    total_timesteps | 8380416 |
--------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 4093      |
|    time_elapsed         | 13282     |
|    total_timesteps      | 8382464   |
| train/                  |           |
|    approx_kl            | 0.2214585 |
|    clip_fraction        | 0.402     |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.66      |
|    explained_variance   | 0.373     |
|    learning_rate        | 0.000366  |
|    loss                 | 0.00297   |
|    n_updates            | 40920     |
|    policy_gradient_loss | -0.00268  |
|    std                  | 0.065     |
|    value_loss           | 0.00199   |
---------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4094       |
|    time_elapsed         | 13285      |
|    total_timesteps      | 8384512    |
| train/                  |            |
|    approx_kl            | 0.14526805 |
|    clip_fraction        | 0.427      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.65       |
|    explained_variance   | 0.704      |
|    learning_rate        | 0.000365   |
|    loss                 | -0.0337    |
|    n_updates            | 40930      |
|    policy_gradient_loss | 0.0125     |
|    std                  | 0.0655     |
|    value_loss           | 0.00348    |
----------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 4095      |
|    time_elapsed         | 13288     |
|    total_timesteps      | 8386560   |
| train/                  |           |
|    approx_kl            | 0.1487878 |
|    clip_fraction        | 0.446     |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.64      |
|    explained_variance   | 0.383     |
|    learning_rate        | 0.000365  |
|    loss                 | 0.0557    |
|    n_updates            | 40940     |
|    policy_gradient_loss | 0.011     |
|    std                  | 0.0656    |
|    value_loss           | 0.123     |
---------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4096       |
|    time_elapsed         | 13291      |
|    total_timesteps      | 8388608    |
| train/                  |            |
|    approx_kl            | 0.23442304 |
|    clip_fraction        | 0.48       |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.64       |
|    explained_variance   | 0.163      |
|    learning_rate        | 0.000365   |
|    loss                 | 0.0742     |
|    n_updates            | 40950      |
|    policy_gradient_loss | 0.015      |
|    std                  | 0.0657     |
|    value_loss           | 0.119      |
----------------------------------------
Eval num_timesteps=8390000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1         |
| time/                   |            |
|    total_timesteps      | 8390000    |
| train/                  |            |
|    approx_kl            | 0.10133354 |
|    clip_fraction        | 0.346      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.64       |
|    explained_variance   | 0.973      |
|    learning_rate        | 0.000364   |
|    loss                 | -0.00316   |
|    n_updates            | 40960      |
|    policy_gradient_loss | 0.0125     |
|    std                  | 0.0652     |
|    value_loss           | 0.00355    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 4097    |
|    time_elapsed    | 13295   |
|    total_timesteps | 8390656 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4098       |
|    time_elapsed         | 13298      |
|    total_timesteps      | 8392704    |
| train/                  |            |
|    approx_kl            | 0.11717727 |
|    clip_fraction        | 0.386      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.64       |
|    explained_variance   | 0.514      |
|    learning_rate        | 0.000364   |
|    loss                 | 0.02       |
|    n_updates            | 40970      |
|    policy_gradient_loss | 0.0192     |
|    std                  | 0.0655     |
|    value_loss           | 0.00152    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4099       |
|    time_elapsed         | 13301      |
|    total_timesteps      | 8394752    |
| train/                  |            |
|    approx_kl            | 0.18645626 |
|    clip_fraction        | 0.389      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.64       |
|    explained_variance   | 0.847      |
|    learning_rate        | 0.000363   |
|    loss                 | 0.023      |
|    n_updates            | 40980      |
|    policy_gradient_loss | 0.00126    |
|    std                  | 0.0649     |
|    value_loss           | 0.00511    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4100       |
|    time_elapsed         | 13304      |
|    total_timesteps      | 8396800    |
| train/                  |            |
|    approx_kl            | 0.18704304 |
|    clip_fraction        | 0.397      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.65       |
|    explained_variance   | 0.555      |
|    learning_rate        | 0.000363   |
|    loss                 | 0.0504     |
|    n_updates            | 40990      |
|    policy_gradient_loss | 0.00776    |
|    std                  | 0.0644     |
|    value_loss           | 0.00121    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4101       |
|    time_elapsed         | 13307      |
|    total_timesteps      | 8398848    |
| train/                  |            |
|    approx_kl            | 0.33532834 |
|    clip_fraction        | 0.401      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.66       |
|    explained_variance   | 0.673      |
|    learning_rate        | 0.000363   |
|    loss                 | -0.0306    |
|    n_updates            | 41000      |
|    policy_gradient_loss | 0.0024     |
|    std                  | 0.0645     |
|    value_loss           | 0.00164    |
----------------------------------------
Eval num_timesteps=8400000, episode_reward=-0.74 +/- 0.53
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -0.736     |
| time/                   |            |
|    total_timesteps      | 8400000    |
| train/                  |            |
|    approx_kl            | 0.09125898 |
|    clip_fraction        | 0.365      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.66       |
|    explained_variance   | 0.435      |
|    learning_rate        | 0.000362   |
|    loss                 | -0.0167    |
|    n_updates            | 41010      |
|    policy_gradient_loss | 0.0163     |
|    std                  | 0.0647     |
|    value_loss           | 0.000984   |
----------------------------------------
box reached target
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 4102    |
|    time_elapsed    | 13311   |
|    total_timesteps | 8400896 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4103       |
|    time_elapsed         | 13314      |
|    total_timesteps      | 8402944    |
| train/                  |            |
|    approx_kl            | 0.35417274 |
|    clip_fraction        | 0.498      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.65       |
|    explained_variance   | 0.933      |
|    learning_rate        | 0.000362   |
|    loss                 | 0.0216     |
|    n_updates            | 41020      |
|    policy_gradient_loss | 0.00547    |
|    std                  | 0.0642     |
|    value_loss           | 0.0146     |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4104       |
|    time_elapsed         | 13317      |
|    total_timesteps      | 8404992    |
| train/                  |            |
|    approx_kl            | 0.15777841 |
|    clip_fraction        | 0.348      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.66       |
|    explained_variance   | 0.375      |
|    learning_rate        | 0.000361   |
|    loss                 | 0.000563   |
|    n_updates            | 41030      |
|    policy_gradient_loss | 0.0156     |
|    std                  | 0.0648     |
|    value_loss           | 0.00112    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4105       |
|    time_elapsed         | 13320      |
|    total_timesteps      | 8407040    |
| train/                  |            |
|    approx_kl            | 0.18410194 |
|    clip_fraction        | 0.375      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.63       |
|    explained_variance   | 0.683      |
|    learning_rate        | 0.000361   |
|    loss                 | -0.0227    |
|    n_updates            | 41040      |
|    policy_gradient_loss | 0.0109     |
|    std                  | 0.0656     |
|    value_loss           | 0.000707   |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4106       |
|    time_elapsed         | 13323      |
|    total_timesteps      | 8409088    |
| train/                  |            |
|    approx_kl            | 0.39298773 |
|    clip_fraction        | 0.414      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.63       |
|    explained_variance   | 0.419      |
|    learning_rate        | 0.000361   |
|    loss                 | -0.00151   |
|    n_updates            | 41050      |
|    policy_gradient_loss | 0.0114     |
|    std                  | 0.0649     |
|    value_loss           | 0.001      |
----------------------------------------
Eval num_timesteps=8410000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1         |
| time/                   |            |
|    total_timesteps      | 8410000    |
| train/                  |            |
|    approx_kl            | 0.19629002 |
|    clip_fraction        | 0.394      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.64       |
|    explained_variance   | 0.453      |
|    learning_rate        | 0.00036    |
|    loss                 | 0.0415     |
|    n_updates            | 41060      |
|    policy_gradient_loss | 0.018      |
|    std                  | 0.065      |
|    value_loss           | 0.0011     |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 4107    |
|    time_elapsed    | 13327   |
|    total_timesteps | 8411136 |
--------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4108       |
|    time_elapsed         | 13330      |
|    total_timesteps      | 8413184    |
| train/                  |            |
|    approx_kl            | 0.17778334 |
|    clip_fraction        | 0.39       |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.63       |
|    explained_variance   | 0.765      |
|    learning_rate        | 0.00036    |
|    loss                 | -0.027     |
|    n_updates            | 41070      |
|    policy_gradient_loss | 0.00292    |
|    std                  | 0.0652     |
|    value_loss           | 0.00311    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4109       |
|    time_elapsed         | 13333      |
|    total_timesteps      | 8415232    |
| train/                  |            |
|    approx_kl            | 0.21710649 |
|    clip_fraction        | 0.476      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.64       |
|    explained_variance   | 0.811      |
|    learning_rate        | 0.000359   |
|    loss                 | 0.00799    |
|    n_updates            | 41080      |
|    policy_gradient_loss | 0.0105     |
|    std                  | 0.0653     |
|    value_loss           | 0.0198     |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4110       |
|    time_elapsed         | 13336      |
|    total_timesteps      | 8417280    |
| train/                  |            |
|    approx_kl            | 0.12465647 |
|    clip_fraction        | 0.426      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.62       |
|    explained_variance   | 0.83       |
|    learning_rate        | 0.000359   |
|    loss                 | -0.0112    |
|    n_updates            | 41090      |
|    policy_gradient_loss | 0.0165     |
|    std                  | 0.0656     |
|    value_loss           | 0.00787    |
----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 4111      |
|    time_elapsed         | 13339     |
|    total_timesteps      | 8419328   |
| train/                  |           |
|    approx_kl            | 0.3044448 |
|    clip_fraction        | 0.451     |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.6       |
|    explained_variance   | 0.878     |
|    learning_rate        | 0.000359  |
|    loss                 | -0.0256   |
|    n_updates            | 41100     |
|    policy_gradient_loss | -0.00102  |
|    std                  | 0.0661    |
|    value_loss           | 0.00229   |
---------------------------------------
Eval num_timesteps=8420000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1         |
| time/                   |            |
|    total_timesteps      | 8420000    |
| train/                  |            |
|    approx_kl            | 0.40796876 |
|    clip_fraction        | 0.454      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.62       |
|    explained_variance   | 0.526      |
|    learning_rate        | 0.000358   |
|    loss                 | 0.00941    |
|    n_updates            | 41110      |
|    policy_gradient_loss | 0.0444     |
|    std                  | 0.0654     |
|    value_loss           | 0.00162    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 4112    |
|    time_elapsed    | 13343   |
|    total_timesteps | 8421376 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4113       |
|    time_elapsed         | 13346      |
|    total_timesteps      | 8423424    |
| train/                  |            |
|    approx_kl            | 0.47987252 |
|    clip_fraction        | 0.381      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.64       |
|    explained_variance   | 0.348      |
|    learning_rate        | 0.000358   |
|    loss                 | -0.00274   |
|    n_updates            | 41120      |
|    policy_gradient_loss | 0.0224     |
|    std                  | 0.0649     |
|    value_loss           | 0.00137    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4114       |
|    time_elapsed         | 13350      |
|    total_timesteps      | 8425472    |
| train/                  |            |
|    approx_kl            | 0.10301395 |
|    clip_fraction        | 0.382      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.64       |
|    explained_variance   | 0.348      |
|    learning_rate        | 0.000357   |
|    loss                 | -0.028     |
|    n_updates            | 41130      |
|    policy_gradient_loss | 0.00513    |
|    std                  | 0.0651     |
|    value_loss           | 0.00213    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4115       |
|    time_elapsed         | 13353      |
|    total_timesteps      | 8427520    |
| train/                  |            |
|    approx_kl            | 0.22509955 |
|    clip_fraction        | 0.398      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.64       |
|    explained_variance   | 0.403      |
|    learning_rate        | 0.000357   |
|    loss                 | -0.0288    |
|    n_updates            | 41140      |
|    policy_gradient_loss | 0.00834    |
|    std                  | 0.0651     |
|    value_loss           | 0.00153    |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4116       |
|    time_elapsed         | 13356      |
|    total_timesteps      | 8429568    |
| train/                  |            |
|    approx_kl            | 0.19978279 |
|    clip_fraction        | 0.4        |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.63       |
|    explained_variance   | 0.593      |
|    learning_rate        | 0.000357   |
|    loss                 | -0.0204    |
|    n_updates            | 41150      |
|    policy_gradient_loss | 0.00142    |
|    std                  | 0.0657     |
|    value_loss           | 0.00131    |
----------------------------------------
Eval num_timesteps=8430000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1         |
| time/                   |            |
|    total_timesteps      | 8430000    |
| train/                  |            |
|    approx_kl            | 0.31097108 |
|    clip_fraction        | 0.516      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.62       |
|    explained_variance   | 0.939      |
|    learning_rate        | 0.000356   |
|    loss                 | -0.0151    |
|    n_updates            | 41160      |
|    policy_gradient_loss | 0.0142     |
|    std                  | 0.0661     |
|    value_loss           | 0.00991    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 4117    |
|    time_elapsed    | 13360   |
|    total_timesteps | 8431616 |
--------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 4118      |
|    time_elapsed         | 13363     |
|    total_timesteps      | 8433664   |
| train/                  |           |
|    approx_kl            | 0.1446932 |
|    clip_fraction        | 0.373     |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.6       |
|    explained_variance   | 0.79      |
|    learning_rate        | 0.000356  |
|    loss                 | 0.0464    |
|    n_updates            | 41170     |
|    policy_gradient_loss | 0.000197  |
|    std                  | 0.0668    |
|    value_loss           | 0.0037    |
---------------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4119       |
|    time_elapsed         | 13366      |
|    total_timesteps      | 8435712    |
| train/                  |            |
|    approx_kl            | 0.16702878 |
|    clip_fraction        | 0.393      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.57       |
|    explained_variance   | 0.897      |
|    learning_rate        | 0.000355   |
|    loss                 | -0.00742   |
|    n_updates            | 41180      |
|    policy_gradient_loss | 0.00157    |
|    std                  | 0.0675     |
|    value_loss           | 0.0124     |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4120       |
|    time_elapsed         | 13369      |
|    total_timesteps      | 8437760    |
| train/                  |            |
|    approx_kl            | 0.31632242 |
|    clip_fraction        | 0.468      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.56       |
|    explained_variance   | 0.87       |
|    learning_rate        | 0.000355   |
|    loss                 | 0.0489     |
|    n_updates            | 41190      |
|    policy_gradient_loss | 0.0144     |
|    std                  | 0.068      |
|    value_loss           | 0.0292     |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4121       |
|    time_elapsed         | 13372      |
|    total_timesteps      | 8439808    |
| train/                  |            |
|    approx_kl            | 0.15904945 |
|    clip_fraction        | 0.432      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.54       |
|    explained_variance   | 0.939      |
|    learning_rate        | 0.000355   |
|    loss                 | 0.0309     |
|    n_updates            | 41200      |
|    policy_gradient_loss | 0.0136     |
|    std                  | 0.0686     |
|    value_loss           | 0.0127     |
----------------------------------------
Eval num_timesteps=8440000, episode_reward=-0.58 +/- 0.54
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -0.579     |
| time/                   |            |
|    total_timesteps      | 8440000    |
| train/                  |            |
|    approx_kl            | 0.34293237 |
|    clip_fraction        | 0.381      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.52       |
|    explained_variance   | 0.851      |
|    learning_rate        | 0.000354   |
|    loss                 | -0.0313    |
|    n_updates            | 41210      |
|    policy_gradient_loss | -0.00886   |
|    std                  | 0.0687     |
|    value_loss           | 0.00244    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 4122    |
|    time_elapsed    | 13376   |
|    total_timesteps | 8441856 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4123       |
|    time_elapsed         | 13379      |
|    total_timesteps      | 8443904    |
| train/                  |            |
|    approx_kl            | 0.11345524 |
|    clip_fraction        | 0.385      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.54       |
|    explained_variance   | 0.904      |
|    learning_rate        | 0.000354   |
|    loss                 | -0.0412    |
|    n_updates            | 41220      |
|    policy_gradient_loss | 0.00128    |
|    std                  | 0.0682     |
|    value_loss           | 0.0045     |
----------------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4124       |
|    time_elapsed         | 13382      |
|    total_timesteps      | 8445952    |
| train/                  |            |
|    approx_kl            | 0.29353544 |
|    clip_fraction        | 0.426      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.54       |
|    explained_variance   | 0.348      |
|    learning_rate        | 0.000353   |
|    loss                 | -0.00527   |
|    n_updates            | 41230      |
|    policy_gradient_loss | 0.00372    |
|    std                  | 0.0686     |
|    value_loss           | 0.00196    |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4125       |
|    time_elapsed         | 13385      |
|    total_timesteps      | 8448000    |
| train/                  |            |
|    approx_kl            | 0.10811504 |
|    clip_fraction        | 0.423      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.53       |
|    explained_variance   | 0.989      |
|    learning_rate        | 0.000353   |
|    loss                 | -0.0159    |
|    n_updates            | 41240      |
|    policy_gradient_loss | 0.016      |
|    std                  | 0.0684     |
|    value_loss           | 0.00654    |
----------------------------------------
Eval num_timesteps=8450000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 300       |
|    mean_reward          | -1        |
| time/                   |           |
|    total_timesteps      | 8450000   |
| train/                  |           |
|    approx_kl            | 0.7491286 |
|    clip_fraction        | 0.429     |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.55      |
|    explained_variance   | 0.983     |
|    learning_rate        | 0.000353  |
|    loss                 | -0.0175   |
|    n_updates            | 41250     |
|    policy_gradient_loss | 0.0173    |
|    std                  | 0.068     |
|    value_loss           | 0.00186   |
---------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 4126    |
|    time_elapsed    | 13389   |
|    total_timesteps | 8450048 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4127       |
|    time_elapsed         | 13392      |
|    total_timesteps      | 8452096    |
| train/                  |            |
|    approx_kl            | 0.14155637 |
|    clip_fraction        | 0.408      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.53       |
|    explained_variance   | 0.734      |
|    learning_rate        | 0.000352   |
|    loss                 | 0.0119     |
|    n_updates            | 41260      |
|    policy_gradient_loss | -0.0104    |
|    std                  | 0.0688     |
|    value_loss           | 0.00248    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4128       |
|    time_elapsed         | 13395      |
|    total_timesteps      | 8454144    |
| train/                  |            |
|    approx_kl            | 0.20792511 |
|    clip_fraction        | 0.376      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.53       |
|    explained_variance   | 0.72       |
|    learning_rate        | 0.000352   |
|    loss                 | -0.0312    |
|    n_updates            | 41270      |
|    policy_gradient_loss | 0.00804    |
|    std                  | 0.0684     |
|    value_loss           | 0.000616   |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4129       |
|    time_elapsed         | 13398      |
|    total_timesteps      | 8456192    |
| train/                  |            |
|    approx_kl            | 0.14750935 |
|    clip_fraction        | 0.359      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.54       |
|    explained_variance   | 0.676      |
|    learning_rate        | 0.000351   |
|    loss                 | 0.0112     |
|    n_updates            | 41280      |
|    policy_gradient_loss | 0.00351    |
|    std                  | 0.0684     |
|    value_loss           | 0.00282    |
----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 4130      |
|    time_elapsed         | 13401     |
|    total_timesteps      | 8458240   |
| train/                  |           |
|    approx_kl            | 0.4585202 |
|    clip_fraction        | 0.406     |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.54      |
|    explained_variance   | 0.979     |
|    learning_rate        | 0.000351  |
|    loss                 | -0.0136   |
|    n_updates            | 41290     |
|    policy_gradient_loss | 0.00808   |
|    std                  | 0.0678    |
|    value_loss           | 0.00271   |
---------------------------------------
box reached target
Eval num_timesteps=8460000, episode_reward=0.22 +/- 2.44
Episode length: 280.20 +/- 39.60
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 280         |
|    mean_reward          | 0.22        |
| time/                   |             |
|    total_timesteps      | 8460000     |
| train/                  |             |
|    approx_kl            | 0.106734626 |
|    clip_fraction        | 0.372       |
|    clip_range           | 0.2         |
|    entropy_loss         | 2.54        |
|    explained_variance   | 0.885       |
|    learning_rate        | 0.000351    |
|    loss                 | 0.131       |
|    n_updates            | 41300       |
|    policy_gradient_loss | 0.00978     |
|    std                  | 0.069       |
|    value_loss           | 0.00238     |
-----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 4131    |
|    time_elapsed    | 13405   |
|    total_timesteps | 8460288 |
--------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 4132      |
|    time_elapsed         | 13408     |
|    total_timesteps      | 8462336   |
| train/                  |           |
|    approx_kl            | 0.2161378 |
|    clip_fraction        | 0.358     |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.53      |
|    explained_variance   | 0.39      |
|    learning_rate        | 0.00035   |
|    loss                 | -0.0079   |
|    n_updates            | 41310     |
|    policy_gradient_loss | -0.00279  |
|    std                  | 0.0679    |
|    value_loss           | 0.00152   |
---------------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4133       |
|    time_elapsed         | 13411      |
|    total_timesteps      | 8464384    |
| train/                  |            |
|    approx_kl            | 0.14715037 |
|    clip_fraction        | 0.374      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.56       |
|    explained_variance   | 0.841      |
|    learning_rate        | 0.00035    |
|    loss                 | 0.025      |
|    n_updates            | 41320      |
|    policy_gradient_loss | 0.0161     |
|    std                  | 0.0674     |
|    value_loss           | 0.000645   |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4134       |
|    time_elapsed         | 13414      |
|    total_timesteps      | 8466432    |
| train/                  |            |
|    approx_kl            | 0.10648135 |
|    clip_fraction        | 0.376      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.55       |
|    explained_variance   | 0.971      |
|    learning_rate        | 0.000349   |
|    loss                 | 0.0293     |
|    n_updates            | 41330      |
|    policy_gradient_loss | 0.00863    |
|    std                  | 0.0682     |
|    value_loss           | 0.00606    |
----------------------------------------
box reached target
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 4135      |
|    time_elapsed         | 13417     |
|    total_timesteps      | 8468480   |
| train/                  |           |
|    approx_kl            | 0.2333695 |
|    clip_fraction        | 0.376     |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.54      |
|    explained_variance   | 0.34      |
|    learning_rate        | 0.000349  |
|    loss                 | -0.0323   |
|    n_updates            | 41340     |
|    policy_gradient_loss | -0.00619  |
|    std                  | 0.068     |
|    value_loss           | 0.000953  |
---------------------------------------
box reached target
Eval num_timesteps=8470000, episode_reward=-0.70 +/- 0.60
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -0.7       |
| time/                   |            |
|    total_timesteps      | 8470000    |
| train/                  |            |
|    approx_kl            | 0.36541566 |
|    clip_fraction        | 0.426      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.55       |
|    explained_variance   | 0.944      |
|    learning_rate        | 0.000349   |
|    loss                 | -0.00765   |
|    n_updates            | 41350      |
|    policy_gradient_loss | -0.000614  |
|    std                  | 0.0675     |
|    value_loss           | 0.0187     |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 4136    |
|    time_elapsed    | 13421   |
|    total_timesteps | 8470528 |
--------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4137       |
|    time_elapsed         | 13424      |
|    total_timesteps      | 8472576    |
| train/                  |            |
|    approx_kl            | 0.13615826 |
|    clip_fraction        | 0.402      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.54       |
|    explained_variance   | 0.932      |
|    learning_rate        | 0.000348   |
|    loss                 | -0.0411    |
|    n_updates            | 41360      |
|    policy_gradient_loss | 0.00797    |
|    std                  | 0.0684     |
|    value_loss           | 0.0123     |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4138       |
|    time_elapsed         | 13427      |
|    total_timesteps      | 8474624    |
| train/                  |            |
|    approx_kl            | 0.24989288 |
|    clip_fraction        | 0.427      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.53       |
|    explained_variance   | 0.958      |
|    learning_rate        | 0.000348   |
|    loss                 | -0.0201    |
|    n_updates            | 41370      |
|    policy_gradient_loss | 0.0134     |
|    std                  | 0.0685     |
|    value_loss           | 0.00539    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4139       |
|    time_elapsed         | 13430      |
|    total_timesteps      | 8476672    |
| train/                  |            |
|    approx_kl            | 0.06922286 |
|    clip_fraction        | 0.355      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.51       |
|    explained_variance   | 0.872      |
|    learning_rate        | 0.000347   |
|    loss                 | 0.0353     |
|    n_updates            | 41380      |
|    policy_gradient_loss | -0.0104    |
|    std                  | 0.0696     |
|    value_loss           | 0.00786    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4140       |
|    time_elapsed         | 13434      |
|    total_timesteps      | 8478720    |
| train/                  |            |
|    approx_kl            | 0.23467287 |
|    clip_fraction        | 0.343      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.51       |
|    explained_variance   | 0.659      |
|    learning_rate        | 0.000347   |
|    loss                 | -0.0392    |
|    n_updates            | 41390      |
|    policy_gradient_loss | -0.0155    |
|    std                  | 0.0687     |
|    value_loss           | 0.0016     |
----------------------------------------
Eval num_timesteps=8480000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1         |
| time/                   |            |
|    total_timesteps      | 8480000    |
| train/                  |            |
|    approx_kl            | 0.13999215 |
|    clip_fraction        | 0.365      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.53       |
|    explained_variance   | 0.159      |
|    learning_rate        | 0.000347   |
|    loss                 | 0.0221     |
|    n_updates            | 41400      |
|    policy_gradient_loss | 0.00571    |
|    std                  | 0.0681     |
|    value_loss           | 0.00119    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 4141    |
|    time_elapsed    | 13438   |
|    total_timesteps | 8480768 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4142       |
|    time_elapsed         | 13441      |
|    total_timesteps      | 8482816    |
| train/                  |            |
|    approx_kl            | 0.11784935 |
|    clip_fraction        | 0.41       |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.52       |
|    explained_variance   | 0.798      |
|    learning_rate        | 0.000346   |
|    loss                 | -0.0322    |
|    n_updates            | 41410      |
|    policy_gradient_loss | 0.016      |
|    std                  | 0.0697     |
|    value_loss           | 0.00284    |
----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 4143      |
|    time_elapsed         | 13444     |
|    total_timesteps      | 8484864   |
| train/                  |           |
|    approx_kl            | 0.1449168 |
|    clip_fraction        | 0.418     |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.49      |
|    explained_variance   | 0.854     |
|    learning_rate        | 0.000346  |
|    loss                 | 0.0202    |
|    n_updates            | 41420     |
|    policy_gradient_loss | 0.0157    |
|    std                  | 0.0701    |
|    value_loss           | 0.00648   |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4144       |
|    time_elapsed         | 13447      |
|    total_timesteps      | 8486912    |
| train/                  |            |
|    approx_kl            | 0.22805807 |
|    clip_fraction        | 0.356      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.48       |
|    explained_variance   | 0.92       |
|    learning_rate        | 0.000345   |
|    loss                 | 0.0288     |
|    n_updates            | 41430      |
|    policy_gradient_loss | 0.0041     |
|    std                  | 0.0697     |
|    value_loss           | 0.00117    |
----------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 4145      |
|    time_elapsed         | 13450     |
|    total_timesteps      | 8488960   |
| train/                  |           |
|    approx_kl            | 2.9593024 |
|    clip_fraction        | 0.435     |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.5       |
|    explained_variance   | 0.444     |
|    learning_rate        | 0.000345  |
|    loss                 | -0.0867   |
|    n_updates            | 41440     |
|    policy_gradient_loss | -0.0184   |
|    std                  | 0.0686    |
|    value_loss           | 0.000873  |
---------------------------------------
Eval num_timesteps=8490000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 300       |
|    mean_reward          | -1        |
| time/                   |           |
|    total_timesteps      | 8490000   |
| train/                  |           |
|    approx_kl            | 0.2068367 |
|    clip_fraction        | 0.406     |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.52      |
|    explained_variance   | 0.676     |
|    learning_rate        | 0.000345  |
|    loss                 | -0.0164   |
|    n_updates            | 41450     |
|    policy_gradient_loss | 0.0119    |
|    std                  | 0.0691    |
|    value_loss           | 0.0279    |
---------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 4146    |
|    time_elapsed    | 13454   |
|    total_timesteps | 8491008 |
--------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 4147      |
|    time_elapsed         | 13457     |
|    total_timesteps      | 8493056   |
| train/                  |           |
|    approx_kl            | 1.0842154 |
|    clip_fraction        | 0.431     |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.5       |
|    explained_variance   | 0.234     |
|    learning_rate        | 0.000344  |
|    loss                 | -0.00301  |
|    n_updates            | 41460     |
|    policy_gradient_loss | 0.0157    |
|    std                  | 0.069     |
|    value_loss           | 0.00137   |
---------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4148       |
|    time_elapsed         | 13460      |
|    total_timesteps      | 8495104    |
| train/                  |            |
|    approx_kl            | 0.33250484 |
|    clip_fraction        | 0.431      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.52       |
|    explained_variance   | 0.442      |
|    learning_rate        | 0.000344   |
|    loss                 | -0.0135    |
|    n_updates            | 41470      |
|    policy_gradient_loss | 0.0145     |
|    std                  | 0.0685     |
|    value_loss           | 0.00161    |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4149       |
|    time_elapsed         | 13463      |
|    total_timesteps      | 8497152    |
| train/                  |            |
|    approx_kl            | 0.23146039 |
|    clip_fraction        | 0.399      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.52       |
|    explained_variance   | 0.929      |
|    learning_rate        | 0.000343   |
|    loss                 | 0.0817     |
|    n_updates            | 41480      |
|    policy_gradient_loss | 0.00811    |
|    std                  | 0.0686     |
|    value_loss           | 0.0125     |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4150       |
|    time_elapsed         | 13466      |
|    total_timesteps      | 8499200    |
| train/                  |            |
|    approx_kl            | 0.15994154 |
|    clip_fraction        | 0.356      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.55       |
|    explained_variance   | 0.985      |
|    learning_rate        | 0.000343   |
|    loss                 | -0.0435    |
|    n_updates            | 41490      |
|    policy_gradient_loss | 0.00058    |
|    std                  | 0.0668     |
|    value_loss           | 0.00316    |
----------------------------------------
Eval num_timesteps=8500000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 300         |
|    mean_reward          | -1          |
| time/                   |             |
|    total_timesteps      | 8500000     |
| train/                  |             |
|    approx_kl            | 0.107836425 |
|    clip_fraction        | 0.45        |
|    clip_range           | 0.2         |
|    entropy_loss         | 2.56        |
|    explained_variance   | 0.763       |
|    learning_rate        | 0.000343    |
|    loss                 | 0.177       |
|    n_updates            | 41500       |
|    policy_gradient_loss | 0.0179      |
|    std                  | 0.0678      |
|    value_loss           | 0.0221      |
-----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 4151    |
|    time_elapsed    | 13470   |
|    total_timesteps | 8501248 |
--------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 4152      |
|    time_elapsed         | 13473     |
|    total_timesteps      | 8503296   |
| train/                  |           |
|    approx_kl            | 0.2676294 |
|    clip_fraction        | 0.405     |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.55      |
|    explained_variance   | -0.509    |
|    learning_rate        | 0.000342  |
|    loss                 | 0.0314    |
|    n_updates            | 41510     |
|    policy_gradient_loss | -0.00394  |
|    std                  | 0.0677    |
|    value_loss           | 0.00325   |
---------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4153       |
|    time_elapsed         | 13476      |
|    total_timesteps      | 8505344    |
| train/                  |            |
|    approx_kl            | 0.16429691 |
|    clip_fraction        | 0.42       |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.55       |
|    explained_variance   | 0.751      |
|    learning_rate        | 0.000342   |
|    loss                 | 0.0107     |
|    n_updates            | 41520      |
|    policy_gradient_loss | 0.015      |
|    std                  | 0.0679     |
|    value_loss           | 0.00141    |
----------------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4154       |
|    time_elapsed         | 13479      |
|    total_timesteps      | 8507392    |
| train/                  |            |
|    approx_kl            | 0.24809328 |
|    clip_fraction        | 0.426      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.55       |
|    explained_variance   | 0.952      |
|    learning_rate        | 0.000341   |
|    loss                 | -0.00864   |
|    n_updates            | 41530      |
|    policy_gradient_loss | 0.00995    |
|    std                  | 0.0672     |
|    value_loss           | 0.0119     |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4155       |
|    time_elapsed         | 13482      |
|    total_timesteps      | 8509440    |
| train/                  |            |
|    approx_kl            | 0.21324301 |
|    clip_fraction        | 0.374      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.56       |
|    explained_variance   | 0.928      |
|    learning_rate        | 0.000341   |
|    loss                 | -0.0409    |
|    n_updates            | 41540      |
|    policy_gradient_loss | 0.0102     |
|    std                  | 0.0669     |
|    value_loss           | 0.0195     |
----------------------------------------
box reached target
Eval num_timesteps=8510000, episode_reward=0.52 +/- 2.36
Episode length: 276.40 +/- 47.20
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 276        |
|    mean_reward          | 0.52       |
| time/                   |            |
|    total_timesteps      | 8510000    |
| train/                  |            |
|    approx_kl            | 0.22256821 |
|    clip_fraction        | 0.401      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.58       |
|    explained_variance   | 0.972      |
|    learning_rate        | 0.000341   |
|    loss                 | -0.0463    |
|    n_updates            | 41550      |
|    policy_gradient_loss | -0.00284   |
|    std                  | 0.0665     |
|    value_loss           | 0.0101     |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 4156    |
|    time_elapsed    | 13486   |
|    total_timesteps | 8511488 |
--------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 4157      |
|    time_elapsed         | 13489     |
|    total_timesteps      | 8513536   |
| train/                  |           |
|    approx_kl            | 0.3550142 |
|    clip_fraction        | 0.387     |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.57      |
|    explained_variance   | 0.616     |
|    learning_rate        | 0.00034   |
|    loss                 | 0.026     |
|    n_updates            | 41560     |
|    policy_gradient_loss | 0.0138    |
|    std                  | 0.0668    |
|    value_loss           | 0.00623   |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4158       |
|    time_elapsed         | 13492      |
|    total_timesteps      | 8515584    |
| train/                  |            |
|    approx_kl            | 0.22660032 |
|    clip_fraction        | 0.39       |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.58       |
|    explained_variance   | 0.958      |
|    learning_rate        | 0.00034    |
|    loss                 | 0.0288     |
|    n_updates            | 41570      |
|    policy_gradient_loss | -0.000146  |
|    std                  | 0.0661     |
|    value_loss           | 0.00852    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4159       |
|    time_elapsed         | 13495      |
|    total_timesteps      | 8517632    |
| train/                  |            |
|    approx_kl            | 0.29099452 |
|    clip_fraction        | 0.368      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.59       |
|    explained_variance   | 0.579      |
|    learning_rate        | 0.000339   |
|    loss                 | 0.0262     |
|    n_updates            | 41580      |
|    policy_gradient_loss | 0.00755    |
|    std                  | 0.0664     |
|    value_loss           | 0.00145    |
----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 4160      |
|    time_elapsed         | 13498     |
|    total_timesteps      | 8519680   |
| train/                  |           |
|    approx_kl            | 0.8769028 |
|    clip_fraction        | 0.431     |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.59      |
|    explained_variance   | 0.44      |
|    learning_rate        | 0.000339  |
|    loss                 | -0.0308   |
|    n_updates            | 41590     |
|    policy_gradient_loss | 0.0206    |
|    std                  | 0.0662    |
|    value_loss           | 0.00183   |
---------------------------------------
Eval num_timesteps=8520000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1         |
| time/                   |            |
|    total_timesteps      | 8520000    |
| train/                  |            |
|    approx_kl            | 0.13483801 |
|    clip_fraction        | 0.4        |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.59       |
|    explained_variance   | 0.47       |
|    learning_rate        | 0.000339   |
|    loss                 | 0.0145     |
|    n_updates            | 41600      |
|    policy_gradient_loss | 0.00731    |
|    std                  | 0.0663     |
|    value_loss           | 0.00141    |
----------------------------------------
box reached target
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 4161    |
|    time_elapsed    | 13502   |
|    total_timesteps | 8521728 |
--------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4162       |
|    time_elapsed         | 13505      |
|    total_timesteps      | 8523776    |
| train/                  |            |
|    approx_kl            | 0.18930379 |
|    clip_fraction        | 0.426      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.61       |
|    explained_variance   | 0.922      |
|    learning_rate        | 0.000338   |
|    loss                 | -0.00614   |
|    n_updates            | 41610      |
|    policy_gradient_loss | 0.0108     |
|    std                  | 0.0655     |
|    value_loss           | 0.00615    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4163       |
|    time_elapsed         | 13508      |
|    total_timesteps      | 8525824    |
| train/                  |            |
|    approx_kl            | 0.22882885 |
|    clip_fraction        | 0.445      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.62       |
|    explained_variance   | 0.759      |
|    learning_rate        | 0.000338   |
|    loss                 | 0.028      |
|    n_updates            | 41620      |
|    policy_gradient_loss | 0.0063     |
|    std                  | 0.0657     |
|    value_loss           | 0.0114     |
----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 4164      |
|    time_elapsed         | 13511     |
|    total_timesteps      | 8527872   |
| train/                  |           |
|    approx_kl            | 1.2712032 |
|    clip_fraction        | 0.475     |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.6       |
|    explained_variance   | 0.213     |
|    learning_rate        | 0.000337  |
|    loss                 | 0.0485    |
|    n_updates            | 41630     |
|    policy_gradient_loss | 0.00759   |
|    std                  | 0.0658    |
|    value_loss           | 0.00258   |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4165       |
|    time_elapsed         | 13514      |
|    total_timesteps      | 8529920    |
| train/                  |            |
|    approx_kl            | 0.27534318 |
|    clip_fraction        | 0.382      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.61       |
|    explained_variance   | 0.876      |
|    learning_rate        | 0.000337   |
|    loss                 | 0.0217     |
|    n_updates            | 41640      |
|    policy_gradient_loss | 0.000761   |
|    std                  | 0.0658     |
|    value_loss           | 0.00158    |
----------------------------------------
Eval num_timesteps=8530000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1         |
| time/                   |            |
|    total_timesteps      | 8530000    |
| train/                  |            |
|    approx_kl            | 0.20281228 |
|    clip_fraction        | 0.381      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.6        |
|    explained_variance   | 0.606      |
|    learning_rate        | 0.000337   |
|    loss                 | -0.0021    |
|    n_updates            | 41650      |
|    policy_gradient_loss | -0.003     |
|    std                  | 0.0658     |
|    value_loss           | 0.00115    |
----------------------------------------
box reached target
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 4166    |
|    time_elapsed    | 13518   |
|    total_timesteps | 8531968 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4167       |
|    time_elapsed         | 13522      |
|    total_timesteps      | 8534016    |
| train/                  |            |
|    approx_kl            | 0.13372163 |
|    clip_fraction        | 0.394      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.63       |
|    explained_variance   | 0.504      |
|    learning_rate        | 0.000336   |
|    loss                 | -0.018     |
|    n_updates            | 41660      |
|    policy_gradient_loss | 0.00682    |
|    std                  | 0.0646     |
|    value_loss           | 0.124      |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4168       |
|    time_elapsed         | 13525      |
|    total_timesteps      | 8536064    |
| train/                  |            |
|    approx_kl            | 0.13742483 |
|    clip_fraction        | 0.393      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.64       |
|    explained_variance   | 0.729      |
|    learning_rate        | 0.000336   |
|    loss                 | -0.0148    |
|    n_updates            | 41670      |
|    policy_gradient_loss | 0.0155     |
|    std                  | 0.0647     |
|    value_loss           | 0.00146    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4169       |
|    time_elapsed         | 13528      |
|    total_timesteps      | 8538112    |
| train/                  |            |
|    approx_kl            | 0.14386718 |
|    clip_fraction        | 0.34       |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.64       |
|    explained_variance   | 0.337      |
|    learning_rate        | 0.000335   |
|    loss                 | -0.000988  |
|    n_updates            | 41680      |
|    policy_gradient_loss | -0.00777   |
|    std                  | 0.0645     |
|    value_loss           | 0.00128    |
----------------------------------------
Eval num_timesteps=8540000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1         |
| time/                   |            |
|    total_timesteps      | 8540000    |
| train/                  |            |
|    approx_kl            | 0.10272512 |
|    clip_fraction        | 0.325      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.65       |
|    explained_variance   | 0.527      |
|    learning_rate        | 0.000335   |
|    loss                 | -0.0188    |
|    n_updates            | 41690      |
|    policy_gradient_loss | 0.00239    |
|    std                  | 0.0641     |
|    value_loss           | 0.001      |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 4170    |
|    time_elapsed    | 13532   |
|    total_timesteps | 8540160 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4171       |
|    time_elapsed         | 13535      |
|    total_timesteps      | 8542208    |
| train/                  |            |
|    approx_kl            | 0.26236045 |
|    clip_fraction        | 0.358      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.67       |
|    explained_variance   | 0.546      |
|    learning_rate        | 0.000335   |
|    loss                 | -0.00155   |
|    n_updates            | 41700      |
|    policy_gradient_loss | 0.00386    |
|    std                  | 0.0634     |
|    value_loss           | 0.000926   |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4172       |
|    time_elapsed         | 13538      |
|    total_timesteps      | 8544256    |
| train/                  |            |
|    approx_kl            | 0.15216413 |
|    clip_fraction        | 0.353      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.69       |
|    explained_variance   | 0.574      |
|    learning_rate        | 0.000334   |
|    loss                 | 0.0249     |
|    n_updates            | 41710      |
|    policy_gradient_loss | 0.00406    |
|    std                  | 0.0626     |
|    value_loss           | 0.000962   |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4173       |
|    time_elapsed         | 13541      |
|    total_timesteps      | 8546304    |
| train/                  |            |
|    approx_kl            | 0.19053026 |
|    clip_fraction        | 0.399      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.7        |
|    explained_variance   | 0.678      |
|    learning_rate        | 0.000334   |
|    loss                 | -0.00728   |
|    n_updates            | 41720      |
|    policy_gradient_loss | 0.0153     |
|    std                  | 0.0631     |
|    value_loss           | 0.00116    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4174       |
|    time_elapsed         | 13544      |
|    total_timesteps      | 8548352    |
| train/                  |            |
|    approx_kl            | 0.13125128 |
|    clip_fraction        | 0.386      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.71       |
|    explained_variance   | -2.35      |
|    learning_rate        | 0.000333   |
|    loss                 | 0.00587    |
|    n_updates            | 41730      |
|    policy_gradient_loss | 0.0057     |
|    std                  | 0.0622     |
|    value_loss           | 0.00498    |
----------------------------------------
box reached target
box reached target
box reached target
box reached target
Eval num_timesteps=8550000, episode_reward=0.49 +/- 2.36
Episode length: 274.20 +/- 51.60
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 274        |
|    mean_reward          | 0.486      |
| time/                   |            |
|    total_timesteps      | 8550000    |
| train/                  |            |
|    approx_kl            | 0.12809327 |
|    clip_fraction        | 0.37       |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.71       |
|    explained_variance   | 0.648      |
|    learning_rate        | 0.000333   |
|    loss                 | 0.0171     |
|    n_updates            | 41740      |
|    policy_gradient_loss | 0.02       |
|    std                  | 0.0628     |
|    value_loss           | 0.000701   |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 4175    |
|    time_elapsed    | 13548   |
|    total_timesteps | 8550400 |
--------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 4176      |
|    time_elapsed         | 13551     |
|    total_timesteps      | 8552448   |
| train/                  |           |
|    approx_kl            | 0.3316674 |
|    clip_fraction        | 0.435     |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.71      |
|    explained_variance   | 0.847     |
|    learning_rate        | 0.000333  |
|    loss                 | -0.0249   |
|    n_updates            | 41750     |
|    policy_gradient_loss | 0.0164    |
|    std                  | 0.0619    |
|    value_loss           | 0.129     |
---------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4177       |
|    time_elapsed         | 13554      |
|    total_timesteps      | 8554496    |
| train/                  |            |
|    approx_kl            | 0.12652749 |
|    clip_fraction        | 0.395      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.72       |
|    explained_variance   | 0.978      |
|    learning_rate        | 0.000332   |
|    loss                 | -0.00864   |
|    n_updates            | 41760      |
|    policy_gradient_loss | 0.012      |
|    std                  | 0.0625     |
|    value_loss           | 0.00199    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4178       |
|    time_elapsed         | 13557      |
|    total_timesteps      | 8556544    |
| train/                  |            |
|    approx_kl            | 0.31951606 |
|    clip_fraction        | 0.454      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.7        |
|    explained_variance   | 0.98       |
|    learning_rate        | 0.000332   |
|    loss                 | 0.0117     |
|    n_updates            | 41770      |
|    policy_gradient_loss | 0.00786    |
|    std                  | 0.0632     |
|    value_loss           | 0.00402    |
----------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 4179      |
|    time_elapsed         | 13560     |
|    total_timesteps      | 8558592   |
| train/                  |           |
|    approx_kl            | 0.1894551 |
|    clip_fraction        | 0.457     |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.69      |
|    explained_variance   | 0.602     |
|    learning_rate        | 0.000331  |
|    loss                 | -0.0307   |
|    n_updates            | 41780     |
|    policy_gradient_loss | 0.0126    |
|    std                  | 0.0631    |
|    value_loss           | 0.00178   |
---------------------------------------
Eval num_timesteps=8560000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 300       |
|    mean_reward          | -1        |
| time/                   |           |
|    total_timesteps      | 8560000   |
| train/                  |           |
|    approx_kl            | 0.1355783 |
|    clip_fraction        | 0.428     |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.7       |
|    explained_variance   | 0.954     |
|    learning_rate        | 0.000331  |
|    loss                 | 0.0106    |
|    n_updates            | 41790     |
|    policy_gradient_loss | 0.0119    |
|    std                  | 0.0624    |
|    value_loss           | 0.00984   |
---------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 4180    |
|    time_elapsed    | 13564   |
|    total_timesteps | 8560640 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4181       |
|    time_elapsed         | 13567      |
|    total_timesteps      | 8562688    |
| train/                  |            |
|    approx_kl            | 0.09035361 |
|    clip_fraction        | 0.449      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.68       |
|    explained_variance   | 0.686      |
|    learning_rate        | 0.000331   |
|    loss                 | -0.0131    |
|    n_updates            | 41800      |
|    policy_gradient_loss | 0.0204     |
|    std                  | 0.064      |
|    value_loss           | 0.00702    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4182       |
|    time_elapsed         | 13570      |
|    total_timesteps      | 8564736    |
| train/                  |            |
|    approx_kl            | 0.19708325 |
|    clip_fraction        | 0.417      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.67       |
|    explained_variance   | 0.711      |
|    learning_rate        | 0.00033    |
|    loss                 | -0.00761   |
|    n_updates            | 41810      |
|    policy_gradient_loss | 0.0035     |
|    std                  | 0.0635     |
|    value_loss           | 0.00262    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4183       |
|    time_elapsed         | 13573      |
|    total_timesteps      | 8566784    |
| train/                  |            |
|    approx_kl            | 0.26397192 |
|    clip_fraction        | 0.373      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.68       |
|    explained_variance   | 0.606      |
|    learning_rate        | 0.00033    |
|    loss                 | 0.0288     |
|    n_updates            | 41820      |
|    policy_gradient_loss | 0.00887    |
|    std                  | 0.0636     |
|    value_loss           | 0.00203    |
----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 4184      |
|    time_elapsed         | 13576     |
|    total_timesteps      | 8568832   |
| train/                  |           |
|    approx_kl            | 1.1240219 |
|    clip_fraction        | 0.434     |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.68      |
|    explained_variance   | 0.719     |
|    learning_rate        | 0.000329  |
|    loss                 | -0.035    |
|    n_updates            | 41830     |
|    policy_gradient_loss | -0.0181   |
|    std                  | 0.0632    |
|    value_loss           | 0.00233   |
---------------------------------------
box reached target
Eval num_timesteps=8570000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1         |
| time/                   |            |
|    total_timesteps      | 8570000    |
| train/                  |            |
|    approx_kl            | 0.92162645 |
|    clip_fraction        | 0.423      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.68       |
|    explained_variance   | 0.407      |
|    learning_rate        | 0.000329   |
|    loss                 | -6.9e-05   |
|    n_updates            | 41840      |
|    policy_gradient_loss | 0.025      |
|    std                  | 0.0629     |
|    value_loss           | 0.00125    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 4185    |
|    time_elapsed    | 13580   |
|    total_timesteps | 8570880 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4186       |
|    time_elapsed         | 13583      |
|    total_timesteps      | 8572928    |
| train/                  |            |
|    approx_kl            | 0.22154033 |
|    clip_fraction        | 0.448      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.7        |
|    explained_variance   | 0.113      |
|    learning_rate        | 0.000329   |
|    loss                 | 0.0155     |
|    n_updates            | 41850      |
|    policy_gradient_loss | 0.0101     |
|    std                  | 0.0626     |
|    value_loss           | 0.117      |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4187       |
|    time_elapsed         | 13586      |
|    total_timesteps      | 8574976    |
| train/                  |            |
|    approx_kl            | 0.19547194 |
|    clip_fraction        | 0.352      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.72       |
|    explained_variance   | 0.564      |
|    learning_rate        | 0.000328   |
|    loss                 | 0.0357     |
|    n_updates            | 41860      |
|    policy_gradient_loss | 0.0029     |
|    std                  | 0.0617     |
|    value_loss           | 0.00129    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4188       |
|    time_elapsed         | 13590      |
|    total_timesteps      | 8577024    |
| train/                  |            |
|    approx_kl            | 0.21243869 |
|    clip_fraction        | 0.405      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.74       |
|    explained_variance   | 0.966      |
|    learning_rate        | 0.000328   |
|    loss                 | 0.0257     |
|    n_updates            | 41870      |
|    policy_gradient_loss | 0.0173     |
|    std                  | 0.0614     |
|    value_loss           | 0.00238    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4189       |
|    time_elapsed         | 13593      |
|    total_timesteps      | 8579072    |
| train/                  |            |
|    approx_kl            | 0.09516623 |
|    clip_fraction        | 0.31       |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.74       |
|    explained_variance   | 0.598      |
|    learning_rate        | 0.000327   |
|    loss                 | 0.0352     |
|    n_updates            | 41880      |
|    policy_gradient_loss | 0.0086     |
|    std                  | 0.0613     |
|    value_loss           | 0.000627   |
----------------------------------------
Eval num_timesteps=8580000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1         |
| time/                   |            |
|    total_timesteps      | 8580000    |
| train/                  |            |
|    approx_kl            | 0.11142464 |
|    clip_fraction        | 0.347      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.75       |
|    explained_variance   | 0.574      |
|    learning_rate        | 0.000327   |
|    loss                 | 0.0204     |
|    n_updates            | 41890      |
|    policy_gradient_loss | 0.00473    |
|    std                  | 0.0609     |
|    value_loss           | 0.00112    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 4190    |
|    time_elapsed    | 13597   |
|    total_timesteps | 8581120 |
--------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4191       |
|    time_elapsed         | 13600      |
|    total_timesteps      | 8583168    |
| train/                  |            |
|    approx_kl            | 0.10247411 |
|    clip_fraction        | 0.395      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.76       |
|    explained_variance   | 0.684      |
|    learning_rate        | 0.000327   |
|    loss                 | -0.0118    |
|    n_updates            | 41900      |
|    policy_gradient_loss | 0.0239     |
|    std                  | 0.0607     |
|    value_loss           | 0.000896   |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4192       |
|    time_elapsed         | 13603      |
|    total_timesteps      | 8585216    |
| train/                  |            |
|    approx_kl            | 0.17459802 |
|    clip_fraction        | 0.427      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.77       |
|    explained_variance   | 0.95       |
|    learning_rate        | 0.000326   |
|    loss                 | 0.0272     |
|    n_updates            | 41910      |
|    policy_gradient_loss | 0.0171     |
|    std                  | 0.0603     |
|    value_loss           | 0.00647    |
----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 4193      |
|    time_elapsed         | 13606     |
|    total_timesteps      | 8587264   |
| train/                  |           |
|    approx_kl            | 0.3547481 |
|    clip_fraction        | 0.412     |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.78      |
|    explained_variance   | 0.478     |
|    learning_rate        | 0.000326  |
|    loss                 | -0.0287   |
|    n_updates            | 41920     |
|    policy_gradient_loss | 0.00645   |
|    std                  | 0.0601    |
|    value_loss           | 0.00113   |
---------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 4194      |
|    time_elapsed         | 13609     |
|    total_timesteps      | 8589312   |
| train/                  |           |
|    approx_kl            | 0.0940312 |
|    clip_fraction        | 0.371     |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.78      |
|    explained_variance   | 0.449     |
|    learning_rate        | 0.000325  |
|    loss                 | 0.00503   |
|    n_updates            | 41930     |
|    policy_gradient_loss | 0.0125    |
|    std                  | 0.0602    |
|    value_loss           | 0.000913  |
---------------------------------------
Eval num_timesteps=8590000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1         |
| time/                   |            |
|    total_timesteps      | 8590000    |
| train/                  |            |
|    approx_kl            | 0.14902762 |
|    clip_fraction        | 0.36       |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.78       |
|    explained_variance   | 0.623      |
|    learning_rate        | 0.000325   |
|    loss                 | 0.0267     |
|    n_updates            | 41940      |
|    policy_gradient_loss | 0.00448    |
|    std                  | 0.0602     |
|    value_loss           | 0.000925   |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 4195    |
|    time_elapsed    | 13613   |
|    total_timesteps | 8591360 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4196       |
|    time_elapsed         | 13616      |
|    total_timesteps      | 8593408    |
| train/                  |            |
|    approx_kl            | 0.23437485 |
|    clip_fraction        | 0.381      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.78       |
|    explained_variance   | 0.839      |
|    learning_rate        | 0.000325   |
|    loss                 | -0.0362    |
|    n_updates            | 41950      |
|    policy_gradient_loss | -0.00293   |
|    std                  | 0.0603     |
|    value_loss           | 0.00246    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4197       |
|    time_elapsed         | 13619      |
|    total_timesteps      | 8595456    |
| train/                  |            |
|    approx_kl            | 0.16397893 |
|    clip_fraction        | 0.442      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.78       |
|    explained_variance   | 0.556      |
|    learning_rate        | 0.000324   |
|    loss                 | -0.0247    |
|    n_updates            | 41960      |
|    policy_gradient_loss | 0.00808    |
|    std                  | 0.0601     |
|    value_loss           | 0.0013     |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4198       |
|    time_elapsed         | 13622      |
|    total_timesteps      | 8597504    |
| train/                  |            |
|    approx_kl            | 0.09860765 |
|    clip_fraction        | 0.366      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.8        |
|    explained_variance   | 0.652      |
|    learning_rate        | 0.000324   |
|    loss                 | -0.0266    |
|    n_updates            | 41970      |
|    policy_gradient_loss | 0.00339    |
|    std                  | 0.0593     |
|    value_loss           | 0.0013     |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4199       |
|    time_elapsed         | 13625      |
|    total_timesteps      | 8599552    |
| train/                  |            |
|    approx_kl            | 0.22758955 |
|    clip_fraction        | 0.34       |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.81       |
|    explained_variance   | 0.698      |
|    learning_rate        | 0.000323   |
|    loss                 | 0.0653     |
|    n_updates            | 41980      |
|    policy_gradient_loss | 0.00394    |
|    std                  | 0.0595     |
|    value_loss           | 0.000887   |
----------------------------------------
Eval num_timesteps=8600000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 300         |
|    mean_reward          | -1          |
| time/                   |             |
|    total_timesteps      | 8600000     |
| train/                  |             |
|    approx_kl            | 0.105184205 |
|    clip_fraction        | 0.449       |
|    clip_range           | 0.2         |
|    entropy_loss         | 2.81        |
|    explained_variance   | 0.842       |
|    learning_rate        | 0.000323    |
|    loss                 | -0.0191     |
|    n_updates            | 41990       |
|    policy_gradient_loss | 0.0187      |
|    std                  | 0.0596      |
|    value_loss           | 0.0115      |
-----------------------------------------
box reached target
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 4200    |
|    time_elapsed    | 13629   |
|    total_timesteps | 8601600 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4201       |
|    time_elapsed         | 13632      |
|    total_timesteps      | 8603648    |
| train/                  |            |
|    approx_kl            | 0.23784077 |
|    clip_fraction        | 0.446      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.8        |
|    explained_variance   | 0.357      |
|    learning_rate        | 0.000323   |
|    loss                 | 0.0205     |
|    n_updates            | 42000      |
|    policy_gradient_loss | 0.00992    |
|    std                  | 0.0597     |
|    value_loss           | 0.119      |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4202       |
|    time_elapsed         | 13635      |
|    total_timesteps      | 8605696    |
| train/                  |            |
|    approx_kl            | 0.27806893 |
|    clip_fraction        | 0.486      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.8        |
|    explained_variance   | 0.487      |
|    learning_rate        | 0.000322   |
|    loss                 | 0.00199    |
|    n_updates            | 42010      |
|    policy_gradient_loss | 0.0465     |
|    std                  | 0.0597     |
|    value_loss           | 0.00165    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4203       |
|    time_elapsed         | 13638      |
|    total_timesteps      | 8607744    |
| train/                  |            |
|    approx_kl            | 0.21108557 |
|    clip_fraction        | 0.411      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.82       |
|    explained_variance   | 0.978      |
|    learning_rate        | 0.000322   |
|    loss                 | -0.0284    |
|    n_updates            | 42020      |
|    policy_gradient_loss | 0.011      |
|    std                  | 0.0591     |
|    value_loss           | 0.00453    |
----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 4204      |
|    time_elapsed         | 13641     |
|    total_timesteps      | 8609792   |
| train/                  |           |
|    approx_kl            | 1.6366459 |
|    clip_fraction        | 0.432     |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.82      |
|    explained_variance   | 0.645     |
|    learning_rate        | 0.000321  |
|    loss                 | -0.036    |
|    n_updates            | 42030     |
|    policy_gradient_loss | 0.0312    |
|    std                  | 0.0593    |
|    value_loss           | 0.00136   |
---------------------------------------
Eval num_timesteps=8610000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1         |
| time/                   |            |
|    total_timesteps      | 8610000    |
| train/                  |            |
|    approx_kl            | 0.18645419 |
|    clip_fraction        | 0.373      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.82       |
|    explained_variance   | 0.513      |
|    learning_rate        | 0.000321   |
|    loss                 | 0.0308     |
|    n_updates            | 42040      |
|    policy_gradient_loss | -0.00092   |
|    std                  | 0.0592     |
|    value_loss           | 0.00139    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 4205    |
|    time_elapsed    | 13645   |
|    total_timesteps | 8611840 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4206       |
|    time_elapsed         | 13648      |
|    total_timesteps      | 8613888    |
| train/                  |            |
|    approx_kl            | 0.08147326 |
|    clip_fraction        | 0.321      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.82       |
|    explained_variance   | 0.419      |
|    learning_rate        | 0.000321   |
|    loss                 | 0.0249     |
|    n_updates            | 42050      |
|    policy_gradient_loss | 0.00237    |
|    std                  | 0.059      |
|    value_loss           | 0.0011     |
----------------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 631         |
|    iterations           | 4207        |
|    time_elapsed         | 13651       |
|    total_timesteps      | 8615936     |
| train/                  |             |
|    approx_kl            | 0.054925293 |
|    clip_fraction        | 0.324       |
|    clip_range           | 0.2         |
|    entropy_loss         | 2.83        |
|    explained_variance   | 0.657       |
|    learning_rate        | 0.00032     |
|    loss                 | 0.0479      |
|    n_updates            | 42060       |
|    policy_gradient_loss | 0.0102      |
|    std                  | 0.059       |
|    value_loss           | 0.000869    |
-----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4208       |
|    time_elapsed         | 13654      |
|    total_timesteps      | 8617984    |
| train/                  |            |
|    approx_kl            | 0.12569997 |
|    clip_fraction        | 0.454      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.81       |
|    explained_variance   | 0.855      |
|    learning_rate        | 0.00032    |
|    loss                 | 0.0211     |
|    n_updates            | 42070      |
|    policy_gradient_loss | 0.02       |
|    std                  | 0.0599     |
|    value_loss           | 0.018      |
----------------------------------------
Eval num_timesteps=8620000, episode_reward=-0.90 +/- 0.20
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -0.898     |
| time/                   |            |
|    total_timesteps      | 8620000    |
| train/                  |            |
|    approx_kl            | 0.21893474 |
|    clip_fraction        | 0.405      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.82       |
|    explained_variance   | 0.487      |
|    learning_rate        | 0.000319   |
|    loss                 | 0.0539     |
|    n_updates            | 42080      |
|    policy_gradient_loss | 0.00187    |
|    std                  | 0.0589     |
|    value_loss           | 0.123      |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 4209    |
|    time_elapsed    | 13658   |
|    total_timesteps | 8620032 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4210       |
|    time_elapsed         | 13661      |
|    total_timesteps      | 8622080    |
| train/                  |            |
|    approx_kl            | 0.12884198 |
|    clip_fraction        | 0.425      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.82       |
|    explained_variance   | 0.436      |
|    learning_rate        | 0.000319   |
|    loss                 | 0.0477     |
|    n_updates            | 42090      |
|    policy_gradient_loss | 0.0101     |
|    std                  | 0.0591     |
|    value_loss           | 0.00197    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4211       |
|    time_elapsed         | 13665      |
|    total_timesteps      | 8624128    |
| train/                  |            |
|    approx_kl            | 0.21453089 |
|    clip_fraction        | 0.414      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.81       |
|    explained_variance   | 0.535      |
|    learning_rate        | 0.000319   |
|    loss                 | 0.049      |
|    n_updates            | 42100      |
|    policy_gradient_loss | 0.0202     |
|    std                  | 0.0599     |
|    value_loss           | 0.00172    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4212       |
|    time_elapsed         | 13668      |
|    total_timesteps      | 8626176    |
| train/                  |            |
|    approx_kl            | 0.17088345 |
|    clip_fraction        | 0.406      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.8        |
|    explained_variance   | 0.676      |
|    learning_rate        | 0.000318   |
|    loss                 | 0.0149     |
|    n_updates            | 42110      |
|    policy_gradient_loss | 0.0111     |
|    std                  | 0.0596     |
|    value_loss           | 0.0013     |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4213       |
|    time_elapsed         | 13671      |
|    total_timesteps      | 8628224    |
| train/                  |            |
|    approx_kl            | 0.15094236 |
|    clip_fraction        | 0.403      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.8        |
|    explained_variance   | 0.577      |
|    learning_rate        | 0.000318   |
|    loss                 | -0.0274    |
|    n_updates            | 42120      |
|    policy_gradient_loss | 0.0202     |
|    std                  | 0.0596     |
|    value_loss           | 0.00119    |
----------------------------------------
box reached target
Eval num_timesteps=8630000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1         |
| time/                   |            |
|    total_timesteps      | 8630000    |
| train/                  |            |
|    approx_kl            | 0.21549226 |
|    clip_fraction        | 0.402      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.81       |
|    explained_variance   | 0.972      |
|    learning_rate        | 0.000317   |
|    loss                 | -0.00294   |
|    n_updates            | 42130      |
|    policy_gradient_loss | 0.0199     |
|    std                  | 0.0596     |
|    value_loss           | 0.00326    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 4214    |
|    time_elapsed    | 13675   |
|    total_timesteps | 8630272 |
--------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4215       |
|    time_elapsed         | 13678      |
|    total_timesteps      | 8632320    |
| train/                  |            |
|    approx_kl            | 0.12281334 |
|    clip_fraction        | 0.339      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.8        |
|    explained_variance   | 0.985      |
|    learning_rate        | 0.000317   |
|    loss                 | -0.0266    |
|    n_updates            | 42140      |
|    policy_gradient_loss | 0.0171     |
|    std                  | 0.0598     |
|    value_loss           | 0.00175    |
----------------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 631         |
|    iterations           | 4216        |
|    time_elapsed         | 13681       |
|    total_timesteps      | 8634368     |
| train/                  |             |
|    approx_kl            | 0.116723225 |
|    clip_fraction        | 0.378       |
|    clip_range           | 0.2         |
|    entropy_loss         | 2.81        |
|    explained_variance   | 0.873       |
|    learning_rate        | 0.000317    |
|    loss                 | -0.0201     |
|    n_updates            | 42150       |
|    policy_gradient_loss | 0.00383     |
|    std                  | 0.059       |
|    value_loss           | 0.00795     |
-----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4217       |
|    time_elapsed         | 13684      |
|    total_timesteps      | 8636416    |
| train/                  |            |
|    approx_kl            | 0.12484868 |
|    clip_fraction        | 0.426      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.84       |
|    explained_variance   | 0.58       |
|    learning_rate        | 0.000316   |
|    loss                 | 0.00407    |
|    n_updates            | 42160      |
|    policy_gradient_loss | 0.0113     |
|    std                  | 0.0586     |
|    value_loss           | 0.0235     |
----------------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 631         |
|    iterations           | 4218        |
|    time_elapsed         | 13687       |
|    total_timesteps      | 8638464     |
| train/                  |             |
|    approx_kl            | 0.079829685 |
|    clip_fraction        | 0.321       |
|    clip_range           | 0.2         |
|    entropy_loss         | 2.86        |
|    explained_variance   | 0.978       |
|    learning_rate        | 0.000316    |
|    loss                 | -0.0103     |
|    n_updates            | 42170       |
|    policy_gradient_loss | 0.0114      |
|    std                  | 0.0576      |
|    value_loss           | 0.00368     |
-----------------------------------------
box reached target
Eval num_timesteps=8640000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1         |
| time/                   |            |
|    total_timesteps      | 8640000    |
| train/                  |            |
|    approx_kl            | 0.15637262 |
|    clip_fraction        | 0.418      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.89       |
|    explained_variance   | 0.958      |
|    learning_rate        | 0.000315   |
|    loss                 | 0.04       |
|    n_updates            | 42180      |
|    policy_gradient_loss | 0.00747    |
|    std                  | 0.0571     |
|    value_loss           | 0.00599    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 4219    |
|    time_elapsed    | 13691   |
|    total_timesteps | 8640512 |
--------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4220       |
|    time_elapsed         | 13694      |
|    total_timesteps      | 8642560    |
| train/                  |            |
|    approx_kl            | 0.15908849 |
|    clip_fraction        | 0.411      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.89       |
|    explained_variance   | 0.956      |
|    learning_rate        | 0.000315   |
|    loss                 | -0.00953   |
|    n_updates            | 42190      |
|    policy_gradient_loss | 0.0135     |
|    std                  | 0.0573     |
|    value_loss           | 0.00497    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4221       |
|    time_elapsed         | 13697      |
|    total_timesteps      | 8644608    |
| train/                  |            |
|    approx_kl            | 0.10406603 |
|    clip_fraction        | 0.462      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.88       |
|    explained_variance   | 0.875      |
|    learning_rate        | 0.000315   |
|    loss                 | -0.00628   |
|    n_updates            | 42200      |
|    policy_gradient_loss | 0.0202     |
|    std                  | 0.058      |
|    value_loss           | 0.00826    |
----------------------------------------
box reached target
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 4222      |
|    time_elapsed         | 13700     |
|    total_timesteps      | 8646656   |
| train/                  |           |
|    approx_kl            | 0.1339784 |
|    clip_fraction        | 0.357     |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.86      |
|    explained_variance   | 0.525     |
|    learning_rate        | 0.000314  |
|    loss                 | -0.00871  |
|    n_updates            | 42210     |
|    policy_gradient_loss | 0.00375   |
|    std                  | 0.0578    |
|    value_loss           | 0.00133   |
---------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 4223      |
|    time_elapsed         | 13703     |
|    total_timesteps      | 8648704   |
| train/                  |           |
|    approx_kl            | 0.5509022 |
|    clip_fraction        | 0.466     |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.86      |
|    explained_variance   | 0.987     |
|    learning_rate        | 0.000314  |
|    loss                 | -0.0197   |
|    n_updates            | 42220     |
|    policy_gradient_loss | 0.0134    |
|    std                  | 0.0582    |
|    value_loss           | 0.005     |
---------------------------------------
Eval num_timesteps=8650000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 300         |
|    mean_reward          | -1          |
| time/                   |             |
|    total_timesteps      | 8650000     |
| train/                  |             |
|    approx_kl            | 0.037660085 |
|    clip_fraction        | 0.303       |
|    clip_range           | 0.2         |
|    entropy_loss         | 2.86        |
|    explained_variance   | 0.767       |
|    learning_rate        | 0.000314    |
|    loss                 | -0.0175     |
|    n_updates            | 42230       |
|    policy_gradient_loss | 0.00694     |
|    std                  | 0.0578      |
|    value_loss           | 0.00124     |
-----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 4224    |
|    time_elapsed    | 13707   |
|    total_timesteps | 8650752 |
--------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 631         |
|    iterations           | 4225        |
|    time_elapsed         | 13710       |
|    total_timesteps      | 8652800     |
| train/                  |             |
|    approx_kl            | 0.050246824 |
|    clip_fraction        | 0.303       |
|    clip_range           | 0.2         |
|    entropy_loss         | 2.87        |
|    explained_variance   | 0.798       |
|    learning_rate        | 0.000313    |
|    loss                 | -0.0122     |
|    n_updates            | 42240       |
|    policy_gradient_loss | 0.00625     |
|    std                  | 0.0579      |
|    value_loss           | 0.000808    |
-----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4226       |
|    time_elapsed         | 13713      |
|    total_timesteps      | 8654848    |
| train/                  |            |
|    approx_kl            | 0.59636426 |
|    clip_fraction        | 0.427      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.87       |
|    explained_variance   | 0.98       |
|    learning_rate        | 0.000313   |
|    loss                 | 0.0106     |
|    n_updates            | 42250      |
|    policy_gradient_loss | 0.00527    |
|    std                  | 0.0575     |
|    value_loss           | 0.00277    |
----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 4227      |
|    time_elapsed         | 13716     |
|    total_timesteps      | 8656896   |
| train/                  |           |
|    approx_kl            | 0.5179167 |
|    clip_fraction        | 0.412     |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.88      |
|    explained_variance   | 0.5       |
|    learning_rate        | 0.000312  |
|    loss                 | -0.0206   |
|    n_updates            | 42260     |
|    policy_gradient_loss | 0.00693   |
|    std                  | 0.0573    |
|    value_loss           | 0.00211   |
---------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4228       |
|    time_elapsed         | 13719      |
|    total_timesteps      | 8658944    |
| train/                  |            |
|    approx_kl            | 0.16883694 |
|    clip_fraction        | 0.348      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.89       |
|    explained_variance   | 0.656      |
|    learning_rate        | 0.000312   |
|    loss                 | -0.0102    |
|    n_updates            | 42270      |
|    policy_gradient_loss | 0.0209     |
|    std                  | 0.0572     |
|    value_loss           | 0.000805   |
----------------------------------------
Eval num_timesteps=8660000, episode_reward=-0.73 +/- 0.54
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -0.73      |
| time/                   |            |
|    total_timesteps      | 8660000    |
| train/                  |            |
|    approx_kl            | 0.46302277 |
|    clip_fraction        | 0.452      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.9        |
|    explained_variance   | 0.986      |
|    learning_rate        | 0.000312   |
|    loss                 | 0.0128     |
|    n_updates            | 42280      |
|    policy_gradient_loss | 0.00688    |
|    std                  | 0.0567     |
|    value_loss           | 0.00283    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 4229    |
|    time_elapsed    | 13723   |
|    total_timesteps | 8660992 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4230       |
|    time_elapsed         | 13726      |
|    total_timesteps      | 8663040    |
| train/                  |            |
|    approx_kl            | 0.20269239 |
|    clip_fraction        | 0.421      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.9        |
|    explained_variance   | 0.823      |
|    learning_rate        | 0.000311   |
|    loss                 | -0.0234    |
|    n_updates            | 42290      |
|    policy_gradient_loss | -0.00131   |
|    std                  | 0.057      |
|    value_loss           | 0.0172     |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4231       |
|    time_elapsed         | 13729      |
|    total_timesteps      | 8665088    |
| train/                  |            |
|    approx_kl            | 0.22196805 |
|    clip_fraction        | 0.336      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.9        |
|    explained_variance   | 0.324      |
|    learning_rate        | 0.000311   |
|    loss                 | -0.0333    |
|    n_updates            | 42300      |
|    policy_gradient_loss | -0.000196  |
|    std                  | 0.0565     |
|    value_loss           | 0.00122    |
----------------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4232       |
|    time_elapsed         | 13732      |
|    total_timesteps      | 8667136    |
| train/                  |            |
|    approx_kl            | 0.20949206 |
|    clip_fraction        | 0.403      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.91       |
|    explained_variance   | 0.801      |
|    learning_rate        | 0.00031    |
|    loss                 | 0.0215     |
|    n_updates            | 42310      |
|    policy_gradient_loss | 0.0068     |
|    std                  | 0.0564     |
|    value_loss           | 0.00827    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4233       |
|    time_elapsed         | 13735      |
|    total_timesteps      | 8669184    |
| train/                  |            |
|    approx_kl            | 0.25288522 |
|    clip_fraction        | 0.434      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.91       |
|    explained_variance   | 0.913      |
|    learning_rate        | 0.00031    |
|    loss                 | 0.0661     |
|    n_updates            | 42320      |
|    policy_gradient_loss | 0.0155     |
|    std                  | 0.0566     |
|    value_loss           | 0.00861    |
----------------------------------------
Eval num_timesteps=8670000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 300       |
|    mean_reward          | -1        |
| time/                   |           |
|    total_timesteps      | 8670000   |
| train/                  |           |
|    approx_kl            | 0.4534542 |
|    clip_fraction        | 0.44      |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.9       |
|    explained_variance   | 0.845     |
|    learning_rate        | 0.00031   |
|    loss                 | -0.0506   |
|    n_updates            | 42330     |
|    policy_gradient_loss | 0.003     |
|    std                  | 0.0572    |
|    value_loss           | 0.00166   |
---------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 4234    |
|    time_elapsed    | 13739   |
|    total_timesteps | 8671232 |
--------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4235       |
|    time_elapsed         | 13743      |
|    total_timesteps      | 8673280    |
| train/                  |            |
|    approx_kl            | 0.26069772 |
|    clip_fraction        | 0.461      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.88       |
|    explained_variance   | 0.481      |
|    learning_rate        | 0.000309   |
|    loss                 | -0.0325    |
|    n_updates            | 42340      |
|    policy_gradient_loss | 0.0111     |
|    std                  | 0.0579     |
|    value_loss           | 0.00341    |
----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 631         |
|    iterations           | 4236        |
|    time_elapsed         | 13746       |
|    total_timesteps      | 8675328     |
| train/                  |             |
|    approx_kl            | 0.104344025 |
|    clip_fraction        | 0.453       |
|    clip_range           | 0.2         |
|    entropy_loss         | 2.87        |
|    explained_variance   | 0.894       |
|    learning_rate        | 0.000309    |
|    loss                 | 0.0573      |
|    n_updates            | 42350       |
|    policy_gradient_loss | 0.0168      |
|    std                  | 0.0573      |
|    value_loss           | 0.00461     |
-----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4237       |
|    time_elapsed         | 13749      |
|    total_timesteps      | 8677376    |
| train/                  |            |
|    approx_kl            | 0.13588071 |
|    clip_fraction        | 0.364      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.89       |
|    explained_variance   | 0.542      |
|    learning_rate        | 0.000308   |
|    loss                 | 0.0335     |
|    n_updates            | 42360      |
|    policy_gradient_loss | 0.00864    |
|    std                  | 0.0568     |
|    value_loss           | 0.000944   |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4238       |
|    time_elapsed         | 13752      |
|    total_timesteps      | 8679424    |
| train/                  |            |
|    approx_kl            | 0.08295218 |
|    clip_fraction        | 0.331      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.91       |
|    explained_variance   | 0.474      |
|    learning_rate        | 0.000308   |
|    loss                 | -0.0132    |
|    n_updates            | 42370      |
|    policy_gradient_loss | 0.0118     |
|    std                  | 0.0563     |
|    value_loss           | 0.00127    |
----------------------------------------
box reached target
box reached target
Eval num_timesteps=8680000, episode_reward=1.46 +/- 3.02
Episode length: 258.20 +/- 53.67
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 258        |
|    mean_reward          | 1.46       |
| time/                   |            |
|    total_timesteps      | 8680000    |
| train/                  |            |
|    approx_kl            | 0.09451343 |
|    clip_fraction        | 0.334      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.91       |
|    explained_variance   | 0.684      |
|    learning_rate        | 0.000308   |
|    loss                 | -0.0372    |
|    n_updates            | 42380      |
|    policy_gradient_loss | 0.00188    |
|    std                  | 0.0566     |
|    value_loss           | 0.00107    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 4239    |
|    time_elapsed    | 13756   |
|    total_timesteps | 8681472 |
--------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 4240      |
|    time_elapsed         | 13759     |
|    total_timesteps      | 8683520   |
| train/                  |           |
|    approx_kl            | 2.6259506 |
|    clip_fraction        | 0.516     |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.9       |
|    explained_variance   | 0.648     |
|    learning_rate        | 0.000307  |
|    loss                 | -0.0193   |
|    n_updates            | 42390     |
|    policy_gradient_loss | 0.00062   |
|    std                  | 0.0565    |
|    value_loss           | 0.00411   |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4241       |
|    time_elapsed         | 13762      |
|    total_timesteps      | 8685568    |
| train/                  |            |
|    approx_kl            | 0.24930549 |
|    clip_fraction        | 0.42       |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.92       |
|    explained_variance   | 0.482      |
|    learning_rate        | 0.000307   |
|    loss                 | 0.00938    |
|    n_updates            | 42400      |
|    policy_gradient_loss | 8.98e-05   |
|    std                  | 0.0562     |
|    value_loss           | 0.00153    |
----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 4242      |
|    time_elapsed         | 13765     |
|    total_timesteps      | 8687616   |
| train/                  |           |
|    approx_kl            | 0.3828178 |
|    clip_fraction        | 0.35      |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.92      |
|    explained_variance   | 0.596     |
|    learning_rate        | 0.000306  |
|    loss                 | -0.00605  |
|    n_updates            | 42410     |
|    policy_gradient_loss | 0.0159    |
|    std                  | 0.0558    |
|    value_loss           | 0.00118   |
---------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 4243      |
|    time_elapsed         | 13768     |
|    total_timesteps      | 8689664   |
| train/                  |           |
|    approx_kl            | 0.1564945 |
|    clip_fraction        | 0.37      |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.95      |
|    explained_variance   | 0.58      |
|    learning_rate        | 0.000306  |
|    loss                 | 0.0682    |
|    n_updates            | 42420     |
|    policy_gradient_loss | 0.162     |
|    std                  | 0.0548    |
|    value_loss           | 0.00126   |
---------------------------------------
box reached target
Eval num_timesteps=8690000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1         |
| time/                   |            |
|    total_timesteps      | 8690000    |
| train/                  |            |
|    approx_kl            | 0.12071852 |
|    clip_fraction        | 0.369      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.97       |
|    explained_variance   | 0.828      |
|    learning_rate        | 0.000306   |
|    loss                 | -0.0344    |
|    n_updates            | 42430      |
|    policy_gradient_loss | 0.00624    |
|    std                  | 0.0548     |
|    value_loss           | 0.000852   |
----------------------------------------
box reached target
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 4244    |
|    time_elapsed    | 13772   |
|    total_timesteps | 8691712 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4245       |
|    time_elapsed         | 13775      |
|    total_timesteps      | 8693760    |
| train/                  |            |
|    approx_kl            | 0.29388627 |
|    clip_fraction        | 0.45       |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.98       |
|    explained_variance   | 0.366      |
|    learning_rate        | 0.000305   |
|    loss                 | 0.0249     |
|    n_updates            | 42440      |
|    policy_gradient_loss | 0.0092     |
|    std                  | 0.0543     |
|    value_loss           | 0.09       |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4246       |
|    time_elapsed         | 13778      |
|    total_timesteps      | 8695808    |
| train/                  |            |
|    approx_kl            | 0.07863862 |
|    clip_fraction        | 0.339      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.98       |
|    explained_variance   | 0.903      |
|    learning_rate        | 0.000305   |
|    loss                 | 0.0534     |
|    n_updates            | 42450      |
|    policy_gradient_loss | 0.0137     |
|    std                  | 0.0545     |
|    value_loss           | 0.0258     |
----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 4247      |
|    time_elapsed         | 13781     |
|    total_timesteps      | 8697856   |
| train/                  |           |
|    approx_kl            | 1.3636849 |
|    clip_fraction        | 0.433     |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.97      |
|    explained_variance   | 0.713     |
|    learning_rate        | 0.000304  |
|    loss                 | 0.0952    |
|    n_updates            | 42460     |
|    policy_gradient_loss | 0.0246    |
|    std                  | 0.0548    |
|    value_loss           | 0.0531    |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4248       |
|    time_elapsed         | 13784      |
|    total_timesteps      | 8699904    |
| train/                  |            |
|    approx_kl            | 0.07295813 |
|    clip_fraction        | 0.336      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.97       |
|    explained_variance   | 0.741      |
|    learning_rate        | 0.000304   |
|    loss                 | 0.0187     |
|    n_updates            | 42470      |
|    policy_gradient_loss | 0.0129     |
|    std                  | 0.0549     |
|    value_loss           | 0.0317     |
----------------------------------------
box reached target
Eval num_timesteps=8700000, episode_reward=0.21 +/- 2.42
Episode length: 278.20 +/- 43.60
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 278        |
|    mean_reward          | 0.211      |
| time/                   |            |
|    total_timesteps      | 8700000    |
| train/                  |            |
|    approx_kl            | 0.12162746 |
|    clip_fraction        | 0.347      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.97       |
|    explained_variance   | 0.802      |
|    learning_rate        | 0.000304   |
|    loss                 | -0.0242    |
|    n_updates            | 42480      |
|    policy_gradient_loss | 0.0103     |
|    std                  | 0.0545     |
|    value_loss           | 0.00905    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 4249    |
|    time_elapsed    | 13788   |
|    total_timesteps | 8701952 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4250       |
|    time_elapsed         | 13791      |
|    total_timesteps      | 8704000    |
| train/                  |            |
|    approx_kl            | 0.06876165 |
|    clip_fraction        | 0.348      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.97       |
|    explained_variance   | 0.837      |
|    learning_rate        | 0.000303   |
|    loss                 | -0.0123    |
|    n_updates            | 42490      |
|    policy_gradient_loss | 0.0105     |
|    std                  | 0.055      |
|    value_loss           | 0.00382    |
----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 4251      |
|    time_elapsed         | 13794     |
|    total_timesteps      | 8706048   |
| train/                  |           |
|    approx_kl            | 0.1316971 |
|    clip_fraction        | 0.367     |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.96      |
|    explained_variance   | 0.875     |
|    learning_rate        | 0.000303  |
|    loss                 | -0.0367   |
|    n_updates            | 42500     |
|    policy_gradient_loss | 0.00514   |
|    std                  | 0.0553    |
|    value_loss           | 0.00167   |
---------------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 631         |
|    iterations           | 4252        |
|    time_elapsed         | 13797       |
|    total_timesteps      | 8708096     |
| train/                  |             |
|    approx_kl            | 0.101390004 |
|    clip_fraction        | 0.36        |
|    clip_range           | 0.2         |
|    entropy_loss         | 2.96        |
|    explained_variance   | 0.708       |
|    learning_rate        | 0.000302    |
|    loss                 | -0.0174     |
|    n_updates            | 42510       |
|    policy_gradient_loss | 0.008       |
|    std                  | 0.0549      |
|    value_loss           | 0.00294     |
-----------------------------------------
box reached target
Eval num_timesteps=8710000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1         |
| time/                   |            |
|    total_timesteps      | 8710000    |
| train/                  |            |
|    approx_kl            | 0.21240571 |
|    clip_fraction        | 0.393      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.96       |
|    explained_variance   | 0.956      |
|    learning_rate        | 0.000302   |
|    loss                 | -0.0173    |
|    n_updates            | 42520      |
|    policy_gradient_loss | 0.0185     |
|    std                  | 0.0551     |
|    value_loss           | 0.00612    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 4253    |
|    time_elapsed    | 13801   |
|    total_timesteps | 8710144 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4254       |
|    time_elapsed         | 13804      |
|    total_timesteps      | 8712192    |
| train/                  |            |
|    approx_kl            | 0.09930656 |
|    clip_fraction        | 0.387      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.95       |
|    explained_variance   | 0.969      |
|    learning_rate        | 0.000302   |
|    loss                 | -0.0104    |
|    n_updates            | 42530      |
|    policy_gradient_loss | 0.00432    |
|    std                  | 0.0553     |
|    value_loss           | 0.00684    |
----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 4255      |
|    time_elapsed         | 13807     |
|    total_timesteps      | 8714240   |
| train/                  |           |
|    approx_kl            | 0.1287235 |
|    clip_fraction        | 0.393     |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.93      |
|    explained_variance   | 0.729     |
|    learning_rate        | 0.000301  |
|    loss                 | -0.0136   |
|    n_updates            | 42540     |
|    policy_gradient_loss | 0.0147    |
|    std                  | 0.0564    |
|    value_loss           | 0.00104   |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4256       |
|    time_elapsed         | 13811      |
|    total_timesteps      | 8716288    |
| train/                  |            |
|    approx_kl            | 0.21889299 |
|    clip_fraction        | 0.356      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.91       |
|    explained_variance   | 0.842      |
|    learning_rate        | 0.000301   |
|    loss                 | 0.00334    |
|    n_updates            | 42550      |
|    policy_gradient_loss | -0.00475   |
|    std                  | 0.0567     |
|    value_loss           | 0.00214    |
----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 4257      |
|    time_elapsed         | 13814     |
|    total_timesteps      | 8718336   |
| train/                  |           |
|    approx_kl            | 0.2280552 |
|    clip_fraction        | 0.412     |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.92      |
|    explained_variance   | 0.622     |
|    learning_rate        | 0.0003    |
|    loss                 | -0.0324   |
|    n_updates            | 42560     |
|    policy_gradient_loss | 0.00492   |
|    std                  | 0.0558    |
|    value_loss           | 0.00146   |
---------------------------------------
Eval num_timesteps=8720000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1         |
| time/                   |            |
|    total_timesteps      | 8720000    |
| train/                  |            |
|    approx_kl            | 0.19926646 |
|    clip_fraction        | 0.377      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.95       |
|    explained_variance   | 0.394      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0289    |
|    n_updates            | 42570      |
|    policy_gradient_loss | 0.00717    |
|    std                  | 0.055      |
|    value_loss           | 0.00213    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 4258    |
|    time_elapsed    | 13818   |
|    total_timesteps | 8720384 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4259       |
|    time_elapsed         | 13821      |
|    total_timesteps      | 8722432    |
| train/                  |            |
|    approx_kl            | 0.13180484 |
|    clip_fraction        | 0.349      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.95       |
|    explained_variance   | 0.633      |
|    learning_rate        | 0.0003     |
|    loss                 | -0.0185    |
|    n_updates            | 42580      |
|    policy_gradient_loss | 0.00931    |
|    std                  | 0.0556     |
|    value_loss           | 0.00131    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4260       |
|    time_elapsed         | 13824      |
|    total_timesteps      | 8724480    |
| train/                  |            |
|    approx_kl            | 0.08752544 |
|    clip_fraction        | 0.362      |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.94       |
|    explained_variance   | 0.522      |
|    learning_rate        | 0.000299   |
|    loss                 | 0.0064     |
|    n_updates            | 42590      |
|    policy_gradient_loss | 0.0116     |
|    std                  | 0.0553     |
|    value_loss           | 0.00122    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4261       |
|    time_elapsed         | 13827      |
|    total_timesteps      | 8726528    |
| train/                  |            |
|    approx_kl            | 0.34995586 |
|    clip_fraction        | 0.38       |
|    clip_range           | 0.2        |
|    entropy_loss         | 2.96       |
|    explained_variance   | 0.421      |
|    learning_rate        | 0.000299   |
|    loss                 | -0.0483    |
|    n_updates            | 42600      |
|    policy_gradient_loss | 0.00224    |
|    std                  | 0.0548     |
|    value_loss           | 0.00299    |
----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 4262      |
|    time_elapsed         | 13830     |
|    total_timesteps      | 8728576   |
| train/                  |           |
|    approx_kl            | 0.9291362 |
|    clip_fraction        | 0.409     |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.98      |
|    explained_variance   | 0.644     |
|    learning_rate        | 0.000298  |
|    loss                 | -0.0376   |
|    n_updates            | 42610     |
|    policy_gradient_loss | -0.00252  |
|    std                  | 0.0543    |
|    value_loss           | 0.00121   |
---------------------------------------
Eval num_timesteps=8730000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1         |
| time/                   |            |
|    total_timesteps      | 8730000    |
| train/                  |            |
|    approx_kl            | 0.18250342 |
|    clip_fraction        | 0.366      |
|    clip_range           | 0.2        |
|    entropy_loss         | 3          |
|    explained_variance   | 0.629      |
|    learning_rate        | 0.000298   |
|    loss                 | -0.0249    |
|    n_updates            | 42620      |
|    policy_gradient_loss | 0.0143     |
|    std                  | 0.0537     |
|    value_loss           | 0.000796   |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 4263    |
|    time_elapsed    | 13834   |
|    total_timesteps | 8730624 |
--------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4264       |
|    time_elapsed         | 13837      |
|    total_timesteps      | 8732672    |
| train/                  |            |
|    approx_kl            | 0.25441486 |
|    clip_fraction        | 0.376      |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.01       |
|    explained_variance   | 0.499      |
|    learning_rate        | 0.000298   |
|    loss                 | -0.0169    |
|    n_updates            | 42630      |
|    policy_gradient_loss | 0.00668    |
|    std                  | 0.0536     |
|    value_loss           | 0.00166    |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4265       |
|    time_elapsed         | 13840      |
|    total_timesteps      | 8734720    |
| train/                  |            |
|    approx_kl            | 0.12779994 |
|    clip_fraction        | 0.446      |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.01       |
|    explained_variance   | 0.961      |
|    learning_rate        | 0.000297   |
|    loss                 | 0.0659     |
|    n_updates            | 42640      |
|    policy_gradient_loss | 0.0204     |
|    std                  | 0.0535     |
|    value_loss           | 0.00575    |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4266       |
|    time_elapsed         | 13843      |
|    total_timesteps      | 8736768    |
| train/                  |            |
|    approx_kl            | 0.18801835 |
|    clip_fraction        | 0.409      |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.01       |
|    explained_variance   | 0.68       |
|    learning_rate        | 0.000297   |
|    loss                 | 0.00256    |
|    n_updates            | 42650      |
|    policy_gradient_loss | 0.00776    |
|    std                  | 0.0539     |
|    value_loss           | 0.0196     |
----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 4267      |
|    time_elapsed         | 13846     |
|    total_timesteps      | 8738816   |
| train/                  |           |
|    approx_kl            | 0.2707253 |
|    clip_fraction        | 0.412     |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.99      |
|    explained_variance   | 0.962     |
|    learning_rate        | 0.000296  |
|    loss                 | -0.0204   |
|    n_updates            | 42660     |
|    policy_gradient_loss | 0.0159    |
|    std                  | 0.0542    |
|    value_loss           | 0.00586   |
---------------------------------------
Eval num_timesteps=8740000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 300       |
|    mean_reward          | -1        |
| time/                   |           |
|    total_timesteps      | 8740000   |
| train/                  |           |
|    approx_kl            | 0.3157467 |
|    clip_fraction        | 0.41      |
|    clip_range           | 0.2       |
|    entropy_loss         | 2.99      |
|    explained_variance   | 0.279     |
|    learning_rate        | 0.000296  |
|    loss                 | -0.0288   |
|    n_updates            | 42670     |
|    policy_gradient_loss | -0.000279 |
|    std                  | 0.0546    |
|    value_loss           | 0.00146   |
---------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 4268    |
|    time_elapsed    | 13850   |
|    total_timesteps | 8740864 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4269       |
|    time_elapsed         | 13853      |
|    total_timesteps      | 8742912    |
| train/                  |            |
|    approx_kl            | 0.21890071 |
|    clip_fraction        | 0.36       |
|    clip_range           | 0.2        |
|    entropy_loss         | 3          |
|    explained_variance   | 0.483      |
|    learning_rate        | 0.000296   |
|    loss                 | -0.00241   |
|    n_updates            | 42680      |
|    policy_gradient_loss | 0.00765    |
|    std                  | 0.0539     |
|    value_loss           | 0.00105    |
----------------------------------------
box reached target
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 4270      |
|    time_elapsed         | 13856     |
|    total_timesteps      | 8744960   |
| train/                  |           |
|    approx_kl            | 0.4310935 |
|    clip_fraction        | 0.452     |
|    clip_range           | 0.2       |
|    entropy_loss         | 3.01      |
|    explained_variance   | 0.576     |
|    learning_rate        | 0.000295  |
|    loss                 | 0.145     |
|    n_updates            | 42690     |
|    policy_gradient_loss | 0.0102    |
|    std                  | 0.0537    |
|    value_loss           | 0.000975  |
---------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 631         |
|    iterations           | 4271        |
|    time_elapsed         | 13859       |
|    total_timesteps      | 8747008     |
| train/                  |             |
|    approx_kl            | 0.110465035 |
|    clip_fraction        | 0.405       |
|    clip_range           | 0.2         |
|    entropy_loss         | 3.02        |
|    explained_variance   | 0.55        |
|    learning_rate        | 0.000295    |
|    loss                 | 0.0404      |
|    n_updates            | 42700       |
|    policy_gradient_loss | 0.0138      |
|    std                  | 0.0533      |
|    value_loss           | 0.121       |
-----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4272       |
|    time_elapsed         | 13862      |
|    total_timesteps      | 8749056    |
| train/                  |            |
|    approx_kl            | 0.24429098 |
|    clip_fraction        | 0.35       |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.03       |
|    explained_variance   | 0.719      |
|    learning_rate        | 0.000294   |
|    loss                 | 0.0632     |
|    n_updates            | 42710      |
|    policy_gradient_loss | 0.000781   |
|    std                  | 0.053      |
|    value_loss           | 0.00126    |
----------------------------------------
Eval num_timesteps=8750000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1         |
| time/                   |            |
|    total_timesteps      | 8750000    |
| train/                  |            |
|    approx_kl            | 0.27256012 |
|    clip_fraction        | 0.398      |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.04       |
|    explained_variance   | 0.74       |
|    learning_rate        | 0.000294   |
|    loss                 | 0.0132     |
|    n_updates            | 42720      |
|    policy_gradient_loss | -0.00486   |
|    std                  | 0.0527     |
|    value_loss           | 0.000776   |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 4273    |
|    time_elapsed    | 13866   |
|    total_timesteps | 8751104 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4274       |
|    time_elapsed         | 13869      |
|    total_timesteps      | 8753152    |
| train/                  |            |
|    approx_kl            | 0.18808003 |
|    clip_fraction        | 0.348      |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.05       |
|    explained_variance   | 0.784      |
|    learning_rate        | 0.000294   |
|    loss                 | -0.0244    |
|    n_updates            | 42730      |
|    policy_gradient_loss | 0.00814    |
|    std                  | 0.0526     |
|    value_loss           | 0.000598   |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4275       |
|    time_elapsed         | 13872      |
|    total_timesteps      | 8755200    |
| train/                  |            |
|    approx_kl            | 0.18480375 |
|    clip_fraction        | 0.414      |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.06       |
|    explained_variance   | 0.496      |
|    learning_rate        | 0.000293   |
|    loss                 | 0.0232     |
|    n_updates            | 42740      |
|    policy_gradient_loss | 0.0102     |
|    std                  | 0.0524     |
|    value_loss           | 0.00186    |
----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 4276      |
|    time_elapsed         | 13875     |
|    total_timesteps      | 8757248   |
| train/                  |           |
|    approx_kl            | 0.4229986 |
|    clip_fraction        | 0.447     |
|    clip_range           | 0.2       |
|    entropy_loss         | 3.06      |
|    explained_variance   | 0.962     |
|    learning_rate        | 0.000293  |
|    loss                 | 0.0465    |
|    n_updates            | 42750     |
|    policy_gradient_loss | 0.0192    |
|    std                  | 0.0526    |
|    value_loss           | 0.00604   |
---------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4277       |
|    time_elapsed         | 13878      |
|    total_timesteps      | 8759296    |
| train/                  |            |
|    approx_kl            | 0.43211928 |
|    clip_fraction        | 0.378      |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.07       |
|    explained_variance   | 0.106      |
|    learning_rate        | 0.000292   |
|    loss                 | -0.0641    |
|    n_updates            | 42760      |
|    policy_gradient_loss | -0.00693   |
|    std                  | 0.0517     |
|    value_loss           | 0.0015     |
----------------------------------------
Eval num_timesteps=8760000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1         |
| time/                   |            |
|    total_timesteps      | 8760000    |
| train/                  |            |
|    approx_kl            | 0.16088003 |
|    clip_fraction        | 0.435      |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.1        |
|    explained_variance   | 0.97       |
|    learning_rate        | 0.000292   |
|    loss                 | 0.0116     |
|    n_updates            | 42770      |
|    policy_gradient_loss | 0.0132     |
|    std                  | 0.051      |
|    value_loss           | 0.00509    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 4278    |
|    time_elapsed    | 13882   |
|    total_timesteps | 8761344 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4279       |
|    time_elapsed         | 13885      |
|    total_timesteps      | 8763392    |
| train/                  |            |
|    approx_kl            | 0.23780084 |
|    clip_fraction        | 0.427      |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.11       |
|    explained_variance   | 0.742      |
|    learning_rate        | 0.000292   |
|    loss                 | 0.0329     |
|    n_updates            | 42780      |
|    policy_gradient_loss | 0.00843    |
|    std                  | 0.0514     |
|    value_loss           | 0.00421    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4280       |
|    time_elapsed         | 13888      |
|    total_timesteps      | 8765440    |
| train/                  |            |
|    approx_kl            | 0.15748633 |
|    clip_fraction        | 0.327      |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.1        |
|    explained_variance   | 0.508      |
|    learning_rate        | 0.000291   |
|    loss                 | -0.00358   |
|    n_updates            | 42790      |
|    policy_gradient_loss | 0.017      |
|    std                  | 0.0515     |
|    value_loss           | 0.000982   |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4281       |
|    time_elapsed         | 13892      |
|    total_timesteps      | 8767488    |
| train/                  |            |
|    approx_kl            | 0.16320282 |
|    clip_fraction        | 0.437      |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.09       |
|    explained_variance   | 0.795      |
|    learning_rate        | 0.000291   |
|    loss                 | 0.00933    |
|    n_updates            | 42800      |
|    policy_gradient_loss | 0.0156     |
|    std                  | 0.0519     |
|    value_loss           | 0.00283    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4282       |
|    time_elapsed         | 13895      |
|    total_timesteps      | 8769536    |
| train/                  |            |
|    approx_kl            | 0.17399849 |
|    clip_fraction        | 0.391      |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.08       |
|    explained_variance   | 0.568      |
|    learning_rate        | 0.00029    |
|    loss                 | 0.103      |
|    n_updates            | 42810      |
|    policy_gradient_loss | 0.0128     |
|    std                  | 0.0522     |
|    value_loss           | 0.000999   |
----------------------------------------
Eval num_timesteps=8770000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1         |
| time/                   |            |
|    total_timesteps      | 8770000    |
| train/                  |            |
|    approx_kl            | 0.12193045 |
|    clip_fraction        | 0.393      |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.06       |
|    explained_variance   | 0.875      |
|    learning_rate        | 0.00029    |
|    loss                 | -0.0412    |
|    n_updates            | 42820      |
|    policy_gradient_loss | 0.011      |
|    std                  | 0.0526     |
|    value_loss           | 0.00187    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 4283    |
|    time_elapsed    | 13899   |
|    total_timesteps | 8771584 |
--------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4284       |
|    time_elapsed         | 13902      |
|    total_timesteps      | 8773632    |
| train/                  |            |
|    approx_kl            | 0.20919693 |
|    clip_fraction        | 0.419      |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.06       |
|    explained_variance   | 0.538      |
|    learning_rate        | 0.00029    |
|    loss                 | -0.0309    |
|    n_updates            | 42830      |
|    policy_gradient_loss | 0.0342     |
|    std                  | 0.0526     |
|    value_loss           | 0.00132    |
----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 4285      |
|    time_elapsed         | 13905     |
|    total_timesteps      | 8775680   |
| train/                  |           |
|    approx_kl            | 0.6948401 |
|    clip_fraction        | 0.465     |
|    clip_range           | 0.2       |
|    entropy_loss         | 3.05      |
|    explained_variance   | 0.952     |
|    learning_rate        | 0.000289  |
|    loss                 | -0.0139   |
|    n_updates            | 42840     |
|    policy_gradient_loss | 0.01      |
|    std                  | 0.053     |
|    value_loss           | 0.0187    |
---------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 4286      |
|    time_elapsed         | 13908     |
|    total_timesteps      | 8777728   |
| train/                  |           |
|    approx_kl            | 0.4841308 |
|    clip_fraction        | 0.422     |
|    clip_range           | 0.2       |
|    entropy_loss         | 3.04      |
|    explained_variance   | 0.852     |
|    learning_rate        | 0.000289  |
|    loss                 | -0.0211   |
|    n_updates            | 42850     |
|    policy_gradient_loss | 0.00383   |
|    std                  | 0.0526    |
|    value_loss           | 0.00615   |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4287       |
|    time_elapsed         | 13911      |
|    total_timesteps      | 8779776    |
| train/                  |            |
|    approx_kl            | 0.16912273 |
|    clip_fraction        | 0.366      |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.07       |
|    explained_variance   | 0.495      |
|    learning_rate        | 0.000288   |
|    loss                 | -0.0118    |
|    n_updates            | 42860      |
|    policy_gradient_loss | 0.00725    |
|    std                  | 0.0519     |
|    value_loss           | 0.00138    |
----------------------------------------
Eval num_timesteps=8780000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1         |
| time/                   |            |
|    total_timesteps      | 8780000    |
| train/                  |            |
|    approx_kl            | 0.22628775 |
|    clip_fraction        | 0.384      |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.08       |
|    explained_variance   | 0.714      |
|    learning_rate        | 0.000288   |
|    loss                 | -0.0144    |
|    n_updates            | 42870      |
|    policy_gradient_loss | 0.00452    |
|    std                  | 0.052      |
|    value_loss           | 0.000955   |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 4288    |
|    time_elapsed    | 13915   |
|    total_timesteps | 8781824 |
--------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 4289      |
|    time_elapsed         | 13918     |
|    total_timesteps      | 8783872   |
| train/                  |           |
|    approx_kl            | 1.4051986 |
|    clip_fraction        | 0.409     |
|    clip_range           | 0.2       |
|    entropy_loss         | 3.08      |
|    explained_variance   | 0.717     |
|    learning_rate        | 0.000288  |
|    loss                 | 0.00856   |
|    n_updates            | 42880     |
|    policy_gradient_loss | 0.0141    |
|    std                  | 0.0521    |
|    value_loss           | 0.000807  |
---------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4290       |
|    time_elapsed         | 13921      |
|    total_timesteps      | 8785920    |
| train/                  |            |
|    approx_kl            | 0.36758035 |
|    clip_fraction        | 0.344      |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.08       |
|    explained_variance   | 0.538      |
|    learning_rate        | 0.000287   |
|    loss                 | -0.00212   |
|    n_updates            | 42890      |
|    policy_gradient_loss | 0.0054     |
|    std                  | 0.052      |
|    value_loss           | 0.00196    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4291       |
|    time_elapsed         | 13924      |
|    total_timesteps      | 8787968    |
| train/                  |            |
|    approx_kl            | 0.11588072 |
|    clip_fraction        | 0.419      |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.09       |
|    explained_variance   | 0.825      |
|    learning_rate        | 0.000287   |
|    loss                 | -0.0148    |
|    n_updates            | 42900      |
|    policy_gradient_loss | 0.014      |
|    std                  | 0.0513     |
|    value_loss           | 0.0134     |
----------------------------------------
Eval num_timesteps=8790000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1         |
| time/                   |            |
|    total_timesteps      | 8790000    |
| train/                  |            |
|    approx_kl            | 0.14524856 |
|    clip_fraction        | 0.367      |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.1        |
|    explained_variance   | 0.139      |
|    learning_rate        | 0.000286   |
|    loss                 | -0.00544   |
|    n_updates            | 42910      |
|    policy_gradient_loss | 0.0103     |
|    std                  | 0.0514     |
|    value_loss           | 0.00236    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 4292    |
|    time_elapsed    | 13928   |
|    total_timesteps | 8790016 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4293       |
|    time_elapsed         | 13931      |
|    total_timesteps      | 8792064    |
| train/                  |            |
|    approx_kl            | 0.14117593 |
|    clip_fraction        | 0.415      |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.09       |
|    explained_variance   | 0.722      |
|    learning_rate        | 0.000286   |
|    loss                 | 0.0453     |
|    n_updates            | 42920      |
|    policy_gradient_loss | 0.0105     |
|    std                  | 0.0518     |
|    value_loss           | 0.00371    |
----------------------------------------
box reached target
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 631         |
|    iterations           | 4294        |
|    time_elapsed         | 13934       |
|    total_timesteps      | 8794112     |
| train/                  |             |
|    approx_kl            | 0.102831736 |
|    clip_fraction        | 0.343       |
|    clip_range           | 0.2         |
|    entropy_loss         | 3.11        |
|    explained_variance   | 0.569       |
|    learning_rate        | 0.000286    |
|    loss                 | -0.0327     |
|    n_updates            | 42930       |
|    policy_gradient_loss | 0.00631     |
|    std                  | 0.0506      |
|    value_loss           | 0.00143     |
-----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 4295      |
|    time_elapsed         | 13937     |
|    total_timesteps      | 8796160   |
| train/                  |           |
|    approx_kl            | 0.3178107 |
|    clip_fraction        | 0.411     |
|    clip_range           | 0.2       |
|    entropy_loss         | 3.13      |
|    explained_variance   | 0.979     |
|    learning_rate        | 0.000285  |
|    loss                 | 0.0331    |
|    n_updates            | 42940     |
|    policy_gradient_loss | 0.00606   |
|    std                  | 0.0505    |
|    value_loss           | 0.00785   |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4296       |
|    time_elapsed         | 13940      |
|    total_timesteps      | 8798208    |
| train/                  |            |
|    approx_kl            | 0.16635422 |
|    clip_fraction        | 0.388      |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.12       |
|    explained_variance   | 0.88       |
|    learning_rate        | 0.000285   |
|    loss                 | 0.0601     |
|    n_updates            | 42950      |
|    policy_gradient_loss | 0.0169     |
|    std                  | 0.0512     |
|    value_loss           | 0.00208    |
----------------------------------------
Eval num_timesteps=8800000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 300       |
|    mean_reward          | -1        |
| time/                   |           |
|    total_timesteps      | 8800000   |
| train/                  |           |
|    approx_kl            | 1.2927294 |
|    clip_fraction        | 0.469     |
|    clip_range           | 0.2       |
|    entropy_loss         | 3.11      |
|    explained_variance   | 0.732     |
|    learning_rate        | 0.000284  |
|    loss                 | -0.0151   |
|    n_updates            | 42960     |
|    policy_gradient_loss | -4.42e-05 |
|    std                  | 0.0509    |
|    value_loss           | 0.001     |
---------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 4297    |
|    time_elapsed    | 13944   |
|    total_timesteps | 8800256 |
--------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 4298      |
|    time_elapsed         | 13947     |
|    total_timesteps      | 8802304   |
| train/                  |           |
|    approx_kl            | 0.6974593 |
|    clip_fraction        | 0.383     |
|    clip_range           | 0.2       |
|    entropy_loss         | 3.14      |
|    explained_variance   | 0.566     |
|    learning_rate        | 0.000284  |
|    loss                 | -0.0113   |
|    n_updates            | 42970     |
|    policy_gradient_loss | 0.02      |
|    std                  | 0.0502    |
|    value_loss           | 0.000924  |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4299       |
|    time_elapsed         | 13950      |
|    total_timesteps      | 8804352    |
| train/                  |            |
|    approx_kl            | 0.16598207 |
|    clip_fraction        | 0.314      |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.16       |
|    explained_variance   | 0.378      |
|    learning_rate        | 0.000284   |
|    loss                 | -0.0131    |
|    n_updates            | 42980      |
|    policy_gradient_loss | -0.00232   |
|    std                  | 0.0495     |
|    value_loss           | 0.00123    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4300       |
|    time_elapsed         | 13953      |
|    total_timesteps      | 8806400    |
| train/                  |            |
|    approx_kl            | 0.20430136 |
|    clip_fraction        | 0.449      |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.16       |
|    explained_variance   | 0.603      |
|    learning_rate        | 0.000283   |
|    loss                 | 0.065      |
|    n_updates            | 42990      |
|    policy_gradient_loss | 0.0308     |
|    std                  | 0.0505     |
|    value_loss           | 0.00201    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4301       |
|    time_elapsed         | 13956      |
|    total_timesteps      | 8808448    |
| train/                  |            |
|    approx_kl            | 0.26076624 |
|    clip_fraction        | 0.393      |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.14       |
|    explained_variance   | 0.493      |
|    learning_rate        | 0.000283   |
|    loss                 | -0.0409    |
|    n_updates            | 43000      |
|    policy_gradient_loss | 0.00246    |
|    std                  | 0.0499     |
|    value_loss           | 0.00122    |
----------------------------------------
Eval num_timesteps=8810000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 300       |
|    mean_reward          | -1        |
| time/                   |           |
|    total_timesteps      | 8810000   |
| train/                  |           |
|    approx_kl            | 0.2548416 |
|    clip_fraction        | 0.41      |
|    clip_range           | 0.2       |
|    entropy_loss         | 3.18      |
|    explained_variance   | 0.781     |
|    learning_rate        | 0.000282  |
|    loss                 | -0.0537   |
|    n_updates            | 43010     |
|    policy_gradient_loss | -0.00376  |
|    std                  | 0.0491    |
|    value_loss           | 0.000826  |
---------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 4302    |
|    time_elapsed    | 13960   |
|    total_timesteps | 8810496 |
--------------------------------
box reached target
--------------------------------------
| time/                   |          |
|    fps                  | 631      |
|    iterations           | 4303     |
|    time_elapsed         | 13964    |
|    total_timesteps      | 8812544  |
| train/                  |          |
|    approx_kl            | 0.2598   |
|    clip_fraction        | 0.415    |
|    clip_range           | 0.2      |
|    entropy_loss         | 3.19     |
|    explained_variance   | 0.478    |
|    learning_rate        | 0.000282 |
|    loss                 | 0.00214  |
|    n_updates            | 43020    |
|    policy_gradient_loss | 0.0127   |
|    std                  | 0.0489   |
|    value_loss           | 0.00428  |
--------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 4304      |
|    time_elapsed         | 13967     |
|    total_timesteps      | 8814592   |
| train/                  |           |
|    approx_kl            | 1.1898648 |
|    clip_fraction        | 0.481     |
|    clip_range           | 0.2       |
|    entropy_loss         | 3.2       |
|    explained_variance   | 0.109     |
|    learning_rate        | 0.000282  |
|    loss                 | 0.143     |
|    n_updates            | 43030     |
|    policy_gradient_loss | 0.0145    |
|    std                  | 0.0488    |
|    value_loss           | 0.113     |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4305       |
|    time_elapsed         | 13970      |
|    total_timesteps      | 8816640    |
| train/                  |            |
|    approx_kl            | 0.12794589 |
|    clip_fraction        | 0.367      |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.18       |
|    explained_variance   | 0.783      |
|    learning_rate        | 0.000281   |
|    loss                 | 0.00555    |
|    n_updates            | 43040      |
|    policy_gradient_loss | 0.019      |
|    std                  | 0.0497     |
|    value_loss           | 0.00137    |
----------------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 631         |
|    iterations           | 4306        |
|    time_elapsed         | 13973       |
|    total_timesteps      | 8818688     |
| train/                  |             |
|    approx_kl            | 0.069434986 |
|    clip_fraction        | 0.342       |
|    clip_range           | 0.2         |
|    entropy_loss         | 3.16        |
|    explained_variance   | 0.685       |
|    learning_rate        | 0.000281    |
|    loss                 | 0.0112      |
|    n_updates            | 43050       |
|    policy_gradient_loss | 0.0112      |
|    std                  | 0.0502      |
|    value_loss           | 0.00129     |
-----------------------------------------
box reached target
Eval num_timesteps=8820000, episode_reward=0.24 +/- 2.48
Episode length: 280.60 +/- 38.80
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 281        |
|    mean_reward          | 0.238      |
| time/                   |            |
|    total_timesteps      | 8820000    |
| train/                  |            |
|    approx_kl            | 0.14218454 |
|    clip_fraction        | 0.394      |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.14       |
|    explained_variance   | 0.875      |
|    learning_rate        | 0.00028    |
|    loss                 | -0.00414   |
|    n_updates            | 43060      |
|    policy_gradient_loss | 0.013      |
|    std                  | 0.0506     |
|    value_loss           | 0.0177     |
----------------------------------------
box reached target
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 4307    |
|    time_elapsed    | 13977   |
|    total_timesteps | 8820736 |
--------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4308       |
|    time_elapsed         | 13980      |
|    total_timesteps      | 8822784    |
| train/                  |            |
|    approx_kl            | 0.19007075 |
|    clip_fraction        | 0.429      |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.14       |
|    explained_variance   | 0.935      |
|    learning_rate        | 0.00028    |
|    loss                 | -0.0075    |
|    n_updates            | 43070      |
|    policy_gradient_loss | 0.017      |
|    std                  | 0.0503     |
|    value_loss           | 0.0104     |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4309       |
|    time_elapsed         | 13983      |
|    total_timesteps      | 8824832    |
| train/                  |            |
|    approx_kl            | 0.37059242 |
|    clip_fraction        | 0.446      |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.14       |
|    explained_variance   | 0.943      |
|    learning_rate        | 0.00028    |
|    loss                 | 0.0194     |
|    n_updates            | 43080      |
|    policy_gradient_loss | 0.018      |
|    std                  | 0.0505     |
|    value_loss           | 0.0076     |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4310       |
|    time_elapsed         | 13986      |
|    total_timesteps      | 8826880    |
| train/                  |            |
|    approx_kl            | 0.37391204 |
|    clip_fraction        | 0.446      |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.15       |
|    explained_variance   | 0.955      |
|    learning_rate        | 0.000279   |
|    loss                 | -0.0249    |
|    n_updates            | 43090      |
|    policy_gradient_loss | 0.0101     |
|    std                  | 0.0497     |
|    value_loss           | 0.00724    |
----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 4311      |
|    time_elapsed         | 13989     |
|    total_timesteps      | 8828928   |
| train/                  |           |
|    approx_kl            | 0.1844259 |
|    clip_fraction        | 0.387     |
|    clip_range           | 0.2       |
|    entropy_loss         | 3.17      |
|    explained_variance   | 0.868     |
|    learning_rate        | 0.000279  |
|    loss                 | 0.00119   |
|    n_updates            | 43100     |
|    policy_gradient_loss | 0.0175    |
|    std                  | 0.0496    |
|    value_loss           | 0.0177    |
---------------------------------------
Eval num_timesteps=8830000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 300       |
|    mean_reward          | -1        |
| time/                   |           |
|    total_timesteps      | 8830000   |
| train/                  |           |
|    approx_kl            | 0.3962701 |
|    clip_fraction        | 0.38      |
|    clip_range           | 0.2       |
|    entropy_loss         | 3.18      |
|    explained_variance   | 0.887     |
|    learning_rate        | 0.000278  |
|    loss                 | 0.101     |
|    n_updates            | 43110     |
|    policy_gradient_loss | 0.000683  |
|    std                  | 0.0492    |
|    value_loss           | 0.00167   |
---------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 4312    |
|    time_elapsed    | 13993   |
|    total_timesteps | 8830976 |
--------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 4313      |
|    time_elapsed         | 13996     |
|    total_timesteps      | 8833024   |
| train/                  |           |
|    approx_kl            | 0.2392071 |
|    clip_fraction        | 0.378     |
|    clip_range           | 0.2       |
|    entropy_loss         | 3.19      |
|    explained_variance   | 0.751     |
|    learning_rate        | 0.000278  |
|    loss                 | 0.0107    |
|    n_updates            | 43120     |
|    policy_gradient_loss | 0.0131    |
|    std                  | 0.0493    |
|    value_loss           | 0.000938  |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4314       |
|    time_elapsed         | 13999      |
|    total_timesteps      | 8835072    |
| train/                  |            |
|    approx_kl            | 0.17519131 |
|    clip_fraction        | 0.453      |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.17       |
|    explained_variance   | 0.821      |
|    learning_rate        | 0.000278   |
|    loss                 | -0.00538   |
|    n_updates            | 43130      |
|    policy_gradient_loss | 0.00649    |
|    std                  | 0.0496     |
|    value_loss           | 0.00291    |
----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 4315      |
|    time_elapsed         | 14002     |
|    total_timesteps      | 8837120   |
| train/                  |           |
|    approx_kl            | 0.2077674 |
|    clip_fraction        | 0.409     |
|    clip_range           | 0.2       |
|    entropy_loss         | 3.17      |
|    explained_variance   | 0.018     |
|    learning_rate        | 0.000277  |
|    loss                 | -0.0223   |
|    n_updates            | 43140     |
|    policy_gradient_loss | 0.0113    |
|    std                  | 0.0496    |
|    value_loss           | 0.00168   |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4316       |
|    time_elapsed         | 14005      |
|    total_timesteps      | 8839168    |
| train/                  |            |
|    approx_kl            | 0.35751933 |
|    clip_fraction        | 0.406      |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.17       |
|    explained_variance   | 0.653      |
|    learning_rate        | 0.000277   |
|    loss                 | -0.0471    |
|    n_updates            | 43150      |
|    policy_gradient_loss | 0.00357    |
|    std                  | 0.0495     |
|    value_loss           | 0.000947   |
----------------------------------------
Eval num_timesteps=8840000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1         |
| time/                   |            |
|    total_timesteps      | 8840000    |
| train/                  |            |
|    approx_kl            | 0.28024632 |
|    clip_fraction        | 0.376      |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.19       |
|    explained_variance   | 0.714      |
|    learning_rate        | 0.000276   |
|    loss                 | -0.027     |
|    n_updates            | 43160      |
|    policy_gradient_loss | 0.00299    |
|    std                  | 0.0489     |
|    value_loss           | 0.000879   |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 4317    |
|    time_elapsed    | 14009   |
|    total_timesteps | 8841216 |
--------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4318       |
|    time_elapsed         | 14012      |
|    total_timesteps      | 8843264    |
| train/                  |            |
|    approx_kl            | 0.17906976 |
|    clip_fraction        | 0.441      |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.19       |
|    explained_variance   | 0.636      |
|    learning_rate        | 0.000276   |
|    loss                 | -0.0141    |
|    n_updates            | 43170      |
|    policy_gradient_loss | 0.016      |
|    std                  | 0.0494     |
|    value_loss           | 0.00173    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4319       |
|    time_elapsed         | 14015      |
|    total_timesteps      | 8845312    |
| train/                  |            |
|    approx_kl            | 0.15378639 |
|    clip_fraction        | 0.438      |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.19       |
|    explained_variance   | 0.812      |
|    learning_rate        | 0.000276   |
|    loss                 | 0.00156    |
|    n_updates            | 43180      |
|    policy_gradient_loss | 0.00673    |
|    std                  | 0.0492     |
|    value_loss           | 0.0185     |
----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 4320      |
|    time_elapsed         | 14018     |
|    total_timesteps      | 8847360   |
| train/                  |           |
|    approx_kl            | 0.3109027 |
|    clip_fraction        | 0.437     |
|    clip_range           | 0.2       |
|    entropy_loss         | 3.19      |
|    explained_variance   | 0.672     |
|    learning_rate        | 0.000275  |
|    loss                 | -0.0419   |
|    n_updates            | 43190     |
|    policy_gradient_loss | 0.0102    |
|    std                  | 0.0492    |
|    value_loss           | 0.00111   |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4321       |
|    time_elapsed         | 14021      |
|    total_timesteps      | 8849408    |
| train/                  |            |
|    approx_kl            | 0.14426108 |
|    clip_fraction        | 0.338      |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.19       |
|    explained_variance   | 0.382      |
|    learning_rate        | 0.000275   |
|    loss                 | -0.00135   |
|    n_updates            | 43200      |
|    policy_gradient_loss | 0.00104    |
|    std                  | 0.0493     |
|    value_loss           | 0.00125    |
----------------------------------------
Eval num_timesteps=8850000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1         |
| time/                   |            |
|    total_timesteps      | 8850000    |
| train/                  |            |
|    approx_kl            | 0.12167855 |
|    clip_fraction        | 0.366      |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.19       |
|    explained_variance   | 0.701      |
|    learning_rate        | 0.000274   |
|    loss                 | 0.0142     |
|    n_updates            | 43210      |
|    policy_gradient_loss | 0.0069     |
|    std                  | 0.049      |
|    value_loss           | 0.00113    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 4322    |
|    time_elapsed    | 14025   |
|    total_timesteps | 8851456 |
--------------------------------
box reached target
--------------------------------------
| time/                   |          |
|    fps                  | 631      |
|    iterations           | 4323     |
|    time_elapsed         | 14028    |
|    total_timesteps      | 8853504  |
| train/                  |          |
|    approx_kl            | 0.312408 |
|    clip_fraction        | 0.42     |
|    clip_range           | 0.2      |
|    entropy_loss         | 3.2      |
|    explained_variance   | 0.611    |
|    learning_rate        | 0.000274 |
|    loss                 | -2.9e-05 |
|    n_updates            | 43220    |
|    policy_gradient_loss | 0.00227  |
|    std                  | 0.0489   |
|    value_loss           | 0.00192  |
--------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 4324      |
|    time_elapsed         | 14031     |
|    total_timesteps      | 8855552   |
| train/                  |           |
|    approx_kl            | 0.4279306 |
|    clip_fraction        | 0.405     |
|    clip_range           | 0.2       |
|    entropy_loss         | 3.22      |
|    explained_variance   | 0.983     |
|    learning_rate        | 0.000274  |
|    loss                 | 0.0468    |
|    n_updates            | 43230     |
|    policy_gradient_loss | 0.00255   |
|    std                  | 0.0481    |
|    value_loss           | 0.00218   |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4325       |
|    time_elapsed         | 14035      |
|    total_timesteps      | 8857600    |
| train/                  |            |
|    approx_kl            | 0.35323164 |
|    clip_fraction        | 0.363      |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.24       |
|    explained_variance   | 0.683      |
|    learning_rate        | 0.000273   |
|    loss                 | -0.0174    |
|    n_updates            | 43240      |
|    policy_gradient_loss | 0.00543    |
|    std                  | 0.0479     |
|    value_loss           | 0.000891   |
----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 4326      |
|    time_elapsed         | 14038     |
|    total_timesteps      | 8859648   |
| train/                  |           |
|    approx_kl            | 0.5293278 |
|    clip_fraction        | 0.448     |
|    clip_range           | 0.2       |
|    entropy_loss         | 3.25      |
|    explained_variance   | 0.476     |
|    learning_rate        | 0.000273  |
|    loss                 | -0.0473   |
|    n_updates            | 43250     |
|    policy_gradient_loss | 0.0188    |
|    std                  | 0.0477    |
|    value_loss           | 0.00125   |
---------------------------------------
Eval num_timesteps=8860000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 300         |
|    mean_reward          | -1          |
| time/                   |             |
|    total_timesteps      | 8860000     |
| train/                  |             |
|    approx_kl            | 0.082008705 |
|    clip_fraction        | 0.372       |
|    clip_range           | 0.2         |
|    entropy_loss         | 3.26        |
|    explained_variance   | -0.0559     |
|    learning_rate        | 0.000272    |
|    loss                 | -0.00667    |
|    n_updates            | 43260       |
|    policy_gradient_loss | 0.00282     |
|    std                  | 0.0473      |
|    value_loss           | 0.00249     |
-----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 4327    |
|    time_elapsed    | 14042   |
|    total_timesteps | 8861696 |
--------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4328       |
|    time_elapsed         | 14045      |
|    total_timesteps      | 8863744    |
| train/                  |            |
|    approx_kl            | 0.08557454 |
|    clip_fraction        | 0.363      |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.26       |
|    explained_variance   | 0.573      |
|    learning_rate        | 0.000272   |
|    loss                 | -0.000858  |
|    n_updates            | 43270      |
|    policy_gradient_loss | 0.0163     |
|    std                  | 0.0475     |
|    value_loss           | 0.000964   |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4329       |
|    time_elapsed         | 14048      |
|    total_timesteps      | 8865792    |
| train/                  |            |
|    approx_kl            | 0.19042937 |
|    clip_fraction        | 0.384      |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.26       |
|    explained_variance   | 0.94       |
|    learning_rate        | 0.000272   |
|    loss                 | -0.017     |
|    n_updates            | 43280      |
|    policy_gradient_loss | 0.0175     |
|    std                  | 0.0476     |
|    value_loss           | 0.0063     |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4330       |
|    time_elapsed         | 14051      |
|    total_timesteps      | 8867840    |
| train/                  |            |
|    approx_kl            | 0.14677201 |
|    clip_fraction        | 0.364      |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.26       |
|    explained_variance   | 0.758      |
|    learning_rate        | 0.000271   |
|    loss                 | -0.0186    |
|    n_updates            | 43290      |
|    policy_gradient_loss | 0.00233    |
|    std                  | 0.0473     |
|    value_loss           | 0.00113    |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4331       |
|    time_elapsed         | 14054      |
|    total_timesteps      | 8869888    |
| train/                  |            |
|    approx_kl            | 0.12554663 |
|    clip_fraction        | 0.435      |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.26       |
|    explained_variance   | 0.806      |
|    learning_rate        | 0.000271   |
|    loss                 | -0.0017    |
|    n_updates            | 43300      |
|    policy_gradient_loss | 0.0244     |
|    std                  | 0.0475     |
|    value_loss           | 0.0275     |
----------------------------------------
Eval num_timesteps=8870000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1         |
| time/                   |            |
|    total_timesteps      | 8870000    |
| train/                  |            |
|    approx_kl            | 0.12763754 |
|    clip_fraction        | 0.418      |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.26       |
|    explained_variance   | 0.932      |
|    learning_rate        | 0.00027    |
|    loss                 | -0.0263    |
|    n_updates            | 43310      |
|    policy_gradient_loss | 0.0222     |
|    std                  | 0.0476     |
|    value_loss           | 0.00633    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 4332    |
|    time_elapsed    | 14058   |
|    total_timesteps | 8871936 |
--------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4333       |
|    time_elapsed         | 14061      |
|    total_timesteps      | 8873984    |
| train/                  |            |
|    approx_kl            | 0.32297963 |
|    clip_fraction        | 0.397      |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.25       |
|    explained_variance   | 0.955      |
|    learning_rate        | 0.00027    |
|    loss                 | -0.0264    |
|    n_updates            | 43320      |
|    policy_gradient_loss | 0.0114     |
|    std                  | 0.0478     |
|    value_loss           | 0.00549    |
----------------------------------------
box reached target
box reached target
--------------------------------------
| time/                   |          |
|    fps                  | 631      |
|    iterations           | 4334     |
|    time_elapsed         | 14064    |
|    total_timesteps      | 8876032  |
| train/                  |          |
|    approx_kl            | 0.146922 |
|    clip_fraction        | 0.433    |
|    clip_range           | 0.2      |
|    entropy_loss         | 3.23     |
|    explained_variance   | 0.288    |
|    learning_rate        | 0.00027  |
|    loss                 | 0.0183   |
|    n_updates            | 43330    |
|    policy_gradient_loss | 0.0102   |
|    std                  | 0.0484   |
|    value_loss           | 0.068    |
--------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4335       |
|    time_elapsed         | 14067      |
|    total_timesteps      | 8878080    |
| train/                  |            |
|    approx_kl            | 0.08657408 |
|    clip_fraction        | 0.354      |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.21       |
|    explained_variance   | 0.922      |
|    learning_rate        | 0.000269   |
|    loss                 | -0.0357    |
|    n_updates            | 43340      |
|    policy_gradient_loss | 0.00563    |
|    std                  | 0.0488     |
|    value_loss           | 0.0168     |
----------------------------------------
Eval num_timesteps=8880000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 300       |
|    mean_reward          | -1        |
| time/                   |           |
|    total_timesteps      | 8880000   |
| train/                  |           |
|    approx_kl            | 0.3236911 |
|    clip_fraction        | 0.454     |
|    clip_range           | 0.2       |
|    entropy_loss         | 3.23      |
|    explained_variance   | 0.605     |
|    learning_rate        | 0.000269  |
|    loss                 | -0.00331  |
|    n_updates            | 43350     |
|    policy_gradient_loss | 0.00688   |
|    std                  | 0.0476    |
|    value_loss           | 0.0254    |
---------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 4336    |
|    time_elapsed    | 14071   |
|    total_timesteps | 8880128 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4337       |
|    time_elapsed         | 14074      |
|    total_timesteps      | 8882176    |
| train/                  |            |
|    approx_kl            | 0.25263184 |
|    clip_fraction        | 0.369      |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.26       |
|    explained_variance   | 0.926      |
|    learning_rate        | 0.000268   |
|    loss                 | -0.00283   |
|    n_updates            | 43360      |
|    policy_gradient_loss | 0.00531    |
|    std                  | 0.0475     |
|    value_loss           | 0.00233    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4338       |
|    time_elapsed         | 14077      |
|    total_timesteps      | 8884224    |
| train/                  |            |
|    approx_kl            | 0.07817899 |
|    clip_fraction        | 0.386      |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.25       |
|    explained_variance   | 0.851      |
|    learning_rate        | 0.000268   |
|    loss                 | 0.0241     |
|    n_updates            | 43370      |
|    policy_gradient_loss | 0.0189     |
|    std                  | 0.0476     |
|    value_loss           | 0.00684    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4339       |
|    time_elapsed         | 14080      |
|    total_timesteps      | 8886272    |
| train/                  |            |
|    approx_kl            | 0.15681475 |
|    clip_fraction        | 0.353      |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.25       |
|    explained_variance   | 0.425      |
|    learning_rate        | 0.000268   |
|    loss                 | 0.0459     |
|    n_updates            | 43380      |
|    policy_gradient_loss | 0.0199     |
|    std                  | 0.0477     |
|    value_loss           | 0.00209    |
----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 631         |
|    iterations           | 4340        |
|    time_elapsed         | 14083       |
|    total_timesteps      | 8888320     |
| train/                  |             |
|    approx_kl            | 0.051891774 |
|    clip_fraction        | 0.342       |
|    clip_range           | 0.2         |
|    entropy_loss         | 3.26        |
|    explained_variance   | 0.816       |
|    learning_rate        | 0.000267    |
|    loss                 | 0.0105      |
|    n_updates            | 43390       |
|    policy_gradient_loss | 0.0114      |
|    std                  | 0.0474      |
|    value_loss           | 0.00779     |
-----------------------------------------
Eval num_timesteps=8890000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1         |
| time/                   |            |
|    total_timesteps      | 8890000    |
| train/                  |            |
|    approx_kl            | 0.17256036 |
|    clip_fraction        | 0.411      |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.26       |
|    explained_variance   | 0.742      |
|    learning_rate        | 0.000267   |
|    loss                 | -0.00724   |
|    n_updates            | 43400      |
|    policy_gradient_loss | 0.00557    |
|    std                  | 0.0477     |
|    value_loss           | 0.00648    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 4341    |
|    time_elapsed    | 14087   |
|    total_timesteps | 8890368 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4342       |
|    time_elapsed         | 14090      |
|    total_timesteps      | 8892416    |
| train/                  |            |
|    approx_kl            | 0.06710518 |
|    clip_fraction        | 0.364      |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.24       |
|    explained_variance   | 0.753      |
|    learning_rate        | 0.000266   |
|    loss                 | 0.0664     |
|    n_updates            | 43410      |
|    policy_gradient_loss | 0.0141     |
|    std                  | 0.0481     |
|    value_loss           | 0.00608    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4343       |
|    time_elapsed         | 14093      |
|    total_timesteps      | 8894464    |
| train/                  |            |
|    approx_kl            | 0.13043472 |
|    clip_fraction        | 0.332      |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.23       |
|    explained_variance   | 0.625      |
|    learning_rate        | 0.000266   |
|    loss                 | 0.09       |
|    n_updates            | 43420      |
|    policy_gradient_loss | 0.00413    |
|    std                  | 0.0482     |
|    value_loss           | 0.00345    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4344       |
|    time_elapsed         | 14096      |
|    total_timesteps      | 8896512    |
| train/                  |            |
|    approx_kl            | 0.23727083 |
|    clip_fraction        | 0.384      |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.23       |
|    explained_variance   | 0.786      |
|    learning_rate        | 0.000266   |
|    loss                 | -0.0317    |
|    n_updates            | 43430      |
|    policy_gradient_loss | 0.016      |
|    std                  | 0.0483     |
|    value_loss           | 0.00169    |
----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 4345      |
|    time_elapsed         | 14099     |
|    total_timesteps      | 8898560   |
| train/                  |           |
|    approx_kl            | 0.2822619 |
|    clip_fraction        | 0.421     |
|    clip_range           | 0.2       |
|    entropy_loss         | 3.23      |
|    explained_variance   | 0.408     |
|    learning_rate        | 0.000265  |
|    loss                 | -0.005    |
|    n_updates            | 43440     |
|    policy_gradient_loss | 0.0107    |
|    std                  | 0.0484    |
|    value_loss           | 0.00145   |
---------------------------------------
box reached target
Eval num_timesteps=8900000, episode_reward=0.22 +/- 2.45
Episode length: 278.20 +/- 43.60
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 278        |
|    mean_reward          | 0.225      |
| time/                   |            |
|    total_timesteps      | 8900000    |
| train/                  |            |
|    approx_kl            | 0.31889352 |
|    clip_fraction        | 0.371      |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.22       |
|    explained_variance   | 0.378      |
|    learning_rate        | 0.000265   |
|    loss                 | -0.0623    |
|    n_updates            | 43450      |
|    policy_gradient_loss | 0.00745    |
|    std                  | 0.0484     |
|    value_loss           | 0.00147    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 4346    |
|    time_elapsed    | 14103   |
|    total_timesteps | 8900608 |
--------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 4347      |
|    time_elapsed         | 14106     |
|    total_timesteps      | 8902656   |
| train/                  |           |
|    approx_kl            | 0.3710909 |
|    clip_fraction        | 0.374     |
|    clip_range           | 0.2       |
|    entropy_loss         | 3.22      |
|    explained_variance   | 0.338     |
|    learning_rate        | 0.000264  |
|    loss                 | -0.00311  |
|    n_updates            | 43460     |
|    policy_gradient_loss | 0.00337   |
|    std                  | 0.0487    |
|    value_loss           | 0.00139   |
---------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 4348      |
|    time_elapsed         | 14109     |
|    total_timesteps      | 8904704   |
| train/                  |           |
|    approx_kl            | 0.2777119 |
|    clip_fraction        | 0.332     |
|    clip_range           | 0.2       |
|    entropy_loss         | 3.22      |
|    explained_variance   | 0.184     |
|    learning_rate        | 0.000264  |
|    loss                 | 0.0322    |
|    n_updates            | 43470     |
|    policy_gradient_loss | -0.00824  |
|    std                  | 0.0485    |
|    value_loss           | 0.000995  |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4349       |
|    time_elapsed         | 14112      |
|    total_timesteps      | 8906752    |
| train/                  |            |
|    approx_kl            | 0.26506114 |
|    clip_fraction        | 0.396      |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.23       |
|    explained_variance   | 0.899      |
|    learning_rate        | 0.000264   |
|    loss                 | -0.0151    |
|    n_updates            | 43480      |
|    policy_gradient_loss | 0.0192     |
|    std                  | 0.048      |
|    value_loss           | 0.0098     |
----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 631         |
|    iterations           | 4350        |
|    time_elapsed         | 14115       |
|    total_timesteps      | 8908800     |
| train/                  |             |
|    approx_kl            | 0.078822955 |
|    clip_fraction        | 0.342       |
|    clip_range           | 0.2         |
|    entropy_loss         | 3.25        |
|    explained_variance   | 0.496       |
|    learning_rate        | 0.000263    |
|    loss                 | -0.0254     |
|    n_updates            | 43490       |
|    policy_gradient_loss | 0.00235     |
|    std                  | 0.0473      |
|    value_loss           | 0.000885    |
-----------------------------------------
Eval num_timesteps=8910000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1         |
| time/                   |            |
|    total_timesteps      | 8910000    |
| train/                  |            |
|    approx_kl            | 0.11517656 |
|    clip_fraction        | 0.427      |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.26       |
|    explained_variance   | 0.657      |
|    learning_rate        | 0.000263   |
|    loss                 | -0.00225   |
|    n_updates            | 43500      |
|    policy_gradient_loss | 0.0251     |
|    std                  | 0.0478     |
|    value_loss           | 0.00166    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 4351    |
|    time_elapsed    | 14119   |
|    total_timesteps | 8910848 |
--------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4352       |
|    time_elapsed         | 14123      |
|    total_timesteps      | 8912896    |
| train/                  |            |
|    approx_kl            | 0.18089205 |
|    clip_fraction        | 0.415      |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.24       |
|    explained_variance   | 0.726      |
|    learning_rate        | 0.000262   |
|    loss                 | -0.0109    |
|    n_updates            | 43510      |
|    policy_gradient_loss | 0.0127     |
|    std                  | 0.048      |
|    value_loss           | 0.00128    |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4353       |
|    time_elapsed         | 14126      |
|    total_timesteps      | 8914944    |
| train/                  |            |
|    approx_kl            | 0.46887022 |
|    clip_fraction        | 0.423      |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.25       |
|    explained_variance   | 0.392      |
|    learning_rate        | 0.000262   |
|    loss                 | 0.129      |
|    n_updates            | 43520      |
|    policy_gradient_loss | 0.0112     |
|    std                  | 0.0477     |
|    value_loss           | 0.0455     |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4354       |
|    time_elapsed         | 14129      |
|    total_timesteps      | 8916992    |
| train/                  |            |
|    approx_kl            | 0.29961753 |
|    clip_fraction        | 0.391      |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.26       |
|    explained_variance   | 0.959      |
|    learning_rate        | 0.000262   |
|    loss                 | 0.0726     |
|    n_updates            | 43530      |
|    policy_gradient_loss | 0.00896    |
|    std                  | 0.0471     |
|    value_loss           | 0.00733    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4355       |
|    time_elapsed         | 14132      |
|    total_timesteps      | 8919040    |
| train/                  |            |
|    approx_kl            | 0.14657383 |
|    clip_fraction        | 0.379      |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.28       |
|    explained_variance   | 0.693      |
|    learning_rate        | 0.000261   |
|    loss                 | 0.0168     |
|    n_updates            | 43540      |
|    policy_gradient_loss | 0.0113     |
|    std                  | 0.0469     |
|    value_loss           | 0.000981   |
----------------------------------------
Eval num_timesteps=8920000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1         |
| time/                   |            |
|    total_timesteps      | 8920000    |
| train/                  |            |
|    approx_kl            | 0.23480698 |
|    clip_fraction        | 0.387      |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.29       |
|    explained_variance   | 0.822      |
|    learning_rate        | 0.000261   |
|    loss                 | -0.00377   |
|    n_updates            | 43550      |
|    policy_gradient_loss | 0.00874    |
|    std                  | 0.0469     |
|    value_loss           | 0.00318    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 4356    |
|    time_elapsed    | 14136   |
|    total_timesteps | 8921088 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4357       |
|    time_elapsed         | 14139      |
|    total_timesteps      | 8923136    |
| train/                  |            |
|    approx_kl            | 0.08525872 |
|    clip_fraction        | 0.35       |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.28       |
|    explained_variance   | 0.603      |
|    learning_rate        | 0.00026    |
|    loss                 | -0.0199    |
|    n_updates            | 43560      |
|    policy_gradient_loss | 0.015      |
|    std                  | 0.0471     |
|    value_loss           | 0.00278    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4358       |
|    time_elapsed         | 14142      |
|    total_timesteps      | 8925184    |
| train/                  |            |
|    approx_kl            | 0.20784834 |
|    clip_fraction        | 0.373      |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.28       |
|    explained_variance   | 0.738      |
|    learning_rate        | 0.00026    |
|    loss                 | 0.0339     |
|    n_updates            | 43570      |
|    policy_gradient_loss | 0.0188     |
|    std                  | 0.0469     |
|    value_loss           | 0.000781   |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4359       |
|    time_elapsed         | 14145      |
|    total_timesteps      | 8927232    |
| train/                  |            |
|    approx_kl            | 0.69718796 |
|    clip_fraction        | 0.389      |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.3        |
|    explained_variance   | 0.699      |
|    learning_rate        | 0.00026    |
|    loss                 | -0.0404    |
|    n_updates            | 43580      |
|    policy_gradient_loss | 0.0143     |
|    std                  | 0.0463     |
|    value_loss           | 0.000776   |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4360       |
|    time_elapsed         | 14148      |
|    total_timesteps      | 8929280    |
| train/                  |            |
|    approx_kl            | 0.28432688 |
|    clip_fraction        | 0.43       |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.3        |
|    explained_variance   | 0.821      |
|    learning_rate        | 0.000259   |
|    loss                 | 0.00826    |
|    n_updates            | 43590      |
|    policy_gradient_loss | 0.00881    |
|    std                  | 0.0465     |
|    value_loss           | 0.00279    |
----------------------------------------
Eval num_timesteps=8930000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1         |
| time/                   |            |
|    total_timesteps      | 8930000    |
| train/                  |            |
|    approx_kl            | 0.44920552 |
|    clip_fraction        | 0.352      |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.32       |
|    explained_variance   | 0.648      |
|    learning_rate        | 0.000259   |
|    loss                 | -0.0472    |
|    n_updates            | 43600      |
|    policy_gradient_loss | 0.00277    |
|    std                  | 0.0457     |
|    value_loss           | 0.0011     |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 4361    |
|    time_elapsed    | 14152   |
|    total_timesteps | 8931328 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4362       |
|    time_elapsed         | 14155      |
|    total_timesteps      | 8933376    |
| train/                  |            |
|    approx_kl            | 0.17105958 |
|    clip_fraction        | 0.415      |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.34       |
|    explained_variance   | 0.566      |
|    learning_rate        | 0.000258   |
|    loss                 | -0.0437    |
|    n_updates            | 43610      |
|    policy_gradient_loss | 0.00109    |
|    std                  | 0.0456     |
|    value_loss           | 0.00205    |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4363       |
|    time_elapsed         | 14158      |
|    total_timesteps      | 8935424    |
| train/                  |            |
|    approx_kl            | 0.18323861 |
|    clip_fraction        | 0.45       |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.34       |
|    explained_variance   | 0.864      |
|    learning_rate        | 0.000258   |
|    loss                 | 0.0347     |
|    n_updates            | 43620      |
|    policy_gradient_loss | 0.00278    |
|    std                  | 0.0457     |
|    value_loss           | 0.00183    |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4364       |
|    time_elapsed         | 14161      |
|    total_timesteps      | 8937472    |
| train/                  |            |
|    approx_kl            | 0.13739622 |
|    clip_fraction        | 0.434      |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.32       |
|    explained_variance   | 0.625      |
|    learning_rate        | 0.000258   |
|    loss                 | 0.0179     |
|    n_updates            | 43630      |
|    policy_gradient_loss | 0.0105     |
|    std                  | 0.0464     |
|    value_loss           | 0.0514     |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4365       |
|    time_elapsed         | 14164      |
|    total_timesteps      | 8939520    |
| train/                  |            |
|    approx_kl            | 0.25711882 |
|    clip_fraction        | 0.431      |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.28       |
|    explained_variance   | 0.93       |
|    learning_rate        | 0.000257   |
|    loss                 | 0.108      |
|    n_updates            | 43640      |
|    policy_gradient_loss | 0.00808    |
|    std                  | 0.0472     |
|    value_loss           | 0.0147     |
----------------------------------------
Eval num_timesteps=8940000, episode_reward=-0.82 +/- 0.36
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -0.82      |
| time/                   |            |
|    total_timesteps      | 8940000    |
| train/                  |            |
|    approx_kl            | 0.23129827 |
|    clip_fraction        | 0.396      |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.27       |
|    explained_variance   | 0.707      |
|    learning_rate        | 0.000257   |
|    loss                 | 0.0708     |
|    n_updates            | 43650      |
|    policy_gradient_loss | -0.00135   |
|    std                  | 0.0472     |
|    value_loss           | 0.000757   |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 4366    |
|    time_elapsed    | 14168   |
|    total_timesteps | 8941568 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4367       |
|    time_elapsed         | 14171      |
|    total_timesteps      | 8943616    |
| train/                  |            |
|    approx_kl            | 0.21822809 |
|    clip_fraction        | 0.437      |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.27       |
|    explained_variance   | 0.535      |
|    learning_rate        | 0.000256   |
|    loss                 | -0.0184    |
|    n_updates            | 43660      |
|    policy_gradient_loss | 0.0108     |
|    std                  | 0.0474     |
|    value_loss           | 0.003      |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4368       |
|    time_elapsed         | 14174      |
|    total_timesteps      | 8945664    |
| train/                  |            |
|    approx_kl            | 0.09826833 |
|    clip_fraction        | 0.371      |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.26       |
|    explained_variance   | 0.392      |
|    learning_rate        | 0.000256   |
|    loss                 | 0.269      |
|    n_updates            | 43670      |
|    policy_gradient_loss | 0.0175     |
|    std                  | 0.0475     |
|    value_loss           | 0.00117    |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4369       |
|    time_elapsed         | 14177      |
|    total_timesteps      | 8947712    |
| train/                  |            |
|    approx_kl            | 0.13573329 |
|    clip_fraction        | 0.348      |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.27       |
|    explained_variance   | 0.527      |
|    learning_rate        | 0.000256   |
|    loss                 | -0.0271    |
|    n_updates            | 43680      |
|    policy_gradient_loss | 0.00522    |
|    std                  | 0.0472     |
|    value_loss           | 0.000978   |
----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 4370      |
|    time_elapsed         | 14180     |
|    total_timesteps      | 8949760   |
| train/                  |           |
|    approx_kl            | 2.8174722 |
|    clip_fraction        | 0.551     |
|    clip_range           | 0.2       |
|    entropy_loss         | 3.26      |
|    explained_variance   | 0.0575    |
|    learning_rate        | 0.000255  |
|    loss                 | -0.0218   |
|    n_updates            | 43690     |
|    policy_gradient_loss | 0.0267    |
|    std                  | 0.0476    |
|    value_loss           | 0.0458    |
---------------------------------------
box reached target
Eval num_timesteps=8950000, episode_reward=0.24 +/- 2.48
Episode length: 267.60 +/- 64.80
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 268        |
|    mean_reward          | 0.239      |
| time/                   |            |
|    total_timesteps      | 8950000    |
| train/                  |            |
|    approx_kl            | 0.31844229 |
|    clip_fraction        | 0.4        |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.26       |
|    explained_variance   | 0.569      |
|    learning_rate        | 0.000255   |
|    loss                 | -0.00841   |
|    n_updates            | 43700      |
|    policy_gradient_loss | -0.00427   |
|    std                  | 0.0471     |
|    value_loss           | 0.00239    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 4371    |
|    time_elapsed    | 14184   |
|    total_timesteps | 8951808 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4372       |
|    time_elapsed         | 14187      |
|    total_timesteps      | 8953856    |
| train/                  |            |
|    approx_kl            | 0.19305688 |
|    clip_fraction        | 0.411      |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.26       |
|    explained_variance   | 0.246      |
|    learning_rate        | 0.000254   |
|    loss                 | -0.0403    |
|    n_updates            | 43710      |
|    policy_gradient_loss | 0.0115     |
|    std                  | 0.0477     |
|    value_loss           | 0.00453    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4373       |
|    time_elapsed         | 14190      |
|    total_timesteps      | 8955904    |
| train/                  |            |
|    approx_kl            | 0.26798522 |
|    clip_fraction        | 0.382      |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.25       |
|    explained_variance   | 0.692      |
|    learning_rate        | 0.000254   |
|    loss                 | -0.0213    |
|    n_updates            | 43720      |
|    policy_gradient_loss | -0.00854   |
|    std                  | 0.0476     |
|    value_loss           | 0.00331    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4374       |
|    time_elapsed         | 14193      |
|    total_timesteps      | 8957952    |
| train/                  |            |
|    approx_kl            | 0.12757851 |
|    clip_fraction        | 0.331      |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.27       |
|    explained_variance   | 0.667      |
|    learning_rate        | 0.000254   |
|    loss                 | 0.0137     |
|    n_updates            | 43730      |
|    policy_gradient_loss | 0.00483    |
|    std                  | 0.0469     |
|    value_loss           | 0.000914   |
----------------------------------------
Eval num_timesteps=8960000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1         |
| time/                   |            |
|    total_timesteps      | 8960000    |
| train/                  |            |
|    approx_kl            | 0.17178029 |
|    clip_fraction        | 0.362      |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.28       |
|    explained_variance   | 0.392      |
|    learning_rate        | 0.000253   |
|    loss                 | 0.00163    |
|    n_updates            | 43740      |
|    policy_gradient_loss | 0.0115     |
|    std                  | 0.0471     |
|    value_loss           | 0.00206    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 4375    |
|    time_elapsed    | 14197   |
|    total_timesteps | 8960000 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4376       |
|    time_elapsed         | 14200      |
|    total_timesteps      | 8962048    |
| train/                  |            |
|    approx_kl            | 0.15828858 |
|    clip_fraction        | 0.385      |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.29       |
|    explained_variance   | 0.75       |
|    learning_rate        | 0.000253   |
|    loss                 | -0.022     |
|    n_updates            | 43750      |
|    policy_gradient_loss | 0.00798    |
|    std                  | 0.0465     |
|    value_loss           | 0.00652    |
----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 631         |
|    iterations           | 4377        |
|    time_elapsed         | 14203       |
|    total_timesteps      | 8964096     |
| train/                  |             |
|    approx_kl            | 0.060530026 |
|    clip_fraction        | 0.343       |
|    clip_range           | 0.2         |
|    entropy_loss         | 3.3         |
|    explained_variance   | 0.631       |
|    learning_rate        | 0.000252    |
|    loss                 | -0.0374     |
|    n_updates            | 43760       |
|    policy_gradient_loss | 0.00291     |
|    std                  | 0.0465      |
|    value_loss           | 0.000933    |
-----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4378       |
|    time_elapsed         | 14207      |
|    total_timesteps      | 8966144    |
| train/                  |            |
|    approx_kl            | 0.28739977 |
|    clip_fraction        | 0.406      |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.31       |
|    explained_variance   | 0.746      |
|    learning_rate        | 0.000252   |
|    loss                 | -0.0242    |
|    n_updates            | 43770      |
|    policy_gradient_loss | 0.00103    |
|    std                  | 0.0462     |
|    value_loss           | 0.00379    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4379       |
|    time_elapsed         | 14210      |
|    total_timesteps      | 8968192    |
| train/                  |            |
|    approx_kl            | 0.35685736 |
|    clip_fraction        | 0.439      |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.32       |
|    explained_variance   | 0.473      |
|    learning_rate        | 0.000252   |
|    loss                 | 0.0346     |
|    n_updates            | 43780      |
|    policy_gradient_loss | 0.0231     |
|    std                  | 0.0459     |
|    value_loss           | 0.00185    |
----------------------------------------
Eval num_timesteps=8970000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1         |
| time/                   |            |
|    total_timesteps      | 8970000    |
| train/                  |            |
|    approx_kl            | 0.51293623 |
|    clip_fraction        | 0.429      |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.33       |
|    explained_variance   | 0.71       |
|    learning_rate        | 0.000251   |
|    loss                 | -0.0347    |
|    n_updates            | 43790      |
|    policy_gradient_loss | 0.00442    |
|    std                  | 0.0461     |
|    value_loss           | 0.000754   |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 4380    |
|    time_elapsed    | 14214   |
|    total_timesteps | 8970240 |
--------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 4381      |
|    time_elapsed         | 14217     |
|    total_timesteps      | 8972288   |
| train/                  |           |
|    approx_kl            | 1.5453053 |
|    clip_fraction        | 0.442     |
|    clip_range           | 0.2       |
|    entropy_loss         | 3.34      |
|    explained_variance   | 0.135     |
|    learning_rate        | 0.000251  |
|    loss                 | -0.00512  |
|    n_updates            | 43800     |
|    policy_gradient_loss | 0.0136    |
|    std                  | 0.0454    |
|    value_loss           | 0.00127   |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4382       |
|    time_elapsed         | 14220      |
|    total_timesteps      | 8974336    |
| train/                  |            |
|    approx_kl            | 0.57082117 |
|    clip_fraction        | 0.38       |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.35       |
|    explained_variance   | 0.771      |
|    learning_rate        | 0.00025    |
|    loss                 | 0.0573     |
|    n_updates            | 43810      |
|    policy_gradient_loss | 0.00758    |
|    std                  | 0.0456     |
|    value_loss           | 0.000897   |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4383       |
|    time_elapsed         | 14223      |
|    total_timesteps      | 8976384    |
| train/                  |            |
|    approx_kl            | 0.10885556 |
|    clip_fraction        | 0.406      |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.35       |
|    explained_variance   | 0.599      |
|    learning_rate        | 0.00025    |
|    loss                 | -0.0167    |
|    n_updates            | 43820      |
|    policy_gradient_loss | 0.00736    |
|    std                  | 0.0453     |
|    value_loss           | 0.001      |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4384       |
|    time_elapsed         | 14226      |
|    total_timesteps      | 8978432    |
| train/                  |            |
|    approx_kl            | 0.25396407 |
|    clip_fraction        | 0.326      |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.36       |
|    explained_variance   | 0.732      |
|    learning_rate        | 0.00025    |
|    loss                 | -0.0193    |
|    n_updates            | 43830      |
|    policy_gradient_loss | 0.0169     |
|    std                  | 0.0451     |
|    value_loss           | 0.000775   |
----------------------------------------
Eval num_timesteps=8980000, episode_reward=-0.73 +/- 0.54
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -0.732     |
| time/                   |            |
|    total_timesteps      | 8980000    |
| train/                  |            |
|    approx_kl            | 0.54165596 |
|    clip_fraction        | 0.406      |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.36       |
|    explained_variance   | 0.532      |
|    learning_rate        | 0.000249   |
|    loss                 | -0.0299    |
|    n_updates            | 43840      |
|    policy_gradient_loss | 0.00131    |
|    std                  | 0.0453     |
|    value_loss           | 0.00108    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 4385    |
|    time_elapsed    | 14230   |
|    total_timesteps | 8980480 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4386       |
|    time_elapsed         | 14233      |
|    total_timesteps      | 8982528    |
| train/                  |            |
|    approx_kl            | 0.19943675 |
|    clip_fraction        | 0.365      |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.36       |
|    explained_variance   | 0.755      |
|    learning_rate        | 0.000249   |
|    loss                 | -0.0243    |
|    n_updates            | 43850      |
|    policy_gradient_loss | 0.005      |
|    std                  | 0.0452     |
|    value_loss           | 0.000768   |
----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 4387      |
|    time_elapsed         | 14236     |
|    total_timesteps      | 8984576   |
| train/                  |           |
|    approx_kl            | 1.2035671 |
|    clip_fraction        | 0.398     |
|    clip_range           | 0.2       |
|    entropy_loss         | 3.35      |
|    explained_variance   | 0.694     |
|    learning_rate        | 0.000248  |
|    loss                 | 0.0039    |
|    n_updates            | 43860     |
|    policy_gradient_loss | 0.0327    |
|    std                  | 0.0454    |
|    value_loss           | 0.00102   |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4388       |
|    time_elapsed         | 14239      |
|    total_timesteps      | 8986624    |
| train/                  |            |
|    approx_kl            | 0.14880064 |
|    clip_fraction        | 0.332      |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.36       |
|    explained_variance   | 0.62       |
|    learning_rate        | 0.000248   |
|    loss                 | -0.000456  |
|    n_updates            | 43870      |
|    policy_gradient_loss | -0.00567   |
|    std                  | 0.045      |
|    value_loss           | 0.000976   |
----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 4389      |
|    time_elapsed         | 14242     |
|    total_timesteps      | 8988672   |
| train/                  |           |
|    approx_kl            | 0.2997362 |
|    clip_fraction        | 0.37      |
|    clip_range           | 0.2       |
|    entropy_loss         | 3.37      |
|    explained_variance   | 0.571     |
|    learning_rate        | 0.000248  |
|    loss                 | -0.0505   |
|    n_updates            | 43880     |
|    policy_gradient_loss | 0.000964  |
|    std                  | 0.0448    |
|    value_loss           | 0.0011    |
---------------------------------------
Eval num_timesteps=8990000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 300       |
|    mean_reward          | -1        |
| time/                   |           |
|    total_timesteps      | 8990000   |
| train/                  |           |
|    approx_kl            | 0.2739544 |
|    clip_fraction        | 0.377     |
|    clip_range           | 0.2       |
|    entropy_loss         | 3.38      |
|    explained_variance   | 0.69      |
|    learning_rate        | 0.000247  |
|    loss                 | 0.00952   |
|    n_updates            | 43890     |
|    policy_gradient_loss | 0.0119    |
|    std                  | 0.0447    |
|    value_loss           | 0.00114   |
---------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 4390    |
|    time_elapsed    | 14246   |
|    total_timesteps | 8990720 |
--------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 4391      |
|    time_elapsed         | 14249     |
|    total_timesteps      | 8992768   |
| train/                  |           |
|    approx_kl            | 0.2051091 |
|    clip_fraction        | 0.407     |
|    clip_range           | 0.2       |
|    entropy_loss         | 3.39      |
|    explained_variance   | 0.577     |
|    learning_rate        | 0.000247  |
|    loss                 | 0.00247   |
|    n_updates            | 43900     |
|    policy_gradient_loss | -0.00217  |
|    std                  | 0.0446    |
|    value_loss           | 0.0011    |
---------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4392       |
|    time_elapsed         | 14252      |
|    total_timesteps      | 8994816    |
| train/                  |            |
|    approx_kl            | 0.21743473 |
|    clip_fraction        | 0.394      |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.38       |
|    explained_variance   | 0.669      |
|    learning_rate        | 0.000246   |
|    loss                 | -0.0274    |
|    n_updates            | 43910      |
|    policy_gradient_loss | 0.00457    |
|    std                  | 0.0448     |
|    value_loss           | 0.00111    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4393       |
|    time_elapsed         | 14255      |
|    total_timesteps      | 8996864    |
| train/                  |            |
|    approx_kl            | 0.25707388 |
|    clip_fraction        | 0.401      |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.39       |
|    explained_variance   | 0.948      |
|    learning_rate        | 0.000246   |
|    loss                 | -0.0189    |
|    n_updates            | 43920      |
|    policy_gradient_loss | 0.0155     |
|    std                  | 0.0444     |
|    value_loss           | 0.00453    |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4394       |
|    time_elapsed         | 14258      |
|    total_timesteps      | 8998912    |
| train/                  |            |
|    approx_kl            | 0.14735979 |
|    clip_fraction        | 0.391      |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.39       |
|    explained_variance   | 0.42       |
|    learning_rate        | 0.000246   |
|    loss                 | 0.115      |
|    n_updates            | 43930      |
|    policy_gradient_loss | 0.0162     |
|    std                  | 0.0445     |
|    value_loss           | 0.00108    |
----------------------------------------
Eval num_timesteps=9000000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1         |
| time/                   |            |
|    total_timesteps      | 9000000    |
| train/                  |            |
|    approx_kl            | 0.23603037 |
|    clip_fraction        | 0.378      |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.4        |
|    explained_variance   | -0.00564   |
|    learning_rate        | 0.000245   |
|    loss                 | -0.0275    |
|    n_updates            | 43940      |
|    policy_gradient_loss | 0.0309     |
|    std                  | 0.0442     |
|    value_loss           | 0.0866     |
----------------------------------------
box reached target
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 4395    |
|    time_elapsed    | 14262   |
|    total_timesteps | 9000960 |
--------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4396       |
|    time_elapsed         | 14265      |
|    total_timesteps      | 9003008    |
| train/                  |            |
|    approx_kl            | 0.08345645 |
|    clip_fraction        | 0.354      |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.41       |
|    explained_variance   | 0.439      |
|    learning_rate        | 0.000245   |
|    loss                 | 0.00774    |
|    n_updates            | 43950      |
|    policy_gradient_loss | 0.00879    |
|    std                  | 0.0439     |
|    value_loss           | 0.0362     |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4397       |
|    time_elapsed         | 14268      |
|    total_timesteps      | 9005056    |
| train/                  |            |
|    approx_kl            | 0.16565067 |
|    clip_fraction        | 0.426      |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.43       |
|    explained_variance   | 0.615      |
|    learning_rate        | 0.000244   |
|    loss                 | 0.0353     |
|    n_updates            | 43960      |
|    policy_gradient_loss | 0.0125     |
|    std                  | 0.0433     |
|    value_loss           | 0.0503     |
----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 4398      |
|    time_elapsed         | 14271     |
|    total_timesteps      | 9007104   |
| train/                  |           |
|    approx_kl            | 2.3930805 |
|    clip_fraction        | 0.4       |
|    clip_range           | 0.2       |
|    entropy_loss         | 3.44      |
|    explained_variance   | 0.51      |
|    learning_rate        | 0.000244  |
|    loss                 | -0.0239   |
|    n_updates            | 43970     |
|    policy_gradient_loss | -0.00346  |
|    std                  | 0.0432    |
|    value_loss           | 0.00635   |
---------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 4399      |
|    time_elapsed         | 14274     |
|    total_timesteps      | 9009152   |
| train/                  |           |
|    approx_kl            | 0.4469963 |
|    clip_fraction        | 0.377     |
|    clip_range           | 0.2       |
|    entropy_loss         | 3.44      |
|    explained_variance   | 0.532     |
|    learning_rate        | 0.000244  |
|    loss                 | 0.00832   |
|    n_updates            | 43980     |
|    policy_gradient_loss | -0.00794  |
|    std                  | 0.0436    |
|    value_loss           | 0.00246   |
---------------------------------------
Eval num_timesteps=9010000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 300       |
|    mean_reward          | -1        |
| time/                   |           |
|    total_timesteps      | 9010000   |
| train/                  |           |
|    approx_kl            | 0.7093662 |
|    clip_fraction        | 0.458     |
|    clip_range           | 0.2       |
|    entropy_loss         | 3.43      |
|    explained_variance   | 0.953     |
|    learning_rate        | 0.000243  |
|    loss                 | -0.0193   |
|    n_updates            | 43990     |
|    policy_gradient_loss | 0.00716   |
|    std                  | 0.0437    |
|    value_loss           | 0.00583   |
---------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 4400    |
|    time_elapsed    | 14278   |
|    total_timesteps | 9011200 |
--------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 4401      |
|    time_elapsed         | 14281     |
|    total_timesteps      | 9013248   |
| train/                  |           |
|    approx_kl            | 0.2332411 |
|    clip_fraction        | 0.327     |
|    clip_range           | 0.2       |
|    entropy_loss         | 3.43      |
|    explained_variance   | 0.333     |
|    learning_rate        | 0.000243  |
|    loss                 | 0.0182    |
|    n_updates            | 44000     |
|    policy_gradient_loss | -0.00713  |
|    std                  | 0.0435    |
|    value_loss           | 0.00155   |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4402       |
|    time_elapsed         | 14285      |
|    total_timesteps      | 9015296    |
| train/                  |            |
|    approx_kl            | 0.13947833 |
|    clip_fraction        | 0.334      |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.43       |
|    explained_variance   | 0.389      |
|    learning_rate        | 0.000242   |
|    loss                 | -0.000814  |
|    n_updates            | 44010      |
|    policy_gradient_loss | 0.0127     |
|    std                  | 0.0436     |
|    value_loss           | 0.00211    |
----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 4403      |
|    time_elapsed         | 14288     |
|    total_timesteps      | 9017344   |
| train/                  |           |
|    approx_kl            | 0.5051097 |
|    clip_fraction        | 0.399     |
|    clip_range           | 0.2       |
|    entropy_loss         | 3.45      |
|    explained_variance   | 0.405     |
|    learning_rate        | 0.000242  |
|    loss                 | -0.0487   |
|    n_updates            | 44020     |
|    policy_gradient_loss | 0.00378   |
|    std                  | 0.043     |
|    value_loss           | 0.00264   |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4404       |
|    time_elapsed         | 14291      |
|    total_timesteps      | 9019392    |
| train/                  |            |
|    approx_kl            | 0.21108282 |
|    clip_fraction        | 0.416      |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.45       |
|    explained_variance   | 0.848      |
|    learning_rate        | 0.000242   |
|    loss                 | 0.00725    |
|    n_updates            | 44030      |
|    policy_gradient_loss | 0.014      |
|    std                  | 0.0434     |
|    value_loss           | 0.00246    |
----------------------------------------
box reached target
Eval num_timesteps=9020000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1         |
| time/                   |            |
|    total_timesteps      | 9020000    |
| train/                  |            |
|    approx_kl            | 0.15508977 |
|    clip_fraction        | 0.366      |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.44       |
|    explained_variance   | 0.838      |
|    learning_rate        | 0.000241   |
|    loss                 | -0.0247    |
|    n_updates            | 44040      |
|    policy_gradient_loss | -0.0022    |
|    std                  | 0.0433     |
|    value_loss           | 0.00256    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 4405    |
|    time_elapsed    | 14295   |
|    total_timesteps | 9021440 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4406       |
|    time_elapsed         | 14298      |
|    total_timesteps      | 9023488    |
| train/                  |            |
|    approx_kl            | 0.18733999 |
|    clip_fraction        | 0.415      |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.46       |
|    explained_variance   | 0.553      |
|    learning_rate        | 0.000241   |
|    loss                 | 0.0428     |
|    n_updates            | 44050      |
|    policy_gradient_loss | 0.00382    |
|    std                  | 0.043      |
|    value_loss           | 0.0318     |
----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 4407      |
|    time_elapsed         | 14301     |
|    total_timesteps      | 9025536   |
| train/                  |           |
|    approx_kl            | 0.6114597 |
|    clip_fraction        | 0.45      |
|    clip_range           | 0.2       |
|    entropy_loss         | 3.46      |
|    explained_variance   | 0.593     |
|    learning_rate        | 0.00024   |
|    loss                 | -0.0496   |
|    n_updates            | 44060     |
|    policy_gradient_loss | 0.0128    |
|    std                  | 0.043     |
|    value_loss           | 0.00517   |
---------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 4408      |
|    time_elapsed         | 14304     |
|    total_timesteps      | 9027584   |
| train/                  |           |
|    approx_kl            | 0.2010877 |
|    clip_fraction        | 0.414     |
|    clip_range           | 0.2       |
|    entropy_loss         | 3.47      |
|    explained_variance   | 0.69      |
|    learning_rate        | 0.00024   |
|    loss                 | 0.0117    |
|    n_updates            | 44070     |
|    policy_gradient_loss | 0.00521   |
|    std                  | 0.043     |
|    value_loss           | 0.00582   |
---------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 4409      |
|    time_elapsed         | 14307     |
|    total_timesteps      | 9029632   |
| train/                  |           |
|    approx_kl            | 0.2398893 |
|    clip_fraction        | 0.408     |
|    clip_range           | 0.2       |
|    entropy_loss         | 3.47      |
|    explained_variance   | 0.656     |
|    learning_rate        | 0.00024   |
|    loss                 | -0.0202   |
|    n_updates            | 44080     |
|    policy_gradient_loss | 0.00951   |
|    std                  | 0.0427    |
|    value_loss           | 0.00126   |
---------------------------------------
Eval num_timesteps=9030000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1         |
| time/                   |            |
|    total_timesteps      | 9030000    |
| train/                  |            |
|    approx_kl            | 0.26263317 |
|    clip_fraction        | 0.406      |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.49       |
|    explained_variance   | 0.955      |
|    learning_rate        | 0.000239   |
|    loss                 | -0.0034    |
|    n_updates            | 44090      |
|    policy_gradient_loss | -0.00189   |
|    std                  | 0.0424     |
|    value_loss           | 0.0112     |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 4410    |
|    time_elapsed    | 14311   |
|    total_timesteps | 9031680 |
--------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 4411      |
|    time_elapsed         | 14314     |
|    total_timesteps      | 9033728   |
| train/                  |           |
|    approx_kl            | 0.3182064 |
|    clip_fraction        | 0.365     |
|    clip_range           | 0.2       |
|    entropy_loss         | 3.5       |
|    explained_variance   | 0.547     |
|    learning_rate        | 0.000239  |
|    loss                 | 0.00518   |
|    n_updates            | 44100     |
|    policy_gradient_loss | -0.00522  |
|    std                  | 0.042     |
|    value_loss           | 0.00202   |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4412       |
|    time_elapsed         | 14317      |
|    total_timesteps      | 9035776    |
| train/                  |            |
|    approx_kl            | 0.49315292 |
|    clip_fraction        | 0.422      |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.5        |
|    explained_variance   | 0.447      |
|    learning_rate        | 0.000238   |
|    loss                 | -0.0054    |
|    n_updates            | 44110      |
|    policy_gradient_loss | 0.0319     |
|    std                  | 0.0423     |
|    value_loss           | 0.00228    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4413       |
|    time_elapsed         | 14321      |
|    total_timesteps      | 9037824    |
| train/                  |            |
|    approx_kl            | 0.24897802 |
|    clip_fraction        | 0.367      |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.5        |
|    explained_variance   | 0.762      |
|    learning_rate        | 0.000238   |
|    loss                 | 0.0291     |
|    n_updates            | 44120      |
|    policy_gradient_loss | 0.0268     |
|    std                  | 0.0419     |
|    value_loss           | 0.00129    |
----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 631         |
|    iterations           | 4414        |
|    time_elapsed         | 14324       |
|    total_timesteps      | 9039872     |
| train/                  |             |
|    approx_kl            | 0.122634165 |
|    clip_fraction        | 0.394       |
|    clip_range           | 0.2         |
|    entropy_loss         | 3.51        |
|    explained_variance   | 0.878       |
|    learning_rate        | 0.000238    |
|    loss                 | -0.00334    |
|    n_updates            | 44130       |
|    policy_gradient_loss | 0.00801     |
|    std                  | 0.0423      |
|    value_loss           | 0.00409     |
-----------------------------------------
Eval num_timesteps=9040000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1         |
| time/                   |            |
|    total_timesteps      | 9040000    |
| train/                  |            |
|    approx_kl            | 0.17947486 |
|    clip_fraction        | 0.363      |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.49       |
|    explained_variance   | 0.733      |
|    learning_rate        | 0.000237   |
|    loss                 | -0.000844  |
|    n_updates            | 44140      |
|    policy_gradient_loss | -0.00948   |
|    std                  | 0.0423     |
|    value_loss           | 0.00103    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 4415    |
|    time_elapsed    | 14328   |
|    total_timesteps | 9041920 |
--------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4416       |
|    time_elapsed         | 14331      |
|    total_timesteps      | 9043968    |
| train/                  |            |
|    approx_kl            | 0.15980054 |
|    clip_fraction        | 0.402      |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.49       |
|    explained_variance   | 0.55       |
|    learning_rate        | 0.000237   |
|    loss                 | 0.0213     |
|    n_updates            | 44150      |
|    policy_gradient_loss | 0.00901    |
|    std                  | 0.0425     |
|    value_loss           | 0.00169    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4417       |
|    time_elapsed         | 14334      |
|    total_timesteps      | 9046016    |
| train/                  |            |
|    approx_kl            | 0.17785093 |
|    clip_fraction        | 0.376      |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.5        |
|    explained_variance   | 0.946      |
|    learning_rate        | 0.000236   |
|    loss                 | 0.0442     |
|    n_updates            | 44160      |
|    policy_gradient_loss | 0.00261    |
|    std                  | 0.0419     |
|    value_loss           | 0.00642    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4418       |
|    time_elapsed         | 14337      |
|    total_timesteps      | 9048064    |
| train/                  |            |
|    approx_kl            | 0.21030222 |
|    clip_fraction        | 0.396      |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.5        |
|    explained_variance   | 0.725      |
|    learning_rate        | 0.000236   |
|    loss                 | -0.0406    |
|    n_updates            | 44170      |
|    policy_gradient_loss | 0.0433     |
|    std                  | 0.0422     |
|    value_loss           | 0.00222    |
----------------------------------------
box reached target
Eval num_timesteps=9050000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 300       |
|    mean_reward          | -1        |
| time/                   |           |
|    total_timesteps      | 9050000   |
| train/                  |           |
|    approx_kl            | 0.1129849 |
|    clip_fraction        | 0.374     |
|    clip_range           | 0.2       |
|    entropy_loss         | 3.49      |
|    explained_variance   | 0.784     |
|    learning_rate        | 0.000236  |
|    loss                 | 0.0338    |
|    n_updates            | 44180     |
|    policy_gradient_loss | 0.00177   |
|    std                  | 0.0427    |
|    value_loss           | 0.00265   |
---------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 4419    |
|    time_elapsed    | 14341   |
|    total_timesteps | 9050112 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4420       |
|    time_elapsed         | 14344      |
|    total_timesteps      | 9052160    |
| train/                  |            |
|    approx_kl            | 0.20668338 |
|    clip_fraction        | 0.435      |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.48       |
|    explained_variance   | 0.164      |
|    learning_rate        | 0.000235   |
|    loss                 | 0.0371     |
|    n_updates            | 44190      |
|    policy_gradient_loss | 0.0128     |
|    std                  | 0.0425     |
|    value_loss           | 0.0474     |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4421       |
|    time_elapsed         | 14347      |
|    total_timesteps      | 9054208    |
| train/                  |            |
|    approx_kl            | 0.13659129 |
|    clip_fraction        | 0.411      |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.48       |
|    explained_variance   | 0.639      |
|    learning_rate        | 0.000235   |
|    loss                 | -0.0372    |
|    n_updates            | 44200      |
|    policy_gradient_loss | 0.00425    |
|    std                  | 0.0428     |
|    value_loss           | 0.00187    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4422       |
|    time_elapsed         | 14350      |
|    total_timesteps      | 9056256    |
| train/                  |            |
|    approx_kl            | 0.24866968 |
|    clip_fraction        | 0.343      |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.48       |
|    explained_variance   | 0.602      |
|    learning_rate        | 0.000234   |
|    loss                 | 9.34e-05   |
|    n_updates            | 44210      |
|    policy_gradient_loss | -0.00164   |
|    std                  | 0.0423     |
|    value_loss           | 0.00135    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4423       |
|    time_elapsed         | 14353      |
|    total_timesteps      | 9058304    |
| train/                  |            |
|    approx_kl            | 0.08248228 |
|    clip_fraction        | 0.336      |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.49       |
|    explained_variance   | 0.808      |
|    learning_rate        | 0.000234   |
|    loss                 | -0.0351    |
|    n_updates            | 44220      |
|    policy_gradient_loss | 0.012      |
|    std                  | 0.0423     |
|    value_loss           | 0.000782   |
----------------------------------------
Eval num_timesteps=9060000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1         |
| time/                   |            |
|    total_timesteps      | 9060000    |
| train/                  |            |
|    approx_kl            | 0.21882051 |
|    clip_fraction        | 0.385      |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.49       |
|    explained_variance   | 0.574      |
|    learning_rate        | 0.000234   |
|    loss                 | 0.0277     |
|    n_updates            | 44230      |
|    policy_gradient_loss | 0.0104     |
|    std                  | 0.0424     |
|    value_loss           | 0.00343    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 4424    |
|    time_elapsed    | 14357   |
|    total_timesteps | 9060352 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4425       |
|    time_elapsed         | 14360      |
|    total_timesteps      | 9062400    |
| train/                  |            |
|    approx_kl            | 0.17598899 |
|    clip_fraction        | 0.411      |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.48       |
|    explained_variance   | 0.724      |
|    learning_rate        | 0.000233   |
|    loss                 | 0.027      |
|    n_updates            | 44240      |
|    policy_gradient_loss | 0.00746    |
|    std                  | 0.0427     |
|    value_loss           | 0.00435    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4426       |
|    time_elapsed         | 14363      |
|    total_timesteps      | 9064448    |
| train/                  |            |
|    approx_kl            | 0.22906324 |
|    clip_fraction        | 0.419      |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.47       |
|    explained_variance   | 0.673      |
|    learning_rate        | 0.000233   |
|    loss                 | -0.00342   |
|    n_updates            | 44250      |
|    policy_gradient_loss | 0.013      |
|    std                  | 0.0427     |
|    value_loss           | 0.0013     |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4427       |
|    time_elapsed         | 14366      |
|    total_timesteps      | 9066496    |
| train/                  |            |
|    approx_kl            | 0.40309253 |
|    clip_fraction        | 0.381      |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.49       |
|    explained_variance   | 0.565      |
|    learning_rate        | 0.000232   |
|    loss                 | -0.0275    |
|    n_updates            | 44260      |
|    policy_gradient_loss | -0.00541   |
|    std                  | 0.0421     |
|    value_loss           | 0.0014     |
----------------------------------------
box reached target
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 4428      |
|    time_elapsed         | 14369     |
|    total_timesteps      | 9068544   |
| train/                  |           |
|    approx_kl            | 0.4445964 |
|    clip_fraction        | 0.379     |
|    clip_range           | 0.2       |
|    entropy_loss         | 3.51      |
|    explained_variance   | 0.602     |
|    learning_rate        | 0.000232  |
|    loss                 | -0.018    |
|    n_updates            | 44270     |
|    policy_gradient_loss | 0.00214   |
|    std                  | 0.0417    |
|    value_loss           | 0.00116   |
---------------------------------------
box reached target
Eval num_timesteps=9070000, episode_reward=0.26 +/- 2.52
Episode length: 282.60 +/- 34.80
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 283        |
|    mean_reward          | 0.258      |
| time/                   |            |
|    total_timesteps      | 9070000    |
| train/                  |            |
|    approx_kl            | 0.19933353 |
|    clip_fraction        | 0.443      |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.53       |
|    explained_variance   | 0.76       |
|    learning_rate        | 0.000232   |
|    loss                 | 0.0978     |
|    n_updates            | 44280      |
|    policy_gradient_loss | 0.0118     |
|    std                  | 0.0415     |
|    value_loss           | 0.0309     |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 4429    |
|    time_elapsed    | 14373   |
|    total_timesteps | 9070592 |
--------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 4430      |
|    time_elapsed         | 14376     |
|    total_timesteps      | 9072640   |
| train/                  |           |
|    approx_kl            | 0.3776435 |
|    clip_fraction        | 0.411     |
|    clip_range           | 0.2       |
|    entropy_loss         | 3.52      |
|    explained_variance   | 0.632     |
|    learning_rate        | 0.000231  |
|    loss                 | -0.00815  |
|    n_updates            | 44290     |
|    policy_gradient_loss | 0.0127    |
|    std                  | 0.0418    |
|    value_loss           | 0.0014    |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4431       |
|    time_elapsed         | 14379      |
|    total_timesteps      | 9074688    |
| train/                  |            |
|    approx_kl            | 0.20502973 |
|    clip_fraction        | 0.434      |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.52       |
|    explained_variance   | 0.756      |
|    learning_rate        | 0.000231   |
|    loss                 | 0.109      |
|    n_updates            | 44300      |
|    policy_gradient_loss | 0.013      |
|    std                  | 0.0419     |
|    value_loss           | 0.00574    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4432       |
|    time_elapsed         | 14382      |
|    total_timesteps      | 9076736    |
| train/                  |            |
|    approx_kl            | 0.16557863 |
|    clip_fraction        | 0.406      |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.51       |
|    explained_variance   | 0.815      |
|    learning_rate        | 0.00023    |
|    loss                 | -0.0231    |
|    n_updates            | 44310      |
|    policy_gradient_loss | 0.0121     |
|    std                  | 0.0419     |
|    value_loss           | 0.00358    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4433       |
|    time_elapsed         | 14385      |
|    total_timesteps      | 9078784    |
| train/                  |            |
|    approx_kl            | 0.07254422 |
|    clip_fraction        | 0.382      |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.5        |
|    explained_variance   | 0.845      |
|    learning_rate        | 0.00023    |
|    loss                 | 0.00326    |
|    n_updates            | 44320      |
|    policy_gradient_loss | 0.00609    |
|    std                  | 0.0423     |
|    value_loss           | 0.00248    |
----------------------------------------
Eval num_timesteps=9080000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1         |
| time/                   |            |
|    total_timesteps      | 9080000    |
| train/                  |            |
|    approx_kl            | 0.15891425 |
|    clip_fraction        | 0.341      |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.5        |
|    explained_variance   | 0.613      |
|    learning_rate        | 0.00023    |
|    loss                 | 0.0356     |
|    n_updates            | 44330      |
|    policy_gradient_loss | 0.00103    |
|    std                  | 0.0419     |
|    value_loss           | 0.00317    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 4434    |
|    time_elapsed    | 14389   |
|    total_timesteps | 9080832 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4435       |
|    time_elapsed         | 14392      |
|    total_timesteps      | 9082880    |
| train/                  |            |
|    approx_kl            | 0.21389636 |
|    clip_fraction        | 0.374      |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.51       |
|    explained_variance   | 0.37       |
|    learning_rate        | 0.000229   |
|    loss                 | 0.00812    |
|    n_updates            | 44340      |
|    policy_gradient_loss | 0.00726    |
|    std                  | 0.0419     |
|    value_loss           | 0.000915   |
----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 631         |
|    iterations           | 4436        |
|    time_elapsed         | 14395       |
|    total_timesteps      | 9084928     |
| train/                  |             |
|    approx_kl            | 0.115725145 |
|    clip_fraction        | 0.352       |
|    clip_range           | 0.2         |
|    entropy_loss         | 3.5         |
|    explained_variance   | 0.761       |
|    learning_rate        | 0.000229    |
|    loss                 | 0.0255      |
|    n_updates            | 44350       |
|    policy_gradient_loss | -0.000924   |
|    std                  | 0.0421      |
|    value_loss           | 0.00511     |
-----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 4437      |
|    time_elapsed         | 14398     |
|    total_timesteps      | 9086976   |
| train/                  |           |
|    approx_kl            | 0.2097118 |
|    clip_fraction        | 0.41      |
|    clip_range           | 0.2       |
|    entropy_loss         | 3.51      |
|    explained_variance   | 0.375     |
|    learning_rate        | 0.000228  |
|    loss                 | 0.000263  |
|    n_updates            | 44360     |
|    policy_gradient_loss | -0.00757  |
|    std                  | 0.0415    |
|    value_loss           | 0.0011    |
---------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 4438      |
|    time_elapsed         | 14402     |
|    total_timesteps      | 9089024   |
| train/                  |           |
|    approx_kl            | 0.7407989 |
|    clip_fraction        | 0.377     |
|    clip_range           | 0.2       |
|    entropy_loss         | 3.54      |
|    explained_variance   | 0.529     |
|    learning_rate        | 0.000228  |
|    loss                 | 0.0503    |
|    n_updates            | 44370     |
|    policy_gradient_loss | 0.0118    |
|    std                  | 0.0412    |
|    value_loss           | 0.00111   |
---------------------------------------
Eval num_timesteps=9090000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1         |
| time/                   |            |
|    total_timesteps      | 9090000    |
| train/                  |            |
|    approx_kl            | 0.24889776 |
|    clip_fraction        | 0.43       |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.54       |
|    explained_variance   | 0.75       |
|    learning_rate        | 0.000228   |
|    loss                 | 9.42e-05   |
|    n_updates            | 44380      |
|    policy_gradient_loss | -0.0016    |
|    std                  | 0.0412     |
|    value_loss           | 0.000755   |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 4439    |
|    time_elapsed    | 14406   |
|    total_timesteps | 9091072 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4440       |
|    time_elapsed         | 14409      |
|    total_timesteps      | 9093120    |
| train/                  |            |
|    approx_kl            | 0.16499852 |
|    clip_fraction        | 0.373      |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.54       |
|    explained_variance   | 0.442      |
|    learning_rate        | 0.000227   |
|    loss                 | 0.0495     |
|    n_updates            | 44390      |
|    policy_gradient_loss | 0.00306    |
|    std                  | 0.0412     |
|    value_loss           | 0.00189    |
----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 4441      |
|    time_elapsed         | 14412     |
|    total_timesteps      | 9095168   |
| train/                  |           |
|    approx_kl            | 0.3445654 |
|    clip_fraction        | 0.431     |
|    clip_range           | 0.2       |
|    entropy_loss         | 3.55      |
|    explained_variance   | 0.744     |
|    learning_rate        | 0.000227  |
|    loss                 | -0.0261   |
|    n_updates            | 44400     |
|    policy_gradient_loss | 0.0111    |
|    std                  | 0.0411    |
|    value_loss           | 0.00132   |
---------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 631         |
|    iterations           | 4442        |
|    time_elapsed         | 14415       |
|    total_timesteps      | 9097216     |
| train/                  |             |
|    approx_kl            | 0.062326677 |
|    clip_fraction        | 0.333       |
|    clip_range           | 0.2         |
|    entropy_loss         | 3.56        |
|    explained_variance   | 0.529       |
|    learning_rate        | 0.000226    |
|    loss                 | -0.0198     |
|    n_updates            | 44410       |
|    policy_gradient_loss | 0.0127      |
|    std                  | 0.041       |
|    value_loss           | 0.00177     |
-----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4443       |
|    time_elapsed         | 14418      |
|    total_timesteps      | 9099264    |
| train/                  |            |
|    approx_kl            | 0.12035262 |
|    clip_fraction        | 0.371      |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.55       |
|    explained_variance   | 0.466      |
|    learning_rate        | 0.000226   |
|    loss                 | 0.000535   |
|    n_updates            | 44420      |
|    policy_gradient_loss | 0.00681    |
|    std                  | 0.0412     |
|    value_loss           | 0.00118    |
----------------------------------------
box reached target
Eval num_timesteps=9100000, episode_reward=-0.68 +/- 0.63
Episode length: 300.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 300       |
|    mean_reward          | -0.684    |
| time/                   |           |
|    total_timesteps      | 9100000   |
| train/                  |           |
|    approx_kl            | 0.1262745 |
|    clip_fraction        | 0.407     |
|    clip_range           | 0.2       |
|    entropy_loss         | 3.56      |
|    explained_variance   | 0.75      |
|    learning_rate        | 0.000226  |
|    loss                 | -0.0353   |
|    n_updates            | 44430     |
|    policy_gradient_loss | 0.00905   |
|    std                  | 0.0409    |
|    value_loss           | 0.00123   |
---------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 4444    |
|    time_elapsed    | 14422   |
|    total_timesteps | 9101312 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4445       |
|    time_elapsed         | 14425      |
|    total_timesteps      | 9103360    |
| train/                  |            |
|    approx_kl            | 0.13792977 |
|    clip_fraction        | 0.418      |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.56       |
|    explained_variance   | 0.607      |
|    learning_rate        | 0.000225   |
|    loss                 | 0.0756     |
|    n_updates            | 44440      |
|    policy_gradient_loss | 0.022      |
|    std                  | 0.0408     |
|    value_loss           | 0.00337    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4446       |
|    time_elapsed         | 14428      |
|    total_timesteps      | 9105408    |
| train/                  |            |
|    approx_kl            | 0.26044893 |
|    clip_fraction        | 0.355      |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.57       |
|    explained_variance   | 0.628      |
|    learning_rate        | 0.000225   |
|    loss                 | -0.0033    |
|    n_updates            | 44450      |
|    policy_gradient_loss | 0.0016     |
|    std                  | 0.0405     |
|    value_loss           | 0.000974   |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4447       |
|    time_elapsed         | 14431      |
|    total_timesteps      | 9107456    |
| train/                  |            |
|    approx_kl            | 0.19738412 |
|    clip_fraction        | 0.446      |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.58       |
|    explained_variance   | 0.569      |
|    learning_rate        | 0.000224   |
|    loss                 | 0.0228     |
|    n_updates            | 44460      |
|    policy_gradient_loss | 0.00317    |
|    std                  | 0.0404     |
|    value_loss           | 0.00129    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4448       |
|    time_elapsed         | 14434      |
|    total_timesteps      | 9109504    |
| train/                  |            |
|    approx_kl            | 0.16294223 |
|    clip_fraction        | 0.356      |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.59       |
|    explained_variance   | 0.72       |
|    learning_rate        | 0.000224   |
|    loss                 | 0.0454     |
|    n_updates            | 44470      |
|    policy_gradient_loss | 0.00743    |
|    std                  | 0.0401     |
|    value_loss           | 0.000634   |
----------------------------------------
Eval num_timesteps=9110000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1         |
| time/                   |            |
|    total_timesteps      | 9110000    |
| train/                  |            |
|    approx_kl            | 0.19132484 |
|    clip_fraction        | 0.375      |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.61       |
|    explained_variance   | 0.452      |
|    learning_rate        | 0.000224   |
|    loss                 | -0.00919   |
|    n_updates            | 44480      |
|    policy_gradient_loss | -0.00203   |
|    std                  | 0.0395     |
|    value_loss           | 0.000913   |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 4449    |
|    time_elapsed    | 14438   |
|    total_timesteps | 9111552 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4450       |
|    time_elapsed         | 14441      |
|    total_timesteps      | 9113600    |
| train/                  |            |
|    approx_kl            | 0.53257585 |
|    clip_fraction        | 0.441      |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.62       |
|    explained_variance   | 0.73       |
|    learning_rate        | 0.000223   |
|    loss                 | -0.0262    |
|    n_updates            | 44490      |
|    policy_gradient_loss | 0.021      |
|    std                  | 0.0397     |
|    value_loss           | 0.000911   |
----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 4451      |
|    time_elapsed         | 14444     |
|    total_timesteps      | 9115648   |
| train/                  |           |
|    approx_kl            | 0.2305046 |
|    clip_fraction        | 0.386     |
|    clip_range           | 0.2       |
|    entropy_loss         | 3.63      |
|    explained_variance   | 0.697     |
|    learning_rate        | 0.000223  |
|    loss                 | 0.0139    |
|    n_updates            | 44500     |
|    policy_gradient_loss | 0.00906   |
|    std                  | 0.0395    |
|    value_loss           | 0.000957  |
---------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4452       |
|    time_elapsed         | 14447      |
|    total_timesteps      | 9117696    |
| train/                  |            |
|    approx_kl            | 0.28344792 |
|    clip_fraction        | 0.401      |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.64       |
|    explained_variance   | 0.637      |
|    learning_rate        | 0.000222   |
|    loss                 | 0.0283     |
|    n_updates            | 44510      |
|    policy_gradient_loss | -0.00021   |
|    std                  | 0.0391     |
|    value_loss           | 0.000884   |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4453       |
|    time_elapsed         | 14450      |
|    total_timesteps      | 9119744    |
| train/                  |            |
|    approx_kl            | 0.09698346 |
|    clip_fraction        | 0.438      |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.64       |
|    explained_variance   | 0.305      |
|    learning_rate        | 0.000222   |
|    loss                 | 0.119      |
|    n_updates            | 44520      |
|    policy_gradient_loss | 0.0268     |
|    std                  | 0.0396     |
|    value_loss           | 0.121      |
----------------------------------------
Eval num_timesteps=9120000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 300         |
|    mean_reward          | -1          |
| time/                   |             |
|    total_timesteps      | 9120000     |
| train/                  |             |
|    approx_kl            | 0.085849985 |
|    clip_fraction        | 0.396       |
|    clip_range           | 0.2         |
|    entropy_loss         | 3.63        |
|    explained_variance   | 0.698       |
|    learning_rate        | 0.000222    |
|    loss                 | 0.0326      |
|    n_updates            | 44530       |
|    policy_gradient_loss | 0.0129      |
|    std                  | 0.0394      |
|    value_loss           | 0.00124     |
-----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 4454    |
|    time_elapsed    | 14454   |
|    total_timesteps | 9121792 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4455       |
|    time_elapsed         | 14457      |
|    total_timesteps      | 9123840    |
| train/                  |            |
|    approx_kl            | 0.20550436 |
|    clip_fraction        | 0.407      |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.64       |
|    explained_variance   | 0.61       |
|    learning_rate        | 0.000221   |
|    loss                 | -0.00928   |
|    n_updates            | 44540      |
|    policy_gradient_loss | 0.0138     |
|    std                  | 0.0394     |
|    value_loss           | 0.00131    |
----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 4456      |
|    time_elapsed         | 14460     |
|    total_timesteps      | 9125888   |
| train/                  |           |
|    approx_kl            | 0.2088564 |
|    clip_fraction        | 0.368     |
|    clip_range           | 0.2       |
|    entropy_loss         | 3.65      |
|    explained_variance   | -0.114    |
|    learning_rate        | 0.000221  |
|    loss                 | -0.031    |
|    n_updates            | 44550     |
|    policy_gradient_loss | 0.0202    |
|    std                  | 0.039     |
|    value_loss           | 0.00148   |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4457       |
|    time_elapsed         | 14463      |
|    total_timesteps      | 9127936    |
| train/                  |            |
|    approx_kl            | 0.41684514 |
|    clip_fraction        | 0.427      |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.66       |
|    explained_variance   | 0.596      |
|    learning_rate        | 0.00022    |
|    loss                 | -0.0309    |
|    n_updates            | 44560      |
|    policy_gradient_loss | 0.00829    |
|    std                  | 0.0389     |
|    value_loss           | 0.00425    |
----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 4458      |
|    time_elapsed         | 14466     |
|    total_timesteps      | 9129984   |
| train/                  |           |
|    approx_kl            | 1.6636703 |
|    clip_fraction        | 0.395     |
|    clip_range           | 0.2       |
|    entropy_loss         | 3.66      |
|    explained_variance   | 0.756     |
|    learning_rate        | 0.00022   |
|    loss                 | 0.03      |
|    n_updates            | 44570     |
|    policy_gradient_loss | -0.000127 |
|    std                  | 0.0389    |
|    value_loss           | 0.00102   |
---------------------------------------
Eval num_timesteps=9130000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 300       |
|    mean_reward          | -1        |
| time/                   |           |
|    total_timesteps      | 9130000   |
| train/                  |           |
|    approx_kl            | 0.1653012 |
|    clip_fraction        | 0.354     |
|    clip_range           | 0.2       |
|    entropy_loss         | 3.65      |
|    explained_variance   | 0.775     |
|    learning_rate        | 0.00022   |
|    loss                 | -0.006    |
|    n_updates            | 44580     |
|    policy_gradient_loss | 0.00341   |
|    std                  | 0.0391    |
|    value_loss           | 0.000713  |
---------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 4459    |
|    time_elapsed    | 14470   |
|    total_timesteps | 9132032 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4460       |
|    time_elapsed         | 14473      |
|    total_timesteps      | 9134080    |
| train/                  |            |
|    approx_kl            | 0.12706381 |
|    clip_fraction        | 0.397      |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.65       |
|    explained_variance   | 0.762      |
|    learning_rate        | 0.000219   |
|    loss                 | -0.0234    |
|    n_updates            | 44590      |
|    policy_gradient_loss | 0.0046     |
|    std                  | 0.039      |
|    value_loss           | 0.000852   |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4461       |
|    time_elapsed         | 14476      |
|    total_timesteps      | 9136128    |
| train/                  |            |
|    approx_kl            | 0.36123052 |
|    clip_fraction        | 0.42       |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.67       |
|    explained_variance   | 0.452      |
|    learning_rate        | 0.000219   |
|    loss                 | 0.0706     |
|    n_updates            | 44600      |
|    policy_gradient_loss | 0.0163     |
|    std                  | 0.0383     |
|    value_loss           | 0.00142    |
----------------------------------------
box reached target
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4462       |
|    time_elapsed         | 14480      |
|    total_timesteps      | 9138176    |
| train/                  |            |
|    approx_kl            | 0.26046988 |
|    clip_fraction        | 0.46       |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.69       |
|    explained_variance   | 0.817      |
|    learning_rate        | 0.000218   |
|    loss                 | -0.0258    |
|    n_updates            | 44610      |
|    policy_gradient_loss | 0.0261     |
|    std                  | 0.0383     |
|    value_loss           | 0.00951    |
----------------------------------------
Eval num_timesteps=9140000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 300       |
|    mean_reward          | -1        |
| time/                   |           |
|    total_timesteps      | 9140000   |
| train/                  |           |
|    approx_kl            | 4.9916716 |
|    clip_fraction        | 0.526     |
|    clip_range           | 0.2       |
|    entropy_loss         | 3.69      |
|    explained_variance   | 0.878     |
|    learning_rate        | 0.000218  |
|    loss                 | 0.0275    |
|    n_updates            | 44620     |
|    policy_gradient_loss | 0.0183    |
|    std                  | 0.0383    |
|    value_loss           | 0.0478    |
---------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 4463    |
|    time_elapsed    | 14484   |
|    total_timesteps | 9140224 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4464       |
|    time_elapsed         | 14487      |
|    total_timesteps      | 9142272    |
| train/                  |            |
|    approx_kl            | 0.18468106 |
|    clip_fraction        | 0.419      |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.69       |
|    explained_variance   | 0.587      |
|    learning_rate        | 0.000218   |
|    loss                 | -0.0266    |
|    n_updates            | 44630      |
|    policy_gradient_loss | -0.000524  |
|    std                  | 0.0383     |
|    value_loss           | 0.0325     |
----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 4465      |
|    time_elapsed         | 14490     |
|    total_timesteps      | 9144320   |
| train/                  |           |
|    approx_kl            | 0.4146596 |
|    clip_fraction        | 0.492     |
|    clip_range           | 0.2       |
|    entropy_loss         | 3.68      |
|    explained_variance   | 0.553     |
|    learning_rate        | 0.000217  |
|    loss                 | 0.0828    |
|    n_updates            | 44640     |
|    policy_gradient_loss | 0.0215    |
|    std                  | 0.0386    |
|    value_loss           | 0.00397   |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4466       |
|    time_elapsed         | 14493      |
|    total_timesteps      | 9146368    |
| train/                  |            |
|    approx_kl            | 0.17261589 |
|    clip_fraction        | 0.378      |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.67       |
|    explained_variance   | 0.837      |
|    learning_rate        | 0.000217   |
|    loss                 | -0.0308    |
|    n_updates            | 44650      |
|    policy_gradient_loss | 0.0141     |
|    std                  | 0.0387     |
|    value_loss           | 0.000813   |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4467       |
|    time_elapsed         | 14496      |
|    total_timesteps      | 9148416    |
| train/                  |            |
|    approx_kl            | 0.27123863 |
|    clip_fraction        | 0.402      |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.67       |
|    explained_variance   | 0.0209     |
|    learning_rate        | 0.000216   |
|    loss                 | 0.0229     |
|    n_updates            | 44660      |
|    policy_gradient_loss | -0.0043    |
|    std                  | 0.0385     |
|    value_loss           | 0.0036     |
----------------------------------------
box reached target
Eval num_timesteps=9150000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1         |
| time/                   |            |
|    total_timesteps      | 9150000    |
| train/                  |            |
|    approx_kl            | 0.24238652 |
|    clip_fraction        | 0.476      |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.69       |
|    explained_variance   | 0.95       |
|    learning_rate        | 0.000216   |
|    loss                 | 0.0595     |
|    n_updates            | 44670      |
|    policy_gradient_loss | 0.02       |
|    std                  | 0.0382     |
|    value_loss           | 0.00914    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 4468    |
|    time_elapsed    | 14500   |
|    total_timesteps | 9150464 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4469       |
|    time_elapsed         | 14503      |
|    total_timesteps      | 9152512    |
| train/                  |            |
|    approx_kl            | 0.13735601 |
|    clip_fraction        | 0.429      |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.69       |
|    explained_variance   | 0.795      |
|    learning_rate        | 0.000216   |
|    loss                 | 0.00568    |
|    n_updates            | 44680      |
|    policy_gradient_loss | 0.0108     |
|    std                  | 0.0385     |
|    value_loss           | 0.027      |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4470       |
|    time_elapsed         | 14506      |
|    total_timesteps      | 9154560    |
| train/                  |            |
|    approx_kl            | 0.25635594 |
|    clip_fraction        | 0.393      |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.68       |
|    explained_variance   | 0.52       |
|    learning_rate        | 0.000215   |
|    loss                 | -0.0384    |
|    n_updates            | 44690      |
|    policy_gradient_loss | 0.00388    |
|    std                  | 0.0385     |
|    value_loss           | 0.00285    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4471       |
|    time_elapsed         | 14509      |
|    total_timesteps      | 9156608    |
| train/                  |            |
|    approx_kl            | 0.20175612 |
|    clip_fraction        | 0.365      |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.69       |
|    explained_variance   | 0.735      |
|    learning_rate        | 0.000215   |
|    loss                 | 0.0495     |
|    n_updates            | 44700      |
|    policy_gradient_loss | 0.0093     |
|    std                  | 0.0384     |
|    value_loss           | 0.00082    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4472       |
|    time_elapsed         | 14512      |
|    total_timesteps      | 9158656    |
| train/                  |            |
|    approx_kl            | 0.19198376 |
|    clip_fraction        | 0.369      |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.69       |
|    explained_variance   | 0.562      |
|    learning_rate        | 0.000214   |
|    loss                 | -0.00609   |
|    n_updates            | 44710      |
|    policy_gradient_loss | 0.0042     |
|    std                  | 0.0382     |
|    value_loss           | 0.00124    |
----------------------------------------
Eval num_timesteps=9160000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1         |
| time/                   |            |
|    total_timesteps      | 9160000    |
| train/                  |            |
|    approx_kl            | 0.23996037 |
|    clip_fraction        | 0.381      |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.7        |
|    explained_variance   | 0.721      |
|    learning_rate        | 0.000214   |
|    loss                 | 0.0516     |
|    n_updates            | 44720      |
|    policy_gradient_loss | 0.00623    |
|    std                  | 0.0383     |
|    value_loss           | 0.000642   |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 4473    |
|    time_elapsed    | 14516   |
|    total_timesteps | 9160704 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4474       |
|    time_elapsed         | 14519      |
|    total_timesteps      | 9162752    |
| train/                  |            |
|    approx_kl            | 0.18082166 |
|    clip_fraction        | 0.409      |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.68       |
|    explained_variance   | 0.52       |
|    learning_rate        | 0.000214   |
|    loss                 | -0.0223    |
|    n_updates            | 44730      |
|    policy_gradient_loss | 0.0128     |
|    std                  | 0.0386     |
|    value_loss           | 0.00324    |
----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 4475      |
|    time_elapsed         | 14522     |
|    total_timesteps      | 9164800   |
| train/                  |           |
|    approx_kl            | 0.1320646 |
|    clip_fraction        | 0.407     |
|    clip_range           | 0.2       |
|    entropy_loss         | 3.68      |
|    explained_variance   | 0.332     |
|    learning_rate        | 0.000213  |
|    loss                 | -0.0147   |
|    n_updates            | 44740     |
|    policy_gradient_loss | 0.00444   |
|    std                  | 0.0386    |
|    value_loss           | 0.00298   |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4476       |
|    time_elapsed         | 14525      |
|    total_timesteps      | 9166848    |
| train/                  |            |
|    approx_kl            | 0.12628855 |
|    clip_fraction        | 0.377      |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.69       |
|    explained_variance   | 0.578      |
|    learning_rate        | 0.000213   |
|    loss                 | -0.0216    |
|    n_updates            | 44750      |
|    policy_gradient_loss | 0.0105     |
|    std                  | 0.0383     |
|    value_loss           | 0.000938   |
----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 4477      |
|    time_elapsed         | 14528     |
|    total_timesteps      | 9168896   |
| train/                  |           |
|    approx_kl            | 0.5992729 |
|    clip_fraction        | 0.446     |
|    clip_range           | 0.2       |
|    entropy_loss         | 3.69      |
|    explained_variance   | 0.364     |
|    learning_rate        | 0.000212  |
|    loss                 | -0.0329   |
|    n_updates            | 44760     |
|    policy_gradient_loss | 0.0104    |
|    std                  | 0.0382    |
|    value_loss           | 0.0014    |
---------------------------------------
Eval num_timesteps=9170000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 300         |
|    mean_reward          | -1          |
| time/                   |             |
|    total_timesteps      | 9170000     |
| train/                  |             |
|    approx_kl            | 0.077285215 |
|    clip_fraction        | 0.353       |
|    clip_range           | 0.2         |
|    entropy_loss         | 3.69        |
|    explained_variance   | 0.683       |
|    learning_rate        | 0.000212    |
|    loss                 | -0.00854    |
|    n_updates            | 44770       |
|    policy_gradient_loss | 0.00972     |
|    std                  | 0.0383      |
|    value_loss           | 0.00214     |
-----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 4478    |
|    time_elapsed    | 14532   |
|    total_timesteps | 9170944 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4479       |
|    time_elapsed         | 14535      |
|    total_timesteps      | 9172992    |
| train/                  |            |
|    approx_kl            | 0.22717214 |
|    clip_fraction        | 0.423      |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.68       |
|    explained_variance   | 0.233      |
|    learning_rate        | 0.000212   |
|    loss                 | 0.0152     |
|    n_updates            | 44780      |
|    policy_gradient_loss | 0.0106     |
|    std                  | 0.0388     |
|    value_loss           | 0.0102     |
----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 631         |
|    iterations           | 4480        |
|    time_elapsed         | 14538       |
|    total_timesteps      | 9175040     |
| train/                  |             |
|    approx_kl            | 0.085867494 |
|    clip_fraction        | 0.351       |
|    clip_range           | 0.2         |
|    entropy_loss         | 3.67        |
|    explained_variance   | 0.712       |
|    learning_rate        | 0.000211    |
|    loss                 | -0.0184     |
|    n_updates            | 44790       |
|    policy_gradient_loss | 0.0115      |
|    std                  | 0.0388      |
|    value_loss           | 0.00102     |
-----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4481       |
|    time_elapsed         | 14541      |
|    total_timesteps      | 9177088    |
| train/                  |            |
|    approx_kl            | 0.13304141 |
|    clip_fraction        | 0.377      |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.68       |
|    explained_variance   | 0.576      |
|    learning_rate        | 0.000211   |
|    loss                 | -0.0212    |
|    n_updates            | 44800      |
|    policy_gradient_loss | 0.0144     |
|    std                  | 0.0384     |
|    value_loss           | 0.00162    |
----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 4482      |
|    time_elapsed         | 14544     |
|    total_timesteps      | 9179136   |
| train/                  |           |
|    approx_kl            | 0.1904764 |
|    clip_fraction        | 0.375     |
|    clip_range           | 0.2       |
|    entropy_loss         | 3.7       |
|    explained_variance   | 0.309     |
|    learning_rate        | 0.00021   |
|    loss                 | -0.0169   |
|    n_updates            | 44810     |
|    policy_gradient_loss | 0.0201    |
|    std                  | 0.038     |
|    value_loss           | 0.00107   |
---------------------------------------
box reached target
Eval num_timesteps=9180000, episode_reward=0.23 +/- 2.47
Episode length: 272.00 +/- 56.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 272       |
|    mean_reward          | 0.235     |
| time/                   |           |
|    total_timesteps      | 9180000   |
| train/                  |           |
|    approx_kl            | 0.6226613 |
|    clip_fraction        | 0.393     |
|    clip_range           | 0.2       |
|    entropy_loss         | 3.71      |
|    explained_variance   | 0.43      |
|    learning_rate        | 0.00021   |
|    loss                 | 0.00796   |
|    n_updates            | 44820     |
|    policy_gradient_loss | 0.0112    |
|    std                  | 0.0379    |
|    value_loss           | 0.00099   |
---------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 4483    |
|    time_elapsed    | 14548   |
|    total_timesteps | 9181184 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4484       |
|    time_elapsed         | 14551      |
|    total_timesteps      | 9183232    |
| train/                  |            |
|    approx_kl            | 0.19645102 |
|    clip_fraction        | 0.353      |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.73       |
|    explained_variance   | 0.622      |
|    learning_rate        | 0.00021    |
|    loss                 | 0.0618     |
|    n_updates            | 44830      |
|    policy_gradient_loss | 0.0209     |
|    std                  | 0.0375     |
|    value_loss           | 0.000962   |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4485       |
|    time_elapsed         | 14554      |
|    total_timesteps      | 9185280    |
| train/                  |            |
|    approx_kl            | 0.32256228 |
|    clip_fraction        | 0.365      |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.75       |
|    explained_variance   | 0.616      |
|    learning_rate        | 0.000209   |
|    loss                 | 0.0561     |
|    n_updates            | 44840      |
|    policy_gradient_loss | 0.000173   |
|    std                  | 0.0372     |
|    value_loss           | 0.000975   |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4486       |
|    time_elapsed         | 14557      |
|    total_timesteps      | 9187328    |
| train/                  |            |
|    approx_kl            | 0.30779022 |
|    clip_fraction        | 0.445      |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.75       |
|    explained_variance   | 0.677      |
|    learning_rate        | 0.000209   |
|    loss                 | 0.0255     |
|    n_updates            | 44850      |
|    policy_gradient_loss | 0.0131     |
|    std                  | 0.0374     |
|    value_loss           | 0.0011     |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4487       |
|    time_elapsed         | 14561      |
|    total_timesteps      | 9189376    |
| train/                  |            |
|    approx_kl            | 0.42786103 |
|    clip_fraction        | 0.439      |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.75       |
|    explained_variance   | 0.599      |
|    learning_rate        | 0.000208   |
|    loss                 | 0.0325     |
|    n_updates            | 44860      |
|    policy_gradient_loss | 0.0163     |
|    std                  | 0.0372     |
|    value_loss           | 0.0163     |
----------------------------------------
box reached target
Eval num_timesteps=9190000, episode_reward=0.21 +/- 2.43
Episode length: 276.00 +/- 48.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 276        |
|    mean_reward          | 0.215      |
| time/                   |            |
|    total_timesteps      | 9190000    |
| train/                  |            |
|    approx_kl            | 0.16938856 |
|    clip_fraction        | 0.429      |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.76       |
|    explained_variance   | 0.637      |
|    learning_rate        | 0.000208   |
|    loss                 | -0.0174    |
|    n_updates            | 44870      |
|    policy_gradient_loss | 0.00827    |
|    std                  | 0.0369     |
|    value_loss           | 0.00119    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 4488    |
|    time_elapsed    | 14564   |
|    total_timesteps | 9191424 |
--------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4489       |
|    time_elapsed         | 14567      |
|    total_timesteps      | 9193472    |
| train/                  |            |
|    approx_kl            | 0.41429055 |
|    clip_fraction        | 0.438      |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.77       |
|    explained_variance   | 0.733      |
|    learning_rate        | 0.000208   |
|    loss                 | 0.00726    |
|    n_updates            | 44880      |
|    policy_gradient_loss | 0.0213     |
|    std                  | 0.037      |
|    value_loss           | 0.000706   |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4490       |
|    time_elapsed         | 14571      |
|    total_timesteps      | 9195520    |
| train/                  |            |
|    approx_kl            | 0.22949243 |
|    clip_fraction        | 0.387      |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.79       |
|    explained_variance   | 0.816      |
|    learning_rate        | 0.000207   |
|    loss                 | 0.00292    |
|    n_updates            | 44890      |
|    policy_gradient_loss | 0.00583    |
|    std                  | 0.0364     |
|    value_loss           | 0.0107     |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4491       |
|    time_elapsed         | 14574      |
|    total_timesteps      | 9197568    |
| train/                  |            |
|    approx_kl            | 0.13596526 |
|    clip_fraction        | 0.332      |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.81       |
|    explained_variance   | 0.697      |
|    learning_rate        | 0.000207   |
|    loss                 | -0.00943   |
|    n_updates            | 44900      |
|    policy_gradient_loss | 0.00155    |
|    std                  | 0.0361     |
|    value_loss           | 0.0011     |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4492       |
|    time_elapsed         | 14577      |
|    total_timesteps      | 9199616    |
| train/                  |            |
|    approx_kl            | 0.17395252 |
|    clip_fraction        | 0.417      |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.81       |
|    explained_variance   | 0.859      |
|    learning_rate        | 0.000206   |
|    loss                 | -0.00854   |
|    n_updates            | 44910      |
|    policy_gradient_loss | 0.00895    |
|    std                  | 0.0363     |
|    value_loss           | 0.0108     |
----------------------------------------
Eval num_timesteps=9200000, episode_reward=-0.72 +/- 0.56
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -0.72      |
| time/                   |            |
|    total_timesteps      | 9200000    |
| train/                  |            |
|    approx_kl            | 0.26198256 |
|    clip_fraction        | 0.349      |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.82       |
|    explained_variance   | 0.703      |
|    learning_rate        | 0.000206   |
|    loss                 | 0.032      |
|    n_updates            | 44920      |
|    policy_gradient_loss | 0.000999   |
|    std                  | 0.036      |
|    value_loss           | 0.00104    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 4493    |
|    time_elapsed    | 14581   |
|    total_timesteps | 9201664 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4494       |
|    time_elapsed         | 14584      |
|    total_timesteps      | 9203712    |
| train/                  |            |
|    approx_kl            | 0.13934588 |
|    clip_fraction        | 0.397      |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.83       |
|    explained_variance   | 0.631      |
|    learning_rate        | 0.000206   |
|    loss                 | 0.0322     |
|    n_updates            | 44930      |
|    policy_gradient_loss | 0.00654    |
|    std                  | 0.0359     |
|    value_loss           | 0.00107    |
----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 4495      |
|    time_elapsed         | 14587     |
|    total_timesteps      | 9205760   |
| train/                  |           |
|    approx_kl            | 0.3146398 |
|    clip_fraction        | 0.408     |
|    clip_range           | 0.2       |
|    entropy_loss         | 3.83      |
|    explained_variance   | 0.745     |
|    learning_rate        | 0.000205  |
|    loss                 | -0.0284   |
|    n_updates            | 44940     |
|    policy_gradient_loss | 0.0174    |
|    std                  | 0.0356    |
|    value_loss           | 0.000855  |
---------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4496       |
|    time_elapsed         | 14590      |
|    total_timesteps      | 9207808    |
| train/                  |            |
|    approx_kl            | 0.17765568 |
|    clip_fraction        | 0.391      |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.85       |
|    explained_variance   | 0.633      |
|    learning_rate        | 0.000205   |
|    loss                 | -0.053     |
|    n_updates            | 44950      |
|    policy_gradient_loss | 0.0136     |
|    std                  | 0.0354     |
|    value_loss           | 0.000892   |
----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 4497      |
|    time_elapsed         | 14593     |
|    total_timesteps      | 9209856   |
| train/                  |           |
|    approx_kl            | 1.9874911 |
|    clip_fraction        | 0.552     |
|    clip_range           | 0.2       |
|    entropy_loss         | 3.86      |
|    explained_variance   | 0.619     |
|    learning_rate        | 0.000204  |
|    loss                 | -0.00345  |
|    n_updates            | 44960     |
|    policy_gradient_loss | 0.0232    |
|    std                  | 0.0354    |
|    value_loss           | 0.0352    |
---------------------------------------
Eval num_timesteps=9210000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1         |
| time/                   |            |
|    total_timesteps      | 9210000    |
| train/                  |            |
|    approx_kl            | 0.23095912 |
|    clip_fraction        | 0.361      |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.86       |
|    explained_variance   | 0.852      |
|    learning_rate        | 0.000204   |
|    loss                 | -0.0147    |
|    n_updates            | 44970      |
|    policy_gradient_loss | 0.0163     |
|    std                  | 0.0353     |
|    value_loss           | 0.000896   |
----------------------------------------
box reached target
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 4498    |
|    time_elapsed    | 14597   |
|    total_timesteps | 9211904 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4499       |
|    time_elapsed         | 14600      |
|    total_timesteps      | 9213952    |
| train/                  |            |
|    approx_kl            | 0.25197724 |
|    clip_fraction        | 0.404      |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.85       |
|    explained_variance   | 0.796      |
|    learning_rate        | 0.000204   |
|    loss                 | 0.0225     |
|    n_updates            | 44980      |
|    policy_gradient_loss | 0.00642    |
|    std                  | 0.0356     |
|    value_loss           | 0.0311     |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4500       |
|    time_elapsed         | 14603      |
|    total_timesteps      | 9216000    |
| train/                  |            |
|    approx_kl            | 0.14423339 |
|    clip_fraction        | 0.372      |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.84       |
|    explained_variance   | 0.464      |
|    learning_rate        | 0.000203   |
|    loss                 | 0.0617     |
|    n_updates            | 44990      |
|    policy_gradient_loss | 0.0018     |
|    std                  | 0.0357     |
|    value_loss           | 0.0013     |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4501       |
|    time_elapsed         | 14606      |
|    total_timesteps      | 9218048    |
| train/                  |            |
|    approx_kl            | 0.09690925 |
|    clip_fraction        | 0.376      |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.84       |
|    explained_variance   | 0.97       |
|    learning_rate        | 0.000203   |
|    loss                 | 0.0174     |
|    n_updates            | 45000      |
|    policy_gradient_loss | 0.0137     |
|    std                  | 0.0355     |
|    value_loss           | 0.00374    |
----------------------------------------
Eval num_timesteps=9220000, episode_reward=-0.72 +/- 0.56
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -0.718     |
| time/                   |            |
|    total_timesteps      | 9220000    |
| train/                  |            |
|    approx_kl            | 0.56360775 |
|    clip_fraction        | 0.451      |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.84       |
|    explained_variance   | 0.736      |
|    learning_rate        | 0.000202   |
|    loss                 | -0.0293    |
|    n_updates            | 45010      |
|    policy_gradient_loss | 0.0102     |
|    std                  | 0.0357     |
|    value_loss           | 0.00136    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 4502    |
|    time_elapsed    | 14610   |
|    total_timesteps | 9220096 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4503       |
|    time_elapsed         | 14613      |
|    total_timesteps      | 9222144    |
| train/                  |            |
|    approx_kl            | 0.41388595 |
|    clip_fraction        | 0.396      |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.83       |
|    explained_variance   | 0.616      |
|    learning_rate        | 0.000202   |
|    loss                 | -0.0261    |
|    n_updates            | 45020      |
|    policy_gradient_loss | 0.00787    |
|    std                  | 0.0356     |
|    value_loss           | 0.000892   |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4504       |
|    time_elapsed         | 14616      |
|    total_timesteps      | 9224192    |
| train/                  |            |
|    approx_kl            | 0.10936561 |
|    clip_fraction        | 0.391      |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.84       |
|    explained_variance   | 0.494      |
|    learning_rate        | 0.000202   |
|    loss                 | -0.0208    |
|    n_updates            | 45030      |
|    policy_gradient_loss | 0.0208     |
|    std                  | 0.0356     |
|    value_loss           | 0.00125    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4505       |
|    time_elapsed         | 14619      |
|    total_timesteps      | 9226240    |
| train/                  |            |
|    approx_kl            | 0.14984842 |
|    clip_fraction        | 0.363      |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.83       |
|    explained_variance   | 0.71       |
|    learning_rate        | 0.000201   |
|    loss                 | 0.00228    |
|    n_updates            | 45040      |
|    policy_gradient_loss | 0.00654    |
|    std                  | 0.0356     |
|    value_loss           | 0.0015     |
----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 631         |
|    iterations           | 4506        |
|    time_elapsed         | 14622       |
|    total_timesteps      | 9228288     |
| train/                  |             |
|    approx_kl            | 0.051483486 |
|    clip_fraction        | 0.348       |
|    clip_range           | 0.2         |
|    entropy_loss         | 3.85        |
|    explained_variance   | 0.69        |
|    learning_rate        | 0.000201    |
|    loss                 | 0.0157      |
|    n_updates            | 45050       |
|    policy_gradient_loss | 0.00314     |
|    std                  | 0.0352      |
|    value_loss           | 0.00117     |
-----------------------------------------
Eval num_timesteps=9230000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 300       |
|    mean_reward          | -1        |
| time/                   |           |
|    total_timesteps      | 9230000   |
| train/                  |           |
|    approx_kl            | 0.1601162 |
|    clip_fraction        | 0.342     |
|    clip_range           | 0.2       |
|    entropy_loss         | 3.86      |
|    explained_variance   | 0.739     |
|    learning_rate        | 0.0002    |
|    loss                 | 0.00708   |
|    n_updates            | 45060     |
|    policy_gradient_loss | 0.00538   |
|    std                  | 0.0353    |
|    value_loss           | 0.000936  |
---------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 4507    |
|    time_elapsed    | 14626   |
|    total_timesteps | 9230336 |
--------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 4508      |
|    time_elapsed         | 14629     |
|    total_timesteps      | 9232384   |
| train/                  |           |
|    approx_kl            | 0.1901479 |
|    clip_fraction        | 0.401     |
|    clip_range           | 0.2       |
|    entropy_loss         | 3.85      |
|    explained_variance   | 0.73      |
|    learning_rate        | 0.0002    |
|    loss                 | 0.0601    |
|    n_updates            | 45070     |
|    policy_gradient_loss | 0.00978   |
|    std                  | 0.0353    |
|    value_loss           | 0.00206   |
---------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 4509      |
|    time_elapsed         | 14632     |
|    total_timesteps      | 9234432   |
| train/                  |           |
|    approx_kl            | 0.1370793 |
|    clip_fraction        | 0.423     |
|    clip_range           | 0.2       |
|    entropy_loss         | 3.85      |
|    explained_variance   | 0.584     |
|    learning_rate        | 0.0002    |
|    loss                 | 0.158     |
|    n_updates            | 45080     |
|    policy_gradient_loss | 0.00895   |
|    std                  | 0.0355    |
|    value_loss           | 0.00566   |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4510       |
|    time_elapsed         | 14635      |
|    total_timesteps      | 9236480    |
| train/                  |            |
|    approx_kl            | 0.19273084 |
|    clip_fraction        | 0.444      |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.83       |
|    explained_variance   | 0.676      |
|    learning_rate        | 0.000199   |
|    loss                 | -0.0152    |
|    n_updates            | 45090      |
|    policy_gradient_loss | 0.00859    |
|    std                  | 0.0361     |
|    value_loss           | 0.0032     |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4511       |
|    time_elapsed         | 14638      |
|    total_timesteps      | 9238528    |
| train/                  |            |
|    approx_kl            | 0.55875707 |
|    clip_fraction        | 0.435      |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.81       |
|    explained_variance   | 0.787      |
|    learning_rate        | 0.000199   |
|    loss                 | -0.0326    |
|    n_updates            | 45100      |
|    policy_gradient_loss | 0.00646    |
|    std                  | 0.0361     |
|    value_loss           | 0.00215    |
----------------------------------------
Eval num_timesteps=9240000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1         |
| time/                   |            |
|    total_timesteps      | 9240000    |
| train/                  |            |
|    approx_kl            | 0.19176176 |
|    clip_fraction        | 0.363      |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.81       |
|    explained_variance   | 0.738      |
|    learning_rate        | 0.000198   |
|    loss                 | -0.0312    |
|    n_updates            | 45110      |
|    policy_gradient_loss | -0.0028    |
|    std                  | 0.036      |
|    value_loss           | 0.00315    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 4512    |
|    time_elapsed    | 14642   |
|    total_timesteps | 9240576 |
--------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 4513      |
|    time_elapsed         | 14646     |
|    total_timesteps      | 9242624   |
| train/                  |           |
|    approx_kl            | 0.1386139 |
|    clip_fraction        | 0.38      |
|    clip_range           | 0.2       |
|    entropy_loss         | 3.82      |
|    explained_variance   | 0.581     |
|    learning_rate        | 0.000198  |
|    loss                 | -0.0339   |
|    n_updates            | 45120     |
|    policy_gradient_loss | 0.00692   |
|    std                  | 0.0359    |
|    value_loss           | 0.000868  |
---------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 631         |
|    iterations           | 4514        |
|    time_elapsed         | 14649       |
|    total_timesteps      | 9244672     |
| train/                  |             |
|    approx_kl            | 0.115966275 |
|    clip_fraction        | 0.375       |
|    clip_range           | 0.2         |
|    entropy_loss         | 3.82        |
|    explained_variance   | 0.423       |
|    learning_rate        | 0.000198    |
|    loss                 | -0.0126     |
|    n_updates            | 45130       |
|    policy_gradient_loss | 0.0161      |
|    std                  | 0.0359      |
|    value_loss           | 0.000977    |
-----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4515       |
|    time_elapsed         | 14652      |
|    total_timesteps      | 9246720    |
| train/                  |            |
|    approx_kl            | 0.15499611 |
|    clip_fraction        | 0.377      |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.81       |
|    explained_variance   | 0.792      |
|    learning_rate        | 0.000197   |
|    loss                 | -0.0169    |
|    n_updates            | 45140      |
|    policy_gradient_loss | 0.00498    |
|    std                  | 0.0361     |
|    value_loss           | 0.000849   |
----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 4516      |
|    time_elapsed         | 14655     |
|    total_timesteps      | 9248768   |
| train/                  |           |
|    approx_kl            | 0.1992227 |
|    clip_fraction        | 0.358     |
|    clip_range           | 0.2       |
|    entropy_loss         | 3.82      |
|    explained_variance   | 0.626     |
|    learning_rate        | 0.000197  |
|    loss                 | -0.0299   |
|    n_updates            | 45150     |
|    policy_gradient_loss | 0.00404   |
|    std                  | 0.0359    |
|    value_loss           | 0.00126   |
---------------------------------------
box reached target
Eval num_timesteps=9250000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1         |
| time/                   |            |
|    total_timesteps      | 9250000    |
| train/                  |            |
|    approx_kl            | 0.22325325 |
|    clip_fraction        | 0.384      |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.82       |
|    explained_variance   | 0.809      |
|    learning_rate        | 0.000196   |
|    loss                 | -0.0473    |
|    n_updates            | 45160      |
|    policy_gradient_loss | 0.00649    |
|    std                  | 0.0359     |
|    value_loss           | 0.00266    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 4517    |
|    time_elapsed    | 14659   |
|    total_timesteps | 9250816 |
--------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 631         |
|    iterations           | 4518        |
|    time_elapsed         | 14662       |
|    total_timesteps      | 9252864     |
| train/                  |             |
|    approx_kl            | 0.088699125 |
|    clip_fraction        | 0.418       |
|    clip_range           | 0.2         |
|    entropy_loss         | 3.82        |
|    explained_variance   | 0.715       |
|    learning_rate        | 0.000196    |
|    loss                 | 0.0321      |
|    n_updates            | 45170       |
|    policy_gradient_loss | 0.00668     |
|    std                  | 0.0358      |
|    value_loss           | 0.0129      |
-----------------------------------------
box reached target
--------------------------------------
| time/                   |          |
|    fps                  | 631      |
|    iterations           | 4519     |
|    time_elapsed         | 14665    |
|    total_timesteps      | 9254912  |
| train/                  |          |
|    approx_kl            | 0.203595 |
|    clip_fraction        | 0.38     |
|    clip_range           | 0.2      |
|    entropy_loss         | 3.83     |
|    explained_variance   | 0.472    |
|    learning_rate        | 0.000196 |
|    loss                 | -0.0185  |
|    n_updates            | 45180    |
|    policy_gradient_loss | 0.0456   |
|    std                  | 0.0358   |
|    value_loss           | 0.0012   |
--------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 631         |
|    iterations           | 4520        |
|    time_elapsed         | 14668       |
|    total_timesteps      | 9256960     |
| train/                  |             |
|    approx_kl            | 0.096546605 |
|    clip_fraction        | 0.4         |
|    clip_range           | 0.2         |
|    entropy_loss         | 3.83        |
|    explained_variance   | 0.911       |
|    learning_rate        | 0.000195    |
|    loss                 | 0.0237      |
|    n_updates            | 45190       |
|    policy_gradient_loss | 0.0185      |
|    std                  | 0.0356      |
|    value_loss           | 0.0102      |
-----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4521       |
|    time_elapsed         | 14671      |
|    total_timesteps      | 9259008    |
| train/                  |            |
|    approx_kl            | 0.32365692 |
|    clip_fraction        | 0.379      |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.84       |
|    explained_variance   | 0.506      |
|    learning_rate        | 0.000195   |
|    loss                 | 0.0181     |
|    n_updates            | 45200      |
|    policy_gradient_loss | -0.00501   |
|    std                  | 0.0355     |
|    value_loss           | 0.00139    |
----------------------------------------
box reached target
Eval num_timesteps=9260000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 300         |
|    mean_reward          | -1          |
| time/                   |             |
|    total_timesteps      | 9260000     |
| train/                  |             |
|    approx_kl            | 0.100747615 |
|    clip_fraction        | 0.402       |
|    clip_range           | 0.2         |
|    entropy_loss         | 3.82        |
|    explained_variance   | 0.863       |
|    learning_rate        | 0.000194    |
|    loss                 | 0.0118      |
|    n_updates            | 45210       |
|    policy_gradient_loss | 0.0113      |
|    std                  | 0.0361      |
|    value_loss           | 0.0229      |
-----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 4522    |
|    time_elapsed    | 14675   |
|    total_timesteps | 9261056 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4523       |
|    time_elapsed         | 14678      |
|    total_timesteps      | 9263104    |
| train/                  |            |
|    approx_kl            | 0.10613769 |
|    clip_fraction        | 0.414      |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.81       |
|    explained_variance   | 0.918      |
|    learning_rate        | 0.000194   |
|    loss                 | -0.00925   |
|    n_updates            | 45220      |
|    policy_gradient_loss | 0.0221     |
|    std                  | 0.0362     |
|    value_loss           | 0.0111     |
----------------------------------------
box reached target
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 4524      |
|    time_elapsed         | 14681     |
|    total_timesteps      | 9265152   |
| train/                  |           |
|    approx_kl            | 0.3134947 |
|    clip_fraction        | 0.4       |
|    clip_range           | 0.2       |
|    entropy_loss         | 3.81      |
|    explained_variance   | 0.544     |
|    learning_rate        | 0.000194  |
|    loss                 | 0.00799   |
|    n_updates            | 45230     |
|    policy_gradient_loss | 0.0039    |
|    std                  | 0.0361    |
|    value_loss           | 0.0022    |
---------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4525       |
|    time_elapsed         | 14684      |
|    total_timesteps      | 9267200    |
| train/                  |            |
|    approx_kl            | 0.09852232 |
|    clip_fraction        | 0.433      |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.8        |
|    explained_variance   | 0.896      |
|    learning_rate        | 0.000193   |
|    loss                 | 0.0171     |
|    n_updates            | 45240      |
|    policy_gradient_loss | 0.0155     |
|    std                  | 0.0362     |
|    value_loss           | 0.0339     |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4526       |
|    time_elapsed         | 14687      |
|    total_timesteps      | 9269248    |
| train/                  |            |
|    approx_kl            | 0.10583951 |
|    clip_fraction        | 0.425      |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.81       |
|    explained_variance   | 0.64       |
|    learning_rate        | 0.000193   |
|    loss                 | 0.0728     |
|    n_updates            | 45250      |
|    policy_gradient_loss | 0.021      |
|    std                  | 0.0361     |
|    value_loss           | 0.0199     |
----------------------------------------
Eval num_timesteps=9270000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1         |
| time/                   |            |
|    total_timesteps      | 9270000    |
| train/                  |            |
|    approx_kl            | 0.17830928 |
|    clip_fraction        | 0.408      |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.81       |
|    explained_variance   | 0.96       |
|    learning_rate        | 0.000192   |
|    loss                 | 0.0224     |
|    n_updates            | 45260      |
|    policy_gradient_loss | 0.00551    |
|    std                  | 0.0361     |
|    value_loss           | 0.00975    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 4527    |
|    time_elapsed    | 14691   |
|    total_timesteps | 9271296 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4528       |
|    time_elapsed         | 14694      |
|    total_timesteps      | 9273344    |
| train/                  |            |
|    approx_kl            | 0.17776197 |
|    clip_fraction        | 0.4        |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.8        |
|    explained_variance   | 0.7        |
|    learning_rate        | 0.000192   |
|    loss                 | -0.0155    |
|    n_updates            | 45270      |
|    policy_gradient_loss | 0.0244     |
|    std                  | 0.0364     |
|    value_loss           | 0.0012     |
----------------------------------------
box reached target
--------------------------------------
| time/                   |          |
|    fps                  | 631      |
|    iterations           | 4529     |
|    time_elapsed         | 14697    |
|    total_timesteps      | 9275392  |
| train/                  |          |
|    approx_kl            | 0.191931 |
|    clip_fraction        | 0.423    |
|    clip_range           | 0.2      |
|    entropy_loss         | 3.8      |
|    explained_variance   | 0.594    |
|    learning_rate        | 0.000192 |
|    loss                 | -0.0338  |
|    n_updates            | 45280    |
|    policy_gradient_loss | 0.00887  |
|    std                  | 0.0362   |
|    value_loss           | 0.00155  |
--------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4530       |
|    time_elapsed         | 14700      |
|    total_timesteps      | 9277440    |
| train/                  |            |
|    approx_kl            | 0.14163427 |
|    clip_fraction        | 0.464      |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.8        |
|    explained_variance   | 0.637      |
|    learning_rate        | 0.000191   |
|    loss                 | -0.0131    |
|    n_updates            | 45290      |
|    policy_gradient_loss | 0.0165     |
|    std                  | 0.0361     |
|    value_loss           | 0.127      |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4531       |
|    time_elapsed         | 14703      |
|    total_timesteps      | 9279488    |
| train/                  |            |
|    approx_kl            | 0.16932337 |
|    clip_fraction        | 0.417      |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.8        |
|    explained_variance   | 0.745      |
|    learning_rate        | 0.000191   |
|    loss                 | 0.0221     |
|    n_updates            | 45300      |
|    policy_gradient_loss | 0.00867    |
|    std                  | 0.0362     |
|    value_loss           | 0.00173    |
----------------------------------------
Eval num_timesteps=9280000, episode_reward=-0.76 +/- 0.29
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -0.76      |
| time/                   |            |
|    total_timesteps      | 9280000    |
| train/                  |            |
|    approx_kl            | 0.38454264 |
|    clip_fraction        | 0.396      |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.8        |
|    explained_variance   | 0.848      |
|    learning_rate        | 0.00019    |
|    loss                 | -0.0234    |
|    n_updates            | 45310      |
|    policy_gradient_loss | 0.00129    |
|    std                  | 0.0363     |
|    value_loss           | 0.00529    |
----------------------------------------
box reached target
box reached target
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 4532    |
|    time_elapsed    | 14707   |
|    total_timesteps | 9281536 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4533       |
|    time_elapsed         | 14710      |
|    total_timesteps      | 9283584    |
| train/                  |            |
|    approx_kl            | 0.12736544 |
|    clip_fraction        | 0.406      |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.8        |
|    explained_variance   | 0.587      |
|    learning_rate        | 0.00019    |
|    loss                 | -0.00277   |
|    n_updates            | 45320      |
|    policy_gradient_loss | 0.00853    |
|    std                  | 0.0362     |
|    value_loss           | 0.0663     |
----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 4534      |
|    time_elapsed         | 14714     |
|    total_timesteps      | 9285632   |
| train/                  |           |
|    approx_kl            | 0.3188415 |
|    clip_fraction        | 0.363     |
|    clip_range           | 0.2       |
|    entropy_loss         | 3.8       |
|    explained_variance   | 0.357     |
|    learning_rate        | 0.00019   |
|    loss                 | 0.0302    |
|    n_updates            | 45330     |
|    policy_gradient_loss | -0.00499  |
|    std                  | 0.0363    |
|    value_loss           | 0.00364   |
---------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 4535      |
|    time_elapsed         | 14717     |
|    total_timesteps      | 9287680   |
| train/                  |           |
|    approx_kl            | 17.570505 |
|    clip_fraction        | 0.411     |
|    clip_range           | 0.2       |
|    entropy_loss         | 3.82      |
|    explained_variance   | 0.768     |
|    learning_rate        | 0.000189  |
|    loss                 | -0.071    |
|    n_updates            | 45340     |
|    policy_gradient_loss | -0.0337   |
|    std                  | 0.0357    |
|    value_loss           | 0.00127   |
---------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4536       |
|    time_elapsed         | 14720      |
|    total_timesteps      | 9289728    |
| train/                  |            |
|    approx_kl            | 0.23131034 |
|    clip_fraction        | 0.39       |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.84       |
|    explained_variance   | 0.117      |
|    learning_rate        | 0.000189   |
|    loss                 | -0.0129    |
|    n_updates            | 45350      |
|    policy_gradient_loss | -0.0014    |
|    std                  | 0.0355     |
|    value_loss           | 0.00161    |
----------------------------------------
box reached target
Eval num_timesteps=9290000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1         |
| time/                   |            |
|    total_timesteps      | 9290000    |
| train/                  |            |
|    approx_kl            | 0.14503087 |
|    clip_fraction        | 0.402      |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.84       |
|    explained_variance   | 0.934      |
|    learning_rate        | 0.000189   |
|    loss                 | 0.0172     |
|    n_updates            | 45360      |
|    policy_gradient_loss | 0.00498    |
|    std                  | 0.0355     |
|    value_loss           | 0.00551    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 4537    |
|    time_elapsed    | 14724   |
|    total_timesteps | 9291776 |
--------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 4538      |
|    time_elapsed         | 14727     |
|    total_timesteps      | 9293824   |
| train/                  |           |
|    approx_kl            | 0.4697249 |
|    clip_fraction        | 0.412     |
|    clip_range           | 0.2       |
|    entropy_loss         | 3.85      |
|    explained_variance   | 0.94      |
|    learning_rate        | 0.000188  |
|    loss                 | 0.0369    |
|    n_updates            | 45370     |
|    policy_gradient_loss | 0.0122    |
|    std                  | 0.0353    |
|    value_loss           | 0.0193    |
---------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4539       |
|    time_elapsed         | 14730      |
|    total_timesteps      | 9295872    |
| train/                  |            |
|    approx_kl            | 0.19326605 |
|    clip_fraction        | 0.331      |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.85       |
|    explained_variance   | 0.588      |
|    learning_rate        | 0.000188   |
|    loss                 | 0.0234     |
|    n_updates            | 45380      |
|    policy_gradient_loss | 0.00571    |
|    std                  | 0.0354     |
|    value_loss           | 0.00136    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4540       |
|    time_elapsed         | 14733      |
|    total_timesteps      | 9297920    |
| train/                  |            |
|    approx_kl            | 0.14193022 |
|    clip_fraction        | 0.358      |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.86       |
|    explained_variance   | 0.984      |
|    learning_rate        | 0.000187   |
|    loss                 | -0.0206    |
|    n_updates            | 45390      |
|    policy_gradient_loss | 0.00439    |
|    std                  | 0.0349     |
|    value_loss           | 0.00435    |
----------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 4541      |
|    time_elapsed         | 14736     |
|    total_timesteps      | 9299968   |
| train/                  |           |
|    approx_kl            | 0.2910733 |
|    clip_fraction        | 0.349     |
|    clip_range           | 0.2       |
|    entropy_loss         | 3.87      |
|    explained_variance   | 0.61      |
|    learning_rate        | 0.000187  |
|    loss                 | 0.00863   |
|    n_updates            | 45400     |
|    policy_gradient_loss | -0.00387  |
|    std                  | 0.0351    |
|    value_loss           | 0.00168   |
---------------------------------------
Eval num_timesteps=9300000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1         |
| time/                   |            |
|    total_timesteps      | 9300000    |
| train/                  |            |
|    approx_kl            | 0.15171209 |
|    clip_fraction        | 0.464      |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.87       |
|    explained_variance   | 0.891      |
|    learning_rate        | 0.000187   |
|    loss                 | 0.0542     |
|    n_updates            | 45410      |
|    policy_gradient_loss | 0.0199     |
|    std                  | 0.0352     |
|    value_loss           | 0.0178     |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 4542    |
|    time_elapsed    | 14740   |
|    total_timesteps | 9302016 |
--------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4543       |
|    time_elapsed         | 14743      |
|    total_timesteps      | 9304064    |
| train/                  |            |
|    approx_kl            | 0.12685323 |
|    clip_fraction        | 0.326      |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.87       |
|    explained_variance   | 0.711      |
|    learning_rate        | 0.000186   |
|    loss                 | 0.0307     |
|    n_updates            | 45420      |
|    policy_gradient_loss | -0.00362   |
|    std                  | 0.035      |
|    value_loss           | 0.00101    |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4544       |
|    time_elapsed         | 14746      |
|    total_timesteps      | 9306112    |
| train/                  |            |
|    approx_kl            | 0.08372711 |
|    clip_fraction        | 0.425      |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.88       |
|    explained_variance   | 0.944      |
|    learning_rate        | 0.000186   |
|    loss                 | 0.0304     |
|    n_updates            | 45430      |
|    policy_gradient_loss | 0.0269     |
|    std                  | 0.0349     |
|    value_loss           | 0.0121     |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4545       |
|    time_elapsed         | 14749      |
|    total_timesteps      | 9308160    |
| train/                  |            |
|    approx_kl            | 0.35781407 |
|    clip_fraction        | 0.403      |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.88       |
|    explained_variance   | 0.955      |
|    learning_rate        | 0.000185   |
|    loss                 | -0.000911  |
|    n_updates            | 45440      |
|    policy_gradient_loss | 0.00628    |
|    std                  | 0.0348     |
|    value_loss           | 0.00792    |
----------------------------------------
box reached target
Eval num_timesteps=9310000, episode_reward=0.24 +/- 2.48
Episode length: 276.20 +/- 47.60
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 276        |
|    mean_reward          | 0.241      |
| time/                   |            |
|    total_timesteps      | 9310000    |
| train/                  |            |
|    approx_kl            | 0.22347516 |
|    clip_fraction        | 0.378      |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.89       |
|    explained_variance   | 0.627      |
|    learning_rate        | 0.000185   |
|    loss                 | -0.0201    |
|    n_updates            | 45450      |
|    policy_gradient_loss | 0.00858    |
|    std                  | 0.0347     |
|    value_loss           | 0.00107    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 4546    |
|    time_elapsed    | 14753   |
|    total_timesteps | 9310208 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4547       |
|    time_elapsed         | 14756      |
|    total_timesteps      | 9312256    |
| train/                  |            |
|    approx_kl            | 0.16848618 |
|    clip_fraction        | 0.318      |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.9        |
|    explained_variance   | 0.324      |
|    learning_rate        | 0.000185   |
|    loss                 | -0.0341    |
|    n_updates            | 45460      |
|    policy_gradient_loss | 0.00271    |
|    std                  | 0.0344     |
|    value_loss           | 0.00124    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4548       |
|    time_elapsed         | 14759      |
|    total_timesteps      | 9314304    |
| train/                  |            |
|    approx_kl            | 0.20338078 |
|    clip_fraction        | 0.38       |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.9        |
|    explained_variance   | 0.766      |
|    learning_rate        | 0.000184   |
|    loss                 | -0.00531   |
|    n_updates            | 45470      |
|    policy_gradient_loss | 0.00941    |
|    std                  | 0.0347     |
|    value_loss           | 0.00112    |
----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 631         |
|    iterations           | 4549        |
|    time_elapsed         | 14762       |
|    total_timesteps      | 9316352     |
| train/                  |             |
|    approx_kl            | 0.121623375 |
|    clip_fraction        | 0.375       |
|    clip_range           | 0.2         |
|    entropy_loss         | 3.9         |
|    explained_variance   | 0.661       |
|    learning_rate        | 0.000184    |
|    loss                 | -0.0172     |
|    n_updates            | 45480       |
|    policy_gradient_loss | 0.00835     |
|    std                  | 0.0346      |
|    value_loss           | 0.00135     |
-----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4550       |
|    time_elapsed         | 14765      |
|    total_timesteps      | 9318400    |
| train/                  |            |
|    approx_kl            | 0.12949976 |
|    clip_fraction        | 0.374      |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.9        |
|    explained_variance   | 0.705      |
|    learning_rate        | 0.000183   |
|    loss                 | -0.00318   |
|    n_updates            | 45490      |
|    policy_gradient_loss | 0.000699   |
|    std                  | 0.0344     |
|    value_loss           | 0.000862   |
----------------------------------------
Eval num_timesteps=9320000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1         |
| time/                   |            |
|    total_timesteps      | 9320000    |
| train/                  |            |
|    approx_kl            | 0.13789153 |
|    clip_fraction        | 0.322      |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.91       |
|    explained_variance   | 0.815      |
|    learning_rate        | 0.000183   |
|    loss                 | 0.0162     |
|    n_updates            | 45500      |
|    policy_gradient_loss | 0.00542    |
|    std                  | 0.0345     |
|    value_loss           | 0.000893   |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 4551    |
|    time_elapsed    | 14769   |
|    total_timesteps | 9320448 |
--------------------------------
--------------------------------------
| time/                   |          |
|    fps                  | 631      |
|    iterations           | 4552     |
|    time_elapsed         | 14772    |
|    total_timesteps      | 9322496  |
| train/                  |          |
|    approx_kl            | 0.29482  |
|    clip_fraction        | 0.33     |
|    clip_range           | 0.2      |
|    entropy_loss         | 3.93     |
|    explained_variance   | 0.686    |
|    learning_rate        | 0.000183 |
|    loss                 | 0.00464  |
|    n_updates            | 45510    |
|    policy_gradient_loss | 0.00616  |
|    std                  | 0.0338   |
|    value_loss           | 0.000905 |
--------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4553       |
|    time_elapsed         | 14775      |
|    total_timesteps      | 9324544    |
| train/                  |            |
|    approx_kl            | 0.27519038 |
|    clip_fraction        | 0.372      |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.95       |
|    explained_variance   | -0.0127    |
|    learning_rate        | 0.000182   |
|    loss                 | -0.0295    |
|    n_updates            | 45520      |
|    policy_gradient_loss | 0.00141    |
|    std                  | 0.0336     |
|    value_loss           | 0.00177    |
----------------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4554       |
|    time_elapsed         | 14778      |
|    total_timesteps      | 9326592    |
| train/                  |            |
|    approx_kl            | 0.07464036 |
|    clip_fraction        | 0.318      |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.96       |
|    explained_variance   | 0.673      |
|    learning_rate        | 0.000182   |
|    loss                 | 0.0248     |
|    n_updates            | 45530      |
|    policy_gradient_loss | 0.0104     |
|    std                  | 0.0335     |
|    value_loss           | 0.000826   |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4555       |
|    time_elapsed         | 14781      |
|    total_timesteps      | 9328640    |
| train/                  |            |
|    approx_kl            | 0.14848098 |
|    clip_fraction        | 0.375      |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.96       |
|    explained_variance   | 0.974      |
|    learning_rate        | 0.000181   |
|    loss                 | -0.0103    |
|    n_updates            | 45540      |
|    policy_gradient_loss | 0.00809    |
|    std                  | 0.0337     |
|    value_loss           | 0.00774    |
----------------------------------------
box reached target
Eval num_timesteps=9330000, episode_reward=0.25 +/- 2.51
Episode length: 271.60 +/- 56.80
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 272       |
|    mean_reward          | 0.254     |
| time/                   |           |
|    total_timesteps      | 9330000   |
| train/                  |           |
|    approx_kl            | 0.2891191 |
|    clip_fraction        | 0.402     |
|    clip_range           | 0.2       |
|    entropy_loss         | 3.95      |
|    explained_variance   | 0.771     |
|    learning_rate        | 0.000181  |
|    loss                 | -0.00122  |
|    n_updates            | 45550     |
|    policy_gradient_loss | -0.00522  |
|    std                  | 0.0337    |
|    value_loss           | 0.00367   |
---------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 4556    |
|    time_elapsed    | 14785   |
|    total_timesteps | 9330688 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4557       |
|    time_elapsed         | 14788      |
|    total_timesteps      | 9332736    |
| train/                  |            |
|    approx_kl            | 0.30616271 |
|    clip_fraction        | 0.421      |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.95       |
|    explained_variance   | -0.167     |
|    learning_rate        | 0.000181   |
|    loss                 | 0.00674    |
|    n_updates            | 45560      |
|    policy_gradient_loss | -0.00463   |
|    std                  | 0.0338     |
|    value_loss           | 0.00553    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4558       |
|    time_elapsed         | 14791      |
|    total_timesteps      | 9334784    |
| train/                  |            |
|    approx_kl            | 0.20811951 |
|    clip_fraction        | 0.345      |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.95       |
|    explained_variance   | 0.712      |
|    learning_rate        | 0.00018    |
|    loss                 | -0.0129    |
|    n_updates            | 45570      |
|    policy_gradient_loss | 0.00449    |
|    std                  | 0.0336     |
|    value_loss           | 0.00091    |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4559       |
|    time_elapsed         | 14794      |
|    total_timesteps      | 9336832    |
| train/                  |            |
|    approx_kl            | 0.20967159 |
|    clip_fraction        | 0.412      |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.95       |
|    explained_variance   | 0.785      |
|    learning_rate        | 0.00018    |
|    loss                 | -0.00629   |
|    n_updates            | 45580      |
|    policy_gradient_loss | 0.00142    |
|    std                  | 0.0337     |
|    value_loss           | 0.00408    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4560       |
|    time_elapsed         | 14797      |
|    total_timesteps      | 9338880    |
| train/                  |            |
|    approx_kl            | 0.15431303 |
|    clip_fraction        | 0.407      |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.96       |
|    explained_variance   | 0.957      |
|    learning_rate        | 0.000179   |
|    loss                 | 0.0445     |
|    n_updates            | 45590      |
|    policy_gradient_loss | 0.00624    |
|    std                  | 0.0335     |
|    value_loss           | 0.00665    |
----------------------------------------
Eval num_timesteps=9340000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 300       |
|    mean_reward          | -1        |
| time/                   |           |
|    total_timesteps      | 9340000   |
| train/                  |           |
|    approx_kl            | 0.2652982 |
|    clip_fraction        | 0.317     |
|    clip_range           | 0.2       |
|    entropy_loss         | 3.97      |
|    explained_variance   | 0.558     |
|    learning_rate        | 0.000179  |
|    loss                 | -0.0337   |
|    n_updates            | 45600     |
|    policy_gradient_loss | 0.0059    |
|    std                  | 0.0332    |
|    value_loss           | 0.00149   |
---------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 4561    |
|    time_elapsed    | 14801   |
|    total_timesteps | 9340928 |
--------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 631         |
|    iterations           | 4562        |
|    time_elapsed         | 14805       |
|    total_timesteps      | 9342976     |
| train/                  |             |
|    approx_kl            | 0.115864724 |
|    clip_fraction        | 0.342       |
|    clip_range           | 0.2         |
|    entropy_loss         | 3.97        |
|    explained_variance   | 0.0593      |
|    learning_rate        | 0.000179    |
|    loss                 | -0.000125   |
|    n_updates            | 45610       |
|    policy_gradient_loss | 0.0279      |
|    std                  | 0.0335      |
|    value_loss           | 0.00155     |
-----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 4563      |
|    time_elapsed         | 14808     |
|    total_timesteps      | 9345024   |
| train/                  |           |
|    approx_kl            | 3.4671524 |
|    clip_fraction        | 0.51      |
|    clip_range           | 0.2       |
|    entropy_loss         | 3.96      |
|    explained_variance   | 0.486     |
|    learning_rate        | 0.000178  |
|    loss                 | 0.0391    |
|    n_updates            | 45620     |
|    policy_gradient_loss | 0.0075    |
|    std                  | 0.0336    |
|    value_loss           | 0.00153   |
---------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 4564      |
|    time_elapsed         | 14811     |
|    total_timesteps      | 9347072   |
| train/                  |           |
|    approx_kl            | 0.2719637 |
|    clip_fraction        | 0.356     |
|    clip_range           | 0.2       |
|    entropy_loss         | 3.97      |
|    explained_variance   | 0.733     |
|    learning_rate        | 0.000178  |
|    loss                 | 0.0522    |
|    n_updates            | 45630     |
|    policy_gradient_loss | -0.0128   |
|    std                  | 0.0334    |
|    value_loss           | 0.00202   |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4565       |
|    time_elapsed         | 14814      |
|    total_timesteps      | 9349120    |
| train/                  |            |
|    approx_kl            | 0.22527641 |
|    clip_fraction        | 0.379      |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.98       |
|    explained_variance   | 0.606      |
|    learning_rate        | 0.000177   |
|    loss                 | -0.0308    |
|    n_updates            | 45640      |
|    policy_gradient_loss | 0.00385    |
|    std                  | 0.0332     |
|    value_loss           | 0.00103    |
----------------------------------------
Eval num_timesteps=9350000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1         |
| time/                   |            |
|    total_timesteps      | 9350000    |
| train/                  |            |
|    approx_kl            | 0.14566107 |
|    clip_fraction        | 0.405      |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.98       |
|    explained_variance   | 0.628      |
|    learning_rate        | 0.000177   |
|    loss                 | -0.00271   |
|    n_updates            | 45650      |
|    policy_gradient_loss | 0.0115     |
|    std                  | 0.0333     |
|    value_loss           | 0.00134    |
----------------------------------------
box reached target
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 4566    |
|    time_elapsed    | 14818   |
|    total_timesteps | 9351168 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4567       |
|    time_elapsed         | 14821      |
|    total_timesteps      | 9353216    |
| train/                  |            |
|    approx_kl            | 0.35327592 |
|    clip_fraction        | 0.416      |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.99       |
|    explained_variance   | 0.513      |
|    learning_rate        | 0.000177   |
|    loss                 | 0.308      |
|    n_updates            | 45660      |
|    policy_gradient_loss | 0.0123     |
|    std                  | 0.0331     |
|    value_loss           | 0.122      |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4568       |
|    time_elapsed         | 14824      |
|    total_timesteps      | 9355264    |
| train/                  |            |
|    approx_kl            | 0.31557927 |
|    clip_fraction        | 0.366      |
|    clip_range           | 0.2        |
|    entropy_loss         | 3.99       |
|    explained_variance   | 0.661      |
|    learning_rate        | 0.000176   |
|    loss                 | -0.0386    |
|    n_updates            | 45670      |
|    policy_gradient_loss | 0.00146    |
|    std                  | 0.033      |
|    value_loss           | 0.00268    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4569       |
|    time_elapsed         | 14827      |
|    total_timesteps      | 9357312    |
| train/                  |            |
|    approx_kl            | 0.10513848 |
|    clip_fraction        | 0.349      |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.01       |
|    explained_variance   | 0.815      |
|    learning_rate        | 0.000176   |
|    loss                 | 0.0239     |
|    n_updates            | 45680      |
|    policy_gradient_loss | 0.0122     |
|    std                  | 0.0327     |
|    value_loss           | 0.000818   |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4570       |
|    time_elapsed         | 14830      |
|    total_timesteps      | 9359360    |
| train/                  |            |
|    approx_kl            | 0.21292427 |
|    clip_fraction        | 0.357      |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.02       |
|    explained_variance   | 0.553      |
|    learning_rate        | 0.000175   |
|    loss                 | 0.0147     |
|    n_updates            | 45690      |
|    policy_gradient_loss | 0.00689    |
|    std                  | 0.0327     |
|    value_loss           | 0.0011     |
----------------------------------------
Eval num_timesteps=9360000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1         |
| time/                   |            |
|    total_timesteps      | 9360000    |
| train/                  |            |
|    approx_kl            | 0.19389263 |
|    clip_fraction        | 0.449      |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.03       |
|    explained_variance   | 0.642      |
|    learning_rate        | 0.000175   |
|    loss                 | 0.0363     |
|    n_updates            | 45700      |
|    policy_gradient_loss | 0.0123     |
|    std                  | 0.0324     |
|    value_loss           | 0.0437     |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 4571    |
|    time_elapsed    | 14834   |
|    total_timesteps | 9361408 |
--------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 4572      |
|    time_elapsed         | 14838     |
|    total_timesteps      | 9363456   |
| train/                  |           |
|    approx_kl            | 0.1326919 |
|    clip_fraction        | 0.419     |
|    clip_range           | 0.2       |
|    entropy_loss         | 4.04      |
|    explained_variance   | 0.555     |
|    learning_rate        | 0.000175  |
|    loss                 | -0.00513  |
|    n_updates            | 45710     |
|    policy_gradient_loss | 0.0151    |
|    std                  | 0.0323    |
|    value_loss           | 0.00917   |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4573       |
|    time_elapsed         | 14841      |
|    total_timesteps      | 9365504    |
| train/                  |            |
|    approx_kl            | 0.14351016 |
|    clip_fraction        | 0.4        |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.04       |
|    explained_variance   | 0.964      |
|    learning_rate        | 0.000174   |
|    loss                 | -0.00822   |
|    n_updates            | 45720      |
|    policy_gradient_loss | 0.00523    |
|    std                  | 0.0323     |
|    value_loss           | 0.00545    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4574       |
|    time_elapsed         | 14844      |
|    total_timesteps      | 9367552    |
| train/                  |            |
|    approx_kl            | 0.17160507 |
|    clip_fraction        | 0.357      |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.04       |
|    explained_variance   | 0.697      |
|    learning_rate        | 0.000174   |
|    loss                 | -0.000364  |
|    n_updates            | 45730      |
|    policy_gradient_loss | 0.00984    |
|    std                  | 0.0322     |
|    value_loss           | 0.00263    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4575       |
|    time_elapsed         | 14847      |
|    total_timesteps      | 9369600    |
| train/                  |            |
|    approx_kl            | 0.12877673 |
|    clip_fraction        | 0.311      |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.04       |
|    explained_variance   | 0.628      |
|    learning_rate        | 0.000173   |
|    loss                 | 0.0152     |
|    n_updates            | 45740      |
|    policy_gradient_loss | 0.000585   |
|    std                  | 0.0324     |
|    value_loss           | 0.000768   |
----------------------------------------
Eval num_timesteps=9370000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1         |
| time/                   |            |
|    total_timesteps      | 9370000    |
| train/                  |            |
|    approx_kl            | 0.17607519 |
|    clip_fraction        | 0.349      |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.04       |
|    explained_variance   | 0.0288     |
|    learning_rate        | 0.000173   |
|    loss                 | -0.0258    |
|    n_updates            | 45750      |
|    policy_gradient_loss | -0.000685  |
|    std                  | 0.0325     |
|    value_loss           | 0.0013     |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 4576    |
|    time_elapsed    | 14851   |
|    total_timesteps | 9371648 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4577       |
|    time_elapsed         | 14854      |
|    total_timesteps      | 9373696    |
| train/                  |            |
|    approx_kl            | 0.20988156 |
|    clip_fraction        | 0.39       |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.03       |
|    explained_variance   | 0.492      |
|    learning_rate        | 0.000173   |
|    loss                 | -0.0487    |
|    n_updates            | 45760      |
|    policy_gradient_loss | -0.00192   |
|    std                  | 0.0325     |
|    value_loss           | 0.00113    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4578       |
|    time_elapsed         | 14857      |
|    total_timesteps      | 9375744    |
| train/                  |            |
|    approx_kl            | 0.19539997 |
|    clip_fraction        | 0.365      |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.03       |
|    explained_variance   | 0.705      |
|    learning_rate        | 0.000172   |
|    loss                 | 0.017      |
|    n_updates            | 45770      |
|    policy_gradient_loss | 0.0179     |
|    std                  | 0.0326     |
|    value_loss           | 0.0012     |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4579       |
|    time_elapsed         | 14860      |
|    total_timesteps      | 9377792    |
| train/                  |            |
|    approx_kl            | 0.07914417 |
|    clip_fraction        | 0.366      |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.02       |
|    explained_variance   | 0.667      |
|    learning_rate        | 0.000172   |
|    loss                 | -0.0062    |
|    n_updates            | 45780      |
|    policy_gradient_loss | 0.00848    |
|    std                  | 0.0326     |
|    value_loss           | 0.00162    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4580       |
|    time_elapsed         | 14863      |
|    total_timesteps      | 9379840    |
| train/                  |            |
|    approx_kl            | 0.15997574 |
|    clip_fraction        | 0.429      |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.02       |
|    explained_variance   | 0.557      |
|    learning_rate        | 0.000171   |
|    loss                 | -0.000834  |
|    n_updates            | 45790      |
|    policy_gradient_loss | 0.00635    |
|    std                  | 0.0328     |
|    value_loss           | 0.00245    |
----------------------------------------
Eval num_timesteps=9380000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1         |
| time/                   |            |
|    total_timesteps      | 9380000    |
| train/                  |            |
|    approx_kl            | 0.19689488 |
|    clip_fraction        | 0.365      |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.01       |
|    explained_variance   | 0.548      |
|    learning_rate        | 0.000171   |
|    loss                 | -0.00769   |
|    n_updates            | 45800      |
|    policy_gradient_loss | 0.00295    |
|    std                  | 0.0326     |
|    value_loss           | 0.00122    |
----------------------------------------
box reached target
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 4581    |
|    time_elapsed    | 14867   |
|    total_timesteps | 9381888 |
--------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 4582      |
|    time_elapsed         | 14870     |
|    total_timesteps      | 9383936   |
| train/                  |           |
|    approx_kl            | 0.3286636 |
|    clip_fraction        | 0.449     |
|    clip_range           | 0.2       |
|    entropy_loss         | 4.02      |
|    explained_variance   | 0.97      |
|    learning_rate        | 0.000171  |
|    loss                 | 0.022     |
|    n_updates            | 45810     |
|    policy_gradient_loss | 0.0145    |
|    std                  | 0.0325    |
|    value_loss           | 0.00774   |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4583       |
|    time_elapsed         | 14873      |
|    total_timesteps      | 9385984    |
| train/                  |            |
|    approx_kl            | 0.20842935 |
|    clip_fraction        | 0.347      |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.02       |
|    explained_variance   | 0.867      |
|    learning_rate        | 0.00017    |
|    loss                 | 0.106      |
|    n_updates            | 45820      |
|    policy_gradient_loss | 0.0525     |
|    std                  | 0.0329     |
|    value_loss           | 0.0125     |
----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 4584      |
|    time_elapsed         | 14876     |
|    total_timesteps      | 9388032   |
| train/                  |           |
|    approx_kl            | 0.4342603 |
|    clip_fraction        | 0.382     |
|    clip_range           | 0.2       |
|    entropy_loss         | 4         |
|    explained_variance   | 0.696     |
|    learning_rate        | 0.00017   |
|    loss                 | -0.00557  |
|    n_updates            | 45830     |
|    policy_gradient_loss | 0.00762   |
|    std                  | 0.0328    |
|    value_loss           | 0.000967  |
---------------------------------------
box reached target
box reached target
Eval num_timesteps=9390000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1         |
| time/                   |            |
|    total_timesteps      | 9390000    |
| train/                  |            |
|    approx_kl            | 0.16708082 |
|    clip_fraction        | 0.366      |
|    clip_range           | 0.2        |
|    entropy_loss         | 4          |
|    explained_variance   | 0.949      |
|    learning_rate        | 0.000169   |
|    loss                 | -0.0121    |
|    n_updates            | 45840      |
|    policy_gradient_loss | 0.0131     |
|    std                  | 0.0329     |
|    value_loss           | 0.00129    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 4585    |
|    time_elapsed    | 14880   |
|    total_timesteps | 9390080 |
--------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 4586      |
|    time_elapsed         | 14883     |
|    total_timesteps      | 9392128   |
| train/                  |           |
|    approx_kl            | 0.2342323 |
|    clip_fraction        | 0.377     |
|    clip_range           | 0.2       |
|    entropy_loss         | 4.01      |
|    explained_variance   | 0.73      |
|    learning_rate        | 0.000169  |
|    loss                 | 0.0022    |
|    n_updates            | 45850     |
|    policy_gradient_loss | 0.00487   |
|    std                  | 0.0326    |
|    value_loss           | 0.0607    |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4587       |
|    time_elapsed         | 14886      |
|    total_timesteps      | 9394176    |
| train/                  |            |
|    approx_kl            | 0.39946038 |
|    clip_fraction        | 0.4        |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.01       |
|    explained_variance   | 0.854      |
|    learning_rate        | 0.000169   |
|    loss                 | -0.0318    |
|    n_updates            | 45860      |
|    policy_gradient_loss | 0.0143     |
|    std                  | 0.0328     |
|    value_loss           | 0.00561    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4588       |
|    time_elapsed         | 14889      |
|    total_timesteps      | 9396224    |
| train/                  |            |
|    approx_kl            | 0.21834971 |
|    clip_fraction        | 0.35       |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.01       |
|    explained_variance   | 0.599      |
|    learning_rate        | 0.000168   |
|    loss                 | 0.0113     |
|    n_updates            | 45870      |
|    policy_gradient_loss | -0.00244   |
|    std                  | 0.0328     |
|    value_loss           | 0.00127    |
----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 4589      |
|    time_elapsed         | 14892     |
|    total_timesteps      | 9398272   |
| train/                  |           |
|    approx_kl            | 0.3898428 |
|    clip_fraction        | 0.398     |
|    clip_range           | 0.2       |
|    entropy_loss         | 4.01      |
|    explained_variance   | 0.408     |
|    learning_rate        | 0.000168  |
|    loss                 | -0.00326  |
|    n_updates            | 45880     |
|    policy_gradient_loss | 0.0134    |
|    std                  | 0.0328    |
|    value_loss           | 0.00278   |
---------------------------------------
Eval num_timesteps=9400000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1         |
| time/                   |            |
|    total_timesteps      | 9400000    |
| train/                  |            |
|    approx_kl            | 0.07303161 |
|    clip_fraction        | 0.335      |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.01       |
|    explained_variance   | 0.6        |
|    learning_rate        | 0.000167   |
|    loss                 | -0.033     |
|    n_updates            | 45890      |
|    policy_gradient_loss | -0.00278   |
|    std                  | 0.0326     |
|    value_loss           | 0.00144    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 4590    |
|    time_elapsed    | 14896   |
|    total_timesteps | 9400320 |
--------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 4591      |
|    time_elapsed         | 14899     |
|    total_timesteps      | 9402368   |
| train/                  |           |
|    approx_kl            | 0.2197077 |
|    clip_fraction        | 0.349     |
|    clip_range           | 0.2       |
|    entropy_loss         | 4.02      |
|    explained_variance   | 0.338     |
|    learning_rate        | 0.000167  |
|    loss                 | -0.0114   |
|    n_updates            | 45900     |
|    policy_gradient_loss | -0.00249  |
|    std                  | 0.0325    |
|    value_loss           | 0.00211   |
---------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4592       |
|    time_elapsed         | 14902      |
|    total_timesteps      | 9404416    |
| train/                  |            |
|    approx_kl            | 0.12474753 |
|    clip_fraction        | 0.34       |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.02       |
|    explained_variance   | 0.75       |
|    learning_rate        | 0.000167   |
|    loss                 | 0.0328     |
|    n_updates            | 45910      |
|    policy_gradient_loss | 0.00169    |
|    std                  | 0.0326     |
|    value_loss           | 0.000951   |
----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 4593      |
|    time_elapsed         | 14905     |
|    total_timesteps      | 9406464   |
| train/                  |           |
|    approx_kl            | 0.2754264 |
|    clip_fraction        | 0.408     |
|    clip_range           | 0.2       |
|    entropy_loss         | 4.02      |
|    explained_variance   | 0.97      |
|    learning_rate        | 0.000166  |
|    loss                 | 0.00101   |
|    n_updates            | 45920     |
|    policy_gradient_loss | 0.0136    |
|    std                  | 0.0326    |
|    value_loss           | 0.00883   |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4594       |
|    time_elapsed         | 14908      |
|    total_timesteps      | 9408512    |
| train/                  |            |
|    approx_kl            | 0.28344566 |
|    clip_fraction        | 0.407      |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.02       |
|    explained_variance   | 0.745      |
|    learning_rate        | 0.000166   |
|    loss                 | -0.0411    |
|    n_updates            | 45930      |
|    policy_gradient_loss | 0.00463    |
|    std                  | 0.0326     |
|    value_loss           | 0.00224    |
----------------------------------------
box reached target
Eval num_timesteps=9410000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1         |
| time/                   |            |
|    total_timesteps      | 9410000    |
| train/                  |            |
|    approx_kl            | 0.09548424 |
|    clip_fraction        | 0.404      |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.01       |
|    explained_variance   | 0.645      |
|    learning_rate        | 0.000165   |
|    loss                 | -0.00157   |
|    n_updates            | 45940      |
|    policy_gradient_loss | 0.00927    |
|    std                  | 0.0327     |
|    value_loss           | 0.00257    |
----------------------------------------
box reached target
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 4595    |
|    time_elapsed    | 14912   |
|    total_timesteps | 9410560 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4596       |
|    time_elapsed         | 14916      |
|    total_timesteps      | 9412608    |
| train/                  |            |
|    approx_kl            | 0.14838713 |
|    clip_fraction        | 0.337      |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.01       |
|    explained_variance   | 0.981      |
|    learning_rate        | 0.000165   |
|    loss                 | -0.00348   |
|    n_updates            | 45950      |
|    policy_gradient_loss | 0.0159     |
|    std                  | 0.0326     |
|    value_loss           | 0.00521    |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4597       |
|    time_elapsed         | 14919      |
|    total_timesteps      | 9414656    |
| train/                  |            |
|    approx_kl            | 0.20232129 |
|    clip_fraction        | 0.352      |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.02       |
|    explained_variance   | 0.769      |
|    learning_rate        | 0.000165   |
|    loss                 | -0.0228    |
|    n_updates            | 45960      |
|    policy_gradient_loss | 0.00551    |
|    std                  | 0.0325     |
|    value_loss           | 0.00108    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4598       |
|    time_elapsed         | 14922      |
|    total_timesteps      | 9416704    |
| train/                  |            |
|    approx_kl            | 0.17766625 |
|    clip_fraction        | 0.413      |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.02       |
|    explained_variance   | 0.944      |
|    learning_rate        | 0.000164   |
|    loss                 | -0.0213    |
|    n_updates            | 45970      |
|    policy_gradient_loss | 0.00357    |
|    std                  | 0.0327     |
|    value_loss           | 0.00968    |
----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 631         |
|    iterations           | 4599        |
|    time_elapsed         | 14925       |
|    total_timesteps      | 9418752     |
| train/                  |             |
|    approx_kl            | 0.078590676 |
|    clip_fraction        | 0.336       |
|    clip_range           | 0.2         |
|    entropy_loss         | 4.02        |
|    explained_variance   | 0.658       |
|    learning_rate        | 0.000164    |
|    loss                 | -0.00491    |
|    n_updates            | 45980       |
|    policy_gradient_loss | 0.0116      |
|    std                  | 0.0326      |
|    value_loss           | 0.00109     |
-----------------------------------------
Eval num_timesteps=9420000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1         |
| time/                   |            |
|    total_timesteps      | 9420000    |
| train/                  |            |
|    approx_kl            | 0.27132446 |
|    clip_fraction        | 0.355      |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.02       |
|    explained_variance   | 0.693      |
|    learning_rate        | 0.000163   |
|    loss                 | -0.0219    |
|    n_updates            | 45990      |
|    policy_gradient_loss | 0.00534    |
|    std                  | 0.0326     |
|    value_loss           | 0.00109    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 4600    |
|    time_elapsed    | 14929   |
|    total_timesteps | 9420800 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4601       |
|    time_elapsed         | 14932      |
|    total_timesteps      | 9422848    |
| train/                  |            |
|    approx_kl            | 0.22918497 |
|    clip_fraction        | 0.33       |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.03       |
|    explained_variance   | 0.458      |
|    learning_rate        | 0.000163   |
|    loss                 | -0.0338    |
|    n_updates            | 46000      |
|    policy_gradient_loss | -0.0124    |
|    std                  | 0.0324     |
|    value_loss           | 0.00162    |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4602       |
|    time_elapsed         | 14935      |
|    total_timesteps      | 9424896    |
| train/                  |            |
|    approx_kl            | 0.16717061 |
|    clip_fraction        | 0.348      |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.03       |
|    explained_variance   | 0.684      |
|    learning_rate        | 0.000163   |
|    loss                 | -0.0237    |
|    n_updates            | 46010      |
|    policy_gradient_loss | -0.00674   |
|    std                  | 0.0324     |
|    value_loss           | 0.00124    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4603       |
|    time_elapsed         | 14938      |
|    total_timesteps      | 9426944    |
| train/                  |            |
|    approx_kl            | 0.16891989 |
|    clip_fraction        | 0.39       |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.03       |
|    explained_variance   | 0.865      |
|    learning_rate        | 0.000162   |
|    loss                 | 0.03       |
|    n_updates            | 46020      |
|    policy_gradient_loss | 0.00426    |
|    std                  | 0.0326     |
|    value_loss           | 0.0167     |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4604       |
|    time_elapsed         | 14941      |
|    total_timesteps      | 9428992    |
| train/                  |            |
|    approx_kl            | 0.31825727 |
|    clip_fraction        | 0.374      |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.02       |
|    explained_variance   | 0.292      |
|    learning_rate        | 0.000162   |
|    loss                 | -0.00682   |
|    n_updates            | 46030      |
|    policy_gradient_loss | -0.00439   |
|    std                  | 0.0326     |
|    value_loss           | 0.0051     |
----------------------------------------
box reached target
Eval num_timesteps=9430000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 300       |
|    mean_reward          | -1        |
| time/                   |           |
|    total_timesteps      | 9430000   |
| train/                  |           |
|    approx_kl            | 0.1877414 |
|    clip_fraction        | 0.39      |
|    clip_range           | 0.2       |
|    entropy_loss         | 4.03      |
|    explained_variance   | 0.955     |
|    learning_rate        | 0.000161  |
|    loss                 | -0.0244   |
|    n_updates            | 46040     |
|    policy_gradient_loss | 0.00463   |
|    std                  | 0.0324    |
|    value_loss           | 0.0036    |
---------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 4605    |
|    time_elapsed    | 14945   |
|    total_timesteps | 9431040 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4606       |
|    time_elapsed         | 14948      |
|    total_timesteps      | 9433088    |
| train/                  |            |
|    approx_kl            | 0.12368586 |
|    clip_fraction        | 0.359      |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.03       |
|    explained_variance   | 0.966      |
|    learning_rate        | 0.000161   |
|    loss                 | -0.0207    |
|    n_updates            | 46050      |
|    policy_gradient_loss | 3.07e-05   |
|    std                  | 0.0324     |
|    value_loss           | 0.0024     |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4607       |
|    time_elapsed         | 14951      |
|    total_timesteps      | 9435136    |
| train/                  |            |
|    approx_kl            | 0.16330616 |
|    clip_fraction        | 0.374      |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.03       |
|    explained_variance   | 0.419      |
|    learning_rate        | 0.000161   |
|    loss                 | 0.0134     |
|    n_updates            | 46060      |
|    policy_gradient_loss | 0.00677    |
|    std                  | 0.0324     |
|    value_loss           | 0.00137    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4608       |
|    time_elapsed         | 14954      |
|    total_timesteps      | 9437184    |
| train/                  |            |
|    approx_kl            | 0.13379925 |
|    clip_fraction        | 0.337      |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.03       |
|    explained_variance   | 0.758      |
|    learning_rate        | 0.00016    |
|    loss                 | 0.0173     |
|    n_updates            | 46070      |
|    policy_gradient_loss | -0.002     |
|    std                  | 0.0324     |
|    value_loss           | 0.00174    |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4609       |
|    time_elapsed         | 14957      |
|    total_timesteps      | 9439232    |
| train/                  |            |
|    approx_kl            | 0.14043248 |
|    clip_fraction        | 0.389      |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.03       |
|    explained_variance   | 0.701      |
|    learning_rate        | 0.00016    |
|    loss                 | 1.49       |
|    n_updates            | 46080      |
|    policy_gradient_loss | 0.0216     |
|    std                  | 0.0324     |
|    value_loss           | 0.0013     |
----------------------------------------
Eval num_timesteps=9440000, episode_reward=-0.90 +/- 0.19
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -0.903     |
| time/                   |            |
|    total_timesteps      | 9440000    |
| train/                  |            |
|    approx_kl            | 0.27422577 |
|    clip_fraction        | 0.462      |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.03       |
|    explained_variance   | 0.885      |
|    learning_rate        | 0.000159   |
|    loss                 | 0.00925    |
|    n_updates            | 46090      |
|    policy_gradient_loss | 0.0193     |
|    std                  | 0.0325     |
|    value_loss           | 0.0185     |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 4610    |
|    time_elapsed    | 14961   |
|    total_timesteps | 9441280 |
--------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 4611      |
|    time_elapsed         | 14964     |
|    total_timesteps      | 9443328   |
| train/                  |           |
|    approx_kl            | 4.0398045 |
|    clip_fraction        | 0.418     |
|    clip_range           | 0.2       |
|    entropy_loss         | 4.03      |
|    explained_variance   | 0.685     |
|    learning_rate        | 0.000159  |
|    loss                 | -0.0126   |
|    n_updates            | 46100     |
|    policy_gradient_loss | -0.00566  |
|    std                  | 0.0324    |
|    value_loss           | 0.00177   |
---------------------------------------
box reached target
--------------------------------------
| time/                   |          |
|    fps                  | 631      |
|    iterations           | 4612     |
|    time_elapsed         | 14967    |
|    total_timesteps      | 9445376  |
| train/                  |          |
|    approx_kl            | 1.114634 |
|    clip_fraction        | 0.403    |
|    clip_range           | 0.2      |
|    entropy_loss         | 4.04     |
|    explained_variance   | 0.0456   |
|    learning_rate        | 0.000159 |
|    loss                 | -0.0522  |
|    n_updates            | 46110    |
|    policy_gradient_loss | 0.00311  |
|    std                  | 0.0322   |
|    value_loss           | 0.00197  |
--------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 4613      |
|    time_elapsed         | 14970     |
|    total_timesteps      | 9447424   |
| train/                  |           |
|    approx_kl            | 0.1765514 |
|    clip_fraction        | 0.368     |
|    clip_range           | 0.2       |
|    entropy_loss         | 4.06      |
|    explained_variance   | 0.975     |
|    learning_rate        | 0.000158  |
|    loss                 | 0.0057    |
|    n_updates            | 46120     |
|    policy_gradient_loss | 0.0105    |
|    std                  | 0.0319    |
|    value_loss           | 0.00195   |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4614       |
|    time_elapsed         | 14973      |
|    total_timesteps      | 9449472    |
| train/                  |            |
|    approx_kl            | 0.07510649 |
|    clip_fraction        | 0.327      |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.07       |
|    explained_variance   | 0.591      |
|    learning_rate        | 0.000158   |
|    loss                 | -0.0122    |
|    n_updates            | 46130      |
|    policy_gradient_loss | 0.00676    |
|    std                  | 0.0318     |
|    value_loss           | 0.00123    |
----------------------------------------
Eval num_timesteps=9450000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1         |
| time/                   |            |
|    total_timesteps      | 9450000    |
| train/                  |            |
|    approx_kl            | 0.27027798 |
|    clip_fraction        | 0.42       |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.07       |
|    explained_variance   | 0.744      |
|    learning_rate        | 0.000157   |
|    loss                 | 0.00296    |
|    n_updates            | 46140      |
|    policy_gradient_loss | 0.0106     |
|    std                  | 0.0318     |
|    value_loss           | 0.00164    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 4615    |
|    time_elapsed    | 14977   |
|    total_timesteps | 9451520 |
--------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 4616      |
|    time_elapsed         | 14980     |
|    total_timesteps      | 9453568   |
| train/                  |           |
|    approx_kl            | 0.1031886 |
|    clip_fraction        | 0.324     |
|    clip_range           | 0.2       |
|    entropy_loss         | 4.07      |
|    explained_variance   | 0.587     |
|    learning_rate        | 0.000157  |
|    loss                 | 0.00423   |
|    n_updates            | 46150     |
|    policy_gradient_loss | -0.000894 |
|    std                  | 0.0318    |
|    value_loss           | 0.0018    |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4617       |
|    time_elapsed         | 14984      |
|    total_timesteps      | 9455616    |
| train/                  |            |
|    approx_kl            | 0.12218946 |
|    clip_fraction        | 0.412      |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.07       |
|    explained_variance   | 0.538      |
|    learning_rate        | 0.000157   |
|    loss                 | -0.00727   |
|    n_updates            | 46160      |
|    policy_gradient_loss | 0.0128     |
|    std                  | 0.032      |
|    value_loss           | 0.00256    |
----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 4618      |
|    time_elapsed         | 14987     |
|    total_timesteps      | 9457664   |
| train/                  |           |
|    approx_kl            | 0.5310873 |
|    clip_fraction        | 0.36      |
|    clip_range           | 0.2       |
|    entropy_loss         | 4.06      |
|    explained_variance   | 0.68      |
|    learning_rate        | 0.000156  |
|    loss                 | -0.0235   |
|    n_updates            | 46170     |
|    policy_gradient_loss | 0.0132    |
|    std                  | 0.0318    |
|    value_loss           | 0.00117   |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4619       |
|    time_elapsed         | 14990      |
|    total_timesteps      | 9459712    |
| train/                  |            |
|    approx_kl            | 0.20830083 |
|    clip_fraction        | 0.343      |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.08       |
|    explained_variance   | 0.154      |
|    learning_rate        | 0.000156   |
|    loss                 | -0.0542    |
|    n_updates            | 46180      |
|    policy_gradient_loss | 0.00818    |
|    std                  | 0.0316     |
|    value_loss           | 0.00125    |
----------------------------------------
box reached target
Eval num_timesteps=9460000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1         |
| time/                   |            |
|    total_timesteps      | 9460000    |
| train/                  |            |
|    approx_kl            | 0.15859655 |
|    clip_fraction        | 0.385      |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.09       |
|    explained_variance   | 0.878      |
|    learning_rate        | 0.000155   |
|    loss                 | -0.0165    |
|    n_updates            | 46190      |
|    policy_gradient_loss | 0.00545    |
|    std                  | 0.0314     |
|    value_loss           | 0.00635    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 4620    |
|    time_elapsed    | 14994   |
|    total_timesteps | 9461760 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4621       |
|    time_elapsed         | 14997      |
|    total_timesteps      | 9463808    |
| train/                  |            |
|    approx_kl            | 0.18709826 |
|    clip_fraction        | 0.312      |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.09       |
|    explained_variance   | 0.992      |
|    learning_rate        | 0.000155   |
|    loss                 | -0.011     |
|    n_updates            | 46200      |
|    policy_gradient_loss | -0.00517   |
|    std                  | 0.0316     |
|    value_loss           | 0.00187    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4622       |
|    time_elapsed         | 15000      |
|    total_timesteps      | 9465856    |
| train/                  |            |
|    approx_kl            | 0.28349465 |
|    clip_fraction        | 0.388      |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.09       |
|    explained_variance   | 0.618      |
|    learning_rate        | 0.000155   |
|    loss                 | 0.0507     |
|    n_updates            | 46210      |
|    policy_gradient_loss | 0.0082     |
|    std                  | 0.0314     |
|    value_loss           | 0.0011     |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4623       |
|    time_elapsed         | 15003      |
|    total_timesteps      | 9467904    |
| train/                  |            |
|    approx_kl            | 0.22202271 |
|    clip_fraction        | 0.367      |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.1        |
|    explained_variance   | 0.516      |
|    learning_rate        | 0.000154   |
|    loss                 | -0.00752   |
|    n_updates            | 46220      |
|    policy_gradient_loss | 0.00397    |
|    std                  | 0.0312     |
|    value_loss           | 0.00119    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4624       |
|    time_elapsed         | 15006      |
|    total_timesteps      | 9469952    |
| train/                  |            |
|    approx_kl            | 0.22495413 |
|    clip_fraction        | 0.372      |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.12       |
|    explained_variance   | 0.541      |
|    learning_rate        | 0.000154   |
|    loss                 | -0.0219    |
|    n_updates            | 46230      |
|    policy_gradient_loss | -0.000919  |
|    std                  | 0.031      |
|    value_loss           | 0.00158    |
----------------------------------------
box reached target
Eval num_timesteps=9470000, episode_reward=0.27 +/- 2.54
Episode length: 272.20 +/- 55.60
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 272        |
|    mean_reward          | 0.272      |
| time/                   |            |
|    total_timesteps      | 9470000    |
| train/                  |            |
|    approx_kl            | 0.07923679 |
|    clip_fraction        | 0.337      |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.13       |
|    explained_variance   | 0.612      |
|    learning_rate        | 0.000153   |
|    loss                 | -0.0339    |
|    n_updates            | 46240      |
|    policy_gradient_loss | 0.0108     |
|    std                  | 0.0307     |
|    value_loss           | 0.00105    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 4625    |
|    time_elapsed    | 15010   |
|    total_timesteps | 9472000 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4626       |
|    time_elapsed         | 15013      |
|    total_timesteps      | 9474048    |
| train/                  |            |
|    approx_kl            | 0.26545265 |
|    clip_fraction        | 0.331      |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.14       |
|    explained_variance   | 0.582      |
|    learning_rate        | 0.000153   |
|    loss                 | -0.0094    |
|    n_updates            | 46250      |
|    policy_gradient_loss | 0.0142     |
|    std                  | 0.0306     |
|    value_loss           | 0.000924   |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4627       |
|    time_elapsed         | 15016      |
|    total_timesteps      | 9476096    |
| train/                  |            |
|    approx_kl            | 0.12003225 |
|    clip_fraction        | 0.338      |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.15       |
|    explained_variance   | 0.587      |
|    learning_rate        | 0.000153   |
|    loss                 | -0.0186    |
|    n_updates            | 46260      |
|    policy_gradient_loss | 0.00559    |
|    std                  | 0.0305     |
|    value_loss           | 0.00102    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4628       |
|    time_elapsed         | 15019      |
|    total_timesteps      | 9478144    |
| train/                  |            |
|    approx_kl            | 0.23208788 |
|    clip_fraction        | 0.392      |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.16       |
|    explained_variance   | 0.631      |
|    learning_rate        | 0.000152   |
|    loss                 | -0.0433    |
|    n_updates            | 46270      |
|    policy_gradient_loss | -0.00172   |
|    std                  | 0.0303     |
|    value_loss           | 0.00394    |
----------------------------------------
box reached target
box reached target
Eval num_timesteps=9480000, episode_reward=-0.74 +/- 0.51
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -0.744     |
| time/                   |            |
|    total_timesteps      | 9480000    |
| train/                  |            |
|    approx_kl            | 0.20916441 |
|    clip_fraction        | 0.369      |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.17       |
|    explained_variance   | 0.721      |
|    learning_rate        | 0.000152   |
|    loss                 | 0.0041     |
|    n_updates            | 46280      |
|    policy_gradient_loss | 0.000297   |
|    std                  | 0.0303     |
|    value_loss           | 0.00462    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 4629    |
|    time_elapsed    | 15023   |
|    total_timesteps | 9480192 |
--------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 631         |
|    iterations           | 4630        |
|    time_elapsed         | 15026       |
|    total_timesteps      | 9482240     |
| train/                  |             |
|    approx_kl            | 0.101650596 |
|    clip_fraction        | 0.376       |
|    clip_range           | 0.2         |
|    entropy_loss         | 4.17        |
|    explained_variance   | 0.936       |
|    learning_rate        | 0.000151    |
|    loss                 | -0.00533    |
|    n_updates            | 46290       |
|    policy_gradient_loss | 0.0116      |
|    std                  | 0.0304      |
|    value_loss           | 0.0196      |
-----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4631       |
|    time_elapsed         | 15029      |
|    total_timesteps      | 9484288    |
| train/                  |            |
|    approx_kl            | 0.13517238 |
|    clip_fraction        | 0.382      |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.15       |
|    explained_variance   | 0.704      |
|    learning_rate        | 0.000151   |
|    loss                 | -0.0136    |
|    n_updates            | 46300      |
|    policy_gradient_loss | 0.00684    |
|    std                  | 0.0307     |
|    value_loss           | 0.00175    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4632       |
|    time_elapsed         | 15032      |
|    total_timesteps      | 9486336    |
| train/                  |            |
|    approx_kl            | 0.15863836 |
|    clip_fraction        | 0.318      |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.15       |
|    explained_variance   | 0.67       |
|    learning_rate        | 0.000151   |
|    loss                 | -0.0238    |
|    n_updates            | 46310      |
|    policy_gradient_loss | 0.00695    |
|    std                  | 0.0303     |
|    value_loss           | 0.000969   |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4633       |
|    time_elapsed         | 15035      |
|    total_timesteps      | 9488384    |
| train/                  |            |
|    approx_kl            | 0.13700445 |
|    clip_fraction        | 0.356      |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.18       |
|    explained_variance   | 0.00835    |
|    learning_rate        | 0.00015    |
|    loss                 | 0.0492     |
|    n_updates            | 46320      |
|    policy_gradient_loss | 0.00163    |
|    std                  | 0.0299     |
|    value_loss           | 0.00216    |
----------------------------------------
Eval num_timesteps=9490000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 300       |
|    mean_reward          | -1        |
| time/                   |           |
|    total_timesteps      | 9490000   |
| train/                  |           |
|    approx_kl            | 0.3870147 |
|    clip_fraction        | 0.41      |
|    clip_range           | 0.2       |
|    entropy_loss         | 4.2       |
|    explained_variance   | 0.962     |
|    learning_rate        | 0.00015   |
|    loss                 | -0.0199   |
|    n_updates            | 46330     |
|    policy_gradient_loss | 0.0115    |
|    std                  | 0.0298    |
|    value_loss           | 0.00477   |
---------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 4634    |
|    time_elapsed    | 15039   |
|    total_timesteps | 9490432 |
--------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 4635      |
|    time_elapsed         | 15042     |
|    total_timesteps      | 9492480   |
| train/                  |           |
|    approx_kl            | 0.1241438 |
|    clip_fraction        | 0.391     |
|    clip_range           | 0.2       |
|    entropy_loss         | 4.21      |
|    explained_variance   | 0.674     |
|    learning_rate        | 0.000149  |
|    loss                 | -0.0195   |
|    n_updates            | 46340     |
|    policy_gradient_loss | 0.00864   |
|    std                  | 0.0297    |
|    value_loss           | 0.00125   |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4636       |
|    time_elapsed         | 15045      |
|    total_timesteps      | 9494528    |
| train/                  |            |
|    approx_kl            | 0.41090184 |
|    clip_fraction        | 0.349      |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.21       |
|    explained_variance   | 0.462      |
|    learning_rate        | 0.000149   |
|    loss                 | 0.0539     |
|    n_updates            | 46350      |
|    policy_gradient_loss | 0.00794    |
|    std                  | 0.0296     |
|    value_loss           | 0.00213    |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4637       |
|    time_elapsed         | 15048      |
|    total_timesteps      | 9496576    |
| train/                  |            |
|    approx_kl            | 0.14431763 |
|    clip_fraction        | 0.392      |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.22       |
|    explained_variance   | 0.767      |
|    learning_rate        | 0.000149   |
|    loss                 | 0.0122     |
|    n_updates            | 46360      |
|    policy_gradient_loss | 0.0141     |
|    std                  | 0.0294     |
|    value_loss           | 0.000855   |
----------------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4638       |
|    time_elapsed         | 15051      |
|    total_timesteps      | 9498624    |
| train/                  |            |
|    approx_kl            | 0.22805226 |
|    clip_fraction        | 0.359      |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.23       |
|    explained_variance   | 0.978      |
|    learning_rate        | 0.000148   |
|    loss                 | 0.0331     |
|    n_updates            | 46370      |
|    policy_gradient_loss | 0.00492    |
|    std                  | 0.0294     |
|    value_loss           | 0.00308    |
----------------------------------------
Eval num_timesteps=9500000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 300       |
|    mean_reward          | -1        |
| time/                   |           |
|    total_timesteps      | 9500000   |
| train/                  |           |
|    approx_kl            | 0.1327162 |
|    clip_fraction        | 0.408     |
|    clip_range           | 0.2       |
|    entropy_loss         | 4.24      |
|    explained_variance   | 0.824     |
|    learning_rate        | 0.000148  |
|    loss                 | -0.0114   |
|    n_updates            | 46380     |
|    policy_gradient_loss | 0.0127    |
|    std                  | 0.0291    |
|    value_loss           | 0.0553    |
---------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 4639    |
|    time_elapsed    | 15055   |
|    total_timesteps | 9500672 |
--------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 4640      |
|    time_elapsed         | 15058     |
|    total_timesteps      | 9502720   |
| train/                  |           |
|    approx_kl            | 0.1716846 |
|    clip_fraction        | 0.356     |
|    clip_range           | 0.2       |
|    entropy_loss         | 4.25      |
|    explained_variance   | -0.0685   |
|    learning_rate        | 0.000147  |
|    loss                 | -0.0274   |
|    n_updates            | 46390     |
|    policy_gradient_loss | 0.00806   |
|    std                  | 0.029     |
|    value_loss           | 0.00115   |
---------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4641       |
|    time_elapsed         | 15061      |
|    total_timesteps      | 9504768    |
| train/                  |            |
|    approx_kl            | 0.15333623 |
|    clip_fraction        | 0.392      |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.26       |
|    explained_variance   | 0.74       |
|    learning_rate        | 0.000147   |
|    loss                 | -0.0163    |
|    n_updates            | 46400      |
|    policy_gradient_loss | 0.0219     |
|    std                  | 0.029      |
|    value_loss           | 0.00188    |
----------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 4642      |
|    time_elapsed         | 15064     |
|    total_timesteps      | 9506816   |
| train/                  |           |
|    approx_kl            | 0.1154623 |
|    clip_fraction        | 0.373     |
|    clip_range           | 0.2       |
|    entropy_loss         | 4.26      |
|    explained_variance   | 0.987     |
|    learning_rate        | 0.000147  |
|    loss                 | 0.0208    |
|    n_updates            | 46410     |
|    policy_gradient_loss | 0.0134    |
|    std                  | 0.0289    |
|    value_loss           | 0.00333   |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4643       |
|    time_elapsed         | 15068      |
|    total_timesteps      | 9508864    |
| train/                  |            |
|    approx_kl            | 0.23559798 |
|    clip_fraction        | 0.381      |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.27       |
|    explained_variance   | 0.981      |
|    learning_rate        | 0.000146   |
|    loss                 | 0.0163     |
|    n_updates            | 46420      |
|    policy_gradient_loss | 0.00507    |
|    std                  | 0.0287     |
|    value_loss           | 0.00363    |
----------------------------------------
Eval num_timesteps=9510000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1         |
| time/                   |            |
|    total_timesteps      | 9510000    |
| train/                  |            |
|    approx_kl            | 0.20599174 |
|    clip_fraction        | 0.354      |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.28       |
|    explained_variance   | 0.702      |
|    learning_rate        | 0.000146   |
|    loss                 | -0.0184    |
|    n_updates            | 46430      |
|    policy_gradient_loss | 0.00695    |
|    std                  | 0.0285     |
|    value_loss           | 0.00107    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 4644    |
|    time_elapsed    | 15072   |
|    total_timesteps | 9510912 |
--------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 4645      |
|    time_elapsed         | 15075     |
|    total_timesteps      | 9512960   |
| train/                  |           |
|    approx_kl            | 0.2686032 |
|    clip_fraction        | 0.345     |
|    clip_range           | 0.2       |
|    entropy_loss         | 4.29      |
|    explained_variance   | 0.396     |
|    learning_rate        | 0.000145  |
|    loss                 | -0.0199   |
|    n_updates            | 46440     |
|    policy_gradient_loss | -0.0112   |
|    std                  | 0.0283    |
|    value_loss           | 0.00303   |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4646       |
|    time_elapsed         | 15078      |
|    total_timesteps      | 9515008    |
| train/                  |            |
|    approx_kl            | 0.14282668 |
|    clip_fraction        | 0.343      |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.31       |
|    explained_variance   | 0.811      |
|    learning_rate        | 0.000145   |
|    loss                 | 0.0232     |
|    n_updates            | 46450      |
|    policy_gradient_loss | 0.00916    |
|    std                  | 0.0282     |
|    value_loss           | 0.000759   |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4647       |
|    time_elapsed         | 15081      |
|    total_timesteps      | 9517056    |
| train/                  |            |
|    approx_kl            | 0.14380701 |
|    clip_fraction        | 0.35       |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.31       |
|    explained_variance   | 0.607      |
|    learning_rate        | 0.000145   |
|    loss                 | 0.0174     |
|    n_updates            | 46460      |
|    policy_gradient_loss | 0.0064     |
|    std                  | 0.0282     |
|    value_loss           | 0.00106    |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4648       |
|    time_elapsed         | 15084      |
|    total_timesteps      | 9519104    |
| train/                  |            |
|    approx_kl            | 0.26881716 |
|    clip_fraction        | 0.353      |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.31       |
|    explained_variance   | 0.245      |
|    learning_rate        | 0.000144   |
|    loss                 | -0.00428   |
|    n_updates            | 46470      |
|    policy_gradient_loss | 0.01       |
|    std                  | 0.0282     |
|    value_loss           | 0.00137    |
----------------------------------------
Eval num_timesteps=9520000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1         |
| time/                   |            |
|    total_timesteps      | 9520000    |
| train/                  |            |
|    approx_kl            | 0.07333176 |
|    clip_fraction        | 0.348      |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.31       |
|    explained_variance   | 0.979      |
|    learning_rate        | 0.000144   |
|    loss                 | 0.0104     |
|    n_updates            | 46480      |
|    policy_gradient_loss | 0.0229     |
|    std                  | 0.0283     |
|    value_loss           | 0.00562    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 4649    |
|    time_elapsed    | 15088   |
|    total_timesteps | 9521152 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4650       |
|    time_elapsed         | 15091      |
|    total_timesteps      | 9523200    |
| train/                  |            |
|    approx_kl            | 0.27359757 |
|    clip_fraction        | 0.366      |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.31       |
|    explained_variance   | 0.798      |
|    learning_rate        | 0.000143   |
|    loss                 | -0.000954  |
|    n_updates            | 46490      |
|    policy_gradient_loss | 0.00118    |
|    std                  | 0.0281     |
|    value_loss           | 0.000729   |
----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 4651      |
|    time_elapsed         | 15094     |
|    total_timesteps      | 9525248   |
| train/                  |           |
|    approx_kl            | 0.1461324 |
|    clip_fraction        | 0.326     |
|    clip_range           | 0.2       |
|    entropy_loss         | 4.33      |
|    explained_variance   | 0.691     |
|    learning_rate        | 0.000143  |
|    loss                 | -0.0003   |
|    n_updates            | 46500     |
|    policy_gradient_loss | 0.00173   |
|    std                  | 0.0278    |
|    value_loss           | 0.00112   |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4652       |
|    time_elapsed         | 15097      |
|    total_timesteps      | 9527296    |
| train/                  |            |
|    approx_kl            | 0.09230675 |
|    clip_fraction        | 0.412      |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.34       |
|    explained_variance   | 0.842      |
|    learning_rate        | 0.000143   |
|    loss                 | 0.0118     |
|    n_updates            | 46510      |
|    policy_gradient_loss | 0.0233     |
|    std                  | 0.0279     |
|    value_loss           | 0.0097     |
----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 631         |
|    iterations           | 4653        |
|    time_elapsed         | 15100       |
|    total_timesteps      | 9529344     |
| train/                  |             |
|    approx_kl            | 0.035523646 |
|    clip_fraction        | 0.285       |
|    clip_range           | 0.2         |
|    entropy_loss         | 4.34        |
|    explained_variance   | 0.739       |
|    learning_rate        | 0.000142    |
|    loss                 | -0.0142     |
|    n_updates            | 46520       |
|    policy_gradient_loss | 0.00572     |
|    std                  | 0.0277      |
|    value_loss           | 0.000937    |
-----------------------------------------
Eval num_timesteps=9530000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 300         |
|    mean_reward          | -1          |
| time/                   |             |
|    total_timesteps      | 9530000     |
| train/                  |             |
|    approx_kl            | 0.098176695 |
|    clip_fraction        | 0.328       |
|    clip_range           | 0.2         |
|    entropy_loss         | 4.35        |
|    explained_variance   | 0.792       |
|    learning_rate        | 0.000142    |
|    loss                 | 0.033       |
|    n_updates            | 46530       |
|    policy_gradient_loss | 0.00123     |
|    std                  | 0.0276      |
|    value_loss           | 0.00103     |
-----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 4654    |
|    time_elapsed    | 15104   |
|    total_timesteps | 9531392 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4655       |
|    time_elapsed         | 15107      |
|    total_timesteps      | 9533440    |
| train/                  |            |
|    approx_kl            | 0.13869724 |
|    clip_fraction        | 0.417      |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.35       |
|    explained_variance   | 0.671      |
|    learning_rate        | 0.000141   |
|    loss                 | -0.0343    |
|    n_updates            | 46540      |
|    policy_gradient_loss | 0.0118     |
|    std                  | 0.0277     |
|    value_loss           | 0.00308    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4656       |
|    time_elapsed         | 15110      |
|    total_timesteps      | 9535488    |
| train/                  |            |
|    approx_kl            | 0.15490596 |
|    clip_fraction        | 0.377      |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.34       |
|    explained_variance   | 0.726      |
|    learning_rate        | 0.000141   |
|    loss                 | -0.0194    |
|    n_updates            | 46550      |
|    policy_gradient_loss | 0.00584    |
|    std                  | 0.0279     |
|    value_loss           | 0.00492    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4657       |
|    time_elapsed         | 15113      |
|    total_timesteps      | 9537536    |
| train/                  |            |
|    approx_kl            | 0.24629782 |
|    clip_fraction        | 0.341      |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.34       |
|    explained_variance   | 0.666      |
|    learning_rate        | 0.000141   |
|    loss                 | -0.0191    |
|    n_updates            | 46560      |
|    policy_gradient_loss | 0.00494    |
|    std                  | 0.0278     |
|    value_loss           | 0.00123    |
----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 4658      |
|    time_elapsed         | 15116     |
|    total_timesteps      | 9539584   |
| train/                  |           |
|    approx_kl            | 0.2784981 |
|    clip_fraction        | 0.355     |
|    clip_range           | 0.2       |
|    entropy_loss         | 4.34      |
|    explained_variance   | 0.605     |
|    learning_rate        | 0.00014   |
|    loss                 | -0.0339   |
|    n_updates            | 46570     |
|    policy_gradient_loss | 0.00171   |
|    std                  | 0.0277    |
|    value_loss           | 0.00117   |
---------------------------------------
Eval num_timesteps=9540000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 300       |
|    mean_reward          | -1        |
| time/                   |           |
|    total_timesteps      | 9540000   |
| train/                  |           |
|    approx_kl            | 0.4881498 |
|    clip_fraction        | 0.364     |
|    clip_range           | 0.2       |
|    entropy_loss         | 4.34      |
|    explained_variance   | 0.842     |
|    learning_rate        | 0.00014   |
|    loss                 | -0.043    |
|    n_updates            | 46580     |
|    policy_gradient_loss | 0.012     |
|    std                  | 0.0278    |
|    value_loss           | 0.00481   |
---------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 4659    |
|    time_elapsed    | 15120   |
|    total_timesteps | 9541632 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4660       |
|    time_elapsed         | 15123      |
|    total_timesteps      | 9543680    |
| train/                  |            |
|    approx_kl            | 0.35702747 |
|    clip_fraction        | 0.362      |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.34       |
|    explained_variance   | 0.342      |
|    learning_rate        | 0.000139   |
|    loss                 | -0.051     |
|    n_updates            | 46590      |
|    policy_gradient_loss | -0.00115   |
|    std                  | 0.0276     |
|    value_loss           | 0.00126    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4661       |
|    time_elapsed         | 15126      |
|    total_timesteps      | 9545728    |
| train/                  |            |
|    approx_kl            | 0.11353878 |
|    clip_fraction        | 0.349      |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.35       |
|    explained_variance   | 0.508      |
|    learning_rate        | 0.000139   |
|    loss                 | -0.00294   |
|    n_updates            | 46600      |
|    policy_gradient_loss | 0.000168   |
|    std                  | 0.0275     |
|    value_loss           | 0.00121    |
----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 4662      |
|    time_elapsed         | 15129     |
|    total_timesteps      | 9547776   |
| train/                  |           |
|    approx_kl            | 0.2933943 |
|    clip_fraction        | 0.376     |
|    clip_range           | 0.2       |
|    entropy_loss         | 4.36      |
|    explained_variance   | 0.707     |
|    learning_rate        | 0.000139  |
|    loss                 | 0.0231    |
|    n_updates            | 46610     |
|    policy_gradient_loss | -0.00214  |
|    std                  | 0.0275    |
|    value_loss           | 0.0213    |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4663       |
|    time_elapsed         | 15132      |
|    total_timesteps      | 9549824    |
| train/                  |            |
|    approx_kl            | 0.19658563 |
|    clip_fraction        | 0.396      |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.36       |
|    explained_variance   | 0.657      |
|    learning_rate        | 0.000138   |
|    loss                 | -0.0636    |
|    n_updates            | 46620      |
|    policy_gradient_loss | 0.000134   |
|    std                  | 0.0273     |
|    value_loss           | 0.00193    |
----------------------------------------
box reached target
Eval num_timesteps=9550000, episode_reward=0.32 +/- 2.65
Episode length: 289.20 +/- 21.60
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 289       |
|    mean_reward          | 0.324     |
| time/                   |           |
|    total_timesteps      | 9550000   |
| train/                  |           |
|    approx_kl            | 0.2310769 |
|    clip_fraction        | 0.381     |
|    clip_range           | 0.2       |
|    entropy_loss         | 4.37      |
|    explained_variance   | 0.647     |
|    learning_rate        | 0.000138  |
|    loss                 | 0.00152   |
|    n_updates            | 46630     |
|    policy_gradient_loss | 0.00572   |
|    std                  | 0.0275    |
|    value_loss           | 0.00108   |
---------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 4664    |
|    time_elapsed    | 15136   |
|    total_timesteps | 9551872 |
--------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4665       |
|    time_elapsed         | 15139      |
|    total_timesteps      | 9553920    |
| train/                  |            |
|    approx_kl            | 0.32319862 |
|    clip_fraction        | 0.342      |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.37       |
|    explained_variance   | 0.44       |
|    learning_rate        | 0.000137   |
|    loss                 | -0.0334    |
|    n_updates            | 46640      |
|    policy_gradient_loss | 0.00186    |
|    std                  | 0.0273     |
|    value_loss           | 0.00132    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4666       |
|    time_elapsed         | 15143      |
|    total_timesteps      | 9555968    |
| train/                  |            |
|    approx_kl            | 0.17789689 |
|    clip_fraction        | 0.433      |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.38       |
|    explained_variance   | 0.845      |
|    learning_rate        | 0.000137   |
|    loss                 | 0.0386     |
|    n_updates            | 46650      |
|    policy_gradient_loss | 0.00942    |
|    std                  | 0.0272     |
|    value_loss           | 0.0213     |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4667       |
|    time_elapsed         | 15146      |
|    total_timesteps      | 9558016    |
| train/                  |            |
|    approx_kl            | 0.17013408 |
|    clip_fraction        | 0.388      |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.38       |
|    explained_variance   | 0.62       |
|    learning_rate        | 0.000137   |
|    loss                 | -0.0145    |
|    n_updates            | 46660      |
|    policy_gradient_loss | 0.0368     |
|    std                  | 0.0272     |
|    value_loss           | 0.000978   |
----------------------------------------
Eval num_timesteps=9560000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1         |
| time/                   |            |
|    total_timesteps      | 9560000    |
| train/                  |            |
|    approx_kl            | 0.10062418 |
|    clip_fraction        | 0.322      |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.38       |
|    explained_variance   | 0.638      |
|    learning_rate        | 0.000136   |
|    loss                 | -0.00115   |
|    n_updates            | 46670      |
|    policy_gradient_loss | 0.00266    |
|    std                  | 0.0272     |
|    value_loss           | 0.00111    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 4668    |
|    time_elapsed    | 15150   |
|    total_timesteps | 9560064 |
--------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 4669      |
|    time_elapsed         | 15153     |
|    total_timesteps      | 9562112   |
| train/                  |           |
|    approx_kl            | 3.1787176 |
|    clip_fraction        | 0.403     |
|    clip_range           | 0.2       |
|    entropy_loss         | 4.38      |
|    explained_variance   | 0.762     |
|    learning_rate        | 0.000136  |
|    loss                 | -0.0243   |
|    n_updates            | 46680     |
|    policy_gradient_loss | 0.000997  |
|    std                  | 0.0273    |
|    value_loss           | 0.000918  |
---------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 4670      |
|    time_elapsed         | 15156     |
|    total_timesteps      | 9564160   |
| train/                  |           |
|    approx_kl            | 0.5018297 |
|    clip_fraction        | 0.422     |
|    clip_range           | 0.2       |
|    entropy_loss         | 4.37      |
|    explained_variance   | 0.769     |
|    learning_rate        | 0.000135  |
|    loss                 | -0.0167   |
|    n_updates            | 46690     |
|    policy_gradient_loss | 0.00451   |
|    std                  | 0.0272    |
|    value_loss           | 0.00908   |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4671       |
|    time_elapsed         | 15159      |
|    total_timesteps      | 9566208    |
| train/                  |            |
|    approx_kl            | 0.41440612 |
|    clip_fraction        | 0.358      |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.38       |
|    explained_variance   | 0.446      |
|    learning_rate        | 0.000135   |
|    loss                 | -0.00986   |
|    n_updates            | 46700      |
|    policy_gradient_loss | 0.00509    |
|    std                  | 0.0272     |
|    value_loss           | 0.0011     |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4672       |
|    time_elapsed         | 15162      |
|    total_timesteps      | 9568256    |
| train/                  |            |
|    approx_kl            | 0.15013319 |
|    clip_fraction        | 0.399      |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.38       |
|    explained_variance   | 0.67       |
|    learning_rate        | 0.000135   |
|    loss                 | -0.00564   |
|    n_updates            | 46710      |
|    policy_gradient_loss | 0.0101     |
|    std                  | 0.0273     |
|    value_loss           | 0.00604    |
----------------------------------------
box reached target
Eval num_timesteps=9570000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1         |
| time/                   |            |
|    total_timesteps      | 9570000    |
| train/                  |            |
|    approx_kl            | 0.19487959 |
|    clip_fraction        | 0.412      |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.37       |
|    explained_variance   | 0.942      |
|    learning_rate        | 0.000134   |
|    loss                 | 0.0444     |
|    n_updates            | 46720      |
|    policy_gradient_loss | 0.0219     |
|    std                  | 0.0274     |
|    value_loss           | 0.00719    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 4673    |
|    time_elapsed    | 15166   |
|    total_timesteps | 9570304 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4674       |
|    time_elapsed         | 15169      |
|    total_timesteps      | 9572352    |
| train/                  |            |
|    approx_kl            | 0.14503783 |
|    clip_fraction        | 0.371      |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.36       |
|    explained_variance   | 0.974      |
|    learning_rate        | 0.000134   |
|    loss                 | 0.0136     |
|    n_updates            | 46730      |
|    policy_gradient_loss | 0.0144     |
|    std                  | 0.0275     |
|    value_loss           | 0.00584    |
----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 631         |
|    iterations           | 4675        |
|    time_elapsed         | 15172       |
|    total_timesteps      | 9574400     |
| train/                  |             |
|    approx_kl            | 0.073945686 |
|    clip_fraction        | 0.424       |
|    clip_range           | 0.2         |
|    entropy_loss         | 4.35        |
|    explained_variance   | 0.82        |
|    learning_rate        | 0.000133    |
|    loss                 | 0.0812      |
|    n_updates            | 46740       |
|    policy_gradient_loss | 0.00599     |
|    std                  | 0.0277      |
|    value_loss           | 0.00631     |
-----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4676       |
|    time_elapsed         | 15175      |
|    total_timesteps      | 9576448    |
| train/                  |            |
|    approx_kl            | 0.07938978 |
|    clip_fraction        | 0.327      |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.35       |
|    explained_variance   | 0.775      |
|    learning_rate        | 0.000133   |
|    loss                 | 0.00244    |
|    n_updates            | 46750      |
|    policy_gradient_loss | 0.00528    |
|    std                  | 0.0276     |
|    value_loss           | 0.000641   |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4677       |
|    time_elapsed         | 15178      |
|    total_timesteps      | 9578496    |
| train/                  |            |
|    approx_kl            | 0.16145292 |
|    clip_fraction        | 0.417      |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.34       |
|    explained_variance   | 0.759      |
|    learning_rate        | 0.000133   |
|    loss                 | 0.0334     |
|    n_updates            | 46760      |
|    policy_gradient_loss | 0.014      |
|    std                  | 0.0279     |
|    value_loss           | 0.0059     |
----------------------------------------
box reached target
Eval num_timesteps=9580000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1         |
| time/                   |            |
|    total_timesteps      | 9580000    |
| train/                  |            |
|    approx_kl            | 0.09298349 |
|    clip_fraction        | 0.369      |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.32       |
|    explained_variance   | 0.705      |
|    learning_rate        | 0.000132   |
|    loss                 | -0.00952   |
|    n_updates            | 46770      |
|    policy_gradient_loss | 0.0163     |
|    std                  | 0.0281     |
|    value_loss           | 0.119      |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 4678    |
|    time_elapsed    | 15182   |
|    total_timesteps | 9580544 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4679       |
|    time_elapsed         | 15185      |
|    total_timesteps      | 9582592    |
| train/                  |            |
|    approx_kl            | 0.10760778 |
|    clip_fraction        | 0.308      |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.32       |
|    explained_variance   | 0.977      |
|    learning_rate        | 0.000132   |
|    loss                 | -0.0259    |
|    n_updates            | 46780      |
|    policy_gradient_loss | 0.00422    |
|    std                  | 0.0279     |
|    value_loss           | 0.00198    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4680       |
|    time_elapsed         | 15188      |
|    total_timesteps      | 9584640    |
| train/                  |            |
|    approx_kl            | 0.16743651 |
|    clip_fraction        | 0.322      |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.33       |
|    explained_variance   | 0.528      |
|    learning_rate        | 0.000131   |
|    loss                 | -0.0199    |
|    n_updates            | 46790      |
|    policy_gradient_loss | 0.000767   |
|    std                  | 0.0279     |
|    value_loss           | 0.00124    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4681       |
|    time_elapsed         | 15191      |
|    total_timesteps      | 9586688    |
| train/                  |            |
|    approx_kl            | 0.20486248 |
|    clip_fraction        | 0.382      |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.33       |
|    explained_variance   | 0.659      |
|    learning_rate        | 0.000131   |
|    loss                 | -0.0255    |
|    n_updates            | 46800      |
|    policy_gradient_loss | 0.00891    |
|    std                  | 0.028      |
|    value_loss           | 0.00122    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4682       |
|    time_elapsed         | 15194      |
|    total_timesteps      | 9588736    |
| train/                  |            |
|    approx_kl            | 0.08312831 |
|    clip_fraction        | 0.311      |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.33       |
|    explained_variance   | 0.473      |
|    learning_rate        | 0.000131   |
|    loss                 | -0.0112    |
|    n_updates            | 46810      |
|    policy_gradient_loss | -0.00327   |
|    std                  | 0.0278     |
|    value_loss           | 0.000997   |
----------------------------------------
Eval num_timesteps=9590000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 300         |
|    mean_reward          | -1          |
| time/                   |             |
|    total_timesteps      | 9590000     |
| train/                  |             |
|    approx_kl            | 0.093342185 |
|    clip_fraction        | 0.346       |
|    clip_range           | 0.2         |
|    entropy_loss         | 4.35        |
|    explained_variance   | 0.443       |
|    learning_rate        | 0.00013     |
|    loss                 | -0.0333     |
|    n_updates            | 46820       |
|    policy_gradient_loss | 0.00769     |
|    std                  | 0.0276      |
|    value_loss           | 0.000936    |
-----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 4683    |
|    time_elapsed    | 15198   |
|    total_timesteps | 9590784 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4684       |
|    time_elapsed         | 15201      |
|    total_timesteps      | 9592832    |
| train/                  |            |
|    approx_kl            | 0.10990515 |
|    clip_fraction        | 0.345      |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.36       |
|    explained_variance   | 0.551      |
|    learning_rate        | 0.00013    |
|    loss                 | -0.0119    |
|    n_updates            | 46830      |
|    policy_gradient_loss | -0.00124   |
|    std                  | 0.0275     |
|    value_loss           | 0.000945   |
----------------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4685       |
|    time_elapsed         | 15204      |
|    total_timesteps      | 9594880    |
| train/                  |            |
|    approx_kl            | 0.16415577 |
|    clip_fraction        | 0.325      |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.36       |
|    explained_variance   | 0.755      |
|    learning_rate        | 0.000129   |
|    loss                 | -0.0358    |
|    n_updates            | 46840      |
|    policy_gradient_loss | 0.0145     |
|    std                  | 0.0274     |
|    value_loss           | 0.000728   |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4686       |
|    time_elapsed         | 15207      |
|    total_timesteps      | 9596928    |
| train/                  |            |
|    approx_kl            | 0.24903187 |
|    clip_fraction        | 0.453      |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.37       |
|    explained_variance   | 0.824      |
|    learning_rate        | 0.000129   |
|    loss                 | -0.0105    |
|    n_updates            | 46850      |
|    policy_gradient_loss | 0.0122     |
|    std                  | 0.0274     |
|    value_loss           | 0.0572     |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4687       |
|    time_elapsed         | 15211      |
|    total_timesteps      | 9598976    |
| train/                  |            |
|    approx_kl            | 0.07077883 |
|    clip_fraction        | 0.448      |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.36       |
|    explained_variance   | 0.39       |
|    learning_rate        | 0.000129   |
|    loss                 | 0.0989     |
|    n_updates            | 46860      |
|    policy_gradient_loss | 0.029      |
|    std                  | 0.0276     |
|    value_loss           | 0.112      |
----------------------------------------
Eval num_timesteps=9600000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 300       |
|    mean_reward          | -1        |
| time/                   |           |
|    total_timesteps      | 9600000   |
| train/                  |           |
|    approx_kl            | 0.1644981 |
|    clip_fraction        | 0.303     |
|    clip_range           | 0.2       |
|    entropy_loss         | 4.36      |
|    explained_variance   | 0.395     |
|    learning_rate        | 0.000128  |
|    loss                 | 0.00935   |
|    n_updates            | 46870     |
|    policy_gradient_loss | -0.00836  |
|    std                  | 0.0275    |
|    value_loss           | 0.00401   |
---------------------------------------
box reached target
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 4688    |
|    time_elapsed    | 15215   |
|    total_timesteps | 9601024 |
--------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 631         |
|    iterations           | 4689        |
|    time_elapsed         | 15218       |
|    total_timesteps      | 9603072     |
| train/                  |             |
|    approx_kl            | 0.080312505 |
|    clip_fraction        | 0.377       |
|    clip_range           | 0.2         |
|    entropy_loss         | 4.36        |
|    explained_variance   | 0.958       |
|    learning_rate        | 0.000128    |
|    loss                 | -0.0613     |
|    n_updates            | 46880       |
|    policy_gradient_loss | 0.014       |
|    std                  | 0.0276      |
|    value_loss           | 0.0113      |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 631         |
|    iterations           | 4690        |
|    time_elapsed         | 15221       |
|    total_timesteps      | 9605120     |
| train/                  |             |
|    approx_kl            | 0.058055382 |
|    clip_fraction        | 0.328       |
|    clip_range           | 0.2         |
|    entropy_loss         | 4.36        |
|    explained_variance   | 0.767       |
|    learning_rate        | 0.000127    |
|    loss                 | 0.0412      |
|    n_updates            | 46890       |
|    policy_gradient_loss | 0.00695     |
|    std                  | 0.0275      |
|    value_loss           | 0.00242     |
-----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4691       |
|    time_elapsed         | 15224      |
|    total_timesteps      | 9607168    |
| train/                  |            |
|    approx_kl            | 0.18530747 |
|    clip_fraction        | 0.375      |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.36       |
|    explained_variance   | 0.333      |
|    learning_rate        | 0.000127   |
|    loss                 | -0.016     |
|    n_updates            | 46900      |
|    policy_gradient_loss | 0.0203     |
|    std                  | 0.0276     |
|    value_loss           | 0.00243    |
----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 631         |
|    iterations           | 4692        |
|    time_elapsed         | 15227       |
|    total_timesteps      | 9609216     |
| train/                  |             |
|    approx_kl            | 0.045218103 |
|    clip_fraction        | 0.257       |
|    clip_range           | 0.2         |
|    entropy_loss         | 4.36        |
|    explained_variance   | 0.689       |
|    learning_rate        | 0.000127    |
|    loss                 | 0.00786     |
|    n_updates            | 46910       |
|    policy_gradient_loss | 0.00845     |
|    std                  | 0.0275      |
|    value_loss           | 0.000811    |
-----------------------------------------
Eval num_timesteps=9610000, episode_reward=-0.79 +/- 0.41
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -0.795     |
| time/                   |            |
|    total_timesteps      | 9610000    |
| train/                  |            |
|    approx_kl            | 0.17863926 |
|    clip_fraction        | 0.303      |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.36       |
|    explained_variance   | 0.587      |
|    learning_rate        | 0.000126   |
|    loss                 | 0.0131     |
|    n_updates            | 46920      |
|    policy_gradient_loss | 0.00439    |
|    std                  | 0.0275     |
|    value_loss           | 0.00149    |
----------------------------------------
box reached target
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 4693    |
|    time_elapsed    | 15231   |
|    total_timesteps | 9611264 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4694       |
|    time_elapsed         | 15234      |
|    total_timesteps      | 9613312    |
| train/                  |            |
|    approx_kl            | 0.15857957 |
|    clip_fraction        | 0.367      |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.37       |
|    explained_variance   | 0.976      |
|    learning_rate        | 0.000126   |
|    loss                 | 0.000661   |
|    n_updates            | 46930      |
|    policy_gradient_loss | 0.00731    |
|    std                  | 0.0274     |
|    value_loss           | 0.00411    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4695       |
|    time_elapsed         | 15237      |
|    total_timesteps      | 9615360    |
| train/                  |            |
|    approx_kl            | 0.08689318 |
|    clip_fraction        | 0.322      |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.37       |
|    explained_variance   | 0.387      |
|    learning_rate        | 0.000125   |
|    loss                 | -0.00666   |
|    n_updates            | 46940      |
|    policy_gradient_loss | 0.0116     |
|    std                  | 0.0273     |
|    value_loss           | 0.0016     |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4696       |
|    time_elapsed         | 15240      |
|    total_timesteps      | 9617408    |
| train/                  |            |
|    approx_kl            | 0.36635852 |
|    clip_fraction        | 0.354      |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.38       |
|    explained_variance   | 0.699      |
|    learning_rate        | 0.000125   |
|    loss                 | -0.0109    |
|    n_updates            | 46950      |
|    policy_gradient_loss | 0.0083     |
|    std                  | 0.0272     |
|    value_loss           | 0.000993   |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4697       |
|    time_elapsed         | 15243      |
|    total_timesteps      | 9619456    |
| train/                  |            |
|    approx_kl            | 0.09717604 |
|    clip_fraction        | 0.32       |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.39       |
|    explained_variance   | 0.53       |
|    learning_rate        | 0.000125   |
|    loss                 | 0.0103     |
|    n_updates            | 46960      |
|    policy_gradient_loss | 0.00646    |
|    std                  | 0.027      |
|    value_loss           | 0.00133    |
----------------------------------------
Eval num_timesteps=9620000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1         |
| time/                   |            |
|    total_timesteps      | 9620000    |
| train/                  |            |
|    approx_kl            | 0.08492131 |
|    clip_fraction        | 0.334      |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.4        |
|    explained_variance   | 0.698      |
|    learning_rate        | 0.000124   |
|    loss                 | 0.0148     |
|    n_updates            | 46970      |
|    policy_gradient_loss | -0.0016    |
|    std                  | 0.0269     |
|    value_loss           | 0.00117    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 4698    |
|    time_elapsed    | 15247   |
|    total_timesteps | 9621504 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4699       |
|    time_elapsed         | 15250      |
|    total_timesteps      | 9623552    |
| train/                  |            |
|    approx_kl            | 0.06494725 |
|    clip_fraction        | 0.302      |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.41       |
|    explained_variance   | 0.267      |
|    learning_rate        | 0.000124   |
|    loss                 | -0.0279    |
|    n_updates            | 46980      |
|    policy_gradient_loss | -0.00127   |
|    std                  | 0.0269     |
|    value_loss           | 0.00231    |
----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 4700      |
|    time_elapsed         | 15253     |
|    total_timesteps      | 9625600   |
| train/                  |           |
|    approx_kl            | 0.1368306 |
|    clip_fraction        | 0.337     |
|    clip_range           | 0.2       |
|    entropy_loss         | 4.41      |
|    explained_variance   | 0.805     |
|    learning_rate        | 0.000123  |
|    loss                 | -0.0269   |
|    n_updates            | 46990     |
|    policy_gradient_loss | 0.000683  |
|    std                  | 0.0268    |
|    value_loss           | 0.00249   |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4701       |
|    time_elapsed         | 15256      |
|    total_timesteps      | 9627648    |
| train/                  |            |
|    approx_kl            | 0.21028721 |
|    clip_fraction        | 0.331      |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.41       |
|    explained_variance   | 0.594      |
|    learning_rate        | 0.000123   |
|    loss                 | -0.0317    |
|    n_updates            | 47000      |
|    policy_gradient_loss | -0.002     |
|    std                  | 0.0267     |
|    value_loss           | 0.00133    |
----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 4702      |
|    time_elapsed         | 15259     |
|    total_timesteps      | 9629696   |
| train/                  |           |
|    approx_kl            | 0.3306596 |
|    clip_fraction        | 0.423     |
|    clip_range           | 0.2       |
|    entropy_loss         | 4.42      |
|    explained_variance   | 0.587     |
|    learning_rate        | 0.000123  |
|    loss                 | -0.0394   |
|    n_updates            | 47010     |
|    policy_gradient_loss | 0.00411   |
|    std                  | 0.0268    |
|    value_loss           | 0.00632   |
---------------------------------------
Eval num_timesteps=9630000, episode_reward=-0.69 +/- 0.62
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -0.691     |
| time/                   |            |
|    total_timesteps      | 9630000    |
| train/                  |            |
|    approx_kl            | 0.08878314 |
|    clip_fraction        | 0.341      |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.41       |
|    explained_variance   | 0.65       |
|    learning_rate        | 0.000122   |
|    loss                 | -0.0234    |
|    n_updates            | 47020      |
|    policy_gradient_loss | 0.00485    |
|    std                  | 0.0268     |
|    value_loss           | 0.00137    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 4703    |
|    time_elapsed    | 15263   |
|    total_timesteps | 9631744 |
--------------------------------
--------------------------------------
| time/                   |          |
|    fps                  | 631      |
|    iterations           | 4704     |
|    time_elapsed         | 15266    |
|    total_timesteps      | 9633792  |
| train/                  |          |
|    approx_kl            | 0.103988 |
|    clip_fraction        | 0.328    |
|    clip_range           | 0.2      |
|    entropy_loss         | 4.41     |
|    explained_variance   | 0.724    |
|    learning_rate        | 0.000122 |
|    loss                 | 0.00342  |
|    n_updates            | 47030    |
|    policy_gradient_loss | 0.0175   |
|    std                  | 0.0267   |
|    value_loss           | 0.000941 |
--------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4705       |
|    time_elapsed         | 15269      |
|    total_timesteps      | 9635840    |
| train/                  |            |
|    approx_kl            | 0.23546219 |
|    clip_fraction        | 0.315      |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.42       |
|    explained_variance   | 0.593      |
|    learning_rate        | 0.000121   |
|    loss                 | -0.0404    |
|    n_updates            | 47040      |
|    policy_gradient_loss | -0.0106    |
|    std                  | 0.0266     |
|    value_loss           | 0.000874   |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4706       |
|    time_elapsed         | 15272      |
|    total_timesteps      | 9637888    |
| train/                  |            |
|    approx_kl            | 0.11795311 |
|    clip_fraction        | 0.299      |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.43       |
|    explained_variance   | 0.773      |
|    learning_rate        | 0.000121   |
|    loss                 | -0.0137    |
|    n_updates            | 47050      |
|    policy_gradient_loss | 0.00139    |
|    std                  | 0.0266     |
|    value_loss           | 0.000668   |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4707       |
|    time_elapsed         | 15275      |
|    total_timesteps      | 9639936    |
| train/                  |            |
|    approx_kl            | 0.18970591 |
|    clip_fraction        | 0.376      |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.42       |
|    explained_variance   | 0.69       |
|    learning_rate        | 0.000121   |
|    loss                 | 0.0188     |
|    n_updates            | 47060      |
|    policy_gradient_loss | 0.0171     |
|    std                  | 0.0268     |
|    value_loss           | 0.00129    |
----------------------------------------
Eval num_timesteps=9640000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 300         |
|    mean_reward          | -1          |
| time/                   |             |
|    total_timesteps      | 9640000     |
| train/                  |             |
|    approx_kl            | 0.042598806 |
|    clip_fraction        | 0.28        |
|    clip_range           | 0.2         |
|    entropy_loss         | 4.41        |
|    explained_variance   | 0.86        |
|    learning_rate        | 0.00012     |
|    loss                 | 0.0196      |
|    n_updates            | 47070       |
|    policy_gradient_loss | 0.0208      |
|    std                  | 0.0269      |
|    value_loss           | 0.00145     |
-----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 4708    |
|    time_elapsed    | 15279   |
|    total_timesteps | 9641984 |
--------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 4709      |
|    time_elapsed         | 15283     |
|    total_timesteps      | 9644032   |
| train/                  |           |
|    approx_kl            | 0.3085816 |
|    clip_fraction        | 0.333     |
|    clip_range           | 0.2       |
|    entropy_loss         | 4.4       |
|    explained_variance   | 0.411     |
|    learning_rate        | 0.00012   |
|    loss                 | -0.017    |
|    n_updates            | 47080     |
|    policy_gradient_loss | 0.00418   |
|    std                  | 0.0269    |
|    value_loss           | 0.00166   |
---------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 4710      |
|    time_elapsed         | 15286     |
|    total_timesteps      | 9646080   |
| train/                  |           |
|    approx_kl            | 0.4675243 |
|    clip_fraction        | 0.389     |
|    clip_range           | 0.2       |
|    entropy_loss         | 4.41      |
|    explained_variance   | 0.58      |
|    learning_rate        | 0.000119  |
|    loss                 | -0.0131   |
|    n_updates            | 47090     |
|    policy_gradient_loss | 0.00222   |
|    std                  | 0.0267    |
|    value_loss           | 0.00136   |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4711       |
|    time_elapsed         | 15289      |
|    total_timesteps      | 9648128    |
| train/                  |            |
|    approx_kl            | 0.10327846 |
|    clip_fraction        | 0.288      |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.42       |
|    explained_variance   | 0.759      |
|    learning_rate        | 0.000119   |
|    loss                 | -0.0396    |
|    n_updates            | 47100      |
|    policy_gradient_loss | 0.000988   |
|    std                  | 0.0266     |
|    value_loss           | 0.000726   |
----------------------------------------
box reached target
Eval num_timesteps=9650000, episode_reward=0.23 +/- 2.46
Episode length: 271.80 +/- 56.40
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 272        |
|    mean_reward          | 0.232      |
| time/                   |            |
|    total_timesteps      | 9650000    |
| train/                  |            |
|    approx_kl            | 0.16558607 |
|    clip_fraction        | 0.412      |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.42       |
|    explained_variance   | 0.696      |
|    learning_rate        | 0.000119   |
|    loss                 | -0.0382    |
|    n_updates            | 47110      |
|    policy_gradient_loss | 0.0129     |
|    std                  | 0.0267     |
|    value_loss           | 0.00129    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 4712    |
|    time_elapsed    | 15293   |
|    total_timesteps | 9650176 |
--------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4713       |
|    time_elapsed         | 15296      |
|    total_timesteps      | 9652224    |
| train/                  |            |
|    approx_kl            | 0.38304853 |
|    clip_fraction        | 0.394      |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.42       |
|    explained_variance   | 0.612      |
|    learning_rate        | 0.000118   |
|    loss                 | -0.0466    |
|    n_updates            | 47120      |
|    policy_gradient_loss | -0.00175   |
|    std                  | 0.0267     |
|    value_loss           | 0.00249    |
----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 631         |
|    iterations           | 4714        |
|    time_elapsed         | 15299       |
|    total_timesteps      | 9654272     |
| train/                  |             |
|    approx_kl            | 0.094115816 |
|    clip_fraction        | 0.408       |
|    clip_range           | 0.2         |
|    entropy_loss         | 4.43        |
|    explained_variance   | 0.688       |
|    learning_rate        | 0.000118    |
|    loss                 | 0.0215      |
|    n_updates            | 47130       |
|    policy_gradient_loss | 0.00679     |
|    std                  | 0.0266      |
|    value_loss           | 0.0363      |
-----------------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 631         |
|    iterations           | 4715        |
|    time_elapsed         | 15302       |
|    total_timesteps      | 9656320     |
| train/                  |             |
|    approx_kl            | 0.085182056 |
|    clip_fraction        | 0.283       |
|    clip_range           | 0.2         |
|    entropy_loss         | 4.44        |
|    explained_variance   | 0.631       |
|    learning_rate        | 0.000117    |
|    loss                 | 0.0154      |
|    n_updates            | 47140       |
|    policy_gradient_loss | -0.003      |
|    std                  | 0.0263      |
|    value_loss           | 0.00112     |
-----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 4716      |
|    time_elapsed         | 15305     |
|    total_timesteps      | 9658368   |
| train/                  |           |
|    approx_kl            | 1.0745554 |
|    clip_fraction        | 0.384     |
|    clip_range           | 0.2       |
|    entropy_loss         | 4.45      |
|    explained_variance   | 0.932     |
|    learning_rate        | 0.000117  |
|    loss                 | 0.029     |
|    n_updates            | 47150     |
|    policy_gradient_loss | 0.00577   |
|    std                  | 0.0262    |
|    value_loss           | 0.00404   |
---------------------------------------
box reached target
Eval num_timesteps=9660000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1         |
| time/                   |            |
|    total_timesteps      | 9660000    |
| train/                  |            |
|    approx_kl            | 0.12520337 |
|    clip_fraction        | 0.289      |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.46       |
|    explained_variance   | 0.778      |
|    learning_rate        | 0.000117   |
|    loss                 | -0.031     |
|    n_updates            | 47160      |
|    policy_gradient_loss | 0.00203    |
|    std                  | 0.026      |
|    value_loss           | 0.000857   |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 4717    |
|    time_elapsed    | 15309   |
|    total_timesteps | 9660416 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4718       |
|    time_elapsed         | 15312      |
|    total_timesteps      | 9662464    |
| train/                  |            |
|    approx_kl            | 0.23358804 |
|    clip_fraction        | 0.395      |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.47       |
|    explained_variance   | 0.432      |
|    learning_rate        | 0.000116   |
|    loss                 | 0.00725    |
|    n_updates            | 47170      |
|    policy_gradient_loss | 0.00788    |
|    std                  | 0.026      |
|    value_loss           | 0.128      |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4719       |
|    time_elapsed         | 15315      |
|    total_timesteps      | 9664512    |
| train/                  |            |
|    approx_kl            | 0.08865597 |
|    clip_fraction        | 0.283      |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.48       |
|    explained_variance   | 0.818      |
|    learning_rate        | 0.000116   |
|    loss                 | -0.00953   |
|    n_updates            | 47180      |
|    policy_gradient_loss | -0.00117   |
|    std                  | 0.0258     |
|    value_loss           | 0.000718   |
----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 631         |
|    iterations           | 4720        |
|    time_elapsed         | 15318       |
|    total_timesteps      | 9666560     |
| train/                  |             |
|    approx_kl            | 0.029472005 |
|    clip_fraction        | 0.262       |
|    clip_range           | 0.2         |
|    entropy_loss         | 4.49        |
|    explained_variance   | 0.813       |
|    learning_rate        | 0.000115    |
|    loss                 | -0.0279     |
|    n_updates            | 47190       |
|    policy_gradient_loss | 0.0151      |
|    std                  | 0.0258      |
|    value_loss           | 0.000892    |
-----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4721       |
|    time_elapsed         | 15321      |
|    total_timesteps      | 9668608    |
| train/                  |            |
|    approx_kl            | 0.19957179 |
|    clip_fraction        | 0.345      |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.49       |
|    explained_variance   | 0.824      |
|    learning_rate        | 0.000115   |
|    loss                 | 0.0528     |
|    n_updates            | 47200      |
|    policy_gradient_loss | 0.00393    |
|    std                  | 0.0257     |
|    value_loss           | 0.000648   |
----------------------------------------
Eval num_timesteps=9670000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1         |
| time/                   |            |
|    total_timesteps      | 9670000    |
| train/                  |            |
|    approx_kl            | 0.11521779 |
|    clip_fraction        | 0.338      |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.49       |
|    explained_variance   | 0.83       |
|    learning_rate        | 0.000115   |
|    loss                 | 0.0409     |
|    n_updates            | 47210      |
|    policy_gradient_loss | 0.00648    |
|    std                  | 0.0257     |
|    value_loss           | 0.000609   |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 4722    |
|    time_elapsed    | 15325   |
|    total_timesteps | 9670656 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4723       |
|    time_elapsed         | 15328      |
|    total_timesteps      | 9672704    |
| train/                  |            |
|    approx_kl            | 0.30392712 |
|    clip_fraction        | 0.368      |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.49       |
|    explained_variance   | 0.672      |
|    learning_rate        | 0.000114   |
|    loss                 | 0.00101    |
|    n_updates            | 47220      |
|    policy_gradient_loss | 0.00623    |
|    std                  | 0.0258     |
|    value_loss           | 0.00171    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4724       |
|    time_elapsed         | 15331      |
|    total_timesteps      | 9674752    |
| train/                  |            |
|    approx_kl            | 0.11083844 |
|    clip_fraction        | 0.297      |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.49       |
|    explained_variance   | 0.724      |
|    learning_rate        | 0.000114   |
|    loss                 | 0.00315    |
|    n_updates            | 47230      |
|    policy_gradient_loss | 0.00135    |
|    std                  | 0.0257     |
|    value_loss           | 0.000903   |
----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 631         |
|    iterations           | 4725        |
|    time_elapsed         | 15334       |
|    total_timesteps      | 9676800     |
| train/                  |             |
|    approx_kl            | 0.091600366 |
|    clip_fraction        | 0.328       |
|    clip_range           | 0.2         |
|    entropy_loss         | 4.49        |
|    explained_variance   | 0.803       |
|    learning_rate        | 0.000113    |
|    loss                 | -0.00477    |
|    n_updates            | 47240       |
|    policy_gradient_loss | -0.00671    |
|    std                  | 0.0258      |
|    value_loss           | 0.00808     |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 631         |
|    iterations           | 4726        |
|    time_elapsed         | 15337       |
|    total_timesteps      | 9678848     |
| train/                  |             |
|    approx_kl            | 0.074211806 |
|    clip_fraction        | 0.382       |
|    clip_range           | 0.2         |
|    entropy_loss         | 4.49        |
|    explained_variance   | 0.748       |
|    learning_rate        | 0.000113    |
|    loss                 | -0.00295    |
|    n_updates            | 47250       |
|    policy_gradient_loss | 0.00485     |
|    std                  | 0.0258      |
|    value_loss           | 0.0076      |
-----------------------------------------
Eval num_timesteps=9680000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1         |
| time/                   |            |
|    total_timesteps      | 9680000    |
| train/                  |            |
|    approx_kl            | 0.06621776 |
|    clip_fraction        | 0.298      |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.49       |
|    explained_variance   | 0.766      |
|    learning_rate        | 0.000113   |
|    loss                 | -0.0233    |
|    n_updates            | 47260      |
|    policy_gradient_loss | 0.00371    |
|    std                  | 0.0258     |
|    value_loss           | 0.000946   |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 4727    |
|    time_elapsed    | 15341   |
|    total_timesteps | 9680896 |
--------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4728       |
|    time_elapsed         | 15344      |
|    total_timesteps      | 9682944    |
| train/                  |            |
|    approx_kl            | 0.05895555 |
|    clip_fraction        | 0.356      |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.48       |
|    explained_variance   | 0.79       |
|    learning_rate        | 0.000112   |
|    loss                 | -0.0307    |
|    n_updates            | 47270      |
|    policy_gradient_loss | 0.0166     |
|    std                  | 0.0259     |
|    value_loss           | 0.00342    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4729       |
|    time_elapsed         | 15347      |
|    total_timesteps      | 9684992    |
| train/                  |            |
|    approx_kl            | 0.07755534 |
|    clip_fraction        | 0.383      |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.47       |
|    explained_variance   | 0.966      |
|    learning_rate        | 0.000112   |
|    loss                 | 0.0474     |
|    n_updates            | 47280      |
|    policy_gradient_loss | 0.0128     |
|    std                  | 0.026      |
|    value_loss           | 0.00622    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4730       |
|    time_elapsed         | 15350      |
|    total_timesteps      | 9687040    |
| train/                  |            |
|    approx_kl            | 0.38212168 |
|    clip_fraction        | 0.357      |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.47       |
|    explained_variance   | 0.415      |
|    learning_rate        | 0.000111   |
|    loss                 | -0.0309    |
|    n_updates            | 47290      |
|    policy_gradient_loss | 0.00038    |
|    std                  | 0.026      |
|    value_loss           | 0.00172    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4731       |
|    time_elapsed         | 15353      |
|    total_timesteps      | 9689088    |
| train/                  |            |
|    approx_kl            | 0.17918058 |
|    clip_fraction        | 0.304      |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.47       |
|    explained_variance   | 0.848      |
|    learning_rate        | 0.000111   |
|    loss                 | -0.00734   |
|    n_updates            | 47300      |
|    policy_gradient_loss | 0.00386    |
|    std                  | 0.0261     |
|    value_loss           | 0.000587   |
----------------------------------------
Eval num_timesteps=9690000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 300       |
|    mean_reward          | -1        |
| time/                   |           |
|    total_timesteps      | 9690000   |
| train/                  |           |
|    approx_kl            | 0.1343998 |
|    clip_fraction        | 0.338     |
|    clip_range           | 0.2       |
|    entropy_loss         | 4.46      |
|    explained_variance   | 0.581     |
|    learning_rate        | 0.000111  |
|    loss                 | 0.00714   |
|    n_updates            | 47310     |
|    policy_gradient_loss | 0.00794   |
|    std                  | 0.0261    |
|    value_loss           | 0.00141   |
---------------------------------------
box reached target
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 4732    |
|    time_elapsed    | 15357   |
|    total_timesteps | 9691136 |
--------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 4733      |
|    time_elapsed         | 15360     |
|    total_timesteps      | 9693184   |
| train/                  |           |
|    approx_kl            | 0.8684472 |
|    clip_fraction        | 0.378     |
|    clip_range           | 0.2       |
|    entropy_loss         | 4.47      |
|    explained_variance   | 0.991     |
|    learning_rate        | 0.00011   |
|    loss                 | -0.0465   |
|    n_updates            | 47320     |
|    policy_gradient_loss | -0.00844  |
|    std                  | 0.0259    |
|    value_loss           | 0.00444   |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4734       |
|    time_elapsed         | 15364      |
|    total_timesteps      | 9695232    |
| train/                  |            |
|    approx_kl            | 0.09558681 |
|    clip_fraction        | 0.266      |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.48       |
|    explained_variance   | 0.401      |
|    learning_rate        | 0.00011    |
|    loss                 | 0.00899    |
|    n_updates            | 47330      |
|    policy_gradient_loss | 0.00012    |
|    std                  | 0.0258     |
|    value_loss           | 0.000904   |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4735       |
|    time_elapsed         | 15367      |
|    total_timesteps      | 9697280    |
| train/                  |            |
|    approx_kl            | 0.07800107 |
|    clip_fraction        | 0.3        |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.49       |
|    explained_variance   | 0.794      |
|    learning_rate        | 0.000109   |
|    loss                 | -0.0304    |
|    n_updates            | 47340      |
|    policy_gradient_loss | -0.000643  |
|    std                  | 0.0257     |
|    value_loss           | 0.000827   |
----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 4736      |
|    time_elapsed         | 15370     |
|    total_timesteps      | 9699328   |
| train/                  |           |
|    approx_kl            | 4.1722856 |
|    clip_fraction        | 0.434     |
|    clip_range           | 0.2       |
|    entropy_loss         | 4.5       |
|    explained_variance   | 0.673     |
|    learning_rate        | 0.000109  |
|    loss                 | 0.00208   |
|    n_updates            | 47350     |
|    policy_gradient_loss | 0.0433    |
|    std                  | 0.0256    |
|    value_loss           | 0.00105   |
---------------------------------------
Eval num_timesteps=9700000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 300       |
|    mean_reward          | -1        |
| time/                   |           |
|    total_timesteps      | 9700000   |
| train/                  |           |
|    approx_kl            | 0.2599108 |
|    clip_fraction        | 0.353     |
|    clip_range           | 0.2       |
|    entropy_loss         | 4.51      |
|    explained_variance   | 0.666     |
|    learning_rate        | 0.000109  |
|    loss                 | -0.0186   |
|    n_updates            | 47360     |
|    policy_gradient_loss | 0.000875  |
|    std                  | 0.0255    |
|    value_loss           | 0.00109   |
---------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 4737    |
|    time_elapsed    | 15374   |
|    total_timesteps | 9701376 |
--------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4738       |
|    time_elapsed         | 15377      |
|    total_timesteps      | 9703424    |
| train/                  |            |
|    approx_kl            | 0.11640707 |
|    clip_fraction        | 0.309      |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.52       |
|    explained_variance   | 0.641      |
|    learning_rate        | 0.000108   |
|    loss                 | -0.0366    |
|    n_updates            | 47370      |
|    policy_gradient_loss | -0.00443   |
|    std                  | 0.0254     |
|    value_loss           | 0.000876   |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4739       |
|    time_elapsed         | 15380      |
|    total_timesteps      | 9705472    |
| train/                  |            |
|    approx_kl            | 0.10988981 |
|    clip_fraction        | 0.352      |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.52       |
|    explained_variance   | 0.283      |
|    learning_rate        | 0.000108   |
|    loss                 | -0.0264    |
|    n_updates            | 47380      |
|    policy_gradient_loss | -0.00398   |
|    std                  | 0.0253     |
|    value_loss           | 0.116      |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4740       |
|    time_elapsed         | 15383      |
|    total_timesteps      | 9707520    |
| train/                  |            |
|    approx_kl            | 0.15418822 |
|    clip_fraction        | 0.365      |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.53       |
|    explained_variance   | 0.223      |
|    learning_rate        | 0.000107   |
|    loss                 | -0.0396    |
|    n_updates            | 47390      |
|    policy_gradient_loss | -0.00424   |
|    std                  | 0.0251     |
|    value_loss           | 0.00172    |
----------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 4741      |
|    time_elapsed         | 15386     |
|    total_timesteps      | 9709568   |
| train/                  |           |
|    approx_kl            | 0.1496503 |
|    clip_fraction        | 0.388     |
|    clip_range           | 0.2       |
|    entropy_loss         | 4.54      |
|    explained_variance   | 0.976     |
|    learning_rate        | 0.000107  |
|    loss                 | -0.0351   |
|    n_updates            | 47400     |
|    policy_gradient_loss | 0.0104    |
|    std                  | 0.0251    |
|    value_loss           | 0.00505   |
---------------------------------------
box reached target
Eval num_timesteps=9710000, episode_reward=0.37 +/- 2.74
Episode length: 296.80 +/- 6.40
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 297        |
|    mean_reward          | 0.371      |
| time/                   |            |
|    total_timesteps      | 9710000    |
| train/                  |            |
|    approx_kl            | 0.08432248 |
|    clip_fraction        | 0.362      |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.54       |
|    explained_variance   | 0.709      |
|    learning_rate        | 0.000107   |
|    loss                 | -0.00155   |
|    n_updates            | 47410      |
|    policy_gradient_loss | 0.0101     |
|    std                  | 0.0251     |
|    value_loss           | 0.0289     |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 4742    |
|    time_elapsed    | 15390   |
|    total_timesteps | 9711616 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4743       |
|    time_elapsed         | 15393      |
|    total_timesteps      | 9713664    |
| train/                  |            |
|    approx_kl            | 0.10415525 |
|    clip_fraction        | 0.33       |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.55       |
|    explained_variance   | 0.423      |
|    learning_rate        | 0.000106   |
|    loss                 | -0.0331    |
|    n_updates            | 47420      |
|    policy_gradient_loss | -0.00371   |
|    std                  | 0.025      |
|    value_loss           | 0.00276    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4744       |
|    time_elapsed         | 15396      |
|    total_timesteps      | 9715712    |
| train/                  |            |
|    approx_kl            | 0.12857419 |
|    clip_fraction        | 0.318      |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.56       |
|    explained_variance   | -1.08      |
|    learning_rate        | 0.000106   |
|    loss                 | -0.0344    |
|    n_updates            | 47430      |
|    policy_gradient_loss | 0.000609   |
|    std                  | 0.0249     |
|    value_loss           | 0.00135    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4745       |
|    time_elapsed         | 15399      |
|    total_timesteps      | 9717760    |
| train/                  |            |
|    approx_kl            | 0.09940591 |
|    clip_fraction        | 0.366      |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.56       |
|    explained_variance   | 0.706      |
|    learning_rate        | 0.000105   |
|    loss                 | 0.00546    |
|    n_updates            | 47440      |
|    policy_gradient_loss | 0.00523    |
|    std                  | 0.0249     |
|    value_loss           | 0.00232    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4746       |
|    time_elapsed         | 15402      |
|    total_timesteps      | 9719808    |
| train/                  |            |
|    approx_kl            | 0.13060586 |
|    clip_fraction        | 0.334      |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.56       |
|    explained_variance   | 0.609      |
|    learning_rate        | 0.000105   |
|    loss                 | -0.0139    |
|    n_updates            | 47450      |
|    policy_gradient_loss | 0.000967   |
|    std                  | 0.0248     |
|    value_loss           | 0.000556   |
----------------------------------------
Eval num_timesteps=9720000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1         |
| time/                   |            |
|    total_timesteps      | 9720000    |
| train/                  |            |
|    approx_kl            | 0.07502404 |
|    clip_fraction        | 0.345      |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.56       |
|    explained_variance   | 0.747      |
|    learning_rate        | 0.000105   |
|    loss                 | -0.0158    |
|    n_updates            | 47460      |
|    policy_gradient_loss | 0.00485    |
|    std                  | 0.0249     |
|    value_loss           | 0.00363    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 4747    |
|    time_elapsed    | 15406   |
|    total_timesteps | 9721856 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4748       |
|    time_elapsed         | 15409      |
|    total_timesteps      | 9723904    |
| train/                  |            |
|    approx_kl            | 0.21549451 |
|    clip_fraction        | 0.351      |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.56       |
|    explained_variance   | 0.749      |
|    learning_rate        | 0.000104   |
|    loss                 | -0.0168    |
|    n_updates            | 47470      |
|    policy_gradient_loss | -0.00298   |
|    std                  | 0.0249     |
|    value_loss           | 0.00487    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4749       |
|    time_elapsed         | 15412      |
|    total_timesteps      | 9725952    |
| train/                  |            |
|    approx_kl            | 0.07863712 |
|    clip_fraction        | 0.28       |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.56       |
|    explained_variance   | 0.677      |
|    learning_rate        | 0.000104   |
|    loss                 | -0.0106    |
|    n_updates            | 47480      |
|    policy_gradient_loss | 0.00967    |
|    std                  | 0.0248     |
|    value_loss           | 0.000834   |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4750       |
|    time_elapsed         | 15415      |
|    total_timesteps      | 9728000    |
| train/                  |            |
|    approx_kl            | 0.11305468 |
|    clip_fraction        | 0.327      |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.57       |
|    explained_variance   | 0.592      |
|    learning_rate        | 0.000103   |
|    loss                 | 0.0223     |
|    n_updates            | 47490      |
|    policy_gradient_loss | 0.00573    |
|    std                  | 0.0248     |
|    value_loss           | 0.000932   |
----------------------------------------
Eval num_timesteps=9730000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 300       |
|    mean_reward          | -1        |
| time/                   |           |
|    total_timesteps      | 9730000   |
| train/                  |           |
|    approx_kl            | 0.0770909 |
|    clip_fraction        | 0.315     |
|    clip_range           | 0.2       |
|    entropy_loss         | 4.57      |
|    explained_variance   | 0.478     |
|    learning_rate        | 0.000103  |
|    loss                 | -0.0266   |
|    n_updates            | 47500     |
|    policy_gradient_loss | -0.00316  |
|    std                  | 0.0247    |
|    value_loss           | 0.00129   |
---------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 4751    |
|    time_elapsed    | 15419   |
|    total_timesteps | 9730048 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4752       |
|    time_elapsed         | 15422      |
|    total_timesteps      | 9732096    |
| train/                  |            |
|    approx_kl            | 0.08046673 |
|    clip_fraction        | 0.29       |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.58       |
|    explained_variance   | 0.524      |
|    learning_rate        | 0.000103   |
|    loss                 | -0.0168    |
|    n_updates            | 47510      |
|    policy_gradient_loss | -0.00192   |
|    std                  | 0.0247     |
|    value_loss           | 0.00119    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4753       |
|    time_elapsed         | 15425      |
|    total_timesteps      | 9734144    |
| train/                  |            |
|    approx_kl            | 0.08814035 |
|    clip_fraction        | 0.299      |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.58       |
|    explained_variance   | 0.813      |
|    learning_rate        | 0.000102   |
|    loss                 | 0.00802    |
|    n_updates            | 47520      |
|    policy_gradient_loss | -0.000298  |
|    std                  | 0.0246     |
|    value_loss           | 0.000722   |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4754       |
|    time_elapsed         | 15428      |
|    total_timesteps      | 9736192    |
| train/                  |            |
|    approx_kl            | 0.20358354 |
|    clip_fraction        | 0.417      |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.58       |
|    explained_variance   | 0.427      |
|    learning_rate        | 0.000102   |
|    loss                 | 0.0145     |
|    n_updates            | 47530      |
|    policy_gradient_loss | 0.00675    |
|    std                  | 0.0248     |
|    value_loss           | 0.00551    |
----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 4755      |
|    time_elapsed         | 15431     |
|    total_timesteps      | 9738240   |
| train/                  |           |
|    approx_kl            | 3.4325655 |
|    clip_fraction        | 0.39      |
|    clip_range           | 0.2       |
|    entropy_loss         | 4.57      |
|    explained_variance   | 0.694     |
|    learning_rate        | 0.000101  |
|    loss                 | 0.0691    |
|    n_updates            | 47540     |
|    policy_gradient_loss | 0.0447    |
|    std                  | 0.0247    |
|    value_loss           | 0.00084   |
---------------------------------------
box reached target
box reached target
Eval num_timesteps=9740000, episode_reward=0.23 +/- 2.47
Episode length: 273.20 +/- 53.60
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 273        |
|    mean_reward          | 0.233      |
| time/                   |            |
|    total_timesteps      | 9740000    |
| train/                  |            |
|    approx_kl            | 0.06985922 |
|    clip_fraction        | 0.268      |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.58       |
|    explained_variance   | 0.669      |
|    learning_rate        | 0.000101   |
|    loss                 | 0.00801    |
|    n_updates            | 47550      |
|    policy_gradient_loss | -0.00135   |
|    std                  | 0.0245     |
|    value_loss           | 0.000884   |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 4756    |
|    time_elapsed    | 15435   |
|    total_timesteps | 9740288 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4757       |
|    time_elapsed         | 15438      |
|    total_timesteps      | 9742336    |
| train/                  |            |
|    approx_kl            | 0.36128402 |
|    clip_fraction        | 0.411      |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.59       |
|    explained_variance   | 0.796      |
|    learning_rate        | 0.000101   |
|    loss                 | -0.00639   |
|    n_updates            | 47560      |
|    policy_gradient_loss | 0.0159     |
|    std                  | 0.0244     |
|    value_loss           | 0.00987    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4758       |
|    time_elapsed         | 15441      |
|    total_timesteps      | 9744384    |
| train/                  |            |
|    approx_kl            | 0.24877107 |
|    clip_fraction        | 0.341      |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.6        |
|    explained_variance   | 0.756      |
|    learning_rate        | 0.0001     |
|    loss                 | -0.0165    |
|    n_updates            | 47570      |
|    policy_gradient_loss | -0.00973   |
|    std                  | 0.0244     |
|    value_loss           | 0.00108    |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4759       |
|    time_elapsed         | 15445      |
|    total_timesteps      | 9746432    |
| train/                  |            |
|    approx_kl            | 0.09176432 |
|    clip_fraction        | 0.34       |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.6        |
|    explained_variance   | 0.586      |
|    learning_rate        | 9.98e-05   |
|    loss                 | -0.0103    |
|    n_updates            | 47580      |
|    policy_gradient_loss | -0.00654   |
|    std                  | 0.0243     |
|    value_loss           | 0.00335    |
----------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 4760      |
|    time_elapsed         | 15448     |
|    total_timesteps      | 9748480   |
| train/                  |           |
|    approx_kl            | 0.2818042 |
|    clip_fraction        | 0.375     |
|    clip_range           | 0.2       |
|    entropy_loss         | 4.6       |
|    explained_variance   | 0.946     |
|    learning_rate        | 9.94e-05  |
|    loss                 | 0.0168    |
|    n_updates            | 47590     |
|    policy_gradient_loss | 0.0221    |
|    std                  | 0.0244    |
|    value_loss           | 0.0152    |
---------------------------------------
box reached target
Eval num_timesteps=9750000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1         |
| time/                   |            |
|    total_timesteps      | 9750000    |
| train/                  |            |
|    approx_kl            | 0.05489642 |
|    clip_fraction        | 0.329      |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.61       |
|    explained_variance   | 0.973      |
|    learning_rate        | 9.9e-05    |
|    loss                 | 0.00426    |
|    n_updates            | 47600      |
|    policy_gradient_loss | 0.00161    |
|    std                  | 0.0242     |
|    value_loss           | 0.00801    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 4761    |
|    time_elapsed    | 15452   |
|    total_timesteps | 9750528 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4762       |
|    time_elapsed         | 15455      |
|    total_timesteps      | 9752576    |
| train/                  |            |
|    approx_kl            | 0.05433392 |
|    clip_fraction        | 0.345      |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.62       |
|    explained_variance   | 0.965      |
|    learning_rate        | 9.86e-05   |
|    loss                 | -0.0286    |
|    n_updates            | 47610      |
|    policy_gradient_loss | 0.0144     |
|    std                  | 0.0241     |
|    value_loss           | 0.00612    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4763       |
|    time_elapsed         | 15458      |
|    total_timesteps      | 9754624    |
| train/                  |            |
|    approx_kl            | 0.22298309 |
|    clip_fraction        | 0.374      |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.62       |
|    explained_variance   | 0.737      |
|    learning_rate        | 9.82e-05   |
|    loss                 | -0.0156    |
|    n_updates            | 47620      |
|    policy_gradient_loss | 0.0162     |
|    std                  | 0.0241     |
|    value_loss           | 0.00125    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4764       |
|    time_elapsed         | 15461      |
|    total_timesteps      | 9756672    |
| train/                  |            |
|    approx_kl            | 0.27823943 |
|    clip_fraction        | 0.292      |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.62       |
|    explained_variance   | 0.823      |
|    learning_rate        | 9.78e-05   |
|    loss                 | -0.0199    |
|    n_updates            | 47630      |
|    policy_gradient_loss | 0.00883    |
|    std                  | 0.024      |
|    value_loss           | 0.000785   |
----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 631         |
|    iterations           | 4765        |
|    time_elapsed         | 15464       |
|    total_timesteps      | 9758720     |
| train/                  |             |
|    approx_kl            | 0.056760795 |
|    clip_fraction        | 0.292       |
|    clip_range           | 0.2         |
|    entropy_loss         | 4.62        |
|    explained_variance   | 0.82        |
|    learning_rate        | 9.74e-05    |
|    loss                 | -0.00673    |
|    n_updates            | 47640       |
|    policy_gradient_loss | 0.00159     |
|    std                  | 0.0241      |
|    value_loss           | 0.000688    |
-----------------------------------------
Eval num_timesteps=9760000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 300         |
|    mean_reward          | -1          |
| time/                   |             |
|    total_timesteps      | 9760000     |
| train/                  |             |
|    approx_kl            | 0.073060945 |
|    clip_fraction        | 0.279       |
|    clip_range           | 0.2         |
|    entropy_loss         | 4.62        |
|    explained_variance   | 0.79        |
|    learning_rate        | 9.7e-05     |
|    loss                 | -0.0206     |
|    n_updates            | 47650       |
|    policy_gradient_loss | 0.000823    |
|    std                  | 0.024       |
|    value_loss           | 0.00082     |
-----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 4766    |
|    time_elapsed    | 15468   |
|    total_timesteps | 9760768 |
--------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 631         |
|    iterations           | 4767        |
|    time_elapsed         | 15471       |
|    total_timesteps      | 9762816     |
| train/                  |             |
|    approx_kl            | 0.103644125 |
|    clip_fraction        | 0.319       |
|    clip_range           | 0.2         |
|    entropy_loss         | 4.63        |
|    explained_variance   | 0.54        |
|    learning_rate        | 9.67e-05    |
|    loss                 | 0.00148     |
|    n_updates            | 47660       |
|    policy_gradient_loss | -0.000818   |
|    std                  | 0.024       |
|    value_loss           | 0.00178     |
-----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4768       |
|    time_elapsed         | 15474      |
|    total_timesteps      | 9764864    |
| train/                  |            |
|    approx_kl            | 0.04746672 |
|    clip_fraction        | 0.295      |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.63       |
|    explained_variance   | 0.87       |
|    learning_rate        | 9.63e-05   |
|    loss                 | -0.00894   |
|    n_updates            | 47670      |
|    policy_gradient_loss | 0.000535   |
|    std                  | 0.0239     |
|    value_loss           | 0.0218     |
----------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 4769      |
|    time_elapsed         | 15477     |
|    total_timesteps      | 9766912   |
| train/                  |           |
|    approx_kl            | 0.0986359 |
|    clip_fraction        | 0.294     |
|    clip_range           | 0.2       |
|    entropy_loss         | 4.64      |
|    explained_variance   | 0.741     |
|    learning_rate        | 9.59e-05  |
|    loss                 | -0.0325   |
|    n_updates            | 47680     |
|    policy_gradient_loss | -0.00679  |
|    std                  | 0.0237    |
|    value_loss           | 0.00133   |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4770       |
|    time_elapsed         | 15480      |
|    total_timesteps      | 9768960    |
| train/                  |            |
|    approx_kl            | 0.09913893 |
|    clip_fraction        | 0.295      |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.66       |
|    explained_variance   | 0.969      |
|    learning_rate        | 9.55e-05   |
|    loss                 | -0.0208    |
|    n_updates            | 47690      |
|    policy_gradient_loss | 0.000432   |
|    std                  | 0.0236     |
|    value_loss           | 0.00424    |
----------------------------------------
Eval num_timesteps=9770000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1         |
| time/                   |            |
|    total_timesteps      | 9770000    |
| train/                  |            |
|    approx_kl            | 0.08588973 |
|    clip_fraction        | 0.352      |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.66       |
|    explained_variance   | 0.775      |
|    learning_rate        | 9.51e-05   |
|    loss                 | 0.0215     |
|    n_updates            | 47700      |
|    policy_gradient_loss | 0.0135     |
|    std                  | 0.0237     |
|    value_loss           | 0.00227    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 4771    |
|    time_elapsed    | 15484   |
|    total_timesteps | 9771008 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4772       |
|    time_elapsed         | 15487      |
|    total_timesteps      | 9773056    |
| train/                  |            |
|    approx_kl            | 0.21690474 |
|    clip_fraction        | 0.378      |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.65       |
|    explained_variance   | 0.764      |
|    learning_rate        | 9.47e-05   |
|    loss                 | -0.00653   |
|    n_updates            | 47710      |
|    policy_gradient_loss | 0.0125     |
|    std                  | 0.0238     |
|    value_loss           | 0.00405    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4773       |
|    time_elapsed         | 15490      |
|    total_timesteps      | 9775104    |
| train/                  |            |
|    approx_kl            | 0.09816401 |
|    clip_fraction        | 0.418      |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.64       |
|    explained_variance   | 0.601      |
|    learning_rate        | 9.43e-05   |
|    loss                 | 0.0128     |
|    n_updates            | 47720      |
|    policy_gradient_loss | 0.00658    |
|    std                  | 0.0239     |
|    value_loss           | 0.0106     |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4774       |
|    time_elapsed         | 15493      |
|    total_timesteps      | 9777152    |
| train/                  |            |
|    approx_kl            | 0.12851009 |
|    clip_fraction        | 0.327      |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.63       |
|    explained_variance   | 0.471      |
|    learning_rate        | 9.39e-05   |
|    loss                 | 0.0362     |
|    n_updates            | 47730      |
|    policy_gradient_loss | 0.000736   |
|    std                  | 0.024      |
|    value_loss           | 0.00119    |
----------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 4775      |
|    time_elapsed         | 15496     |
|    total_timesteps      | 9779200   |
| train/                  |           |
|    approx_kl            | 2.6175523 |
|    clip_fraction        | 0.38      |
|    clip_range           | 0.2       |
|    entropy_loss         | 4.63      |
|    explained_variance   | 0.369     |
|    learning_rate        | 9.35e-05  |
|    loss                 | -0.0248   |
|    n_updates            | 47740     |
|    policy_gradient_loss | -0.00247  |
|    std                  | 0.0239    |
|    value_loss           | 0.00102   |
---------------------------------------
Eval num_timesteps=9780000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 300       |
|    mean_reward          | -1        |
| time/                   |           |
|    total_timesteps      | 9780000   |
| train/                  |           |
|    approx_kl            | 0.160068  |
|    clip_fraction        | 0.379     |
|    clip_range           | 0.2       |
|    entropy_loss         | 4.64      |
|    explained_variance   | 0.901     |
|    learning_rate        | 9.31e-05  |
|    loss                 | -0.000549 |
|    n_updates            | 47750     |
|    policy_gradient_loss | 0.00142   |
|    std                  | 0.0239    |
|    value_loss           | 0.0205    |
---------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 4776    |
|    time_elapsed    | 15500   |
|    total_timesteps | 9781248 |
--------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 4777      |
|    time_elapsed         | 15503     |
|    total_timesteps      | 9783296   |
| train/                  |           |
|    approx_kl            | 0.2800274 |
|    clip_fraction        | 0.32      |
|    clip_range           | 0.2       |
|    entropy_loss         | 4.64      |
|    explained_variance   | 0.736     |
|    learning_rate        | 9.27e-05  |
|    loss                 | -0.0111   |
|    n_updates            | 47760     |
|    policy_gradient_loss | -0.00616  |
|    std                  | 0.0238    |
|    value_loss           | 0.00115   |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4778       |
|    time_elapsed         | 15506      |
|    total_timesteps      | 9785344    |
| train/                  |            |
|    approx_kl            | 0.25149152 |
|    clip_fraction        | 0.348      |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.65       |
|    explained_variance   | 0.805      |
|    learning_rate        | 9.23e-05   |
|    loss                 | -0.0353    |
|    n_updates            | 47770      |
|    policy_gradient_loss | -0.00354   |
|    std                  | 0.0237     |
|    value_loss           | 0.00076    |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4779       |
|    time_elapsed         | 15509      |
|    total_timesteps      | 9787392    |
| train/                  |            |
|    approx_kl            | 0.18815008 |
|    clip_fraction        | 0.352      |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.66       |
|    explained_variance   | 0.489      |
|    learning_rate        | 9.19e-05   |
|    loss                 | 0.0138     |
|    n_updates            | 47780      |
|    policy_gradient_loss | -0.00673   |
|    std                  | 0.0236     |
|    value_loss           | 0.00136    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4780       |
|    time_elapsed         | 15512      |
|    total_timesteps      | 9789440    |
| train/                  |            |
|    approx_kl            | 0.06870867 |
|    clip_fraction        | 0.319      |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.66       |
|    explained_variance   | 0.922      |
|    learning_rate        | 9.15e-05   |
|    loss                 | 0.0326     |
|    n_updates            | 47790      |
|    policy_gradient_loss | 0.00367    |
|    std                  | 0.0237     |
|    value_loss           | 0.00646    |
----------------------------------------
Eval num_timesteps=9790000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 300       |
|    mean_reward          | -1        |
| time/                   |           |
|    total_timesteps      | 9790000   |
| train/                  |           |
|    approx_kl            | 0.0936792 |
|    clip_fraction        | 0.325     |
|    clip_range           | 0.2       |
|    entropy_loss         | 4.67      |
|    explained_variance   | 0.69      |
|    learning_rate        | 9.11e-05  |
|    loss                 | -0.0273   |
|    n_updates            | 47800     |
|    policy_gradient_loss | 0.00155   |
|    std                  | 0.0236    |
|    value_loss           | 0.000875  |
---------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 4781    |
|    time_elapsed    | 15516   |
|    total_timesteps | 9791488 |
--------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 4782      |
|    time_elapsed         | 15519     |
|    total_timesteps      | 9793536   |
| train/                  |           |
|    approx_kl            | 0.1289308 |
|    clip_fraction        | 0.353     |
|    clip_range           | 0.2       |
|    entropy_loss         | 4.67      |
|    explained_variance   | 0.621     |
|    learning_rate        | 9.07e-05  |
|    loss                 | 0.0441    |
|    n_updates            | 47810     |
|    policy_gradient_loss | -0.00199  |
|    std                  | 0.0236    |
|    value_loss           | 0.0016    |
---------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 631         |
|    iterations           | 4783        |
|    time_elapsed         | 15522       |
|    total_timesteps      | 9795584     |
| train/                  |             |
|    approx_kl            | 0.060486782 |
|    clip_fraction        | 0.339       |
|    clip_range           | 0.2         |
|    entropy_loss         | 4.67        |
|    explained_variance   | 0.831       |
|    learning_rate        | 9.03e-05    |
|    loss                 | 0.0302      |
|    n_updates            | 47820       |
|    policy_gradient_loss | 0.00963     |
|    std                  | 0.0235      |
|    value_loss           | 0.00589     |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 631         |
|    iterations           | 4784        |
|    time_elapsed         | 15525       |
|    total_timesteps      | 9797632     |
| train/                  |             |
|    approx_kl            | 0.085023925 |
|    clip_fraction        | 0.265       |
|    clip_range           | 0.2         |
|    entropy_loss         | 4.68        |
|    explained_variance   | 0.7         |
|    learning_rate        | 8.99e-05    |
|    loss                 | 0.017       |
|    n_updates            | 47830       |
|    policy_gradient_loss | -0.00264    |
|    std                  | 0.0234      |
|    value_loss           | 0.000924    |
-----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4785       |
|    time_elapsed         | 15529      |
|    total_timesteps      | 9799680    |
| train/                  |            |
|    approx_kl            | 0.14954881 |
|    clip_fraction        | 0.312      |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.68       |
|    explained_variance   | 0.639      |
|    learning_rate        | 8.95e-05   |
|    loss                 | -0.045     |
|    n_updates            | 47840      |
|    policy_gradient_loss | -0.00446   |
|    std                  | 0.0234     |
|    value_loss           | 0.00126    |
----------------------------------------
Eval num_timesteps=9800000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1         |
| time/                   |            |
|    total_timesteps      | 9800000    |
| train/                  |            |
|    approx_kl            | 0.09471788 |
|    clip_fraction        | 0.281      |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.69       |
|    explained_variance   | 0.678      |
|    learning_rate        | 8.91e-05   |
|    loss                 | -0.00443   |
|    n_updates            | 47850      |
|    policy_gradient_loss | -0.00485   |
|    std                  | 0.0234     |
|    value_loss           | 0.001      |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 4786    |
|    time_elapsed    | 15533   |
|    total_timesteps | 9801728 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4787       |
|    time_elapsed         | 15536      |
|    total_timesteps      | 9803776    |
| train/                  |            |
|    approx_kl            | 0.14620902 |
|    clip_fraction        | 0.309      |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.69       |
|    explained_variance   | 0.408      |
|    learning_rate        | 8.87e-05   |
|    loss                 | -0.00838   |
|    n_updates            | 47860      |
|    policy_gradient_loss | -0.00637   |
|    std                  | 0.0233     |
|    value_loss           | 0.00204    |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4788       |
|    time_elapsed         | 15539      |
|    total_timesteps      | 9805824    |
| train/                  |            |
|    approx_kl            | 0.06861502 |
|    clip_fraction        | 0.293      |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.69       |
|    explained_variance   | 0.774      |
|    learning_rate        | 8.83e-05   |
|    loss                 | 0.036      |
|    n_updates            | 47870      |
|    policy_gradient_loss | 0.00838    |
|    std                  | 0.0233     |
|    value_loss           | 0.00103    |
----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 631         |
|    iterations           | 4789        |
|    time_elapsed         | 15542       |
|    total_timesteps      | 9807872     |
| train/                  |             |
|    approx_kl            | 0.088816926 |
|    clip_fraction        | 0.293       |
|    clip_range           | 0.2         |
|    entropy_loss         | 4.7         |
|    explained_variance   | 0.946       |
|    learning_rate        | 8.79e-05    |
|    loss                 | 0.0325      |
|    n_updates            | 47880       |
|    policy_gradient_loss | 0.00262     |
|    std                  | 0.0232      |
|    value_loss           | 0.00853     |
-----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4790       |
|    time_elapsed         | 15545      |
|    total_timesteps      | 9809920    |
| train/                  |            |
|    approx_kl            | 0.14600115 |
|    clip_fraction        | 0.359      |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.7        |
|    explained_variance   | 0.6        |
|    learning_rate        | 8.75e-05   |
|    loss                 | -0.0128    |
|    n_updates            | 47890      |
|    policy_gradient_loss | 0.00466    |
|    std                  | 0.0232     |
|    value_loss           | 0.014      |
----------------------------------------
Eval num_timesteps=9810000, episode_reward=-0.75 +/- 0.50
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -0.748     |
| time/                   |            |
|    total_timesteps      | 9810000    |
| train/                  |            |
|    approx_kl            | 0.13151556 |
|    clip_fraction        | 0.293      |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.7        |
|    explained_variance   | 0.601      |
|    learning_rate        | 8.71e-05   |
|    loss                 | -0.0404    |
|    n_updates            | 47900      |
|    policy_gradient_loss | -0.000683  |
|    std                  | 0.0232     |
|    value_loss           | 0.00106    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 4791    |
|    time_elapsed    | 15549   |
|    total_timesteps | 9811968 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4792       |
|    time_elapsed         | 15552      |
|    total_timesteps      | 9814016    |
| train/                  |            |
|    approx_kl            | 0.13956966 |
|    clip_fraction        | 0.302      |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.7        |
|    explained_variance   | 0.529      |
|    learning_rate        | 8.67e-05   |
|    loss                 | 0.014      |
|    n_updates            | 47910      |
|    policy_gradient_loss | -0.00728   |
|    std                  | 0.0231     |
|    value_loss           | 0.00114    |
----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 631         |
|    iterations           | 4793        |
|    time_elapsed         | 15555       |
|    total_timesteps      | 9816064     |
| train/                  |             |
|    approx_kl            | 0.071700595 |
|    clip_fraction        | 0.306       |
|    clip_range           | 0.2         |
|    entropy_loss         | 4.71        |
|    explained_variance   | 0.574       |
|    learning_rate        | 8.63e-05    |
|    loss                 | -0.0101     |
|    n_updates            | 47920       |
|    policy_gradient_loss | -0.00225    |
|    std                  | 0.023       |
|    value_loss           | 0.00105     |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 631         |
|    iterations           | 4794        |
|    time_elapsed         | 15558       |
|    total_timesteps      | 9818112     |
| train/                  |             |
|    approx_kl            | 0.050543636 |
|    clip_fraction        | 0.257       |
|    clip_range           | 0.2         |
|    entropy_loss         | 4.73        |
|    explained_variance   | 0.766       |
|    learning_rate        | 8.59e-05    |
|    loss                 | -0.0277     |
|    n_updates            | 47930       |
|    policy_gradient_loss | -0.00233    |
|    std                  | 0.0228      |
|    value_loss           | 0.000989    |
-----------------------------------------
box reached target
Eval num_timesteps=9820000, episode_reward=-0.90 +/- 0.21
Episode length: 300.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 300         |
|    mean_reward          | -0.896      |
| time/                   |             |
|    total_timesteps      | 9820000     |
| train/                  |             |
|    approx_kl            | 0.102861606 |
|    clip_fraction        | 0.274       |
|    clip_range           | 0.2         |
|    entropy_loss         | 4.74        |
|    explained_variance   | 0.817       |
|    learning_rate        | 8.55e-05    |
|    loss                 | -0.0133     |
|    n_updates            | 47940       |
|    policy_gradient_loss | 0.00342     |
|    std                  | 0.0228      |
|    value_loss           | 0.000856    |
-----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 4795    |
|    time_elapsed    | 15562   |
|    total_timesteps | 9820160 |
--------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 631         |
|    iterations           | 4796        |
|    time_elapsed         | 15565       |
|    total_timesteps      | 9822208     |
| train/                  |             |
|    approx_kl            | 0.052807204 |
|    clip_fraction        | 0.375       |
|    clip_range           | 0.2         |
|    entropy_loss         | 4.73        |
|    explained_variance   | 0.422       |
|    learning_rate        | 8.51e-05    |
|    loss                 | 0.0457      |
|    n_updates            | 47950       |
|    policy_gradient_loss | 0.0109      |
|    std                  | 0.0228      |
|    value_loss           | 0.126       |
-----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4797       |
|    time_elapsed         | 15568      |
|    total_timesteps      | 9824256    |
| train/                  |            |
|    approx_kl            | 0.07802366 |
|    clip_fraction        | 0.24       |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.74       |
|    explained_variance   | 0.682      |
|    learning_rate        | 8.47e-05   |
|    loss                 | 0.0273     |
|    n_updates            | 47960      |
|    policy_gradient_loss | 0.00529    |
|    std                  | 0.0227     |
|    value_loss           | 0.00128    |
----------------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 631         |
|    iterations           | 4798        |
|    time_elapsed         | 15571       |
|    total_timesteps      | 9826304     |
| train/                  |             |
|    approx_kl            | 0.064021885 |
|    clip_fraction        | 0.263       |
|    clip_range           | 0.2         |
|    entropy_loss         | 4.75        |
|    explained_variance   | 0.767       |
|    learning_rate        | 8.43e-05    |
|    loss                 | -0.0165     |
|    n_updates            | 47970       |
|    policy_gradient_loss | 0.00601     |
|    std                  | 0.0227      |
|    value_loss           | 0.000753    |
-----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4799       |
|    time_elapsed         | 15574      |
|    total_timesteps      | 9828352    |
| train/                  |            |
|    approx_kl            | 0.22815365 |
|    clip_fraction        | 0.305      |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.75       |
|    explained_variance   | 0.962      |
|    learning_rate        | 8.39e-05   |
|    loss                 | 0.0591     |
|    n_updates            | 47980      |
|    policy_gradient_loss | 0.00627    |
|    std                  | 0.0227     |
|    value_loss           | 0.0102     |
----------------------------------------
box reached target
box reached target
Eval num_timesteps=9830000, episode_reward=0.31 +/- 2.61
Episode length: 279.60 +/- 40.80
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 280        |
|    mean_reward          | 0.307      |
| time/                   |            |
|    total_timesteps      | 9830000    |
| train/                  |            |
|    approx_kl            | 0.14343646 |
|    clip_fraction        | 0.336      |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.75       |
|    explained_variance   | 0.463      |
|    learning_rate        | 8.35e-05   |
|    loss                 | -0.0231    |
|    n_updates            | 47990      |
|    policy_gradient_loss | 0.00227    |
|    std                  | 0.0226     |
|    value_loss           | 0.00159    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 4800    |
|    time_elapsed    | 15578   |
|    total_timesteps | 9830400 |
--------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 631         |
|    iterations           | 4801        |
|    time_elapsed         | 15581       |
|    total_timesteps      | 9832448     |
| train/                  |             |
|    approx_kl            | 0.053015128 |
|    clip_fraction        | 0.301       |
|    clip_range           | 0.2         |
|    entropy_loss         | 4.75        |
|    explained_variance   | 0.497       |
|    learning_rate        | 8.31e-05    |
|    loss                 | 0.0784      |
|    n_updates            | 48000       |
|    policy_gradient_loss | 0.00568     |
|    std                  | 0.0226      |
|    value_loss           | 0.117       |
-----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4802       |
|    time_elapsed         | 15584      |
|    total_timesteps      | 9834496    |
| train/                  |            |
|    approx_kl            | 0.04227455 |
|    clip_fraction        | 0.25       |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.75       |
|    explained_variance   | 0.782      |
|    learning_rate        | 8.27e-05   |
|    loss                 | -0.00803   |
|    n_updates            | 48010      |
|    policy_gradient_loss | 0.0076     |
|    std                  | 0.0227     |
|    value_loss           | 0.00165    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4803       |
|    time_elapsed         | 15587      |
|    total_timesteps      | 9836544    |
| train/                  |            |
|    approx_kl            | 0.06701824 |
|    clip_fraction        | 0.228      |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.75       |
|    explained_variance   | 0.788      |
|    learning_rate        | 8.23e-05   |
|    loss                 | -0.00838   |
|    n_updates            | 48020      |
|    policy_gradient_loss | 0.00538    |
|    std                  | 0.0226     |
|    value_loss           | 0.000618   |
----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 631         |
|    iterations           | 4804        |
|    time_elapsed         | 15590       |
|    total_timesteps      | 9838592     |
| train/                  |             |
|    approx_kl            | 0.080192104 |
|    clip_fraction        | 0.288       |
|    clip_range           | 0.2         |
|    entropy_loss         | 4.76        |
|    explained_variance   | 0.817       |
|    learning_rate        | 8.19e-05    |
|    loss                 | 0.0326      |
|    n_updates            | 48030       |
|    policy_gradient_loss | -0.00104    |
|    std                  | 0.0226      |
|    value_loss           | 0.000982    |
-----------------------------------------
box reached target
Eval num_timesteps=9840000, episode_reward=0.27 +/- 2.54
Episode length: 283.40 +/- 33.20
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 283         |
|    mean_reward          | 0.268       |
| time/                   |             |
|    total_timesteps      | 9840000     |
| train/                  |             |
|    approx_kl            | 0.045754462 |
|    clip_fraction        | 0.275       |
|    clip_range           | 0.2         |
|    entropy_loss         | 4.77        |
|    explained_variance   | 0.469       |
|    learning_rate        | 8.15e-05    |
|    loss                 | -0.00473    |
|    n_updates            | 48040       |
|    policy_gradient_loss | -0.000621   |
|    std                  | 0.0224      |
|    value_loss           | 0.000843    |
-----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 4805    |
|    time_elapsed    | 15594   |
|    total_timesteps | 9840640 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4806       |
|    time_elapsed         | 15597      |
|    total_timesteps      | 9842688    |
| train/                  |            |
|    approx_kl            | 0.04579784 |
|    clip_fraction        | 0.272      |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.77       |
|    explained_variance   | 0.717      |
|    learning_rate        | 8.11e-05   |
|    loss                 | 0.00653    |
|    n_updates            | 48050      |
|    policy_gradient_loss | 0.00507    |
|    std                  | 0.0225     |
|    value_loss           | 0.000664   |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4807       |
|    time_elapsed         | 15600      |
|    total_timesteps      | 9844736    |
| train/                  |            |
|    approx_kl            | 0.08951755 |
|    clip_fraction        | 0.26       |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.77       |
|    explained_variance   | -1.73      |
|    learning_rate        | 8.07e-05   |
|    loss                 | -0.0431    |
|    n_updates            | 48060      |
|    policy_gradient_loss | 0.00316    |
|    std                  | 0.0224     |
|    value_loss           | 0.00146    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4808       |
|    time_elapsed         | 15603      |
|    total_timesteps      | 9846784    |
| train/                  |            |
|    approx_kl            | 0.07719737 |
|    clip_fraction        | 0.334      |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.77       |
|    explained_variance   | 0.564      |
|    learning_rate        | 8.03e-05   |
|    loss                 | -0.0255    |
|    n_updates            | 48070      |
|    policy_gradient_loss | 0.00413    |
|    std                  | 0.0224     |
|    value_loss           | 0.00106    |
----------------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4809       |
|    time_elapsed         | 15606      |
|    total_timesteps      | 9848832    |
| train/                  |            |
|    approx_kl            | 0.43273473 |
|    clip_fraction        | 0.285      |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.77       |
|    explained_variance   | 0.251      |
|    learning_rate        | 7.99e-05   |
|    loss                 | -0.0146    |
|    n_updates            | 48080      |
|    policy_gradient_loss | 0.00141    |
|    std                  | 0.0224     |
|    value_loss           | 0.0013     |
----------------------------------------
box reached target
Eval num_timesteps=9850000, episode_reward=0.24 +/- 2.48
Episode length: 273.20 +/- 53.60
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 273        |
|    mean_reward          | 0.239      |
| time/                   |            |
|    total_timesteps      | 9850000    |
| train/                  |            |
|    approx_kl            | 0.07328901 |
|    clip_fraction        | 0.332      |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.78       |
|    explained_variance   | 0.779      |
|    learning_rate        | 7.95e-05   |
|    loss                 | 0.153      |
|    n_updates            | 48090      |
|    policy_gradient_loss | 0.00633    |
|    std                  | 0.0223     |
|    value_loss           | 0.127      |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 4810    |
|    time_elapsed    | 15610   |
|    total_timesteps | 9850880 |
--------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4811       |
|    time_elapsed         | 15613      |
|    total_timesteps      | 9852928    |
| train/                  |            |
|    approx_kl            | 0.06003434 |
|    clip_fraction        | 0.296      |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.78       |
|    explained_variance   | 0.749      |
|    learning_rate        | 7.91e-05   |
|    loss                 | -0.0139    |
|    n_updates            | 48100      |
|    policy_gradient_loss | 0.000126   |
|    std                  | 0.0222     |
|    value_loss           | 0.000961   |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4812       |
|    time_elapsed         | 15616      |
|    total_timesteps      | 9854976    |
| train/                  |            |
|    approx_kl            | 0.06671564 |
|    clip_fraction        | 0.297      |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.8        |
|    explained_variance   | 0.61       |
|    learning_rate        | 7.87e-05   |
|    loss                 | -0.0305    |
|    n_updates            | 48110      |
|    policy_gradient_loss | 0.00436    |
|    std                  | 0.022      |
|    value_loss           | 0.0262     |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4813       |
|    time_elapsed         | 15619      |
|    total_timesteps      | 9857024    |
| train/                  |            |
|    approx_kl            | 0.16902989 |
|    clip_fraction        | 0.274      |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.8        |
|    explained_variance   | 0.976      |
|    learning_rate        | 7.83e-05   |
|    loss                 | 0.0255     |
|    n_updates            | 48120      |
|    policy_gradient_loss | 0.00608    |
|    std                  | 0.0221     |
|    value_loss           | 0.00483    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4814       |
|    time_elapsed         | 15622      |
|    total_timesteps      | 9859072    |
| train/                  |            |
|    approx_kl            | 0.08861229 |
|    clip_fraction        | 0.339      |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.8        |
|    explained_variance   | 0.879      |
|    learning_rate        | 7.79e-05   |
|    loss                 | 0.0357     |
|    n_updates            | 48130      |
|    policy_gradient_loss | 0.0032     |
|    std                  | 0.0221     |
|    value_loss           | 0.0243     |
----------------------------------------
Eval num_timesteps=9860000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1         |
| time/                   |            |
|    total_timesteps      | 9860000    |
| train/                  |            |
|    approx_kl            | 0.05011327 |
|    clip_fraction        | 0.27       |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.79       |
|    explained_variance   | 0.709      |
|    learning_rate        | 7.75e-05   |
|    loss                 | 0.0391     |
|    n_updates            | 48140      |
|    policy_gradient_loss | -0.000396  |
|    std                  | 0.0222     |
|    value_loss           | 0.00114    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 4815    |
|    time_elapsed    | 15626   |
|    total_timesteps | 9861120 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4816       |
|    time_elapsed         | 15629      |
|    total_timesteps      | 9863168    |
| train/                  |            |
|    approx_kl            | 0.07671425 |
|    clip_fraction        | 0.281      |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.79       |
|    explained_variance   | 0.516      |
|    learning_rate        | 7.71e-05   |
|    loss                 | -0.0223    |
|    n_updates            | 48150      |
|    policy_gradient_loss | -0.00902   |
|    std                  | 0.0221     |
|    value_loss           | 0.0026     |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4817       |
|    time_elapsed         | 15632      |
|    total_timesteps      | 9865216    |
| train/                  |            |
|    approx_kl            | 0.23241834 |
|    clip_fraction        | 0.306      |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.8        |
|    explained_variance   | 0.549      |
|    learning_rate        | 7.67e-05   |
|    loss                 | -0.0579    |
|    n_updates            | 48160      |
|    policy_gradient_loss | -0.0054    |
|    std                  | 0.022      |
|    value_loss           | 0.00251    |
----------------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 631         |
|    iterations           | 4818        |
|    time_elapsed         | 15635       |
|    total_timesteps      | 9867264     |
| train/                  |             |
|    approx_kl            | 0.120831326 |
|    clip_fraction        | 0.312       |
|    clip_range           | 0.2         |
|    entropy_loss         | 4.81        |
|    explained_variance   | 0.889       |
|    learning_rate        | 7.63e-05    |
|    loss                 | -0.0412     |
|    n_updates            | 48170       |
|    policy_gradient_loss | -0.000283   |
|    std                  | 0.022       |
|    value_loss           | 0.0193      |
-----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4819       |
|    time_elapsed         | 15638      |
|    total_timesteps      | 9869312    |
| train/                  |            |
|    approx_kl            | 0.09364993 |
|    clip_fraction        | 0.294      |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.81       |
|    explained_variance   | 0.993      |
|    learning_rate        | 7.59e-05   |
|    loss                 | -0.0195    |
|    n_updates            | 48180      |
|    policy_gradient_loss | -0.00197   |
|    std                  | 0.022      |
|    value_loss           | 0.00198    |
----------------------------------------
Eval num_timesteps=9870000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1         |
| time/                   |            |
|    total_timesteps      | 9870000    |
| train/                  |            |
|    approx_kl            | 0.09327805 |
|    clip_fraction        | 0.353      |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.81       |
|    explained_variance   | 0.983      |
|    learning_rate        | 7.55e-05   |
|    loss                 | -0.0315    |
|    n_updates            | 48190      |
|    policy_gradient_loss | 0.00698    |
|    std                  | 0.022      |
|    value_loss           | 0.00486    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 4820    |
|    time_elapsed    | 15642   |
|    total_timesteps | 9871360 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4821       |
|    time_elapsed         | 15645      |
|    total_timesteps      | 9873408    |
| train/                  |            |
|    approx_kl            | 0.12271158 |
|    clip_fraction        | 0.339      |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.81       |
|    explained_variance   | 0.763      |
|    learning_rate        | 7.51e-05   |
|    loss                 | -0.0386    |
|    n_updates            | 48200      |
|    policy_gradient_loss | 0.00209    |
|    std                  | 0.022      |
|    value_loss           | 0.00138    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4822       |
|    time_elapsed         | 15648      |
|    total_timesteps      | 9875456    |
| train/                  |            |
|    approx_kl            | 0.07958828 |
|    clip_fraction        | 0.286      |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.8        |
|    explained_variance   | 0.815      |
|    learning_rate        | 7.47e-05   |
|    loss                 | 0.00902    |
|    n_updates            | 48210      |
|    policy_gradient_loss | -0.00675   |
|    std                  | 0.022      |
|    value_loss           | 0.000831   |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4823       |
|    time_elapsed         | 15651      |
|    total_timesteps      | 9877504    |
| train/                  |            |
|    approx_kl            | 0.05074818 |
|    clip_fraction        | 0.245      |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.81       |
|    explained_variance   | 0.792      |
|    learning_rate        | 7.43e-05   |
|    loss                 | 0.0167     |
|    n_updates            | 48220      |
|    policy_gradient_loss | -0.00341   |
|    std                  | 0.0219     |
|    value_loss           | 0.000885   |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4824       |
|    time_elapsed         | 15654      |
|    total_timesteps      | 9879552    |
| train/                  |            |
|    approx_kl            | 0.15978524 |
|    clip_fraction        | 0.28       |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.81       |
|    explained_variance   | 0.785      |
|    learning_rate        | 7.39e-05   |
|    loss                 | -0.0255    |
|    n_updates            | 48230      |
|    policy_gradient_loss | 0.00666    |
|    std                  | 0.022      |
|    value_loss           | 0.0115     |
----------------------------------------
Eval num_timesteps=9880000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1         |
| time/                   |            |
|    total_timesteps      | 9880000    |
| train/                  |            |
|    approx_kl            | 0.06804594 |
|    clip_fraction        | 0.264      |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.81       |
|    explained_variance   | 0.897      |
|    learning_rate        | 7.35e-05   |
|    loss                 | -0.00425   |
|    n_updates            | 48240      |
|    policy_gradient_loss | -0.00434   |
|    std                  | 0.0218     |
|    value_loss           | 0.0164     |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 4825    |
|    time_elapsed    | 15658   |
|    total_timesteps | 9881600 |
--------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 4826      |
|    time_elapsed         | 15661     |
|    total_timesteps      | 9883648   |
| train/                  |           |
|    approx_kl            | 0.0775381 |
|    clip_fraction        | 0.286     |
|    clip_range           | 0.2       |
|    entropy_loss         | 4.83      |
|    explained_variance   | 0.606     |
|    learning_rate        | 7.31e-05  |
|    loss                 | -0.0295   |
|    n_updates            | 48250     |
|    policy_gradient_loss | -0.00185  |
|    std                  | 0.0217    |
|    value_loss           | 0.00175   |
---------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4827       |
|    time_elapsed         | 15664      |
|    total_timesteps      | 9885696    |
| train/                  |            |
|    approx_kl            | 0.04407595 |
|    clip_fraction        | 0.227      |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.83       |
|    explained_variance   | 0.568      |
|    learning_rate        | 7.27e-05   |
|    loss                 | -0.0171    |
|    n_updates            | 48260      |
|    policy_gradient_loss | -0.00196   |
|    std                  | 0.0218     |
|    value_loss           | 0.00108    |
----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 4828      |
|    time_elapsed         | 15667     |
|    total_timesteps      | 9887744   |
| train/                  |           |
|    approx_kl            | 2.8030705 |
|    clip_fraction        | 0.461     |
|    clip_range           | 0.2       |
|    entropy_loss         | 4.83      |
|    explained_variance   | 0.911     |
|    learning_rate        | 7.23e-05  |
|    loss                 | 0.0411    |
|    n_updates            | 48270     |
|    policy_gradient_loss | 0.00416   |
|    std                  | 0.0217    |
|    value_loss           | 0.0236    |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4829       |
|    time_elapsed         | 15670      |
|    total_timesteps      | 9889792    |
| train/                  |            |
|    approx_kl            | 0.04495787 |
|    clip_fraction        | 0.242      |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.83       |
|    explained_variance   | 0.755      |
|    learning_rate        | 7.19e-05   |
|    loss                 | -0.029     |
|    n_updates            | 48280      |
|    policy_gradient_loss | -0.00214   |
|    std                  | 0.0217     |
|    value_loss           | 0.00113    |
----------------------------------------
Eval num_timesteps=9890000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1         |
| time/                   |            |
|    total_timesteps      | 9890000    |
| train/                  |            |
|    approx_kl            | 0.20982835 |
|    clip_fraction        | 0.3        |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.83       |
|    explained_variance   | 0.71       |
|    learning_rate        | 7.15e-05   |
|    loss                 | -0.0443    |
|    n_updates            | 48290      |
|    policy_gradient_loss | -0.00477   |
|    std                  | 0.0217     |
|    value_loss           | 0.00215    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 4830    |
|    time_elapsed    | 15674   |
|    total_timesteps | 9891840 |
--------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 631         |
|    iterations           | 4831        |
|    time_elapsed         | 15677       |
|    total_timesteps      | 9893888     |
| train/                  |             |
|    approx_kl            | 0.061007187 |
|    clip_fraction        | 0.244       |
|    clip_range           | 0.2         |
|    entropy_loss         | 4.83        |
|    explained_variance   | 0.699       |
|    learning_rate        | 7.11e-05    |
|    loss                 | -0.0488     |
|    n_updates            | 48300       |
|    policy_gradient_loss | -0.00904    |
|    std                  | 0.0218      |
|    value_loss           | 0.00115     |
-----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4832       |
|    time_elapsed         | 15680      |
|    total_timesteps      | 9895936    |
| train/                  |            |
|    approx_kl            | 0.10624468 |
|    clip_fraction        | 0.281      |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.83       |
|    explained_variance   | 0.655      |
|    learning_rate        | 7.07e-05   |
|    loss                 | -0.0331    |
|    n_updates            | 48310      |
|    policy_gradient_loss | -0.0049    |
|    std                  | 0.0216     |
|    value_loss           | 0.00121    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4833       |
|    time_elapsed         | 15683      |
|    total_timesteps      | 9897984    |
| train/                  |            |
|    approx_kl            | 0.05438744 |
|    clip_fraction        | 0.261      |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.84       |
|    explained_variance   | 0.77       |
|    learning_rate        | 7.03e-05   |
|    loss                 | 0.00118    |
|    n_updates            | 48320      |
|    policy_gradient_loss | -0.000334  |
|    std                  | 0.0216     |
|    value_loss           | 0.000917   |
----------------------------------------
box reached target
Eval num_timesteps=9900000, episode_reward=0.24 +/- 2.48
Episode length: 274.20 +/- 51.60
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 274         |
|    mean_reward          | 0.238       |
| time/                   |             |
|    total_timesteps      | 9900000     |
| train/                  |             |
|    approx_kl            | 0.087053165 |
|    clip_fraction        | 0.281       |
|    clip_range           | 0.2         |
|    entropy_loss         | 4.85        |
|    explained_variance   | 0.735       |
|    learning_rate        | 6.99e-05    |
|    loss                 | -0.0205     |
|    n_updates            | 48330       |
|    policy_gradient_loss | -0.00185    |
|    std                  | 0.0215      |
|    value_loss           | 0.0015      |
-----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 4834    |
|    time_elapsed    | 15687   |
|    total_timesteps | 9900032 |
--------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4835       |
|    time_elapsed         | 15690      |
|    total_timesteps      | 9902080    |
| train/                  |            |
|    approx_kl            | 0.15604767 |
|    clip_fraction        | 0.319      |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.85       |
|    explained_variance   | 0.428      |
|    learning_rate        | 6.95e-05   |
|    loss                 | 0.00538    |
|    n_updates            | 48340      |
|    policy_gradient_loss | -0.0112    |
|    std                  | 0.0215     |
|    value_loss           | 0.00195    |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4836       |
|    time_elapsed         | 15693      |
|    total_timesteps      | 9904128    |
| train/                  |            |
|    approx_kl            | 0.21507266 |
|    clip_fraction        | 0.319      |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.85       |
|    explained_variance   | 0.974      |
|    learning_rate        | 6.91e-05   |
|    loss                 | -0.031     |
|    n_updates            | 48350      |
|    policy_gradient_loss | -0.00229   |
|    std                  | 0.0215     |
|    value_loss           | 0.00473    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4837       |
|    time_elapsed         | 15696      |
|    total_timesteps      | 9906176    |
| train/                  |            |
|    approx_kl            | 0.05715195 |
|    clip_fraction        | 0.303      |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.86       |
|    explained_variance   | 0.986      |
|    learning_rate        | 6.87e-05   |
|    loss                 | 0.0144     |
|    n_updates            | 48360      |
|    policy_gradient_loss | 0.00328    |
|    std                  | 0.0213     |
|    value_loss           | 0.00399    |
----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 631         |
|    iterations           | 4838        |
|    time_elapsed         | 15699       |
|    total_timesteps      | 9908224     |
| train/                  |             |
|    approx_kl            | 0.045814216 |
|    clip_fraction        | 0.263       |
|    clip_range           | 0.2         |
|    entropy_loss         | 4.87        |
|    explained_variance   | 0.794       |
|    learning_rate        | 6.83e-05    |
|    loss                 | -0.00661    |
|    n_updates            | 48370       |
|    policy_gradient_loss | 0.0036      |
|    std                  | 0.0214      |
|    value_loss           | 0.00178     |
-----------------------------------------
Eval num_timesteps=9910000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1         |
| time/                   |            |
|    total_timesteps      | 9910000    |
| train/                  |            |
|    approx_kl            | 0.04193084 |
|    clip_fraction        | 0.242      |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.87       |
|    explained_variance   | 0.722      |
|    learning_rate        | 6.79e-05   |
|    loss                 | -0.016     |
|    n_updates            | 48380      |
|    policy_gradient_loss | 0.00157    |
|    std                  | 0.0213     |
|    value_loss           | 0.000987   |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 4839    |
|    time_elapsed    | 15703   |
|    total_timesteps | 9910272 |
--------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4840       |
|    time_elapsed         | 15706      |
|    total_timesteps      | 9912320    |
| train/                  |            |
|    approx_kl            | 0.16970697 |
|    clip_fraction        | 0.289      |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.86       |
|    explained_variance   | 0.427      |
|    learning_rate        | 6.75e-05   |
|    loss                 | -0.0207    |
|    n_updates            | 48390      |
|    policy_gradient_loss | -0.00367   |
|    std                  | 0.0214     |
|    value_loss           | 0.00211    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4841       |
|    time_elapsed         | 15709      |
|    total_timesteps      | 9914368    |
| train/                  |            |
|    approx_kl            | 0.06825693 |
|    clip_fraction        | 0.303      |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.87       |
|    explained_variance   | 0.97       |
|    learning_rate        | 6.71e-05   |
|    loss                 | 0.0107     |
|    n_updates            | 48400      |
|    policy_gradient_loss | 0.00787    |
|    std                  | 0.0213     |
|    value_loss           | 0.00519    |
----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 631         |
|    iterations           | 4842        |
|    time_elapsed         | 15712       |
|    total_timesteps      | 9916416     |
| train/                  |             |
|    approx_kl            | 0.065373786 |
|    clip_fraction        | 0.275       |
|    clip_range           | 0.2         |
|    entropy_loss         | 4.88        |
|    explained_variance   | 0.746       |
|    learning_rate        | 6.67e-05    |
|    loss                 | -0.00257    |
|    n_updates            | 48410       |
|    policy_gradient_loss | -0.00302    |
|    std                  | 0.0212      |
|    value_loss           | 0.000844    |
-----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4843       |
|    time_elapsed         | 15715      |
|    total_timesteps      | 9918464    |
| train/                  |            |
|    approx_kl            | 0.04348976 |
|    clip_fraction        | 0.245      |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.88       |
|    explained_variance   | 0.745      |
|    learning_rate        | 6.63e-05   |
|    loss                 | -0.0286    |
|    n_updates            | 48420      |
|    policy_gradient_loss | -0.00175   |
|    std                  | 0.0212     |
|    value_loss           | 0.000746   |
----------------------------------------
Eval num_timesteps=9920000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1         |
| time/                   |            |
|    total_timesteps      | 9920000    |
| train/                  |            |
|    approx_kl            | 0.08373521 |
|    clip_fraction        | 0.291      |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.88       |
|    explained_variance   | 0.764      |
|    learning_rate        | 6.59e-05   |
|    loss                 | 0.0107     |
|    n_updates            | 48430      |
|    policy_gradient_loss | 0.00543    |
|    std                  | 0.0212     |
|    value_loss           | 0.00643    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 4844    |
|    time_elapsed    | 15719   |
|    total_timesteps | 9920512 |
--------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 631         |
|    iterations           | 4845        |
|    time_elapsed         | 15722       |
|    total_timesteps      | 9922560     |
| train/                  |             |
|    approx_kl            | 0.061724864 |
|    clip_fraction        | 0.218       |
|    clip_range           | 0.2         |
|    entropy_loss         | 4.88        |
|    explained_variance   | 0.638       |
|    learning_rate        | 6.55e-05    |
|    loss                 | -0.011      |
|    n_updates            | 48440       |
|    policy_gradient_loss | -0.00346    |
|    std                  | 0.0211      |
|    value_loss           | 0.00109     |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 631         |
|    iterations           | 4846        |
|    time_elapsed         | 15725       |
|    total_timesteps      | 9924608     |
| train/                  |             |
|    approx_kl            | 0.057442456 |
|    clip_fraction        | 0.26        |
|    clip_range           | 0.2         |
|    entropy_loss         | 4.89        |
|    explained_variance   | 0.743       |
|    learning_rate        | 6.51e-05    |
|    loss                 | -0.0283     |
|    n_updates            | 48450       |
|    policy_gradient_loss | -0.00487    |
|    std                  | 0.0211      |
|    value_loss           | 0.000825    |
-----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4847       |
|    time_elapsed         | 15729      |
|    total_timesteps      | 9926656    |
| train/                  |            |
|    approx_kl            | 0.07184307 |
|    clip_fraction        | 0.279      |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.89       |
|    explained_variance   | 0.657      |
|    learning_rate        | 6.47e-05   |
|    loss                 | 0.00698    |
|    n_updates            | 48460      |
|    policy_gradient_loss | 0.00766    |
|    std                  | 0.0211     |
|    value_loss           | 0.012      |
----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4848       |
|    time_elapsed         | 15732      |
|    total_timesteps      | 9928704    |
| train/                  |            |
|    approx_kl            | 0.08315702 |
|    clip_fraction        | 0.248      |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.89       |
|    explained_variance   | 0.706      |
|    learning_rate        | 6.43e-05   |
|    loss                 | 0.00965    |
|    n_updates            | 48470      |
|    policy_gradient_loss | -0.00316   |
|    std                  | 0.0211     |
|    value_loss           | 0.00117    |
----------------------------------------
Eval num_timesteps=9930000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1         |
| time/                   |            |
|    total_timesteps      | 9930000    |
| train/                  |            |
|    approx_kl            | 0.06658992 |
|    clip_fraction        | 0.272      |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.9        |
|    explained_variance   | 0.923      |
|    learning_rate        | 6.39e-05   |
|    loss                 | -0.0246    |
|    n_updates            | 48480      |
|    policy_gradient_loss | 0.00421    |
|    std                  | 0.021      |
|    value_loss           | 0.0167     |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 4849    |
|    time_elapsed    | 15736   |
|    total_timesteps | 9930752 |
--------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4850       |
|    time_elapsed         | 15739      |
|    total_timesteps      | 9932800    |
| train/                  |            |
|    approx_kl            | 0.07609658 |
|    clip_fraction        | 0.247      |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.9        |
|    explained_variance   | 0.807      |
|    learning_rate        | 6.35e-05   |
|    loss                 | -0.0108    |
|    n_updates            | 48490      |
|    policy_gradient_loss | -0.000242  |
|    std                  | 0.021      |
|    value_loss           | 0.000899   |
----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 4851      |
|    time_elapsed         | 15742     |
|    total_timesteps      | 9934848   |
| train/                  |           |
|    approx_kl            | 0.0964599 |
|    clip_fraction        | 0.319     |
|    clip_range           | 0.2       |
|    entropy_loss         | 4.9       |
|    explained_variance   | 0.957     |
|    learning_rate        | 6.31e-05  |
|    loss                 | -0.044    |
|    n_updates            | 48500     |
|    policy_gradient_loss | 0.00831   |
|    std                  | 0.021     |
|    value_loss           | 0.0129    |
---------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4852       |
|    time_elapsed         | 15745      |
|    total_timesteps      | 9936896    |
| train/                  |            |
|    approx_kl            | 0.17750953 |
|    clip_fraction        | 0.262      |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.9        |
|    explained_variance   | 0.556      |
|    learning_rate        | 6.27e-05   |
|    loss                 | -0.0307    |
|    n_updates            | 48510      |
|    policy_gradient_loss | -0.0173    |
|    std                  | 0.021      |
|    value_loss           | 0.00163    |
----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 631         |
|    iterations           | 4853        |
|    time_elapsed         | 15748       |
|    total_timesteps      | 9938944     |
| train/                  |             |
|    approx_kl            | 0.050103024 |
|    clip_fraction        | 0.289       |
|    clip_range           | 0.2         |
|    entropy_loss         | 4.9         |
|    explained_variance   | 0.731       |
|    learning_rate        | 6.23e-05    |
|    loss                 | 0.116       |
|    n_updates            | 48520       |
|    policy_gradient_loss | 0.00843     |
|    std                  | 0.021       |
|    value_loss           | 0.00383     |
-----------------------------------------
Eval num_timesteps=9940000, episode_reward=-0.90 +/- 0.20
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -0.898     |
| time/                   |            |
|    total_timesteps      | 9940000    |
| train/                  |            |
|    approx_kl            | 0.05543503 |
|    clip_fraction        | 0.241      |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.91       |
|    explained_variance   | 0.566      |
|    learning_rate        | 6.19e-05   |
|    loss                 | 0.0426     |
|    n_updates            | 48530      |
|    policy_gradient_loss | -0.0014    |
|    std                  | 0.0208     |
|    value_loss           | 0.0013     |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 4854    |
|    time_elapsed    | 15752   |
|    total_timesteps | 9940992 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4855       |
|    time_elapsed         | 15755      |
|    total_timesteps      | 9943040    |
| train/                  |            |
|    approx_kl            | 0.07887696 |
|    clip_fraction        | 0.296      |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.92       |
|    explained_variance   | 0.765      |
|    learning_rate        | 6.15e-05   |
|    loss                 | -0.0455    |
|    n_updates            | 48540      |
|    policy_gradient_loss | -0.00352   |
|    std                  | 0.0208     |
|    value_loss           | 0.000906   |
----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 631         |
|    iterations           | 4856        |
|    time_elapsed         | 15758       |
|    total_timesteps      | 9945088     |
| train/                  |             |
|    approx_kl            | 0.061595157 |
|    clip_fraction        | 0.245       |
|    clip_range           | 0.2         |
|    entropy_loss         | 4.92        |
|    explained_variance   | 0.75        |
|    learning_rate        | 6.11e-05    |
|    loss                 | -0.0103     |
|    n_updates            | 48550       |
|    policy_gradient_loss | -0.00934    |
|    std                  | 0.0208      |
|    value_loss           | 0.000997    |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 631         |
|    iterations           | 4857        |
|    time_elapsed         | 15761       |
|    total_timesteps      | 9947136     |
| train/                  |             |
|    approx_kl            | 0.045278147 |
|    clip_fraction        | 0.281       |
|    clip_range           | 0.2         |
|    entropy_loss         | 4.92        |
|    explained_variance   | 0.732       |
|    learning_rate        | 6.07e-05    |
|    loss                 | 0.0137      |
|    n_updates            | 48560       |
|    policy_gradient_loss | 0.0033      |
|    std                  | 0.0208      |
|    value_loss           | 0.00334     |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 631         |
|    iterations           | 4858        |
|    time_elapsed         | 15764       |
|    total_timesteps      | 9949184     |
| train/                  |             |
|    approx_kl            | 0.038421802 |
|    clip_fraction        | 0.202       |
|    clip_range           | 0.2         |
|    entropy_loss         | 4.92        |
|    explained_variance   | 0.747       |
|    learning_rate        | 6.03e-05    |
|    loss                 | 0.00564     |
|    n_updates            | 48570       |
|    policy_gradient_loss | -0.00814    |
|    std                  | 0.0207      |
|    value_loss           | 0.000839    |
-----------------------------------------
box reached target
Eval num_timesteps=9950000, episode_reward=0.31 +/- 2.61
Episode length: 285.40 +/- 29.20
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 285        |
|    mean_reward          | 0.307      |
| time/                   |            |
|    total_timesteps      | 9950000    |
| train/                  |            |
|    approx_kl            | 0.04137233 |
|    clip_fraction        | 0.257      |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.93       |
|    explained_variance   | 0.825      |
|    learning_rate        | 5.99e-05   |
|    loss                 | 0.00405    |
|    n_updates            | 48580      |
|    policy_gradient_loss | -0.00504   |
|    std                  | 0.0207     |
|    value_loss           | 0.000744   |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 4859    |
|    time_elapsed    | 15768   |
|    total_timesteps | 9951232 |
--------------------------------
box reached target
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 631         |
|    iterations           | 4860        |
|    time_elapsed         | 15771       |
|    total_timesteps      | 9953280     |
| train/                  |             |
|    approx_kl            | 0.059880387 |
|    clip_fraction        | 0.202       |
|    clip_range           | 0.2         |
|    entropy_loss         | 4.93        |
|    explained_variance   | 0.814       |
|    learning_rate        | 5.95e-05    |
|    loss                 | -0.0199     |
|    n_updates            | 48590       |
|    policy_gradient_loss | -0.00808    |
|    std                  | 0.0206      |
|    value_loss           | 0.000813    |
-----------------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4861       |
|    time_elapsed         | 15774      |
|    total_timesteps      | 9955328    |
| train/                  |            |
|    approx_kl            | 0.17719015 |
|    clip_fraction        | 0.275      |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.93       |
|    explained_variance   | 0.809      |
|    learning_rate        | 5.91e-05   |
|    loss                 | -0.00608   |
|    n_updates            | 48600      |
|    policy_gradient_loss | -0.00824   |
|    std                  | 0.0206     |
|    value_loss           | 0.0685     |
----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 631         |
|    iterations           | 4862        |
|    time_elapsed         | 15777       |
|    total_timesteps      | 9957376     |
| train/                  |             |
|    approx_kl            | 0.053132843 |
|    clip_fraction        | 0.272       |
|    clip_range           | 0.2         |
|    entropy_loss         | 4.94        |
|    explained_variance   | 0.984       |
|    learning_rate        | 5.87e-05    |
|    loss                 | 0.0155      |
|    n_updates            | 48610       |
|    policy_gradient_loss | -0.00591    |
|    std                  | 0.0205      |
|    value_loss           | 0.00945     |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 631         |
|    iterations           | 4863        |
|    time_elapsed         | 15780       |
|    total_timesteps      | 9959424     |
| train/                  |             |
|    approx_kl            | 0.058878817 |
|    clip_fraction        | 0.295       |
|    clip_range           | 0.2         |
|    entropy_loss         | 4.94        |
|    explained_variance   | 0.641       |
|    learning_rate        | 5.83e-05    |
|    loss                 | -0.00188    |
|    n_updates            | 48620       |
|    policy_gradient_loss | 0.00243     |
|    std                  | 0.0206      |
|    value_loss           | 0.00849     |
-----------------------------------------
box reached target
box reached target
Eval num_timesteps=9960000, episode_reward=0.32 +/- 2.63
Episode length: 286.40 +/- 27.20
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 286        |
|    mean_reward          | 0.317      |
| time/                   |            |
|    total_timesteps      | 9960000    |
| train/                  |            |
|    approx_kl            | 0.08432633 |
|    clip_fraction        | 0.246      |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.94       |
|    explained_variance   | 0.602      |
|    learning_rate        | 5.79e-05   |
|    loss                 | 0.0271     |
|    n_updates            | 48630      |
|    policy_gradient_loss | 0.00403    |
|    std                  | 0.0206     |
|    value_loss           | 0.00544    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 4864    |
|    time_elapsed    | 15784   |
|    total_timesteps | 9961472 |
--------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 631         |
|    iterations           | 4865        |
|    time_elapsed         | 15787       |
|    total_timesteps      | 9963520     |
| train/                  |             |
|    approx_kl            | 0.119255036 |
|    clip_fraction        | 0.316       |
|    clip_range           | 0.2         |
|    entropy_loss         | 4.94        |
|    explained_variance   | 0.942       |
|    learning_rate        | 5.75e-05    |
|    loss                 | 0.0173      |
|    n_updates            | 48640       |
|    policy_gradient_loss | -0.00207    |
|    std                  | 0.0206      |
|    value_loss           | 0.0291      |
-----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4866       |
|    time_elapsed         | 15790      |
|    total_timesteps      | 9965568    |
| train/                  |            |
|    approx_kl            | 0.08257641 |
|    clip_fraction        | 0.235      |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.94       |
|    explained_variance   | 0.751      |
|    learning_rate        | 5.71e-05   |
|    loss                 | -0.0286    |
|    n_updates            | 48650      |
|    policy_gradient_loss | -0.01      |
|    std                  | 0.0205     |
|    value_loss           | 0.00115    |
----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 631         |
|    iterations           | 4867        |
|    time_elapsed         | 15793       |
|    total_timesteps      | 9967616     |
| train/                  |             |
|    approx_kl            | 0.061234113 |
|    clip_fraction        | 0.281       |
|    clip_range           | 0.2         |
|    entropy_loss         | 4.94        |
|    explained_variance   | 0.947       |
|    learning_rate        | 5.67e-05    |
|    loss                 | -0.0143     |
|    n_updates            | 48660       |
|    policy_gradient_loss | -0.00132    |
|    std                  | 0.0205      |
|    value_loss           | 0.0178      |
-----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 4868      |
|    time_elapsed         | 15796     |
|    total_timesteps      | 9969664   |
| train/                  |           |
|    approx_kl            | 0.3438934 |
|    clip_fraction        | 0.248     |
|    clip_range           | 0.2       |
|    entropy_loss         | 4.94      |
|    explained_variance   | 0.718     |
|    learning_rate        | 5.63e-05  |
|    loss                 | -0.0631   |
|    n_updates            | 48670     |
|    policy_gradient_loss | -0.0121   |
|    std                  | 0.0205    |
|    value_loss           | 0.00169   |
---------------------------------------
Eval num_timesteps=9970000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 300         |
|    mean_reward          | -1          |
| time/                   |             |
|    total_timesteps      | 9970000     |
| train/                  |             |
|    approx_kl            | 0.058454398 |
|    clip_fraction        | 0.236       |
|    clip_range           | 0.2         |
|    entropy_loss         | 4.94        |
|    explained_variance   | 0.734       |
|    learning_rate        | 5.59e-05    |
|    loss                 | -0.000597   |
|    n_updates            | 48680       |
|    policy_gradient_loss | -0.00707    |
|    std                  | 0.0205      |
|    value_loss           | 0.00108     |
-----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 4869    |
|    time_elapsed    | 15800   |
|    total_timesteps | 9971712 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4870       |
|    time_elapsed         | 15803      |
|    total_timesteps      | 9973760    |
| train/                  |            |
|    approx_kl            | 0.04441319 |
|    clip_fraction        | 0.222      |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.95       |
|    explained_variance   | 0.871      |
|    learning_rate        | 5.55e-05   |
|    loss                 | 0.02       |
|    n_updates            | 48690      |
|    policy_gradient_loss | -0.0037    |
|    std                  | 0.0204     |
|    value_loss           | 0.000696   |
----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 4871      |
|    time_elapsed         | 15806     |
|    total_timesteps      | 9975808   |
| train/                  |           |
|    approx_kl            | 0.0477793 |
|    clip_fraction        | 0.208     |
|    clip_range           | 0.2       |
|    entropy_loss         | 4.96      |
|    explained_variance   | 0.64      |
|    learning_rate        | 5.51e-05  |
|    loss                 | 0.0129    |
|    n_updates            | 48700     |
|    policy_gradient_loss | -0.00551  |
|    std                  | 0.0203    |
|    value_loss           | 0.00119   |
---------------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 631         |
|    iterations           | 4872        |
|    time_elapsed         | 15809       |
|    total_timesteps      | 9977856     |
| train/                  |             |
|    approx_kl            | 0.061577283 |
|    clip_fraction        | 0.274       |
|    clip_range           | 0.2         |
|    entropy_loss         | 4.96        |
|    explained_variance   | 0.751       |
|    learning_rate        | 5.47e-05    |
|    loss                 | -0.0171     |
|    n_updates            | 48710       |
|    policy_gradient_loss | -0.00927    |
|    std                  | 0.0204      |
|    value_loss           | 0.00113     |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 631         |
|    iterations           | 4873        |
|    time_elapsed         | 15812       |
|    total_timesteps      | 9979904     |
| train/                  |             |
|    approx_kl            | 0.054526888 |
|    clip_fraction        | 0.269       |
|    clip_range           | 0.2         |
|    entropy_loss         | 4.96        |
|    explained_variance   | 0.976       |
|    learning_rate        | 5.43e-05    |
|    loss                 | 0.0126      |
|    n_updates            | 48720       |
|    policy_gradient_loss | -0.00646    |
|    std                  | 0.0203      |
|    value_loss           | 0.00741     |
-----------------------------------------
Eval num_timesteps=9980000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 300         |
|    mean_reward          | -1          |
| time/                   |             |
|    total_timesteps      | 9980000     |
| train/                  |             |
|    approx_kl            | 0.055867948 |
|    clip_fraction        | 0.284       |
|    clip_range           | 0.2         |
|    entropy_loss         | 4.96        |
|    explained_variance   | 0.61        |
|    learning_rate        | 5.39e-05    |
|    loss                 | 0.0159      |
|    n_updates            | 48730       |
|    policy_gradient_loss | -0.00506    |
|    std                  | 0.0203      |
|    value_loss           | 0.0271      |
-----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 4874    |
|    time_elapsed    | 15816   |
|    total_timesteps | 9981952 |
--------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 631         |
|    iterations           | 4875        |
|    time_elapsed         | 15819       |
|    total_timesteps      | 9984000     |
| train/                  |             |
|    approx_kl            | 0.049170114 |
|    clip_fraction        | 0.186       |
|    clip_range           | 0.2         |
|    entropy_loss         | 4.97        |
|    explained_variance   | 0.73        |
|    learning_rate        | 5.35e-05    |
|    loss                 | -0.0112     |
|    n_updates            | 48740       |
|    policy_gradient_loss | -0.00418    |
|    std                  | 0.0203      |
|    value_loss           | 0.00106     |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 631         |
|    iterations           | 4876        |
|    time_elapsed         | 15822       |
|    total_timesteps      | 9986048     |
| train/                  |             |
|    approx_kl            | 0.043154154 |
|    clip_fraction        | 0.235       |
|    clip_range           | 0.2         |
|    entropy_loss         | 4.97        |
|    explained_variance   | 0.968       |
|    learning_rate        | 5.31e-05    |
|    loss                 | 0.00392     |
|    n_updates            | 48750       |
|    policy_gradient_loss | -0.00456    |
|    std                  | 0.0202      |
|    value_loss           | 0.0149      |
-----------------------------------------
---------------------------------------
| time/                   |           |
|    fps                  | 631       |
|    iterations           | 4877      |
|    time_elapsed         | 15825     |
|    total_timesteps      | 9988096   |
| train/                  |           |
|    approx_kl            | 0.1023456 |
|    clip_fraction        | 0.235     |
|    clip_range           | 0.2       |
|    entropy_loss         | 4.97      |
|    explained_variance   | 0.572     |
|    learning_rate        | 5.27e-05  |
|    loss                 | -0.00975  |
|    n_updates            | 48760     |
|    policy_gradient_loss | -0.0073   |
|    std                  | 0.0202    |
|    value_loss           | 0.00217   |
---------------------------------------
Eval num_timesteps=9990000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1         |
| time/                   |            |
|    total_timesteps      | 9990000    |
| train/                  |            |
|    approx_kl            | 0.10797469 |
|    clip_fraction        | 0.23       |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.98       |
|    explained_variance   | 0.61       |
|    learning_rate        | 5.23e-05   |
|    loss                 | -0.0372    |
|    n_updates            | 48770      |
|    policy_gradient_loss | 0.00968    |
|    std                  | 0.0201     |
|    value_loss           | 0.00136    |
----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 4878    |
|    time_elapsed    | 15829   |
|    total_timesteps | 9990144 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4879       |
|    time_elapsed         | 15832      |
|    total_timesteps      | 9992192    |
| train/                  |            |
|    approx_kl            | 0.07291832 |
|    clip_fraction        | 0.255      |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.98       |
|    explained_variance   | 0.655      |
|    learning_rate        | 5.19e-05   |
|    loss                 | -0.0174    |
|    n_updates            | 48780      |
|    policy_gradient_loss | -0.0115    |
|    std                  | 0.0202     |
|    value_loss           | 0.00185    |
----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 631         |
|    iterations           | 4880        |
|    time_elapsed         | 15835       |
|    total_timesteps      | 9994240     |
| train/                  |             |
|    approx_kl            | 0.037822217 |
|    clip_fraction        | 0.265       |
|    clip_range           | 0.2         |
|    entropy_loss         | 4.98        |
|    explained_variance   | 0.776       |
|    learning_rate        | 5.15e-05    |
|    loss                 | -0.0275     |
|    n_updates            | 48790       |
|    policy_gradient_loss | -0.00213    |
|    std                  | 0.0202      |
|    value_loss           | 0.001       |
-----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4881       |
|    time_elapsed         | 15838      |
|    total_timesteps      | 9996288    |
| train/                  |            |
|    approx_kl            | 0.09244453 |
|    clip_fraction        | 0.205      |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.98       |
|    explained_variance   | 0.474      |
|    learning_rate        | 5.11e-05   |
|    loss                 | -0.0357    |
|    n_updates            | 48800      |
|    policy_gradient_loss | -0.0151    |
|    std                  | 0.0202     |
|    value_loss           | 0.00174    |
----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 631        |
|    iterations           | 4882       |
|    time_elapsed         | 15841      |
|    total_timesteps      | 9998336    |
| train/                  |            |
|    approx_kl            | 0.03957446 |
|    clip_fraction        | 0.191      |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.97       |
|    explained_variance   | 0.793      |
|    learning_rate        | 5.07e-05   |
|    loss                 | -0.0198    |
|    n_updates            | 48810      |
|    policy_gradient_loss | -0.00633   |
|    std                  | 0.0202     |
|    value_loss           | 0.000898   |
----------------------------------------
Eval num_timesteps=10000000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1         |
| time/                   |            |
|    total_timesteps      | 10000000   |
| train/                  |            |
|    approx_kl            | 0.04592001 |
|    clip_fraction        | 0.216      |
|    clip_range           | 0.2        |
|    entropy_loss         | 4.98       |
|    explained_variance   | 0.63       |
|    learning_rate        | 5.03e-05   |
|    loss                 | -0.0223    |
|    n_updates            | 48820      |
|    policy_gradient_loss | -0.00889   |
|    std                  | 0.0202     |
|    value_loss           | 0.00114    |
----------------------------------------
---------------------------------
| time/              |          |
|    fps             | 631      |
|    iterations      | 4883     |
|    time_elapsed    | 15845    |
|    total_timesteps | 10000384 |
---------------------------------
Deactivating TensorFlow-2.6.2 environment
/var/spool/slurmd/job09271/slurm_script: line 34: deactivate: command not found
Done.
