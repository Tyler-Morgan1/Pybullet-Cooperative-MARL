CUDA_VISIBLE_DEVICES: 1
Activating TensorFlow-2.6.2 environment
Running clusterTrain.py
pybullet build time: Nov 28 2023 23:48:36
Using cuda device
Logging to Training/clusterResults/clusterLogs/PPO_7
-----------------------------
| time/              |      |
|    fps             | 972  |
|    iterations      | 1    |
|    time_elapsed    | 2    |
|    total_timesteps | 2048 |
-----------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 772         |
|    iterations           | 2           |
|    time_elapsed         | 5           |
|    total_timesteps      | 4096        |
| train/                  |             |
|    approx_kl            | 0.004423511 |
|    clip_fraction        | 0.0084      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.84       |
|    explained_variance   | 0.9         |
|    learning_rate        | 5e-05       |
|    loss                 | -0.00527    |
|    n_updates            | 10          |
|    policy_gradient_loss | -0.00281    |
|    std                  | 0.999       |
|    value_loss           | 0.00594     |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 735         |
|    iterations           | 3           |
|    time_elapsed         | 8           |
|    total_timesteps      | 6144        |
| train/                  |             |
|    approx_kl            | 0.005202296 |
|    clip_fraction        | 0.0195      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.83       |
|    explained_variance   | 0.881       |
|    learning_rate        | 5e-05       |
|    loss                 | 0.0156      |
|    n_updates            | 20          |
|    policy_gradient_loss | -0.00375    |
|    std                  | 0.998       |
|    value_loss           | 0.00409     |
-----------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 718          |
|    iterations           | 4            |
|    time_elapsed         | 11           |
|    total_timesteps      | 8192         |
| train/                  |              |
|    approx_kl            | 0.0012758491 |
|    clip_fraction        | 0.000195     |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.83        |
|    explained_variance   | 0.9          |
|    learning_rate        | 5e-05        |
|    loss                 | 0.000783     |
|    n_updates            | 30           |
|    policy_gradient_loss | -0.000562    |
|    std                  | 0.995        |
|    value_loss           | 0.00276      |
------------------------------------------
/home/tmorgan01/anaconda3/envs/dan/lib/python3.11/site-packages/stable_baselines3/common/evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.
  warnings.warn(
Eval num_timesteps=10000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 300          |
|    mean_reward          | -1           |
| time/                   |              |
|    total_timesteps      | 10000        |
| train/                  |              |
|    approx_kl            | 0.0016208575 |
|    clip_fraction        | 0.000879     |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.83        |
|    explained_variance   | 0.901        |
|    learning_rate        | 5e-05        |
|    loss                 | -0.00319     |
|    n_updates            | 40           |
|    policy_gradient_loss | -0.000862    |
|    std                  | 0.994        |
|    value_loss           | 0.000847     |
------------------------------------------
New best mean reward!
------------------------------
| time/              |       |
|    fps             | 665   |
|    iterations      | 5     |
|    time_elapsed    | 15    |
|    total_timesteps | 10240 |
------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 666          |
|    iterations           | 6            |
|    time_elapsed         | 18           |
|    total_timesteps      | 12288        |
| train/                  |              |
|    approx_kl            | 0.0045011966 |
|    clip_fraction        | 0.0178       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.83        |
|    explained_variance   | 0.889        |
|    learning_rate        | 5.01e-05     |
|    loss                 | 0.00677      |
|    n_updates            | 50           |
|    policy_gradient_loss | -0.00293     |
|    std                  | 0.996        |
|    value_loss           | 0.00144      |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 666          |
|    iterations           | 7            |
|    time_elapsed         | 21           |
|    total_timesteps      | 14336        |
| train/                  |              |
|    approx_kl            | 0.0038314238 |
|    clip_fraction        | 0.00742      |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.83        |
|    explained_variance   | 0.648        |
|    learning_rate        | 5.01e-05     |
|    loss                 | 0.00855      |
|    n_updates            | 60           |
|    policy_gradient_loss | -0.00181     |
|    std                  | 0.993        |
|    value_loss           | 0.00103      |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 667          |
|    iterations           | 8            |
|    time_elapsed         | 24           |
|    total_timesteps      | 16384        |
| train/                  |              |
|    approx_kl            | 0.0053712977 |
|    clip_fraction        | 0.0314       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.82        |
|    explained_variance   | 0.849        |
|    learning_rate        | 5.01e-05     |
|    loss                 | -0.0137      |
|    n_updates            | 70           |
|    policy_gradient_loss | -0.0045      |
|    std                  | 0.992        |
|    value_loss           | 0.000666     |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 667          |
|    iterations           | 9            |
|    time_elapsed         | 27           |
|    total_timesteps      | 18432        |
| train/                  |              |
|    approx_kl            | 0.0020299777 |
|    clip_fraction        | 0.00215      |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.82        |
|    explained_variance   | 0.856        |
|    learning_rate        | 5.01e-05     |
|    loss                 | 0.0204       |
|    n_updates            | 80           |
|    policy_gradient_loss | -0.00188     |
|    std                  | 0.991        |
|    value_loss           | 0.00102      |
------------------------------------------
Eval num_timesteps=20000, episode_reward=-0.78 +/- 0.44
Episode length: 300.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 300         |
|    mean_reward          | -0.781      |
| time/                   |             |
|    total_timesteps      | 20000       |
| train/                  |             |
|    approx_kl            | 0.004666895 |
|    clip_fraction        | 0.0117      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.82       |
|    explained_variance   | 0.823       |
|    learning_rate        | 5.01e-05    |
|    loss                 | 0.00301     |
|    n_updates            | 90          |
|    policy_gradient_loss | -0.00398    |
|    std                  | 0.991       |
|    value_loss           | 0.0012      |
-----------------------------------------
New best mean reward!
------------------------------
| time/              |       |
|    fps             | 647   |
|    iterations      | 10    |
|    time_elapsed    | 31    |
|    total_timesteps | 20480 |
------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 649          |
|    iterations           | 11           |
|    time_elapsed         | 34           |
|    total_timesteps      | 22528        |
| train/                  |              |
|    approx_kl            | 0.0041787066 |
|    clip_fraction        | 0.0126       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.82        |
|    explained_variance   | 0.749        |
|    learning_rate        | 5.01e-05     |
|    loss                 | -0.00489     |
|    n_updates            | 100          |
|    policy_gradient_loss | -0.00317     |
|    std                  | 0.989        |
|    value_loss           | 0.00166      |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 651          |
|    iterations           | 12           |
|    time_elapsed         | 37           |
|    total_timesteps      | 24576        |
| train/                  |              |
|    approx_kl            | 0.0050170254 |
|    clip_fraction        | 0.0241       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.81        |
|    explained_variance   | 0.782        |
|    learning_rate        | 5.01e-05     |
|    loss                 | 0.00178      |
|    n_updates            | 110          |
|    policy_gradient_loss | -0.00319     |
|    std                  | 0.986        |
|    value_loss           | 0.00151      |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 653          |
|    iterations           | 13           |
|    time_elapsed         | 40           |
|    total_timesteps      | 26624        |
| train/                  |              |
|    approx_kl            | 0.0019415178 |
|    clip_fraction        | 0.00298      |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.81        |
|    explained_variance   | 0.635        |
|    learning_rate        | 5.01e-05     |
|    loss                 | -0.00184     |
|    n_updates            | 120          |
|    policy_gradient_loss | -0.00237     |
|    std                  | 0.984        |
|    value_loss           | 0.000779     |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 654          |
|    iterations           | 14           |
|    time_elapsed         | 43           |
|    total_timesteps      | 28672        |
| train/                  |              |
|    approx_kl            | 0.0038102833 |
|    clip_fraction        | 0.0102       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.8         |
|    explained_variance   | 0.68         |
|    learning_rate        | 5.01e-05     |
|    loss                 | 0.00665      |
|    n_updates            | 130          |
|    policy_gradient_loss | -0.00275     |
|    std                  | 0.982        |
|    value_loss           | 0.0018       |
------------------------------------------
Eval num_timesteps=30000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 300          |
|    mean_reward          | -1           |
| time/                   |              |
|    total_timesteps      | 30000        |
| train/                  |              |
|    approx_kl            | 0.0051606637 |
|    clip_fraction        | 0.0238       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.8         |
|    explained_variance   | 0.624        |
|    learning_rate        | 5.01e-05     |
|    loss                 | -0.0158      |
|    n_updates            | 140          |
|    policy_gradient_loss | -0.00371     |
|    std                  | 0.981        |
|    value_loss           | 0.00106      |
------------------------------------------
------------------------------
| time/              |       |
|    fps             | 642   |
|    iterations      | 15    |
|    time_elapsed    | 47    |
|    total_timesteps | 30720 |
------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 644          |
|    iterations           | 16           |
|    time_elapsed         | 50           |
|    total_timesteps      | 32768        |
| train/                  |              |
|    approx_kl            | 0.0040781684 |
|    clip_fraction        | 0.0167       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.8         |
|    explained_variance   | 0.639        |
|    learning_rate        | 5.02e-05     |
|    loss                 | -0.0346      |
|    n_updates            | 150          |
|    policy_gradient_loss | -0.0049      |
|    std                  | 0.979        |
|    value_loss           | 0.00176      |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 645          |
|    iterations           | 17           |
|    time_elapsed         | 53           |
|    total_timesteps      | 34816        |
| train/                  |              |
|    approx_kl            | 0.0027715964 |
|    clip_fraction        | 0.00249      |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.79        |
|    explained_variance   | 0.599        |
|    learning_rate        | 5.02e-05     |
|    loss                 | -0.0144      |
|    n_updates            | 160          |
|    policy_gradient_loss | -0.00144     |
|    std                  | 0.977        |
|    value_loss           | 0.00158      |
------------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 646         |
|    iterations           | 18          |
|    time_elapsed         | 56          |
|    total_timesteps      | 36864       |
| train/                  |             |
|    approx_kl            | 0.003259544 |
|    clip_fraction        | 0.00869     |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.79       |
|    explained_variance   | 0.712       |
|    learning_rate        | 5.02e-05    |
|    loss                 | 0.00777     |
|    n_updates            | 170         |
|    policy_gradient_loss | -0.00299    |
|    std                  | 0.978       |
|    value_loss           | 0.0017      |
-----------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 647          |
|    iterations           | 19           |
|    time_elapsed         | 60           |
|    total_timesteps      | 38912        |
| train/                  |              |
|    approx_kl            | 0.0014112523 |
|    clip_fraction        | 0.000195     |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.79        |
|    explained_variance   | 0.334        |
|    learning_rate        | 5.02e-05     |
|    loss                 | 0.00192      |
|    n_updates            | 180          |
|    policy_gradient_loss | -0.00125     |
|    std                  | 0.977        |
|    value_loss           | 0.00157      |
------------------------------------------
Eval num_timesteps=40000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 300          |
|    mean_reward          | -1           |
| time/                   |              |
|    total_timesteps      | 40000        |
| train/                  |              |
|    approx_kl            | 0.0029218476 |
|    clip_fraction        | 0.0146       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.79        |
|    explained_variance   | 0.563        |
|    learning_rate        | 5.02e-05     |
|    loss                 | 0.00719      |
|    n_updates            | 190          |
|    policy_gradient_loss | -0.00241     |
|    std                  | 0.976        |
|    value_loss           | 0.00147      |
------------------------------------------
------------------------------
| time/              |       |
|    fps             | 639   |
|    iterations      | 20    |
|    time_elapsed    | 64    |
|    total_timesteps | 40960 |
------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 640          |
|    iterations           | 21           |
|    time_elapsed         | 67           |
|    total_timesteps      | 43008        |
| train/                  |              |
|    approx_kl            | 0.0049538985 |
|    clip_fraction        | 0.0263       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.79        |
|    explained_variance   | 0.614        |
|    learning_rate        | 5.02e-05     |
|    loss                 | 0.00318      |
|    n_updates            | 200          |
|    policy_gradient_loss | -0.00317     |
|    std                  | 0.973        |
|    value_loss           | 0.00146      |
------------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 642         |
|    iterations           | 22          |
|    time_elapsed         | 70          |
|    total_timesteps      | 45056       |
| train/                  |             |
|    approx_kl            | 0.002900145 |
|    clip_fraction        | 0.00776     |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.78       |
|    explained_variance   | 0.741       |
|    learning_rate        | 5.02e-05    |
|    loss                 | -0.00209    |
|    n_updates            | 210         |
|    policy_gradient_loss | -0.00246    |
|    std                  | 0.97        |
|    value_loss           | 0.00233     |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 643         |
|    iterations           | 23          |
|    time_elapsed         | 73          |
|    total_timesteps      | 47104       |
| train/                  |             |
|    approx_kl            | 0.006047018 |
|    clip_fraction        | 0.0411      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.78       |
|    explained_variance   | 0.548       |
|    learning_rate        | 5.02e-05    |
|    loss                 | -0.0129     |
|    n_updates            | 220         |
|    policy_gradient_loss | -0.00572    |
|    std                  | 0.968       |
|    value_loss           | 0.00147     |
-----------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 644          |
|    iterations           | 24           |
|    time_elapsed         | 76           |
|    total_timesteps      | 49152        |
| train/                  |              |
|    approx_kl            | 0.0011610244 |
|    clip_fraction        | 0.000146     |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.77        |
|    explained_variance   | 0.37         |
|    learning_rate        | 5.02e-05     |
|    loss                 | -0.00569     |
|    n_updates            | 230          |
|    policy_gradient_loss | -0.00125     |
|    std                  | 0.962        |
|    value_loss           | 0.00154      |
------------------------------------------
Eval num_timesteps=50000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 300         |
|    mean_reward          | -1          |
| time/                   |             |
|    total_timesteps      | 50000       |
| train/                  |             |
|    approx_kl            | 0.004500663 |
|    clip_fraction        | 0.0127      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.76       |
|    explained_variance   | 0.643       |
|    learning_rate        | 5.02e-05    |
|    loss                 | -0.0163     |
|    n_updates            | 240         |
|    policy_gradient_loss | -0.00336    |
|    std                  | 0.958       |
|    value_loss           | 0.00148     |
-----------------------------------------
------------------------------
| time/              |       |
|    fps             | 637   |
|    iterations      | 25    |
|    time_elapsed    | 80    |
|    total_timesteps | 51200 |
------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 638          |
|    iterations           | 26           |
|    time_elapsed         | 83           |
|    total_timesteps      | 53248        |
| train/                  |              |
|    approx_kl            | 0.0038000317 |
|    clip_fraction        | 0.0134       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.75        |
|    explained_variance   | 0.644        |
|    learning_rate        | 5.03e-05     |
|    loss                 | -0.00783     |
|    n_updates            | 250          |
|    policy_gradient_loss | -0.00342     |
|    std                  | 0.956        |
|    value_loss           | 0.00155      |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 640          |
|    iterations           | 27           |
|    time_elapsed         | 86           |
|    total_timesteps      | 55296        |
| train/                  |              |
|    approx_kl            | 0.0010079341 |
|    clip_fraction        | 9.77e-05     |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.75        |
|    explained_variance   | 0.726        |
|    learning_rate        | 5.03e-05     |
|    loss                 | 0.00589      |
|    n_updates            | 260          |
|    policy_gradient_loss | -0.000664    |
|    std                  | 0.954        |
|    value_loss           | 0.00166      |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 640          |
|    iterations           | 28           |
|    time_elapsed         | 89           |
|    total_timesteps      | 57344        |
| train/                  |              |
|    approx_kl            | 0.0018813671 |
|    clip_fraction        | 0.000635     |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.74        |
|    explained_variance   | 0.547        |
|    learning_rate        | 5.03e-05     |
|    loss                 | -0.00212     |
|    n_updates            | 270          |
|    policy_gradient_loss | -0.00102     |
|    std                  | 0.951        |
|    value_loss           | 0.00186      |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 641          |
|    iterations           | 29           |
|    time_elapsed         | 92           |
|    total_timesteps      | 59392        |
| train/                  |              |
|    approx_kl            | 0.0041256947 |
|    clip_fraction        | 0.0124       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.73        |
|    explained_variance   | 0.779        |
|    learning_rate        | 5.03e-05     |
|    loss                 | 0.000734     |
|    n_updates            | 280          |
|    policy_gradient_loss | -0.00261     |
|    std                  | 0.948        |
|    value_loss           | 0.00141      |
------------------------------------------
Eval num_timesteps=60000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 300        |
|    mean_reward          | -1         |
| time/                   |            |
|    total_timesteps      | 60000      |
| train/                  |            |
|    approx_kl            | 0.00632383 |
|    clip_fraction        | 0.0414     |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.73      |
|    explained_variance   | 0.76       |
|    learning_rate        | 5.03e-05   |
|    loss                 | -0.00541   |
|    n_updates            | 290        |
|    policy_gradient_loss | -0.00478   |
|    std                  | 0.946      |
|    value_loss           | 0.0017     |
----------------------------------------
------------------------------
| time/              |       |
|    fps             | 636   |
|    iterations      | 30    |
|    time_elapsed    | 96    |
|    total_timesteps | 61440 |
------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 637          |
|    iterations           | 31           |
|    time_elapsed         | 99           |
|    total_timesteps      | 63488        |
| train/                  |              |
|    approx_kl            | 0.0070684776 |
|    clip_fraction        | 0.0482       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.72        |
|    explained_variance   | 0.631        |
|    learning_rate        | 5.03e-05     |
|    loss                 | 0.00236      |
|    n_updates            | 300          |
|    policy_gradient_loss | -0.0062      |
|    std                  | 0.944        |
|    value_loss           | 0.00207      |
------------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 638         |
|    iterations           | 32          |
|    time_elapsed         | 102         |
|    total_timesteps      | 65536       |
| train/                  |             |
|    approx_kl            | 0.002880189 |
|    clip_fraction        | 0.00508     |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.72       |
|    explained_variance   | 0.661       |
|    learning_rate        | 5.03e-05    |
|    loss                 | -0.00814    |
|    n_updates            | 310         |
|    policy_gradient_loss | -0.00215    |
|    std                  | 0.942       |
|    value_loss           | 0.00105     |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 639         |
|    iterations           | 33          |
|    time_elapsed         | 105         |
|    total_timesteps      | 67584       |
| train/                  |             |
|    approx_kl            | 0.003977228 |
|    clip_fraction        | 0.0204      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.71       |
|    explained_variance   | 0.562       |
|    learning_rate        | 5.03e-05    |
|    loss                 | -0.0218     |
|    n_updates            | 320         |
|    policy_gradient_loss | -0.0026     |
|    std                  | 0.938       |
|    value_loss           | 0.00131     |
-----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 640        |
|    iterations           | 34         |
|    time_elapsed         | 108        |
|    total_timesteps      | 69632      |
| train/                  |            |
|    approx_kl            | 0.00467483 |
|    clip_fraction        | 0.0245     |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.71      |
|    explained_variance   | 0.742      |
|    learning_rate        | 5.03e-05   |
|    loss                 | 0.00208    |
|    n_updates            | 330        |
|    policy_gradient_loss | -0.00381   |
|    std                  | 0.935      |
|    value_loss           | 0.000879   |
----------------------------------------
Eval num_timesteps=70000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 300         |
|    mean_reward          | -1          |
| time/                   |             |
|    total_timesteps      | 70000       |
| train/                  |             |
|    approx_kl            | 0.005527642 |
|    clip_fraction        | 0.0396      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.7        |
|    explained_variance   | 0.795       |
|    learning_rate        | 5.03e-05    |
|    loss                 | 0.0013      |
|    n_updates            | 340         |
|    policy_gradient_loss | -0.00501    |
|    std                  | 0.931       |
|    value_loss           | 0.000771    |
-----------------------------------------
------------------------------
| time/              |       |
|    fps             | 635   |
|    iterations      | 35    |
|    time_elapsed    | 112   |
|    total_timesteps | 71680 |
------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 636          |
|    iterations           | 36           |
|    time_elapsed         | 115          |
|    total_timesteps      | 73728        |
| train/                  |              |
|    approx_kl            | 0.0029788981 |
|    clip_fraction        | 0.00386      |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.69        |
|    explained_variance   | 0.792        |
|    learning_rate        | 5.04e-05     |
|    loss                 | -0.00368     |
|    n_updates            | 350          |
|    policy_gradient_loss | -0.00208     |
|    std                  | 0.929        |
|    value_loss           | 0.000828     |
------------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 637         |
|    iterations           | 37          |
|    time_elapsed         | 118         |
|    total_timesteps      | 75776       |
| train/                  |             |
|    approx_kl            | 0.004949412 |
|    clip_fraction        | 0.0192      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.69       |
|    explained_variance   | 0.439       |
|    learning_rate        | 5.04e-05    |
|    loss                 | 0.00292     |
|    n_updates            | 360         |
|    policy_gradient_loss | -0.00332    |
|    std                  | 0.924       |
|    value_loss           | 0.0015      |
-----------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 638          |
|    iterations           | 38           |
|    time_elapsed         | 121          |
|    total_timesteps      | 77824        |
| train/                  |              |
|    approx_kl            | 0.0036677425 |
|    clip_fraction        | 0.0194       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.68        |
|    explained_variance   | 0.784        |
|    learning_rate        | 5.04e-05     |
|    loss                 | 0.00373      |
|    n_updates            | 370          |
|    policy_gradient_loss | -0.0024      |
|    std                  | 0.921        |
|    value_loss           | 0.000999     |
------------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 638         |
|    iterations           | 39          |
|    time_elapsed         | 125         |
|    total_timesteps      | 79872       |
| train/                  |             |
|    approx_kl            | 0.005111623 |
|    clip_fraction        | 0.0327      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.67       |
|    explained_variance   | 0.765       |
|    learning_rate        | 5.04e-05    |
|    loss                 | -0.0304     |
|    n_updates            | 380         |
|    policy_gradient_loss | -0.00472    |
|    std                  | 0.919       |
|    value_loss           | 0.00101     |
-----------------------------------------
Eval num_timesteps=80000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 300          |
|    mean_reward          | -1           |
| time/                   |              |
|    total_timesteps      | 80000        |
| train/                  |              |
|    approx_kl            | 0.0045894436 |
|    clip_fraction        | 0.0192       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.67        |
|    explained_variance   | 0.769        |
|    learning_rate        | 5.04e-05     |
|    loss                 | 0.0116       |
|    n_updates            | 390          |
|    policy_gradient_loss | -0.00281     |
|    std                  | 0.919        |
|    value_loss           | 0.00103      |
------------------------------------------
------------------------------
| time/              |       |
|    fps             | 634   |
|    iterations      | 40    |
|    time_elapsed    | 129   |
|    total_timesteps | 81920 |
------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 635          |
|    iterations           | 41           |
|    time_elapsed         | 132          |
|    total_timesteps      | 83968        |
| train/                  |              |
|    approx_kl            | 0.0037258093 |
|    clip_fraction        | 0.00889      |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.67        |
|    explained_variance   | 0.566        |
|    learning_rate        | 5.04e-05     |
|    loss                 | -0.000327    |
|    n_updates            | 400          |
|    policy_gradient_loss | -0.00222     |
|    std                  | 0.917        |
|    value_loss           | 0.00101      |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 636          |
|    iterations           | 42           |
|    time_elapsed         | 135          |
|    total_timesteps      | 86016        |
| train/                  |              |
|    approx_kl            | 0.0028125958 |
|    clip_fraction        | 0.0146       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.66        |
|    explained_variance   | 0.555        |
|    learning_rate        | 5.04e-05     |
|    loss                 | 0.00233      |
|    n_updates            | 410          |
|    policy_gradient_loss | -0.0038      |
|    std                  | 0.914        |
|    value_loss           | 0.00123      |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 637          |
|    iterations           | 43           |
|    time_elapsed         | 138          |
|    total_timesteps      | 88064        |
| train/                  |              |
|    approx_kl            | 0.0038228761 |
|    clip_fraction        | 0.0157       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.66        |
|    explained_variance   | 0.748        |
|    learning_rate        | 5.04e-05     |
|    loss                 | -0.0143      |
|    n_updates            | 420          |
|    policy_gradient_loss | -0.00363     |
|    std                  | 0.912        |
|    value_loss           | 0.000864     |
------------------------------------------
Eval num_timesteps=90000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 300          |
|    mean_reward          | -1           |
| time/                   |              |
|    total_timesteps      | 90000        |
| train/                  |              |
|    approx_kl            | 0.0023813746 |
|    clip_fraction        | 0.00464      |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.65        |
|    explained_variance   | 0.886        |
|    learning_rate        | 5.04e-05     |
|    loss                 | 0.002        |
|    n_updates            | 430          |
|    policy_gradient_loss | -0.00219     |
|    std                  | 0.909        |
|    value_loss           | 0.000431     |
------------------------------------------
------------------------------
| time/              |       |
|    fps             | 633   |
|    iterations      | 44    |
|    time_elapsed    | 142   |
|    total_timesteps | 90112 |
------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 634          |
|    iterations           | 45           |
|    time_elapsed         | 145          |
|    total_timesteps      | 92160        |
| train/                  |              |
|    approx_kl            | 0.0032006097 |
|    clip_fraction        | 0.00698      |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.64        |
|    explained_variance   | 0.587        |
|    learning_rate        | 5.05e-05     |
|    loss                 | -0.00557     |
|    n_updates            | 440          |
|    policy_gradient_loss | -0.00221     |
|    std                  | 0.905        |
|    value_loss           | 0.00139      |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 635          |
|    iterations           | 46           |
|    time_elapsed         | 148          |
|    total_timesteps      | 94208        |
| train/                  |              |
|    approx_kl            | 0.0016618291 |
|    clip_fraction        | 0.00186      |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.63        |
|    explained_variance   | 0.598        |
|    learning_rate        | 5.05e-05     |
|    loss                 | -0.00698     |
|    n_updates            | 450          |
|    policy_gradient_loss | -0.0014      |
|    std                  | 0.902        |
|    value_loss           | 0.00133      |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 635          |
|    iterations           | 47           |
|    time_elapsed         | 151          |
|    total_timesteps      | 96256        |
| train/                  |              |
|    approx_kl            | 0.0014944376 |
|    clip_fraction        | 0.00386      |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.63        |
|    explained_variance   | 0.491        |
|    learning_rate        | 5.05e-05     |
|    loss                 | 0.00444      |
|    n_updates            | 460          |
|    policy_gradient_loss | -0.00106     |
|    std                  | 0.899        |
|    value_loss           | 0.00141      |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 636          |
|    iterations           | 48           |
|    time_elapsed         | 154          |
|    total_timesteps      | 98304        |
| train/                  |              |
|    approx_kl            | 0.0037966648 |
|    clip_fraction        | 0.00991      |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.62        |
|    explained_variance   | 0.723        |
|    learning_rate        | 5.05e-05     |
|    loss                 | 0.00249      |
|    n_updates            | 470          |
|    policy_gradient_loss | -0.00243     |
|    std                  | 0.896        |
|    value_loss           | 0.0013       |
------------------------------------------
Eval num_timesteps=100000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 300         |
|    mean_reward          | -1          |
| time/                   |             |
|    total_timesteps      | 100000      |
| train/                  |             |
|    approx_kl            | 0.004171654 |
|    clip_fraction        | 0.0232      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.62       |
|    explained_variance   | 0.772       |
|    learning_rate        | 5.05e-05    |
|    loss                 | -0.00532    |
|    n_updates            | 480         |
|    policy_gradient_loss | -0.0034     |
|    std                  | 0.893       |
|    value_loss           | 0.000719    |
-----------------------------------------
-------------------------------
| time/              |        |
|    fps             | 633    |
|    iterations      | 49     |
|    time_elapsed    | 158    |
|    total_timesteps | 100352 |
-------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 634          |
|    iterations           | 50           |
|    time_elapsed         | 161          |
|    total_timesteps      | 102400       |
| train/                  |              |
|    approx_kl            | 0.0015081497 |
|    clip_fraction        | 0.000977     |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.61        |
|    explained_variance   | 0.103        |
|    learning_rate        | 5.05e-05     |
|    loss                 | 0.00948      |
|    n_updates            | 490          |
|    policy_gradient_loss | -0.000887    |
|    std                  | 0.892        |
|    value_loss           | 0.00121      |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 634          |
|    iterations           | 51           |
|    time_elapsed         | 164          |
|    total_timesteps      | 104448       |
| train/                  |              |
|    approx_kl            | 0.0034483825 |
|    clip_fraction        | 0.00991      |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.61        |
|    explained_variance   | 0.711        |
|    learning_rate        | 5.05e-05     |
|    loss                 | 0.00838      |
|    n_updates            | 500          |
|    policy_gradient_loss | -0.00264     |
|    std                  | 0.891        |
|    value_loss           | 0.00114      |
------------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 635         |
|    iterations           | 52          |
|    time_elapsed         | 167         |
|    total_timesteps      | 106496      |
| train/                  |             |
|    approx_kl            | 0.004983401 |
|    clip_fraction        | 0.0383      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.6        |
|    explained_variance   | 0.673       |
|    learning_rate        | 5.05e-05    |
|    loss                 | -0.00725    |
|    n_updates            | 510         |
|    policy_gradient_loss | -0.00365    |
|    std                  | 0.889       |
|    value_loss           | 0.0018      |
-----------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 635          |
|    iterations           | 53           |
|    time_elapsed         | 170          |
|    total_timesteps      | 108544       |
| train/                  |              |
|    approx_kl            | 0.0039420077 |
|    clip_fraction        | 0.0191       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.6         |
|    explained_variance   | 0.719        |
|    learning_rate        | 5.05e-05     |
|    loss                 | -0.00652     |
|    n_updates            | 520          |
|    policy_gradient_loss | -0.0034      |
|    std                  | 0.887        |
|    value_loss           | 0.00193      |
------------------------------------------
Eval num_timesteps=110000, episode_reward=-0.79 +/- 0.41
Episode length: 300.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 300         |
|    mean_reward          | -0.794      |
| time/                   |             |
|    total_timesteps      | 110000      |
| train/                  |             |
|    approx_kl            | 0.004836769 |
|    clip_fraction        | 0.0161      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.6        |
|    explained_variance   | 0.757       |
|    learning_rate        | 5.05e-05    |
|    loss                 | -0.0225     |
|    n_updates            | 530         |
|    policy_gradient_loss | -0.00337    |
|    std                  | 0.885       |
|    value_loss           | 0.000648    |
-----------------------------------------
-------------------------------
| time/              |        |
|    fps             | 633    |
|    iterations      | 54     |
|    time_elapsed    | 174    |
|    total_timesteps | 110592 |
-------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 633          |
|    iterations           | 55           |
|    time_elapsed         | 177          |
|    total_timesteps      | 112640       |
| train/                  |              |
|    approx_kl            | 0.0021388317 |
|    clip_fraction        | 0.00337      |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.59        |
|    explained_variance   | 0.586        |
|    learning_rate        | 5.06e-05     |
|    loss                 | -0.00375     |
|    n_updates            | 540          |
|    policy_gradient_loss | -0.00158     |
|    std                  | 0.884        |
|    value_loss           | 0.00118      |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 634          |
|    iterations           | 56           |
|    time_elapsed         | 180          |
|    total_timesteps      | 114688       |
| train/                  |              |
|    approx_kl            | 0.0050014136 |
|    clip_fraction        | 0.0233       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.59        |
|    explained_variance   | 0.612        |
|    learning_rate        | 5.06e-05     |
|    loss                 | -0.0224      |
|    n_updates            | 550          |
|    policy_gradient_loss | -0.00393     |
|    std                  | 0.879        |
|    value_loss           | 0.00115      |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 634          |
|    iterations           | 57           |
|    time_elapsed         | 183          |
|    total_timesteps      | 116736       |
| train/                  |              |
|    approx_kl            | 0.0035111916 |
|    clip_fraction        | 0.00757      |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.58        |
|    explained_variance   | 0.719        |
|    learning_rate        | 5.06e-05     |
|    loss                 | 0.0116       |
|    n_updates            | 560          |
|    policy_gradient_loss | -0.00233     |
|    std                  | 0.875        |
|    value_loss           | 0.000941     |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 635          |
|    iterations           | 58           |
|    time_elapsed         | 186          |
|    total_timesteps      | 118784       |
| train/                  |              |
|    approx_kl            | 0.0041608834 |
|    clip_fraction        | 0.0148       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.57        |
|    explained_variance   | 0.701        |
|    learning_rate        | 5.06e-05     |
|    loss                 | -0.00617     |
|    n_updates            | 570          |
|    policy_gradient_loss | -0.00235     |
|    std                  | 0.873        |
|    value_loss           | 0.000853     |
------------------------------------------
Eval num_timesteps=120000, episode_reward=-0.75 +/- 0.50
Episode length: 300.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 300         |
|    mean_reward          | -0.748      |
| time/                   |             |
|    total_timesteps      | 120000      |
| train/                  |             |
|    approx_kl            | 0.003366656 |
|    clip_fraction        | 0.022       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.56       |
|    explained_variance   | 0.804       |
|    learning_rate        | 5.06e-05    |
|    loss                 | 0.00735     |
|    n_updates            | 580         |
|    policy_gradient_loss | -0.00217    |
|    std                  | 0.87        |
|    value_loss           | 0.000706    |
-----------------------------------------
New best mean reward!
-------------------------------
| time/              |        |
|    fps             | 632    |
|    iterations      | 59     |
|    time_elapsed    | 190    |
|    total_timesteps | 120832 |
-------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 633          |
|    iterations           | 60           |
|    time_elapsed         | 193          |
|    total_timesteps      | 122880       |
| train/                  |              |
|    approx_kl            | 0.0034419433 |
|    clip_fraction        | 0.0166       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.56        |
|    explained_variance   | 0.781        |
|    learning_rate        | 5.06e-05     |
|    loss                 | 0.0224       |
|    n_updates            | 590          |
|    policy_gradient_loss | -0.00444     |
|    std                  | 0.868        |
|    value_loss           | 0.000524     |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 633          |
|    iterations           | 61           |
|    time_elapsed         | 197          |
|    total_timesteps      | 124928       |
| train/                  |              |
|    approx_kl            | 0.0032181432 |
|    clip_fraction        | 0.00635      |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.55        |
|    explained_variance   | 0.619        |
|    learning_rate        | 5.06e-05     |
|    loss                 | -0.00425     |
|    n_updates            | 600          |
|    policy_gradient_loss | -0.00189     |
|    std                  | 0.867        |
|    value_loss           | 0.00111      |
------------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 634         |
|    iterations           | 62          |
|    time_elapsed         | 200         |
|    total_timesteps      | 126976      |
| train/                  |             |
|    approx_kl            | 0.005077485 |
|    clip_fraction        | 0.0288      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.55       |
|    explained_variance   | 0.884       |
|    learning_rate        | 5.06e-05    |
|    loss                 | -0.00676    |
|    n_updates            | 610         |
|    policy_gradient_loss | -0.0031     |
|    std                  | 0.863       |
|    value_loss           | 0.000369    |
-----------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 634          |
|    iterations           | 63           |
|    time_elapsed         | 203          |
|    total_timesteps      | 129024       |
| train/                  |              |
|    approx_kl            | 0.0025795144 |
|    clip_fraction        | 0.00723      |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.54        |
|    explained_variance   | 0.826        |
|    learning_rate        | 5.06e-05     |
|    loss                 | -0.0109      |
|    n_updates            | 620          |
|    policy_gradient_loss | -0.0013      |
|    std                  | 0.862        |
|    value_loss           | 0.000783     |
------------------------------------------
Eval num_timesteps=130000, episode_reward=-0.87 +/- 0.27
Episode length: 300.00 +/- 0.00
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 300          |
|    mean_reward          | -0.865       |
| time/                   |              |
|    total_timesteps      | 130000       |
| train/                  |              |
|    approx_kl            | 0.0042609973 |
|    clip_fraction        | 0.0231       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.54        |
|    explained_variance   | 0.809        |
|    learning_rate        | 5.06e-05     |
|    loss                 | -0.00139     |
|    n_updates            | 630          |
|    policy_gradient_loss | -0.00402     |
|    std                  | 0.858        |
|    value_loss           | 0.000791     |
------------------------------------------
-------------------------------
| time/              |        |
|    fps             | 632    |
|    iterations      | 64     |
|    time_elapsed    | 207    |
|    total_timesteps | 131072 |
-------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 633          |
|    iterations           | 65           |
|    time_elapsed         | 210          |
|    total_timesteps      | 133120       |
| train/                  |              |
|    approx_kl            | 0.0063342964 |
|    clip_fraction        | 0.0437       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.53        |
|    explained_variance   | 0.829        |
|    learning_rate        | 5.07e-05     |
|    loss                 | -0.0208      |
|    n_updates            | 640          |
|    policy_gradient_loss | -0.00567     |
|    std                  | 0.857        |
|    value_loss           | 0.000879     |
------------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 633        |
|    iterations           | 66         |
|    time_elapsed         | 213        |
|    total_timesteps      | 135168     |
| train/                  |            |
|    approx_kl            | 0.00513407 |
|    clip_fraction        | 0.0344     |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.53      |
|    explained_variance   | 0.843      |
|    learning_rate        | 5.07e-05   |
|    loss                 | -0.0154    |
|    n_updates            | 650        |
|    policy_gradient_loss | -0.00512   |
|    std                  | 0.858      |
|    value_loss           | 0.000521   |
----------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 634          |
|    iterations           | 67           |
|    time_elapsed         | 216          |
|    total_timesteps      | 137216       |
| train/                  |              |
|    approx_kl            | 0.0021962598 |
|    clip_fraction        | 0.00747      |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.53        |
|    explained_variance   | 0.428        |
|    learning_rate        | 5.07e-05     |
|    loss                 | -0.00843     |
|    n_updates            | 660          |
|    policy_gradient_loss | -0.00249     |
|    std                  | 0.853        |
|    value_loss           | 0.00115      |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 634          |
|    iterations           | 68           |
|    time_elapsed         | 219          |
|    total_timesteps      | 139264       |
| train/                  |              |
|    approx_kl            | 0.0046617878 |
|    clip_fraction        | 0.0333       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.52        |
|    explained_variance   | 0.849        |
|    learning_rate        | 5.07e-05     |
|    loss                 | 0.00319      |
|    n_updates            | 670          |
|    policy_gradient_loss | -0.00434     |
|    std                  | 0.852        |
|    value_loss           | 0.000632     |
------------------------------------------
Eval num_timesteps=140000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 300          |
|    mean_reward          | -1           |
| time/                   |              |
|    total_timesteps      | 140000       |
| train/                  |              |
|    approx_kl            | 0.0062378105 |
|    clip_fraction        | 0.0374       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.52        |
|    explained_variance   | 0.364        |
|    learning_rate        | 5.07e-05     |
|    loss                 | -0.0205      |
|    n_updates            | 680          |
|    policy_gradient_loss | -0.00559     |
|    std                  | 0.852        |
|    value_loss           | 0.000612     |
------------------------------------------
-------------------------------
| time/              |        |
|    fps             | 632    |
|    iterations      | 69     |
|    time_elapsed    | 223    |
|    total_timesteps | 141312 |
-------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 633          |
|    iterations           | 70           |
|    time_elapsed         | 226          |
|    total_timesteps      | 143360       |
| train/                  |              |
|    approx_kl            | 0.0038960427 |
|    clip_fraction        | 0.0188       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.51        |
|    explained_variance   | 0.799        |
|    learning_rate        | 5.07e-05     |
|    loss                 | 0.00207      |
|    n_updates            | 690          |
|    policy_gradient_loss | -0.004       |
|    std                  | 0.849        |
|    value_loss           | 0.000853     |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 633          |
|    iterations           | 71           |
|    time_elapsed         | 229          |
|    total_timesteps      | 145408       |
| train/                  |              |
|    approx_kl            | 0.0014110508 |
|    clip_fraction        | 4.88e-05     |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.51        |
|    explained_variance   | 0.68         |
|    learning_rate        | 5.07e-05     |
|    loss                 | 0.000575     |
|    n_updates            | 700          |
|    policy_gradient_loss | -0.00119     |
|    std                  | 0.848        |
|    value_loss           | 0.000995     |
------------------------------------------
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 634          |
|    iterations           | 72           |
|    time_elapsed         | 232          |
|    total_timesteps      | 147456       |
| train/                  |              |
|    approx_kl            | 0.0029802807 |
|    clip_fraction        | 0.00698      |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.51        |
|    explained_variance   | 0.632        |
|    learning_rate        | 5.07e-05     |
|    loss                 | -0.00655     |
|    n_updates            | 710          |
|    policy_gradient_loss | -0.0019      |
|    std                  | 0.846        |
|    value_loss           | 0.00119      |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 634          |
|    iterations           | 73           |
|    time_elapsed         | 235          |
|    total_timesteps      | 149504       |
| train/                  |              |
|    approx_kl            | 0.0040521673 |
|    clip_fraction        | 0.023        |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.5         |
|    explained_variance   | -0.0291      |
|    learning_rate        | 5.07e-05     |
|    loss                 | -0.000975    |
|    n_updates            | 720          |
|    policy_gradient_loss | -0.00475     |
|    std                  | 0.841        |
|    value_loss           | 0.0755       |
------------------------------------------
Eval num_timesteps=150000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 300          |
|    mean_reward          | -1           |
| time/                   |              |
|    total_timesteps      | 150000       |
| train/                  |              |
|    approx_kl            | 0.0037811853 |
|    clip_fraction        | 0.0217       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.49        |
|    explained_variance   | 0.827        |
|    learning_rate        | 5.07e-05     |
|    loss                 | -0.00338     |
|    n_updates            | 730          |
|    policy_gradient_loss | -0.00321     |
|    std                  | 0.837        |
|    value_loss           | 0.00137      |
------------------------------------------
-------------------------------
| time/              |        |
|    fps             | 632    |
|    iterations      | 74     |
|    time_elapsed    | 239    |
|    total_timesteps | 151552 |
-------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 633         |
|    iterations           | 75          |
|    time_elapsed         | 242         |
|    total_timesteps      | 153600      |
| train/                  |             |
|    approx_kl            | 0.003886661 |
|    clip_fraction        | 0.0178      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.48       |
|    explained_variance   | 0.87        |
|    learning_rate        | 5.08e-05    |
|    loss                 | -0.00972    |
|    n_updates            | 740         |
|    policy_gradient_loss | -0.00298    |
|    std                  | 0.836       |
|    value_loss           | 0.000693    |
-----------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 633          |
|    iterations           | 76           |
|    time_elapsed         | 245          |
|    total_timesteps      | 155648       |
| train/                  |              |
|    approx_kl            | 0.0024928746 |
|    clip_fraction        | 0.00586      |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.48        |
|    explained_variance   | 0.842        |
|    learning_rate        | 5.08e-05     |
|    loss                 | 0.00069      |
|    n_updates            | 750          |
|    policy_gradient_loss | -0.0013      |
|    std                  | 0.834        |
|    value_loss           | 0.000739     |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 634          |
|    iterations           | 77           |
|    time_elapsed         | 248          |
|    total_timesteps      | 157696       |
| train/                  |              |
|    approx_kl            | 0.0034686765 |
|    clip_fraction        | 0.0179       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.47        |
|    explained_variance   | 0.728        |
|    learning_rate        | 5.08e-05     |
|    loss                 | 0.0211       |
|    n_updates            | 760          |
|    policy_gradient_loss | -0.00378     |
|    std                  | 0.834        |
|    value_loss           | 0.000934     |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 634          |
|    iterations           | 78           |
|    time_elapsed         | 251          |
|    total_timesteps      | 159744       |
| train/                  |              |
|    approx_kl            | 0.0035760198 |
|    clip_fraction        | 0.0207       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.47        |
|    explained_variance   | 0.882        |
|    learning_rate        | 5.08e-05     |
|    loss                 | 0.00776      |
|    n_updates            | 770          |
|    policy_gradient_loss | -0.00324     |
|    std                  | 0.83         |
|    value_loss           | 0.00119      |
------------------------------------------
Eval num_timesteps=160000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 300          |
|    mean_reward          | -1           |
| time/                   |              |
|    total_timesteps      | 160000       |
| train/                  |              |
|    approx_kl            | 0.0042415517 |
|    clip_fraction        | 0.0105       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.46        |
|    explained_variance   | 0.602        |
|    learning_rate        | 5.08e-05     |
|    loss                 | -0.00265     |
|    n_updates            | 780          |
|    policy_gradient_loss | -0.00223     |
|    std                  | 0.828        |
|    value_loss           | 0.00207      |
------------------------------------------
box reached target
-------------------------------
| time/              |        |
|    fps             | 632    |
|    iterations      | 79     |
|    time_elapsed    | 255    |
|    total_timesteps | 161792 |
-------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 633         |
|    iterations           | 80          |
|    time_elapsed         | 258         |
|    total_timesteps      | 163840      |
| train/                  |             |
|    approx_kl            | 0.003035231 |
|    clip_fraction        | 0.00215     |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.46       |
|    explained_variance   | -0.198      |
|    learning_rate        | 5.08e-05    |
|    loss                 | 0.0911      |
|    n_updates            | 790         |
|    policy_gradient_loss | -0.000106   |
|    std                  | 0.825       |
|    value_loss           | 0.082       |
-----------------------------------------
box reached target
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 633          |
|    iterations           | 81           |
|    time_elapsed         | 261          |
|    total_timesteps      | 165888       |
| train/                  |              |
|    approx_kl            | 0.0042957645 |
|    clip_fraction        | 0.0123       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.45        |
|    explained_variance   | 0.18         |
|    learning_rate        | 5.08e-05     |
|    loss                 | 0.00621      |
|    n_updates            | 800          |
|    policy_gradient_loss | -0.00154     |
|    std                  | 0.822        |
|    value_loss           | 0.0699       |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 633          |
|    iterations           | 82           |
|    time_elapsed         | 264          |
|    total_timesteps      | 167936       |
| train/                  |              |
|    approx_kl            | 0.0012008506 |
|    clip_fraction        | 0.00103      |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.44        |
|    explained_variance   | 0.114        |
|    learning_rate        | 5.08e-05     |
|    loss                 | 0.0312       |
|    n_updates            | 810          |
|    policy_gradient_loss | -0.000463    |
|    std                  | 0.819        |
|    value_loss           | 0.199        |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 634          |
|    iterations           | 83           |
|    time_elapsed         | 267          |
|    total_timesteps      | 169984       |
| train/                  |              |
|    approx_kl            | 0.0022488355 |
|    clip_fraction        | 0.0105       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.44        |
|    explained_variance   | 0.857        |
|    learning_rate        | 5.08e-05     |
|    loss                 | -0.00255     |
|    n_updates            | 820          |
|    policy_gradient_loss | -0.00392     |
|    std                  | 0.82         |
|    value_loss           | 0.00374      |
------------------------------------------
Eval num_timesteps=170000, episode_reward=-0.79 +/- 0.42
Episode length: 300.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 300         |
|    mean_reward          | -0.792      |
| time/                   |             |
|    total_timesteps      | 170000      |
| train/                  |             |
|    approx_kl            | 0.004544434 |
|    clip_fraction        | 0.0187      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.44       |
|    explained_variance   | 0.776       |
|    learning_rate        | 5.08e-05    |
|    loss                 | -0.0031     |
|    n_updates            | 830         |
|    policy_gradient_loss | -0.00267    |
|    std                  | 0.817       |
|    value_loss           | 0.00182     |
-----------------------------------------
-------------------------------
| time/              |        |
|    fps             | 632    |
|    iterations      | 84     |
|    time_elapsed    | 271    |
|    total_timesteps | 172032 |
-------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 633          |
|    iterations           | 85           |
|    time_elapsed         | 274          |
|    total_timesteps      | 174080       |
| train/                  |              |
|    approx_kl            | 0.0069504445 |
|    clip_fraction        | 0.0489       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.43        |
|    explained_variance   | 0.725        |
|    learning_rate        | 5.09e-05     |
|    loss                 | 0.00615      |
|    n_updates            | 840          |
|    policy_gradient_loss | -0.00507     |
|    std                  | 0.818        |
|    value_loss           | 0.00531      |
------------------------------------------
box reached target
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 633          |
|    iterations           | 86           |
|    time_elapsed         | 278          |
|    total_timesteps      | 176128       |
| train/                  |              |
|    approx_kl            | 0.0056230817 |
|    clip_fraction        | 0.05         |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.43        |
|    explained_variance   | 0.866        |
|    learning_rate        | 5.09e-05     |
|    loss                 | -0.0147      |
|    n_updates            | 850          |
|    policy_gradient_loss | -0.00613     |
|    std                  | 0.817        |
|    value_loss           | 0.00244      |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 633          |
|    iterations           | 87           |
|    time_elapsed         | 281          |
|    total_timesteps      | 178176       |
| train/                  |              |
|    approx_kl            | 0.0040856125 |
|    clip_fraction        | 0.00747      |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.43        |
|    explained_variance   | -0.358       |
|    learning_rate        | 5.09e-05     |
|    loss                 | 0.0464       |
|    n_updates            | 860          |
|    policy_gradient_loss | -0.00107     |
|    std                  | 0.812        |
|    value_loss           | 0.172        |
------------------------------------------
box reached target
Eval num_timesteps=180000, episode_reward=0.27 +/- 2.53
Episode length: 277.40 +/- 45.20
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 277         |
|    mean_reward          | 0.267       |
| time/                   |             |
|    total_timesteps      | 180000      |
| train/                  |             |
|    approx_kl            | 0.004107269 |
|    clip_fraction        | 0.0244      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.42       |
|    explained_variance   | 0.904       |
|    learning_rate        | 5.09e-05    |
|    loss                 | 0.00192     |
|    n_updates            | 870         |
|    policy_gradient_loss | -0.00341    |
|    std                  | 0.811       |
|    value_loss           | 0.00132     |
-----------------------------------------
New best mean reward!
-------------------------------
| time/              |        |
|    fps             | 632    |
|    iterations      | 88     |
|    time_elapsed    | 285    |
|    total_timesteps | 180224 |
-------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 632         |
|    iterations           | 89          |
|    time_elapsed         | 288         |
|    total_timesteps      | 182272      |
| train/                  |             |
|    approx_kl            | 0.003164778 |
|    clip_fraction        | 0.0117      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.42       |
|    explained_variance   | 0.857       |
|    learning_rate        | 5.09e-05    |
|    loss                 | -0.00552    |
|    n_updates            | 880         |
|    policy_gradient_loss | -0.00198    |
|    std                  | 0.813       |
|    value_loss           | 0.00168     |
-----------------------------------------
box reached target
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 633         |
|    iterations           | 90          |
|    time_elapsed         | 291         |
|    total_timesteps      | 184320      |
| train/                  |             |
|    approx_kl            | 0.004434442 |
|    clip_fraction        | 0.0244      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.43       |
|    explained_variance   | 0.861       |
|    learning_rate        | 5.09e-05    |
|    loss                 | -0.000827   |
|    n_updates            | 890         |
|    policy_gradient_loss | -0.00436    |
|    std                  | 0.814       |
|    value_loss           | 0.000843    |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 633         |
|    iterations           | 91          |
|    time_elapsed         | 294         |
|    total_timesteps      | 186368      |
| train/                  |             |
|    approx_kl            | 0.002845857 |
|    clip_fraction        | 0.0103      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.42       |
|    explained_variance   | 0.146       |
|    learning_rate        | 5.09e-05    |
|    loss                 | 0.213       |
|    n_updates            | 900         |
|    policy_gradient_loss | -0.00251    |
|    std                  | 0.811       |
|    value_loss           | 0.18        |
-----------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 633          |
|    iterations           | 92           |
|    time_elapsed         | 297          |
|    total_timesteps      | 188416       |
| train/                  |              |
|    approx_kl            | 0.0036825417 |
|    clip_fraction        | 0.0229       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.42        |
|    explained_variance   | 0.916        |
|    learning_rate        | 5.09e-05     |
|    loss                 | -0.0211      |
|    n_updates            | 910          |
|    policy_gradient_loss | -0.00342     |
|    std                  | 0.809        |
|    value_loss           | 0.00247      |
------------------------------------------
Eval num_timesteps=190000, episode_reward=-0.74 +/- 0.52
Episode length: 300.00 +/- 0.00
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 300          |
|    mean_reward          | -0.738       |
| time/                   |              |
|    total_timesteps      | 190000       |
| train/                  |              |
|    approx_kl            | 0.0044649653 |
|    clip_fraction        | 0.0212       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.41        |
|    explained_variance   | 0.894        |
|    learning_rate        | 5.09e-05     |
|    loss                 | -0.0115      |
|    n_updates            | 920          |
|    policy_gradient_loss | -0.00346     |
|    std                  | 0.808        |
|    value_loss           | 0.00178      |
------------------------------------------
-------------------------------
| time/              |        |
|    fps             | 632    |
|    iterations      | 93     |
|    time_elapsed    | 301    |
|    total_timesteps | 190464 |
-------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 632         |
|    iterations           | 94          |
|    time_elapsed         | 304         |
|    total_timesteps      | 192512      |
| train/                  |             |
|    approx_kl            | 0.004545128 |
|    clip_fraction        | 0.0257      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.41       |
|    explained_variance   | 0.836       |
|    learning_rate        | 5.1e-05     |
|    loss                 | 0.00211     |
|    n_updates            | 930         |
|    policy_gradient_loss | -0.00328    |
|    std                  | 0.808       |
|    value_loss           | 0.000887    |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 633         |
|    iterations           | 95          |
|    time_elapsed         | 307         |
|    total_timesteps      | 194560      |
| train/                  |             |
|    approx_kl            | 0.003654011 |
|    clip_fraction        | 0.0159      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.41       |
|    explained_variance   | 0.888       |
|    learning_rate        | 5.1e-05     |
|    loss                 | -0.0181     |
|    n_updates            | 940         |
|    policy_gradient_loss | -0.0015     |
|    std                  | 0.81        |
|    value_loss           | 0.000781    |
-----------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 633          |
|    iterations           | 96           |
|    time_elapsed         | 310          |
|    total_timesteps      | 196608       |
| train/                  |              |
|    approx_kl            | 0.0028050512 |
|    clip_fraction        | 0.012        |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.41        |
|    explained_variance   | 0.878        |
|    learning_rate        | 5.1e-05      |
|    loss                 | -0.00878     |
|    n_updates            | 950          |
|    policy_gradient_loss | -0.0031      |
|    std                  | 0.809        |
|    value_loss           | 0.000977     |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 633          |
|    iterations           | 97           |
|    time_elapsed         | 313          |
|    total_timesteps      | 198656       |
| train/                  |              |
|    approx_kl            | 0.0035960923 |
|    clip_fraction        | 0.0182       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.41        |
|    explained_variance   | 0.811        |
|    learning_rate        | 5.1e-05      |
|    loss                 | -0.0169      |
|    n_updates            | 960          |
|    policy_gradient_loss | -0.0026      |
|    std                  | 0.805        |
|    value_loss           | 0.000769     |
------------------------------------------
box reached target
Eval num_timesteps=200000, episode_reward=0.81 +/- 2.58
Episode length: 290.00 +/- 20.00
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 290          |
|    mean_reward          | 0.809        |
| time/                   |              |
|    total_timesteps      | 200000       |
| train/                  |              |
|    approx_kl            | 0.0032151605 |
|    clip_fraction        | 0.0212       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.4         |
|    explained_variance   | 0.652        |
|    learning_rate        | 5.1e-05      |
|    loss                 | -0.0106      |
|    n_updates            | 970          |
|    policy_gradient_loss | -0.00285     |
|    std                  | 0.803        |
|    value_loss           | 0.000564     |
------------------------------------------
New best mean reward!
-------------------------------
| time/              |        |
|    fps             | 632    |
|    iterations      | 98     |
|    time_elapsed    | 317    |
|    total_timesteps | 200704 |
-------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 99           |
|    time_elapsed         | 320          |
|    total_timesteps      | 202752       |
| train/                  |              |
|    approx_kl            | 0.0047649154 |
|    clip_fraction        | 0.0187       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.4         |
|    explained_variance   | 0.86         |
|    learning_rate        | 5.1e-05      |
|    loss                 | 0.00825      |
|    n_updates            | 980          |
|    policy_gradient_loss | -0.00381     |
|    std                  | 0.8          |
|    value_loss           | 0.00252      |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 633          |
|    iterations           | 100          |
|    time_elapsed         | 323          |
|    total_timesteps      | 204800       |
| train/                  |              |
|    approx_kl            | 0.0039685117 |
|    clip_fraction        | 0.00928      |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.39        |
|    explained_variance   | 0.9          |
|    learning_rate        | 5.1e-05      |
|    loss                 | 0.0014       |
|    n_updates            | 990          |
|    policy_gradient_loss | -0.00172     |
|    std                  | 0.799        |
|    value_loss           | 0.000935     |
------------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 633         |
|    iterations           | 101         |
|    time_elapsed         | 326         |
|    total_timesteps      | 206848      |
| train/                  |             |
|    approx_kl            | 0.004327275 |
|    clip_fraction        | 0.033       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.38       |
|    explained_variance   | 0.88        |
|    learning_rate        | 5.1e-05     |
|    loss                 | 0.00452     |
|    n_updates            | 1000        |
|    policy_gradient_loss | -0.00444    |
|    std                  | 0.795       |
|    value_loss           | 0.000788    |
-----------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 633          |
|    iterations           | 102          |
|    time_elapsed         | 329          |
|    total_timesteps      | 208896       |
| train/                  |              |
|    approx_kl            | 0.0036818585 |
|    clip_fraction        | 0.0102       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.37        |
|    explained_variance   | 0.777        |
|    learning_rate        | 5.1e-05      |
|    loss                 | 0.0233       |
|    n_updates            | 1010         |
|    policy_gradient_loss | -0.00216     |
|    std                  | 0.792        |
|    value_loss           | 0.000802     |
------------------------------------------
box reached target
box reached target
box reached target
Eval num_timesteps=210000, episode_reward=2.80 +/- 3.11
Episode length: 232.00 +/- 56.58
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 232         |
|    mean_reward          | 2.8         |
| time/                   |             |
|    total_timesteps      | 210000      |
| train/                  |             |
|    approx_kl            | 0.004078707 |
|    clip_fraction        | 0.0182      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.37       |
|    explained_variance   | 0.905       |
|    learning_rate        | 5.1e-05     |
|    loss                 | 0.00887     |
|    n_updates            | 1020        |
|    policy_gradient_loss | -0.00419    |
|    std                  | 0.791       |
|    value_loss           | 0.000925    |
-----------------------------------------
New best mean reward!
box reached target
-------------------------------
| time/              |        |
|    fps             | 632    |
|    iterations      | 103    |
|    time_elapsed    | 333    |
|    total_timesteps | 210944 |
-------------------------------
box reached target
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 633          |
|    iterations           | 104          |
|    time_elapsed         | 336          |
|    total_timesteps      | 212992       |
| train/                  |              |
|    approx_kl            | 0.0046159877 |
|    clip_fraction        | 0.0283       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.37        |
|    explained_variance   | 0.372        |
|    learning_rate        | 5.11e-05     |
|    loss                 | 0.0145       |
|    n_updates            | 1030         |
|    policy_gradient_loss | -0.00263     |
|    std                  | 0.788        |
|    value_loss           | 0.0577       |
------------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 633         |
|    iterations           | 105         |
|    time_elapsed         | 339         |
|    total_timesteps      | 215040      |
| train/                  |             |
|    approx_kl            | 0.004365115 |
|    clip_fraction        | 0.0102      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.36       |
|    explained_variance   | 0.699       |
|    learning_rate        | 5.11e-05    |
|    loss                 | 0.0209      |
|    n_updates            | 1040        |
|    policy_gradient_loss | -0.00184    |
|    std                  | 0.787       |
|    value_loss           | 0.0752      |
-----------------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 633         |
|    iterations           | 106         |
|    time_elapsed         | 342         |
|    total_timesteps      | 217088      |
| train/                  |             |
|    approx_kl            | 0.005234445 |
|    clip_fraction        | 0.0333      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.36       |
|    explained_variance   | 0.761       |
|    learning_rate        | 5.11e-05    |
|    loss                 | -0.0223     |
|    n_updates            | 1050        |
|    policy_gradient_loss | -0.00611    |
|    std                  | 0.787       |
|    value_loss           | 0.00251     |
-----------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 634          |
|    iterations           | 107          |
|    time_elapsed         | 345          |
|    total_timesteps      | 219136       |
| train/                  |              |
|    approx_kl            | 0.0016344802 |
|    clip_fraction        | 0.00405      |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.36        |
|    explained_variance   | -0.552       |
|    learning_rate        | 5.11e-05     |
|    loss                 | -0.000113    |
|    n_updates            | 1060         |
|    policy_gradient_loss | -0.0012      |
|    std                  | 0.787        |
|    value_loss           | 0.1          |
------------------------------------------
box reached target
Eval num_timesteps=220000, episode_reward=-0.74 +/- 0.52
Episode length: 300.00 +/- 0.00
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 300          |
|    mean_reward          | -0.742       |
| time/                   |              |
|    total_timesteps      | 220000       |
| train/                  |              |
|    approx_kl            | 0.0043066023 |
|    clip_fraction        | 0.00903      |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.36        |
|    explained_variance   | 0.905        |
|    learning_rate        | 5.11e-05     |
|    loss                 | -0.00954     |
|    n_updates            | 1070         |
|    policy_gradient_loss | -0.00281     |
|    std                  | 0.786        |
|    value_loss           | 0.00172      |
------------------------------------------
-------------------------------
| time/              |        |
|    fps             | 632    |
|    iterations      | 108    |
|    time_elapsed    | 349    |
|    total_timesteps | 221184 |
-------------------------------
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 633          |
|    iterations           | 109          |
|    time_elapsed         | 352          |
|    total_timesteps      | 223232       |
| train/                  |              |
|    approx_kl            | 0.0032018474 |
|    clip_fraction        | 0.0101       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.35        |
|    explained_variance   | 0.24         |
|    learning_rate        | 5.11e-05     |
|    loss                 | 0.068        |
|    n_updates            | 1080         |
|    policy_gradient_loss | -0.00128     |
|    std                  | 0.783        |
|    value_loss           | 0.0677       |
------------------------------------------
box reached target
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 633         |
|    iterations           | 110         |
|    time_elapsed         | 355         |
|    total_timesteps      | 225280      |
| train/                  |             |
|    approx_kl            | 0.004259903 |
|    clip_fraction        | 0.0152      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.34       |
|    explained_variance   | 0.428       |
|    learning_rate        | 5.11e-05    |
|    loss                 | -0.00685    |
|    n_updates            | 1090        |
|    policy_gradient_loss | -0.00206    |
|    std                  | 0.778       |
|    value_loss           | 0.0574      |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 633         |
|    iterations           | 111         |
|    time_elapsed         | 358         |
|    total_timesteps      | 227328      |
| train/                  |             |
|    approx_kl            | 0.004578501 |
|    clip_fraction        | 0.0143      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.33       |
|    explained_variance   | 0.799       |
|    learning_rate        | 5.11e-05    |
|    loss                 | 0.00278     |
|    n_updates            | 1100        |
|    policy_gradient_loss | -0.00383    |
|    std                  | 0.775       |
|    value_loss           | 0.0684      |
-----------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 633          |
|    iterations           | 112          |
|    time_elapsed         | 361          |
|    total_timesteps      | 229376       |
| train/                  |              |
|    approx_kl            | 0.0029692147 |
|    clip_fraction        | 0.0158       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.33        |
|    explained_variance   | 0.916        |
|    learning_rate        | 5.11e-05     |
|    loss                 | -0.0117      |
|    n_updates            | 1110         |
|    policy_gradient_loss | -0.00236     |
|    std                  | 0.777        |
|    value_loss           | 0.0104       |
------------------------------------------
Eval num_timesteps=230000, episode_reward=-0.57 +/- 0.73
Episode length: 300.00 +/- 0.00
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 300          |
|    mean_reward          | -0.572       |
| time/                   |              |
|    total_timesteps      | 230000       |
| train/                  |              |
|    approx_kl            | 0.0063746283 |
|    clip_fraction        | 0.0621       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.33        |
|    explained_variance   | 0.891        |
|    learning_rate        | 5.11e-05     |
|    loss                 | -0.00273     |
|    n_updates            | 1120         |
|    policy_gradient_loss | -0.00641     |
|    std                  | 0.777        |
|    value_loss           | 0.00698      |
------------------------------------------
-------------------------------
| time/              |        |
|    fps             | 632    |
|    iterations      | 113    |
|    time_elapsed    | 365    |
|    total_timesteps | 231424 |
-------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 114          |
|    time_elapsed         | 368          |
|    total_timesteps      | 233472       |
| train/                  |              |
|    approx_kl            | 0.0043552136 |
|    clip_fraction        | 0.0323       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.33        |
|    explained_variance   | 0.864        |
|    learning_rate        | 5.12e-05     |
|    loss                 | -0.00838     |
|    n_updates            | 1130         |
|    policy_gradient_loss | -0.00341     |
|    std                  | 0.775        |
|    value_loss           | 0.00466      |
------------------------------------------
box reached target
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 633          |
|    iterations           | 115          |
|    time_elapsed         | 371          |
|    total_timesteps      | 235520       |
| train/                  |              |
|    approx_kl            | 0.0034055952 |
|    clip_fraction        | 0.0123       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.33        |
|    explained_variance   | 0.942        |
|    learning_rate        | 5.12e-05     |
|    loss                 | -0.00164     |
|    n_updates            | 1140         |
|    policy_gradient_loss | -0.0018      |
|    std                  | 0.775        |
|    value_loss           | 0.00436      |
------------------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 633         |
|    iterations           | 116         |
|    time_elapsed         | 374         |
|    total_timesteps      | 237568      |
| train/                  |             |
|    approx_kl            | 0.002045396 |
|    clip_fraction        | 0.000977    |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.32       |
|    explained_variance   | 0.305       |
|    learning_rate        | 5.12e-05    |
|    loss                 | 0.219       |
|    n_updates            | 1150        |
|    policy_gradient_loss | -0.000839   |
|    std                  | 0.773       |
|    value_loss           | 0.129       |
-----------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 633          |
|    iterations           | 117          |
|    time_elapsed         | 378          |
|    total_timesteps      | 239616       |
| train/                  |              |
|    approx_kl            | 0.0064949496 |
|    clip_fraction        | 0.0435       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.32        |
|    explained_variance   | 0.574        |
|    learning_rate        | 5.12e-05     |
|    loss                 | -0.00887     |
|    n_updates            | 1160         |
|    policy_gradient_loss | -0.00384     |
|    std                  | 0.772        |
|    value_loss           | 0.0609       |
------------------------------------------
box reached target
Eval num_timesteps=240000, episode_reward=0.55 +/- 2.55
Episode length: 291.00 +/- 18.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 291        |
|    mean_reward          | 0.551      |
| time/                   |            |
|    total_timesteps      | 240000     |
| train/                  |            |
|    approx_kl            | 0.00308755 |
|    clip_fraction        | 0.0216     |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.32      |
|    explained_variance   | 0.899      |
|    learning_rate        | 5.12e-05   |
|    loss                 | 0.00644    |
|    n_updates            | 1170       |
|    policy_gradient_loss | -0.00299   |
|    std                  | 0.774      |
|    value_loss           | 0.00466    |
----------------------------------------
-------------------------------
| time/              |        |
|    fps             | 632    |
|    iterations      | 118    |
|    time_elapsed    | 382    |
|    total_timesteps | 241664 |
-------------------------------
box reached target
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 119          |
|    time_elapsed         | 385          |
|    total_timesteps      | 243712       |
| train/                  |              |
|    approx_kl            | 0.0037670166 |
|    clip_fraction        | 0.0222       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.32        |
|    explained_variance   | 0.898        |
|    learning_rate        | 5.12e-05     |
|    loss                 | 0.000445     |
|    n_updates            | 1180         |
|    policy_gradient_loss | -0.00359     |
|    std                  | 0.773        |
|    value_loss           | 0.00145      |
------------------------------------------
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 633          |
|    iterations           | 120          |
|    time_elapsed         | 388          |
|    total_timesteps      | 245760       |
| train/                  |              |
|    approx_kl            | 0.0028587386 |
|    clip_fraction        | 0.011        |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.32        |
|    explained_variance   | 0.692        |
|    learning_rate        | 5.12e-05     |
|    loss                 | 0.0321       |
|    n_updates            | 1190         |
|    policy_gradient_loss | -0.00172     |
|    std                  | 0.771        |
|    value_loss           | 0.0876       |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 633          |
|    iterations           | 121          |
|    time_elapsed         | 391          |
|    total_timesteps      | 247808       |
| train/                  |              |
|    approx_kl            | 0.0021924267 |
|    clip_fraction        | 0.0101       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.31        |
|    explained_variance   | 0.383        |
|    learning_rate        | 5.12e-05     |
|    loss                 | -0.00591     |
|    n_updates            | 1200         |
|    policy_gradient_loss | -0.00287     |
|    std                  | 0.767        |
|    value_loss           | 0.068        |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 633          |
|    iterations           | 122          |
|    time_elapsed         | 394          |
|    total_timesteps      | 249856       |
| train/                  |              |
|    approx_kl            | 0.0035575414 |
|    clip_fraction        | 0.0249       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.3         |
|    explained_variance   | 0.903        |
|    learning_rate        | 5.12e-05     |
|    loss                 | 0.00419      |
|    n_updates            | 1210         |
|    policy_gradient_loss | -0.00612     |
|    std                  | 0.765        |
|    value_loss           | 0.00337      |
------------------------------------------
box reached target
Eval num_timesteps=250000, episode_reward=0.44 +/- 2.44
Episode length: 278.00 +/- 44.00
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 278          |
|    mean_reward          | 0.442        |
| time/                   |              |
|    total_timesteps      | 250000       |
| train/                  |              |
|    approx_kl            | 0.0031014243 |
|    clip_fraction        | 0.0187       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.3         |
|    explained_variance   | 0.85         |
|    learning_rate        | 5.12e-05     |
|    loss                 | 0.00709      |
|    n_updates            | 1220         |
|    policy_gradient_loss | -0.0041      |
|    std                  | 0.766        |
|    value_loss           | 0.00085      |
------------------------------------------
-------------------------------
| time/              |        |
|    fps             | 632    |
|    iterations      | 123    |
|    time_elapsed    | 398    |
|    total_timesteps | 251904 |
-------------------------------
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 124          |
|    time_elapsed         | 401          |
|    total_timesteps      | 253952       |
| train/                  |              |
|    approx_kl            | 0.0036680803 |
|    clip_fraction        | 0.015        |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.3         |
|    explained_variance   | 0.924        |
|    learning_rate        | 5.13e-05     |
|    loss                 | -0.00339     |
|    n_updates            | 1230         |
|    policy_gradient_loss | -0.00202     |
|    std                  | 0.766        |
|    value_loss           | 0.00341      |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 633          |
|    iterations           | 125          |
|    time_elapsed         | 404          |
|    total_timesteps      | 256000       |
| train/                  |              |
|    approx_kl            | 0.0011445238 |
|    clip_fraction        | 0.00396      |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.3         |
|    explained_variance   | 0.695        |
|    learning_rate        | 5.13e-05     |
|    loss                 | 0.00779      |
|    n_updates            | 1240         |
|    policy_gradient_loss | -0.0024      |
|    std                  | 0.763        |
|    value_loss           | 0.0412       |
------------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 633         |
|    iterations           | 126         |
|    time_elapsed         | 407         |
|    total_timesteps      | 258048      |
| train/                  |             |
|    approx_kl            | 0.003971504 |
|    clip_fraction        | 0.0195      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.29       |
|    explained_variance   | 0.857       |
|    learning_rate        | 5.13e-05    |
|    loss                 | -0.00679    |
|    n_updates            | 1250        |
|    policy_gradient_loss | -0.00208    |
|    std                  | 0.76        |
|    value_loss           | 0.00456     |
-----------------------------------------
box reached target
box reached target
box reached target
Eval num_timesteps=260000, episode_reward=0.29 +/- 2.58
Episode length: 282.80 +/- 34.40
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 283          |
|    mean_reward          | 0.291        |
| time/                   |              |
|    total_timesteps      | 260000       |
| train/                  |              |
|    approx_kl            | 0.0041864114 |
|    clip_fraction        | 0.0237       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.29        |
|    explained_variance   | 0.829        |
|    learning_rate        | 5.13e-05     |
|    loss                 | -2.88e-06    |
|    n_updates            | 1260         |
|    policy_gradient_loss | -0.00223     |
|    std                  | 0.759        |
|    value_loss           | 0.00286      |
------------------------------------------
-------------------------------
| time/              |        |
|    fps             | 632    |
|    iterations      | 127    |
|    time_elapsed    | 411    |
|    total_timesteps | 260096 |
-------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 632         |
|    iterations           | 128         |
|    time_elapsed         | 414         |
|    total_timesteps      | 262144      |
| train/                  |             |
|    approx_kl            | 0.003503711 |
|    clip_fraction        | 0.00576     |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.28       |
|    explained_variance   | 0.832       |
|    learning_rate        | 5.13e-05    |
|    loss                 | -0.00518    |
|    n_updates            | 1270        |
|    policy_gradient_loss | -0.00171    |
|    std                  | 0.755       |
|    value_loss           | 0.0566      |
-----------------------------------------
box reached target
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 129          |
|    time_elapsed         | 417          |
|    total_timesteps      | 264192       |
| train/                  |              |
|    approx_kl            | 0.0029565748 |
|    clip_fraction        | 0.00562      |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.27        |
|    explained_variance   | 0.935        |
|    learning_rate        | 5.13e-05     |
|    loss                 | -0.00181     |
|    n_updates            | 1280         |
|    policy_gradient_loss | -0.00167     |
|    std                  | 0.752        |
|    value_loss           | 0.0218       |
------------------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 633         |
|    iterations           | 130         |
|    time_elapsed         | 420         |
|    total_timesteps      | 266240      |
| train/                  |             |
|    approx_kl            | 0.007970789 |
|    clip_fraction        | 0.0602      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.26       |
|    explained_variance   | 0.351       |
|    learning_rate        | 5.13e-05    |
|    loss                 | 0.0225      |
|    n_updates            | 1290        |
|    policy_gradient_loss | -0.00489    |
|    std                  | 0.75        |
|    value_loss           | 0.131       |
-----------------------------------------
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 633          |
|    iterations           | 131          |
|    time_elapsed         | 423          |
|    total_timesteps      | 268288       |
| train/                  |              |
|    approx_kl            | 0.0020147879 |
|    clip_fraction        | 0.00918      |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.26        |
|    explained_variance   | 0.166        |
|    learning_rate        | 5.13e-05     |
|    loss                 | 0.00616      |
|    n_updates            | 1300         |
|    policy_gradient_loss | -0.00351     |
|    std                  | 0.745        |
|    value_loss           | 0.0683       |
------------------------------------------
box reached target
Eval num_timesteps=270000, episode_reward=0.44 +/- 2.49
Episode length: 284.80 +/- 30.40
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 285          |
|    mean_reward          | 0.436        |
| time/                   |              |
|    total_timesteps      | 270000       |
| train/                  |              |
|    approx_kl            | 0.0041432283 |
|    clip_fraction        | 0.025        |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.25        |
|    explained_variance   | 0.836        |
|    learning_rate        | 5.13e-05     |
|    loss                 | 0.0416       |
|    n_updates            | 1310         |
|    policy_gradient_loss | -0.00288     |
|    std                  | 0.743        |
|    value_loss           | 0.0267       |
------------------------------------------
box reached target
-------------------------------
| time/              |        |
|    fps             | 632    |
|    iterations      | 132    |
|    time_elapsed    | 427    |
|    total_timesteps | 270336 |
-------------------------------
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 133          |
|    time_elapsed         | 430          |
|    total_timesteps      | 272384       |
| train/                  |              |
|    approx_kl            | 0.0008019004 |
|    clip_fraction        | 0.000488     |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.25        |
|    explained_variance   | 0.531        |
|    learning_rate        | 5.14e-05     |
|    loss                 | -0.0129      |
|    n_updates            | 1320         |
|    policy_gradient_loss | -0.000717    |
|    std                  | 0.744        |
|    value_loss           | 0.0664       |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 134          |
|    time_elapsed         | 433          |
|    total_timesteps      | 274432       |
| train/                  |              |
|    approx_kl            | 0.0019715335 |
|    clip_fraction        | 0.00488      |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.24        |
|    explained_variance   | 0.842        |
|    learning_rate        | 5.14e-05     |
|    loss                 | 0.0618       |
|    n_updates            | 1330         |
|    policy_gradient_loss | -0.00253     |
|    std                  | 0.742        |
|    value_loss           | 0.0279       |
------------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 633        |
|    iterations           | 135        |
|    time_elapsed         | 436        |
|    total_timesteps      | 276480     |
| train/                  |            |
|    approx_kl            | 0.00490544 |
|    clip_fraction        | 0.0389     |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.23      |
|    explained_variance   | 0.85       |
|    learning_rate        | 5.14e-05   |
|    loss                 | -0.0366    |
|    n_updates            | 1340       |
|    policy_gradient_loss | -0.00467   |
|    std                  | 0.738      |
|    value_loss           | 0.00173    |
----------------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 633         |
|    iterations           | 136         |
|    time_elapsed         | 439         |
|    total_timesteps      | 278528      |
| train/                  |             |
|    approx_kl            | 0.004355051 |
|    clip_fraction        | 0.0349      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.23       |
|    explained_variance   | 0.863       |
|    learning_rate        | 5.14e-05    |
|    loss                 | -0.00196    |
|    n_updates            | 1350        |
|    policy_gradient_loss | -0.00519    |
|    std                  | 0.736       |
|    value_loss           | 0.00248     |
-----------------------------------------
Eval num_timesteps=280000, episode_reward=-0.97 +/- 0.06
Episode length: 300.00 +/- 0.00
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 300          |
|    mean_reward          | -0.968       |
| time/                   |              |
|    total_timesteps      | 280000       |
| train/                  |              |
|    approx_kl            | 0.0022535033 |
|    clip_fraction        | 0.0121       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.22        |
|    explained_variance   | 0.7          |
|    learning_rate        | 5.14e-05     |
|    loss                 | 0.00859      |
|    n_updates            | 1360         |
|    policy_gradient_loss | -0.00277     |
|    std                  | 0.734        |
|    value_loss           | 0.04         |
------------------------------------------
-------------------------------
| time/              |        |
|    fps             | 632    |
|    iterations      | 137    |
|    time_elapsed    | 443    |
|    total_timesteps | 280576 |
-------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 138          |
|    time_elapsed         | 446          |
|    total_timesteps      | 282624       |
| train/                  |              |
|    approx_kl            | 0.0044586477 |
|    clip_fraction        | 0.0189       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.22        |
|    explained_variance   | 0.846        |
|    learning_rate        | 5.14e-05     |
|    loss                 | 0.008        |
|    n_updates            | 1370         |
|    policy_gradient_loss | -0.00119     |
|    std                  | 0.734        |
|    value_loss           | 0.0134       |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 139          |
|    time_elapsed         | 449          |
|    total_timesteps      | 284672       |
| train/                  |              |
|    approx_kl            | 0.0030334326 |
|    clip_fraction        | 0.0134       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.22        |
|    explained_variance   | 0.901        |
|    learning_rate        | 5.14e-05     |
|    loss                 | 0.0133       |
|    n_updates            | 1380         |
|    policy_gradient_loss | -0.0032      |
|    std                  | 0.734        |
|    value_loss           | 0.00211      |
------------------------------------------
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 633          |
|    iterations           | 140          |
|    time_elapsed         | 452          |
|    total_timesteps      | 286720       |
| train/                  |              |
|    approx_kl            | 0.0038648038 |
|    clip_fraction        | 0.0261       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.22        |
|    explained_variance   | 0.917        |
|    learning_rate        | 5.14e-05     |
|    loss                 | -0.00488     |
|    n_updates            | 1390         |
|    policy_gradient_loss | -0.00441     |
|    std                  | 0.733        |
|    value_loss           | 0.00148      |
------------------------------------------
box reached target
box reached target
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 633          |
|    iterations           | 141          |
|    time_elapsed         | 455          |
|    total_timesteps      | 288768       |
| train/                  |              |
|    approx_kl            | 0.0037669449 |
|    clip_fraction        | 0.0128       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.21        |
|    explained_variance   | 0.72         |
|    learning_rate        | 5.14e-05     |
|    loss                 | 0.0223       |
|    n_updates            | 1400         |
|    policy_gradient_loss | -0.000882    |
|    std                  | 0.731        |
|    value_loss           | 0.0581       |
------------------------------------------
Eval num_timesteps=290000, episode_reward=-0.50 +/- 0.62
Episode length: 300.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 300         |
|    mean_reward          | -0.496      |
| time/                   |             |
|    total_timesteps      | 290000      |
| train/                  |             |
|    approx_kl            | 0.003000706 |
|    clip_fraction        | 0.00781     |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.21       |
|    explained_variance   | 0.719       |
|    learning_rate        | 5.14e-05    |
|    loss                 | 0.0173      |
|    n_updates            | 1410        |
|    policy_gradient_loss | -0.00135    |
|    std                  | 0.729       |
|    value_loss           | 0.0998      |
-----------------------------------------
-------------------------------
| time/              |        |
|    fps             | 632    |
|    iterations      | 142    |
|    time_elapsed    | 459    |
|    total_timesteps | 290816 |
-------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 143          |
|    time_elapsed         | 462          |
|    total_timesteps      | 292864       |
| train/                  |              |
|    approx_kl            | 0.0042716786 |
|    clip_fraction        | 0.0242       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.2         |
|    explained_variance   | 0.918        |
|    learning_rate        | 5.15e-05     |
|    loss                 | -0.00249     |
|    n_updates            | 1420         |
|    policy_gradient_loss | -0.00315     |
|    std                  | 0.729        |
|    value_loss           | 0.00742      |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 144          |
|    time_elapsed         | 466          |
|    total_timesteps      | 294912       |
| train/                  |              |
|    approx_kl            | 0.0042346185 |
|    clip_fraction        | 0.0338       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.21        |
|    explained_variance   | 0.925        |
|    learning_rate        | 5.15e-05     |
|    loss                 | 0.0156       |
|    n_updates            | 1430         |
|    policy_gradient_loss | -0.00514     |
|    std                  | 0.73         |
|    value_loss           | 0.00622      |
------------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 633         |
|    iterations           | 145         |
|    time_elapsed         | 469         |
|    total_timesteps      | 296960      |
| train/                  |             |
|    approx_kl            | 0.006326315 |
|    clip_fraction        | 0.0529      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.21       |
|    explained_variance   | 0.957       |
|    learning_rate        | 5.15e-05    |
|    loss                 | 0.0289      |
|    n_updates            | 1440        |
|    policy_gradient_loss | -0.00611    |
|    std                  | 0.729       |
|    value_loss           | 0.00104     |
-----------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 633          |
|    iterations           | 146          |
|    time_elapsed         | 472          |
|    total_timesteps      | 299008       |
| train/                  |              |
|    approx_kl            | 0.0022892165 |
|    clip_fraction        | 0.0103       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.21        |
|    explained_variance   | 0.915        |
|    learning_rate        | 5.15e-05     |
|    loss                 | -0.0108      |
|    n_updates            | 1450         |
|    policy_gradient_loss | -0.0038      |
|    std                  | 0.729        |
|    value_loss           | 0.00464      |
------------------------------------------
Eval num_timesteps=300000, episode_reward=-0.56 +/- 0.44
Episode length: 300.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 300         |
|    mean_reward          | -0.558      |
| time/                   |             |
|    total_timesteps      | 300000      |
| train/                  |             |
|    approx_kl            | 0.004470013 |
|    clip_fraction        | 0.0424      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.2        |
|    explained_variance   | 0.837       |
|    learning_rate        | 5.15e-05    |
|    loss                 | 0.00853     |
|    n_updates            | 1460        |
|    policy_gradient_loss | -0.00619    |
|    std                  | 0.729       |
|    value_loss           | 0.000914    |
-----------------------------------------
box reached target
-------------------------------
| time/              |        |
|    fps             | 632    |
|    iterations      | 147    |
|    time_elapsed    | 476    |
|    total_timesteps | 301056 |
-------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 632         |
|    iterations           | 148         |
|    time_elapsed         | 479         |
|    total_timesteps      | 303104      |
| train/                  |             |
|    approx_kl            | 0.004848746 |
|    clip_fraction        | 0.0188      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.2        |
|    explained_variance   | 0.844       |
|    learning_rate        | 5.15e-05    |
|    loss                 | -0.012      |
|    n_updates            | 1470        |
|    policy_gradient_loss | -0.00393    |
|    std                  | 0.727       |
|    value_loss           | 0.0289      |
-----------------------------------------
box reached target
box reached target
box reached target
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 632         |
|    iterations           | 149         |
|    time_elapsed         | 482         |
|    total_timesteps      | 305152      |
| train/                  |             |
|    approx_kl            | 0.004838067 |
|    clip_fraction        | 0.0223      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.2        |
|    explained_variance   | 0.876       |
|    learning_rate        | 5.15e-05    |
|    loss                 | 0.00864     |
|    n_updates            | 1480        |
|    policy_gradient_loss | -0.00418    |
|    std                  | 0.726       |
|    value_loss           | 0.00424     |
-----------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 633          |
|    iterations           | 150          |
|    time_elapsed         | 485          |
|    total_timesteps      | 307200       |
| train/                  |              |
|    approx_kl            | 0.0036156154 |
|    clip_fraction        | 0.0287       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.19        |
|    explained_variance   | 0.703        |
|    learning_rate        | 5.15e-05     |
|    loss                 | 0.017        |
|    n_updates            | 1490         |
|    policy_gradient_loss | -0.00298     |
|    std                  | 0.724        |
|    value_loss           | 0.152        |
------------------------------------------
box reached target
box reached target
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 633         |
|    iterations           | 151         |
|    time_elapsed         | 488         |
|    total_timesteps      | 309248      |
| train/                  |             |
|    approx_kl            | 0.002683627 |
|    clip_fraction        | 0.00996     |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.19       |
|    explained_variance   | 0.892       |
|    learning_rate        | 5.15e-05    |
|    loss                 | 0.00795     |
|    n_updates            | 1500        |
|    policy_gradient_loss | -0.00179    |
|    std                  | 0.721       |
|    value_loss           | 0.012       |
-----------------------------------------
Eval num_timesteps=310000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 300         |
|    mean_reward          | -1          |
| time/                   |             |
|    total_timesteps      | 310000      |
| train/                  |             |
|    approx_kl            | 0.003325109 |
|    clip_fraction        | 0.00972     |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.18       |
|    explained_variance   | 0.752       |
|    learning_rate        | 5.15e-05    |
|    loss                 | 0.0906      |
|    n_updates            | 1510        |
|    policy_gradient_loss | -0.00229    |
|    std                  | 0.72        |
|    value_loss           | 0.0945      |
-----------------------------------------
-------------------------------
| time/              |        |
|    fps             | 632    |
|    iterations      | 152    |
|    time_elapsed    | 492    |
|    total_timesteps | 311296 |
-------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 153          |
|    time_elapsed         | 495          |
|    total_timesteps      | 313344       |
| train/                  |              |
|    approx_kl            | 0.0050724996 |
|    clip_fraction        | 0.0323       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.18        |
|    explained_variance   | 0.905        |
|    learning_rate        | 5.16e-05     |
|    loss                 | 0.000598     |
|    n_updates            | 1520         |
|    policy_gradient_loss | -0.00489     |
|    std                  | 0.72         |
|    value_loss           | 0.00492      |
------------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 632         |
|    iterations           | 154         |
|    time_elapsed         | 498         |
|    total_timesteps      | 315392      |
| train/                  |             |
|    approx_kl            | 0.003498561 |
|    clip_fraction        | 0.0145      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.18       |
|    explained_variance   | 0.872       |
|    learning_rate        | 5.16e-05    |
|    loss                 | -0.00247    |
|    n_updates            | 1530        |
|    policy_gradient_loss | -0.00224    |
|    std                  | 0.722       |
|    value_loss           | 0.00956     |
-----------------------------------------
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 633          |
|    iterations           | 155          |
|    time_elapsed         | 501          |
|    total_timesteps      | 317440       |
| train/                  |              |
|    approx_kl            | 0.0025187177 |
|    clip_fraction        | 0.0116       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.19        |
|    explained_variance   | 0.827        |
|    learning_rate        | 5.16e-05     |
|    loss                 | -0.00263     |
|    n_updates            | 1540         |
|    policy_gradient_loss | -0.00173     |
|    std                  | 0.723        |
|    value_loss           | 0.00895      |
------------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 633         |
|    iterations           | 156         |
|    time_elapsed         | 504         |
|    total_timesteps      | 319488      |
| train/                  |             |
|    approx_kl            | 0.003289878 |
|    clip_fraction        | 0.0218      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.19       |
|    explained_variance   | 0.812       |
|    learning_rate        | 5.16e-05    |
|    loss                 | 0.00201     |
|    n_updates            | 1550        |
|    policy_gradient_loss | -0.00217    |
|    std                  | 0.721       |
|    value_loss           | 0.033       |
-----------------------------------------
box reached target
Eval num_timesteps=320000, episode_reward=0.26 +/- 2.53
Episode length: 280.60 +/- 38.80
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 281          |
|    mean_reward          | 0.264        |
| time/                   |              |
|    total_timesteps      | 320000       |
| train/                  |              |
|    approx_kl            | 0.0078864815 |
|    clip_fraction        | 0.0742       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.18        |
|    explained_variance   | 0.897        |
|    learning_rate        | 5.16e-05     |
|    loss                 | 0.00186      |
|    n_updates            | 1560         |
|    policy_gradient_loss | -0.00732     |
|    std                  | 0.719        |
|    value_loss           | 0.00172      |
------------------------------------------
-------------------------------
| time/              |        |
|    fps             | 632    |
|    iterations      | 157    |
|    time_elapsed    | 508    |
|    total_timesteps | 321536 |
-------------------------------
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 158          |
|    time_elapsed         | 511          |
|    total_timesteps      | 323584       |
| train/                  |              |
|    approx_kl            | 0.0031428244 |
|    clip_fraction        | 0.00967      |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.18        |
|    explained_variance   | 0.799        |
|    learning_rate        | 5.16e-05     |
|    loss                 | 0.00154      |
|    n_updates            | 1570         |
|    policy_gradient_loss | -0.00152     |
|    std                  | 0.723        |
|    value_loss           | 0.0125       |
------------------------------------------
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 159          |
|    time_elapsed         | 514          |
|    total_timesteps      | 325632       |
| train/                  |              |
|    approx_kl            | 0.0034950213 |
|    clip_fraction        | 0.0222       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.18        |
|    explained_variance   | 0.821        |
|    learning_rate        | 5.16e-05     |
|    loss                 | -0.0204      |
|    n_updates            | 1580         |
|    policy_gradient_loss | -0.00364     |
|    std                  | 0.719        |
|    value_loss           | 0.0305       |
------------------------------------------
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 633          |
|    iterations           | 160          |
|    time_elapsed         | 517          |
|    total_timesteps      | 327680       |
| train/                  |              |
|    approx_kl            | 0.0051024156 |
|    clip_fraction        | 0.0357       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.17        |
|    explained_variance   | 0.783        |
|    learning_rate        | 5.16e-05     |
|    loss                 | -0.00915     |
|    n_updates            | 1590         |
|    policy_gradient_loss | -0.00301     |
|    std                  | 0.717        |
|    value_loss           | 0.0275       |
------------------------------------------
box reached target
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 633         |
|    iterations           | 161         |
|    time_elapsed         | 520         |
|    total_timesteps      | 329728      |
| train/                  |             |
|    approx_kl            | 0.004605042 |
|    clip_fraction        | 0.0148      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.17       |
|    explained_variance   | 0.664       |
|    learning_rate        | 5.16e-05    |
|    loss                 | -0.0132     |
|    n_updates            | 1600        |
|    policy_gradient_loss | -0.00325    |
|    std                  | 0.715       |
|    value_loss           | 0.0388      |
-----------------------------------------
box reached target
Eval num_timesteps=330000, episode_reward=0.28 +/- 2.55
Episode length: 271.20 +/- 57.60
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 271         |
|    mean_reward          | 0.276       |
| time/                   |             |
|    total_timesteps      | 330000      |
| train/                  |             |
|    approx_kl            | 0.002677394 |
|    clip_fraction        | 0.0165      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.16       |
|    explained_variance   | 0.588       |
|    learning_rate        | 5.16e-05    |
|    loss                 | 0.071       |
|    n_updates            | 1610        |
|    policy_gradient_loss | -0.00359    |
|    std                  | 0.714       |
|    value_loss           | 0.087       |
-----------------------------------------
-------------------------------
| time/              |        |
|    fps             | 632    |
|    iterations      | 162    |
|    time_elapsed    | 524    |
|    total_timesteps | 331776 |
-------------------------------
box reached target
box reached target
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 163          |
|    time_elapsed         | 527          |
|    total_timesteps      | 333824       |
| train/                  |              |
|    approx_kl            | 0.0015787629 |
|    clip_fraction        | 0.00645      |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.17        |
|    explained_variance   | 0.808        |
|    learning_rate        | 5.17e-05     |
|    loss                 | 0.00379      |
|    n_updates            | 1620         |
|    policy_gradient_loss | -0.00122     |
|    std                  | 0.718        |
|    value_loss           | 0.0293       |
------------------------------------------
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 164          |
|    time_elapsed         | 530          |
|    total_timesteps      | 335872       |
| train/                  |              |
|    approx_kl            | 0.0032719832 |
|    clip_fraction        | 0.0115       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.17        |
|    explained_variance   | 0.872        |
|    learning_rate        | 5.17e-05     |
|    loss                 | 0.02         |
|    n_updates            | 1630         |
|    policy_gradient_loss | -0.0033      |
|    std                  | 0.714        |
|    value_loss           | 0.0546       |
------------------------------------------
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 633          |
|    iterations           | 165          |
|    time_elapsed         | 533          |
|    total_timesteps      | 337920       |
| train/                  |              |
|    approx_kl            | 0.0044120103 |
|    clip_fraction        | 0.0181       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.16        |
|    explained_variance   | 0.94         |
|    learning_rate        | 5.17e-05     |
|    loss                 | 0.00232      |
|    n_updates            | 1640         |
|    policy_gradient_loss | -0.00199     |
|    std                  | 0.714        |
|    value_loss           | 0.0129       |
------------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 633         |
|    iterations           | 166         |
|    time_elapsed         | 536         |
|    total_timesteps      | 339968      |
| train/                  |             |
|    approx_kl            | 0.003726405 |
|    clip_fraction        | 0.0257      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.16       |
|    explained_variance   | 0.955       |
|    learning_rate        | 5.17e-05    |
|    loss                 | 0.00331     |
|    n_updates            | 1650        |
|    policy_gradient_loss | -0.0033     |
|    std                  | 0.712       |
|    value_loss           | 0.00793     |
-----------------------------------------
Eval num_timesteps=340000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 300          |
|    mean_reward          | -1           |
| time/                   |              |
|    total_timesteps      | 340000       |
| train/                  |              |
|    approx_kl            | 0.0034581497 |
|    clip_fraction        | 0.0148       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.16        |
|    explained_variance   | 0.933        |
|    learning_rate        | 5.17e-05     |
|    loss                 | -0.00206     |
|    n_updates            | 1660         |
|    policy_gradient_loss | -0.00381     |
|    std                  | 0.715        |
|    value_loss           | 0.00376      |
------------------------------------------
-------------------------------
| time/              |        |
|    fps             | 632    |
|    iterations      | 167    |
|    time_elapsed    | 540    |
|    total_timesteps | 342016 |
-------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 168          |
|    time_elapsed         | 543          |
|    total_timesteps      | 344064       |
| train/                  |              |
|    approx_kl            | 0.0069064246 |
|    clip_fraction        | 0.0501       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.17        |
|    explained_variance   | 0.868        |
|    learning_rate        | 5.17e-05     |
|    loss                 | -0.0215      |
|    n_updates            | 1670         |
|    policy_gradient_loss | -0.00616     |
|    std                  | 0.717        |
|    value_loss           | 0.00184      |
------------------------------------------
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 169          |
|    time_elapsed         | 546          |
|    total_timesteps      | 346112       |
| train/                  |              |
|    approx_kl            | 0.0040901606 |
|    clip_fraction        | 0.0275       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.17        |
|    explained_variance   | 0.862        |
|    learning_rate        | 5.17e-05     |
|    loss                 | 0.00842      |
|    n_updates            | 1680         |
|    policy_gradient_loss | -0.00268     |
|    std                  | 0.715        |
|    value_loss           | 0.00766      |
------------------------------------------
box reached target
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 633          |
|    iterations           | 170          |
|    time_elapsed         | 549          |
|    total_timesteps      | 348160       |
| train/                  |              |
|    approx_kl            | 0.0038767925 |
|    clip_fraction        | 0.0226       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.16        |
|    explained_variance   | 0.964        |
|    learning_rate        | 5.17e-05     |
|    loss                 | -0.00886     |
|    n_updates            | 1690         |
|    policy_gradient_loss | -0.00332     |
|    std                  | 0.713        |
|    value_loss           | 0.0147       |
------------------------------------------
box reached target
Eval num_timesteps=350000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 300          |
|    mean_reward          | -1           |
| time/                   |              |
|    total_timesteps      | 350000       |
| train/                  |              |
|    approx_kl            | 0.0050906865 |
|    clip_fraction        | 0.0212       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.16        |
|    explained_variance   | 0.828        |
|    learning_rate        | 5.17e-05     |
|    loss                 | -0.00665     |
|    n_updates            | 1700         |
|    policy_gradient_loss | -0.0033      |
|    std                  | 0.711        |
|    value_loss           | 0.0389       |
------------------------------------------
-------------------------------
| time/              |        |
|    fps             | 632    |
|    iterations      | 171    |
|    time_elapsed    | 553    |
|    total_timesteps | 350208 |
-------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 172          |
|    time_elapsed         | 556          |
|    total_timesteps      | 352256       |
| train/                  |              |
|    approx_kl            | 0.0067873597 |
|    clip_fraction        | 0.0444       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.15        |
|    explained_variance   | 0.937        |
|    learning_rate        | 5.18e-05     |
|    loss                 | 0.00639      |
|    n_updates            | 1710         |
|    policy_gradient_loss | -0.0074      |
|    std                  | 0.71         |
|    value_loss           | 0.0115       |
------------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 632         |
|    iterations           | 173         |
|    time_elapsed         | 559         |
|    total_timesteps      | 354304      |
| train/                  |             |
|    approx_kl            | 0.003389464 |
|    clip_fraction        | 0.0213      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.15       |
|    explained_variance   | 0.923       |
|    learning_rate        | 5.18e-05    |
|    loss                 | -0.00365    |
|    n_updates            | 1720        |
|    policy_gradient_loss | -0.00342    |
|    std                  | 0.709       |
|    value_loss           | 0.00207     |
-----------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 174          |
|    time_elapsed         | 563          |
|    total_timesteps      | 356352       |
| train/                  |              |
|    approx_kl            | 0.0027452162 |
|    clip_fraction        | 0.0164       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.15        |
|    explained_variance   | 0.894        |
|    learning_rate        | 5.18e-05     |
|    loss                 | -0.0236      |
|    n_updates            | 1730         |
|    policy_gradient_loss | -0.00455     |
|    std                  | 0.707        |
|    value_loss           | 0.00471      |
------------------------------------------
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 633          |
|    iterations           | 175          |
|    time_elapsed         | 566          |
|    total_timesteps      | 358400       |
| train/                  |              |
|    approx_kl            | 0.0050844196 |
|    clip_fraction        | 0.0369       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.14        |
|    explained_variance   | 0.917        |
|    learning_rate        | 5.18e-05     |
|    loss                 | -0.0115      |
|    n_updates            | 1740         |
|    policy_gradient_loss | -0.00496     |
|    std                  | 0.706        |
|    value_loss           | 0.00509      |
------------------------------------------
Eval num_timesteps=360000, episode_reward=-0.46 +/- 0.69
Episode length: 300.00 +/- 0.00
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 300          |
|    mean_reward          | -0.459       |
| time/                   |              |
|    total_timesteps      | 360000       |
| train/                  |              |
|    approx_kl            | 0.0046914904 |
|    clip_fraction        | 0.0245       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.14        |
|    explained_variance   | 0.86         |
|    learning_rate        | 5.18e-05     |
|    loss                 | -0.00371     |
|    n_updates            | 1750         |
|    policy_gradient_loss | -0.00479     |
|    std                  | 0.704        |
|    value_loss           | 0.0163       |
------------------------------------------
box reached target
-------------------------------
| time/              |        |
|    fps             | 632    |
|    iterations      | 176    |
|    time_elapsed    | 570    |
|    total_timesteps | 360448 |
-------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 177          |
|    time_elapsed         | 573          |
|    total_timesteps      | 362496       |
| train/                  |              |
|    approx_kl            | 0.0023598818 |
|    clip_fraction        | 0.0106       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.14        |
|    explained_variance   | 0.864        |
|    learning_rate        | 5.18e-05     |
|    loss                 | 0.00908      |
|    n_updates            | 1760         |
|    policy_gradient_loss | -0.00339     |
|    std                  | 0.706        |
|    value_loss           | 0.0384       |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 178          |
|    time_elapsed         | 576          |
|    total_timesteps      | 364544       |
| train/                  |              |
|    approx_kl            | 0.0041264193 |
|    clip_fraction        | 0.0193       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.14        |
|    explained_variance   | 0.876        |
|    learning_rate        | 5.18e-05     |
|    loss                 | -0.0124      |
|    n_updates            | 1770         |
|    policy_gradient_loss | -0.00315     |
|    std                  | 0.708        |
|    value_loss           | 0.0126       |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 179          |
|    time_elapsed         | 579          |
|    total_timesteps      | 366592       |
| train/                  |              |
|    approx_kl            | 0.0050071613 |
|    clip_fraction        | 0.0322       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.14        |
|    explained_variance   | 0.872        |
|    learning_rate        | 5.18e-05     |
|    loss                 | -0.0115      |
|    n_updates            | 1780         |
|    policy_gradient_loss | -0.00526     |
|    std                  | 0.705        |
|    value_loss           | 0.00256      |
------------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 633         |
|    iterations           | 180         |
|    time_elapsed         | 582         |
|    total_timesteps      | 368640      |
| train/                  |             |
|    approx_kl            | 0.002891122 |
|    clip_fraction        | 0.0062      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.14       |
|    explained_variance   | 0.847       |
|    learning_rate        | 5.18e-05    |
|    loss                 | 0.0142      |
|    n_updates            | 1790        |
|    policy_gradient_loss | -0.00224    |
|    std                  | 0.706       |
|    value_loss           | 0.00241     |
-----------------------------------------
Eval num_timesteps=370000, episode_reward=-0.65 +/- 0.43
Episode length: 300.00 +/- 0.00
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 300          |
|    mean_reward          | -0.648       |
| time/                   |              |
|    total_timesteps      | 370000       |
| train/                  |              |
|    approx_kl            | 0.0057084328 |
|    clip_fraction        | 0.0506       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.14        |
|    explained_variance   | 0.925        |
|    learning_rate        | 5.18e-05     |
|    loss                 | -0.0167      |
|    n_updates            | 1800         |
|    policy_gradient_loss | -0.00808     |
|    std                  | 0.707        |
|    value_loss           | 0.0039       |
------------------------------------------
-------------------------------
| time/              |        |
|    fps             | 632    |
|    iterations      | 181    |
|    time_elapsed    | 586    |
|    total_timesteps | 370688 |
-------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 632         |
|    iterations           | 182         |
|    time_elapsed         | 589         |
|    total_timesteps      | 372736      |
| train/                  |             |
|    approx_kl            | 0.002726509 |
|    clip_fraction        | 0.0131      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.14       |
|    explained_variance   | 0.84        |
|    learning_rate        | 5.19e-05    |
|    loss                 | 0.00497     |
|    n_updates            | 1810        |
|    policy_gradient_loss | -0.00237    |
|    std                  | 0.705       |
|    value_loss           | 0.0169      |
-----------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 183          |
|    time_elapsed         | 592          |
|    total_timesteps      | 374784       |
| train/                  |              |
|    approx_kl            | 0.0047797007 |
|    clip_fraction        | 0.0351       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.14        |
|    explained_variance   | 0.733        |
|    learning_rate        | 5.19e-05     |
|    loss                 | -0.0131      |
|    n_updates            | 1820         |
|    policy_gradient_loss | -0.00437     |
|    std                  | 0.706        |
|    value_loss           | 0.00119      |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 184          |
|    time_elapsed         | 595          |
|    total_timesteps      | 376832       |
| train/                  |              |
|    approx_kl            | 0.0057246257 |
|    clip_fraction        | 0.0349       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.14        |
|    explained_variance   | 0.803        |
|    learning_rate        | 5.19e-05     |
|    loss                 | -0.00715     |
|    n_updates            | 1830         |
|    policy_gradient_loss | -0.0055      |
|    std                  | 0.704        |
|    value_loss           | 0.00136      |
------------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 633         |
|    iterations           | 185         |
|    time_elapsed         | 598         |
|    total_timesteps      | 378880      |
| train/                  |             |
|    approx_kl            | 0.005281923 |
|    clip_fraction        | 0.0377      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.13       |
|    explained_variance   | 0.851       |
|    learning_rate        | 5.19e-05    |
|    loss                 | -0.0107     |
|    n_updates            | 1840        |
|    policy_gradient_loss | -0.00411    |
|    std                  | 0.7         |
|    value_loss           | 0.00152     |
-----------------------------------------
Eval num_timesteps=380000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 300          |
|    mean_reward          | -1           |
| time/                   |              |
|    total_timesteps      | 380000       |
| train/                  |              |
|    approx_kl            | 0.0038113398 |
|    clip_fraction        | 0.0207       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.12        |
|    explained_variance   | 0.94         |
|    learning_rate        | 5.19e-05     |
|    loss                 | 0.00494      |
|    n_updates            | 1850         |
|    policy_gradient_loss | -0.00438     |
|    std                  | 0.699        |
|    value_loss           | 0.00195      |
------------------------------------------
box reached target
-------------------------------
| time/              |        |
|    fps             | 632    |
|    iterations      | 186    |
|    time_elapsed    | 602    |
|    total_timesteps | 380928 |
-------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 187          |
|    time_elapsed         | 605          |
|    total_timesteps      | 382976       |
| train/                  |              |
|    approx_kl            | 0.0040785503 |
|    clip_fraction        | 0.0159       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.12        |
|    explained_variance   | 0.82         |
|    learning_rate        | 5.19e-05     |
|    loss                 | -0.0224      |
|    n_updates            | 1860         |
|    policy_gradient_loss | -0.00254     |
|    std                  | 0.698        |
|    value_loss           | 0.0141       |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 188          |
|    time_elapsed         | 608          |
|    total_timesteps      | 385024       |
| train/                  |              |
|    approx_kl            | 0.0036162473 |
|    clip_fraction        | 0.0222       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.12        |
|    explained_variance   | 0.902        |
|    learning_rate        | 5.19e-05     |
|    loss                 | -0.0102      |
|    n_updates            | 1870         |
|    policy_gradient_loss | -0.00371     |
|    std                  | 0.698        |
|    value_loss           | 0.00212      |
------------------------------------------
box reached target
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 632         |
|    iterations           | 189         |
|    time_elapsed         | 611         |
|    total_timesteps      | 387072      |
| train/                  |             |
|    approx_kl            | 0.003998354 |
|    clip_fraction        | 0.02        |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.12       |
|    explained_variance   | 0.944       |
|    learning_rate        | 5.19e-05    |
|    loss                 | 0.00306     |
|    n_updates            | 1880        |
|    policy_gradient_loss | -0.00328    |
|    std                  | 0.697       |
|    value_loss           | 0.00123     |
-----------------------------------------
box reached target
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 633         |
|    iterations           | 190         |
|    time_elapsed         | 614         |
|    total_timesteps      | 389120      |
| train/                  |             |
|    approx_kl            | 0.004090027 |
|    clip_fraction        | 0.0168      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.11       |
|    explained_variance   | 0.673       |
|    learning_rate        | 5.19e-05    |
|    loss                 | 0.00188     |
|    n_updates            | 1890        |
|    policy_gradient_loss | -0.00158    |
|    std                  | 0.695       |
|    value_loss           | 0.0804      |
-----------------------------------------
Eval num_timesteps=390000, episode_reward=-1.01 +/- 0.02
Episode length: 300.00 +/- 0.00
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 300          |
|    mean_reward          | -1.01        |
| time/                   |              |
|    total_timesteps      | 390000       |
| train/                  |              |
|    approx_kl            | 0.0032909038 |
|    clip_fraction        | 0.00679      |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.11        |
|    explained_variance   | 0.76         |
|    learning_rate        | 5.19e-05     |
|    loss                 | 0.0488       |
|    n_updates            | 1900         |
|    policy_gradient_loss | -0.00188     |
|    std                  | 0.694        |
|    value_loss           | 0.0341       |
------------------------------------------
box reached target
box reached target
box reached target
-------------------------------
| time/              |        |
|    fps             | 632    |
|    iterations      | 191    |
|    time_elapsed    | 618    |
|    total_timesteps | 391168 |
-------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 192          |
|    time_elapsed         | 621          |
|    total_timesteps      | 393216       |
| train/                  |              |
|    approx_kl            | 0.0044525266 |
|    clip_fraction        | 0.0347       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.11        |
|    explained_variance   | 0.842        |
|    learning_rate        | 5.2e-05      |
|    loss                 | 0.0021       |
|    n_updates            | 1910         |
|    policy_gradient_loss | -0.00491     |
|    std                  | 0.694        |
|    value_loss           | 0.0604       |
------------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 632         |
|    iterations           | 193         |
|    time_elapsed         | 624         |
|    total_timesteps      | 395264      |
| train/                  |             |
|    approx_kl            | 0.005833597 |
|    clip_fraction        | 0.0394      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.11       |
|    explained_variance   | 0.905       |
|    learning_rate        | 5.2e-05     |
|    loss                 | -0.00931    |
|    n_updates            | 1920        |
|    policy_gradient_loss | -0.00739    |
|    std                  | 0.694       |
|    value_loss           | 0.00338     |
-----------------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 632         |
|    iterations           | 194         |
|    time_elapsed         | 627         |
|    total_timesteps      | 397312      |
| train/                  |             |
|    approx_kl            | 0.003917071 |
|    clip_fraction        | 0.0259      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.11       |
|    explained_variance   | 0.89        |
|    learning_rate        | 5.2e-05     |
|    loss                 | -0.0137     |
|    n_updates            | 1930        |
|    policy_gradient_loss | -0.00525    |
|    std                  | 0.696       |
|    value_loss           | 0.00376     |
-----------------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 633         |
|    iterations           | 195         |
|    time_elapsed         | 630         |
|    total_timesteps      | 399360      |
| train/                  |             |
|    approx_kl            | 0.003951552 |
|    clip_fraction        | 0.0253      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.12       |
|    explained_variance   | 0.917       |
|    learning_rate        | 5.2e-05     |
|    loss                 | 0.00676     |
|    n_updates            | 1940        |
|    policy_gradient_loss | -0.00464    |
|    std                  | 0.698       |
|    value_loss           | 0.0209      |
-----------------------------------------
Eval num_timesteps=400000, episode_reward=-0.55 +/- 0.63
Episode length: 300.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 300         |
|    mean_reward          | -0.553      |
| time/                   |             |
|    total_timesteps      | 400000      |
| train/                  |             |
|    approx_kl            | 0.004105459 |
|    clip_fraction        | 0.0157      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.11       |
|    explained_variance   | 0.723       |
|    learning_rate        | 5.2e-05     |
|    loss                 | 0.0119      |
|    n_updates            | 1950        |
|    policy_gradient_loss | -0.00263    |
|    std                  | 0.695       |
|    value_loss           | 0.0353      |
-----------------------------------------
box reached target
-------------------------------
| time/              |        |
|    fps             | 632    |
|    iterations      | 196    |
|    time_elapsed    | 634    |
|    total_timesteps | 401408 |
-------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 632         |
|    iterations           | 197         |
|    time_elapsed         | 637         |
|    total_timesteps      | 403456      |
| train/                  |             |
|    approx_kl            | 0.002726907 |
|    clip_fraction        | 0.00659     |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.11       |
|    explained_variance   | 0.933       |
|    learning_rate        | 5.2e-05     |
|    loss                 | 0.00356     |
|    n_updates            | 1960        |
|    policy_gradient_loss | -0.00238    |
|    std                  | 0.692       |
|    value_loss           | 0.00666     |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 632         |
|    iterations           | 198         |
|    time_elapsed         | 640         |
|    total_timesteps      | 405504      |
| train/                  |             |
|    approx_kl            | 0.002814194 |
|    clip_fraction        | 0.0134      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.1        |
|    explained_variance   | 0.92        |
|    learning_rate        | 5.2e-05     |
|    loss                 | -0.0142     |
|    n_updates            | 1970        |
|    policy_gradient_loss | -0.00394    |
|    std                  | 0.694       |
|    value_loss           | 0.00244     |
-----------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 199          |
|    time_elapsed         | 643          |
|    total_timesteps      | 407552       |
| train/                  |              |
|    approx_kl            | 0.0057007903 |
|    clip_fraction        | 0.0477       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.11        |
|    explained_variance   | 0.92         |
|    learning_rate        | 5.2e-05      |
|    loss                 | -0.00986     |
|    n_updates            | 1980         |
|    policy_gradient_loss | -0.00693     |
|    std                  | 0.694        |
|    value_loss           | 0.00123      |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 633          |
|    iterations           | 200          |
|    time_elapsed         | 647          |
|    total_timesteps      | 409600       |
| train/                  |              |
|    approx_kl            | 0.0075345505 |
|    clip_fraction        | 0.0625       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.11        |
|    explained_variance   | 0.825        |
|    learning_rate        | 5.2e-05      |
|    loss                 | 0.00198      |
|    n_updates            | 1990         |
|    policy_gradient_loss | -0.00755     |
|    std                  | 0.694        |
|    value_loss           | 0.0012       |
------------------------------------------
Eval num_timesteps=410000, episode_reward=-0.51 +/- 0.51
Episode length: 300.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 300         |
|    mean_reward          | -0.515      |
| time/                   |             |
|    total_timesteps      | 410000      |
| train/                  |             |
|    approx_kl            | 0.006120232 |
|    clip_fraction        | 0.0309      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.11       |
|    explained_variance   | 0.944       |
|    learning_rate        | 5.2e-05     |
|    loss                 | -0.0117     |
|    n_updates            | 2000        |
|    policy_gradient_loss | -0.004      |
|    std                  | 0.696       |
|    value_loss           | 0.00159     |
-----------------------------------------
-------------------------------
| time/              |        |
|    fps             | 632    |
|    iterations      | 201    |
|    time_elapsed    | 651    |
|    total_timesteps | 411648 |
-------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 202          |
|    time_elapsed         | 654          |
|    total_timesteps      | 413696       |
| train/                  |              |
|    approx_kl            | 0.0064049223 |
|    clip_fraction        | 0.0398       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.11        |
|    explained_variance   | 0.813        |
|    learning_rate        | 5.21e-05     |
|    loss                 | -0.000692    |
|    n_updates            | 2010         |
|    policy_gradient_loss | -0.00587     |
|    std                  | 0.695        |
|    value_loss           | 0.00138      |
------------------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 632         |
|    iterations           | 203         |
|    time_elapsed         | 657         |
|    total_timesteps      | 415744      |
| train/                  |             |
|    approx_kl            | 0.004627464 |
|    clip_fraction        | 0.0349      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.11       |
|    explained_variance   | 0.746       |
|    learning_rate        | 5.21e-05    |
|    loss                 | 0.00793     |
|    n_updates            | 2020        |
|    policy_gradient_loss | -0.00543    |
|    std                  | 0.694       |
|    value_loss           | 0.00161     |
-----------------------------------------
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 204          |
|    time_elapsed         | 660          |
|    total_timesteps      | 417792       |
| train/                  |              |
|    approx_kl            | 0.0052993894 |
|    clip_fraction        | 0.0333       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.1         |
|    explained_variance   | 0.98         |
|    learning_rate        | 5.21e-05     |
|    loss                 | -0.00495     |
|    n_updates            | 2030         |
|    policy_gradient_loss | -0.0062      |
|    std                  | 0.69         |
|    value_loss           | 0.00503      |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 633          |
|    iterations           | 205          |
|    time_elapsed         | 663          |
|    total_timesteps      | 419840       |
| train/                  |              |
|    approx_kl            | 0.0026088762 |
|    clip_fraction        | 0.00732      |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.09        |
|    explained_variance   | 0.947        |
|    learning_rate        | 5.21e-05     |
|    loss                 | -0.0104      |
|    n_updates            | 2040         |
|    policy_gradient_loss | -0.00198     |
|    std                  | 0.689        |
|    value_loss           | 0.00143      |
------------------------------------------
Eval num_timesteps=420000, episode_reward=-0.73 +/- 0.53
Episode length: 300.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 300         |
|    mean_reward          | -0.734      |
| time/                   |             |
|    total_timesteps      | 420000      |
| train/                  |             |
|    approx_kl            | 0.004146874 |
|    clip_fraction        | 0.0158      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.09       |
|    explained_variance   | 0.815       |
|    learning_rate        | 5.21e-05    |
|    loss                 | -0.0147     |
|    n_updates            | 2050        |
|    policy_gradient_loss | -0.004      |
|    std                  | 0.688       |
|    value_loss           | 0.000889    |
-----------------------------------------
box reached target
-------------------------------
| time/              |        |
|    fps             | 632    |
|    iterations      | 206    |
|    time_elapsed    | 667    |
|    total_timesteps | 421888 |
-------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 207          |
|    time_elapsed         | 670          |
|    total_timesteps      | 423936       |
| train/                  |              |
|    approx_kl            | 0.0039996644 |
|    clip_fraction        | 0.00986      |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.09        |
|    explained_variance   | 0.64         |
|    learning_rate        | 5.21e-05     |
|    loss                 | -0.0218      |
|    n_updates            | 2060         |
|    policy_gradient_loss | -0.00206     |
|    std                  | 0.687        |
|    value_loss           | 0.0537       |
------------------------------------------
box reached target
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 208          |
|    time_elapsed         | 673          |
|    total_timesteps      | 425984       |
| train/                  |              |
|    approx_kl            | 0.0059442567 |
|    clip_fraction        | 0.0369       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.09        |
|    explained_variance   | 0.896        |
|    learning_rate        | 5.21e-05     |
|    loss                 | -0.0114      |
|    n_updates            | 2070         |
|    policy_gradient_loss | -0.00617     |
|    std                  | 0.689        |
|    value_loss           | 0.00139      |
------------------------------------------
box reached target
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 209          |
|    time_elapsed         | 676          |
|    total_timesteps      | 428032       |
| train/                  |              |
|    approx_kl            | 0.0050132913 |
|    clip_fraction        | 0.0244       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.09        |
|    explained_variance   | 0.977        |
|    learning_rate        | 5.21e-05     |
|    loss                 | -0.00706     |
|    n_updates            | 2080         |
|    policy_gradient_loss | -0.00331     |
|    std                  | 0.684        |
|    value_loss           | 0.0116       |
------------------------------------------
Eval num_timesteps=430000, episode_reward=-0.95 +/- 0.10
Episode length: 300.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 300         |
|    mean_reward          | -0.951      |
| time/                   |             |
|    total_timesteps      | 430000      |
| train/                  |             |
|    approx_kl            | 0.007834898 |
|    clip_fraction        | 0.056       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.08       |
|    explained_variance   | 0.943       |
|    learning_rate        | 5.21e-05    |
|    loss                 | 0.00797     |
|    n_updates            | 2090        |
|    policy_gradient_loss | -0.00656    |
|    std                  | 0.682       |
|    value_loss           | 0.0185      |
-----------------------------------------
-------------------------------
| time/              |        |
|    fps             | 632    |
|    iterations      | 210    |
|    time_elapsed    | 680    |
|    total_timesteps | 430080 |
-------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 632         |
|    iterations           | 211         |
|    time_elapsed         | 683         |
|    total_timesteps      | 432128      |
| train/                  |             |
|    approx_kl            | 0.004621464 |
|    clip_fraction        | 0.0243      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.07       |
|    explained_variance   | 0.912       |
|    learning_rate        | 5.22e-05    |
|    loss                 | -0.00203    |
|    n_updates            | 2100        |
|    policy_gradient_loss | -0.00457    |
|    std                  | 0.682       |
|    value_loss           | 0.00308     |
-----------------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 632         |
|    iterations           | 212         |
|    time_elapsed         | 686         |
|    total_timesteps      | 434176      |
| train/                  |             |
|    approx_kl            | 0.005291908 |
|    clip_fraction        | 0.0324      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.07       |
|    explained_variance   | 0.935       |
|    learning_rate        | 5.22e-05    |
|    loss                 | -0.0161     |
|    n_updates            | 2110        |
|    policy_gradient_loss | -0.00512    |
|    std                  | 0.681       |
|    value_loss           | 0.00238     |
-----------------------------------------
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 213          |
|    time_elapsed         | 689          |
|    total_timesteps      | 436224       |
| train/                  |              |
|    approx_kl            | 0.0021869985 |
|    clip_fraction        | 0.0114       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.07        |
|    explained_variance   | 0.919        |
|    learning_rate        | 5.22e-05     |
|    loss                 | 0.00814      |
|    n_updates            | 2120         |
|    policy_gradient_loss | -0.0041      |
|    std                  | 0.682        |
|    value_loss           | 0.0155       |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 214          |
|    time_elapsed         | 692          |
|    total_timesteps      | 438272       |
| train/                  |              |
|    approx_kl            | 0.0039723655 |
|    clip_fraction        | 0.0323       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.07        |
|    explained_variance   | 0.949        |
|    learning_rate        | 5.22e-05     |
|    loss                 | -0.0271      |
|    n_updates            | 2130         |
|    policy_gradient_loss | -0.00328     |
|    std                  | 0.681        |
|    value_loss           | 0.0057       |
------------------------------------------
box reached target
Eval num_timesteps=440000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 300          |
|    mean_reward          | -1           |
| time/                   |              |
|    total_timesteps      | 440000       |
| train/                  |              |
|    approx_kl            | 0.0045297155 |
|    clip_fraction        | 0.0405       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.07        |
|    explained_variance   | 0.919        |
|    learning_rate        | 5.22e-05     |
|    loss                 | 0.0117       |
|    n_updates            | 2140         |
|    policy_gradient_loss | -0.00683     |
|    std                  | 0.682        |
|    value_loss           | 0.00104      |
------------------------------------------
box reached target
-------------------------------
| time/              |        |
|    fps             | 632    |
|    iterations      | 215    |
|    time_elapsed    | 696    |
|    total_timesteps | 440320 |
-------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 632         |
|    iterations           | 216         |
|    time_elapsed         | 699         |
|    total_timesteps      | 442368      |
| train/                  |             |
|    approx_kl            | 0.004647487 |
|    clip_fraction        | 0.0286      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.07       |
|    explained_variance   | 0.89        |
|    learning_rate        | 5.22e-05    |
|    loss                 | 0.00184     |
|    n_updates            | 2150        |
|    policy_gradient_loss | -0.00385    |
|    std                  | 0.681       |
|    value_loss           | 0.0508      |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 632         |
|    iterations           | 217         |
|    time_elapsed         | 702         |
|    total_timesteps      | 444416      |
| train/                  |             |
|    approx_kl            | 0.003840379 |
|    clip_fraction        | 0.0363      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.07       |
|    explained_variance   | 0.851       |
|    learning_rate        | 5.22e-05    |
|    loss                 | 0.036       |
|    n_updates            | 2160        |
|    policy_gradient_loss | -0.00384    |
|    std                  | 0.682       |
|    value_loss           | 0.0368      |
-----------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 218          |
|    time_elapsed         | 705          |
|    total_timesteps      | 446464       |
| train/                  |              |
|    approx_kl            | 0.0047752885 |
|    clip_fraction        | 0.0252       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.07        |
|    explained_variance   | 0.854        |
|    learning_rate        | 5.22e-05     |
|    loss                 | -0.0155      |
|    n_updates            | 2170         |
|    policy_gradient_loss | -0.00607     |
|    std                  | 0.682        |
|    value_loss           | 0.00101      |
------------------------------------------
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 219          |
|    time_elapsed         | 708          |
|    total_timesteps      | 448512       |
| train/                  |              |
|    approx_kl            | 0.0050640698 |
|    clip_fraction        | 0.0357       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.07        |
|    explained_variance   | 0.896        |
|    learning_rate        | 5.22e-05     |
|    loss                 | -0.0139      |
|    n_updates            | 2180         |
|    policy_gradient_loss | -0.00598     |
|    std                  | 0.684        |
|    value_loss           | 0.00783      |
------------------------------------------
box reached target
Eval num_timesteps=450000, episode_reward=0.36 +/- 2.55
Episode length: 272.20 +/- 55.60
--------------------------------------
| eval/                   |          |
|    mean_ep_length       | 272      |
|    mean_reward          | 0.36     |
| time/                   |          |
|    total_timesteps      | 450000   |
| train/                  |          |
|    approx_kl            | 0.004297 |
|    clip_fraction        | 0.0231   |
|    clip_range           | 0.2      |
|    entropy_loss         | -2.08    |
|    explained_variance   | 0.94     |
|    learning_rate        | 5.22e-05 |
|    loss                 | -0.014   |
|    n_updates            | 2190     |
|    policy_gradient_loss | -0.00361 |
|    std                  | 0.686    |
|    value_loss           | 0.0156   |
--------------------------------------
-------------------------------
| time/              |        |
|    fps             | 632    |
|    iterations      | 220    |
|    time_elapsed    | 712    |
|    total_timesteps | 450560 |
-------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 221          |
|    time_elapsed         | 715          |
|    total_timesteps      | 452608       |
| train/                  |              |
|    approx_kl            | 0.0023404686 |
|    clip_fraction        | 0.0124       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.09        |
|    explained_variance   | 0.901        |
|    learning_rate        | 5.23e-05     |
|    loss                 | -0.0115      |
|    n_updates            | 2200         |
|    policy_gradient_loss | -0.00378     |
|    std                  | 0.687        |
|    value_loss           | 0.00634      |
------------------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 632         |
|    iterations           | 222         |
|    time_elapsed         | 718         |
|    total_timesteps      | 454656      |
| train/                  |             |
|    approx_kl            | 0.005222289 |
|    clip_fraction        | 0.0345      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.09       |
|    explained_variance   | 0.855       |
|    learning_rate        | 5.23e-05    |
|    loss                 | -0.00937    |
|    n_updates            | 2210        |
|    policy_gradient_loss | -0.00595    |
|    std                  | 0.689       |
|    value_loss           | 0.00364     |
-----------------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 632         |
|    iterations           | 223         |
|    time_elapsed         | 721         |
|    total_timesteps      | 456704      |
| train/                  |             |
|    approx_kl            | 0.005074735 |
|    clip_fraction        | 0.0276      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.09       |
|    explained_variance   | 0.693       |
|    learning_rate        | 5.23e-05    |
|    loss                 | 0.0159      |
|    n_updates            | 2220        |
|    policy_gradient_loss | -0.00295    |
|    std                  | 0.686       |
|    value_loss           | 0.0261      |
-----------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 224          |
|    time_elapsed         | 724          |
|    total_timesteps      | 458752       |
| train/                  |              |
|    approx_kl            | 0.0044565354 |
|    clip_fraction        | 0.027        |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.08        |
|    explained_variance   | 0.819        |
|    learning_rate        | 5.23e-05     |
|    loss                 | 0.0172       |
|    n_updates            | 2230         |
|    policy_gradient_loss | -0.00356     |
|    std                  | 0.685        |
|    value_loss           | 0.0225       |
------------------------------------------
box reached target
Eval num_timesteps=460000, episode_reward=-1.04 +/- 0.09
Episode length: 300.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 300         |
|    mean_reward          | -1.04       |
| time/                   |             |
|    total_timesteps      | 460000      |
| train/                  |             |
|    approx_kl            | 0.003148126 |
|    clip_fraction        | 0.0167      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.09       |
|    explained_variance   | 0.911       |
|    learning_rate        | 5.23e-05    |
|    loss                 | 0.0208      |
|    n_updates            | 2240        |
|    policy_gradient_loss | -0.00378    |
|    std                  | 0.688       |
|    value_loss           | 0.00689     |
-----------------------------------------
-------------------------------
| time/              |        |
|    fps             | 632    |
|    iterations      | 225    |
|    time_elapsed    | 728    |
|    total_timesteps | 460800 |
-------------------------------
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 226          |
|    time_elapsed         | 731          |
|    total_timesteps      | 462848       |
| train/                  |              |
|    approx_kl            | 0.0042459667 |
|    clip_fraction        | 0.0297       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.09        |
|    explained_variance   | 0.912        |
|    learning_rate        | 5.23e-05     |
|    loss                 | -0.00677     |
|    n_updates            | 2250         |
|    policy_gradient_loss | -0.00439     |
|    std                  | 0.685        |
|    value_loss           | 0.0145       |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 227          |
|    time_elapsed         | 734          |
|    total_timesteps      | 464896       |
| train/                  |              |
|    approx_kl            | 0.0054524397 |
|    clip_fraction        | 0.0377       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.08        |
|    explained_variance   | 0.955        |
|    learning_rate        | 5.23e-05     |
|    loss                 | -0.00303     |
|    n_updates            | 2260         |
|    policy_gradient_loss | -0.00477     |
|    std                  | 0.685        |
|    value_loss           | 0.0103       |
------------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 632         |
|    iterations           | 228         |
|    time_elapsed         | 737         |
|    total_timesteps      | 466944      |
| train/                  |             |
|    approx_kl            | 0.004653914 |
|    clip_fraction        | 0.0228      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.08       |
|    explained_variance   | 0.858       |
|    learning_rate        | 5.23e-05    |
|    loss                 | -0.0177     |
|    n_updates            | 2270        |
|    policy_gradient_loss | -0.00423    |
|    std                  | 0.686       |
|    value_loss           | 0.00553     |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 632         |
|    iterations           | 229         |
|    time_elapsed         | 741         |
|    total_timesteps      | 468992      |
| train/                  |             |
|    approx_kl            | 0.006710312 |
|    clip_fraction        | 0.0517      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.08       |
|    explained_variance   | 0.859       |
|    learning_rate        | 5.23e-05    |
|    loss                 | 0.0124      |
|    n_updates            | 2280        |
|    policy_gradient_loss | -0.00739    |
|    std                  | 0.684       |
|    value_loss           | 0.00274     |
-----------------------------------------
box reached target
Eval num_timesteps=470000, episode_reward=0.74 +/- 2.37
Episode length: 281.80 +/- 36.40
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 282          |
|    mean_reward          | 0.737        |
| time/                   |              |
|    total_timesteps      | 470000       |
| train/                  |              |
|    approx_kl            | 0.0051119346 |
|    clip_fraction        | 0.0241       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.08        |
|    explained_variance   | 0.937        |
|    learning_rate        | 5.23e-05     |
|    loss                 | 0.0141       |
|    n_updates            | 2290         |
|    policy_gradient_loss | -0.0041      |
|    std                  | 0.685        |
|    value_loss           | 0.00146      |
------------------------------------------
-------------------------------
| time/              |        |
|    fps             | 632    |
|    iterations      | 230    |
|    time_elapsed    | 744    |
|    total_timesteps | 471040 |
-------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 632         |
|    iterations           | 231         |
|    time_elapsed         | 748         |
|    total_timesteps      | 473088      |
| train/                  |             |
|    approx_kl            | 0.004036369 |
|    clip_fraction        | 0.0223      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.09       |
|    explained_variance   | 0.867       |
|    learning_rate        | 5.24e-05    |
|    loss                 | 0.0246      |
|    n_updates            | 2300        |
|    policy_gradient_loss | -0.00378    |
|    std                  | 0.688       |
|    value_loss           | 0.0123      |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 632         |
|    iterations           | 232         |
|    time_elapsed         | 751         |
|    total_timesteps      | 475136      |
| train/                  |             |
|    approx_kl            | 0.005043799 |
|    clip_fraction        | 0.0404      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.09       |
|    explained_variance   | 0.913       |
|    learning_rate        | 5.24e-05    |
|    loss                 | 0.0271      |
|    n_updates            | 2310        |
|    policy_gradient_loss | -0.00447    |
|    std                  | 0.689       |
|    value_loss           | 0.00351     |
-----------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 233          |
|    time_elapsed         | 754          |
|    total_timesteps      | 477184       |
| train/                  |              |
|    approx_kl            | 0.0052602403 |
|    clip_fraction        | 0.0321       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.09        |
|    explained_variance   | 0.901        |
|    learning_rate        | 5.24e-05     |
|    loss                 | -0.0196      |
|    n_updates            | 2320         |
|    policy_gradient_loss | -0.00458     |
|    std                  | 0.69         |
|    value_loss           | 0.00173      |
------------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 632         |
|    iterations           | 234         |
|    time_elapsed         | 757         |
|    total_timesteps      | 479232      |
| train/                  |             |
|    approx_kl            | 0.006303269 |
|    clip_fraction        | 0.0556      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.1        |
|    explained_variance   | 0.87        |
|    learning_rate        | 5.24e-05    |
|    loss                 | 0.00341     |
|    n_updates            | 2330        |
|    policy_gradient_loss | -0.00878    |
|    std                  | 0.691       |
|    value_loss           | 0.00128     |
-----------------------------------------
Eval num_timesteps=480000, episode_reward=-0.98 +/- 0.04
Episode length: 300.00 +/- 0.00
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 300          |
|    mean_reward          | -0.978       |
| time/                   |              |
|    total_timesteps      | 480000       |
| train/                  |              |
|    approx_kl            | 0.0039027082 |
|    clip_fraction        | 0.0273       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.1         |
|    explained_variance   | 0.889        |
|    learning_rate        | 5.24e-05     |
|    loss                 | 0.00744      |
|    n_updates            | 2340         |
|    policy_gradient_loss | -0.00533     |
|    std                  | 0.69         |
|    value_loss           | 0.00372      |
------------------------------------------
-------------------------------
| time/              |        |
|    fps             | 632    |
|    iterations      | 235    |
|    time_elapsed    | 761    |
|    total_timesteps | 481280 |
-------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 632         |
|    iterations           | 236         |
|    time_elapsed         | 764         |
|    total_timesteps      | 483328      |
| train/                  |             |
|    approx_kl            | 0.004651197 |
|    clip_fraction        | 0.0297      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.09       |
|    explained_variance   | 0.848       |
|    learning_rate        | 5.24e-05    |
|    loss                 | -0.0108     |
|    n_updates            | 2350        |
|    policy_gradient_loss | -0.00519    |
|    std                  | 0.689       |
|    value_loss           | 0.00129     |
-----------------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 632         |
|    iterations           | 237         |
|    time_elapsed         | 767         |
|    total_timesteps      | 485376      |
| train/                  |             |
|    approx_kl            | 0.005832419 |
|    clip_fraction        | 0.0375      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.1        |
|    explained_variance   | 0.888       |
|    learning_rate        | 5.24e-05    |
|    loss                 | 0.0297      |
|    n_updates            | 2360        |
|    policy_gradient_loss | -0.00561    |
|    std                  | 0.693       |
|    value_loss           | 0.00128     |
-----------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 238          |
|    time_elapsed         | 770          |
|    total_timesteps      | 487424       |
| train/                  |              |
|    approx_kl            | 0.0043921922 |
|    clip_fraction        | 0.0234       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.1         |
|    explained_variance   | 0.853        |
|    learning_rate        | 5.24e-05     |
|    loss                 | -0.00506     |
|    n_updates            | 2370         |
|    policy_gradient_loss | -0.00332     |
|    std                  | 0.692        |
|    value_loss           | 0.0335       |
------------------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 632         |
|    iterations           | 239         |
|    time_elapsed         | 773         |
|    total_timesteps      | 489472      |
| train/                  |             |
|    approx_kl            | 0.004438885 |
|    clip_fraction        | 0.0247      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.1        |
|    explained_variance   | 0.826       |
|    learning_rate        | 5.24e-05    |
|    loss                 | 0.00482     |
|    n_updates            | 2380        |
|    policy_gradient_loss | -0.00424    |
|    std                  | 0.692       |
|    value_loss           | 0.001       |
-----------------------------------------
Eval num_timesteps=490000, episode_reward=-0.77 +/- 0.53
Episode length: 300.00 +/- 0.00
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 300          |
|    mean_reward          | -0.768       |
| time/                   |              |
|    total_timesteps      | 490000       |
| train/                  |              |
|    approx_kl            | 0.0039932006 |
|    clip_fraction        | 0.0301       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.1         |
|    explained_variance   | 0.545        |
|    learning_rate        | 5.24e-05     |
|    loss                 | -0.0296      |
|    n_updates            | 2390         |
|    policy_gradient_loss | -0.00426     |
|    std                  | 0.691        |
|    value_loss           | 0.0385       |
------------------------------------------
-------------------------------
| time/              |        |
|    fps             | 632    |
|    iterations      | 240    |
|    time_elapsed    | 777    |
|    total_timesteps | 491520 |
-------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 632         |
|    iterations           | 241         |
|    time_elapsed         | 780         |
|    total_timesteps      | 493568      |
| train/                  |             |
|    approx_kl            | 0.003903321 |
|    clip_fraction        | 0.0275      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.1        |
|    explained_variance   | 0.837       |
|    learning_rate        | 5.25e-05    |
|    loss                 | -0.0224     |
|    n_updates            | 2400        |
|    policy_gradient_loss | -0.00538    |
|    std                  | 0.691       |
|    value_loss           | 0.00251     |
-----------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 242          |
|    time_elapsed         | 783          |
|    total_timesteps      | 495616       |
| train/                  |              |
|    approx_kl            | 0.0044788253 |
|    clip_fraction        | 0.0338       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.1         |
|    explained_variance   | 0.797        |
|    learning_rate        | 5.25e-05     |
|    loss                 | -0.0025      |
|    n_updates            | 2410         |
|    policy_gradient_loss | -0.00692     |
|    std                  | 0.688        |
|    value_loss           | 0.0263       |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 243          |
|    time_elapsed         | 786          |
|    total_timesteps      | 497664       |
| train/                  |              |
|    approx_kl            | 0.0042248024 |
|    clip_fraction        | 0.0392       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.09        |
|    explained_variance   | 0.88         |
|    learning_rate        | 5.25e-05     |
|    loss                 | -0.0108      |
|    n_updates            | 2420         |
|    policy_gradient_loss | -0.00603     |
|    std                  | 0.69         |
|    value_loss           | 0.00338      |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 244          |
|    time_elapsed         | 789          |
|    total_timesteps      | 499712       |
| train/                  |              |
|    approx_kl            | 0.0053377403 |
|    clip_fraction        | 0.0329       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.1         |
|    explained_variance   | 0.939        |
|    learning_rate        | 5.25e-05     |
|    loss                 | 0.00801      |
|    n_updates            | 2430         |
|    policy_gradient_loss | -0.00574     |
|    std                  | 0.691        |
|    value_loss           | 0.00171      |
------------------------------------------
box reached target
Eval num_timesteps=500000, episode_reward=0.23 +/- 2.47
Episode length: 279.80 +/- 40.40
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 280         |
|    mean_reward          | 0.233       |
| time/                   |             |
|    total_timesteps      | 500000      |
| train/                  |             |
|    approx_kl            | 0.003939046 |
|    clip_fraction        | 0.0302      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.1        |
|    explained_variance   | 0.936       |
|    learning_rate        | 5.25e-05    |
|    loss                 | -0.0197     |
|    n_updates            | 2440        |
|    policy_gradient_loss | -0.00526    |
|    std                  | 0.691       |
|    value_loss           | 0.00127     |
-----------------------------------------
-------------------------------
| time/              |        |
|    fps             | 632    |
|    iterations      | 245    |
|    time_elapsed    | 793    |
|    total_timesteps | 501760 |
-------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 246          |
|    time_elapsed         | 796          |
|    total_timesteps      | 503808       |
| train/                  |              |
|    approx_kl            | 0.0053488337 |
|    clip_fraction        | 0.0265       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.1         |
|    explained_variance   | 0.922        |
|    learning_rate        | 5.25e-05     |
|    loss                 | -0.00147     |
|    n_updates            | 2450         |
|    policy_gradient_loss | -0.0034      |
|    std                  | 0.692        |
|    value_loss           | 0.00142      |
------------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 632         |
|    iterations           | 247         |
|    time_elapsed         | 799         |
|    total_timesteps      | 505856      |
| train/                  |             |
|    approx_kl            | 0.004608389 |
|    clip_fraction        | 0.0293      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.1        |
|    explained_variance   | 0.919       |
|    learning_rate        | 5.25e-05    |
|    loss                 | -0.0107     |
|    n_updates            | 2460        |
|    policy_gradient_loss | -0.00684    |
|    std                  | 0.692       |
|    value_loss           | 0.00161     |
-----------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 248          |
|    time_elapsed         | 802          |
|    total_timesteps      | 507904       |
| train/                  |              |
|    approx_kl            | 0.0033393302 |
|    clip_fraction        | 0.0188       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.1         |
|    explained_variance   | 0.836        |
|    learning_rate        | 5.25e-05     |
|    loss                 | -0.00219     |
|    n_updates            | 2470         |
|    policy_gradient_loss | -0.00298     |
|    std                  | 0.694        |
|    value_loss           | 0.00171      |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 249          |
|    time_elapsed         | 805          |
|    total_timesteps      | 509952       |
| train/                  |              |
|    approx_kl            | 0.0045932746 |
|    clip_fraction        | 0.0303       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.11        |
|    explained_variance   | 0.925        |
|    learning_rate        | 5.25e-05     |
|    loss                 | 0.00745      |
|    n_updates            | 2480         |
|    policy_gradient_loss | -0.00393     |
|    std                  | 0.693        |
|    value_loss           | 0.000724     |
------------------------------------------
Eval num_timesteps=510000, episode_reward=-1.00 +/- 0.13
Episode length: 300.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 300         |
|    mean_reward          | -1          |
| time/                   |             |
|    total_timesteps      | 510000      |
| train/                  |             |
|    approx_kl            | 0.006262214 |
|    clip_fraction        | 0.0606      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.1        |
|    explained_variance   | 0.871       |
|    learning_rate        | 5.25e-05    |
|    loss                 | -0.00139    |
|    n_updates            | 2490        |
|    policy_gradient_loss | -0.00625    |
|    std                  | 0.693       |
|    value_loss           | 0.00422     |
-----------------------------------------
-------------------------------
| time/              |        |
|    fps             | 632    |
|    iterations      | 250    |
|    time_elapsed    | 809    |
|    total_timesteps | 512000 |
-------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 251          |
|    time_elapsed         | 812          |
|    total_timesteps      | 514048       |
| train/                  |              |
|    approx_kl            | 0.0042536343 |
|    clip_fraction        | 0.0269       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.1         |
|    explained_variance   | 0.891        |
|    learning_rate        | 5.26e-05     |
|    loss                 | -0.00728     |
|    n_updates            | 2500         |
|    policy_gradient_loss | -0.00414     |
|    std                  | 0.693        |
|    value_loss           | 0.000544     |
------------------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 632         |
|    iterations           | 252         |
|    time_elapsed         | 815         |
|    total_timesteps      | 516096      |
| train/                  |             |
|    approx_kl            | 0.005361532 |
|    clip_fraction        | 0.0429      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.11       |
|    explained_variance   | 0.932       |
|    learning_rate        | 5.26e-05    |
|    loss                 | -0.0291     |
|    n_updates            | 2510        |
|    policy_gradient_loss | -0.00577    |
|    std                  | 0.694       |
|    value_loss           | 0.000733    |
-----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 632        |
|    iterations           | 253        |
|    time_elapsed         | 818        |
|    total_timesteps      | 518144     |
| train/                  |            |
|    approx_kl            | 0.00403269 |
|    clip_fraction        | 0.019      |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.11      |
|    explained_variance   | 0.858      |
|    learning_rate        | 5.26e-05   |
|    loss                 | -0.00417   |
|    n_updates            | 2520       |
|    policy_gradient_loss | -0.00132   |
|    std                  | 0.693      |
|    value_loss           | 0.0219     |
----------------------------------------
box reached target
box reached target
Eval num_timesteps=520000, episode_reward=-0.62 +/- 0.49
Episode length: 300.00 +/- 0.00
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 300          |
|    mean_reward          | -0.623       |
| time/                   |              |
|    total_timesteps      | 520000       |
| train/                  |              |
|    approx_kl            | 0.0036641713 |
|    clip_fraction        | 0.0136       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.1         |
|    explained_variance   | 0.774        |
|    learning_rate        | 5.26e-05     |
|    loss                 | 0.000862     |
|    n_updates            | 2530         |
|    policy_gradient_loss | -0.00141     |
|    std                  | 0.69         |
|    value_loss           | 0.0164       |
------------------------------------------
-------------------------------
| time/              |        |
|    fps             | 632    |
|    iterations      | 254    |
|    time_elapsed    | 822    |
|    total_timesteps | 520192 |
-------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 632         |
|    iterations           | 255         |
|    time_elapsed         | 825         |
|    total_timesteps      | 522240      |
| train/                  |             |
|    approx_kl            | 0.004440693 |
|    clip_fraction        | 0.0233      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.09       |
|    explained_variance   | 0.927       |
|    learning_rate        | 5.26e-05    |
|    loss                 | 0.00261     |
|    n_updates            | 2540        |
|    policy_gradient_loss | -0.00373    |
|    std                  | 0.69        |
|    value_loss           | 0.0198      |
-----------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 256          |
|    time_elapsed         | 828          |
|    total_timesteps      | 524288       |
| train/                  |              |
|    approx_kl            | 0.0049629454 |
|    clip_fraction        | 0.0235       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.09        |
|    explained_variance   | 0.952        |
|    learning_rate        | 5.26e-05     |
|    loss                 | 0.014        |
|    n_updates            | 2550         |
|    policy_gradient_loss | -0.00397     |
|    std                  | 0.688        |
|    value_loss           | 0.00694      |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 257          |
|    time_elapsed         | 831          |
|    total_timesteps      | 526336       |
| train/                  |              |
|    approx_kl            | 0.0043850546 |
|    clip_fraction        | 0.0262       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.09        |
|    explained_variance   | 0.775        |
|    learning_rate        | 5.26e-05     |
|    loss                 | 0.00844      |
|    n_updates            | 2560         |
|    policy_gradient_loss | -0.00581     |
|    std                  | 0.69         |
|    value_loss           | 0.00237      |
------------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 632         |
|    iterations           | 258         |
|    time_elapsed         | 835         |
|    total_timesteps      | 528384      |
| train/                  |             |
|    approx_kl            | 0.006758473 |
|    clip_fraction        | 0.0687      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.1        |
|    explained_variance   | 0.881       |
|    learning_rate        | 5.26e-05    |
|    loss                 | 0.0337      |
|    n_updates            | 2570        |
|    policy_gradient_loss | -0.00683    |
|    std                  | 0.69        |
|    value_loss           | 0.000918    |
-----------------------------------------
box reached target
Eval num_timesteps=530000, episode_reward=0.66 +/- 2.52
Episode length: 285.00 +/- 30.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 285         |
|    mean_reward          | 0.66        |
| time/                   |             |
|    total_timesteps      | 530000      |
| train/                  |             |
|    approx_kl            | 0.004522018 |
|    clip_fraction        | 0.0257      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.09       |
|    explained_variance   | 0.861       |
|    learning_rate        | 5.26e-05    |
|    loss                 | -0.0172     |
|    n_updates            | 2580        |
|    policy_gradient_loss | -0.00398    |
|    std                  | 0.687       |
|    value_loss           | 0.000747    |
-----------------------------------------
-------------------------------
| time/              |        |
|    fps             | 632    |
|    iterations      | 259    |
|    time_elapsed    | 838    |
|    total_timesteps | 530432 |
-------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 260          |
|    time_elapsed         | 841          |
|    total_timesteps      | 532480       |
| train/                  |              |
|    approx_kl            | 0.0038838095 |
|    clip_fraction        | 0.0251       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.09        |
|    explained_variance   | 0.922        |
|    learning_rate        | 5.27e-05     |
|    loss                 | -0.0103      |
|    n_updates            | 2590         |
|    policy_gradient_loss | -0.00527     |
|    std                  | 0.688        |
|    value_loss           | 0.00268      |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 261          |
|    time_elapsed         | 845          |
|    total_timesteps      | 534528       |
| train/                  |              |
|    approx_kl            | 0.0047316337 |
|    clip_fraction        | 0.0341       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.09        |
|    explained_variance   | 0.949        |
|    learning_rate        | 5.27e-05     |
|    loss                 | 0.0199       |
|    n_updates            | 2600         |
|    policy_gradient_loss | -0.00549     |
|    std                  | 0.688        |
|    value_loss           | 0.000947     |
------------------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 632         |
|    iterations           | 262         |
|    time_elapsed         | 848         |
|    total_timesteps      | 536576      |
| train/                  |             |
|    approx_kl            | 0.005276379 |
|    clip_fraction        | 0.0382      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.09       |
|    explained_variance   | 0.895       |
|    learning_rate        | 5.27e-05    |
|    loss                 | -0.0202     |
|    n_updates            | 2610        |
|    policy_gradient_loss | -0.00344    |
|    std                  | 0.69        |
|    value_loss           | 0.00721     |
-----------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 263          |
|    time_elapsed         | 851          |
|    total_timesteps      | 538624       |
| train/                  |              |
|    approx_kl            | 0.0044739805 |
|    clip_fraction        | 0.031        |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.09        |
|    explained_variance   | 0.975        |
|    learning_rate        | 5.27e-05     |
|    loss                 | -0.00624     |
|    n_updates            | 2620         |
|    policy_gradient_loss | -0.00205     |
|    std                  | 0.689        |
|    value_loss           | 0.00401      |
------------------------------------------
Eval num_timesteps=540000, episode_reward=-0.72 +/- 0.55
Episode length: 300.00 +/- 0.00
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 300          |
|    mean_reward          | -0.725       |
| time/                   |              |
|    total_timesteps      | 540000       |
| train/                  |              |
|    approx_kl            | 0.0047936803 |
|    clip_fraction        | 0.0273       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.1         |
|    explained_variance   | 0.926        |
|    learning_rate        | 5.27e-05     |
|    loss                 | 0.0159       |
|    n_updates            | 2630         |
|    policy_gradient_loss | -0.00654     |
|    std                  | 0.691        |
|    value_loss           | 0.00175      |
------------------------------------------
-------------------------------
| time/              |        |
|    fps             | 632    |
|    iterations      | 264    |
|    time_elapsed    | 855    |
|    total_timesteps | 540672 |
-------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 265          |
|    time_elapsed         | 858          |
|    total_timesteps      | 542720       |
| train/                  |              |
|    approx_kl            | 0.0035644795 |
|    clip_fraction        | 0.0153       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.1         |
|    explained_variance   | 0.873        |
|    learning_rate        | 5.27e-05     |
|    loss                 | -0.00612     |
|    n_updates            | 2640         |
|    policy_gradient_loss | -0.00317     |
|    std                  | 0.693        |
|    value_loss           | 0.00623      |
------------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 632         |
|    iterations           | 266         |
|    time_elapsed         | 861         |
|    total_timesteps      | 544768      |
| train/                  |             |
|    approx_kl            | 0.004580741 |
|    clip_fraction        | 0.0326      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.11       |
|    explained_variance   | 0.958       |
|    learning_rate        | 5.27e-05    |
|    loss                 | -0.00906    |
|    n_updates            | 2650        |
|    policy_gradient_loss | -0.00494    |
|    std                  | 0.695       |
|    value_loss           | 0.00133     |
-----------------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 632         |
|    iterations           | 267         |
|    time_elapsed         | 864         |
|    total_timesteps      | 546816      |
| train/                  |             |
|    approx_kl            | 0.004480075 |
|    clip_fraction        | 0.0355      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.11       |
|    explained_variance   | 0.902       |
|    learning_rate        | 5.27e-05    |
|    loss                 | -0.0324     |
|    n_updates            | 2660        |
|    policy_gradient_loss | -0.0111     |
|    std                  | 0.698       |
|    value_loss           | 0.00144     |
-----------------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 632         |
|    iterations           | 268         |
|    time_elapsed         | 867         |
|    total_timesteps      | 548864      |
| train/                  |             |
|    approx_kl            | 0.004018075 |
|    clip_fraction        | 0.0282      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.12       |
|    explained_variance   | 0.971       |
|    learning_rate        | 5.27e-05    |
|    loss                 | -0.00782    |
|    n_updates            | 2670        |
|    policy_gradient_loss | -0.00156    |
|    std                  | 0.697       |
|    value_loss           | 0.00488     |
-----------------------------------------
Eval num_timesteps=550000, episode_reward=-1.03 +/- 0.06
Episode length: 300.00 +/- 0.00
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 300          |
|    mean_reward          | -1.03        |
| time/                   |              |
|    total_timesteps      | 550000       |
| train/                  |              |
|    approx_kl            | 0.0040444327 |
|    clip_fraction        | 0.0226       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.11        |
|    explained_variance   | 0.943        |
|    learning_rate        | 5.27e-05     |
|    loss                 | -0.00773     |
|    n_updates            | 2680         |
|    policy_gradient_loss | -0.00317     |
|    std                  | 0.696        |
|    value_loss           | 0.0105       |
------------------------------------------
-------------------------------
| time/              |        |
|    fps             | 632    |
|    iterations      | 269    |
|    time_elapsed    | 871    |
|    total_timesteps | 550912 |
-------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 270          |
|    time_elapsed         | 874          |
|    total_timesteps      | 552960       |
| train/                  |              |
|    approx_kl            | 0.0043239966 |
|    clip_fraction        | 0.0417       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.12        |
|    explained_variance   | 0.914        |
|    learning_rate        | 5.28e-05     |
|    loss                 | -0.0198      |
|    n_updates            | 2690         |
|    policy_gradient_loss | -0.00642     |
|    std                  | 0.698        |
|    value_loss           | 0.00145      |
------------------------------------------
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 271          |
|    time_elapsed         | 877          |
|    total_timesteps      | 555008       |
| train/                  |              |
|    approx_kl            | 0.0039063026 |
|    clip_fraction        | 0.0245       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.12        |
|    explained_variance   | 0.946        |
|    learning_rate        | 5.28e-05     |
|    loss                 | -0.0211      |
|    n_updates            | 2700         |
|    policy_gradient_loss | -0.0029      |
|    std                  | 0.699        |
|    value_loss           | 0.00129      |
------------------------------------------
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 272          |
|    time_elapsed         | 880          |
|    total_timesteps      | 557056       |
| train/                  |              |
|    approx_kl            | 0.0039579915 |
|    clip_fraction        | 0.0214       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.12        |
|    explained_variance   | 0.638        |
|    learning_rate        | 5.28e-05     |
|    loss                 | 0.0748       |
|    n_updates            | 2710         |
|    policy_gradient_loss | -0.00415     |
|    std                  | 0.699        |
|    value_loss           | 0.0475       |
------------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 632         |
|    iterations           | 273         |
|    time_elapsed         | 883         |
|    total_timesteps      | 559104      |
| train/                  |             |
|    approx_kl            | 0.004832625 |
|    clip_fraction        | 0.0356      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.12       |
|    explained_variance   | 0.785       |
|    learning_rate        | 5.28e-05    |
|    loss                 | -0.00544    |
|    n_updates            | 2720        |
|    policy_gradient_loss | -0.00572    |
|    std                  | 0.699       |
|    value_loss           | 0.0238      |
-----------------------------------------
box reached target
Eval num_timesteps=560000, episode_reward=0.23 +/- 2.45
Episode length: 276.00 +/- 48.00
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 276          |
|    mean_reward          | 0.226        |
| time/                   |              |
|    total_timesteps      | 560000       |
| train/                  |              |
|    approx_kl            | 0.0058840318 |
|    clip_fraction        | 0.0445       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.12        |
|    explained_variance   | 0.9          |
|    learning_rate        | 5.28e-05     |
|    loss                 | 0.00918      |
|    n_updates            | 2730         |
|    policy_gradient_loss | -0.00568     |
|    std                  | 0.698        |
|    value_loss           | 0.000903     |
------------------------------------------
-------------------------------
| time/              |        |
|    fps             | 632    |
|    iterations      | 274    |
|    time_elapsed    | 887    |
|    total_timesteps | 561152 |
-------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 632         |
|    iterations           | 275         |
|    time_elapsed         | 890         |
|    total_timesteps      | 563200      |
| train/                  |             |
|    approx_kl            | 0.006211907 |
|    clip_fraction        | 0.046       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.12       |
|    explained_variance   | 0.949       |
|    learning_rate        | 5.28e-05    |
|    loss                 | -0.0118     |
|    n_updates            | 2740        |
|    policy_gradient_loss | -0.00777    |
|    std                  | 0.697       |
|    value_loss           | 0.000855    |
-----------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 276          |
|    time_elapsed         | 893          |
|    total_timesteps      | 565248       |
| train/                  |              |
|    approx_kl            | 0.0053297356 |
|    clip_fraction        | 0.03         |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.11        |
|    explained_variance   | 0.936        |
|    learning_rate        | 5.28e-05     |
|    loss                 | -0.00985     |
|    n_updates            | 2750         |
|    policy_gradient_loss | -0.00343     |
|    std                  | 0.696        |
|    value_loss           | 0.000968     |
------------------------------------------
box reached target
box reached target
box reached target
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 277          |
|    time_elapsed         | 896          |
|    total_timesteps      | 567296       |
| train/                  |              |
|    approx_kl            | 0.0030772546 |
|    clip_fraction        | 0.0132       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.11        |
|    explained_variance   | 0.943        |
|    learning_rate        | 5.28e-05     |
|    loss                 | 0.000277     |
|    n_updates            | 2760         |
|    policy_gradient_loss | -0.00216     |
|    std                  | 0.696        |
|    value_loss           | 0.00267      |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 278          |
|    time_elapsed         | 899          |
|    total_timesteps      | 569344       |
| train/                  |              |
|    approx_kl            | 0.0059955795 |
|    clip_fraction        | 0.0331       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.11        |
|    explained_variance   | 0.929        |
|    learning_rate        | 5.28e-05     |
|    loss                 | 0.00836      |
|    n_updates            | 2770         |
|    policy_gradient_loss | -0.00409     |
|    std                  | 0.695        |
|    value_loss           | 0.0327       |
------------------------------------------
box reached target
box reached target
Eval num_timesteps=570000, episode_reward=-0.82 +/- 0.36
Episode length: 300.00 +/- 0.00
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 300          |
|    mean_reward          | -0.822       |
| time/                   |              |
|    total_timesteps      | 570000       |
| train/                  |              |
|    approx_kl            | 0.0040529696 |
|    clip_fraction        | 0.0181       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.11        |
|    explained_variance   | 0.923        |
|    learning_rate        | 5.28e-05     |
|    loss                 | 0.0124       |
|    n_updates            | 2780         |
|    policy_gradient_loss | -0.00318     |
|    std                  | 0.695        |
|    value_loss           | 0.00296      |
------------------------------------------
box reached target
-------------------------------
| time/              |        |
|    fps             | 632    |
|    iterations      | 279    |
|    time_elapsed    | 903    |
|    total_timesteps | 571392 |
-------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 280          |
|    time_elapsed         | 906          |
|    total_timesteps      | 573440       |
| train/                  |              |
|    approx_kl            | 0.0037786486 |
|    clip_fraction        | 0.0161       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.11        |
|    explained_variance   | 0.834        |
|    learning_rate        | 5.29e-05     |
|    loss                 | -0.00662     |
|    n_updates            | 2790         |
|    policy_gradient_loss | -0.00475     |
|    std                  | 0.691        |
|    value_loss           | 0.0674       |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 281          |
|    time_elapsed         | 909          |
|    total_timesteps      | 575488       |
| train/                  |              |
|    approx_kl            | 0.0078869015 |
|    clip_fraction        | 0.0824       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.1         |
|    explained_variance   | 0.713        |
|    learning_rate        | 5.29e-05     |
|    loss                 | 0.0296       |
|    n_updates            | 2800         |
|    policy_gradient_loss | -0.00903     |
|    std                  | 0.693        |
|    value_loss           | 0.00782      |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 282          |
|    time_elapsed         | 912          |
|    total_timesteps      | 577536       |
| train/                  |              |
|    approx_kl            | 0.0042873975 |
|    clip_fraction        | 0.0205       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.11        |
|    explained_variance   | 0.926        |
|    learning_rate        | 5.29e-05     |
|    loss                 | -0.0185      |
|    n_updates            | 2810         |
|    policy_gradient_loss | -0.00292     |
|    std                  | 0.695        |
|    value_loss           | 0.00047      |
------------------------------------------
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 283          |
|    time_elapsed         | 915          |
|    total_timesteps      | 579584       |
| train/                  |              |
|    approx_kl            | 0.0037756609 |
|    clip_fraction        | 0.023        |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.11        |
|    explained_variance   | 0.71         |
|    learning_rate        | 5.29e-05     |
|    loss                 | 0.000736     |
|    n_updates            | 2820         |
|    policy_gradient_loss | -0.00544     |
|    std                  | 0.697        |
|    value_loss           | 0.00183      |
------------------------------------------
box reached target
Eval num_timesteps=580000, episode_reward=0.25 +/- 2.51
Episode length: 278.00 +/- 44.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 278        |
|    mean_reward          | 0.254      |
| time/                   |            |
|    total_timesteps      | 580000     |
| train/                  |            |
|    approx_kl            | 0.00580688 |
|    clip_fraction        | 0.0468     |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.11      |
|    explained_variance   | 0.978      |
|    learning_rate        | 5.29e-05   |
|    loss                 | 0.000676   |
|    n_updates            | 2830       |
|    policy_gradient_loss | -0.00499   |
|    std                  | 0.695      |
|    value_loss           | 0.00373    |
----------------------------------------
box reached target
-------------------------------
| time/              |        |
|    fps             | 632    |
|    iterations      | 284    |
|    time_elapsed    | 919    |
|    total_timesteps | 581632 |
-------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 632         |
|    iterations           | 285         |
|    time_elapsed         | 922         |
|    total_timesteps      | 583680      |
| train/                  |             |
|    approx_kl            | 0.005052733 |
|    clip_fraction        | 0.0202      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.11       |
|    explained_variance   | 0.977       |
|    learning_rate        | 5.29e-05    |
|    loss                 | 0.0149      |
|    n_updates            | 2840        |
|    policy_gradient_loss | -0.00218    |
|    std                  | 0.694       |
|    value_loss           | 0.0028      |
-----------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 286          |
|    time_elapsed         | 925          |
|    total_timesteps      | 585728       |
| train/                  |              |
|    approx_kl            | 0.0048228027 |
|    clip_fraction        | 0.0255       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.11        |
|    explained_variance   | 0.929        |
|    learning_rate        | 5.29e-05     |
|    loss                 | -0.0222      |
|    n_updates            | 2850         |
|    policy_gradient_loss | -0.00498     |
|    std                  | 0.693        |
|    value_loss           | 0.000488     |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 287          |
|    time_elapsed         | 928          |
|    total_timesteps      | 587776       |
| train/                  |              |
|    approx_kl            | 0.0034747939 |
|    clip_fraction        | 0.0164       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.1         |
|    explained_variance   | 0.938        |
|    learning_rate        | 5.29e-05     |
|    loss                 | 0.00731      |
|    n_updates            | 2860         |
|    policy_gradient_loss | -0.00351     |
|    std                  | 0.692        |
|    value_loss           | 0.00273      |
------------------------------------------
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 288          |
|    time_elapsed         | 931          |
|    total_timesteps      | 589824       |
| train/                  |              |
|    approx_kl            | 0.0035285554 |
|    clip_fraction        | 0.0402       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.1         |
|    explained_variance   | 0.908        |
|    learning_rate        | 5.29e-05     |
|    loss                 | 0.00385      |
|    n_updates            | 2870         |
|    policy_gradient_loss | -0.00525     |
|    std                  | 0.692        |
|    value_loss           | 0.00187      |
------------------------------------------
Eval num_timesteps=590000, episode_reward=-0.95 +/- 0.10
Episode length: 300.00 +/- 0.00
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 300          |
|    mean_reward          | -0.95        |
| time/                   |              |
|    total_timesteps      | 590000       |
| train/                  |              |
|    approx_kl            | 0.0029058484 |
|    clip_fraction        | 0.0254       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.1         |
|    explained_variance   | 0.381        |
|    learning_rate        | 5.29e-05     |
|    loss                 | 0.00459      |
|    n_updates            | 2880         |
|    policy_gradient_loss | -0.00183     |
|    std                  | 0.689        |
|    value_loss           | 0.0239       |
------------------------------------------
-------------------------------
| time/              |        |
|    fps             | 632    |
|    iterations      | 289    |
|    time_elapsed    | 936    |
|    total_timesteps | 591872 |
-------------------------------
box reached target
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 290          |
|    time_elapsed         | 939          |
|    total_timesteps      | 593920       |
| train/                  |              |
|    approx_kl            | 0.0037608873 |
|    clip_fraction        | 0.0308       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.1         |
|    explained_variance   | 0.891        |
|    learning_rate        | 5.3e-05      |
|    loss                 | 0.009        |
|    n_updates            | 2890         |
|    policy_gradient_loss | -0.00411     |
|    std                  | 0.691        |
|    value_loss           | 0.00336      |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 291          |
|    time_elapsed         | 942          |
|    total_timesteps      | 595968       |
| train/                  |              |
|    approx_kl            | 0.0046957433 |
|    clip_fraction        | 0.0211       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.09        |
|    explained_variance   | 0.88         |
|    learning_rate        | 5.3e-05      |
|    loss                 | 0.0237       |
|    n_updates            | 2900         |
|    policy_gradient_loss | -0.005       |
|    std                  | 0.689        |
|    value_loss           | 0.0271       |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 292          |
|    time_elapsed         | 945          |
|    total_timesteps      | 598016       |
| train/                  |              |
|    approx_kl            | 0.0028208923 |
|    clip_fraction        | 0.00903      |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.09        |
|    explained_variance   | 0.912        |
|    learning_rate        | 5.3e-05      |
|    loss                 | -0.022       |
|    n_updates            | 2910         |
|    policy_gradient_loss | -0.00169     |
|    std                  | 0.689        |
|    value_loss           | 0.000777     |
------------------------------------------
box reached target
Eval num_timesteps=600000, episode_reward=0.32 +/- 2.63
Episode length: 279.80 +/- 40.40
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 280          |
|    mean_reward          | 0.317        |
| time/                   |              |
|    total_timesteps      | 600000       |
| train/                  |              |
|    approx_kl            | 0.0039506345 |
|    clip_fraction        | 0.0208       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.09        |
|    explained_variance   | 0.879        |
|    learning_rate        | 5.3e-05      |
|    loss                 | -0.0116      |
|    n_updates            | 2920         |
|    policy_gradient_loss | -0.0046      |
|    std                  | 0.691        |
|    value_loss           | 0.00436      |
------------------------------------------
-------------------------------
| time/              |        |
|    fps             | 632    |
|    iterations      | 293    |
|    time_elapsed    | 949    |
|    total_timesteps | 600064 |
-------------------------------
box reached target
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 294          |
|    time_elapsed         | 952          |
|    total_timesteps      | 602112       |
| train/                  |              |
|    approx_kl            | 0.0036424918 |
|    clip_fraction        | 0.0171       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.1         |
|    explained_variance   | 0.847        |
|    learning_rate        | 5.3e-05      |
|    loss                 | 0.00195      |
|    n_updates            | 2930         |
|    policy_gradient_loss | -0.00576     |
|    std                  | 0.692        |
|    value_loss           | 0.000942     |
------------------------------------------
box reached target
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 632         |
|    iterations           | 295         |
|    time_elapsed         | 955         |
|    total_timesteps      | 604160      |
| train/                  |             |
|    approx_kl            | 0.004403838 |
|    clip_fraction        | 0.0306      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.1        |
|    explained_variance   | 0.847       |
|    learning_rate        | 5.3e-05     |
|    loss                 | 0.0369      |
|    n_updates            | 2940        |
|    policy_gradient_loss | -0.00617    |
|    std                  | 0.694       |
|    value_loss           | 0.0322      |
-----------------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 632         |
|    iterations           | 296         |
|    time_elapsed         | 958         |
|    total_timesteps      | 606208      |
| train/                  |             |
|    approx_kl            | 0.004250572 |
|    clip_fraction        | 0.0262      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.11       |
|    explained_variance   | 0.829       |
|    learning_rate        | 5.3e-05     |
|    loss                 | 0.00465     |
|    n_updates            | 2950        |
|    policy_gradient_loss | -0.00365    |
|    std                  | 0.693       |
|    value_loss           | 0.0588      |
-----------------------------------------
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 297          |
|    time_elapsed         | 961          |
|    total_timesteps      | 608256       |
| train/                  |              |
|    approx_kl            | 0.0031485483 |
|    clip_fraction        | 0.029        |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.1         |
|    explained_variance   | 0.878        |
|    learning_rate        | 5.3e-05      |
|    loss                 | 0.012        |
|    n_updates            | 2960         |
|    policy_gradient_loss | -0.00485     |
|    std                  | 0.694        |
|    value_loss           | 0.021        |
------------------------------------------
Eval num_timesteps=610000, episode_reward=-1.05 +/- 0.09
Episode length: 300.00 +/- 0.00
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 300          |
|    mean_reward          | -1.05        |
| time/                   |              |
|    total_timesteps      | 610000       |
| train/                  |              |
|    approx_kl            | 0.0053278073 |
|    clip_fraction        | 0.0355       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.1         |
|    explained_variance   | 0.966        |
|    learning_rate        | 5.3e-05      |
|    loss                 | -0.0233      |
|    n_updates            | 2970         |
|    policy_gradient_loss | -0.00564     |
|    std                  | 0.692        |
|    value_loss           | 0.0102       |
------------------------------------------
-------------------------------
| time/              |        |
|    fps             | 632    |
|    iterations      | 298    |
|    time_elapsed    | 965    |
|    total_timesteps | 610304 |
-------------------------------
box reached target
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 299          |
|    time_elapsed         | 968          |
|    total_timesteps      | 612352       |
| train/                  |              |
|    approx_kl            | 0.0028598309 |
|    clip_fraction        | 0.0187       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.1         |
|    explained_variance   | 0.865        |
|    learning_rate        | 5.31e-05     |
|    loss                 | -0.00451     |
|    n_updates            | 2980         |
|    policy_gradient_loss | -0.00232     |
|    std                  | 0.693        |
|    value_loss           | 0.012        |
------------------------------------------
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 300          |
|    time_elapsed         | 971          |
|    total_timesteps      | 614400       |
| train/                  |              |
|    approx_kl            | 0.0042414805 |
|    clip_fraction        | 0.0228       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.1         |
|    explained_variance   | 0.921        |
|    learning_rate        | 5.31e-05     |
|    loss                 | 0.00351      |
|    n_updates            | 2990         |
|    policy_gradient_loss | -0.0049      |
|    std                  | 0.691        |
|    value_loss           | 0.0166       |
------------------------------------------
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 301          |
|    time_elapsed         | 974          |
|    total_timesteps      | 616448       |
| train/                  |              |
|    approx_kl            | 0.0040665213 |
|    clip_fraction        | 0.0217       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.1         |
|    explained_variance   | 0.954        |
|    learning_rate        | 5.31e-05     |
|    loss                 | 0.0233       |
|    n_updates            | 3000         |
|    policy_gradient_loss | -0.00189     |
|    std                  | 0.69         |
|    value_loss           | 0.0101       |
------------------------------------------
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 302          |
|    time_elapsed         | 977          |
|    total_timesteps      | 618496       |
| train/                  |              |
|    approx_kl            | 0.0053478843 |
|    clip_fraction        | 0.0389       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.09        |
|    explained_variance   | 0.959        |
|    learning_rate        | 5.31e-05     |
|    loss                 | -0.00538     |
|    n_updates            | 3010         |
|    policy_gradient_loss | -0.00497     |
|    std                  | 0.687        |
|    value_loss           | 0.0028       |
------------------------------------------
box reached target
box reached target
box reached target
Eval num_timesteps=620000, episode_reward=2.78 +/- 3.09
Episode length: 230.20 +/- 58.93
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 230          |
|    mean_reward          | 2.78         |
| time/                   |              |
|    total_timesteps      | 620000       |
| train/                  |              |
|    approx_kl            | 0.0049060574 |
|    clip_fraction        | 0.0261       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.09        |
|    explained_variance   | 0.986        |
|    learning_rate        | 5.31e-05     |
|    loss                 | 0.00384      |
|    n_updates            | 3020         |
|    policy_gradient_loss | -0.00227     |
|    std                  | 0.687        |
|    value_loss           | 0.0026       |
------------------------------------------
box reached target
-------------------------------
| time/              |        |
|    fps             | 632    |
|    iterations      | 303    |
|    time_elapsed    | 981    |
|    total_timesteps | 620544 |
-------------------------------
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 304          |
|    time_elapsed         | 984          |
|    total_timesteps      | 622592       |
| train/                  |              |
|    approx_kl            | 0.0040401304 |
|    clip_fraction        | 0.0448       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.09        |
|    explained_variance   | 0.979        |
|    learning_rate        | 5.31e-05     |
|    loss                 | 0.0126       |
|    n_updates            | 3030         |
|    policy_gradient_loss | -0.00489     |
|    std                  | 0.686        |
|    value_loss           | 0.00275      |
------------------------------------------
box reached target
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 305          |
|    time_elapsed         | 987          |
|    total_timesteps      | 624640       |
| train/                  |              |
|    approx_kl            | 0.0027420346 |
|    clip_fraction        | 0.00806      |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.08        |
|    explained_variance   | 0.891        |
|    learning_rate        | 5.31e-05     |
|    loss                 | -0.018       |
|    n_updates            | 3040         |
|    policy_gradient_loss | -0.00183     |
|    std                  | 0.687        |
|    value_loss           | 0.0311       |
------------------------------------------
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 306          |
|    time_elapsed         | 990          |
|    total_timesteps      | 626688       |
| train/                  |              |
|    approx_kl            | 0.0036813356 |
|    clip_fraction        | 0.0228       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.08        |
|    explained_variance   | 0.956        |
|    learning_rate        | 5.31e-05     |
|    loss                 | 0.00442      |
|    n_updates            | 3050         |
|    policy_gradient_loss | -0.00498     |
|    std                  | 0.683        |
|    value_loss           | 0.0151       |
------------------------------------------
box reached target
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 632         |
|    iterations           | 307         |
|    time_elapsed         | 993         |
|    total_timesteps      | 628736      |
| train/                  |             |
|    approx_kl            | 0.005536354 |
|    clip_fraction        | 0.0381      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.08       |
|    explained_variance   | 0.932       |
|    learning_rate        | 5.31e-05    |
|    loss                 | -0.0304     |
|    n_updates            | 3060        |
|    policy_gradient_loss | -0.00486    |
|    std                  | 0.686       |
|    value_loss           | 0.00604     |
-----------------------------------------
Eval num_timesteps=630000, episode_reward=-1.07 +/- 0.15
Episode length: 300.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 300         |
|    mean_reward          | -1.07       |
| time/                   |             |
|    total_timesteps      | 630000      |
| train/                  |             |
|    approx_kl            | 0.004410724 |
|    clip_fraction        | 0.0175      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.08       |
|    explained_variance   | 0.873       |
|    learning_rate        | 5.31e-05    |
|    loss                 | -0.0248     |
|    n_updates            | 3070        |
|    policy_gradient_loss | -0.00332    |
|    std                  | 0.684       |
|    value_loss           | 0.0222      |
-----------------------------------------
-------------------------------
| time/              |        |
|    fps             | 632    |
|    iterations      | 308    |
|    time_elapsed    | 997    |
|    total_timesteps | 630784 |
-------------------------------
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 309          |
|    time_elapsed         | 1000         |
|    total_timesteps      | 632832       |
| train/                  |              |
|    approx_kl            | 0.0045943237 |
|    clip_fraction        | 0.0313       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.08        |
|    explained_variance   | 0.808        |
|    learning_rate        | 5.32e-05     |
|    loss                 | 0.00174      |
|    n_updates            | 3080         |
|    policy_gradient_loss | -0.00423     |
|    std                  | 0.684        |
|    value_loss           | 0.00267      |
------------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 632         |
|    iterations           | 310         |
|    time_elapsed         | 1003        |
|    total_timesteps      | 634880      |
| train/                  |             |
|    approx_kl            | 0.005136623 |
|    clip_fraction        | 0.0365      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.08       |
|    explained_variance   | 0.963       |
|    learning_rate        | 5.32e-05    |
|    loss                 | 0.00321     |
|    n_updates            | 3090        |
|    policy_gradient_loss | -0.00417    |
|    std                  | 0.685       |
|    value_loss           | 0.0111      |
-----------------------------------------
box reached target
box reached target
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 311          |
|    time_elapsed         | 1006         |
|    total_timesteps      | 636928       |
| train/                  |              |
|    approx_kl            | 0.0060361903 |
|    clip_fraction        | 0.0494       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.08        |
|    explained_variance   | 0.884        |
|    learning_rate        | 5.32e-05     |
|    loss                 | -0.00537     |
|    n_updates            | 3100         |
|    policy_gradient_loss | -0.00501     |
|    std                  | 0.685        |
|    value_loss           | 0.00511      |
------------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 632         |
|    iterations           | 312         |
|    time_elapsed         | 1009        |
|    total_timesteps      | 638976      |
| train/                  |             |
|    approx_kl            | 0.003969862 |
|    clip_fraction        | 0.0238      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.08       |
|    explained_variance   | 0.912       |
|    learning_rate        | 5.32e-05    |
|    loss                 | -0.00131    |
|    n_updates            | 3110        |
|    policy_gradient_loss | -0.00356    |
|    std                  | 0.683       |
|    value_loss           | 0.0353      |
-----------------------------------------
box reached target
Eval num_timesteps=640000, episode_reward=0.22 +/- 2.43
Episode length: 279.20 +/- 41.60
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 279          |
|    mean_reward          | 0.217        |
| time/                   |              |
|    total_timesteps      | 640000       |
| train/                  |              |
|    approx_kl            | 0.0040974375 |
|    clip_fraction        | 0.0263       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.07        |
|    explained_variance   | 0.81         |
|    learning_rate        | 5.32e-05     |
|    loss                 | -0.00868     |
|    n_updates            | 3120         |
|    policy_gradient_loss | -0.00307     |
|    std                  | 0.682        |
|    value_loss           | 0.00214      |
------------------------------------------
-------------------------------
| time/              |        |
|    fps             | 632    |
|    iterations      | 313    |
|    time_elapsed    | 1013   |
|    total_timesteps | 641024 |
-------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 632         |
|    iterations           | 314         |
|    time_elapsed         | 1016        |
|    total_timesteps      | 643072      |
| train/                  |             |
|    approx_kl            | 0.006295818 |
|    clip_fraction        | 0.0588      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.07       |
|    explained_variance   | 0.906       |
|    learning_rate        | 5.32e-05    |
|    loss                 | -0.0245     |
|    n_updates            | 3130        |
|    policy_gradient_loss | -0.00753    |
|    std                  | 0.682       |
|    value_loss           | 0.00648     |
-----------------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 632         |
|    iterations           | 315         |
|    time_elapsed         | 1019        |
|    total_timesteps      | 645120      |
| train/                  |             |
|    approx_kl            | 0.005999522 |
|    clip_fraction        | 0.0577      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.08       |
|    explained_variance   | 0.891       |
|    learning_rate        | 5.32e-05    |
|    loss                 | -0.0121     |
|    n_updates            | 3140        |
|    policy_gradient_loss | -0.00813    |
|    std                  | 0.685       |
|    value_loss           | 0.0178      |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 632         |
|    iterations           | 316         |
|    time_elapsed         | 1022        |
|    total_timesteps      | 647168      |
| train/                  |             |
|    approx_kl            | 0.003864213 |
|    clip_fraction        | 0.0188      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.08       |
|    explained_variance   | 0.913       |
|    learning_rate        | 5.32e-05    |
|    loss                 | -0.0124     |
|    n_updates            | 3150        |
|    policy_gradient_loss | -0.00218    |
|    std                  | 0.685       |
|    value_loss           | 0.0129      |
-----------------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 632         |
|    iterations           | 317         |
|    time_elapsed         | 1025        |
|    total_timesteps      | 649216      |
| train/                  |             |
|    approx_kl            | 0.005057452 |
|    clip_fraction        | 0.0402      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.08       |
|    explained_variance   | 0.903       |
|    learning_rate        | 5.32e-05    |
|    loss                 | 0.0146      |
|    n_updates            | 3160        |
|    policy_gradient_loss | -0.00546    |
|    std                  | 0.684       |
|    value_loss           | 0.00189     |
-----------------------------------------
box reached target
Eval num_timesteps=650000, episode_reward=-0.75 +/- 0.33
Episode length: 300.00 +/- 0.00
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 300          |
|    mean_reward          | -0.745       |
| time/                   |              |
|    total_timesteps      | 650000       |
| train/                  |              |
|    approx_kl            | 0.0034532216 |
|    clip_fraction        | 0.0144       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.08        |
|    explained_variance   | 0.742        |
|    learning_rate        | 5.32e-05     |
|    loss                 | 0.00402      |
|    n_updates            | 3170         |
|    policy_gradient_loss | -0.00337     |
|    std                  | 0.682        |
|    value_loss           | 0.0166       |
------------------------------------------
-------------------------------
| time/              |        |
|    fps             | 632    |
|    iterations      | 318    |
|    time_elapsed    | 1029   |
|    total_timesteps | 651264 |
-------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 632         |
|    iterations           | 319         |
|    time_elapsed         | 1032        |
|    total_timesteps      | 653312      |
| train/                  |             |
|    approx_kl            | 0.004668629 |
|    clip_fraction        | 0.0258      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.07       |
|    explained_variance   | 0.864       |
|    learning_rate        | 5.33e-05    |
|    loss                 | -0.00708    |
|    n_updates            | 3180        |
|    policy_gradient_loss | -0.00386    |
|    std                  | 0.682       |
|    value_loss           | 0.0115      |
-----------------------------------------
box reached target
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 320          |
|    time_elapsed         | 1035         |
|    total_timesteps      | 655360       |
| train/                  |              |
|    approx_kl            | 0.0044768252 |
|    clip_fraction        | 0.0311       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.08        |
|    explained_variance   | 0.918        |
|    learning_rate        | 5.33e-05     |
|    loss                 | -0.00843     |
|    n_updates            | 3190         |
|    policy_gradient_loss | -0.00405     |
|    std                  | 0.684        |
|    value_loss           | 0.00217      |
------------------------------------------
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 321          |
|    time_elapsed         | 1038         |
|    total_timesteps      | 657408       |
| train/                  |              |
|    approx_kl            | 0.0047978177 |
|    clip_fraction        | 0.0341       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.08        |
|    explained_variance   | 0.975        |
|    learning_rate        | 5.33e-05     |
|    loss                 | -0.00358     |
|    n_updates            | 3200         |
|    policy_gradient_loss | -0.00494     |
|    std                  | 0.686        |
|    value_loss           | 0.00893      |
------------------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 632         |
|    iterations           | 322         |
|    time_elapsed         | 1042        |
|    total_timesteps      | 659456      |
| train/                  |             |
|    approx_kl            | 0.004022671 |
|    clip_fraction        | 0.0206      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.08       |
|    explained_variance   | 0.844       |
|    learning_rate        | 5.33e-05    |
|    loss                 | -0.00789    |
|    n_updates            | 3210        |
|    policy_gradient_loss | -0.00303    |
|    std                  | 0.685       |
|    value_loss           | 0.0177      |
-----------------------------------------
box reached target
Eval num_timesteps=660000, episode_reward=0.59 +/- 2.36
Episode length: 279.20 +/- 41.60
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 279         |
|    mean_reward          | 0.593       |
| time/                   |             |
|    total_timesteps      | 660000      |
| train/                  |             |
|    approx_kl            | 0.004642654 |
|    clip_fraction        | 0.0332      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.08       |
|    explained_variance   | 0.975       |
|    learning_rate        | 5.33e-05    |
|    loss                 | -0.00181    |
|    n_updates            | 3220        |
|    policy_gradient_loss | -0.00516    |
|    std                  | 0.685       |
|    value_loss           | 0.00348     |
-----------------------------------------
-------------------------------
| time/              |        |
|    fps             | 632    |
|    iterations      | 323    |
|    time_elapsed    | 1045   |
|    total_timesteps | 661504 |
-------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 632         |
|    iterations           | 324         |
|    time_elapsed         | 1049        |
|    total_timesteps      | 663552      |
| train/                  |             |
|    approx_kl            | 0.007457865 |
|    clip_fraction        | 0.0645      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.08       |
|    explained_variance   | 0.829       |
|    learning_rate        | 5.33e-05    |
|    loss                 | -0.023      |
|    n_updates            | 3230        |
|    policy_gradient_loss | -0.00739    |
|    std                  | 0.687       |
|    value_loss           | 0.00666     |
-----------------------------------------
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 325          |
|    time_elapsed         | 1052         |
|    total_timesteps      | 665600       |
| train/                  |              |
|    approx_kl            | 0.0057266583 |
|    clip_fraction        | 0.0601       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.08        |
|    explained_variance   | 0.82         |
|    learning_rate        | 5.33e-05     |
|    loss                 | 0.00161      |
|    n_updates            | 3240         |
|    policy_gradient_loss | -0.00827     |
|    std                  | 0.686        |
|    value_loss           | 0.00219      |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 326          |
|    time_elapsed         | 1055         |
|    total_timesteps      | 667648       |
| train/                  |              |
|    approx_kl            | 0.0045478973 |
|    clip_fraction        | 0.0296       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.08        |
|    explained_variance   | 0.946        |
|    learning_rate        | 5.33e-05     |
|    loss                 | -0.0134      |
|    n_updates            | 3250         |
|    policy_gradient_loss | -0.00604     |
|    std                  | 0.684        |
|    value_loss           | 0.0074       |
------------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 632         |
|    iterations           | 327         |
|    time_elapsed         | 1058        |
|    total_timesteps      | 669696      |
| train/                  |             |
|    approx_kl            | 0.004700368 |
|    clip_fraction        | 0.0403      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.08       |
|    explained_variance   | 0.878       |
|    learning_rate        | 5.33e-05    |
|    loss                 | -0.00176    |
|    n_updates            | 3260        |
|    policy_gradient_loss | -0.00412    |
|    std                  | 0.686       |
|    value_loss           | 0.00491     |
-----------------------------------------
Eval num_timesteps=670000, episode_reward=-1.06 +/- 0.11
Episode length: 300.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 300         |
|    mean_reward          | -1.06       |
| time/                   |             |
|    total_timesteps      | 670000      |
| train/                  |             |
|    approx_kl            | 0.005743867 |
|    clip_fraction        | 0.037       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.08       |
|    explained_variance   | 0.81        |
|    learning_rate        | 5.33e-05    |
|    loss                 | -0.0109     |
|    n_updates            | 3270        |
|    policy_gradient_loss | -0.00484    |
|    std                  | 0.684       |
|    value_loss           | 0.000932    |
-----------------------------------------
box reached target
box reached target
-------------------------------
| time/              |        |
|    fps             | 632    |
|    iterations      | 328    |
|    time_elapsed    | 1062   |
|    total_timesteps | 671744 |
-------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 329          |
|    time_elapsed         | 1065         |
|    total_timesteps      | 673792       |
| train/                  |              |
|    approx_kl            | 0.0041766744 |
|    clip_fraction        | 0.0317       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.08        |
|    explained_variance   | 0.882        |
|    learning_rate        | 5.34e-05     |
|    loss                 | -0.00573     |
|    n_updates            | 3280         |
|    policy_gradient_loss | -0.00626     |
|    std                  | 0.683        |
|    value_loss           | 0.0252       |
------------------------------------------
box reached target
box reached target
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 330          |
|    time_elapsed         | 1068         |
|    total_timesteps      | 675840       |
| train/                  |              |
|    approx_kl            | 0.0040356033 |
|    clip_fraction        | 0.0271       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.07        |
|    explained_variance   | 0.93         |
|    learning_rate        | 5.34e-05     |
|    loss                 | -0.0168      |
|    n_updates            | 3290         |
|    policy_gradient_loss | -0.00639     |
|    std                  | 0.682        |
|    value_loss           | 0.00356      |
------------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 632        |
|    iterations           | 331        |
|    time_elapsed         | 1071       |
|    total_timesteps      | 677888     |
| train/                  |            |
|    approx_kl            | 0.00319112 |
|    clip_fraction        | 0.0172     |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.07      |
|    explained_variance   | 0.958      |
|    learning_rate        | 5.34e-05   |
|    loss                 | -0.00714   |
|    n_updates            | 3300       |
|    policy_gradient_loss | -0.00289   |
|    std                  | 0.68       |
|    value_loss           | 0.0219     |
----------------------------------------
box reached target
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 632         |
|    iterations           | 332         |
|    time_elapsed         | 1074        |
|    total_timesteps      | 679936      |
| train/                  |             |
|    approx_kl            | 0.004599684 |
|    clip_fraction        | 0.0237      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.07       |
|    explained_variance   | 0.858       |
|    learning_rate        | 5.34e-05    |
|    loss                 | -0.0148     |
|    n_updates            | 3310        |
|    policy_gradient_loss | -0.00555    |
|    std                  | 0.681       |
|    value_loss           | 0.00175     |
-----------------------------------------
box reached target
Eval num_timesteps=680000, episode_reward=0.57 +/- 2.59
Episode length: 287.60 +/- 24.80
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 288          |
|    mean_reward          | 0.569        |
| time/                   |              |
|    total_timesteps      | 680000       |
| train/                  |              |
|    approx_kl            | 0.0041383924 |
|    clip_fraction        | 0.0188       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.06        |
|    explained_variance   | 0.976        |
|    learning_rate        | 5.34e-05     |
|    loss                 | -0.00705     |
|    n_updates            | 3320         |
|    policy_gradient_loss | -0.00519     |
|    std                  | 0.678        |
|    value_loss           | 0.00829      |
------------------------------------------
-------------------------------
| time/              |        |
|    fps             | 632    |
|    iterations      | 333    |
|    time_elapsed    | 1078   |
|    total_timesteps | 681984 |
-------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 632         |
|    iterations           | 334         |
|    time_elapsed         | 1081        |
|    total_timesteps      | 684032      |
| train/                  |             |
|    approx_kl            | 0.006165041 |
|    clip_fraction        | 0.0367      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.06       |
|    explained_variance   | 0.689       |
|    learning_rate        | 5.34e-05    |
|    loss                 | 0.00465     |
|    n_updates            | 3330        |
|    policy_gradient_loss | -0.00649    |
|    std                  | 0.676       |
|    value_loss           | 0.00174     |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 632         |
|    iterations           | 335         |
|    time_elapsed         | 1084        |
|    total_timesteps      | 686080      |
| train/                  |             |
|    approx_kl            | 0.004263494 |
|    clip_fraction        | 0.0413      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.06       |
|    explained_variance   | 0.896       |
|    learning_rate        | 5.34e-05    |
|    loss                 | -0.0198     |
|    n_updates            | 3340        |
|    policy_gradient_loss | -0.00649    |
|    std                  | 0.678       |
|    value_loss           | 0.00242     |
-----------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 336          |
|    time_elapsed         | 1087         |
|    total_timesteps      | 688128       |
| train/                  |              |
|    approx_kl            | 0.0049283495 |
|    clip_fraction        | 0.0287       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.06        |
|    explained_variance   | 0.877        |
|    learning_rate        | 5.34e-05     |
|    loss                 | -0.0334      |
|    n_updates            | 3350         |
|    policy_gradient_loss | -0.005       |
|    std                  | 0.678        |
|    value_loss           | 0.00281      |
------------------------------------------
box reached target
Eval num_timesteps=690000, episode_reward=-0.68 +/- 0.64
Episode length: 300.00 +/- 0.00
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 300          |
|    mean_reward          | -0.678       |
| time/                   |              |
|    total_timesteps      | 690000       |
| train/                  |              |
|    approx_kl            | 0.0040252046 |
|    clip_fraction        | 0.0255       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.06        |
|    explained_variance   | 0.852        |
|    learning_rate        | 5.34e-05     |
|    loss                 | -0.000641    |
|    n_updates            | 3360         |
|    policy_gradient_loss | -0.00448     |
|    std                  | 0.68         |
|    value_loss           | 0.00851      |
------------------------------------------
-------------------------------
| time/              |        |
|    fps             | 632    |
|    iterations      | 337    |
|    time_elapsed    | 1091   |
|    total_timesteps | 690176 |
-------------------------------
box reached target
box reached target
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 632         |
|    iterations           | 338         |
|    time_elapsed         | 1094        |
|    total_timesteps      | 692224      |
| train/                  |             |
|    approx_kl            | 0.005921171 |
|    clip_fraction        | 0.0355      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.06       |
|    explained_variance   | 0.748       |
|    learning_rate        | 5.35e-05    |
|    loss                 | -0.0274     |
|    n_updates            | 3370        |
|    policy_gradient_loss | -0.00299    |
|    std                  | 0.679       |
|    value_loss           | 0.0175      |
-----------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 339          |
|    time_elapsed         | 1097         |
|    total_timesteps      | 694272       |
| train/                  |              |
|    approx_kl            | 0.0043848017 |
|    clip_fraction        | 0.0374       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.06        |
|    explained_variance   | 0.984        |
|    learning_rate        | 5.35e-05     |
|    loss                 | -0.012       |
|    n_updates            | 3380         |
|    policy_gradient_loss | -0.00489     |
|    std                  | 0.677        |
|    value_loss           | 0.00571      |
------------------------------------------
box reached target
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 340          |
|    time_elapsed         | 1100         |
|    total_timesteps      | 696320       |
| train/                  |              |
|    approx_kl            | 0.0058091474 |
|    clip_fraction        | 0.0549       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.06        |
|    explained_variance   | 0.93         |
|    learning_rate        | 5.35e-05     |
|    loss                 | -0.00208     |
|    n_updates            | 3390         |
|    policy_gradient_loss | -0.00701     |
|    std                  | 0.678        |
|    value_loss           | 0.00197      |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 341          |
|    time_elapsed         | 1103         |
|    total_timesteps      | 698368       |
| train/                  |              |
|    approx_kl            | 0.0047602514 |
|    clip_fraction        | 0.0313       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.06        |
|    explained_variance   | 0.988        |
|    learning_rate        | 5.35e-05     |
|    loss                 | -0.0314      |
|    n_updates            | 3400         |
|    policy_gradient_loss | -0.00758     |
|    std                  | 0.677        |
|    value_loss           | 0.00324      |
------------------------------------------
box reached target
Eval num_timesteps=700000, episode_reward=0.41 +/- 2.63
Episode length: 288.60 +/- 22.80
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 289          |
|    mean_reward          | 0.406        |
| time/                   |              |
|    total_timesteps      | 700000       |
| train/                  |              |
|    approx_kl            | 0.0077698017 |
|    clip_fraction        | 0.0576       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.06        |
|    explained_variance   | 0.839        |
|    learning_rate        | 5.35e-05     |
|    loss                 | -0.00494     |
|    n_updates            | 3410         |
|    policy_gradient_loss | -0.00751     |
|    std                  | 0.679        |
|    value_loss           | 0.00203      |
------------------------------------------
-------------------------------
| time/              |        |
|    fps             | 632    |
|    iterations      | 342    |
|    time_elapsed    | 1107   |
|    total_timesteps | 700416 |
-------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 343          |
|    time_elapsed         | 1110         |
|    total_timesteps      | 702464       |
| train/                  |              |
|    approx_kl            | 0.0041527576 |
|    clip_fraction        | 0.0336       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.07        |
|    explained_variance   | 0.864        |
|    learning_rate        | 5.35e-05     |
|    loss                 | -0.0266      |
|    n_updates            | 3420         |
|    policy_gradient_loss | -0.00503     |
|    std                  | 0.683        |
|    value_loss           | 0.00988      |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 344          |
|    time_elapsed         | 1113         |
|    total_timesteps      | 704512       |
| train/                  |              |
|    approx_kl            | 0.0037291995 |
|    clip_fraction        | 0.0192       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.08        |
|    explained_variance   | 0.852        |
|    learning_rate        | 5.35e-05     |
|    loss                 | -0.00375     |
|    n_updates            | 3430         |
|    policy_gradient_loss | -0.00303     |
|    std                  | 0.683        |
|    value_loss           | 0.00166      |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 345          |
|    time_elapsed         | 1116         |
|    total_timesteps      | 706560       |
| train/                  |              |
|    approx_kl            | 0.0046070097 |
|    clip_fraction        | 0.0307       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.08        |
|    explained_variance   | 0.897        |
|    learning_rate        | 5.35e-05     |
|    loss                 | 0.00835      |
|    n_updates            | 3440         |
|    policy_gradient_loss | -0.0046      |
|    std                  | 0.684        |
|    value_loss           | 0.00336      |
------------------------------------------
box reached target
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 346          |
|    time_elapsed         | 1119         |
|    total_timesteps      | 708608       |
| train/                  |              |
|    approx_kl            | 0.0066562956 |
|    clip_fraction        | 0.0483       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.08        |
|    explained_variance   | 0.94         |
|    learning_rate        | 5.35e-05     |
|    loss                 | 0.00775      |
|    n_updates            | 3450         |
|    policy_gradient_loss | -0.00602     |
|    std                  | 0.683        |
|    value_loss           | 0.00338      |
------------------------------------------
box reached target
box reached target
Eval num_timesteps=710000, episode_reward=0.47 +/- 2.45
Episode length: 275.40 +/- 49.20
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 275         |
|    mean_reward          | 0.473       |
| time/                   |             |
|    total_timesteps      | 710000      |
| train/                  |             |
|    approx_kl            | 0.003656527 |
|    clip_fraction        | 0.0346      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.07       |
|    explained_variance   | 0.913       |
|    learning_rate        | 5.35e-05    |
|    loss                 | 0.0301      |
|    n_updates            | 3460        |
|    policy_gradient_loss | -0.00719    |
|    std                  | 0.682       |
|    value_loss           | 0.0277      |
-----------------------------------------
-------------------------------
| time/              |        |
|    fps             | 632    |
|    iterations      | 347    |
|    time_elapsed    | 1123   |
|    total_timesteps | 710656 |
-------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 632         |
|    iterations           | 348         |
|    time_elapsed         | 1126        |
|    total_timesteps      | 712704      |
| train/                  |             |
|    approx_kl            | 0.006084473 |
|    clip_fraction        | 0.0523      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.07       |
|    explained_variance   | 0.969       |
|    learning_rate        | 5.36e-05    |
|    loss                 | 0.00144     |
|    n_updates            | 3470        |
|    policy_gradient_loss | -0.00599    |
|    std                  | 0.683       |
|    value_loss           | 0.00777     |
-----------------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 632         |
|    iterations           | 349         |
|    time_elapsed         | 1129        |
|    total_timesteps      | 714752      |
| train/                  |             |
|    approx_kl            | 0.004471682 |
|    clip_fraction        | 0.0259      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.08       |
|    explained_variance   | 0.813       |
|    learning_rate        | 5.36e-05    |
|    loss                 | -0.00436    |
|    n_updates            | 3480        |
|    policy_gradient_loss | -0.00585    |
|    std                  | 0.684       |
|    value_loss           | 0.00113     |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 632         |
|    iterations           | 350         |
|    time_elapsed         | 1132        |
|    total_timesteps      | 716800      |
| train/                  |             |
|    approx_kl            | 0.005619429 |
|    clip_fraction        | 0.0394      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.08       |
|    explained_variance   | 0.945       |
|    learning_rate        | 5.36e-05    |
|    loss                 | 0.00249     |
|    n_updates            | 3490        |
|    policy_gradient_loss | -0.00492    |
|    std                  | 0.686       |
|    value_loss           | 0.00632     |
-----------------------------------------
box reached target
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 351          |
|    time_elapsed         | 1135         |
|    total_timesteps      | 718848       |
| train/                  |              |
|    approx_kl            | 0.0036861417 |
|    clip_fraction        | 0.0219       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.08        |
|    explained_variance   | 0.925        |
|    learning_rate        | 5.36e-05     |
|    loss                 | -0.0215      |
|    n_updates            | 3500         |
|    policy_gradient_loss | -0.003       |
|    std                  | 0.685        |
|    value_loss           | 0.00243      |
------------------------------------------
Eval num_timesteps=720000, episode_reward=-1.01 +/- 0.02
Episode length: 300.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 300         |
|    mean_reward          | -1.01       |
| time/                   |             |
|    total_timesteps      | 720000      |
| train/                  |             |
|    approx_kl            | 0.003431141 |
|    clip_fraction        | 0.0203      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.08       |
|    explained_variance   | 0.838       |
|    learning_rate        | 5.36e-05    |
|    loss                 | 0.0139      |
|    n_updates            | 3510        |
|    policy_gradient_loss | -0.00209    |
|    std                  | 0.685       |
|    value_loss           | 0.0492      |
-----------------------------------------
-------------------------------
| time/              |        |
|    fps             | 632    |
|    iterations      | 352    |
|    time_elapsed    | 1139   |
|    total_timesteps | 720896 |
-------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 632         |
|    iterations           | 353         |
|    time_elapsed         | 1142        |
|    total_timesteps      | 722944      |
| train/                  |             |
|    approx_kl            | 0.005122382 |
|    clip_fraction        | 0.0352      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.08       |
|    explained_variance   | 0.934       |
|    learning_rate        | 5.36e-05    |
|    loss                 | -0.00176    |
|    n_updates            | 3520        |
|    policy_gradient_loss | -0.00554    |
|    std                  | 0.688       |
|    value_loss           | 0.00405     |
-----------------------------------------
box reached target
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 354          |
|    time_elapsed         | 1145         |
|    total_timesteps      | 724992       |
| train/                  |              |
|    approx_kl            | 0.0041957553 |
|    clip_fraction        | 0.0196       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.09        |
|    explained_variance   | 0.859        |
|    learning_rate        | 5.36e-05     |
|    loss                 | 0.0245       |
|    n_updates            | 3530         |
|    policy_gradient_loss | -0.00241     |
|    std                  | 0.689        |
|    value_loss           | 0.0244       |
------------------------------------------
box reached target
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 632         |
|    iterations           | 355         |
|    time_elapsed         | 1149        |
|    total_timesteps      | 727040      |
| train/                  |             |
|    approx_kl            | 0.005265633 |
|    clip_fraction        | 0.0417      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.09       |
|    explained_variance   | 0.958       |
|    learning_rate        | 5.36e-05    |
|    loss                 | -0.0118     |
|    n_updates            | 3540        |
|    policy_gradient_loss | -0.00538    |
|    std                  | 0.685       |
|    value_loss           | 0.0152      |
-----------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 632       |
|    iterations           | 356       |
|    time_elapsed         | 1152      |
|    total_timesteps      | 729088    |
| train/                  |           |
|    approx_kl            | 0.0042043 |
|    clip_fraction        | 0.0242    |
|    clip_range           | 0.2       |
|    entropy_loss         | -2.08     |
|    explained_variance   | 0.95      |
|    learning_rate        | 5.36e-05  |
|    loss                 | -0.00149  |
|    n_updates            | 3550      |
|    policy_gradient_loss | -0.003    |
|    std                  | 0.686     |
|    value_loss           | 0.0134    |
---------------------------------------
box reached target
Eval num_timesteps=730000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 300          |
|    mean_reward          | -1           |
| time/                   |              |
|    total_timesteps      | 730000       |
| train/                  |              |
|    approx_kl            | 0.0042898124 |
|    clip_fraction        | 0.0455       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.08        |
|    explained_variance   | 0.919        |
|    learning_rate        | 5.36e-05     |
|    loss                 | -0.00829     |
|    n_updates            | 3560         |
|    policy_gradient_loss | -0.00673     |
|    std                  | 0.686        |
|    value_loss           | 0.0177       |
------------------------------------------
box reached target
-------------------------------
| time/              |        |
|    fps             | 632    |
|    iterations      | 357    |
|    time_elapsed    | 1156   |
|    total_timesteps | 731136 |
-------------------------------
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 358          |
|    time_elapsed         | 1159         |
|    total_timesteps      | 733184       |
| train/                  |              |
|    approx_kl            | 0.0062175747 |
|    clip_fraction        | 0.0541       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.08        |
|    explained_variance   | 0.976        |
|    learning_rate        | 5.37e-05     |
|    loss                 | 0.00415      |
|    n_updates            | 3570         |
|    policy_gradient_loss | -0.00455     |
|    std                  | 0.687        |
|    value_loss           | 0.0121       |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 359          |
|    time_elapsed         | 1162         |
|    total_timesteps      | 735232       |
| train/                  |              |
|    approx_kl            | 0.0042906506 |
|    clip_fraction        | 0.02         |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.09        |
|    explained_variance   | 0.988        |
|    learning_rate        | 5.37e-05     |
|    loss                 | -0.0217      |
|    n_updates            | 3580         |
|    policy_gradient_loss | -0.0034      |
|    std                  | 0.687        |
|    value_loss           | 0.00287      |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 360          |
|    time_elapsed         | 1165         |
|    total_timesteps      | 737280       |
| train/                  |              |
|    approx_kl            | 0.0046557565 |
|    clip_fraction        | 0.0329       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.09        |
|    explained_variance   | 0.791        |
|    learning_rate        | 5.37e-05     |
|    loss                 | -0.0138      |
|    n_updates            | 3590         |
|    policy_gradient_loss | -0.0028      |
|    std                  | 0.687        |
|    value_loss           | 0.00644      |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 361          |
|    time_elapsed         | 1168         |
|    total_timesteps      | 739328       |
| train/                  |              |
|    approx_kl            | 0.0046886695 |
|    clip_fraction        | 0.0267       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.09        |
|    explained_variance   | 0.824        |
|    learning_rate        | 5.37e-05     |
|    loss                 | -0.00033     |
|    n_updates            | 3600         |
|    policy_gradient_loss | -0.00403     |
|    std                  | 0.688        |
|    value_loss           | 0.0113       |
------------------------------------------
box reached target
Eval num_timesteps=740000, episode_reward=-0.45 +/- 0.82
Episode length: 300.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 300         |
|    mean_reward          | -0.448      |
| time/                   |             |
|    total_timesteps      | 740000      |
| train/                  |             |
|    approx_kl            | 0.004634972 |
|    clip_fraction        | 0.0417      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.09       |
|    explained_variance   | 0.886       |
|    learning_rate        | 5.37e-05    |
|    loss                 | -0.0034     |
|    n_updates            | 3610        |
|    policy_gradient_loss | -0.00448    |
|    std                  | 0.69        |
|    value_loss           | 0.00136     |
-----------------------------------------
box reached target
-------------------------------
| time/              |        |
|    fps             | 632    |
|    iterations      | 362    |
|    time_elapsed    | 1172   |
|    total_timesteps | 741376 |
-------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 632         |
|    iterations           | 363         |
|    time_elapsed         | 1175        |
|    total_timesteps      | 743424      |
| train/                  |             |
|    approx_kl            | 0.004154235 |
|    clip_fraction        | 0.0297      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.09       |
|    explained_variance   | 0.977       |
|    learning_rate        | 5.37e-05    |
|    loss                 | 0.00942     |
|    n_updates            | 3620        |
|    policy_gradient_loss | -0.00648    |
|    std                  | 0.69        |
|    value_loss           | 0.00518     |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 632         |
|    iterations           | 364         |
|    time_elapsed         | 1178        |
|    total_timesteps      | 745472      |
| train/                  |             |
|    approx_kl            | 0.004601186 |
|    clip_fraction        | 0.0284      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.09       |
|    explained_variance   | 0.917       |
|    learning_rate        | 5.37e-05    |
|    loss                 | -0.0298     |
|    n_updates            | 3630        |
|    policy_gradient_loss | -0.00371    |
|    std                  | 0.689       |
|    value_loss           | 0.00258     |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 632         |
|    iterations           | 365         |
|    time_elapsed         | 1181        |
|    total_timesteps      | 747520      |
| train/                  |             |
|    approx_kl            | 0.004440481 |
|    clip_fraction        | 0.0351      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.09       |
|    explained_variance   | 0.94        |
|    learning_rate        | 5.37e-05    |
|    loss                 | -0.00159    |
|    n_updates            | 3640        |
|    policy_gradient_loss | -0.00422    |
|    std                  | 0.688       |
|    value_loss           | 0.0021      |
-----------------------------------------
box reached target
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 366          |
|    time_elapsed         | 1184         |
|    total_timesteps      | 749568       |
| train/                  |              |
|    approx_kl            | 0.0029835454 |
|    clip_fraction        | 0.0189       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.09        |
|    explained_variance   | 0.903        |
|    learning_rate        | 5.37e-05     |
|    loss                 | -0.0184      |
|    n_updates            | 3650         |
|    policy_gradient_loss | -0.00317     |
|    std                  | 0.689        |
|    value_loss           | 0.0013       |
------------------------------------------
Eval num_timesteps=750000, episode_reward=-0.72 +/- 0.56
Episode length: 300.00 +/- 0.00
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 300          |
|    mean_reward          | -0.72        |
| time/                   |              |
|    total_timesteps      | 750000       |
| train/                  |              |
|    approx_kl            | 0.0054015694 |
|    clip_fraction        | 0.0446       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.09        |
|    explained_variance   | 0.965        |
|    learning_rate        | 5.37e-05     |
|    loss                 | 0.0214       |
|    n_updates            | 3660         |
|    policy_gradient_loss | -0.00838     |
|    std                  | 0.688        |
|    value_loss           | 0.0077       |
------------------------------------------
box reached target
-------------------------------
| time/              |        |
|    fps             | 632    |
|    iterations      | 367    |
|    time_elapsed    | 1188   |
|    total_timesteps | 751616 |
-------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 632         |
|    iterations           | 368         |
|    time_elapsed         | 1191        |
|    total_timesteps      | 753664      |
| train/                  |             |
|    approx_kl            | 0.004956445 |
|    clip_fraction        | 0.029       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.09       |
|    explained_variance   | 0.504       |
|    learning_rate        | 5.38e-05    |
|    loss                 | 0.0002      |
|    n_updates            | 3670        |
|    policy_gradient_loss | -0.00467    |
|    std                  | 0.687       |
|    value_loss           | 0.0325      |
-----------------------------------------
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 369          |
|    time_elapsed         | 1194         |
|    total_timesteps      | 755712       |
| train/                  |              |
|    approx_kl            | 0.0039019694 |
|    clip_fraction        | 0.0232       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.09        |
|    explained_variance   | 0.877        |
|    learning_rate        | 5.38e-05     |
|    loss                 | -0.00716     |
|    n_updates            | 3680         |
|    policy_gradient_loss | -0.00594     |
|    std                  | 0.689        |
|    value_loss           | 0.00386      |
------------------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 632         |
|    iterations           | 370         |
|    time_elapsed         | 1197        |
|    total_timesteps      | 757760      |
| train/                  |             |
|    approx_kl            | 0.005600799 |
|    clip_fraction        | 0.0423      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.09       |
|    explained_variance   | 0.943       |
|    learning_rate        | 5.38e-05    |
|    loss                 | 0.0154      |
|    n_updates            | 3690        |
|    policy_gradient_loss | -0.00303    |
|    std                  | 0.687       |
|    value_loss           | 0.00653     |
-----------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 371          |
|    time_elapsed         | 1200         |
|    total_timesteps      | 759808       |
| train/                  |              |
|    approx_kl            | 0.0066335853 |
|    clip_fraction        | 0.0681       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.09        |
|    explained_variance   | 0.907        |
|    learning_rate        | 5.38e-05     |
|    loss                 | 0.00565      |
|    n_updates            | 3700         |
|    policy_gradient_loss | -0.00698     |
|    std                  | 0.688        |
|    value_loss           | 0.0209       |
------------------------------------------
Eval num_timesteps=760000, episode_reward=-0.64 +/- 0.71
Episode length: 300.00 +/- 0.00
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 300          |
|    mean_reward          | -0.643       |
| time/                   |              |
|    total_timesteps      | 760000       |
| train/                  |              |
|    approx_kl            | 0.0045169173 |
|    clip_fraction        | 0.0292       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.09        |
|    explained_variance   | 0.781        |
|    learning_rate        | 5.38e-05     |
|    loss                 | 0.00116      |
|    n_updates            | 3710         |
|    policy_gradient_loss | -0.00399     |
|    std                  | 0.688        |
|    value_loss           | 0.00249      |
------------------------------------------
-------------------------------
| time/              |        |
|    fps             | 632    |
|    iterations      | 372    |
|    time_elapsed    | 1204   |
|    total_timesteps | 761856 |
-------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 632         |
|    iterations           | 373         |
|    time_elapsed         | 1207        |
|    total_timesteps      | 763904      |
| train/                  |             |
|    approx_kl            | 0.005712818 |
|    clip_fraction        | 0.0513      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.09       |
|    explained_variance   | 0.928       |
|    learning_rate        | 5.38e-05    |
|    loss                 | 0.0342      |
|    n_updates            | 3720        |
|    policy_gradient_loss | -0.00489    |
|    std                  | 0.69        |
|    value_loss           | 0.00191     |
-----------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 374          |
|    time_elapsed         | 1210         |
|    total_timesteps      | 765952       |
| train/                  |              |
|    approx_kl            | 0.0035348167 |
|    clip_fraction        | 0.0191       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.1         |
|    explained_variance   | 0.912        |
|    learning_rate        | 5.38e-05     |
|    loss                 | -0.0157      |
|    n_updates            | 3730         |
|    policy_gradient_loss | -0.0053      |
|    std                  | 0.691        |
|    value_loss           | 0.00181      |
------------------------------------------
box reached target
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 632         |
|    iterations           | 375         |
|    time_elapsed         | 1213        |
|    total_timesteps      | 768000      |
| train/                  |             |
|    approx_kl            | 0.004750034 |
|    clip_fraction        | 0.0315      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.1        |
|    explained_variance   | 0.888       |
|    learning_rate        | 5.38e-05    |
|    loss                 | 0.00245     |
|    n_updates            | 3740        |
|    policy_gradient_loss | -0.00622    |
|    std                  | 0.692       |
|    value_loss           | 0.000787    |
-----------------------------------------
box reached target
Eval num_timesteps=770000, episode_reward=0.27 +/- 2.54
Episode length: 275.60 +/- 48.80
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 276          |
|    mean_reward          | 0.268        |
| time/                   |              |
|    total_timesteps      | 770000       |
| train/                  |              |
|    approx_kl            | 0.0027241968 |
|    clip_fraction        | 0.0169       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.1         |
|    explained_variance   | 0.878        |
|    learning_rate        | 5.38e-05     |
|    loss                 | -0.00248     |
|    n_updates            | 3750         |
|    policy_gradient_loss | -0.0029      |
|    std                  | 0.688        |
|    value_loss           | 0.0172       |
------------------------------------------
-------------------------------
| time/              |        |
|    fps             | 632    |
|    iterations      | 376    |
|    time_elapsed    | 1217   |
|    total_timesteps | 770048 |
-------------------------------
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 377          |
|    time_elapsed         | 1220         |
|    total_timesteps      | 772096       |
| train/                  |              |
|    approx_kl            | 0.0047165435 |
|    clip_fraction        | 0.0264       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.09        |
|    explained_variance   | 0.868        |
|    learning_rate        | 5.39e-05     |
|    loss                 | -0.0112      |
|    n_updates            | 3760         |
|    policy_gradient_loss | -0.00422     |
|    std                  | 0.69         |
|    value_loss           | 0.00109      |
------------------------------------------
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 378          |
|    time_elapsed         | 1223         |
|    total_timesteps      | 774144       |
| train/                  |              |
|    approx_kl            | 0.0040943446 |
|    clip_fraction        | 0.0251       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.09        |
|    explained_variance   | 0.962        |
|    learning_rate        | 5.39e-05     |
|    loss                 | -0.0076      |
|    n_updates            | 3770         |
|    policy_gradient_loss | -0.00459     |
|    std                  | 0.69         |
|    value_loss           | 0.00586      |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 379          |
|    time_elapsed         | 1226         |
|    total_timesteps      | 776192       |
| train/                  |              |
|    approx_kl            | 0.0036370659 |
|    clip_fraction        | 0.0222       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.1         |
|    explained_variance   | 0.907        |
|    learning_rate        | 5.39e-05     |
|    loss                 | -0.0202      |
|    n_updates            | 3780         |
|    policy_gradient_loss | -0.00513     |
|    std                  | 0.693        |
|    value_loss           | 0.0142       |
------------------------------------------
box reached target
box reached target
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 632         |
|    iterations           | 380         |
|    time_elapsed         | 1229        |
|    total_timesteps      | 778240      |
| train/                  |             |
|    approx_kl            | 0.004368647 |
|    clip_fraction        | 0.0244      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.1        |
|    explained_variance   | 0.937       |
|    learning_rate        | 5.39e-05    |
|    loss                 | -0.00323    |
|    n_updates            | 3790        |
|    policy_gradient_loss | -0.00572    |
|    std                  | 0.694       |
|    value_loss           | 0.00194     |
-----------------------------------------
Eval num_timesteps=780000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 300          |
|    mean_reward          | -1           |
| time/                   |              |
|    total_timesteps      | 780000       |
| train/                  |              |
|    approx_kl            | 0.0040639346 |
|    clip_fraction        | 0.023        |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.11        |
|    explained_variance   | 0.925        |
|    learning_rate        | 5.39e-05     |
|    loss                 | -0.00133     |
|    n_updates            | 3800         |
|    policy_gradient_loss | -0.00401     |
|    std                  | 0.694        |
|    value_loss           | 0.0261       |
------------------------------------------
-------------------------------
| time/              |        |
|    fps             | 632    |
|    iterations      | 381    |
|    time_elapsed    | 1233   |
|    total_timesteps | 780288 |
-------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 632       |
|    iterations           | 382       |
|    time_elapsed         | 1236      |
|    total_timesteps      | 782336    |
| train/                  |           |
|    approx_kl            | 0.0056051 |
|    clip_fraction        | 0.0415    |
|    clip_range           | 0.2       |
|    entropy_loss         | -2.11     |
|    explained_variance   | 0.815     |
|    learning_rate        | 5.39e-05  |
|    loss                 | -0.000186 |
|    n_updates            | 3810      |
|    policy_gradient_loss | -0.00484  |
|    std                  | 0.696     |
|    value_loss           | 0.00504   |
---------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 632         |
|    iterations           | 383         |
|    time_elapsed         | 1240        |
|    total_timesteps      | 784384      |
| train/                  |             |
|    approx_kl            | 0.005287283 |
|    clip_fraction        | 0.0289      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.11       |
|    explained_variance   | 0.879       |
|    learning_rate        | 5.39e-05    |
|    loss                 | -0.0285     |
|    n_updates            | 3820        |
|    policy_gradient_loss | -0.00367    |
|    std                  | 0.694       |
|    value_loss           | 0.011       |
-----------------------------------------
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 384          |
|    time_elapsed         | 1243         |
|    total_timesteps      | 786432       |
| train/                  |              |
|    approx_kl            | 0.0047714286 |
|    clip_fraction        | 0.0231       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.11        |
|    explained_variance   | 0.915        |
|    learning_rate        | 5.39e-05     |
|    loss                 | -0.00736     |
|    n_updates            | 3830         |
|    policy_gradient_loss | -0.00429     |
|    std                  | 0.694        |
|    value_loss           | 0.00119      |
------------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 632         |
|    iterations           | 385         |
|    time_elapsed         | 1246        |
|    total_timesteps      | 788480      |
| train/                  |             |
|    approx_kl            | 0.004708614 |
|    clip_fraction        | 0.0376      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.1        |
|    explained_variance   | 0.968       |
|    learning_rate        | 5.39e-05    |
|    loss                 | -0.014      |
|    n_updates            | 3840        |
|    policy_gradient_loss | -0.00447    |
|    std                  | 0.693       |
|    value_loss           | 0.00237     |
-----------------------------------------
box reached target
Eval num_timesteps=790000, episode_reward=0.31 +/- 2.63
Episode length: 294.00 +/- 12.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 294         |
|    mean_reward          | 0.314       |
| time/                   |             |
|    total_timesteps      | 790000      |
| train/                  |             |
|    approx_kl            | 0.003962977 |
|    clip_fraction        | 0.0324      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.11       |
|    explained_variance   | 0.769       |
|    learning_rate        | 5.39e-05    |
|    loss                 | -0.0167     |
|    n_updates            | 3850        |
|    policy_gradient_loss | -0.00387    |
|    std                  | 0.695       |
|    value_loss           | 0.0132      |
-----------------------------------------
-------------------------------
| time/              |        |
|    fps             | 632    |
|    iterations      | 386    |
|    time_elapsed    | 1250   |
|    total_timesteps | 790528 |
-------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 632         |
|    iterations           | 387         |
|    time_elapsed         | 1253        |
|    total_timesteps      | 792576      |
| train/                  |             |
|    approx_kl            | 0.003641439 |
|    clip_fraction        | 0.0221      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.11       |
|    explained_variance   | 0.874       |
|    learning_rate        | 5.4e-05     |
|    loss                 | -0.00491    |
|    n_updates            | 3860        |
|    policy_gradient_loss | -0.00325    |
|    std                  | 0.697       |
|    value_loss           | 0.00231     |
-----------------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 632         |
|    iterations           | 388         |
|    time_elapsed         | 1256        |
|    total_timesteps      | 794624      |
| train/                  |             |
|    approx_kl            | 0.005820596 |
|    clip_fraction        | 0.0394      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.11       |
|    explained_variance   | 0.911       |
|    learning_rate        | 5.4e-05     |
|    loss                 | 0.015       |
|    n_updates            | 3870        |
|    policy_gradient_loss | -0.00535    |
|    std                  | 0.696       |
|    value_loss           | 0.0134      |
-----------------------------------------
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 389          |
|    time_elapsed         | 1259         |
|    total_timesteps      | 796672       |
| train/                  |              |
|    approx_kl            | 0.0077663073 |
|    clip_fraction        | 0.0523       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.11        |
|    explained_variance   | 0.943        |
|    learning_rate        | 5.4e-05      |
|    loss                 | -0.00288     |
|    n_updates            | 3880         |
|    policy_gradient_loss | -0.00579     |
|    std                  | 0.693        |
|    value_loss           | 0.00737      |
------------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 632         |
|    iterations           | 390         |
|    time_elapsed         | 1262        |
|    total_timesteps      | 798720      |
| train/                  |             |
|    approx_kl            | 0.005782543 |
|    clip_fraction        | 0.0423      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.1        |
|    explained_variance   | 0.987       |
|    learning_rate        | 5.4e-05     |
|    loss                 | -0.0159     |
|    n_updates            | 3890        |
|    policy_gradient_loss | -0.00632    |
|    std                  | 0.691       |
|    value_loss           | 0.00215     |
-----------------------------------------
box reached target
Eval num_timesteps=800000, episode_reward=-0.61 +/- 0.57
Episode length: 300.00 +/- 0.00
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 300          |
|    mean_reward          | -0.611       |
| time/                   |              |
|    total_timesteps      | 800000       |
| train/                  |              |
|    approx_kl            | 0.0063674487 |
|    clip_fraction        | 0.0396       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.1         |
|    explained_variance   | 0.749        |
|    learning_rate        | 5.4e-05      |
|    loss                 | -0.0223      |
|    n_updates            | 3900         |
|    policy_gradient_loss | -0.00517     |
|    std                  | 0.69         |
|    value_loss           | 0.00149      |
------------------------------------------
-------------------------------
| time/              |        |
|    fps             | 632    |
|    iterations      | 391    |
|    time_elapsed    | 1266   |
|    total_timesteps | 800768 |
-------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 632         |
|    iterations           | 392         |
|    time_elapsed         | 1269        |
|    total_timesteps      | 802816      |
| train/                  |             |
|    approx_kl            | 0.005098592 |
|    clip_fraction        | 0.0257      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.1        |
|    explained_variance   | 0.754       |
|    learning_rate        | 5.4e-05     |
|    loss                 | 0.00907     |
|    n_updates            | 3910        |
|    policy_gradient_loss | -0.00281    |
|    std                  | 0.69        |
|    value_loss           | 0.0548      |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 632         |
|    iterations           | 393         |
|    time_elapsed         | 1272        |
|    total_timesteps      | 804864      |
| train/                  |             |
|    approx_kl            | 0.003328986 |
|    clip_fraction        | 0.0181      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.1        |
|    explained_variance   | 0.872       |
|    learning_rate        | 5.4e-05     |
|    loss                 | -0.0223     |
|    n_updates            | 3920        |
|    policy_gradient_loss | -0.00428    |
|    std                  | 0.692       |
|    value_loss           | 0.00281     |
-----------------------------------------
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 394          |
|    time_elapsed         | 1275         |
|    total_timesteps      | 806912       |
| train/                  |              |
|    approx_kl            | 0.0033349758 |
|    clip_fraction        | 0.0184       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.1         |
|    explained_variance   | 0.838        |
|    learning_rate        | 5.4e-05      |
|    loss                 | 8.37e-05     |
|    n_updates            | 3930         |
|    policy_gradient_loss | -0.00426     |
|    std                  | 0.692        |
|    value_loss           | 0.00525      |
------------------------------------------
box reached target
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 632         |
|    iterations           | 395         |
|    time_elapsed         | 1278        |
|    total_timesteps      | 808960      |
| train/                  |             |
|    approx_kl            | 0.005276762 |
|    clip_fraction        | 0.0256      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.1        |
|    explained_variance   | 0.936       |
|    learning_rate        | 5.4e-05     |
|    loss                 | 0.0095      |
|    n_updates            | 3940        |
|    policy_gradient_loss | -0.00246    |
|    std                  | 0.692       |
|    value_loss           | 0.00713     |
-----------------------------------------
box reached target
box reached target
Eval num_timesteps=810000, episode_reward=0.23 +/- 2.46
Episode length: 275.20 +/- 49.60
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 275         |
|    mean_reward          | 0.232       |
| time/                   |             |
|    total_timesteps      | 810000      |
| train/                  |             |
|    approx_kl            | 0.004617051 |
|    clip_fraction        | 0.0144      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.1        |
|    explained_variance   | 0.487       |
|    learning_rate        | 5.4e-05     |
|    loss                 | 0.039       |
|    n_updates            | 3950        |
|    policy_gradient_loss | -0.00268    |
|    std                  | 0.69        |
|    value_loss           | 0.0771      |
-----------------------------------------
-------------------------------
| time/              |        |
|    fps             | 632    |
|    iterations      | 396    |
|    time_elapsed    | 1282   |
|    total_timesteps | 811008 |
-------------------------------
box reached target
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 397          |
|    time_elapsed         | 1285         |
|    total_timesteps      | 813056       |
| train/                  |              |
|    approx_kl            | 0.0049662897 |
|    clip_fraction        | 0.0312       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.09        |
|    explained_variance   | 0.886        |
|    learning_rate        | 5.41e-05     |
|    loss                 | 0.0292       |
|    n_updates            | 3960         |
|    policy_gradient_loss | -0.0037      |
|    std                  | 0.689        |
|    value_loss           | 0.0161       |
------------------------------------------
box reached target
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 398          |
|    time_elapsed         | 1288         |
|    total_timesteps      | 815104       |
| train/                  |              |
|    approx_kl            | 0.0050175088 |
|    clip_fraction        | 0.0348       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.09        |
|    explained_variance   | 0.845        |
|    learning_rate        | 5.41e-05     |
|    loss                 | 0.00747      |
|    n_updates            | 3970         |
|    policy_gradient_loss | -0.00566     |
|    std                  | 0.689        |
|    value_loss           | 0.0513       |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 399          |
|    time_elapsed         | 1291         |
|    total_timesteps      | 817152       |
| train/                  |              |
|    approx_kl            | 0.0025179517 |
|    clip_fraction        | 0.00947      |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.09        |
|    explained_variance   | 0.908        |
|    learning_rate        | 5.41e-05     |
|    loss                 | 0.000312     |
|    n_updates            | 3980         |
|    policy_gradient_loss | -0.00148     |
|    std                  | 0.691        |
|    value_loss           | 0.0197       |
------------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 632         |
|    iterations           | 400         |
|    time_elapsed         | 1294        |
|    total_timesteps      | 819200      |
| train/                  |             |
|    approx_kl            | 0.004789566 |
|    clip_fraction        | 0.0337      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.1        |
|    explained_variance   | 0.856       |
|    learning_rate        | 5.41e-05    |
|    loss                 | -0.007      |
|    n_updates            | 3990        |
|    policy_gradient_loss | -0.00587    |
|    std                  | 0.692       |
|    value_loss           | 0.00421     |
-----------------------------------------
box reached target
Eval num_timesteps=820000, episode_reward=0.33 +/- 2.66
Episode length: 281.20 +/- 37.60
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 281          |
|    mean_reward          | 0.33         |
| time/                   |              |
|    total_timesteps      | 820000       |
| train/                  |              |
|    approx_kl            | 0.0041550742 |
|    clip_fraction        | 0.0237       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.1         |
|    explained_variance   | 0.844        |
|    learning_rate        | 5.41e-05     |
|    loss                 | 0.00961      |
|    n_updates            | 4000         |
|    policy_gradient_loss | -0.00396     |
|    std                  | 0.695        |
|    value_loss           | 0.0129       |
------------------------------------------
-------------------------------
| time/              |        |
|    fps             | 632    |
|    iterations      | 401    |
|    time_elapsed    | 1298   |
|    total_timesteps | 821248 |
-------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 632         |
|    iterations           | 402         |
|    time_elapsed         | 1301        |
|    total_timesteps      | 823296      |
| train/                  |             |
|    approx_kl            | 0.004249937 |
|    clip_fraction        | 0.0309      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.11       |
|    explained_variance   | 0.877       |
|    learning_rate        | 5.41e-05    |
|    loss                 | -0.016      |
|    n_updates            | 4010        |
|    policy_gradient_loss | -0.00429    |
|    std                  | 0.696       |
|    value_loss           | 0.00468     |
-----------------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 632         |
|    iterations           | 403         |
|    time_elapsed         | 1304        |
|    total_timesteps      | 825344      |
| train/                  |             |
|    approx_kl            | 0.005181699 |
|    clip_fraction        | 0.0381      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.11       |
|    explained_variance   | 0.846       |
|    learning_rate        | 5.41e-05    |
|    loss                 | 0.00279     |
|    n_updates            | 4020        |
|    policy_gradient_loss | -0.00517    |
|    std                  | 0.696       |
|    value_loss           | 0.0289      |
-----------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 404          |
|    time_elapsed         | 1307         |
|    total_timesteps      | 827392       |
| train/                  |              |
|    approx_kl            | 0.0050029405 |
|    clip_fraction        | 0.0314       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.11        |
|    explained_variance   | 0.873        |
|    learning_rate        | 5.41e-05     |
|    loss                 | 0.0151       |
|    n_updates            | 4030         |
|    policy_gradient_loss | -0.00519     |
|    std                  | 0.694        |
|    value_loss           | 0.00998      |
------------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 632         |
|    iterations           | 405         |
|    time_elapsed         | 1310        |
|    total_timesteps      | 829440      |
| train/                  |             |
|    approx_kl            | 0.004956673 |
|    clip_fraction        | 0.0405      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.11       |
|    explained_variance   | 0.839       |
|    learning_rate        | 5.41e-05    |
|    loss                 | -0.0145     |
|    n_updates            | 4040        |
|    policy_gradient_loss | -0.00596    |
|    std                  | 0.697       |
|    value_loss           | 0.00109     |
-----------------------------------------
box reached target
box reached target
Eval num_timesteps=830000, episode_reward=1.62 +/- 3.21
Episode length: 262.00 +/- 46.58
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 262         |
|    mean_reward          | 1.62        |
| time/                   |             |
|    total_timesteps      | 830000      |
| train/                  |             |
|    approx_kl            | 0.004612847 |
|    clip_fraction        | 0.0329      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.11       |
|    explained_variance   | 0.778       |
|    learning_rate        | 5.41e-05    |
|    loss                 | 0.00134     |
|    n_updates            | 4050        |
|    policy_gradient_loss | -0.00592    |
|    std                  | 0.694       |
|    value_loss           | 0.00134     |
-----------------------------------------
-------------------------------
| time/              |        |
|    fps             | 632    |
|    iterations      | 406    |
|    time_elapsed    | 1314   |
|    total_timesteps | 831488 |
-------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 632        |
|    iterations           | 407        |
|    time_elapsed         | 1317       |
|    total_timesteps      | 833536     |
| train/                  |            |
|    approx_kl            | 0.00456059 |
|    clip_fraction        | 0.0304     |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.11      |
|    explained_variance   | 0.806      |
|    learning_rate        | 5.42e-05   |
|    loss                 | -0.00666   |
|    n_updates            | 4060       |
|    policy_gradient_loss | -0.00634   |
|    std                  | 0.696      |
|    value_loss           | 0.00338    |
----------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 408          |
|    time_elapsed         | 1320         |
|    total_timesteps      | 835584       |
| train/                  |              |
|    approx_kl            | 0.0057200333 |
|    clip_fraction        | 0.0378       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.11        |
|    explained_variance   | 0.946        |
|    learning_rate        | 5.42e-05     |
|    loss                 | 0.0128       |
|    n_updates            | 4070         |
|    policy_gradient_loss | -0.0052      |
|    std                  | 0.695        |
|    value_loss           | 0.00512      |
------------------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 632         |
|    iterations           | 409         |
|    time_elapsed         | 1323        |
|    total_timesteps      | 837632      |
| train/                  |             |
|    approx_kl            | 0.002880483 |
|    clip_fraction        | 0.0177      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.11       |
|    explained_variance   | 0.92        |
|    learning_rate        | 5.42e-05    |
|    loss                 | -0.00225    |
|    n_updates            | 4080        |
|    policy_gradient_loss | -0.00253    |
|    std                  | 0.696       |
|    value_loss           | 0.00231     |
-----------------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 632         |
|    iterations           | 410         |
|    time_elapsed         | 1326        |
|    total_timesteps      | 839680      |
| train/                  |             |
|    approx_kl            | 0.006294859 |
|    clip_fraction        | 0.0367      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.1        |
|    explained_variance   | 0.583       |
|    learning_rate        | 5.42e-05    |
|    loss                 | 0.0062      |
|    n_updates            | 4090        |
|    policy_gradient_loss | -0.00368    |
|    std                  | 0.692       |
|    value_loss           | 0.0256      |
-----------------------------------------
Eval num_timesteps=840000, episode_reward=-0.92 +/- 0.16
Episode length: 300.00 +/- 0.00
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 300          |
|    mean_reward          | -0.92        |
| time/                   |              |
|    total_timesteps      | 840000       |
| train/                  |              |
|    approx_kl            | 0.0050451756 |
|    clip_fraction        | 0.0406       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.1         |
|    explained_variance   | 0.973        |
|    learning_rate        | 5.42e-05     |
|    loss                 | 0.00886      |
|    n_updates            | 4100         |
|    policy_gradient_loss | -0.00443     |
|    std                  | 0.692        |
|    value_loss           | 0.00285      |
------------------------------------------
-------------------------------
| time/              |        |
|    fps             | 632    |
|    iterations      | 411    |
|    time_elapsed    | 1330   |
|    total_timesteps | 841728 |
-------------------------------
box reached target
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 632         |
|    iterations           | 412         |
|    time_elapsed         | 1333        |
|    total_timesteps      | 843776      |
| train/                  |             |
|    approx_kl            | 0.004202228 |
|    clip_fraction        | 0.0255      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.1        |
|    explained_variance   | 0.812       |
|    learning_rate        | 5.42e-05    |
|    loss                 | -0.0119     |
|    n_updates            | 4110        |
|    policy_gradient_loss | -0.005      |
|    std                  | 0.693       |
|    value_loss           | 0.00907     |
-----------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 413          |
|    time_elapsed         | 1336         |
|    total_timesteps      | 845824       |
| train/                  |              |
|    approx_kl            | 0.0046394058 |
|    clip_fraction        | 0.0335       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.1         |
|    explained_variance   | 0.918        |
|    learning_rate        | 5.42e-05     |
|    loss                 | -0.00584     |
|    n_updates            | 4120         |
|    policy_gradient_loss | -0.00352     |
|    std                  | 0.692        |
|    value_loss           | 0.0305       |
------------------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 632         |
|    iterations           | 414         |
|    time_elapsed         | 1340        |
|    total_timesteps      | 847872      |
| train/                  |             |
|    approx_kl            | 0.004892187 |
|    clip_fraction        | 0.0288      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.1        |
|    explained_variance   | 0.849       |
|    learning_rate        | 5.42e-05    |
|    loss                 | 0.00398     |
|    n_updates            | 4130        |
|    policy_gradient_loss | -0.00569    |
|    std                  | 0.69        |
|    value_loss           | 0.00143     |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 632         |
|    iterations           | 415         |
|    time_elapsed         | 1343        |
|    total_timesteps      | 849920      |
| train/                  |             |
|    approx_kl            | 0.004492917 |
|    clip_fraction        | 0.0215      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.1        |
|    explained_variance   | 0.964       |
|    learning_rate        | 5.42e-05    |
|    loss                 | -0.0104     |
|    n_updates            | 4140        |
|    policy_gradient_loss | -0.00375    |
|    std                  | 0.694       |
|    value_loss           | 0.00783     |
-----------------------------------------
Eval num_timesteps=850000, episode_reward=-0.81 +/- 0.60
Episode length: 300.00 +/- 0.00
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 300          |
|    mean_reward          | -0.807       |
| time/                   |              |
|    total_timesteps      | 850000       |
| train/                  |              |
|    approx_kl            | 0.0039868485 |
|    clip_fraction        | 0.0279       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.11        |
|    explained_variance   | 0.766        |
|    learning_rate        | 5.42e-05     |
|    loss                 | -0.0271      |
|    n_updates            | 4150         |
|    policy_gradient_loss | -0.00572     |
|    std                  | 0.695        |
|    value_loss           | 0.00132      |
------------------------------------------
box reached target
-------------------------------
| time/              |        |
|    fps             | 632    |
|    iterations      | 416    |
|    time_elapsed    | 1347   |
|    total_timesteps | 851968 |
-------------------------------
box reached target
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 417          |
|    time_elapsed         | 1350         |
|    total_timesteps      | 854016       |
| train/                  |              |
|    approx_kl            | 0.0048785675 |
|    clip_fraction        | 0.0336       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.1         |
|    explained_variance   | 0.654        |
|    learning_rate        | 5.43e-05     |
|    loss                 | -0.00804     |
|    n_updates            | 4160         |
|    policy_gradient_loss | -0.00593     |
|    std                  | 0.693        |
|    value_loss           | 0.05         |
------------------------------------------
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 418          |
|    time_elapsed         | 1353         |
|    total_timesteps      | 856064       |
| train/                  |              |
|    approx_kl            | 0.0051467395 |
|    clip_fraction        | 0.0414       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.1         |
|    explained_variance   | 0.873        |
|    learning_rate        | 5.43e-05     |
|    loss                 | -0.00961     |
|    n_updates            | 4170         |
|    policy_gradient_loss | -0.00492     |
|    std                  | 0.692        |
|    value_loss           | 0.0357       |
------------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 632         |
|    iterations           | 419         |
|    time_elapsed         | 1356        |
|    total_timesteps      | 858112      |
| train/                  |             |
|    approx_kl            | 0.005205641 |
|    clip_fraction        | 0.0329      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.09       |
|    explained_variance   | 0.88        |
|    learning_rate        | 5.43e-05    |
|    loss                 | 0.00871     |
|    n_updates            | 4180        |
|    policy_gradient_loss | -0.00472    |
|    std                  | 0.69        |
|    value_loss           | 0.0134      |
-----------------------------------------
Eval num_timesteps=860000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 300          |
|    mean_reward          | -1           |
| time/                   |              |
|    total_timesteps      | 860000       |
| train/                  |              |
|    approx_kl            | 0.0052696085 |
|    clip_fraction        | 0.0512       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.09        |
|    explained_variance   | 0.838        |
|    learning_rate        | 5.43e-05     |
|    loss                 | -0.00293     |
|    n_updates            | 4190         |
|    policy_gradient_loss | -0.00753     |
|    std                  | 0.69         |
|    value_loss           | 0.00187      |
------------------------------------------
-------------------------------
| time/              |        |
|    fps             | 632    |
|    iterations      | 420    |
|    time_elapsed    | 1360   |
|    total_timesteps | 860160 |
-------------------------------
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 421          |
|    time_elapsed         | 1363         |
|    total_timesteps      | 862208       |
| train/                  |              |
|    approx_kl            | 0.0024529821 |
|    clip_fraction        | 0.0112       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.09        |
|    explained_variance   | 0.774        |
|    learning_rate        | 5.43e-05     |
|    loss                 | -0.0232      |
|    n_updates            | 4200         |
|    policy_gradient_loss | -0.00321     |
|    std                  | 0.689        |
|    value_loss           | 0.000738     |
------------------------------------------
box reached target
box reached target
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 422          |
|    time_elapsed         | 1366         |
|    total_timesteps      | 864256       |
| train/                  |              |
|    approx_kl            | 0.0041996436 |
|    clip_fraction        | 0.0183       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.09        |
|    explained_variance   | 0.932        |
|    learning_rate        | 5.43e-05     |
|    loss                 | -0.00205     |
|    n_updates            | 4210         |
|    policy_gradient_loss | -0.00333     |
|    std                  | 0.686        |
|    value_loss           | 0.00582      |
------------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 632         |
|    iterations           | 423         |
|    time_elapsed         | 1369        |
|    total_timesteps      | 866304      |
| train/                  |             |
|    approx_kl            | 0.004049581 |
|    clip_fraction        | 0.0198      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.08       |
|    explained_variance   | 0.856       |
|    learning_rate        | 5.43e-05    |
|    loss                 | -0.0018     |
|    n_updates            | 4220        |
|    policy_gradient_loss | -0.00279    |
|    std                  | 0.685       |
|    value_loss           | 0.0344      |
-----------------------------------------
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 424          |
|    time_elapsed         | 1372         |
|    total_timesteps      | 868352       |
| train/                  |              |
|    approx_kl            | 0.0045146206 |
|    clip_fraction        | 0.0303       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.08        |
|    explained_variance   | 0.936        |
|    learning_rate        | 5.43e-05     |
|    loss                 | -0.00473     |
|    n_updates            | 4230         |
|    policy_gradient_loss | -0.00555     |
|    std                  | 0.686        |
|    value_loss           | 0.00269      |
------------------------------------------
box reached target
Eval num_timesteps=870000, episode_reward=0.29 +/- 2.58
Episode length: 276.00 +/- 48.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 276         |
|    mean_reward          | 0.289       |
| time/                   |             |
|    total_timesteps      | 870000      |
| train/                  |             |
|    approx_kl            | 0.004967908 |
|    clip_fraction        | 0.0285      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.08       |
|    explained_variance   | 0.961       |
|    learning_rate        | 5.43e-05    |
|    loss                 | -0.00887    |
|    n_updates            | 4240        |
|    policy_gradient_loss | -0.00401    |
|    std                  | 0.687       |
|    value_loss           | 0.00715     |
-----------------------------------------
-------------------------------
| time/              |        |
|    fps             | 632    |
|    iterations      | 425    |
|    time_elapsed    | 1376   |
|    total_timesteps | 870400 |
-------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 426          |
|    time_elapsed         | 1379         |
|    total_timesteps      | 872448       |
| train/                  |              |
|    approx_kl            | 0.0044047125 |
|    clip_fraction        | 0.0372       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.08        |
|    explained_variance   | 0.864        |
|    learning_rate        | 5.44e-05     |
|    loss                 | -0.0132      |
|    n_updates            | 4250         |
|    policy_gradient_loss | -0.00509     |
|    std                  | 0.689        |
|    value_loss           | 0.00339      |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 427          |
|    time_elapsed         | 1382         |
|    total_timesteps      | 874496       |
| train/                  |              |
|    approx_kl            | 0.0039728843 |
|    clip_fraction        | 0.0294       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.09        |
|    explained_variance   | 0.82         |
|    learning_rate        | 5.44e-05     |
|    loss                 | -0.0228      |
|    n_updates            | 4260         |
|    policy_gradient_loss | -0.00585     |
|    std                  | 0.688        |
|    value_loss           | 0.00159      |
------------------------------------------
box reached target
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 428          |
|    time_elapsed         | 1385         |
|    total_timesteps      | 876544       |
| train/                  |              |
|    approx_kl            | 0.0040743025 |
|    clip_fraction        | 0.0216       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.08        |
|    explained_variance   | 0.807        |
|    learning_rate        | 5.44e-05     |
|    loss                 | -0.0222      |
|    n_updates            | 4270         |
|    policy_gradient_loss | -0.00625     |
|    std                  | 0.686        |
|    value_loss           | 0.0017       |
------------------------------------------
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 429          |
|    time_elapsed         | 1388         |
|    total_timesteps      | 878592       |
| train/                  |              |
|    approx_kl            | 0.0051979213 |
|    clip_fraction        | 0.0273       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.08        |
|    explained_variance   | 0.98         |
|    learning_rate        | 5.44e-05     |
|    loss                 | 0.00982      |
|    n_updates            | 4280         |
|    policy_gradient_loss | -0.00469     |
|    std                  | 0.684        |
|    value_loss           | 0.00345      |
------------------------------------------
box reached target
Eval num_timesteps=880000, episode_reward=0.24 +/- 2.59
Episode length: 290.80 +/- 18.40
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 291          |
|    mean_reward          | 0.237        |
| time/                   |              |
|    total_timesteps      | 880000       |
| train/                  |              |
|    approx_kl            | 0.0045759995 |
|    clip_fraction        | 0.0282       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.07        |
|    explained_variance   | 0.733        |
|    learning_rate        | 5.44e-05     |
|    loss                 | -0.0127      |
|    n_updates            | 4290         |
|    policy_gradient_loss | -0.00912     |
|    std                  | 0.682        |
|    value_loss           | 0.0216       |
------------------------------------------
box reached target
-------------------------------
| time/              |        |
|    fps             | 632    |
|    iterations      | 430    |
|    time_elapsed    | 1392   |
|    total_timesteps | 880640 |
-------------------------------
box reached target
box reached target
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 632         |
|    iterations           | 431         |
|    time_elapsed         | 1395        |
|    total_timesteps      | 882688      |
| train/                  |             |
|    approx_kl            | 0.003832901 |
|    clip_fraction        | 0.0258      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.07       |
|    explained_variance   | 0.852       |
|    learning_rate        | 5.44e-05    |
|    loss                 | 0.0173      |
|    n_updates            | 4300        |
|    policy_gradient_loss | -0.00436    |
|    std                  | 0.683       |
|    value_loss           | 0.0179      |
-----------------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 632         |
|    iterations           | 432         |
|    time_elapsed         | 1398        |
|    total_timesteps      | 884736      |
| train/                  |             |
|    approx_kl            | 0.004867545 |
|    clip_fraction        | 0.0343      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.07       |
|    explained_variance   | 0.867       |
|    learning_rate        | 5.44e-05    |
|    loss                 | -0.00134    |
|    n_updates            | 4310        |
|    policy_gradient_loss | -0.00385    |
|    std                  | 0.681       |
|    value_loss           | 0.0214      |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 632         |
|    iterations           | 433         |
|    time_elapsed         | 1401        |
|    total_timesteps      | 886784      |
| train/                  |             |
|    approx_kl            | 0.004817602 |
|    clip_fraction        | 0.0391      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.07       |
|    explained_variance   | 0.955       |
|    learning_rate        | 5.44e-05    |
|    loss                 | 0.00985     |
|    n_updates            | 4320        |
|    policy_gradient_loss | -0.00586    |
|    std                  | 0.681       |
|    value_loss           | 0.00444     |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 632         |
|    iterations           | 434         |
|    time_elapsed         | 1404        |
|    total_timesteps      | 888832      |
| train/                  |             |
|    approx_kl            | 0.005441734 |
|    clip_fraction        | 0.036       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.07       |
|    explained_variance   | 0.859       |
|    learning_rate        | 5.44e-05    |
|    loss                 | -0.0156     |
|    n_updates            | 4330        |
|    policy_gradient_loss | -0.00458    |
|    std                  | 0.682       |
|    value_loss           | 0.00571     |
-----------------------------------------
box reached target
Eval num_timesteps=890000, episode_reward=-0.77 +/- 0.60
Episode length: 300.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 300         |
|    mean_reward          | -0.769      |
| time/                   |             |
|    total_timesteps      | 890000      |
| train/                  |             |
|    approx_kl            | 0.004348368 |
|    clip_fraction        | 0.0242      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.07       |
|    explained_variance   | 0.852       |
|    learning_rate        | 5.44e-05    |
|    loss                 | -0.00142    |
|    n_updates            | 4340        |
|    policy_gradient_loss | -0.00559    |
|    std                  | 0.683       |
|    value_loss           | 0.00339     |
-----------------------------------------
box reached target
-------------------------------
| time/              |        |
|    fps             | 632    |
|    iterations      | 435    |
|    time_elapsed    | 1408   |
|    total_timesteps | 890880 |
-------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 436          |
|    time_elapsed         | 1411         |
|    total_timesteps      | 892928       |
| train/                  |              |
|    approx_kl            | 0.0052523077 |
|    clip_fraction        | 0.0493       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.07        |
|    explained_variance   | 0.772        |
|    learning_rate        | 5.45e-05     |
|    loss                 | -0.00154     |
|    n_updates            | 4350         |
|    policy_gradient_loss | -0.00303     |
|    std                  | 0.683        |
|    value_loss           | 0.0628       |
------------------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 632         |
|    iterations           | 437         |
|    time_elapsed         | 1414        |
|    total_timesteps      | 894976      |
| train/                  |             |
|    approx_kl            | 0.004513395 |
|    clip_fraction        | 0.0222      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.07       |
|    explained_variance   | 0.88        |
|    learning_rate        | 5.45e-05    |
|    loss                 | -0.0145     |
|    n_updates            | 4360        |
|    policy_gradient_loss | -0.00323    |
|    std                  | 0.685       |
|    value_loss           | 0.00511     |
-----------------------------------------
box reached target
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 438          |
|    time_elapsed         | 1418         |
|    total_timesteps      | 897024       |
| train/                  |              |
|    approx_kl            | 0.0054676738 |
|    clip_fraction        | 0.0558       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.07        |
|    explained_variance   | 0.684        |
|    learning_rate        | 5.45e-05     |
|    loss                 | -0.00493     |
|    n_updates            | 4370         |
|    policy_gradient_loss | -0.00776     |
|    std                  | 0.683        |
|    value_loss           | 0.0262       |
------------------------------------------
box reached target
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 439          |
|    time_elapsed         | 1421         |
|    total_timesteps      | 899072       |
| train/                  |              |
|    approx_kl            | 0.0046286453 |
|    clip_fraction        | 0.0252       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.07        |
|    explained_variance   | 0.929        |
|    learning_rate        | 5.45e-05     |
|    loss                 | 0.00985      |
|    n_updates            | 4380         |
|    policy_gradient_loss | -0.00487     |
|    std                  | 0.68         |
|    value_loss           | 0.0338       |
------------------------------------------
Eval num_timesteps=900000, episode_reward=-1.00 +/- 0.22
Episode length: 300.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 300         |
|    mean_reward          | -1          |
| time/                   |             |
|    total_timesteps      | 900000      |
| train/                  |             |
|    approx_kl            | 0.004245938 |
|    clip_fraction        | 0.0191      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.06       |
|    explained_variance   | 0.675       |
|    learning_rate        | 5.45e-05    |
|    loss                 | 0.00339     |
|    n_updates            | 4390        |
|    policy_gradient_loss | -0.00253    |
|    std                  | 0.677       |
|    value_loss           | 0.0214      |
-----------------------------------------
-------------------------------
| time/              |        |
|    fps             | 632    |
|    iterations      | 440    |
|    time_elapsed    | 1425   |
|    total_timesteps | 901120 |
-------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 441          |
|    time_elapsed         | 1428         |
|    total_timesteps      | 903168       |
| train/                  |              |
|    approx_kl            | 0.0037808353 |
|    clip_fraction        | 0.0258       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.06        |
|    explained_variance   | 0.901        |
|    learning_rate        | 5.45e-05     |
|    loss                 | -0.0189      |
|    n_updates            | 4400         |
|    policy_gradient_loss | -0.00495     |
|    std                  | 0.679        |
|    value_loss           | 0.00464      |
------------------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 632         |
|    iterations           | 442         |
|    time_elapsed         | 1431        |
|    total_timesteps      | 905216      |
| train/                  |             |
|    approx_kl            | 0.004798035 |
|    clip_fraction        | 0.0354      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.06       |
|    explained_variance   | 0.862       |
|    learning_rate        | 5.45e-05    |
|    loss                 | -0.00583    |
|    n_updates            | 4410        |
|    policy_gradient_loss | -0.00668    |
|    std                  | 0.68        |
|    value_loss           | 0.00537     |
-----------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 443          |
|    time_elapsed         | 1434         |
|    total_timesteps      | 907264       |
| train/                  |              |
|    approx_kl            | 0.0040763738 |
|    clip_fraction        | 0.0281       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.06        |
|    explained_variance   | 0.88         |
|    learning_rate        | 5.45e-05     |
|    loss                 | -0.0111      |
|    n_updates            | 4420         |
|    policy_gradient_loss | -0.00606     |
|    std                  | 0.681        |
|    value_loss           | 0.0311       |
------------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 632         |
|    iterations           | 444         |
|    time_elapsed         | 1437        |
|    total_timesteps      | 909312      |
| train/                  |             |
|    approx_kl            | 0.005194931 |
|    clip_fraction        | 0.0398      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.07       |
|    explained_variance   | 0.851       |
|    learning_rate        | 5.45e-05    |
|    loss                 | -0.00934    |
|    n_updates            | 4430        |
|    policy_gradient_loss | -0.00534    |
|    std                  | 0.683       |
|    value_loss           | 0.00251     |
-----------------------------------------
box reached target
Eval num_timesteps=910000, episode_reward=-0.80 +/- 0.58
Episode length: 300.00 +/- 0.00
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 300          |
|    mean_reward          | -0.798       |
| time/                   |              |
|    total_timesteps      | 910000       |
| train/                  |              |
|    approx_kl            | 0.0040292153 |
|    clip_fraction        | 0.0305       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.07        |
|    explained_variance   | 0.929        |
|    learning_rate        | 5.45e-05     |
|    loss                 | -0.00227     |
|    n_updates            | 4440         |
|    policy_gradient_loss | -0.00291     |
|    std                  | 0.683        |
|    value_loss           | 0.00452      |
------------------------------------------
-------------------------------
| time/              |        |
|    fps             | 632    |
|    iterations      | 445    |
|    time_elapsed    | 1441   |
|    total_timesteps | 911360 |
-------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 446          |
|    time_elapsed         | 1444         |
|    total_timesteps      | 913408       |
| train/                  |              |
|    approx_kl            | 0.0044710524 |
|    clip_fraction        | 0.0247       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.07        |
|    explained_variance   | 0.935        |
|    learning_rate        | 5.46e-05     |
|    loss                 | 0.00918      |
|    n_updates            | 4450         |
|    policy_gradient_loss | -0.00397     |
|    std                  | 0.684        |
|    value_loss           | 0.01         |
------------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 632        |
|    iterations           | 447        |
|    time_elapsed         | 1447       |
|    total_timesteps      | 915456     |
| train/                  |            |
|    approx_kl            | 0.00435375 |
|    clip_fraction        | 0.0229     |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.08      |
|    explained_variance   | 0.85       |
|    learning_rate        | 5.46e-05   |
|    loss                 | 0.00641    |
|    n_updates            | 4460       |
|    policy_gradient_loss | -0.00506   |
|    std                  | 0.687      |
|    value_loss           | 0.00317    |
----------------------------------------
box reached target
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 448          |
|    time_elapsed         | 1450         |
|    total_timesteps      | 917504       |
| train/                  |              |
|    approx_kl            | 0.0045334534 |
|    clip_fraction        | 0.0287       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.08        |
|    explained_variance   | 0.939        |
|    learning_rate        | 5.46e-05     |
|    loss                 | -0.00498     |
|    n_updates            | 4470         |
|    policy_gradient_loss | -0.00367     |
|    std                  | 0.687        |
|    value_loss           | 0.0104       |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 449          |
|    time_elapsed         | 1453         |
|    total_timesteps      | 919552       |
| train/                  |              |
|    approx_kl            | 0.0034391312 |
|    clip_fraction        | 0.0156       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.08        |
|    explained_variance   | 0.886        |
|    learning_rate        | 5.46e-05     |
|    loss                 | -0.00991     |
|    n_updates            | 4480         |
|    policy_gradient_loss | -0.00408     |
|    std                  | 0.684        |
|    value_loss           | 0.0124       |
------------------------------------------
Eval num_timesteps=920000, episode_reward=-0.67 +/- 0.34
Episode length: 300.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 300         |
|    mean_reward          | -0.674      |
| time/                   |             |
|    total_timesteps      | 920000      |
| train/                  |             |
|    approx_kl            | 0.005158392 |
|    clip_fraction        | 0.0296      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.07       |
|    explained_variance   | 0.866       |
|    learning_rate        | 5.46e-05    |
|    loss                 | 0.0164      |
|    n_updates            | 4490        |
|    policy_gradient_loss | -0.00626    |
|    std                  | 0.683       |
|    value_loss           | 0.00226     |
-----------------------------------------
-------------------------------
| time/              |        |
|    fps             | 632    |
|    iterations      | 450    |
|    time_elapsed    | 1457   |
|    total_timesteps | 921600 |
-------------------------------
box reached target
box reached target
box reached target
box reached target
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 451          |
|    time_elapsed         | 1460         |
|    total_timesteps      | 923648       |
| train/                  |              |
|    approx_kl            | 0.0050432724 |
|    clip_fraction        | 0.0316       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.08        |
|    explained_variance   | 0.901        |
|    learning_rate        | 5.46e-05     |
|    loss                 | 0.00613      |
|    n_updates            | 4500         |
|    policy_gradient_loss | -0.00571     |
|    std                  | 0.685        |
|    value_loss           | 0.00224      |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 452          |
|    time_elapsed         | 1463         |
|    total_timesteps      | 925696       |
| train/                  |              |
|    approx_kl            | 0.0034437263 |
|    clip_fraction        | 0.0183       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.08        |
|    explained_variance   | 0.915        |
|    learning_rate        | 5.46e-05     |
|    loss                 | 0.00572      |
|    n_updates            | 4510         |
|    policy_gradient_loss | -0.00283     |
|    std                  | 0.685        |
|    value_loss           | 0.021        |
------------------------------------------
box reached target
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 453          |
|    time_elapsed         | 1466         |
|    total_timesteps      | 927744       |
| train/                  |              |
|    approx_kl            | 0.0037168525 |
|    clip_fraction        | 0.0222       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.08        |
|    explained_variance   | 0.824        |
|    learning_rate        | 5.46e-05     |
|    loss                 | -0.0215      |
|    n_updates            | 4520         |
|    policy_gradient_loss | -0.00533     |
|    std                  | 0.686        |
|    value_loss           | 0.00416      |
------------------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 632         |
|    iterations           | 454         |
|    time_elapsed         | 1469        |
|    total_timesteps      | 929792      |
| train/                  |             |
|    approx_kl            | 0.004678676 |
|    clip_fraction        | 0.0355      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.08       |
|    explained_variance   | 0.938       |
|    learning_rate        | 5.46e-05    |
|    loss                 | -0.0223     |
|    n_updates            | 4530        |
|    policy_gradient_loss | -0.00436    |
|    std                  | 0.684       |
|    value_loss           | 0.0123      |
-----------------------------------------
Eval num_timesteps=930000, episode_reward=-0.66 +/- 0.66
Episode length: 300.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 300         |
|    mean_reward          | -0.661      |
| time/                   |             |
|    total_timesteps      | 930000      |
| train/                  |             |
|    approx_kl            | 0.006257379 |
|    clip_fraction        | 0.0368      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.07       |
|    explained_variance   | 0.927       |
|    learning_rate        | 5.46e-05    |
|    loss                 | -0.028      |
|    n_updates            | 4540        |
|    policy_gradient_loss | -0.0049     |
|    std                  | 0.685       |
|    value_loss           | 0.00815     |
-----------------------------------------
-------------------------------
| time/              |        |
|    fps             | 632    |
|    iterations      | 455    |
|    time_elapsed    | 1473   |
|    total_timesteps | 931840 |
-------------------------------
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 456          |
|    time_elapsed         | 1476         |
|    total_timesteps      | 933888       |
| train/                  |              |
|    approx_kl            | 0.0047371117 |
|    clip_fraction        | 0.0483       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.08        |
|    explained_variance   | 0.855        |
|    learning_rate        | 5.47e-05     |
|    loss                 | -0.0135      |
|    n_updates            | 4550         |
|    policy_gradient_loss | -0.00698     |
|    std                  | 0.687        |
|    value_loss           | 0.00244      |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 457          |
|    time_elapsed         | 1479         |
|    total_timesteps      | 935936       |
| train/                  |              |
|    approx_kl            | 0.0048594764 |
|    clip_fraction        | 0.0347       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.08        |
|    explained_variance   | 0.984        |
|    learning_rate        | 5.47e-05     |
|    loss                 | 0.000897     |
|    n_updates            | 4560         |
|    policy_gradient_loss | -0.00615     |
|    std                  | 0.686        |
|    value_loss           | 0.0031       |
------------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 632         |
|    iterations           | 458         |
|    time_elapsed         | 1482        |
|    total_timesteps      | 937984      |
| train/                  |             |
|    approx_kl            | 0.004059327 |
|    clip_fraction        | 0.0277      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.08       |
|    explained_variance   | 0.816       |
|    learning_rate        | 5.47e-05    |
|    loss                 | 0.0167      |
|    n_updates            | 4570        |
|    policy_gradient_loss | -0.00605    |
|    std                  | 0.686       |
|    value_loss           | 0.00364     |
-----------------------------------------
box reached target
Eval num_timesteps=940000, episode_reward=0.26 +/- 2.53
Episode length: 279.20 +/- 41.60
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 279         |
|    mean_reward          | 0.263       |
| time/                   |             |
|    total_timesteps      | 940000      |
| train/                  |             |
|    approx_kl            | 0.003998955 |
|    clip_fraction        | 0.0227      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.08       |
|    explained_variance   | 0.932       |
|    learning_rate        | 5.47e-05    |
|    loss                 | -0.0267     |
|    n_updates            | 4580        |
|    policy_gradient_loss | -0.00542    |
|    std                  | 0.686       |
|    value_loss           | 0.00146     |
-----------------------------------------
-------------------------------
| time/              |        |
|    fps             | 632    |
|    iterations      | 459    |
|    time_elapsed    | 1486   |
|    total_timesteps | 940032 |
-------------------------------
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 460          |
|    time_elapsed         | 1489         |
|    total_timesteps      | 942080       |
| train/                  |              |
|    approx_kl            | 0.0042057084 |
|    clip_fraction        | 0.0201       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.08        |
|    explained_variance   | 0.813        |
|    learning_rate        | 5.47e-05     |
|    loss                 | 0.0196       |
|    n_updates            | 4590         |
|    policy_gradient_loss | -0.00562     |
|    std                  | 0.686        |
|    value_loss           | 0.00168      |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 461          |
|    time_elapsed         | 1493         |
|    total_timesteps      | 944128       |
| train/                  |              |
|    approx_kl            | 0.0066221794 |
|    clip_fraction        | 0.0467       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.08        |
|    explained_variance   | 0.983        |
|    learning_rate        | 5.47e-05     |
|    loss                 | 0.000633     |
|    n_updates            | 4600         |
|    policy_gradient_loss | -0.00543     |
|    std                  | 0.686        |
|    value_loss           | 0.00233      |
------------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 632         |
|    iterations           | 462         |
|    time_elapsed         | 1496        |
|    total_timesteps      | 946176      |
| train/                  |             |
|    approx_kl            | 0.004655064 |
|    clip_fraction        | 0.044       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.08       |
|    explained_variance   | 0.785       |
|    learning_rate        | 5.47e-05    |
|    loss                 | -0.00609    |
|    n_updates            | 4610        |
|    policy_gradient_loss | -0.00557    |
|    std                  | 0.686       |
|    value_loss           | 0.00234     |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 632         |
|    iterations           | 463         |
|    time_elapsed         | 1499        |
|    total_timesteps      | 948224      |
| train/                  |             |
|    approx_kl            | 0.004110584 |
|    clip_fraction        | 0.0262      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.08       |
|    explained_variance   | 0.887       |
|    learning_rate        | 5.47e-05    |
|    loss                 | 0.00258     |
|    n_updates            | 4620        |
|    policy_gradient_loss | -0.00591    |
|    std                  | 0.687       |
|    value_loss           | 0.00634     |
-----------------------------------------
box reached target
box reached target
Eval num_timesteps=950000, episode_reward=0.43 +/- 2.48
Episode length: 278.20 +/- 43.60
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 278          |
|    mean_reward          | 0.43         |
| time/                   |              |
|    total_timesteps      | 950000       |
| train/                  |              |
|    approx_kl            | 0.0049382756 |
|    clip_fraction        | 0.0372       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.08        |
|    explained_variance   | 0.83         |
|    learning_rate        | 5.47e-05     |
|    loss                 | 0.0108       |
|    n_updates            | 4630         |
|    policy_gradient_loss | -0.00562     |
|    std                  | 0.686        |
|    value_loss           | 0.00135      |
------------------------------------------
-------------------------------
| time/              |        |
|    fps             | 632    |
|    iterations      | 464    |
|    time_elapsed    | 1503   |
|    total_timesteps | 950272 |
-------------------------------
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 465          |
|    time_elapsed         | 1506         |
|    total_timesteps      | 952320       |
| train/                  |              |
|    approx_kl            | 0.0058461507 |
|    clip_fraction        | 0.0388       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.08        |
|    explained_variance   | 0.868        |
|    learning_rate        | 5.48e-05     |
|    loss                 | -0.00796     |
|    n_updates            | 4640         |
|    policy_gradient_loss | -0.00462     |
|    std                  | 0.685        |
|    value_loss           | 0.0147       |
------------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 632         |
|    iterations           | 466         |
|    time_elapsed         | 1509        |
|    total_timesteps      | 954368      |
| train/                  |             |
|    approx_kl            | 0.003151844 |
|    clip_fraction        | 0.0208      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.07       |
|    explained_variance   | 0.929       |
|    learning_rate        | 5.48e-05    |
|    loss                 | -0.00155    |
|    n_updates            | 4650        |
|    policy_gradient_loss | -0.00516    |
|    std                  | 0.684       |
|    value_loss           | 0.00922     |
-----------------------------------------
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 467          |
|    time_elapsed         | 1512         |
|    total_timesteps      | 956416       |
| train/                  |              |
|    approx_kl            | 0.0038976222 |
|    clip_fraction        | 0.0364       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.08        |
|    explained_variance   | 0.844        |
|    learning_rate        | 5.48e-05     |
|    loss                 | -0.00501     |
|    n_updates            | 4660         |
|    policy_gradient_loss | -0.0061      |
|    std                  | 0.685        |
|    value_loss           | 0.0044       |
------------------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 632         |
|    iterations           | 468         |
|    time_elapsed         | 1515        |
|    total_timesteps      | 958464      |
| train/                  |             |
|    approx_kl            | 0.008123966 |
|    clip_fraction        | 0.0751      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.08       |
|    explained_variance   | 0.483       |
|    learning_rate        | 5.48e-05    |
|    loss                 | 0.0156      |
|    n_updates            | 4670        |
|    policy_gradient_loss | -0.0056     |
|    std                  | 0.684       |
|    value_loss           | 0.0265      |
-----------------------------------------
box reached target
Eval num_timesteps=960000, episode_reward=-0.90 +/- 0.20
Episode length: 300.00 +/- 0.00
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 300          |
|    mean_reward          | -0.901       |
| time/                   |              |
|    total_timesteps      | 960000       |
| train/                  |              |
|    approx_kl            | 0.0042733094 |
|    clip_fraction        | 0.0297       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.08        |
|    explained_variance   | 0.6          |
|    learning_rate        | 5.48e-05     |
|    loss                 | 0.0108       |
|    n_updates            | 4680         |
|    policy_gradient_loss | -0.00449     |
|    std                  | 0.686        |
|    value_loss           | 0.0383       |
------------------------------------------
box reached target
-------------------------------
| time/              |        |
|    fps             | 632    |
|    iterations      | 469    |
|    time_elapsed    | 1519   |
|    total_timesteps | 960512 |
-------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 632       |
|    iterations           | 470       |
|    time_elapsed         | 1522      |
|    total_timesteps      | 962560    |
| train/                  |           |
|    approx_kl            | 0.0048356 |
|    clip_fraction        | 0.0314    |
|    clip_range           | 0.2       |
|    entropy_loss         | -2.08     |
|    explained_variance   | 0.854     |
|    learning_rate        | 5.48e-05  |
|    loss                 | -0.00992  |
|    n_updates            | 4690      |
|    policy_gradient_loss | -0.00425  |
|    std                  | 0.684     |
|    value_loss           | 0.0234    |
---------------------------------------
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 471          |
|    time_elapsed         | 1525         |
|    total_timesteps      | 964608       |
| train/                  |              |
|    approx_kl            | 0.0041223406 |
|    clip_fraction        | 0.0189       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.07        |
|    explained_variance   | 0.953        |
|    learning_rate        | 5.48e-05     |
|    loss                 | 0.00107      |
|    n_updates            | 4700         |
|    policy_gradient_loss | -0.00224     |
|    std                  | 0.684        |
|    value_loss           | 0.00728      |
------------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 632         |
|    iterations           | 472         |
|    time_elapsed         | 1528        |
|    total_timesteps      | 966656      |
| train/                  |             |
|    approx_kl            | 0.003949261 |
|    clip_fraction        | 0.0292      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.07       |
|    explained_variance   | 0.836       |
|    learning_rate        | 5.48e-05    |
|    loss                 | -0.00155    |
|    n_updates            | 4710        |
|    policy_gradient_loss | -0.00492    |
|    std                  | 0.682       |
|    value_loss           | 0.00912     |
-----------------------------------------
box reached target
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 473          |
|    time_elapsed         | 1531         |
|    total_timesteps      | 968704       |
| train/                  |              |
|    approx_kl            | 0.0054152114 |
|    clip_fraction        | 0.0387       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.07        |
|    explained_variance   | 0.89         |
|    learning_rate        | 5.48e-05     |
|    loss                 | -0.028       |
|    n_updates            | 4720         |
|    policy_gradient_loss | -0.00571     |
|    std                  | 0.681        |
|    value_loss           | 0.00274      |
------------------------------------------
box reached target
box reached target
Eval num_timesteps=970000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 300         |
|    mean_reward          | -1          |
| time/                   |             |
|    total_timesteps      | 970000      |
| train/                  |             |
|    approx_kl            | 0.004238493 |
|    clip_fraction        | 0.0238      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.06       |
|    explained_variance   | 0.926       |
|    learning_rate        | 5.48e-05    |
|    loss                 | -0.00298    |
|    n_updates            | 4730        |
|    policy_gradient_loss | -0.00217    |
|    std                  | 0.68        |
|    value_loss           | 0.0362      |
-----------------------------------------
box reached target
-------------------------------
| time/              |        |
|    fps             | 632    |
|    iterations      | 474    |
|    time_elapsed    | 1535   |
|    total_timesteps | 970752 |
-------------------------------
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 475          |
|    time_elapsed         | 1538         |
|    total_timesteps      | 972800       |
| train/                  |              |
|    approx_kl            | 0.0050636036 |
|    clip_fraction        | 0.0378       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.06        |
|    explained_variance   | 0.913        |
|    learning_rate        | 5.49e-05     |
|    loss                 | 0.00871      |
|    n_updates            | 4740         |
|    policy_gradient_loss | -0.00609     |
|    std                  | 0.678        |
|    value_loss           | 0.0337       |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 476          |
|    time_elapsed         | 1541         |
|    total_timesteps      | 974848       |
| train/                  |              |
|    approx_kl            | 0.0043767607 |
|    clip_fraction        | 0.0206       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.05        |
|    explained_variance   | 0.569        |
|    learning_rate        | 5.49e-05     |
|    loss                 | -0.0352      |
|    n_updates            | 4750         |
|    policy_gradient_loss | -0.00363     |
|    std                  | 0.676        |
|    value_loss           | 0.0258       |
------------------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 632         |
|    iterations           | 477         |
|    time_elapsed         | 1544        |
|    total_timesteps      | 976896      |
| train/                  |             |
|    approx_kl            | 0.005029193 |
|    clip_fraction        | 0.039       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.05       |
|    explained_variance   | 0.785       |
|    learning_rate        | 5.49e-05    |
|    loss                 | -0.00564    |
|    n_updates            | 4760        |
|    policy_gradient_loss | -0.00555    |
|    std                  | 0.675       |
|    value_loss           | 0.00224     |
-----------------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 632         |
|    iterations           | 478         |
|    time_elapsed         | 1547        |
|    total_timesteps      | 978944      |
| train/                  |             |
|    approx_kl            | 0.005960183 |
|    clip_fraction        | 0.047       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.05       |
|    explained_variance   | 0.94        |
|    learning_rate        | 5.49e-05    |
|    loss                 | -0.0209     |
|    n_updates            | 4770        |
|    policy_gradient_loss | -0.00659    |
|    std                  | 0.675       |
|    value_loss           | 0.0045      |
-----------------------------------------
box reached target
Eval num_timesteps=980000, episode_reward=0.30 +/- 2.60
Episode length: 283.00 +/- 34.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 283         |
|    mean_reward          | 0.301       |
| time/                   |             |
|    total_timesteps      | 980000      |
| train/                  |             |
|    approx_kl            | 0.004616726 |
|    clip_fraction        | 0.0298      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.05       |
|    explained_variance   | 0.909       |
|    learning_rate        | 5.49e-05    |
|    loss                 | 0.00718     |
|    n_updates            | 4780        |
|    policy_gradient_loss | -0.00522    |
|    std                  | 0.677       |
|    value_loss           | 0.0059      |
-----------------------------------------
-------------------------------
| time/              |        |
|    fps             | 632    |
|    iterations      | 479    |
|    time_elapsed    | 1551   |
|    total_timesteps | 980992 |
-------------------------------
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 480          |
|    time_elapsed         | 1554         |
|    total_timesteps      | 983040       |
| train/                  |              |
|    approx_kl            | 0.0045470716 |
|    clip_fraction        | 0.0405       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.05        |
|    explained_variance   | 0.916        |
|    learning_rate        | 5.49e-05     |
|    loss                 | -0.0178      |
|    n_updates            | 4790         |
|    policy_gradient_loss | -0.0063      |
|    std                  | 0.676        |
|    value_loss           | 0.00209      |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 481          |
|    time_elapsed         | 1557         |
|    total_timesteps      | 985088       |
| train/                  |              |
|    approx_kl            | 0.0055508907 |
|    clip_fraction        | 0.0293       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.04        |
|    explained_variance   | 0.18         |
|    learning_rate        | 5.49e-05     |
|    loss                 | 0.0142       |
|    n_updates            | 4800         |
|    policy_gradient_loss | -0.00499     |
|    std                  | 0.673        |
|    value_loss           | 0.0472       |
------------------------------------------
box reached target
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 632         |
|    iterations           | 482         |
|    time_elapsed         | 1560        |
|    total_timesteps      | 987136      |
| train/                  |             |
|    approx_kl            | 0.003785913 |
|    clip_fraction        | 0.0294      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.04       |
|    explained_variance   | 0.805       |
|    learning_rate        | 5.49e-05    |
|    loss                 | 0.0133      |
|    n_updates            | 4810        |
|    policy_gradient_loss | -0.00466    |
|    std                  | 0.674       |
|    value_loss           | 0.00136     |
-----------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 483          |
|    time_elapsed         | 1563         |
|    total_timesteps      | 989184       |
| train/                  |              |
|    approx_kl            | 0.0053082784 |
|    clip_fraction        | 0.0455       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.04        |
|    explained_variance   | 0.941        |
|    learning_rate        | 5.49e-05     |
|    loss                 | -0.0013      |
|    n_updates            | 4820         |
|    policy_gradient_loss | -0.00838     |
|    std                  | 0.671        |
|    value_loss           | 0.0192       |
------------------------------------------
box reached target
Eval num_timesteps=990000, episode_reward=0.74 +/- 2.43
Episode length: 274.40 +/- 51.20
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 274          |
|    mean_reward          | 0.739        |
| time/                   |              |
|    total_timesteps      | 990000       |
| train/                  |              |
|    approx_kl            | 0.0044794367 |
|    clip_fraction        | 0.0233       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.04        |
|    explained_variance   | 0.928        |
|    learning_rate        | 5.49e-05     |
|    loss                 | 0.000136     |
|    n_updates            | 4830         |
|    policy_gradient_loss | -0.00169     |
|    std                  | 0.672        |
|    value_loss           | 0.0035       |
------------------------------------------
box reached target
-------------------------------
| time/              |        |
|    fps             | 632    |
|    iterations      | 484    |
|    time_elapsed    | 1567   |
|    total_timesteps | 991232 |
-------------------------------
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 485          |
|    time_elapsed         | 1570         |
|    total_timesteps      | 993280       |
| train/                  |              |
|    approx_kl            | 0.0043193083 |
|    clip_fraction        | 0.0231       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.04        |
|    explained_variance   | 0.935        |
|    learning_rate        | 5.5e-05      |
|    loss                 | -0.0177      |
|    n_updates            | 4840         |
|    policy_gradient_loss | -0.00507     |
|    std                  | 0.673        |
|    value_loss           | 0.0118       |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 486          |
|    time_elapsed         | 1573         |
|    total_timesteps      | 995328       |
| train/                  |              |
|    approx_kl            | 0.0040166965 |
|    clip_fraction        | 0.0216       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.04        |
|    explained_variance   | 0.968        |
|    learning_rate        | 5.5e-05      |
|    loss                 | -0.000545    |
|    n_updates            | 4850         |
|    policy_gradient_loss | -0.00453     |
|    std                  | 0.674        |
|    value_loss           | 0.01         |
------------------------------------------
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 487          |
|    time_elapsed         | 1577         |
|    total_timesteps      | 997376       |
| train/                  |              |
|    approx_kl            | 0.0053850096 |
|    clip_fraction        | 0.0371       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.04        |
|    explained_variance   | 0.848        |
|    learning_rate        | 5.5e-05      |
|    loss                 | 6.63e-05     |
|    n_updates            | 4860         |
|    policy_gradient_loss | -0.00853     |
|    std                  | 0.674        |
|    value_loss           | 0.000864     |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 488          |
|    time_elapsed         | 1580         |
|    total_timesteps      | 999424       |
| train/                  |              |
|    approx_kl            | 0.0073024114 |
|    clip_fraction        | 0.0462       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.04        |
|    explained_variance   | 0.969        |
|    learning_rate        | 5.5e-05      |
|    loss                 | 0.0187       |
|    n_updates            | 4870         |
|    policy_gradient_loss | -0.00621     |
|    std                  | 0.673        |
|    value_loss           | 0.0052       |
------------------------------------------
Eval num_timesteps=1000000, episode_reward=-0.93 +/- 0.12
Episode length: 300.00 +/- 0.00
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 300          |
|    mean_reward          | -0.93        |
| time/                   |              |
|    total_timesteps      | 1000000      |
| train/                  |              |
|    approx_kl            | 0.0052027293 |
|    clip_fraction        | 0.0418       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.04        |
|    explained_variance   | 0.75         |
|    learning_rate        | 5.5e-05      |
|    loss                 | -0.0116      |
|    n_updates            | 4880         |
|    policy_gradient_loss | -0.00391     |
|    std                  | 0.674        |
|    value_loss           | 0.00718      |
------------------------------------------
--------------------------------
| time/              |         |
|    fps             | 632     |
|    iterations      | 489     |
|    time_elapsed    | 1584    |
|    total_timesteps | 1001472 |
--------------------------------
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 490          |
|    time_elapsed         | 1587         |
|    total_timesteps      | 1003520      |
| train/                  |              |
|    approx_kl            | 0.0045791585 |
|    clip_fraction        | 0.0336       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.04        |
|    explained_variance   | 0.802        |
|    learning_rate        | 5.5e-05      |
|    loss                 | -0.0174      |
|    n_updates            | 4890         |
|    policy_gradient_loss | -0.00498     |
|    std                  | 0.674        |
|    value_loss           | 0.00287      |
------------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 632         |
|    iterations           | 491         |
|    time_elapsed         | 1590        |
|    total_timesteps      | 1005568     |
| train/                  |             |
|    approx_kl            | 0.004190285 |
|    clip_fraction        | 0.0289      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.05       |
|    explained_variance   | 0.933       |
|    learning_rate        | 5.5e-05     |
|    loss                 | -0.00659    |
|    n_updates            | 4900        |
|    policy_gradient_loss | -0.0053     |
|    std                  | 0.677       |
|    value_loss           | 0.00469     |
-----------------------------------------
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 492          |
|    time_elapsed         | 1593         |
|    total_timesteps      | 1007616      |
| train/                  |              |
|    approx_kl            | 0.0052961316 |
|    clip_fraction        | 0.0446       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.05        |
|    explained_variance   | 0.695        |
|    learning_rate        | 5.5e-05      |
|    loss                 | -0.0115      |
|    n_updates            | 4910         |
|    policy_gradient_loss | -0.00611     |
|    std                  | 0.676        |
|    value_loss           | 0.0014       |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 493          |
|    time_elapsed         | 1596         |
|    total_timesteps      | 1009664      |
| train/                  |              |
|    approx_kl            | 0.0074750925 |
|    clip_fraction        | 0.0625       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.05        |
|    explained_variance   | 0.976        |
|    learning_rate        | 5.5e-05      |
|    loss                 | -0.0216      |
|    n_updates            | 4920         |
|    policy_gradient_loss | -0.00668     |
|    std                  | 0.678        |
|    value_loss           | 0.0025       |
------------------------------------------
Eval num_timesteps=1010000, episode_reward=-1.03 +/- 0.05
Episode length: 300.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 300         |
|    mean_reward          | -1.03       |
| time/                   |             |
|    total_timesteps      | 1010000     |
| train/                  |             |
|    approx_kl            | 0.004015415 |
|    clip_fraction        | 0.0302      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.05       |
|    explained_variance   | 0.906       |
|    learning_rate        | 5.5e-05     |
|    loss                 | 0.00319     |
|    n_updates            | 4930        |
|    policy_gradient_loss | -0.00374    |
|    std                  | 0.679       |
|    value_loss           | 0.00371     |
-----------------------------------------
box reached target
box reached target
--------------------------------
| time/              |         |
|    fps             | 632     |
|    iterations      | 494     |
|    time_elapsed    | 1600    |
|    total_timesteps | 1011712 |
--------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 495          |
|    time_elapsed         | 1603         |
|    total_timesteps      | 1013760      |
| train/                  |              |
|    approx_kl            | 0.0038000632 |
|    clip_fraction        | 0.0241       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.06        |
|    explained_variance   | 0.977        |
|    learning_rate        | 5.51e-05     |
|    loss                 | 0.0142       |
|    n_updates            | 4940         |
|    policy_gradient_loss | -0.00456     |
|    std                  | 0.679        |
|    value_loss           | 0.00814      |
------------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 632         |
|    iterations           | 496         |
|    time_elapsed         | 1606        |
|    total_timesteps      | 1015808     |
| train/                  |             |
|    approx_kl            | 0.006884521 |
|    clip_fraction        | 0.0546      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.06       |
|    explained_variance   | 0.836       |
|    learning_rate        | 5.51e-05    |
|    loss                 | -0.00693    |
|    n_updates            | 4950        |
|    policy_gradient_loss | -0.00618    |
|    std                  | 0.683       |
|    value_loss           | 0.00088     |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 632         |
|    iterations           | 497         |
|    time_elapsed         | 1609        |
|    total_timesteps      | 1017856     |
| train/                  |             |
|    approx_kl            | 0.004384998 |
|    clip_fraction        | 0.026       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.07       |
|    explained_variance   | 0.833       |
|    learning_rate        | 5.51e-05    |
|    loss                 | 0.00507     |
|    n_updates            | 4960        |
|    policy_gradient_loss | -0.00521    |
|    std                  | 0.683       |
|    value_loss           | 0.000972    |
-----------------------------------------
box reached target
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 498          |
|    time_elapsed         | 1612         |
|    total_timesteps      | 1019904      |
| train/                  |              |
|    approx_kl            | 0.0037157885 |
|    clip_fraction        | 0.0319       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.07        |
|    explained_variance   | 0.855        |
|    learning_rate        | 5.51e-05     |
|    loss                 | -0.00635     |
|    n_updates            | 4970         |
|    policy_gradient_loss | -0.00456     |
|    std                  | 0.686        |
|    value_loss           | 0.00646      |
------------------------------------------
box reached target
Eval num_timesteps=1020000, episode_reward=0.37 +/- 2.47
Episode length: 276.40 +/- 47.20
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 276         |
|    mean_reward          | 0.368       |
| time/                   |             |
|    total_timesteps      | 1020000     |
| train/                  |             |
|    approx_kl            | 0.006226266 |
|    clip_fraction        | 0.0476      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.07       |
|    explained_variance   | 0.821       |
|    learning_rate        | 5.51e-05    |
|    loss                 | 0.00597     |
|    n_updates            | 4980        |
|    policy_gradient_loss | -0.00522    |
|    std                  | 0.684       |
|    value_loss           | 0.0332      |
-----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 632     |
|    iterations      | 499     |
|    time_elapsed    | 1616    |
|    total_timesteps | 1021952 |
--------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 500          |
|    time_elapsed         | 1619         |
|    total_timesteps      | 1024000      |
| train/                  |              |
|    approx_kl            | 0.0044507547 |
|    clip_fraction        | 0.036        |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.07        |
|    explained_variance   | 0.806        |
|    learning_rate        | 5.51e-05     |
|    loss                 | -0.0102      |
|    n_updates            | 4990         |
|    policy_gradient_loss | -0.00644     |
|    std                  | 0.683        |
|    value_loss           | 0.00215      |
------------------------------------------
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 501          |
|    time_elapsed         | 1622         |
|    total_timesteps      | 1026048      |
| train/                  |              |
|    approx_kl            | 0.0056254845 |
|    clip_fraction        | 0.0455       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.07        |
|    explained_variance   | 0.859        |
|    learning_rate        | 5.51e-05     |
|    loss                 | -0.00422     |
|    n_updates            | 5000         |
|    policy_gradient_loss | -0.00626     |
|    std                  | 0.683        |
|    value_loss           | 0.00169      |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 502          |
|    time_elapsed         | 1625         |
|    total_timesteps      | 1028096      |
| train/                  |              |
|    approx_kl            | 0.0049309772 |
|    clip_fraction        | 0.028        |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.06        |
|    explained_variance   | 0.965        |
|    learning_rate        | 5.51e-05     |
|    loss                 | 0.000886     |
|    n_updates            | 5010         |
|    policy_gradient_loss | -0.00328     |
|    std                  | 0.681        |
|    value_loss           | 0.00636      |
------------------------------------------
box reached target
Eval num_timesteps=1030000, episode_reward=0.60 +/- 2.49
Episode length: 284.60 +/- 30.80
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 285          |
|    mean_reward          | 0.598        |
| time/                   |              |
|    total_timesteps      | 1030000      |
| train/                  |              |
|    approx_kl            | 0.0050885472 |
|    clip_fraction        | 0.0354       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.07        |
|    explained_variance   | 0.749        |
|    learning_rate        | 5.51e-05     |
|    loss                 | -0.0169      |
|    n_updates            | 5020         |
|    policy_gradient_loss | -0.00545     |
|    std                  | 0.684        |
|    value_loss           | 0.00679      |
------------------------------------------
--------------------------------
| time/              |         |
|    fps             | 632     |
|    iterations      | 503     |
|    time_elapsed    | 1629    |
|    total_timesteps | 1030144 |
--------------------------------
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 504          |
|    time_elapsed         | 1632         |
|    total_timesteps      | 1032192      |
| train/                  |              |
|    approx_kl            | 0.0050206757 |
|    clip_fraction        | 0.0214       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.07        |
|    explained_variance   | 0.859        |
|    learning_rate        | 5.52e-05     |
|    loss                 | -0.00521     |
|    n_updates            | 5030         |
|    policy_gradient_loss | -0.00384     |
|    std                  | 0.685        |
|    value_loss           | 0.00283      |
------------------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 632         |
|    iterations           | 505         |
|    time_elapsed         | 1635        |
|    total_timesteps      | 1034240     |
| train/                  |             |
|    approx_kl            | 0.004122135 |
|    clip_fraction        | 0.0315      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.07       |
|    explained_variance   | 0.72        |
|    learning_rate        | 5.52e-05    |
|    loss                 | 0.0029      |
|    n_updates            | 5040        |
|    policy_gradient_loss | -0.00535    |
|    std                  | 0.685       |
|    value_loss           | 0.034       |
-----------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 506          |
|    time_elapsed         | 1638         |
|    total_timesteps      | 1036288      |
| train/                  |              |
|    approx_kl            | 0.0046506305 |
|    clip_fraction        | 0.0267       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.07        |
|    explained_variance   | 0.494        |
|    learning_rate        | 5.52e-05     |
|    loss                 | -0.00429     |
|    n_updates            | 5050         |
|    policy_gradient_loss | -0.0017      |
|    std                  | 0.684        |
|    value_loss           | 0.0489       |
------------------------------------------
box reached target
box reached target
box reached target
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 632         |
|    iterations           | 507         |
|    time_elapsed         | 1641        |
|    total_timesteps      | 1038336     |
| train/                  |             |
|    approx_kl            | 0.004288379 |
|    clip_fraction        | 0.0323      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.07       |
|    explained_variance   | 0.887       |
|    learning_rate        | 5.52e-05    |
|    loss                 | -0.0155     |
|    n_updates            | 5060        |
|    policy_gradient_loss | -0.00549    |
|    std                  | 0.685       |
|    value_loss           | 0.00335     |
-----------------------------------------
box reached target
Eval num_timesteps=1040000, episode_reward=0.41 +/- 2.43
Episode length: 293.00 +/- 14.00
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 293          |
|    mean_reward          | 0.408        |
| time/                   |              |
|    total_timesteps      | 1040000      |
| train/                  |              |
|    approx_kl            | 0.0031562527 |
|    clip_fraction        | 0.0153       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.07        |
|    explained_variance   | 0.814        |
|    learning_rate        | 5.52e-05     |
|    loss                 | -0.0107      |
|    n_updates            | 5070         |
|    policy_gradient_loss | -0.00375     |
|    std                  | 0.683        |
|    value_loss           | 0.0642       |
------------------------------------------
--------------------------------
| time/              |         |
|    fps             | 632     |
|    iterations      | 508     |
|    time_elapsed    | 1645    |
|    total_timesteps | 1040384 |
--------------------------------
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 509          |
|    time_elapsed         | 1648         |
|    total_timesteps      | 1042432      |
| train/                  |              |
|    approx_kl            | 0.0050668046 |
|    clip_fraction        | 0.0392       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.06        |
|    explained_variance   | 0.852        |
|    learning_rate        | 5.52e-05     |
|    loss                 | 0.0184       |
|    n_updates            | 5080         |
|    policy_gradient_loss | -0.00478     |
|    std                  | 0.682        |
|    value_loss           | 0.00165      |
------------------------------------------
box reached target
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 510          |
|    time_elapsed         | 1651         |
|    total_timesteps      | 1044480      |
| train/                  |              |
|    approx_kl            | 0.0052695856 |
|    clip_fraction        | 0.0518       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.06        |
|    explained_variance   | 0.936        |
|    learning_rate        | 5.52e-05     |
|    loss                 | 0.0139       |
|    n_updates            | 5090         |
|    policy_gradient_loss | -0.00794     |
|    std                  | 0.681        |
|    value_loss           | 0.0144       |
------------------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 632         |
|    iterations           | 511         |
|    time_elapsed         | 1654        |
|    total_timesteps      | 1046528     |
| train/                  |             |
|    approx_kl            | 0.004070639 |
|    clip_fraction        | 0.0253      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.06       |
|    explained_variance   | 0.905       |
|    learning_rate        | 5.52e-05    |
|    loss                 | 0.0125      |
|    n_updates            | 5100        |
|    policy_gradient_loss | -0.00294    |
|    std                  | 0.681       |
|    value_loss           | 0.0199      |
-----------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 512          |
|    time_elapsed         | 1658         |
|    total_timesteps      | 1048576      |
| train/                  |              |
|    approx_kl            | 0.0038142737 |
|    clip_fraction        | 0.0327       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.06        |
|    explained_variance   | 0.86         |
|    learning_rate        | 5.52e-05     |
|    loss                 | -0.00895     |
|    n_updates            | 5110         |
|    policy_gradient_loss | -0.00586     |
|    std                  | 0.682        |
|    value_loss           | 0.0123       |
------------------------------------------
Eval num_timesteps=1050000, episode_reward=-0.89 +/- 0.35
Episode length: 300.00 +/- 0.00
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 300          |
|    mean_reward          | -0.89        |
| time/                   |              |
|    total_timesteps      | 1050000      |
| train/                  |              |
|    approx_kl            | 0.0037183638 |
|    clip_fraction        | 0.0253       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.06        |
|    explained_variance   | 0.9          |
|    learning_rate        | 5.52e-05     |
|    loss                 | -0.0153      |
|    n_updates            | 5120         |
|    policy_gradient_loss | -0.00409     |
|    std                  | 0.682        |
|    value_loss           | 0.00549      |
------------------------------------------
--------------------------------
| time/              |         |
|    fps             | 632     |
|    iterations      | 513     |
|    time_elapsed    | 1662    |
|    total_timesteps | 1050624 |
--------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 632         |
|    iterations           | 514         |
|    time_elapsed         | 1665        |
|    total_timesteps      | 1052672     |
| train/                  |             |
|    approx_kl            | 0.005387728 |
|    clip_fraction        | 0.0452      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.06       |
|    explained_variance   | 0.836       |
|    learning_rate        | 5.53e-05    |
|    loss                 | -0.00711    |
|    n_updates            | 5130        |
|    policy_gradient_loss | -0.00737    |
|    std                  | 0.68        |
|    value_loss           | 0.00261     |
-----------------------------------------
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 515          |
|    time_elapsed         | 1668         |
|    total_timesteps      | 1054720      |
| train/                  |              |
|    approx_kl            | 0.0033717551 |
|    clip_fraction        | 0.0147       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.06        |
|    explained_variance   | 0.876        |
|    learning_rate        | 5.53e-05     |
|    loss                 | 0.00375      |
|    n_updates            | 5140         |
|    policy_gradient_loss | -0.00394     |
|    std                  | 0.683        |
|    value_loss           | 0.00265      |
------------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 632         |
|    iterations           | 516         |
|    time_elapsed         | 1671        |
|    total_timesteps      | 1056768     |
| train/                  |             |
|    approx_kl            | 0.003995264 |
|    clip_fraction        | 0.0322      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.06       |
|    explained_variance   | 0.883       |
|    learning_rate        | 5.53e-05    |
|    loss                 | -0.0184     |
|    n_updates            | 5150        |
|    policy_gradient_loss | -0.00474    |
|    std                  | 0.68        |
|    value_loss           | 0.0167      |
-----------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 517          |
|    time_elapsed         | 1674         |
|    total_timesteps      | 1058816      |
| train/                  |              |
|    approx_kl            | 0.0054782284 |
|    clip_fraction        | 0.0467       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.07        |
|    explained_variance   | 0.896        |
|    learning_rate        | 5.53e-05     |
|    loss                 | 0.00849      |
|    n_updates            | 5160         |
|    policy_gradient_loss | -0.0053      |
|    std                  | 0.684        |
|    value_loss           | 0.00635      |
------------------------------------------
box reached target
box reached target
box reached target
box reached target
Eval num_timesteps=1060000, episode_reward=0.42 +/- 2.47
Episode length: 278.00 +/- 44.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 278         |
|    mean_reward          | 0.421       |
| time/                   |             |
|    total_timesteps      | 1060000     |
| train/                  |             |
|    approx_kl            | 0.004310523 |
|    clip_fraction        | 0.018       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.07       |
|    explained_variance   | 0.903       |
|    learning_rate        | 5.53e-05    |
|    loss                 | -0.000444   |
|    n_updates            | 5170        |
|    policy_gradient_loss | -0.00314    |
|    std                  | 0.682       |
|    value_loss           | 0.004       |
-----------------------------------------
box reached target
--------------------------------
| time/              |         |
|    fps             | 632     |
|    iterations      | 518     |
|    time_elapsed    | 1678    |
|    total_timesteps | 1060864 |
--------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 632         |
|    iterations           | 519         |
|    time_elapsed         | 1681        |
|    total_timesteps      | 1062912     |
| train/                  |             |
|    approx_kl            | 0.002907792 |
|    clip_fraction        | 0.0181      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.07       |
|    explained_variance   | 0.864       |
|    learning_rate        | 5.53e-05    |
|    loss                 | -0.000265   |
|    n_updates            | 5180        |
|    policy_gradient_loss | -0.00227    |
|    std                  | 0.683       |
|    value_loss           | 0.0654      |
-----------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 520          |
|    time_elapsed         | 1684         |
|    total_timesteps      | 1064960      |
| train/                  |              |
|    approx_kl            | 0.0054144766 |
|    clip_fraction        | 0.0364       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.07        |
|    explained_variance   | 0.899        |
|    learning_rate        | 5.53e-05     |
|    loss                 | 0.00249      |
|    n_updates            | 5190         |
|    policy_gradient_loss | -0.00537     |
|    std                  | 0.684        |
|    value_loss           | 0.00304      |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 521          |
|    time_elapsed         | 1687         |
|    total_timesteps      | 1067008      |
| train/                  |              |
|    approx_kl            | 0.0050250255 |
|    clip_fraction        | 0.0331       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.07        |
|    explained_variance   | 0.908        |
|    learning_rate        | 5.53e-05     |
|    loss                 | 0.00676      |
|    n_updates            | 5200         |
|    policy_gradient_loss | -0.00376     |
|    std                  | 0.682        |
|    value_loss           | 0.005        |
------------------------------------------
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 522          |
|    time_elapsed         | 1690         |
|    total_timesteps      | 1069056      |
| train/                  |              |
|    approx_kl            | 0.0059509566 |
|    clip_fraction        | 0.0446       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.07        |
|    explained_variance   | 0.781        |
|    learning_rate        | 5.53e-05     |
|    loss                 | -0.0107      |
|    n_updates            | 5210         |
|    policy_gradient_loss | -0.00832     |
|    std                  | 0.681        |
|    value_loss           | 0.00258      |
------------------------------------------
box reached target
Eval num_timesteps=1070000, episode_reward=0.53 +/- 2.51
Episode length: 277.80 +/- 44.40
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 278          |
|    mean_reward          | 0.53         |
| time/                   |              |
|    total_timesteps      | 1070000      |
| train/                  |              |
|    approx_kl            | 0.0058418256 |
|    clip_fraction        | 0.0425       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.06        |
|    explained_variance   | 0.952        |
|    learning_rate        | 5.53e-05     |
|    loss                 | -0.0119      |
|    n_updates            | 5220         |
|    policy_gradient_loss | -0.00591     |
|    std                  | 0.68         |
|    value_loss           | 0.00553      |
------------------------------------------
--------------------------------
| time/              |         |
|    fps             | 632     |
|    iterations      | 523     |
|    time_elapsed    | 1694    |
|    total_timesteps | 1071104 |
--------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 632        |
|    iterations           | 524        |
|    time_elapsed         | 1697       |
|    total_timesteps      | 1073152    |
| train/                  |            |
|    approx_kl            | 0.00513913 |
|    clip_fraction        | 0.0302     |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.06      |
|    explained_variance   | 0.916      |
|    learning_rate        | 5.54e-05   |
|    loss                 | 0.0138     |
|    n_updates            | 5230       |
|    policy_gradient_loss | -0.00575   |
|    std                  | 0.682      |
|    value_loss           | 0.00335    |
----------------------------------------
box reached target
box reached target
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 525          |
|    time_elapsed         | 1700         |
|    total_timesteps      | 1075200      |
| train/                  |              |
|    approx_kl            | 0.0053490335 |
|    clip_fraction        | 0.0404       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.06        |
|    explained_variance   | 0.944        |
|    learning_rate        | 5.54e-05     |
|    loss                 | -0.0101      |
|    n_updates            | 5240         |
|    policy_gradient_loss | -0.00962     |
|    std                  | 0.681        |
|    value_loss           | 0.00401      |
------------------------------------------
box reached target
box reached target
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 526          |
|    time_elapsed         | 1703         |
|    total_timesteps      | 1077248      |
| train/                  |              |
|    approx_kl            | 0.0048339814 |
|    clip_fraction        | 0.0236       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.06        |
|    explained_variance   | 0.926        |
|    learning_rate        | 5.54e-05     |
|    loss                 | 0.00591      |
|    n_updates            | 5250         |
|    policy_gradient_loss | -0.00415     |
|    std                  | 0.677        |
|    value_loss           | 0.00906      |
------------------------------------------
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 527          |
|    time_elapsed         | 1706         |
|    total_timesteps      | 1079296      |
| train/                  |              |
|    approx_kl            | 0.0062059625 |
|    clip_fraction        | 0.0558       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.04        |
|    explained_variance   | 0.901        |
|    learning_rate        | 5.54e-05     |
|    loss                 | -0.00426     |
|    n_updates            | 5260         |
|    policy_gradient_loss | -0.00613     |
|    std                  | 0.673        |
|    value_loss           | 0.0323       |
------------------------------------------
box reached target
Eval num_timesteps=1080000, episode_reward=0.57 +/- 2.69
Episode length: 283.80 +/- 32.40
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 284         |
|    mean_reward          | 0.57        |
| time/                   |             |
|    total_timesteps      | 1080000     |
| train/                  |             |
|    approx_kl            | 0.006462137 |
|    clip_fraction        | 0.0272      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.03       |
|    explained_variance   | 0.749       |
|    learning_rate        | 5.54e-05    |
|    loss                 | -0.00638    |
|    n_updates            | 5270        |
|    policy_gradient_loss | -0.00522    |
|    std                  | 0.67        |
|    value_loss           | 0.0192      |
-----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 632     |
|    iterations      | 528     |
|    time_elapsed    | 1710    |
|    total_timesteps | 1081344 |
--------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 529          |
|    time_elapsed         | 1713         |
|    total_timesteps      | 1083392      |
| train/                  |              |
|    approx_kl            | 0.0060848887 |
|    clip_fraction        | 0.0473       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.03        |
|    explained_variance   | 0.957        |
|    learning_rate        | 5.54e-05     |
|    loss                 | -0.0144      |
|    n_updates            | 5280         |
|    policy_gradient_loss | -0.00625     |
|    std                  | 0.669        |
|    value_loss           | 0.00117      |
------------------------------------------
box reached target
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 530          |
|    time_elapsed         | 1716         |
|    total_timesteps      | 1085440      |
| train/                  |              |
|    approx_kl            | 0.0064504305 |
|    clip_fraction        | 0.0704       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.03        |
|    explained_variance   | 0.803        |
|    learning_rate        | 5.54e-05     |
|    loss                 | 0.0117       |
|    n_updates            | 5290         |
|    policy_gradient_loss | -0.00879     |
|    std                  | 0.67         |
|    value_loss           | 0.00359      |
------------------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 632         |
|    iterations           | 531         |
|    time_elapsed         | 1719        |
|    total_timesteps      | 1087488     |
| train/                  |             |
|    approx_kl            | 0.005330136 |
|    clip_fraction        | 0.0467      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.03       |
|    explained_variance   | 0.927       |
|    learning_rate        | 5.54e-05    |
|    loss                 | 0.0248      |
|    n_updates            | 5300        |
|    policy_gradient_loss | -0.00761    |
|    std                  | 0.669       |
|    value_loss           | 0.0236      |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 632         |
|    iterations           | 532         |
|    time_elapsed         | 1722        |
|    total_timesteps      | 1089536     |
| train/                  |             |
|    approx_kl            | 0.004386712 |
|    clip_fraction        | 0.0307      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.02       |
|    explained_variance   | 0.958       |
|    learning_rate        | 5.54e-05    |
|    loss                 | -0.00378    |
|    n_updates            | 5310        |
|    policy_gradient_loss | -0.00515    |
|    std                  | 0.668       |
|    value_loss           | 0.00538     |
-----------------------------------------
box reached target
Eval num_timesteps=1090000, episode_reward=0.33 +/- 2.53
Episode length: 276.40 +/- 47.20
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 276         |
|    mean_reward          | 0.328       |
| time/                   |             |
|    total_timesteps      | 1090000     |
| train/                  |             |
|    approx_kl            | 0.005117955 |
|    clip_fraction        | 0.0426      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.02       |
|    explained_variance   | 0.869       |
|    learning_rate        | 5.54e-05    |
|    loss                 | -0.023      |
|    n_updates            | 5320        |
|    policy_gradient_loss | -0.00639    |
|    std                  | 0.667       |
|    value_loss           | 0.00301     |
-----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 632     |
|    iterations      | 533     |
|    time_elapsed    | 1726    |
|    total_timesteps | 1091584 |
--------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 632         |
|    iterations           | 534         |
|    time_elapsed         | 1729        |
|    total_timesteps      | 1093632     |
| train/                  |             |
|    approx_kl            | 0.004828929 |
|    clip_fraction        | 0.0495      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.02       |
|    explained_variance   | 0.875       |
|    learning_rate        | 5.55e-05    |
|    loss                 | -0.00555    |
|    n_updates            | 5330        |
|    policy_gradient_loss | -0.00547    |
|    std                  | 0.668       |
|    value_loss           | 0.00811     |
-----------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 535          |
|    time_elapsed         | 1732         |
|    total_timesteps      | 1095680      |
| train/                  |              |
|    approx_kl            | 0.0036856094 |
|    clip_fraction        | 0.0294       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.03        |
|    explained_variance   | 0.918        |
|    learning_rate        | 5.55e-05     |
|    loss                 | -0.0145      |
|    n_updates            | 5340         |
|    policy_gradient_loss | -0.00491     |
|    std                  | 0.671        |
|    value_loss           | 0.00534      |
------------------------------------------
box reached target
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 536          |
|    time_elapsed         | 1735         |
|    total_timesteps      | 1097728      |
| train/                  |              |
|    approx_kl            | 0.0060793785 |
|    clip_fraction        | 0.0534       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.03        |
|    explained_variance   | 0.862        |
|    learning_rate        | 5.55e-05     |
|    loss                 | -0.0102      |
|    n_updates            | 5350         |
|    policy_gradient_loss | -0.00734     |
|    std                  | 0.671        |
|    value_loss           | 0.00131      |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 537          |
|    time_elapsed         | 1738         |
|    total_timesteps      | 1099776      |
| train/                  |              |
|    approx_kl            | 0.0037649437 |
|    clip_fraction        | 0.0158       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.03        |
|    explained_variance   | 0.971        |
|    learning_rate        | 5.55e-05     |
|    loss                 | -0.00127     |
|    n_updates            | 5360         |
|    policy_gradient_loss | -0.00455     |
|    std                  | 0.67         |
|    value_loss           | 0.00664      |
------------------------------------------
box reached target
Eval num_timesteps=1100000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 300          |
|    mean_reward          | -1           |
| time/                   |              |
|    total_timesteps      | 1100000      |
| train/                  |              |
|    approx_kl            | 0.0045728046 |
|    clip_fraction        | 0.0348       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.03        |
|    explained_variance   | 0.954        |
|    learning_rate        | 5.55e-05     |
|    loss                 | -0.0209      |
|    n_updates            | 5370         |
|    policy_gradient_loss | -0.00496     |
|    std                  | 0.669        |
|    value_loss           | 0.00126      |
------------------------------------------
--------------------------------
| time/              |         |
|    fps             | 632     |
|    iterations      | 538     |
|    time_elapsed    | 1742    |
|    total_timesteps | 1101824 |
--------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 632         |
|    iterations           | 539         |
|    time_elapsed         | 1745        |
|    total_timesteps      | 1103872     |
| train/                  |             |
|    approx_kl            | 0.003849802 |
|    clip_fraction        | 0.0486      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.02       |
|    explained_variance   | 0.95        |
|    learning_rate        | 5.55e-05    |
|    loss                 | -0.0194     |
|    n_updates            | 5380        |
|    policy_gradient_loss | -0.00422    |
|    std                  | 0.668       |
|    value_loss           | 0.00977     |
-----------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 632        |
|    iterations           | 540        |
|    time_elapsed         | 1749       |
|    total_timesteps      | 1105920    |
| train/                  |            |
|    approx_kl            | 0.00495549 |
|    clip_fraction        | 0.0366     |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.02      |
|    explained_variance   | 0.905      |
|    learning_rate        | 5.55e-05   |
|    loss                 | 0.00638    |
|    n_updates            | 5390       |
|    policy_gradient_loss | -0.00748   |
|    std                  | 0.667      |
|    value_loss           | 0.00492    |
----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 632         |
|    iterations           | 541         |
|    time_elapsed         | 1752        |
|    total_timesteps      | 1107968     |
| train/                  |             |
|    approx_kl            | 0.004631968 |
|    clip_fraction        | 0.0334      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.02       |
|    explained_variance   | 0.979       |
|    learning_rate        | 5.55e-05    |
|    loss                 | 0.000384    |
|    n_updates            | 5400        |
|    policy_gradient_loss | -0.00736    |
|    std                  | 0.665       |
|    value_loss           | 0.00265     |
-----------------------------------------
box reached target
Eval num_timesteps=1110000, episode_reward=-0.73 +/- 0.38
Episode length: 300.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 300         |
|    mean_reward          | -0.733      |
| time/                   |             |
|    total_timesteps      | 1110000     |
| train/                  |             |
|    approx_kl            | 0.005940993 |
|    clip_fraction        | 0.0471      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.01       |
|    explained_variance   | 0.859       |
|    learning_rate        | 5.55e-05    |
|    loss                 | 0.0248      |
|    n_updates            | 5410        |
|    policy_gradient_loss | -0.00704    |
|    std                  | 0.665       |
|    value_loss           | 0.00274     |
-----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 632     |
|    iterations      | 542     |
|    time_elapsed    | 1756    |
|    total_timesteps | 1110016 |
--------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 632         |
|    iterations           | 543         |
|    time_elapsed         | 1759        |
|    total_timesteps      | 1112064     |
| train/                  |             |
|    approx_kl            | 0.004855414 |
|    clip_fraction        | 0.0413      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.01       |
|    explained_variance   | 0.929       |
|    learning_rate        | 5.56e-05    |
|    loss                 | -0.0278     |
|    n_updates            | 5420        |
|    policy_gradient_loss | -0.0069     |
|    std                  | 0.663       |
|    value_loss           | 0.00606     |
-----------------------------------------
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 544          |
|    time_elapsed         | 1762         |
|    total_timesteps      | 1114112      |
| train/                  |              |
|    approx_kl            | 0.0060961107 |
|    clip_fraction        | 0.0452       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.01        |
|    explained_variance   | 0.976        |
|    learning_rate        | 5.56e-05     |
|    loss                 | -0.00742     |
|    n_updates            | 5430         |
|    policy_gradient_loss | -0.00679     |
|    std                  | 0.662        |
|    value_loss           | 0.00317      |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 545          |
|    time_elapsed         | 1765         |
|    total_timesteps      | 1116160      |
| train/                  |              |
|    approx_kl            | 0.0047928514 |
|    clip_fraction        | 0.0533       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2           |
|    explained_variance   | 0.988        |
|    learning_rate        | 5.56e-05     |
|    loss                 | -0.0135      |
|    n_updates            | 5440         |
|    policy_gradient_loss | -0.00702     |
|    std                  | 0.66         |
|    value_loss           | 0.00173      |
------------------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 632         |
|    iterations           | 546         |
|    time_elapsed         | 1768        |
|    total_timesteps      | 1118208     |
| train/                  |             |
|    approx_kl            | 0.004485406 |
|    clip_fraction        | 0.0372      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2          |
|    explained_variance   | 0.92        |
|    learning_rate        | 5.56e-05    |
|    loss                 | -0.0251     |
|    n_updates            | 5450        |
|    policy_gradient_loss | -0.00507    |
|    std                  | 0.658       |
|    value_loss           | 0.00373     |
-----------------------------------------
box reached target
Eval num_timesteps=1120000, episode_reward=-0.79 +/- 0.54
Episode length: 300.00 +/- 0.00
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 300          |
|    mean_reward          | -0.793       |
| time/                   |              |
|    total_timesteps      | 1120000      |
| train/                  |              |
|    approx_kl            | 0.0043268334 |
|    clip_fraction        | 0.0347       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.99        |
|    explained_variance   | 0.766        |
|    learning_rate        | 5.56e-05     |
|    loss                 | 0.0135       |
|    n_updates            | 5460         |
|    policy_gradient_loss | -0.003       |
|    std                  | 0.657        |
|    value_loss           | 0.0151       |
------------------------------------------
--------------------------------
| time/              |         |
|    fps             | 632     |
|    iterations      | 547     |
|    time_elapsed    | 1772    |
|    total_timesteps | 1120256 |
--------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 548          |
|    time_elapsed         | 1775         |
|    total_timesteps      | 1122304      |
| train/                  |              |
|    approx_kl            | 0.0034591532 |
|    clip_fraction        | 0.0273       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.99        |
|    explained_variance   | 0.797        |
|    learning_rate        | 5.56e-05     |
|    loss                 | -0.000451    |
|    n_updates            | 5470         |
|    policy_gradient_loss | -0.00367     |
|    std                  | 0.657        |
|    value_loss           | 0.0429       |
------------------------------------------
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 549          |
|    time_elapsed         | 1778         |
|    total_timesteps      | 1124352      |
| train/                  |              |
|    approx_kl            | 0.0058387164 |
|    clip_fraction        | 0.0358       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.99        |
|    explained_variance   | 0.809        |
|    learning_rate        | 5.56e-05     |
|    loss                 | -0.0287      |
|    n_updates            | 5480         |
|    policy_gradient_loss | -0.00567     |
|    std                  | 0.657        |
|    value_loss           | 0.00236      |
------------------------------------------
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 550          |
|    time_elapsed         | 1781         |
|    total_timesteps      | 1126400      |
| train/                  |              |
|    approx_kl            | 0.0046959235 |
|    clip_fraction        | 0.0394       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.99        |
|    explained_variance   | 0.956        |
|    learning_rate        | 5.56e-05     |
|    loss                 | -0.0114      |
|    n_updates            | 5490         |
|    policy_gradient_loss | -0.00492     |
|    std                  | 0.657        |
|    value_loss           | 0.00522      |
------------------------------------------
box reached target
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 632         |
|    iterations           | 551         |
|    time_elapsed         | 1784        |
|    total_timesteps      | 1128448     |
| train/                  |             |
|    approx_kl            | 0.004969716 |
|    clip_fraction        | 0.0413      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.99       |
|    explained_variance   | 0.968       |
|    learning_rate        | 5.56e-05    |
|    loss                 | -0.0233     |
|    n_updates            | 5500        |
|    policy_gradient_loss | -0.00462    |
|    std                  | 0.656       |
|    value_loss           | 0.00456     |
-----------------------------------------
box reached target
box reached target
Eval num_timesteps=1130000, episode_reward=0.33 +/- 2.50
Episode length: 273.20 +/- 53.60
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 273          |
|    mean_reward          | 0.334        |
| time/                   |              |
|    total_timesteps      | 1130000      |
| train/                  |              |
|    approx_kl            | 0.0031317286 |
|    clip_fraction        | 0.0224       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.98        |
|    explained_variance   | 0.802        |
|    learning_rate        | 5.56e-05     |
|    loss                 | -0.00958     |
|    n_updates            | 5510         |
|    policy_gradient_loss | -0.00475     |
|    std                  | 0.652        |
|    value_loss           | 0.0291       |
------------------------------------------
--------------------------------
| time/              |         |
|    fps             | 632     |
|    iterations      | 552     |
|    time_elapsed    | 1788    |
|    total_timesteps | 1130496 |
--------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 553          |
|    time_elapsed         | 1791         |
|    total_timesteps      | 1132544      |
| train/                  |              |
|    approx_kl            | 0.0047341487 |
|    clip_fraction        | 0.0409       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.98        |
|    explained_variance   | 0.968        |
|    learning_rate        | 5.57e-05     |
|    loss                 | -0.00461     |
|    n_updates            | 5520         |
|    policy_gradient_loss | -0.00651     |
|    std                  | 0.655        |
|    value_loss           | 0.00468      |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 554          |
|    time_elapsed         | 1794         |
|    total_timesteps      | 1134592      |
| train/                  |              |
|    approx_kl            | 0.0034251828 |
|    clip_fraction        | 0.029        |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.99        |
|    explained_variance   | 0.897        |
|    learning_rate        | 5.57e-05     |
|    loss                 | -0.00237     |
|    n_updates            | 5530         |
|    policy_gradient_loss | -0.00479     |
|    std                  | 0.657        |
|    value_loss           | 0.00317      |
------------------------------------------
box reached target
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 555          |
|    time_elapsed         | 1797         |
|    total_timesteps      | 1136640      |
| train/                  |              |
|    approx_kl            | 0.0057599135 |
|    clip_fraction        | 0.0466       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.99        |
|    explained_variance   | 0.744        |
|    learning_rate        | 5.57e-05     |
|    loss                 | -0.013       |
|    n_updates            | 5540         |
|    policy_gradient_loss | -0.00704     |
|    std                  | 0.657        |
|    value_loss           | 0.00315      |
------------------------------------------
box reached target
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 556          |
|    time_elapsed         | 1800         |
|    total_timesteps      | 1138688      |
| train/                  |              |
|    approx_kl            | 0.0044475873 |
|    clip_fraction        | 0.0195       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.98        |
|    explained_variance   | 0.832        |
|    learning_rate        | 5.57e-05     |
|    loss                 | -0.00618     |
|    n_updates            | 5550         |
|    policy_gradient_loss | -0.00357     |
|    std                  | 0.653        |
|    value_loss           | 0.0263       |
------------------------------------------
box reached target
Eval num_timesteps=1140000, episode_reward=0.15 +/- 2.53
Episode length: 275.20 +/- 49.60
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 275         |
|    mean_reward          | 0.152       |
| time/                   |             |
|    total_timesteps      | 1140000     |
| train/                  |             |
|    approx_kl            | 0.003413118 |
|    clip_fraction        | 0.0156      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.98       |
|    explained_variance   | 0.857       |
|    learning_rate        | 5.57e-05    |
|    loss                 | 0.0217      |
|    n_updates            | 5560        |
|    policy_gradient_loss | -0.00293    |
|    std                  | 0.651       |
|    value_loss           | 0.0182      |
-----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 632     |
|    iterations      | 557     |
|    time_elapsed    | 1804    |
|    total_timesteps | 1140736 |
--------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 632         |
|    iterations           | 558         |
|    time_elapsed         | 1807        |
|    total_timesteps      | 1142784     |
| train/                  |             |
|    approx_kl            | 0.006006444 |
|    clip_fraction        | 0.0536      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.97       |
|    explained_variance   | 0.87        |
|    learning_rate        | 5.57e-05    |
|    loss                 | -0.0165     |
|    n_updates            | 5570        |
|    policy_gradient_loss | -0.00658    |
|    std                  | 0.652       |
|    value_loss           | 0.00445     |
-----------------------------------------
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 559          |
|    time_elapsed         | 1810         |
|    total_timesteps      | 1144832      |
| train/                  |              |
|    approx_kl            | 0.0031742707 |
|    clip_fraction        | 0.0313       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.98        |
|    explained_variance   | 0.89         |
|    learning_rate        | 5.57e-05     |
|    loss                 | 0.000957     |
|    n_updates            | 5580         |
|    policy_gradient_loss | -0.00203     |
|    std                  | 0.653        |
|    value_loss           | 0.00382      |
------------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 632         |
|    iterations           | 560         |
|    time_elapsed         | 1813        |
|    total_timesteps      | 1146880     |
| train/                  |             |
|    approx_kl            | 0.003983602 |
|    clip_fraction        | 0.0248      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.98       |
|    explained_variance   | 0.911       |
|    learning_rate        | 5.57e-05    |
|    loss                 | -0.0106     |
|    n_updates            | 5590        |
|    policy_gradient_loss | -0.00587    |
|    std                  | 0.654       |
|    value_loss           | 0.00873     |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 632         |
|    iterations           | 561         |
|    time_elapsed         | 1816        |
|    total_timesteps      | 1148928     |
| train/                  |             |
|    approx_kl            | 0.006208856 |
|    clip_fraction        | 0.0459      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.98       |
|    explained_variance   | 0.831       |
|    learning_rate        | 5.57e-05    |
|    loss                 | -0.00589    |
|    n_updates            | 5600        |
|    policy_gradient_loss | -0.0079     |
|    std                  | 0.653       |
|    value_loss           | 0.00197     |
-----------------------------------------
Eval num_timesteps=1150000, episode_reward=-0.76 +/- 0.56
Episode length: 300.00 +/- 0.00
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 300          |
|    mean_reward          | -0.756       |
| time/                   |              |
|    total_timesteps      | 1150000      |
| train/                  |              |
|    approx_kl            | 0.0038101664 |
|    clip_fraction        | 0.0223       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.98        |
|    explained_variance   | 0.919        |
|    learning_rate        | 5.57e-05     |
|    loss                 | -0.00222     |
|    n_updates            | 5610         |
|    policy_gradient_loss | -0.00393     |
|    std                  | 0.654        |
|    value_loss           | 0.00317      |
------------------------------------------
--------------------------------
| time/              |         |
|    fps             | 632     |
|    iterations      | 562     |
|    time_elapsed    | 1820    |
|    total_timesteps | 1150976 |
--------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 632         |
|    iterations           | 563         |
|    time_elapsed         | 1823        |
|    total_timesteps      | 1153024     |
| train/                  |             |
|    approx_kl            | 0.005539885 |
|    clip_fraction        | 0.0458      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.98       |
|    explained_variance   | 0.856       |
|    learning_rate        | 5.58e-05    |
|    loss                 | -0.0143     |
|    n_updates            | 5620        |
|    policy_gradient_loss | -0.00667    |
|    std                  | 0.654       |
|    value_loss           | 0.00397     |
-----------------------------------------
box reached target
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 564          |
|    time_elapsed         | 1826         |
|    total_timesteps      | 1155072      |
| train/                  |              |
|    approx_kl            | 0.0029320256 |
|    clip_fraction        | 0.02         |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.98        |
|    explained_variance   | 0.531        |
|    learning_rate        | 5.58e-05     |
|    loss                 | -0.001       |
|    n_updates            | 5630         |
|    policy_gradient_loss | -0.00594     |
|    std                  | 0.653        |
|    value_loss           | 0.0373       |
------------------------------------------
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 565          |
|    time_elapsed         | 1830         |
|    total_timesteps      | 1157120      |
| train/                  |              |
|    approx_kl            | 0.0057658553 |
|    clip_fraction        | 0.0459       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.97        |
|    explained_variance   | 0.947        |
|    learning_rate        | 5.58e-05     |
|    loss                 | -0.00206     |
|    n_updates            | 5640         |
|    policy_gradient_loss | -0.00707     |
|    std                  | 0.651        |
|    value_loss           | 0.00762      |
------------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 632         |
|    iterations           | 566         |
|    time_elapsed         | 1833        |
|    total_timesteps      | 1159168     |
| train/                  |             |
|    approx_kl            | 0.004359792 |
|    clip_fraction        | 0.0383      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.97       |
|    explained_variance   | 0.86        |
|    learning_rate        | 5.58e-05    |
|    loss                 | 0.00841     |
|    n_updates            | 5650        |
|    policy_gradient_loss | -0.00574    |
|    std                  | 0.652       |
|    value_loss           | 0.0102      |
-----------------------------------------
box reached target
Eval num_timesteps=1160000, episode_reward=0.19 +/- 2.59
Episode length: 275.40 +/- 49.20
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 275          |
|    mean_reward          | 0.193        |
| time/                   |              |
|    total_timesteps      | 1160000      |
| train/                  |              |
|    approx_kl            | 0.0043432717 |
|    clip_fraction        | 0.0356       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.97        |
|    explained_variance   | 0.848        |
|    learning_rate        | 5.58e-05     |
|    loss                 | -0.0135      |
|    n_updates            | 5660         |
|    policy_gradient_loss | -0.00608     |
|    std                  | 0.653        |
|    value_loss           | 0.00402      |
------------------------------------------
--------------------------------
| time/              |         |
|    fps             | 632     |
|    iterations      | 567     |
|    time_elapsed    | 1837    |
|    total_timesteps | 1161216 |
--------------------------------
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 568          |
|    time_elapsed         | 1840         |
|    total_timesteps      | 1163264      |
| train/                  |              |
|    approx_kl            | 0.0055487305 |
|    clip_fraction        | 0.0436       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.98        |
|    explained_variance   | 0.815        |
|    learning_rate        | 5.58e-05     |
|    loss                 | 0.00813      |
|    n_updates            | 5670         |
|    policy_gradient_loss | -0.0055      |
|    std                  | 0.653        |
|    value_loss           | 0.00873      |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 569          |
|    time_elapsed         | 1843         |
|    total_timesteps      | 1165312      |
| train/                  |              |
|    approx_kl            | 0.0055758404 |
|    clip_fraction        | 0.0409       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.97        |
|    explained_variance   | 0.916        |
|    learning_rate        | 5.58e-05     |
|    loss                 | -0.0116      |
|    n_updates            | 5680         |
|    policy_gradient_loss | -0.00522     |
|    std                  | 0.649        |
|    value_loss           | 0.00373      |
------------------------------------------
box reached target
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 570          |
|    time_elapsed         | 1846         |
|    total_timesteps      | 1167360      |
| train/                  |              |
|    approx_kl            | 0.0047008106 |
|    clip_fraction        | 0.0372       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.96        |
|    explained_variance   | 0.898        |
|    learning_rate        | 5.58e-05     |
|    loss                 | 0.00209      |
|    n_updates            | 5690         |
|    policy_gradient_loss | -0.00718     |
|    std                  | 0.65         |
|    value_loss           | 0.00144      |
------------------------------------------
box reached target
---------------------------------------
| time/                   |           |
|    fps                  | 632       |
|    iterations           | 571       |
|    time_elapsed         | 1849      |
|    total_timesteps      | 1169408   |
| train/                  |           |
|    approx_kl            | 0.0058389 |
|    clip_fraction        | 0.0471    |
|    clip_range           | 0.2       |
|    entropy_loss         | -1.96     |
|    explained_variance   | 0.898     |
|    learning_rate        | 5.58e-05  |
|    loss                 | 0.03      |
|    n_updates            | 5700      |
|    policy_gradient_loss | -0.00511  |
|    std                  | 0.65      |
|    value_loss           | 0.0278    |
---------------------------------------
box reached target
Eval num_timesteps=1170000, episode_reward=0.26 +/- 2.53
Episode length: 274.60 +/- 50.80
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 275          |
|    mean_reward          | 0.264        |
| time/                   |              |
|    total_timesteps      | 1170000      |
| train/                  |              |
|    approx_kl            | 0.0045574047 |
|    clip_fraction        | 0.0298       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.96        |
|    explained_variance   | 0.914        |
|    learning_rate        | 5.58e-05     |
|    loss                 | -0.0273      |
|    n_updates            | 5710         |
|    policy_gradient_loss | -0.00604     |
|    std                  | 0.65         |
|    value_loss           | 0.0105       |
------------------------------------------
box reached target
--------------------------------
| time/              |         |
|    fps             | 632     |
|    iterations      | 572     |
|    time_elapsed    | 1853    |
|    total_timesteps | 1171456 |
--------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 573          |
|    time_elapsed         | 1856         |
|    total_timesteps      | 1173504      |
| train/                  |              |
|    approx_kl            | 0.0057655983 |
|    clip_fraction        | 0.0354       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.96        |
|    explained_variance   | 0.964        |
|    learning_rate        | 5.59e-05     |
|    loss                 | -0.0136      |
|    n_updates            | 5720         |
|    policy_gradient_loss | -0.00528     |
|    std                  | 0.65         |
|    value_loss           | 0.00409      |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 574          |
|    time_elapsed         | 1859         |
|    total_timesteps      | 1175552      |
| train/                  |              |
|    approx_kl            | 0.0051190043 |
|    clip_fraction        | 0.033        |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.97        |
|    explained_variance   | 0.712        |
|    learning_rate        | 5.59e-05     |
|    loss                 | 0.00578      |
|    n_updates            | 5730         |
|    policy_gradient_loss | -0.00663     |
|    std                  | 0.651        |
|    value_loss           | 0.00147      |
------------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 632         |
|    iterations           | 575         |
|    time_elapsed         | 1862        |
|    total_timesteps      | 1177600     |
| train/                  |             |
|    approx_kl            | 0.006693365 |
|    clip_fraction        | 0.0509      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.97       |
|    explained_variance   | 0.804       |
|    learning_rate        | 5.59e-05    |
|    loss                 | 0.00722     |
|    n_updates            | 5740        |
|    policy_gradient_loss | -0.00648    |
|    std                  | 0.652       |
|    value_loss           | 0.00113     |
-----------------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 632         |
|    iterations           | 576         |
|    time_elapsed         | 1865        |
|    total_timesteps      | 1179648     |
| train/                  |             |
|    approx_kl            | 0.008758961 |
|    clip_fraction        | 0.0843      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.98       |
|    explained_variance   | 0.962       |
|    learning_rate        | 5.59e-05    |
|    loss                 | 0.0383      |
|    n_updates            | 5750        |
|    policy_gradient_loss | -0.0114     |
|    std                  | 0.656       |
|    value_loss           | 0.0017      |
-----------------------------------------
Eval num_timesteps=1180000, episode_reward=-0.68 +/- 0.65
Episode length: 300.00 +/- 0.00
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 300          |
|    mean_reward          | -0.675       |
| time/                   |              |
|    total_timesteps      | 1180000      |
| train/                  |              |
|    approx_kl            | 0.0049147694 |
|    clip_fraction        | 0.0449       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.98        |
|    explained_variance   | 0.967        |
|    learning_rate        | 5.59e-05     |
|    loss                 | 0.00184      |
|    n_updates            | 5760         |
|    policy_gradient_loss | -0.00699     |
|    std                  | 0.656        |
|    value_loss           | 0.00239      |
------------------------------------------
--------------------------------
| time/              |         |
|    fps             | 632     |
|    iterations      | 577     |
|    time_elapsed    | 1869    |
|    total_timesteps | 1181696 |
--------------------------------
box reached target
box reached target
box reached target
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 578          |
|    time_elapsed         | 1872         |
|    total_timesteps      | 1183744      |
| train/                  |              |
|    approx_kl            | 0.0055645043 |
|    clip_fraction        | 0.0427       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.98        |
|    explained_variance   | 0.797        |
|    learning_rate        | 5.59e-05     |
|    loss                 | -0.0186      |
|    n_updates            | 5770         |
|    policy_gradient_loss | -0.00475     |
|    std                  | 0.656        |
|    value_loss           | 0.00126      |
------------------------------------------
box reached target
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 579          |
|    time_elapsed         | 1875         |
|    total_timesteps      | 1185792      |
| train/                  |              |
|    approx_kl            | 0.0049969447 |
|    clip_fraction        | 0.0348       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.98        |
|    explained_variance   | 0.87         |
|    learning_rate        | 5.59e-05     |
|    loss                 | -0.00171     |
|    n_updates            | 5780         |
|    policy_gradient_loss | -0.00375     |
|    std                  | 0.651        |
|    value_loss           | 0.0511       |
------------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 632         |
|    iterations           | 580         |
|    time_elapsed         | 1878        |
|    total_timesteps      | 1187840     |
| train/                  |             |
|    approx_kl            | 0.003869831 |
|    clip_fraction        | 0.0261      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.96       |
|    explained_variance   | 0.865       |
|    learning_rate        | 5.59e-05    |
|    loss                 | 0.0292      |
|    n_updates            | 5790        |
|    policy_gradient_loss | -0.00424    |
|    std                  | 0.649       |
|    value_loss           | 0.0207      |
-----------------------------------------
box reached target
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 581          |
|    time_elapsed         | 1881         |
|    total_timesteps      | 1189888      |
| train/                  |              |
|    approx_kl            | 0.0039226366 |
|    clip_fraction        | 0.0241       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.96        |
|    explained_variance   | 0.851        |
|    learning_rate        | 5.59e-05     |
|    loss                 | 0.0115       |
|    n_updates            | 5800         |
|    policy_gradient_loss | -0.00533     |
|    std                  | 0.651        |
|    value_loss           | 0.00258      |
------------------------------------------
box reached target
Eval num_timesteps=1190000, episode_reward=0.24 +/- 2.48
Episode length: 278.00 +/- 44.00
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 278          |
|    mean_reward          | 0.24         |
| time/                   |              |
|    total_timesteps      | 1190000      |
| train/                  |              |
|    approx_kl            | 0.0056515355 |
|    clip_fraction        | 0.044        |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.96        |
|    explained_variance   | 0.898        |
|    learning_rate        | 5.59e-05     |
|    loss                 | -0.0108      |
|    n_updates            | 5810         |
|    policy_gradient_loss | -0.00689     |
|    std                  | 0.649        |
|    value_loss           | 0.0174       |
------------------------------------------
box reached target
box reached target
--------------------------------
| time/              |         |
|    fps             | 632     |
|    iterations      | 582     |
|    time_elapsed    | 1885    |
|    total_timesteps | 1191936 |
--------------------------------
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 583          |
|    time_elapsed         | 1888         |
|    total_timesteps      | 1193984      |
| train/                  |              |
|    approx_kl            | 0.0041794972 |
|    clip_fraction        | 0.035        |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.96        |
|    explained_variance   | 0.922        |
|    learning_rate        | 5.6e-05      |
|    loss                 | 0.0023       |
|    n_updates            | 5820         |
|    policy_gradient_loss | -0.00351     |
|    std                  | 0.646        |
|    value_loss           | 0.0128       |
------------------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 632         |
|    iterations           | 584         |
|    time_elapsed         | 1891        |
|    total_timesteps      | 1196032     |
| train/                  |             |
|    approx_kl            | 0.003024472 |
|    clip_fraction        | 0.00962     |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.95       |
|    explained_variance   | 0.925       |
|    learning_rate        | 5.6e-05     |
|    loss                 | -0.0339     |
|    n_updates            | 5830        |
|    policy_gradient_loss | -0.00288    |
|    std                  | 0.648       |
|    value_loss           | 0.0121      |
-----------------------------------------
box reached target
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 585          |
|    time_elapsed         | 1894         |
|    total_timesteps      | 1198080      |
| train/                  |              |
|    approx_kl            | 0.0052940072 |
|    clip_fraction        | 0.0439       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.96        |
|    explained_variance   | 0.959        |
|    learning_rate        | 5.6e-05      |
|    loss                 | -0.0132      |
|    n_updates            | 5840         |
|    policy_gradient_loss | -0.00743     |
|    std                  | 0.649        |
|    value_loss           | 0.00833      |
------------------------------------------
box reached target
box reached target
Eval num_timesteps=1200000, episode_reward=0.28 +/- 2.57
Episode length: 281.80 +/- 36.40
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 282         |
|    mean_reward          | 0.283       |
| time/                   |             |
|    total_timesteps      | 1200000     |
| train/                  |             |
|    approx_kl            | 0.004531273 |
|    clip_fraction        | 0.0333      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.96       |
|    explained_variance   | 0.926       |
|    learning_rate        | 5.6e-05     |
|    loss                 | -0.0128     |
|    n_updates            | 5850        |
|    policy_gradient_loss | -0.00629    |
|    std                  | 0.65        |
|    value_loss           | 0.00647     |
-----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 632     |
|    iterations      | 586     |
|    time_elapsed    | 1898    |
|    total_timesteps | 1200128 |
--------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 632         |
|    iterations           | 587         |
|    time_elapsed         | 1901        |
|    total_timesteps      | 1202176     |
| train/                  |             |
|    approx_kl            | 0.002819745 |
|    clip_fraction        | 0.0217      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.97       |
|    explained_variance   | 0.885       |
|    learning_rate        | 5.6e-05     |
|    loss                 | -0.0222     |
|    n_updates            | 5860        |
|    policy_gradient_loss | -0.00418    |
|    std                  | 0.652       |
|    value_loss           | 0.0127      |
-----------------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 632         |
|    iterations           | 588         |
|    time_elapsed         | 1904        |
|    total_timesteps      | 1204224     |
| train/                  |             |
|    approx_kl            | 0.006728959 |
|    clip_fraction        | 0.0533      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.97       |
|    explained_variance   | 0.885       |
|    learning_rate        | 5.6e-05     |
|    loss                 | 0.0346      |
|    n_updates            | 5870        |
|    policy_gradient_loss | -0.00721    |
|    std                  | 0.652       |
|    value_loss           | 0.0223      |
-----------------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 632         |
|    iterations           | 589         |
|    time_elapsed         | 1907        |
|    total_timesteps      | 1206272     |
| train/                  |             |
|    approx_kl            | 0.004326973 |
|    clip_fraction        | 0.0284      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.96       |
|    explained_variance   | 0.932       |
|    learning_rate        | 5.6e-05     |
|    loss                 | -0.0035     |
|    n_updates            | 5880        |
|    policy_gradient_loss | -0.00452    |
|    std                  | 0.649       |
|    value_loss           | 0.0169      |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 632         |
|    iterations           | 590         |
|    time_elapsed         | 1910        |
|    total_timesteps      | 1208320     |
| train/                  |             |
|    approx_kl            | 0.006318388 |
|    clip_fraction        | 0.0596      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.96       |
|    explained_variance   | 0.902       |
|    learning_rate        | 5.6e-05     |
|    loss                 | -0.00591    |
|    n_updates            | 5890        |
|    policy_gradient_loss | -0.00595    |
|    std                  | 0.649       |
|    value_loss           | 0.00985     |
-----------------------------------------
box reached target
box reached target
Eval num_timesteps=1210000, episode_reward=0.52 +/- 2.57
Episode length: 286.60 +/- 26.80
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 287          |
|    mean_reward          | 0.521        |
| time/                   |              |
|    total_timesteps      | 1210000      |
| train/                  |              |
|    approx_kl            | 0.0048307837 |
|    clip_fraction        | 0.0375       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.96        |
|    explained_variance   | 0.79         |
|    learning_rate        | 5.6e-05      |
|    loss                 | -0.00373     |
|    n_updates            | 5900         |
|    policy_gradient_loss | -0.00703     |
|    std                  | 0.651        |
|    value_loss           | 0.00295      |
------------------------------------------
--------------------------------
| time/              |         |
|    fps             | 632     |
|    iterations      | 591     |
|    time_elapsed    | 1914    |
|    total_timesteps | 1210368 |
--------------------------------
box reached target
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 592          |
|    time_elapsed         | 1917         |
|    total_timesteps      | 1212416      |
| train/                  |              |
|    approx_kl            | 0.0070085675 |
|    clip_fraction        | 0.0621       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.97        |
|    explained_variance   | 0.984        |
|    learning_rate        | 5.61e-05     |
|    loss                 | -0.0201      |
|    n_updates            | 5910         |
|    policy_gradient_loss | -0.00733     |
|    std                  | 0.652        |
|    value_loss           | 0.00179      |
------------------------------------------
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 593          |
|    time_elapsed         | 1921         |
|    total_timesteps      | 1214464      |
| train/                  |              |
|    approx_kl            | 0.0058060684 |
|    clip_fraction        | 0.0502       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.97        |
|    explained_variance   | 0.882        |
|    learning_rate        | 5.61e-05     |
|    loss                 | -0.00848     |
|    n_updates            | 5920         |
|    policy_gradient_loss | -0.00821     |
|    std                  | 0.653        |
|    value_loss           | 0.0268       |
------------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 632         |
|    iterations           | 594         |
|    time_elapsed         | 1924        |
|    total_timesteps      | 1216512     |
| train/                  |             |
|    approx_kl            | 0.004062698 |
|    clip_fraction        | 0.031       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.97       |
|    explained_variance   | 0.85        |
|    learning_rate        | 5.61e-05    |
|    loss                 | 0.00827     |
|    n_updates            | 5930        |
|    policy_gradient_loss | -0.00422    |
|    std                  | 0.651       |
|    value_loss           | 0.00956     |
-----------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 595          |
|    time_elapsed         | 1927         |
|    total_timesteps      | 1218560      |
| train/                  |              |
|    approx_kl            | 0.0053353575 |
|    clip_fraction        | 0.0438       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.97        |
|    explained_variance   | 0.822        |
|    learning_rate        | 5.61e-05     |
|    loss                 | -0.000349    |
|    n_updates            | 5940         |
|    policy_gradient_loss | -0.00393     |
|    std                  | 0.653        |
|    value_loss           | 0.00805      |
------------------------------------------
box reached target
box reached target
box reached target
Eval num_timesteps=1220000, episode_reward=1.93 +/- 2.99
Episode length: 268.80 +/- 49.20
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 269         |
|    mean_reward          | 1.93        |
| time/                   |             |
|    total_timesteps      | 1220000     |
| train/                  |             |
|    approx_kl            | 0.005314404 |
|    clip_fraction        | 0.033       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.97       |
|    explained_variance   | 0.955       |
|    learning_rate        | 5.61e-05    |
|    loss                 | -0.0166     |
|    n_updates            | 5950        |
|    policy_gradient_loss | -0.0055     |
|    std                  | 0.652       |
|    value_loss           | 0.00269     |
-----------------------------------------
box reached target
--------------------------------
| time/              |         |
|    fps             | 632     |
|    iterations      | 596     |
|    time_elapsed    | 1931    |
|    total_timesteps | 1220608 |
--------------------------------
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 597          |
|    time_elapsed         | 1934         |
|    total_timesteps      | 1222656      |
| train/                  |              |
|    approx_kl            | 0.0054070787 |
|    clip_fraction        | 0.0551       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.97        |
|    explained_variance   | 0.981        |
|    learning_rate        | 5.61e-05     |
|    loss                 | 0.00267      |
|    n_updates            | 5960         |
|    policy_gradient_loss | -0.00909     |
|    std                  | 0.652        |
|    value_loss           | 0.00743      |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 598          |
|    time_elapsed         | 1937         |
|    total_timesteps      | 1224704      |
| train/                  |              |
|    approx_kl            | 0.0056135394 |
|    clip_fraction        | 0.048        |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.96        |
|    explained_variance   | 0.979        |
|    learning_rate        | 5.61e-05     |
|    loss                 | 0.00897      |
|    n_updates            | 5970         |
|    policy_gradient_loss | -0.00458     |
|    std                  | 0.651        |
|    value_loss           | 0.00162      |
------------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 632         |
|    iterations           | 599         |
|    time_elapsed         | 1940        |
|    total_timesteps      | 1226752     |
| train/                  |             |
|    approx_kl            | 0.005137981 |
|    clip_fraction        | 0.0419      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.96       |
|    explained_variance   | 0.831       |
|    learning_rate        | 5.61e-05    |
|    loss                 | -0.00265    |
|    n_updates            | 5980        |
|    policy_gradient_loss | -0.00896    |
|    std                  | 0.651       |
|    value_loss           | 0.0012      |
-----------------------------------------
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 600          |
|    time_elapsed         | 1943         |
|    total_timesteps      | 1228800      |
| train/                  |              |
|    approx_kl            | 0.0035394244 |
|    clip_fraction        | 0.0238       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.96        |
|    explained_variance   | 0.939        |
|    learning_rate        | 5.61e-05     |
|    loss                 | -0.00809     |
|    n_updates            | 5990         |
|    policy_gradient_loss | -0.00286     |
|    std                  | 0.65         |
|    value_loss           | 0.00194      |
------------------------------------------
box reached target
box reached target
box reached target
box reached target
Eval num_timesteps=1230000, episode_reward=1.49 +/- 3.06
Episode length: 250.00 +/- 61.35
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 250         |
|    mean_reward          | 1.49        |
| time/                   |             |
|    total_timesteps      | 1230000     |
| train/                  |             |
|    approx_kl            | 0.004036023 |
|    clip_fraction        | 0.0262      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.96       |
|    explained_variance   | 0.961       |
|    learning_rate        | 5.61e-05    |
|    loss                 | -0.01       |
|    n_updates            | 6000        |
|    policy_gradient_loss | -0.00305    |
|    std                  | 0.651       |
|    value_loss           | 0.00819     |
-----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 632     |
|    iterations      | 601     |
|    time_elapsed    | 1947    |
|    total_timesteps | 1230848 |
--------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 602          |
|    time_elapsed         | 1950         |
|    total_timesteps      | 1232896      |
| train/                  |              |
|    approx_kl            | 0.0042241113 |
|    clip_fraction        | 0.0266       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.96        |
|    explained_variance   | 0.699        |
|    learning_rate        | 5.62e-05     |
|    loss                 | 0.00382      |
|    n_updates            | 6010         |
|    policy_gradient_loss | -0.00284     |
|    std                  | 0.648        |
|    value_loss           | 0.0313       |
------------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 632         |
|    iterations           | 603         |
|    time_elapsed         | 1953        |
|    total_timesteps      | 1234944     |
| train/                  |             |
|    approx_kl            | 0.005812785 |
|    clip_fraction        | 0.0436      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.96       |
|    explained_variance   | 0.787       |
|    learning_rate        | 5.62e-05    |
|    loss                 | -0.00623    |
|    n_updates            | 6020        |
|    policy_gradient_loss | -0.00751    |
|    std                  | 0.651       |
|    value_loss           | 0.00402     |
-----------------------------------------
box reached target
box reached target
box reached target
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 604          |
|    time_elapsed         | 1956         |
|    total_timesteps      | 1236992      |
| train/                  |              |
|    approx_kl            | 0.0060346588 |
|    clip_fraction        | 0.0418       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.97        |
|    explained_variance   | 0.909        |
|    learning_rate        | 5.62e-05     |
|    loss                 | -0.0264      |
|    n_updates            | 6030         |
|    policy_gradient_loss | -0.00588     |
|    std                  | 0.651        |
|    value_loss           | 0.00534      |
------------------------------------------
box reached target
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 605          |
|    time_elapsed         | 1959         |
|    total_timesteps      | 1239040      |
| train/                  |              |
|    approx_kl            | 0.0047736373 |
|    clip_fraction        | 0.0337       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.96        |
|    explained_variance   | 0.953        |
|    learning_rate        | 5.62e-05     |
|    loss                 | 0.0224       |
|    n_updates            | 6040         |
|    policy_gradient_loss | -0.00374     |
|    std                  | 0.649        |
|    value_loss           | 0.0205       |
------------------------------------------
Eval num_timesteps=1240000, episode_reward=-1.08 +/- 0.13
Episode length: 300.00 +/- 0.00
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 300          |
|    mean_reward          | -1.08        |
| time/                   |              |
|    total_timesteps      | 1240000      |
| train/                  |              |
|    approx_kl            | 0.0067650294 |
|    clip_fraction        | 0.0667       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.96        |
|    explained_variance   | 0.993        |
|    learning_rate        | 5.62e-05     |
|    loss                 | -0.0201      |
|    n_updates            | 6050         |
|    policy_gradient_loss | -0.00914     |
|    std                  | 0.65         |
|    value_loss           | 0.00285      |
------------------------------------------
box reached target
--------------------------------
| time/              |         |
|    fps             | 632     |
|    iterations      | 606     |
|    time_elapsed    | 1963    |
|    total_timesteps | 1241088 |
--------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 632         |
|    iterations           | 607         |
|    time_elapsed         | 1966        |
|    total_timesteps      | 1243136     |
| train/                  |             |
|    approx_kl            | 0.004021489 |
|    clip_fraction        | 0.0235      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.96       |
|    explained_variance   | 0.868       |
|    learning_rate        | 5.62e-05    |
|    loss                 | 0.00306     |
|    n_updates            | 6060        |
|    policy_gradient_loss | -0.00359    |
|    std                  | 0.65        |
|    value_loss           | 0.0387      |
-----------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 608          |
|    time_elapsed         | 1969         |
|    total_timesteps      | 1245184      |
| train/                  |              |
|    approx_kl            | 0.0044781514 |
|    clip_fraction        | 0.0354       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.96        |
|    explained_variance   | 0.791        |
|    learning_rate        | 5.62e-05     |
|    loss                 | -0.00447     |
|    n_updates            | 6070         |
|    policy_gradient_loss | -0.00443     |
|    std                  | 0.65         |
|    value_loss           | 0.0068       |
------------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 632         |
|    iterations           | 609         |
|    time_elapsed         | 1972        |
|    total_timesteps      | 1247232     |
| train/                  |             |
|    approx_kl            | 0.003333793 |
|    clip_fraction        | 0.0279      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.96       |
|    explained_variance   | 0.872       |
|    learning_rate        | 5.62e-05    |
|    loss                 | 0.00579     |
|    n_updates            | 6080        |
|    policy_gradient_loss | -0.00536    |
|    std                  | 0.65        |
|    value_loss           | 0.00645     |
-----------------------------------------
box reached target
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 610          |
|    time_elapsed         | 1975         |
|    total_timesteps      | 1249280      |
| train/                  |              |
|    approx_kl            | 0.0039312732 |
|    clip_fraction        | 0.0267       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.96        |
|    explained_variance   | 0.898        |
|    learning_rate        | 5.62e-05     |
|    loss                 | 0.000274     |
|    n_updates            | 6090         |
|    policy_gradient_loss | -0.00241     |
|    std                  | 0.65         |
|    value_loss           | 0.00584      |
------------------------------------------
Eval num_timesteps=1250000, episode_reward=-1.06 +/- 0.13
Episode length: 300.00 +/- 0.00
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 300          |
|    mean_reward          | -1.06        |
| time/                   |              |
|    total_timesteps      | 1250000      |
| train/                  |              |
|    approx_kl            | 0.0061098076 |
|    clip_fraction        | 0.0357       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.96        |
|    explained_variance   | 0.877        |
|    learning_rate        | 5.62e-05     |
|    loss                 | 0.00121      |
|    n_updates            | 6100         |
|    policy_gradient_loss | -0.00414     |
|    std                  | 0.648        |
|    value_loss           | 0.0364       |
------------------------------------------
--------------------------------
| time/              |         |
|    fps             | 632     |
|    iterations      | 611     |
|    time_elapsed    | 1979    |
|    total_timesteps | 1251328 |
--------------------------------
box reached target
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 612          |
|    time_elapsed         | 1982         |
|    total_timesteps      | 1253376      |
| train/                  |              |
|    approx_kl            | 0.0066884393 |
|    clip_fraction        | 0.0465       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.95        |
|    explained_variance   | 0.83         |
|    learning_rate        | 5.63e-05     |
|    loss                 | -0.0203      |
|    n_updates            | 6110         |
|    policy_gradient_loss | -0.00735     |
|    std                  | 0.647        |
|    value_loss           | 0.00309      |
------------------------------------------
box reached target
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 613          |
|    time_elapsed         | 1985         |
|    total_timesteps      | 1255424      |
| train/                  |              |
|    approx_kl            | 0.0036479686 |
|    clip_fraction        | 0.0148       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.95        |
|    explained_variance   | 0.942        |
|    learning_rate        | 5.63e-05     |
|    loss                 | -0.00891     |
|    n_updates            | 6120         |
|    policy_gradient_loss | -0.00357     |
|    std                  | 0.645        |
|    value_loss           | 0.013        |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 614          |
|    time_elapsed         | 1988         |
|    total_timesteps      | 1257472      |
| train/                  |              |
|    approx_kl            | 0.0060538724 |
|    clip_fraction        | 0.0418       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.94        |
|    explained_variance   | 0.943        |
|    learning_rate        | 5.63e-05     |
|    loss                 | 0.00536      |
|    n_updates            | 6130         |
|    policy_gradient_loss | -0.00543     |
|    std                  | 0.645        |
|    value_loss           | 0.0129       |
------------------------------------------
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 615          |
|    time_elapsed         | 1991         |
|    total_timesteps      | 1259520      |
| train/                  |              |
|    approx_kl            | 0.0067535425 |
|    clip_fraction        | 0.0491       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.95        |
|    explained_variance   | 0.736        |
|    learning_rate        | 5.63e-05     |
|    loss                 | -0.0357      |
|    n_updates            | 6140         |
|    policy_gradient_loss | -0.00798     |
|    std                  | 0.647        |
|    value_loss           | 0.00196      |
------------------------------------------
box reached target
Eval num_timesteps=1260000, episode_reward=0.59 +/- 2.46
Episode length: 271.40 +/- 57.20
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 271         |
|    mean_reward          | 0.587       |
| time/                   |             |
|    total_timesteps      | 1260000     |
| train/                  |             |
|    approx_kl            | 0.005189437 |
|    clip_fraction        | 0.0347      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.95       |
|    explained_variance   | 0.932       |
|    learning_rate        | 5.63e-05    |
|    loss                 | -0.0112     |
|    n_updates            | 6150        |
|    policy_gradient_loss | -0.00454    |
|    std                  | 0.648       |
|    value_loss           | 0.00814     |
-----------------------------------------
box reached target
--------------------------------
| time/              |         |
|    fps             | 632     |
|    iterations      | 616     |
|    time_elapsed    | 1995    |
|    total_timesteps | 1261568 |
--------------------------------
box reached target
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 632         |
|    iterations           | 617         |
|    time_elapsed         | 1998        |
|    total_timesteps      | 1263616     |
| train/                  |             |
|    approx_kl            | 0.005113555 |
|    clip_fraction        | 0.0429      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.95       |
|    explained_variance   | 0.944       |
|    learning_rate        | 5.63e-05    |
|    loss                 | -0.000792   |
|    n_updates            | 6160        |
|    policy_gradient_loss | -0.00539    |
|    std                  | 0.645       |
|    value_loss           | 0.00437     |
-----------------------------------------
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 618          |
|    time_elapsed         | 2001         |
|    total_timesteps      | 1265664      |
| train/                  |              |
|    approx_kl            | 0.0070708785 |
|    clip_fraction        | 0.0607       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.94        |
|    explained_variance   | 0.979        |
|    learning_rate        | 5.63e-05     |
|    loss                 | 0.0044       |
|    n_updates            | 6170         |
|    policy_gradient_loss | -0.00675     |
|    std                  | 0.644        |
|    value_loss           | 0.00507      |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 619          |
|    time_elapsed         | 2004         |
|    total_timesteps      | 1267712      |
| train/                  |              |
|    approx_kl            | 0.0043735234 |
|    clip_fraction        | 0.0266       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.94        |
|    explained_variance   | 0.989        |
|    learning_rate        | 5.63e-05     |
|    loss                 | -0.0228      |
|    n_updates            | 6180         |
|    policy_gradient_loss | -0.00514     |
|    std                  | 0.641        |
|    value_loss           | 0.00225      |
------------------------------------------
box reached target
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 632         |
|    iterations           | 620         |
|    time_elapsed         | 2007        |
|    total_timesteps      | 1269760     |
| train/                  |             |
|    approx_kl            | 0.005778241 |
|    clip_fraction        | 0.0304      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.93       |
|    explained_variance   | 0.854       |
|    learning_rate        | 5.63e-05    |
|    loss                 | -0.0216     |
|    n_updates            | 6190        |
|    policy_gradient_loss | -0.00599    |
|    std                  | 0.641       |
|    value_loss           | 0.000802    |
-----------------------------------------
Eval num_timesteps=1270000, episode_reward=-0.81 +/- 0.54
Episode length: 300.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 300         |
|    mean_reward          | -0.812      |
| time/                   |             |
|    total_timesteps      | 1270000     |
| train/                  |             |
|    approx_kl            | 0.004148542 |
|    clip_fraction        | 0.0256      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.93       |
|    explained_variance   | 0.855       |
|    learning_rate        | 5.63e-05    |
|    loss                 | -0.0139     |
|    n_updates            | 6200        |
|    policy_gradient_loss | -0.00359    |
|    std                  | 0.64        |
|    value_loss           | 0.0249      |
-----------------------------------------
box reached target
box reached target
box reached target
--------------------------------
| time/              |         |
|    fps             | 632     |
|    iterations      | 621     |
|    time_elapsed    | 2011    |
|    total_timesteps | 1271808 |
--------------------------------
box reached target
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 622          |
|    time_elapsed         | 2014         |
|    total_timesteps      | 1273856      |
| train/                  |              |
|    approx_kl            | 0.0048932247 |
|    clip_fraction        | 0.0316       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.93        |
|    explained_variance   | 0.916        |
|    learning_rate        | 5.64e-05     |
|    loss                 | -0.0278      |
|    n_updates            | 6210         |
|    policy_gradient_loss | -0.00558     |
|    std                  | 0.639        |
|    value_loss           | 0.0192       |
------------------------------------------
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 623          |
|    time_elapsed         | 2018         |
|    total_timesteps      | 1275904      |
| train/                  |              |
|    approx_kl            | 0.0045884224 |
|    clip_fraction        | 0.0256       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.93        |
|    explained_variance   | 0.951        |
|    learning_rate        | 5.64e-05     |
|    loss                 | -0.0127      |
|    n_updates            | 6220         |
|    policy_gradient_loss | -0.00394     |
|    std                  | 0.642        |
|    value_loss           | 0.00729      |
------------------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 632         |
|    iterations           | 624         |
|    time_elapsed         | 2021        |
|    total_timesteps      | 1277952     |
| train/                  |             |
|    approx_kl            | 0.004761739 |
|    clip_fraction        | 0.0379      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.93       |
|    explained_variance   | 0.972       |
|    learning_rate        | 5.64e-05    |
|    loss                 | 0.00135     |
|    n_updates            | 6230        |
|    policy_gradient_loss | -0.00459    |
|    std                  | 0.641       |
|    value_loss           | 0.00453     |
-----------------------------------------
box reached target
Eval num_timesteps=1280000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 300          |
|    mean_reward          | -1           |
| time/                   |              |
|    total_timesteps      | 1280000      |
| train/                  |              |
|    approx_kl            | 0.0044391607 |
|    clip_fraction        | 0.0498       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.93        |
|    explained_variance   | 0.964        |
|    learning_rate        | 5.64e-05     |
|    loss                 | 0.00932      |
|    n_updates            | 6240         |
|    policy_gradient_loss | -0.00842     |
|    std                  | 0.642        |
|    value_loss           | 0.00305      |
------------------------------------------
--------------------------------
| time/              |         |
|    fps             | 632     |
|    iterations      | 625     |
|    time_elapsed    | 2025    |
|    total_timesteps | 1280000 |
--------------------------------
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 626          |
|    time_elapsed         | 2028         |
|    total_timesteps      | 1282048      |
| train/                  |              |
|    approx_kl            | 0.0045797676 |
|    clip_fraction        | 0.0323       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.93        |
|    explained_variance   | 0.964        |
|    learning_rate        | 5.64e-05     |
|    loss                 | -0.00363     |
|    n_updates            | 6250         |
|    policy_gradient_loss | -0.00558     |
|    std                  | 0.643        |
|    value_loss           | 0.00383      |
------------------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 632         |
|    iterations           | 627         |
|    time_elapsed         | 2031        |
|    total_timesteps      | 1284096     |
| train/                  |             |
|    approx_kl            | 0.004270392 |
|    clip_fraction        | 0.0335      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.94       |
|    explained_variance   | 0.946       |
|    learning_rate        | 5.64e-05    |
|    loss                 | 0.00514     |
|    n_updates            | 6260        |
|    policy_gradient_loss | -0.0053     |
|    std                  | 0.643       |
|    value_loss           | 0.00642     |
-----------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 628          |
|    time_elapsed         | 2034         |
|    total_timesteps      | 1286144      |
| train/                  |              |
|    approx_kl            | 0.0044683926 |
|    clip_fraction        | 0.0326       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.94        |
|    explained_variance   | 0.913        |
|    learning_rate        | 5.64e-05     |
|    loss                 | -0.0208      |
|    n_updates            | 6270         |
|    policy_gradient_loss | -0.00586     |
|    std                  | 0.648        |
|    value_loss           | 0.00806      |
------------------------------------------
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 629          |
|    time_elapsed         | 2037         |
|    total_timesteps      | 1288192      |
| train/                  |              |
|    approx_kl            | 0.0044235834 |
|    clip_fraction        | 0.0329       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.95        |
|    explained_variance   | 0.879        |
|    learning_rate        | 5.64e-05     |
|    loss                 | 0.0186       |
|    n_updates            | 6280         |
|    policy_gradient_loss | -0.00582     |
|    std                  | 0.647        |
|    value_loss           | 0.00232      |
------------------------------------------
box reached target
box reached target
box reached target
Eval num_timesteps=1290000, episode_reward=1.66 +/- 3.13
Episode length: 255.60 +/- 55.31
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 256          |
|    mean_reward          | 1.66         |
| time/                   |              |
|    total_timesteps      | 1290000      |
| train/                  |              |
|    approx_kl            | 0.0047220327 |
|    clip_fraction        | 0.0493       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.94        |
|    explained_variance   | 0.929        |
|    learning_rate        | 5.64e-05     |
|    loss                 | 0.0228       |
|    n_updates            | 6290         |
|    policy_gradient_loss | -0.00743     |
|    std                  | 0.645        |
|    value_loss           | 0.00454      |
------------------------------------------
--------------------------------
| time/              |         |
|    fps             | 632     |
|    iterations      | 630     |
|    time_elapsed    | 2041    |
|    total_timesteps | 1290240 |
--------------------------------
box reached target
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 632         |
|    iterations           | 631         |
|    time_elapsed         | 2044        |
|    total_timesteps      | 1292288     |
| train/                  |             |
|    approx_kl            | 0.004787692 |
|    clip_fraction        | 0.032       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.94       |
|    explained_variance   | 0.972       |
|    learning_rate        | 5.65e-05    |
|    loss                 | 0.0413      |
|    n_updates            | 6300        |
|    policy_gradient_loss | -0.00422    |
|    std                  | 0.643       |
|    value_loss           | 0.00507     |
-----------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 632          |
|    time_elapsed         | 2047         |
|    total_timesteps      | 1294336      |
| train/                  |              |
|    approx_kl            | 0.0034268778 |
|    clip_fraction        | 0.0123       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.93        |
|    explained_variance   | 0.856        |
|    learning_rate        | 5.65e-05     |
|    loss                 | 0.0278       |
|    n_updates            | 6310         |
|    policy_gradient_loss | -0.00272     |
|    std                  | 0.643        |
|    value_loss           | 0.0333       |
------------------------------------------
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 633          |
|    time_elapsed         | 2050         |
|    total_timesteps      | 1296384      |
| train/                  |              |
|    approx_kl            | 0.0025002612 |
|    clip_fraction        | 0.0133       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.94        |
|    explained_variance   | 0.768        |
|    learning_rate        | 5.65e-05     |
|    loss                 | 0.0109       |
|    n_updates            | 6320         |
|    policy_gradient_loss | -0.00255     |
|    std                  | 0.647        |
|    value_loss           | 0.026        |
------------------------------------------
box reached target
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 634          |
|    time_elapsed         | 2053         |
|    total_timesteps      | 1298432      |
| train/                  |              |
|    approx_kl            | 0.0031463616 |
|    clip_fraction        | 0.0184       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.94        |
|    explained_variance   | 0.968        |
|    learning_rate        | 5.65e-05     |
|    loss                 | 0.00927      |
|    n_updates            | 6330         |
|    policy_gradient_loss | -0.00447     |
|    std                  | 0.647        |
|    value_loss           | 0.00527      |
------------------------------------------
box reached target
Eval num_timesteps=1300000, episode_reward=0.42 +/- 2.41
Episode length: 276.40 +/- 47.20
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 276          |
|    mean_reward          | 0.415        |
| time/                   |              |
|    total_timesteps      | 1300000      |
| train/                  |              |
|    approx_kl            | 0.0043595247 |
|    clip_fraction        | 0.029        |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.94        |
|    explained_variance   | 0.888        |
|    learning_rate        | 5.65e-05     |
|    loss                 | 0.01         |
|    n_updates            | 6340         |
|    policy_gradient_loss | -0.00434     |
|    std                  | 0.645        |
|    value_loss           | 0.0393       |
------------------------------------------
--------------------------------
| time/              |         |
|    fps             | 632     |
|    iterations      | 635     |
|    time_elapsed    | 2057    |
|    total_timesteps | 1300480 |
--------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 632         |
|    iterations           | 636         |
|    time_elapsed         | 2060        |
|    total_timesteps      | 1302528     |
| train/                  |             |
|    approx_kl            | 0.005447232 |
|    clip_fraction        | 0.0623      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.95       |
|    explained_variance   | 0.875       |
|    learning_rate        | 5.65e-05    |
|    loss                 | -0.00708    |
|    n_updates            | 6350        |
|    policy_gradient_loss | -0.00918    |
|    std                  | 0.649       |
|    value_loss           | 0.00278     |
-----------------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 632         |
|    iterations           | 637         |
|    time_elapsed         | 2063        |
|    total_timesteps      | 1304576     |
| train/                  |             |
|    approx_kl            | 0.004676263 |
|    clip_fraction        | 0.0308      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.95       |
|    explained_variance   | 0.767       |
|    learning_rate        | 5.65e-05    |
|    loss                 | 0.00236     |
|    n_updates            | 6360        |
|    policy_gradient_loss | -0.00443    |
|    std                  | 0.649       |
|    value_loss           | 0.00137     |
-----------------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 632         |
|    iterations           | 638         |
|    time_elapsed         | 2066        |
|    total_timesteps      | 1306624     |
| train/                  |             |
|    approx_kl            | 0.004086136 |
|    clip_fraction        | 0.0355      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.95       |
|    explained_variance   | 0.882       |
|    learning_rate        | 5.65e-05    |
|    loss                 | -0.0113     |
|    n_updates            | 6370        |
|    policy_gradient_loss | -0.00497    |
|    std                  | 0.648       |
|    value_loss           | 0.00784     |
-----------------------------------------
box reached target
box reached target
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 639          |
|    time_elapsed         | 2069         |
|    total_timesteps      | 1308672      |
| train/                  |              |
|    approx_kl            | 0.0045707994 |
|    clip_fraction        | 0.0318       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.94        |
|    explained_variance   | 0.979        |
|    learning_rate        | 5.65e-05     |
|    loss                 | -0.0117      |
|    n_updates            | 6380         |
|    policy_gradient_loss | -0.00657     |
|    std                  | 0.645        |
|    value_loss           | 0.00398      |
------------------------------------------
Eval num_timesteps=1310000, episode_reward=-0.77 +/- 0.45
Episode length: 300.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 300         |
|    mean_reward          | -0.773      |
| time/                   |             |
|    total_timesteps      | 1310000     |
| train/                  |             |
|    approx_kl            | 0.005220975 |
|    clip_fraction        | 0.0382      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.94       |
|    explained_variance   | 0.762       |
|    learning_rate        | 5.65e-05    |
|    loss                 | -0.00531    |
|    n_updates            | 6390        |
|    policy_gradient_loss | -0.00461    |
|    std                  | 0.644       |
|    value_loss           | 0.057       |
-----------------------------------------
box reached target
--------------------------------
| time/              |         |
|    fps             | 632     |
|    iterations      | 640     |
|    time_elapsed    | 2073    |
|    total_timesteps | 1310720 |
--------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 641          |
|    time_elapsed         | 2076         |
|    total_timesteps      | 1312768      |
| train/                  |              |
|    approx_kl            | 0.0041555436 |
|    clip_fraction        | 0.0261       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.94        |
|    explained_variance   | 0.815        |
|    learning_rate        | 5.66e-05     |
|    loss                 | 0.0154       |
|    n_updates            | 6400         |
|    policy_gradient_loss | -0.00516     |
|    std                  | 0.645        |
|    value_loss           | 0.0246       |
------------------------------------------
box reached target
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 642          |
|    time_elapsed         | 2079         |
|    total_timesteps      | 1314816      |
| train/                  |              |
|    approx_kl            | 0.0050076726 |
|    clip_fraction        | 0.0386       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.94        |
|    explained_variance   | 0.953        |
|    learning_rate        | 5.66e-05     |
|    loss                 | -0.0275      |
|    n_updates            | 6410         |
|    policy_gradient_loss | -0.00654     |
|    std                  | 0.645        |
|    value_loss           | 0.00172      |
------------------------------------------
box reached target
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 632         |
|    iterations           | 643         |
|    time_elapsed         | 2082        |
|    total_timesteps      | 1316864     |
| train/                  |             |
|    approx_kl            | 0.004133762 |
|    clip_fraction        | 0.0361      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.94       |
|    explained_variance   | 0.935       |
|    learning_rate        | 5.66e-05    |
|    loss                 | 1.64e-05    |
|    n_updates            | 6420        |
|    policy_gradient_loss | -0.00718    |
|    std                  | 0.644       |
|    value_loss           | 0.0214      |
-----------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 644          |
|    time_elapsed         | 2085         |
|    total_timesteps      | 1318912      |
| train/                  |              |
|    approx_kl            | 0.0029955567 |
|    clip_fraction        | 0.00996      |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.93        |
|    explained_variance   | 0.946        |
|    learning_rate        | 5.66e-05     |
|    loss                 | -0.00632     |
|    n_updates            | 6430         |
|    policy_gradient_loss | -0.00129     |
|    std                  | 0.643        |
|    value_loss           | 0.0142       |
------------------------------------------
box reached target
box reached target
Eval num_timesteps=1320000, episode_reward=0.79 +/- 2.39
Episode length: 281.20 +/- 37.60
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 281         |
|    mean_reward          | 0.789       |
| time/                   |             |
|    total_timesteps      | 1320000     |
| train/                  |             |
|    approx_kl            | 0.004002577 |
|    clip_fraction        | 0.0253      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.93       |
|    explained_variance   | 0.865       |
|    learning_rate        | 5.66e-05    |
|    loss                 | -0.00557    |
|    n_updates            | 6440        |
|    policy_gradient_loss | -0.00522    |
|    std                  | 0.645       |
|    value_loss           | 0.0107      |
-----------------------------------------
box reached target
--------------------------------
| time/              |         |
|    fps             | 632     |
|    iterations      | 645     |
|    time_elapsed    | 2089    |
|    total_timesteps | 1320960 |
--------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 632         |
|    iterations           | 646         |
|    time_elapsed         | 2092        |
|    total_timesteps      | 1323008     |
| train/                  |             |
|    approx_kl            | 0.004675224 |
|    clip_fraction        | 0.0271      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.94       |
|    explained_variance   | 0.955       |
|    learning_rate        | 5.66e-05    |
|    loss                 | -0.0235     |
|    n_updates            | 6450        |
|    policy_gradient_loss | -0.00329    |
|    std                  | 0.645       |
|    value_loss           | 0.0155      |
-----------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 647          |
|    time_elapsed         | 2095         |
|    total_timesteps      | 1325056      |
| train/                  |              |
|    approx_kl            | 0.0056614745 |
|    clip_fraction        | 0.0374       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.93        |
|    explained_variance   | 0.968        |
|    learning_rate        | 5.66e-05     |
|    loss                 | -0.0141      |
|    n_updates            | 6460         |
|    policy_gradient_loss | -0.0047      |
|    std                  | 0.644        |
|    value_loss           | 0.00802      |
------------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 632         |
|    iterations           | 648         |
|    time_elapsed         | 2098        |
|    total_timesteps      | 1327104     |
| train/                  |             |
|    approx_kl            | 0.004327928 |
|    clip_fraction        | 0.0276      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.93       |
|    explained_variance   | 0.798       |
|    learning_rate        | 5.66e-05    |
|    loss                 | -0.0102     |
|    n_updates            | 6470        |
|    policy_gradient_loss | -0.00391    |
|    std                  | 0.644       |
|    value_loss           | 0.00116     |
-----------------------------------------
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 649          |
|    time_elapsed         | 2101         |
|    total_timesteps      | 1329152      |
| train/                  |              |
|    approx_kl            | 0.0060194093 |
|    clip_fraction        | 0.0607       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.93        |
|    explained_variance   | 0.889        |
|    learning_rate        | 5.66e-05     |
|    loss                 | -0.0166      |
|    n_updates            | 6480         |
|    policy_gradient_loss | -0.00736     |
|    std                  | 0.644        |
|    value_loss           | 0.00194      |
------------------------------------------
box reached target
Eval num_timesteps=1330000, episode_reward=0.54 +/- 2.47
Episode length: 282.00 +/- 36.00
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 282          |
|    mean_reward          | 0.542        |
| time/                   |              |
|    total_timesteps      | 1330000      |
| train/                  |              |
|    approx_kl            | 0.0041293586 |
|    clip_fraction        | 0.0226       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.93        |
|    explained_variance   | 0.958        |
|    learning_rate        | 5.66e-05     |
|    loss                 | 0.00943      |
|    n_updates            | 6490         |
|    policy_gradient_loss | -0.00375     |
|    std                  | 0.641        |
|    value_loss           | 0.00939      |
------------------------------------------
--------------------------------
| time/              |         |
|    fps             | 632     |
|    iterations      | 650     |
|    time_elapsed    | 2105    |
|    total_timesteps | 1331200 |
--------------------------------
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 651          |
|    time_elapsed         | 2109         |
|    total_timesteps      | 1333248      |
| train/                  |              |
|    approx_kl            | 0.0033404676 |
|    clip_fraction        | 0.0361       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.93        |
|    explained_variance   | 0.898        |
|    learning_rate        | 5.67e-05     |
|    loss                 | 0.00846      |
|    n_updates            | 6500         |
|    policy_gradient_loss | -0.00579     |
|    std                  | 0.642        |
|    value_loss           | 0.00946      |
------------------------------------------
box reached target
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 652          |
|    time_elapsed         | 2112         |
|    total_timesteps      | 1335296      |
| train/                  |              |
|    approx_kl            | 0.0044455957 |
|    clip_fraction        | 0.0302       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.93        |
|    explained_variance   | 0.973        |
|    learning_rate        | 5.67e-05     |
|    loss                 | 0.0197       |
|    n_updates            | 6510         |
|    policy_gradient_loss | -0.00367     |
|    std                  | 0.64         |
|    value_loss           | 0.00381      |
------------------------------------------
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 653          |
|    time_elapsed         | 2115         |
|    total_timesteps      | 1337344      |
| train/                  |              |
|    approx_kl            | 0.0061517134 |
|    clip_fraction        | 0.0591       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.93        |
|    explained_variance   | 0.946        |
|    learning_rate        | 5.67e-05     |
|    loss                 | -0.0026      |
|    n_updates            | 6520         |
|    policy_gradient_loss | -0.00695     |
|    std                  | 0.642        |
|    value_loss           | 0.00545      |
------------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 632        |
|    iterations           | 654        |
|    time_elapsed         | 2118       |
|    total_timesteps      | 1339392    |
| train/                  |            |
|    approx_kl            | 0.00370347 |
|    clip_fraction        | 0.0212     |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.93      |
|    explained_variance   | 0.931      |
|    learning_rate        | 5.67e-05   |
|    loss                 | 0.00431    |
|    n_updates            | 6530       |
|    policy_gradient_loss | -0.00157   |
|    std                  | 0.641      |
|    value_loss           | 0.0184     |
----------------------------------------
Eval num_timesteps=1340000, episode_reward=-0.34 +/- 0.61
Episode length: 300.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 300         |
|    mean_reward          | -0.339      |
| time/                   |             |
|    total_timesteps      | 1340000     |
| train/                  |             |
|    approx_kl            | 0.004536233 |
|    clip_fraction        | 0.0285      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.92       |
|    explained_variance   | 0.919       |
|    learning_rate        | 5.67e-05    |
|    loss                 | -0.0211     |
|    n_updates            | 6540        |
|    policy_gradient_loss | -0.00465    |
|    std                  | 0.64        |
|    value_loss           | 0.00227     |
-----------------------------------------
box reached target
--------------------------------
| time/              |         |
|    fps             | 632     |
|    iterations      | 655     |
|    time_elapsed    | 2122    |
|    total_timesteps | 1341440 |
--------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 632         |
|    iterations           | 656         |
|    time_elapsed         | 2125        |
|    total_timesteps      | 1343488     |
| train/                  |             |
|    approx_kl            | 0.004325088 |
|    clip_fraction        | 0.0272      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.92       |
|    explained_variance   | 0.917       |
|    learning_rate        | 5.67e-05    |
|    loss                 | -0.0115     |
|    n_updates            | 6550        |
|    policy_gradient_loss | -0.0047     |
|    std                  | 0.638       |
|    value_loss           | 0.00753     |
-----------------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 632         |
|    iterations           | 657         |
|    time_elapsed         | 2128        |
|    total_timesteps      | 1345536     |
| train/                  |             |
|    approx_kl            | 0.004800817 |
|    clip_fraction        | 0.0371      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.92       |
|    explained_variance   | 0.961       |
|    learning_rate        | 5.67e-05    |
|    loss                 | 0.0156      |
|    n_updates            | 6560        |
|    policy_gradient_loss | -0.00537    |
|    std                  | 0.639       |
|    value_loss           | 0.00525     |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 632         |
|    iterations           | 658         |
|    time_elapsed         | 2131        |
|    total_timesteps      | 1347584     |
| train/                  |             |
|    approx_kl            | 0.005754002 |
|    clip_fraction        | 0.0505      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.92       |
|    explained_variance   | 0.967       |
|    learning_rate        | 5.67e-05    |
|    loss                 | -0.0119     |
|    n_updates            | 6570        |
|    policy_gradient_loss | -0.00631    |
|    std                  | 0.638       |
|    value_loss           | 0.00424     |
-----------------------------------------
box reached target
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 659          |
|    time_elapsed         | 2134         |
|    total_timesteps      | 1349632      |
| train/                  |              |
|    approx_kl            | 0.0050632297 |
|    clip_fraction        | 0.0351       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.92        |
|    explained_variance   | 0.784        |
|    learning_rate        | 5.67e-05     |
|    loss                 | -0.0238      |
|    n_updates            | 6580         |
|    policy_gradient_loss | -0.00605     |
|    std                  | 0.639        |
|    value_loss           | 0.00384      |
------------------------------------------
box reached target
box reached target
Eval num_timesteps=1350000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 300          |
|    mean_reward          | -1           |
| time/                   |              |
|    total_timesteps      | 1350000      |
| train/                  |              |
|    approx_kl            | 0.0037569995 |
|    clip_fraction        | 0.0173       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.92        |
|    explained_variance   | 0.933        |
|    learning_rate        | 5.67e-05     |
|    loss                 | -0.00149     |
|    n_updates            | 6590         |
|    policy_gradient_loss | -0.00171     |
|    std                  | 0.64         |
|    value_loss           | 0.00879      |
------------------------------------------
box reached target
box reached target
box reached target
--------------------------------
| time/              |         |
|    fps             | 632     |
|    iterations      | 660     |
|    time_elapsed    | 2138    |
|    total_timesteps | 1351680 |
--------------------------------
box reached target
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 632         |
|    iterations           | 661         |
|    time_elapsed         | 2141        |
|    total_timesteps      | 1353728     |
| train/                  |             |
|    approx_kl            | 0.004820941 |
|    clip_fraction        | 0.0259      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.92       |
|    explained_variance   | 0.934       |
|    learning_rate        | 5.68e-05    |
|    loss                 | 0.0255      |
|    n_updates            | 6600        |
|    policy_gradient_loss | -0.00257    |
|    std                  | 0.639       |
|    value_loss           | 0.0355      |
-----------------------------------------
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 662          |
|    time_elapsed         | 2144         |
|    total_timesteps      | 1355776      |
| train/                  |              |
|    approx_kl            | 0.0047030607 |
|    clip_fraction        | 0.0535       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.92        |
|    explained_variance   | 0.932        |
|    learning_rate        | 5.68e-05     |
|    loss                 | 0.0114       |
|    n_updates            | 6610         |
|    policy_gradient_loss | -0.00733     |
|    std                  | 0.636        |
|    value_loss           | 0.0172       |
------------------------------------------
box reached target
box reached target
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 632         |
|    iterations           | 663         |
|    time_elapsed         | 2147        |
|    total_timesteps      | 1357824     |
| train/                  |             |
|    approx_kl            | 0.004641261 |
|    clip_fraction        | 0.0355      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.91       |
|    explained_variance   | 0.95        |
|    learning_rate        | 5.68e-05    |
|    loss                 | -0.0371     |
|    n_updates            | 6620        |
|    policy_gradient_loss | -0.00755    |
|    std                  | 0.635       |
|    value_loss           | 0.00838     |
-----------------------------------------
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 664          |
|    time_elapsed         | 2150         |
|    total_timesteps      | 1359872      |
| train/                  |              |
|    approx_kl            | 0.0050015147 |
|    clip_fraction        | 0.0367       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.91        |
|    explained_variance   | 0.929        |
|    learning_rate        | 5.68e-05     |
|    loss                 | -0.00752     |
|    n_updates            | 6630         |
|    policy_gradient_loss | -0.00595     |
|    std                  | 0.634        |
|    value_loss           | 0.0116       |
------------------------------------------
Eval num_timesteps=1360000, episode_reward=-0.69 +/- 0.63
Episode length: 300.00 +/- 0.00
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 300          |
|    mean_reward          | -0.686       |
| time/                   |              |
|    total_timesteps      | 1360000      |
| train/                  |              |
|    approx_kl            | 0.0061286613 |
|    clip_fraction        | 0.0598       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.91        |
|    explained_variance   | 0.97         |
|    learning_rate        | 5.68e-05     |
|    loss                 | -0.0026      |
|    n_updates            | 6640         |
|    policy_gradient_loss | -0.0056      |
|    std                  | 0.635        |
|    value_loss           | 0.00491      |
------------------------------------------
box reached target
--------------------------------
| time/              |         |
|    fps             | 632     |
|    iterations      | 665     |
|    time_elapsed    | 2154    |
|    total_timesteps | 1361920 |
--------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 632        |
|    iterations           | 666        |
|    time_elapsed         | 2157       |
|    total_timesteps      | 1363968    |
| train/                  |            |
|    approx_kl            | 0.00448741 |
|    clip_fraction        | 0.0276     |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.9       |
|    explained_variance   | 0.899      |
|    learning_rate        | 5.68e-05   |
|    loss                 | -0.00583   |
|    n_updates            | 6650       |
|    policy_gradient_loss | -0.00365   |
|    std                  | 0.633      |
|    value_loss           | 0.0123     |
----------------------------------------
box reached target
box reached target
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 667          |
|    time_elapsed         | 2160         |
|    total_timesteps      | 1366016      |
| train/                  |              |
|    approx_kl            | 0.0046138084 |
|    clip_fraction        | 0.042        |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.9         |
|    explained_variance   | 0.973        |
|    learning_rate        | 5.68e-05     |
|    loss                 | -0.0208      |
|    n_updates            | 6660         |
|    policy_gradient_loss | -0.0069      |
|    std                  | 0.632        |
|    value_loss           | 0.00419      |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 668          |
|    time_elapsed         | 2163         |
|    total_timesteps      | 1368064      |
| train/                  |              |
|    approx_kl            | 0.0061949296 |
|    clip_fraction        | 0.0581       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.9         |
|    explained_variance   | 0.966        |
|    learning_rate        | 5.68e-05     |
|    loss                 | 0.0367       |
|    n_updates            | 6670         |
|    policy_gradient_loss | -0.00618     |
|    std                  | 0.632        |
|    value_loss           | 0.0159       |
------------------------------------------
Eval num_timesteps=1370000, episode_reward=-1.00 +/- 0.00
Episode length: 300.00 +/- 0.00
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 300          |
|    mean_reward          | -1           |
| time/                   |              |
|    total_timesteps      | 1370000      |
| train/                  |              |
|    approx_kl            | 0.0061109196 |
|    clip_fraction        | 0.0396       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.9         |
|    explained_variance   | 0.806        |
|    learning_rate        | 5.68e-05     |
|    loss                 | -0.0326      |
|    n_updates            | 6680         |
|    policy_gradient_loss | -0.0056      |
|    std                  | 0.633        |
|    value_loss           | 0.00444      |
------------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 669     |
|    time_elapsed    | 2167    |
|    total_timesteps | 1370112 |
--------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 632         |
|    iterations           | 670         |
|    time_elapsed         | 2170        |
|    total_timesteps      | 1372160     |
| train/                  |             |
|    approx_kl            | 0.004963641 |
|    clip_fraction        | 0.0464      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.9        |
|    explained_variance   | 0.885       |
|    learning_rate        | 5.69e-05    |
|    loss                 | -0.0145     |
|    n_updates            | 6690        |
|    policy_gradient_loss | -0.00557    |
|    std                  | 0.634       |
|    value_loss           | 0.00498     |
-----------------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 632         |
|    iterations           | 671         |
|    time_elapsed         | 2174        |
|    total_timesteps      | 1374208     |
| train/                  |             |
|    approx_kl            | 0.005989651 |
|    clip_fraction        | 0.0565      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.9        |
|    explained_variance   | 0.947       |
|    learning_rate        | 5.69e-05    |
|    loss                 | 0.000332    |
|    n_updates            | 6700        |
|    policy_gradient_loss | -0.00588    |
|    std                  | 0.634       |
|    value_loss           | 0.0043      |
-----------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 672          |
|    time_elapsed         | 2177         |
|    total_timesteps      | 1376256      |
| train/                  |              |
|    approx_kl            | 0.0060489047 |
|    clip_fraction        | 0.0394       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.9         |
|    explained_variance   | 0.964        |
|    learning_rate        | 5.69e-05     |
|    loss                 | -0.014       |
|    n_updates            | 6710         |
|    policy_gradient_loss | -0.00639     |
|    std                  | 0.633        |
|    value_loss           | 0.00268      |
------------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 632         |
|    iterations           | 673         |
|    time_elapsed         | 2180        |
|    total_timesteps      | 1378304     |
| train/                  |             |
|    approx_kl            | 0.004230958 |
|    clip_fraction        | 0.0288      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.91       |
|    explained_variance   | 0.916       |
|    learning_rate        | 5.69e-05    |
|    loss                 | -0.0193     |
|    n_updates            | 6720        |
|    policy_gradient_loss | -0.00254    |
|    std                  | 0.635       |
|    value_loss           | 0.00203     |
-----------------------------------------
Eval num_timesteps=1380000, episode_reward=-0.77 +/- 0.46
Episode length: 300.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 300         |
|    mean_reward          | -0.769      |
| time/                   |             |
|    total_timesteps      | 1380000     |
| train/                  |             |
|    approx_kl            | 0.004562152 |
|    clip_fraction        | 0.0314      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.91       |
|    explained_variance   | 0.873       |
|    learning_rate        | 5.69e-05    |
|    loss                 | -0.0211     |
|    n_updates            | 6730        |
|    policy_gradient_loss | -0.00623    |
|    std                  | 0.637       |
|    value_loss           | 0.00395     |
-----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 631     |
|    iterations      | 674     |
|    time_elapsed    | 2184    |
|    total_timesteps | 1380352 |
--------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 632         |
|    iterations           | 675         |
|    time_elapsed         | 2187        |
|    total_timesteps      | 1382400     |
| train/                  |             |
|    approx_kl            | 0.004163906 |
|    clip_fraction        | 0.0259      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.91       |
|    explained_variance   | 0.922       |
|    learning_rate        | 5.69e-05    |
|    loss                 | -0.00775    |
|    n_updates            | 6740        |
|    policy_gradient_loss | -0.0029     |
|    std                  | 0.636       |
|    value_loss           | 0.00425     |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 632         |
|    iterations           | 676         |
|    time_elapsed         | 2190        |
|    total_timesteps      | 1384448     |
| train/                  |             |
|    approx_kl            | 0.005355645 |
|    clip_fraction        | 0.0353      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.91       |
|    explained_variance   | 0.903       |
|    learning_rate        | 5.69e-05    |
|    loss                 | -0.00616    |
|    n_updates            | 6750        |
|    policy_gradient_loss | -0.00431    |
|    std                  | 0.636       |
|    value_loss           | 0.00712     |
-----------------------------------------
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 677          |
|    time_elapsed         | 2193         |
|    total_timesteps      | 1386496      |
| train/                  |              |
|    approx_kl            | 0.0036894842 |
|    clip_fraction        | 0.0262       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.91        |
|    explained_variance   | 0.894        |
|    learning_rate        | 5.69e-05     |
|    loss                 | -0.0143      |
|    n_updates            | 6760         |
|    policy_gradient_loss | -0.00548     |
|    std                  | 0.633        |
|    value_loss           | 0.00164      |
------------------------------------------
box reached target
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 632          |
|    iterations           | 678          |
|    time_elapsed         | 2196         |
|    total_timesteps      | 1388544      |
| train/                  |              |
|    approx_kl            | 0.0033097623 |
|    clip_fraction        | 0.0267       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.9         |
|    explained_variance   | 0.893        |
|    learning_rate        | 5.69e-05     |
|    loss                 | -0.0128      |
|    n_updates            | 6770         |
|    policy_gradient_loss | -0.00408     |
|    std                  | 0.635        |
|    value_loss           | 0.00524      |
------------------------------------------
