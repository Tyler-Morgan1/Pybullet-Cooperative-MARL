CUDA_VISIBLE_DEVICES: 4
Activating TensorFlow-2.6.2 environment
Running clusterTrain.py
pybullet build time: Nov 28 2023 23:48:36
Using cuda device
Logging to Training/clusterResults/clusterLogs/PPO_9
-----------------------------
| time/              |      |
|    fps             | 772  |
|    iterations      | 1    |
|    time_elapsed    | 2    |
|    total_timesteps | 2048 |
-----------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 631          |
|    iterations           | 2            |
|    time_elapsed         | 6            |
|    total_timesteps      | 4096         |
| train/                  |              |
|    approx_kl            | 0.0010278968 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.84        |
|    explained_variance   | 0.916        |
|    learning_rate        | 3e-05        |
|    loss                 | -0.00389     |
|    n_updates            | 10           |
|    policy_gradient_loss | -0.000986    |
|    std                  | 0.999        |
|    value_loss           | 0.00116      |
------------------------------------------
-------------------------------------------
| time/                   |               |
|    fps                  | 637           |
|    iterations           | 3             |
|    time_elapsed         | 9             |
|    total_timesteps      | 6144          |
| train/                  |               |
|    approx_kl            | 0.00084244367 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -2.84         |
|    explained_variance   | 0.926         |
|    learning_rate        | 3e-05         |
|    loss                 | -0.00066      |
|    n_updates            | 20            |
|    policy_gradient_loss | -0.000937     |
|    std                  | 1             |
|    value_loss           | 0.000418      |
-------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 640          |
|    iterations           | 4            |
|    time_elapsed         | 12           |
|    total_timesteps      | 8192         |
| train/                  |              |
|    approx_kl            | 0.0020371368 |
|    clip_fraction        | 0.00117      |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.84        |
|    explained_variance   | 0.838        |
|    learning_rate        | 3e-05        |
|    loss                 | -0.00572     |
|    n_updates            | 30           |
|    policy_gradient_loss | -0.00114     |
|    std                  | 1            |
|    value_loss           | 0.000796     |
------------------------------------------
/home/tmorgan01/anaconda3/envs/dan/lib/python3.11/site-packages/stable_baselines3/common/evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.
  warnings.warn(
Eval num_timesteps=10000, episode_reward=-1.00 +/- 0.00
Episode length: 500.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 500         |
|    mean_reward          | -1          |
| time/                   |             |
|    total_timesteps      | 10000       |
| train/                  |             |
|    approx_kl            | 0.004619104 |
|    clip_fraction        | 0.0114      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.84       |
|    explained_variance   | 0.897       |
|    learning_rate        | 3e-05       |
|    loss                 | -0.00612    |
|    n_updates            | 40          |
|    policy_gradient_loss | -0.00392    |
|    std                  | 0.999       |
|    value_loss           | 0.000704    |
-----------------------------------------
New best mean reward!
------------------------------
| time/              |       |
|    fps             | 584   |
|    iterations      | 5     |
|    time_elapsed    | 17    |
|    total_timesteps | 10240 |
------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 595          |
|    iterations           | 6            |
|    time_elapsed         | 20           |
|    total_timesteps      | 12288        |
| train/                  |              |
|    approx_kl            | 0.0026435233 |
|    clip_fraction        | 0.00337      |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.84        |
|    explained_variance   | 0.925        |
|    learning_rate        | 3.01e-05     |
|    loss                 | -0.00844     |
|    n_updates            | 50           |
|    policy_gradient_loss | -0.0022      |
|    std                  | 0.999        |
|    value_loss           | 0.000577     |
------------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 603         |
|    iterations           | 7           |
|    time_elapsed         | 23          |
|    total_timesteps      | 14336       |
| train/                  |             |
|    approx_kl            | 0.004937422 |
|    clip_fraction        | 0.0312      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.84       |
|    explained_variance   | 0.739       |
|    learning_rate        | 3.01e-05    |
|    loss                 | -0.0128     |
|    n_updates            | 60          |
|    policy_gradient_loss | -0.00678    |
|    std                  | 0.998       |
|    value_loss           | 0.000437    |
-----------------------------------------
-------------------------------------------
| time/                   |               |
|    fps                  | 609           |
|    iterations           | 8             |
|    time_elapsed         | 26            |
|    total_timesteps      | 16384         |
| train/                  |               |
|    approx_kl            | 0.00019841563 |
|    clip_fraction        | 0             |
|    clip_range           | 0.2           |
|    entropy_loss         | -2.83         |
|    explained_variance   | 0.918         |
|    learning_rate        | 3.01e-05      |
|    loss                 | -0.000633     |
|    n_updates            | 70            |
|    policy_gradient_loss | -0.000312     |
|    std                  | 0.997         |
|    value_loss           | 0.000551      |
-------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 613          |
|    iterations           | 9            |
|    time_elapsed         | 30           |
|    total_timesteps      | 18432        |
| train/                  |              |
|    approx_kl            | 0.0043151155 |
|    clip_fraction        | 0.0245       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.83        |
|    explained_variance   | 0.907        |
|    learning_rate        | 3.01e-05     |
|    loss                 | -0.0139      |
|    n_updates            | 80           |
|    policy_gradient_loss | -0.00501     |
|    std                  | 0.997        |
|    value_loss           | 0.000603     |
------------------------------------------
Eval num_timesteps=20000, episode_reward=-1.00 +/- 0.00
Episode length: 500.00 +/- 0.00
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 500          |
|    mean_reward          | -1           |
| time/                   |              |
|    total_timesteps      | 20000        |
| train/                  |              |
|    approx_kl            | 0.0017508138 |
|    clip_fraction        | 0.000439     |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.83        |
|    explained_variance   | 0.929        |
|    learning_rate        | 3.01e-05     |
|    loss                 | -0.0129      |
|    n_updates            | 90           |
|    policy_gradient_loss | -0.00106     |
|    std                  | 0.995        |
|    value_loss           | 0.000672     |
------------------------------------------
------------------------------
| time/              |       |
|    fps             | 589   |
|    iterations      | 10    |
|    time_elapsed    | 34    |
|    total_timesteps | 20480 |
------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 594          |
|    iterations           | 11           |
|    time_elapsed         | 37           |
|    total_timesteps      | 22528        |
| train/                  |              |
|    approx_kl            | 0.0010936612 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.83        |
|    explained_variance   | 0.925        |
|    learning_rate        | 3.01e-05     |
|    loss                 | 0.0032       |
|    n_updates            | 100          |
|    policy_gradient_loss | -0.000662    |
|    std                  | 0.995        |
|    value_loss           | 0.000536     |
------------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 599         |
|    iterations           | 12          |
|    time_elapsed         | 40          |
|    total_timesteps      | 24576       |
| train/                  |             |
|    approx_kl            | 0.004257126 |
|    clip_fraction        | 0.0129      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.83       |
|    explained_variance   | 0.781       |
|    learning_rate        | 3.01e-05    |
|    loss                 | -0.0133     |
|    n_updates            | 110         |
|    policy_gradient_loss | -0.0032     |
|    std                  | 0.993       |
|    value_loss           | 0.000693    |
-----------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 603          |
|    iterations           | 13           |
|    time_elapsed         | 44           |
|    total_timesteps      | 26624        |
| train/                  |              |
|    approx_kl            | 0.0037587658 |
|    clip_fraction        | 0.0129       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.82        |
|    explained_variance   | 0.909        |
|    learning_rate        | 3.01e-05     |
|    loss                 | 0.00328      |
|    n_updates            | 120          |
|    policy_gradient_loss | -0.00308     |
|    std                  | 0.993        |
|    value_loss           | 0.000302     |
------------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 606         |
|    iterations           | 14          |
|    time_elapsed         | 47          |
|    total_timesteps      | 28672       |
| train/                  |             |
|    approx_kl            | 0.003270937 |
|    clip_fraction        | 0.00669     |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.83       |
|    explained_variance   | 0.88        |
|    learning_rate        | 3.02e-05    |
|    loss                 | -0.00116    |
|    n_updates            | 130         |
|    policy_gradient_loss | -0.00417    |
|    std                  | 0.995       |
|    value_loss           | 0.00061     |
-----------------------------------------
Eval num_timesteps=30000, episode_reward=-1.00 +/- 0.00
Episode length: 500.00 +/- 0.00
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 500          |
|    mean_reward          | -1           |
| time/                   |              |
|    total_timesteps      | 30000        |
| train/                  |              |
|    approx_kl            | 0.0011851878 |
|    clip_fraction        | 0.000391     |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.83        |
|    explained_variance   | 0.92         |
|    learning_rate        | 3.02e-05     |
|    loss                 | -0.000147    |
|    n_updates            | 140          |
|    policy_gradient_loss | -0.000566    |
|    std                  | 0.996        |
|    value_loss           | 0.000354     |
------------------------------------------
------------------------------
| time/              |       |
|    fps             | 591   |
|    iterations      | 15    |
|    time_elapsed    | 51    |
|    total_timesteps | 30720 |
------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 594          |
|    iterations           | 16           |
|    time_elapsed         | 55           |
|    total_timesteps      | 32768        |
| train/                  |              |
|    approx_kl            | 0.0018135761 |
|    clip_fraction        | 0.000488     |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.83        |
|    explained_variance   | 0.925        |
|    learning_rate        | 3.02e-05     |
|    loss                 | -0.00113     |
|    n_updates            | 150          |
|    policy_gradient_loss | -0.000599    |
|    std                  | 0.994        |
|    value_loss           | 0.000224     |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 597          |
|    iterations           | 17           |
|    time_elapsed         | 58           |
|    total_timesteps      | 34816        |
| train/                  |              |
|    approx_kl            | 0.0014209726 |
|    clip_fraction        | 9.77e-05     |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.83        |
|    explained_variance   | 0.801        |
|    learning_rate        | 3.02e-05     |
|    loss                 | -0.0116      |
|    n_updates            | 160          |
|    policy_gradient_loss | -0.000794    |
|    std                  | 0.994        |
|    value_loss           | 0.000407     |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 600          |
|    iterations           | 18           |
|    time_elapsed         | 61           |
|    total_timesteps      | 36864        |
| train/                  |              |
|    approx_kl            | 0.0028451593 |
|    clip_fraction        | 0.00459      |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.83        |
|    explained_variance   | 0.887        |
|    learning_rate        | 3.02e-05     |
|    loss                 | 9.24e-05     |
|    n_updates            | 170          |
|    policy_gradient_loss | -0.00162     |
|    std                  | 0.996        |
|    value_loss           | 0.000273     |
------------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 603         |
|    iterations           | 19          |
|    time_elapsed         | 64          |
|    total_timesteps      | 38912       |
| train/                  |             |
|    approx_kl            | 0.002099443 |
|    clip_fraction        | 0.00107     |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.83       |
|    explained_variance   | 0.907       |
|    learning_rate        | 3.02e-05    |
|    loss                 | 0.00494     |
|    n_updates            | 180         |
|    policy_gradient_loss | -0.00147    |
|    std                  | 0.994       |
|    value_loss           | 0.000341    |
-----------------------------------------
Eval num_timesteps=40000, episode_reward=-1.00 +/- 0.00
Episode length: 500.00 +/- 0.00
-------------------------------------------
| eval/                   |               |
|    mean_ep_length       | 500           |
|    mean_reward          | -1            |
| time/                   |               |
|    total_timesteps      | 40000         |
| train/                  |               |
|    approx_kl            | 0.00086833193 |
|    clip_fraction        | 4.88e-05      |
|    clip_range           | 0.2           |
|    entropy_loss         | -2.83         |
|    explained_variance   | 0.868         |
|    learning_rate        | 3.02e-05      |
|    loss                 | 0.00359       |
|    n_updates            | 190           |
|    policy_gradient_loss | -0.00148      |
|    std                  | 0.993         |
|    value_loss           | 0.000332      |
-------------------------------------------
------------------------------
| time/              |       |
|    fps             | 591   |
|    iterations      | 20    |
|    time_elapsed    | 69    |
|    total_timesteps | 40960 |
------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 594          |
|    iterations           | 21           |
|    time_elapsed         | 72           |
|    total_timesteps      | 43008        |
| train/                  |              |
|    approx_kl            | 0.0029918773 |
|    clip_fraction        | 0.00679      |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.82        |
|    explained_variance   | 0.899        |
|    learning_rate        | 3.02e-05     |
|    loss                 | -0.00791     |
|    n_updates            | 200          |
|    policy_gradient_loss | -0.00237     |
|    std                  | 0.992        |
|    value_loss           | 0.000161     |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 596          |
|    iterations           | 22           |
|    time_elapsed         | 75           |
|    total_timesteps      | 45056        |
| train/                  |              |
|    approx_kl            | 0.0050363555 |
|    clip_fraction        | 0.0264       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.82        |
|    explained_variance   | 0.525        |
|    learning_rate        | 3.03e-05     |
|    loss                 | -0.012       |
|    n_updates            | 210          |
|    policy_gradient_loss | -0.00482     |
|    std                  | 0.99         |
|    value_loss           | 0.000247     |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 599          |
|    iterations           | 23           |
|    time_elapsed         | 78           |
|    total_timesteps      | 47104        |
| train/                  |              |
|    approx_kl            | 0.0032211572 |
|    clip_fraction        | 0.00669      |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.82        |
|    explained_variance   | 0.373        |
|    learning_rate        | 3.03e-05     |
|    loss                 | -0.0256      |
|    n_updates            | 220          |
|    policy_gradient_loss | -0.00188     |
|    std                  | 0.988        |
|    value_loss           | 0.000256     |
------------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 601         |
|    iterations           | 24          |
|    time_elapsed         | 81          |
|    total_timesteps      | 49152       |
| train/                  |             |
|    approx_kl            | 0.001513948 |
|    clip_fraction        | 0.00146     |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.81       |
|    explained_variance   | 0.604       |
|    learning_rate        | 3.03e-05    |
|    loss                 | -0.00428    |
|    n_updates            | 230         |
|    policy_gradient_loss | -0.00183    |
|    std                  | 0.987       |
|    value_loss           | 0.000377    |
-----------------------------------------
Eval num_timesteps=50000, episode_reward=-1.00 +/- 0.00
Episode length: 500.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 500         |
|    mean_reward          | -1          |
| time/                   |             |
|    total_timesteps      | 50000       |
| train/                  |             |
|    approx_kl            | 0.005828726 |
|    clip_fraction        | 0.0184      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.81       |
|    explained_variance   | 0.554       |
|    learning_rate        | 3.03e-05    |
|    loss                 | -0.011      |
|    n_updates            | 240         |
|    policy_gradient_loss | -0.00356    |
|    std                  | 0.986       |
|    value_loss           | 0.00023     |
-----------------------------------------
------------------------------
| time/              |       |
|    fps             | 591   |
|    iterations      | 25    |
|    time_elapsed    | 86    |
|    total_timesteps | 51200 |
------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 594         |
|    iterations           | 26          |
|    time_elapsed         | 89          |
|    total_timesteps      | 53248       |
| train/                  |             |
|    approx_kl            | 0.005489097 |
|    clip_fraction        | 0.0263      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.81       |
|    explained_variance   | 0.873       |
|    learning_rate        | 3.03e-05    |
|    loss                 | -0.0157     |
|    n_updates            | 250         |
|    policy_gradient_loss | -0.0039     |
|    std                  | 0.985       |
|    value_loss           | 0.000244    |
-----------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 596          |
|    iterations           | 27           |
|    time_elapsed         | 92           |
|    total_timesteps      | 55296        |
| train/                  |              |
|    approx_kl            | 0.0047781426 |
|    clip_fraction        | 0.02         |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.81        |
|    explained_variance   | 0.865        |
|    learning_rate        | 3.03e-05     |
|    loss                 | 0.00402      |
|    n_updates            | 260          |
|    policy_gradient_loss | -0.00375     |
|    std                  | 0.984        |
|    value_loss           | 0.000297     |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 597          |
|    iterations           | 28           |
|    time_elapsed         | 95           |
|    total_timesteps      | 57344        |
| train/                  |              |
|    approx_kl            | 0.0077572316 |
|    clip_fraction        | 0.0438       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.8         |
|    explained_variance   | 0.683        |
|    learning_rate        | 3.03e-05     |
|    loss                 | 0.0118       |
|    n_updates            | 270          |
|    policy_gradient_loss | -0.0061      |
|    std                  | 0.982        |
|    value_loss           | 0.000221     |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 599          |
|    iterations           | 29           |
|    time_elapsed         | 99           |
|    total_timesteps      | 59392        |
| train/                  |              |
|    approx_kl            | 0.0017498438 |
|    clip_fraction        | 0.000195     |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.8         |
|    explained_variance   | 0.569        |
|    learning_rate        | 3.03e-05     |
|    loss                 | -0.00356     |
|    n_updates            | 280          |
|    policy_gradient_loss | -0.00125     |
|    std                  | 0.98         |
|    value_loss           | 0.000474     |
------------------------------------------
Eval num_timesteps=60000, episode_reward=-1.00 +/- 0.00
Episode length: 500.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 500         |
|    mean_reward          | -1          |
| time/                   |             |
|    total_timesteps      | 60000       |
| train/                  |             |
|    approx_kl            | 0.004002809 |
|    clip_fraction        | 0.0163      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.8        |
|    explained_variance   | 0.577       |
|    learning_rate        | 3.04e-05    |
|    loss                 | -0.0194     |
|    n_updates            | 290         |
|    policy_gradient_loss | -0.00337    |
|    std                  | 0.979       |
|    value_loss           | 0.000455    |
-----------------------------------------
------------------------------
| time/              |       |
|    fps             | 592   |
|    iterations      | 30    |
|    time_elapsed    | 103   |
|    total_timesteps | 61440 |
------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 593          |
|    iterations           | 31           |
|    time_elapsed         | 106          |
|    total_timesteps      | 63488        |
| train/                  |              |
|    approx_kl            | 0.0042243674 |
|    clip_fraction        | 0.0164       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.79        |
|    explained_variance   | 0.729        |
|    learning_rate        | 3.04e-05     |
|    loss                 | 0.00106      |
|    n_updates            | 300          |
|    policy_gradient_loss | -0.00242     |
|    std                  | 0.977        |
|    value_loss           | 0.000187     |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 595          |
|    iterations           | 32           |
|    time_elapsed         | 110          |
|    total_timesteps      | 65536        |
| train/                  |              |
|    approx_kl            | 0.0042702015 |
|    clip_fraction        | 0.00928      |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.79        |
|    explained_variance   | 0.917        |
|    learning_rate        | 3.04e-05     |
|    loss                 | 0.0126       |
|    n_updates            | 310          |
|    policy_gradient_loss | -0.00199     |
|    std                  | 0.977        |
|    value_loss           | 0.000485     |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 596          |
|    iterations           | 33           |
|    time_elapsed         | 113          |
|    total_timesteps      | 67584        |
| train/                  |              |
|    approx_kl            | 0.0052825874 |
|    clip_fraction        | 0.0122       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.79        |
|    explained_variance   | 0.771        |
|    learning_rate        | 3.04e-05     |
|    loss                 | 0.013        |
|    n_updates            | 320          |
|    policy_gradient_loss | -0.00326     |
|    std                  | 0.975        |
|    value_loss           | 0.000545     |
------------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 598         |
|    iterations           | 34          |
|    time_elapsed         | 116         |
|    total_timesteps      | 69632       |
| train/                  |             |
|    approx_kl            | 0.004197499 |
|    clip_fraction        | 0.0102      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.79       |
|    explained_variance   | 0.829       |
|    learning_rate        | 3.04e-05    |
|    loss                 | -0.0181     |
|    n_updates            | 330         |
|    policy_gradient_loss | -0.00305    |
|    std                  | 0.973       |
|    value_loss           | 0.000459    |
-----------------------------------------
Eval num_timesteps=70000, episode_reward=-1.00 +/- 0.00
Episode length: 500.00 +/- 0.00
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 500          |
|    mean_reward          | -1           |
| time/                   |              |
|    total_timesteps      | 70000        |
| train/                  |              |
|    approx_kl            | 0.0044433754 |
|    clip_fraction        | 0.0185       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.78        |
|    explained_variance   | 0.618        |
|    learning_rate        | 3.04e-05     |
|    loss                 | -0.0284      |
|    n_updates            | 340          |
|    policy_gradient_loss | -0.00356     |
|    std                  | 0.972        |
|    value_loss           | 0.000283     |
------------------------------------------
------------------------------
| time/              |       |
|    fps             | 591   |
|    iterations      | 35    |
|    time_elapsed    | 121   |
|    total_timesteps | 71680 |
------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 593          |
|    iterations           | 36           |
|    time_elapsed         | 124          |
|    total_timesteps      | 73728        |
| train/                  |              |
|    approx_kl            | 0.0026239764 |
|    clip_fraction        | 0.00381      |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.78        |
|    explained_variance   | 0.707        |
|    learning_rate        | 3.04e-05     |
|    loss                 | 0.00482      |
|    n_updates            | 350          |
|    policy_gradient_loss | -0.00205     |
|    std                  | 0.972        |
|    value_loss           | 0.000339     |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 594          |
|    iterations           | 37           |
|    time_elapsed         | 127          |
|    total_timesteps      | 75776        |
| train/                  |              |
|    approx_kl            | 0.0026725638 |
|    clip_fraction        | 0.000977     |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.78        |
|    explained_variance   | 0.381        |
|    learning_rate        | 3.04e-05     |
|    loss                 | 0.00973      |
|    n_updates            | 360          |
|    policy_gradient_loss | -0.00164     |
|    std                  | 0.968        |
|    value_loss           | 0.000355     |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 596          |
|    iterations           | 38           |
|    time_elapsed         | 130          |
|    total_timesteps      | 77824        |
| train/                  |              |
|    approx_kl            | 0.0032287939 |
|    clip_fraction        | 0.004        |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.77        |
|    explained_variance   | 0.604        |
|    learning_rate        | 3.05e-05     |
|    loss                 | 0.0109       |
|    n_updates            | 370          |
|    policy_gradient_loss | -0.00155     |
|    std                  | 0.968        |
|    value_loss           | 0.000284     |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 597          |
|    iterations           | 39           |
|    time_elapsed         | 133          |
|    total_timesteps      | 79872        |
| train/                  |              |
|    approx_kl            | 0.0028812336 |
|    clip_fraction        | 0.002        |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.77        |
|    explained_variance   | 0.713        |
|    learning_rate        | 3.05e-05     |
|    loss                 | -0.0106      |
|    n_updates            | 380          |
|    policy_gradient_loss | -0.00187     |
|    std                  | 0.968        |
|    value_loss           | 0.000374     |
------------------------------------------
Eval num_timesteps=80000, episode_reward=-1.00 +/- 0.00
Episode length: 500.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 500         |
|    mean_reward          | -1          |
| time/                   |             |
|    total_timesteps      | 80000       |
| train/                  |             |
|    approx_kl            | 0.002002644 |
|    clip_fraction        | 0.000391    |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.77       |
|    explained_variance   | 0.694       |
|    learning_rate        | 3.05e-05    |
|    loss                 | -0.00473    |
|    n_updates            | 390         |
|    policy_gradient_loss | -0.000992   |
|    std                  | 0.966       |
|    value_loss           | 0.000459    |
-----------------------------------------
------------------------------
| time/              |       |
|    fps             | 591   |
|    iterations      | 40    |
|    time_elapsed    | 138   |
|    total_timesteps | 81920 |
------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 593          |
|    iterations           | 41           |
|    time_elapsed         | 141          |
|    total_timesteps      | 83968        |
| train/                  |              |
|    approx_kl            | 0.0018260877 |
|    clip_fraction        | 0.000635     |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.77        |
|    explained_variance   | 0.604        |
|    learning_rate        | 3.05e-05     |
|    loss                 | -0.00396     |
|    n_updates            | 400          |
|    policy_gradient_loss | -0.00127     |
|    std                  | 0.965        |
|    value_loss           | 0.000351     |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 594          |
|    iterations           | 42           |
|    time_elapsed         | 144          |
|    total_timesteps      | 86016        |
| train/                  |              |
|    approx_kl            | 0.0036203777 |
|    clip_fraction        | 0.0108       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.76        |
|    explained_variance   | 0.551        |
|    learning_rate        | 3.05e-05     |
|    loss                 | -0.00445     |
|    n_updates            | 410          |
|    policy_gradient_loss | -0.00266     |
|    std                  | 0.963        |
|    value_loss           | 0.000746     |
------------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 595         |
|    iterations           | 43          |
|    time_elapsed         | 147         |
|    total_timesteps      | 88064       |
| train/                  |             |
|    approx_kl            | 0.003197084 |
|    clip_fraction        | 0.00396     |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.76       |
|    explained_variance   | 0.669       |
|    learning_rate        | 3.05e-05    |
|    loss                 | -0.0135     |
|    n_updates            | 420         |
|    policy_gradient_loss | -0.00251    |
|    std                  | 0.962       |
|    value_loss           | 0.000278    |
-----------------------------------------
Eval num_timesteps=90000, episode_reward=-1.00 +/- 0.00
Episode length: 500.00 +/- 0.00
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 500          |
|    mean_reward          | -1           |
| time/                   |              |
|    total_timesteps      | 90000        |
| train/                  |              |
|    approx_kl            | 0.0060026376 |
|    clip_fraction        | 0.0286       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.76        |
|    explained_variance   | 0.796        |
|    learning_rate        | 3.05e-05     |
|    loss                 | 0.019        |
|    n_updates            | 430          |
|    policy_gradient_loss | -0.00457     |
|    std                  | 0.96         |
|    value_loss           | 0.000324     |
------------------------------------------
------------------------------
| time/              |       |
|    fps             | 590   |
|    iterations      | 44    |
|    time_elapsed    | 152   |
|    total_timesteps | 90112 |
------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 592          |
|    iterations           | 45           |
|    time_elapsed         | 155          |
|    total_timesteps      | 92160        |
| train/                  |              |
|    approx_kl            | 0.0027807248 |
|    clip_fraction        | 0.00396      |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.76        |
|    explained_variance   | 0.886        |
|    learning_rate        | 3.05e-05     |
|    loss                 | -0.0159      |
|    n_updates            | 440          |
|    policy_gradient_loss | -0.00272     |
|    std                  | 0.96         |
|    value_loss           | 0.000245     |
------------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 593         |
|    iterations           | 46          |
|    time_elapsed         | 158         |
|    total_timesteps      | 94208       |
| train/                  |             |
|    approx_kl            | 0.004983357 |
|    clip_fraction        | 0.0192      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.76       |
|    explained_variance   | 0.87        |
|    learning_rate        | 3.06e-05    |
|    loss                 | 0.000604    |
|    n_updates            | 450         |
|    policy_gradient_loss | -0.00432    |
|    std                  | 0.96        |
|    value_loss           | 0.000262    |
-----------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 594          |
|    iterations           | 47           |
|    time_elapsed         | 161          |
|    total_timesteps      | 96256        |
| train/                  |              |
|    approx_kl            | 0.0036224124 |
|    clip_fraction        | 0.0064       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.75        |
|    explained_variance   | -0.29        |
|    learning_rate        | 3.06e-05     |
|    loss                 | 0.008        |
|    n_updates            | 460          |
|    policy_gradient_loss | -0.00222     |
|    std                  | 0.957        |
|    value_loss           | 0.000633     |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 595          |
|    iterations           | 48           |
|    time_elapsed         | 165          |
|    total_timesteps      | 98304        |
| train/                  |              |
|    approx_kl            | 0.0015833237 |
|    clip_fraction        | 0.000928     |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.75        |
|    explained_variance   | 0.818        |
|    learning_rate        | 3.06e-05     |
|    loss                 | -0.00544     |
|    n_updates            | 470          |
|    policy_gradient_loss | -0.00221     |
|    std                  | 0.954        |
|    value_loss           | 0.000342     |
------------------------------------------
Eval num_timesteps=100000, episode_reward=-1.00 +/- 0.00
Episode length: 500.00 +/- 0.00
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 500          |
|    mean_reward          | -1           |
| time/                   |              |
|    total_timesteps      | 100000       |
| train/                  |              |
|    approx_kl            | 0.0055379844 |
|    clip_fraction        | 0.0284       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.74        |
|    explained_variance   | 0.862        |
|    learning_rate        | 3.06e-05     |
|    loss                 | -0.0122      |
|    n_updates            | 480          |
|    policy_gradient_loss | -0.00377     |
|    std                  | 0.953        |
|    value_loss           | 0.00021      |
------------------------------------------
-------------------------------
| time/              |        |
|    fps             | 591    |
|    iterations      | 49     |
|    time_elapsed    | 169    |
|    total_timesteps | 100352 |
-------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 592        |
|    iterations           | 50         |
|    time_elapsed         | 172        |
|    total_timesteps      | 102400     |
| train/                  |            |
|    approx_kl            | 0.00777159 |
|    clip_fraction        | 0.0583     |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.74      |
|    explained_variance   | 0.873      |
|    learning_rate        | 3.06e-05   |
|    loss                 | -0.00449   |
|    n_updates            | 490        |
|    policy_gradient_loss | -0.00726   |
|    std                  | 0.952      |
|    value_loss           | 0.000348   |
----------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 593          |
|    iterations           | 51           |
|    time_elapsed         | 176          |
|    total_timesteps      | 104448       |
| train/                  |              |
|    approx_kl            | 0.0043836096 |
|    clip_fraction        | 0.0082       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.74        |
|    explained_variance   | 0.913        |
|    learning_rate        | 3.06e-05     |
|    loss                 | -0.0047      |
|    n_updates            | 500          |
|    policy_gradient_loss | -0.00239     |
|    std                  | 0.952        |
|    value_loss           | 0.000207     |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 594          |
|    iterations           | 52           |
|    time_elapsed         | 179          |
|    total_timesteps      | 106496       |
| train/                  |              |
|    approx_kl            | 0.0011543122 |
|    clip_fraction        | 4.88e-05     |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.74        |
|    explained_variance   | 0.457        |
|    learning_rate        | 3.06e-05     |
|    loss                 | -0.00176     |
|    n_updates            | 510          |
|    policy_gradient_loss | -0.000452    |
|    std                  | 0.951        |
|    value_loss           | 0.00128      |
------------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 595         |
|    iterations           | 53          |
|    time_elapsed         | 182         |
|    total_timesteps      | 108544      |
| train/                  |             |
|    approx_kl            | 0.006106519 |
|    clip_fraction        | 0.0296      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.74       |
|    explained_variance   | 0.673       |
|    learning_rate        | 3.06e-05    |
|    loss                 | -0.0129     |
|    n_updates            | 520         |
|    policy_gradient_loss | -0.00377    |
|    std                  | 0.95        |
|    value_loss           | 0.000585    |
-----------------------------------------
Eval num_timesteps=110000, episode_reward=-0.83 +/- 0.34
Episode length: 500.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 500         |
|    mean_reward          | -0.83       |
| time/                   |             |
|    total_timesteps      | 110000      |
| train/                  |             |
|    approx_kl            | 0.005880344 |
|    clip_fraction        | 0.0322      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.73       |
|    explained_variance   | 0.865       |
|    learning_rate        | 3.07e-05    |
|    loss                 | -0.0107     |
|    n_updates            | 530         |
|    policy_gradient_loss | -0.00495    |
|    std                  | 0.949       |
|    value_loss           | 0.0003      |
-----------------------------------------
New best mean reward!
-------------------------------
| time/              |        |
|    fps             | 591    |
|    iterations      | 54     |
|    time_elapsed    | 187    |
|    total_timesteps | 110592 |
-------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 592         |
|    iterations           | 55          |
|    time_elapsed         | 190         |
|    total_timesteps      | 112640      |
| train/                  |             |
|    approx_kl            | 0.005073555 |
|    clip_fraction        | 0.0155      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.73       |
|    explained_variance   | 0.867       |
|    learning_rate        | 3.07e-05    |
|    loss                 | -0.00518    |
|    n_updates            | 540         |
|    policy_gradient_loss | -0.00277    |
|    std                  | 0.948       |
|    value_loss           | 0.000385    |
-----------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 593          |
|    iterations           | 56           |
|    time_elapsed         | 193          |
|    total_timesteps      | 114688       |
| train/                  |              |
|    approx_kl            | 0.0028047618 |
|    clip_fraction        | 0.00698      |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.73        |
|    explained_variance   | 0.871        |
|    learning_rate        | 3.07e-05     |
|    loss                 | -0.0144      |
|    n_updates            | 550          |
|    policy_gradient_loss | -0.00236     |
|    std                  | 0.947        |
|    value_loss           | 0.000328     |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 594          |
|    iterations           | 57           |
|    time_elapsed         | 196          |
|    total_timesteps      | 116736       |
| train/                  |              |
|    approx_kl            | 0.0020823202 |
|    clip_fraction        | 0.00107      |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.73        |
|    explained_variance   | 0.812        |
|    learning_rate        | 3.07e-05     |
|    loss                 | -0.00918     |
|    n_updates            | 560          |
|    policy_gradient_loss | -0.00254     |
|    std                  | 0.947        |
|    value_loss           | 0.000238     |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 595          |
|    iterations           | 58           |
|    time_elapsed         | 199          |
|    total_timesteps      | 118784       |
| train/                  |              |
|    approx_kl            | 0.0036112715 |
|    clip_fraction        | 0.0118       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.73        |
|    explained_variance   | -0.456       |
|    learning_rate        | 3.07e-05     |
|    loss                 | 0.0033       |
|    n_updates            | 570          |
|    policy_gradient_loss | -0.00254     |
|    std                  | 0.947        |
|    value_loss           | 0.000925     |
------------------------------------------
box reached target
Eval num_timesteps=120000, episode_reward=0.41 +/- 2.81
Episode length: 462.20 +/- 75.60
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 462          |
|    mean_reward          | 0.406        |
| time/                   |              |
|    total_timesteps      | 120000       |
| train/                  |              |
|    approx_kl            | 0.0015972009 |
|    clip_fraction        | 0.000977     |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.73        |
|    explained_variance   | 0.784        |
|    learning_rate        | 3.07e-05     |
|    loss                 | 0.00369      |
|    n_updates            | 580          |
|    policy_gradient_loss | -0.00137     |
|    std                  | 0.949        |
|    value_loss           | 0.000355     |
------------------------------------------
New best mean reward!
-------------------------------
| time/              |        |
|    fps             | 591    |
|    iterations      | 59     |
|    time_elapsed    | 204    |
|    total_timesteps | 120832 |
-------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 592          |
|    iterations           | 60           |
|    time_elapsed         | 207          |
|    total_timesteps      | 122880       |
| train/                  |              |
|    approx_kl            | 0.0032567494 |
|    clip_fraction        | 0.00684      |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.73        |
|    explained_variance   | 0.796        |
|    learning_rate        | 3.07e-05     |
|    loss                 | -0.0129      |
|    n_updates            | 590          |
|    policy_gradient_loss | -0.0026      |
|    std                  | 0.945        |
|    value_loss           | 0.000635     |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 593          |
|    iterations           | 61           |
|    time_elapsed         | 210          |
|    total_timesteps      | 124928       |
| train/                  |              |
|    approx_kl            | 0.0029548598 |
|    clip_fraction        | 0.0062       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.72        |
|    explained_variance   | 0.709        |
|    learning_rate        | 3.07e-05     |
|    loss                 | -0.00177     |
|    n_updates            | 600          |
|    policy_gradient_loss | -0.00111     |
|    std                  | 0.945        |
|    value_loss           | 0.000328     |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 594          |
|    iterations           | 62           |
|    time_elapsed         | 213          |
|    total_timesteps      | 126976       |
| train/                  |              |
|    approx_kl            | 0.0022887154 |
|    clip_fraction        | 0.00405      |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.72        |
|    explained_variance   | 0.52         |
|    learning_rate        | 3.07e-05     |
|    loss                 | -0.0103      |
|    n_updates            | 610          |
|    policy_gradient_loss | -0.00135     |
|    std                  | 0.943        |
|    value_loss           | 0.000343     |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 595          |
|    iterations           | 63           |
|    time_elapsed         | 216          |
|    total_timesteps      | 129024       |
| train/                  |              |
|    approx_kl            | 0.0038915486 |
|    clip_fraction        | 0.00879      |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.72        |
|    explained_variance   | 0.88         |
|    learning_rate        | 3.08e-05     |
|    loss                 | 0.000522     |
|    n_updates            | 620          |
|    policy_gradient_loss | -0.00271     |
|    std                  | 0.944        |
|    value_loss           | 0.000692     |
------------------------------------------
Eval num_timesteps=130000, episode_reward=-0.51 +/- 0.98
Episode length: 500.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 500         |
|    mean_reward          | -0.511      |
| time/                   |             |
|    total_timesteps      | 130000      |
| train/                  |             |
|    approx_kl            | 0.004401201 |
|    clip_fraction        | 0.0154      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.72       |
|    explained_variance   | 0.881       |
|    learning_rate        | 3.08e-05    |
|    loss                 | -0.0043     |
|    n_updates            | 630         |
|    policy_gradient_loss | -0.00271    |
|    std                  | 0.944       |
|    value_loss           | 0.00031     |
-----------------------------------------
-------------------------------
| time/              |        |
|    fps             | 591    |
|    iterations      | 64     |
|    time_elapsed    | 221    |
|    total_timesteps | 131072 |
-------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 592         |
|    iterations           | 65          |
|    time_elapsed         | 224         |
|    total_timesteps      | 133120      |
| train/                  |             |
|    approx_kl            | 0.002442687 |
|    clip_fraction        | 0.0021      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.72       |
|    explained_variance   | 0.821       |
|    learning_rate        | 3.08e-05    |
|    loss                 | 0.0115      |
|    n_updates            | 640         |
|    policy_gradient_loss | -0.00268    |
|    std                  | 0.944       |
|    value_loss           | 0.000427    |
-----------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 593          |
|    iterations           | 66           |
|    time_elapsed         | 227          |
|    total_timesteps      | 135168       |
| train/                  |              |
|    approx_kl            | 0.0043697096 |
|    clip_fraction        | 0.0121       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.72        |
|    explained_variance   | 0.927        |
|    learning_rate        | 3.08e-05     |
|    loss                 | -0.00962     |
|    n_updates            | 650          |
|    policy_gradient_loss | -0.00362     |
|    std                  | 0.943        |
|    value_loss           | 0.000131     |
------------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 594         |
|    iterations           | 67          |
|    time_elapsed         | 230         |
|    total_timesteps      | 137216      |
| train/                  |             |
|    approx_kl            | 0.002407915 |
|    clip_fraction        | 0.00122     |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.72       |
|    explained_variance   | 0.936       |
|    learning_rate        | 3.08e-05    |
|    loss                 | -0.00025    |
|    n_updates            | 660         |
|    policy_gradient_loss | -0.00134    |
|    std                  | 0.943       |
|    value_loss           | 0.000103    |
-----------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 595          |
|    iterations           | 68           |
|    time_elapsed         | 234          |
|    total_timesteps      | 139264       |
| train/                  |              |
|    approx_kl            | 0.0015263837 |
|    clip_fraction        | 9.77e-05     |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.72        |
|    explained_variance   | 0.754        |
|    learning_rate        | 3.08e-05     |
|    loss                 | -0.00573     |
|    n_updates            | 670          |
|    policy_gradient_loss | -0.000613    |
|    std                  | 0.942        |
|    value_loss           | 0.000387     |
------------------------------------------
Eval num_timesteps=140000, episode_reward=-1.00 +/- 0.00
Episode length: 500.00 +/- 0.00
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 500          |
|    mean_reward          | -1           |
| time/                   |              |
|    total_timesteps      | 140000       |
| train/                  |              |
|    approx_kl            | 0.0027469555 |
|    clip_fraction        | 0.00845      |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.72        |
|    explained_variance   | 0.947        |
|    learning_rate        | 3.08e-05     |
|    loss                 | 0.00389      |
|    n_updates            | 680          |
|    policy_gradient_loss | -0.00401     |
|    std                  | 0.942        |
|    value_loss           | 0.000114     |
------------------------------------------
-------------------------------
| time/              |        |
|    fps             | 591    |
|    iterations      | 69     |
|    time_elapsed    | 238    |
|    total_timesteps | 141312 |
-------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 592        |
|    iterations           | 70         |
|    time_elapsed         | 241        |
|    total_timesteps      | 143360     |
| train/                  |            |
|    approx_kl            | 0.00287664 |
|    clip_fraction        | 0.00322    |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.72      |
|    explained_variance   | 0.809      |
|    learning_rate        | 3.08e-05   |
|    loss                 | 0.00526    |
|    n_updates            | 690        |
|    policy_gradient_loss | -0.00137   |
|    std                  | 0.94       |
|    value_loss           | 0.000326   |
----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 593         |
|    iterations           | 71          |
|    time_elapsed         | 245         |
|    total_timesteps      | 145408      |
| train/                  |             |
|    approx_kl            | 0.004938901 |
|    clip_fraction        | 0.0186      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.71       |
|    explained_variance   | 0.91        |
|    learning_rate        | 3.09e-05    |
|    loss                 | 0.0152      |
|    n_updates            | 700         |
|    policy_gradient_loss | -0.00431    |
|    std                  | 0.939       |
|    value_loss           | 0.000216    |
-----------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 594          |
|    iterations           | 72           |
|    time_elapsed         | 248          |
|    total_timesteps      | 147456       |
| train/                  |              |
|    approx_kl            | 0.0049262377 |
|    clip_fraction        | 0.0186       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.71        |
|    explained_variance   | 0.853        |
|    learning_rate        | 3.09e-05     |
|    loss                 | -0.0127      |
|    n_updates            | 710          |
|    policy_gradient_loss | -0.0054      |
|    std                  | 0.938        |
|    value_loss           | 0.000222     |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 594          |
|    iterations           | 73           |
|    time_elapsed         | 251          |
|    total_timesteps      | 149504       |
| train/                  |              |
|    approx_kl            | 0.0036080997 |
|    clip_fraction        | 0.00664      |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.71        |
|    explained_variance   | 0.882        |
|    learning_rate        | 3.09e-05     |
|    loss                 | 0.000458     |
|    n_updates            | 720          |
|    policy_gradient_loss | -0.00227     |
|    std                  | 0.936        |
|    value_loss           | 0.000195     |
------------------------------------------
Eval num_timesteps=150000, episode_reward=-1.00 +/- 0.00
Episode length: 500.00 +/- 0.00
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 500          |
|    mean_reward          | -1           |
| time/                   |              |
|    total_timesteps      | 150000       |
| train/                  |              |
|    approx_kl            | 0.0045292433 |
|    clip_fraction        | 0.0162       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.7         |
|    explained_variance   | 0.895        |
|    learning_rate        | 3.09e-05     |
|    loss                 | -0.0179      |
|    n_updates            | 730          |
|    policy_gradient_loss | -0.00376     |
|    std                  | 0.936        |
|    value_loss           | 0.000229     |
------------------------------------------
-------------------------------
| time/              |        |
|    fps             | 591    |
|    iterations      | 74     |
|    time_elapsed    | 256    |
|    total_timesteps | 151552 |
-------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 592          |
|    iterations           | 75           |
|    time_elapsed         | 259          |
|    total_timesteps      | 153600       |
| train/                  |              |
|    approx_kl            | 0.0014680447 |
|    clip_fraction        | 0.00132      |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.7         |
|    explained_variance   | 0.732        |
|    learning_rate        | 3.09e-05     |
|    loss                 | 0.00316      |
|    n_updates            | 740          |
|    policy_gradient_loss | -0.00134     |
|    std                  | 0.934        |
|    value_loss           | 0.000526     |
------------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 593         |
|    iterations           | 76          |
|    time_elapsed         | 262         |
|    total_timesteps      | 155648      |
| train/                  |             |
|    approx_kl            | 0.005964317 |
|    clip_fraction        | 0.0382      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.7        |
|    explained_variance   | 0.862       |
|    learning_rate        | 3.09e-05    |
|    loss                 | 0.00842     |
|    n_updates            | 750         |
|    policy_gradient_loss | -0.0046     |
|    std                  | 0.933       |
|    value_loss           | 0.000322    |
-----------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 593          |
|    iterations           | 77           |
|    time_elapsed         | 265          |
|    total_timesteps      | 157696       |
| train/                  |              |
|    approx_kl            | 0.0012270019 |
|    clip_fraction        | 4.88e-05     |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.7         |
|    explained_variance   | 0.177        |
|    learning_rate        | 3.09e-05     |
|    loss                 | -0.00662     |
|    n_updates            | 760          |
|    policy_gradient_loss | -0.000942    |
|    std                  | 0.932        |
|    value_loss           | 0.000709     |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 594          |
|    iterations           | 78           |
|    time_elapsed         | 268          |
|    total_timesteps      | 159744       |
| train/                  |              |
|    approx_kl            | 0.0016724579 |
|    clip_fraction        | 0.000195     |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.7         |
|    explained_variance   | 0.401        |
|    learning_rate        | 3.09e-05     |
|    loss                 | 0.00277      |
|    n_updates            | 770          |
|    policy_gradient_loss | -0.00132     |
|    std                  | 0.933        |
|    value_loss           | 0.00162      |
------------------------------------------
Eval num_timesteps=160000, episode_reward=-0.72 +/- 0.56
Episode length: 500.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 500         |
|    mean_reward          | -0.719      |
| time/                   |             |
|    total_timesteps      | 160000      |
| train/                  |             |
|    approx_kl            | 0.004128161 |
|    clip_fraction        | 0.0196      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.7        |
|    explained_variance   | 0.739       |
|    learning_rate        | 3.1e-05     |
|    loss                 | -0.0151     |
|    n_updates            | 780         |
|    policy_gradient_loss | -0.00437    |
|    std                  | 0.932       |
|    value_loss           | 0.000252    |
-----------------------------------------
-------------------------------
| time/              |        |
|    fps             | 591    |
|    iterations      | 79     |
|    time_elapsed    | 273    |
|    total_timesteps | 161792 |
-------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 592          |
|    iterations           | 80           |
|    time_elapsed         | 276          |
|    total_timesteps      | 163840       |
| train/                  |              |
|    approx_kl            | 0.0026211764 |
|    clip_fraction        | 0.00396      |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.7         |
|    explained_variance   | 0.9          |
|    learning_rate        | 3.1e-05      |
|    loss                 | 0.00106      |
|    n_updates            | 790          |
|    policy_gradient_loss | -0.00326     |
|    std                  | 0.933        |
|    value_loss           | 0.000293     |
------------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 593         |
|    iterations           | 81          |
|    time_elapsed         | 279         |
|    total_timesteps      | 165888      |
| train/                  |             |
|    approx_kl            | 0.003879781 |
|    clip_fraction        | 0.0157      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.7        |
|    explained_variance   | 0.792       |
|    learning_rate        | 3.1e-05     |
|    loss                 | 0.0154      |
|    n_updates            | 800         |
|    policy_gradient_loss | -0.00469    |
|    std                  | 0.933       |
|    value_loss           | 0.000439    |
-----------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 593          |
|    iterations           | 82           |
|    time_elapsed         | 282          |
|    total_timesteps      | 167936       |
| train/                  |              |
|    approx_kl            | 0.0046940474 |
|    clip_fraction        | 0.0242       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.7         |
|    explained_variance   | 0.752        |
|    learning_rate        | 3.1e-05      |
|    loss                 | -0.0205      |
|    n_updates            | 810          |
|    policy_gradient_loss | -0.00408     |
|    std                  | 0.931        |
|    value_loss           | 0.000439     |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 594          |
|    iterations           | 83           |
|    time_elapsed         | 285          |
|    total_timesteps      | 169984       |
| train/                  |              |
|    approx_kl            | 0.0016432814 |
|    clip_fraction        | 0.000781     |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.69        |
|    explained_variance   | 0.487        |
|    learning_rate        | 3.1e-05      |
|    loss                 | -0.00997     |
|    n_updates            | 820          |
|    policy_gradient_loss | -0.00125     |
|    std                  | 0.929        |
|    value_loss           | 0.000664     |
------------------------------------------
Eval num_timesteps=170000, episode_reward=-1.00 +/- 0.00
Episode length: 500.00 +/- 0.00
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 500          |
|    mean_reward          | -1           |
| time/                   |              |
|    total_timesteps      | 170000       |
| train/                  |              |
|    approx_kl            | 0.0049681948 |
|    clip_fraction        | 0.0201       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.69        |
|    explained_variance   | 0.508        |
|    learning_rate        | 3.1e-05      |
|    loss                 | 0.0119       |
|    n_updates            | 830          |
|    policy_gradient_loss | -0.00414     |
|    std                  | 0.931        |
|    value_loss           | 0.000534     |
------------------------------------------
-------------------------------
| time/              |        |
|    fps             | 591    |
|    iterations      | 84     |
|    time_elapsed    | 290    |
|    total_timesteps | 172032 |
-------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 592         |
|    iterations           | 85          |
|    time_elapsed         | 293         |
|    total_timesteps      | 174080      |
| train/                  |             |
|    approx_kl            | 0.003766701 |
|    clip_fraction        | 0.0134      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.69       |
|    explained_variance   | 0.63        |
|    learning_rate        | 3.1e-05     |
|    loss                 | -0.0143     |
|    n_updates            | 840         |
|    policy_gradient_loss | -0.0035     |
|    std                  | 0.93        |
|    value_loss           | 0.000333    |
-----------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 593          |
|    iterations           | 86           |
|    time_elapsed         | 296          |
|    total_timesteps      | 176128       |
| train/                  |              |
|    approx_kl            | 0.0037698084 |
|    clip_fraction        | 0.0145       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.69        |
|    explained_variance   | 0.921        |
|    learning_rate        | 3.1e-05      |
|    loss                 | -0.018       |
|    n_updates            | 850          |
|    policy_gradient_loss | -0.00382     |
|    std                  | 0.931        |
|    value_loss           | 8.18e-05     |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 593          |
|    iterations           | 87           |
|    time_elapsed         | 300          |
|    total_timesteps      | 178176       |
| train/                  |              |
|    approx_kl            | 0.0031754551 |
|    clip_fraction        | 0.00796      |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.7         |
|    explained_variance   | 0.641        |
|    learning_rate        | 3.11e-05     |
|    loss                 | -0.0137      |
|    n_updates            | 860          |
|    policy_gradient_loss | -0.00187     |
|    std                  | 0.931        |
|    value_loss           | 0.000425     |
------------------------------------------
Eval num_timesteps=180000, episode_reward=-1.00 +/- 0.00
Episode length: 500.00 +/- 0.00
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 500          |
|    mean_reward          | -1           |
| time/                   |              |
|    total_timesteps      | 180000       |
| train/                  |              |
|    approx_kl            | 0.0023714646 |
|    clip_fraction        | 0.00654      |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.69        |
|    explained_variance   | 0.885        |
|    learning_rate        | 3.11e-05     |
|    loss                 | 0.00075      |
|    n_updates            | 870          |
|    policy_gradient_loss | -0.00186     |
|    std                  | 0.93         |
|    value_loss           | 0.00037      |
------------------------------------------
-------------------------------
| time/              |        |
|    fps             | 591    |
|    iterations      | 88     |
|    time_elapsed    | 304    |
|    total_timesteps | 180224 |
-------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 591         |
|    iterations           | 89          |
|    time_elapsed         | 308         |
|    total_timesteps      | 182272      |
| train/                  |             |
|    approx_kl            | 0.004400278 |
|    clip_fraction        | 0.0127      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.69       |
|    explained_variance   | 0.823       |
|    learning_rate        | 3.11e-05    |
|    loss                 | -0.00144    |
|    n_updates            | 880         |
|    policy_gradient_loss | -0.00322    |
|    std                  | 0.929       |
|    value_loss           | 0.000203    |
-----------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 592          |
|    iterations           | 90           |
|    time_elapsed         | 311          |
|    total_timesteps      | 184320       |
| train/                  |              |
|    approx_kl            | 0.0026701621 |
|    clip_fraction        | 0.00205      |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.69        |
|    explained_variance   | 0.666        |
|    learning_rate        | 3.11e-05     |
|    loss                 | -0.00127     |
|    n_updates            | 890          |
|    policy_gradient_loss | -0.00151     |
|    std                  | 0.93         |
|    value_loss           | 0.00079      |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 593          |
|    iterations           | 91           |
|    time_elapsed         | 314          |
|    total_timesteps      | 186368       |
| train/                  |              |
|    approx_kl            | 0.0042555183 |
|    clip_fraction        | 0.0115       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.69        |
|    explained_variance   | 0.899        |
|    learning_rate        | 3.11e-05     |
|    loss                 | -0.00638     |
|    n_updates            | 900          |
|    policy_gradient_loss | -0.00307     |
|    std                  | 0.928        |
|    value_loss           | 0.000274     |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 593          |
|    iterations           | 92           |
|    time_elapsed         | 317          |
|    total_timesteps      | 188416       |
| train/                  |              |
|    approx_kl            | 0.0058844388 |
|    clip_fraction        | 0.0414       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.69        |
|    explained_variance   | 0.813        |
|    learning_rate        | 3.11e-05     |
|    loss                 | -0.00295     |
|    n_updates            | 910          |
|    policy_gradient_loss | -0.00712     |
|    std                  | 0.928        |
|    value_loss           | 0.000206     |
------------------------------------------
Eval num_timesteps=190000, episode_reward=-0.80 +/- 0.39
Episode length: 500.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 500         |
|    mean_reward          | -0.803      |
| time/                   |             |
|    total_timesteps      | 190000      |
| train/                  |             |
|    approx_kl            | 0.006417569 |
|    clip_fraction        | 0.0504      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.69       |
|    explained_variance   | 0.858       |
|    learning_rate        | 3.11e-05    |
|    loss                 | -0.0164     |
|    n_updates            | 920         |
|    policy_gradient_loss | -0.00484    |
|    std                  | 0.928       |
|    value_loss           | 0.000182    |
-----------------------------------------
-------------------------------
| time/              |        |
|    fps             | 591    |
|    iterations      | 93     |
|    time_elapsed    | 322    |
|    total_timesteps | 190464 |
-------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 591          |
|    iterations           | 94           |
|    time_elapsed         | 325          |
|    total_timesteps      | 192512       |
| train/                  |              |
|    approx_kl            | 0.0027782388 |
|    clip_fraction        | 0.00249      |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.69        |
|    explained_variance   | 0.783        |
|    learning_rate        | 3.11e-05     |
|    loss                 | -0.00914     |
|    n_updates            | 930          |
|    policy_gradient_loss | -0.00207     |
|    std                  | 0.928        |
|    value_loss           | 0.000187     |
------------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 592         |
|    iterations           | 95          |
|    time_elapsed         | 328         |
|    total_timesteps      | 194560      |
| train/                  |             |
|    approx_kl            | 0.003694592 |
|    clip_fraction        | 0.00791     |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.69       |
|    explained_variance   | 0.735       |
|    learning_rate        | 3.12e-05    |
|    loss                 | -0.00448    |
|    n_updates            | 940         |
|    policy_gradient_loss | -0.00252    |
|    std                  | 0.926       |
|    value_loss           | 0.000385    |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 593         |
|    iterations           | 96          |
|    time_elapsed         | 331         |
|    total_timesteps      | 196608      |
| train/                  |             |
|    approx_kl            | 0.005354305 |
|    clip_fraction        | 0.0289      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.68       |
|    explained_variance   | 0.853       |
|    learning_rate        | 3.12e-05    |
|    loss                 | -0.00552    |
|    n_updates            | 950         |
|    policy_gradient_loss | -0.00432    |
|    std                  | 0.924       |
|    value_loss           | 0.000275    |
-----------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 593          |
|    iterations           | 97           |
|    time_elapsed         | 334          |
|    total_timesteps      | 198656       |
| train/                  |              |
|    approx_kl            | 0.0005663239 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.68        |
|    explained_variance   | 0.8          |
|    learning_rate        | 3.12e-05     |
|    loss                 | -0.004       |
|    n_updates            | 960          |
|    policy_gradient_loss | -0.00091     |
|    std                  | 0.923        |
|    value_loss           | 0.000208     |
------------------------------------------
Eval num_timesteps=200000, episode_reward=-1.00 +/- 0.00
Episode length: 500.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 500         |
|    mean_reward          | -1          |
| time/                   |             |
|    total_timesteps      | 200000      |
| train/                  |             |
|    approx_kl            | 0.002275534 |
|    clip_fraction        | 0.00269     |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.68       |
|    explained_variance   | 0.729       |
|    learning_rate        | 3.12e-05    |
|    loss                 | -0.000666   |
|    n_updates            | 970         |
|    policy_gradient_loss | -0.00187    |
|    std                  | 0.922       |
|    value_loss           | 0.000241    |
-----------------------------------------
-------------------------------
| time/              |        |
|    fps             | 591    |
|    iterations      | 98     |
|    time_elapsed    | 339    |
|    total_timesteps | 200704 |
-------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 591          |
|    iterations           | 99           |
|    time_elapsed         | 342          |
|    total_timesteps      | 202752       |
| train/                  |              |
|    approx_kl            | 0.0041041896 |
|    clip_fraction        | 0.0225       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.67        |
|    explained_variance   | 0.868        |
|    learning_rate        | 3.12e-05     |
|    loss                 | -0.014       |
|    n_updates            | 980          |
|    policy_gradient_loss | -0.00328     |
|    std                  | 0.921        |
|    value_loss           | 0.000152     |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 592          |
|    iterations           | 100          |
|    time_elapsed         | 345          |
|    total_timesteps      | 204800       |
| train/                  |              |
|    approx_kl            | 0.0022562635 |
|    clip_fraction        | 0.00127      |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.67        |
|    explained_variance   | 0.342        |
|    learning_rate        | 3.12e-05     |
|    loss                 | 0.0051       |
|    n_updates            | 990          |
|    policy_gradient_loss | -0.00161     |
|    std                  | 0.919        |
|    value_loss           | 0.000613     |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 592          |
|    iterations           | 101          |
|    time_elapsed         | 348          |
|    total_timesteps      | 206848       |
| train/                  |              |
|    approx_kl            | 0.0014323927 |
|    clip_fraction        | 0.000732     |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.67        |
|    explained_variance   | 0.815        |
|    learning_rate        | 3.12e-05     |
|    loss                 | -0.00576     |
|    n_updates            | 1000         |
|    policy_gradient_loss | -0.00123     |
|    std                  | 0.918        |
|    value_loss           | 0.000303     |
------------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 593         |
|    iterations           | 102         |
|    time_elapsed         | 351         |
|    total_timesteps      | 208896      |
| train/                  |             |
|    approx_kl            | 0.003908604 |
|    clip_fraction        | 0.0136      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.67       |
|    explained_variance   | 0.782       |
|    learning_rate        | 3.12e-05    |
|    loss                 | 0.0146      |
|    n_updates            | 1010        |
|    policy_gradient_loss | -0.00346    |
|    std                  | 0.917       |
|    value_loss           | 0.000374    |
-----------------------------------------
Eval num_timesteps=210000, episode_reward=-1.00 +/- 0.00
Episode length: 500.00 +/- 0.00
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 500          |
|    mean_reward          | -1           |
| time/                   |              |
|    total_timesteps      | 210000       |
| train/                  |              |
|    approx_kl            | 0.0035032546 |
|    clip_fraction        | 0.00464      |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.66        |
|    explained_variance   | 0.673        |
|    learning_rate        | 3.13e-05     |
|    loss                 | -0.0125      |
|    n_updates            | 1020         |
|    policy_gradient_loss | -0.00172     |
|    std                  | 0.916        |
|    value_loss           | 0.000226     |
------------------------------------------
-------------------------------
| time/              |        |
|    fps             | 591    |
|    iterations      | 103    |
|    time_elapsed    | 356    |
|    total_timesteps | 210944 |
-------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 591          |
|    iterations           | 104          |
|    time_elapsed         | 359          |
|    total_timesteps      | 212992       |
| train/                  |              |
|    approx_kl            | 0.0034004953 |
|    clip_fraction        | 0.00537      |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.66        |
|    explained_variance   | 0.815        |
|    learning_rate        | 3.13e-05     |
|    loss                 | 0.0203       |
|    n_updates            | 1030         |
|    policy_gradient_loss | -0.00263     |
|    std                  | 0.916        |
|    value_loss           | 0.000401     |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 592          |
|    iterations           | 105          |
|    time_elapsed         | 363          |
|    total_timesteps      | 215040       |
| train/                  |              |
|    approx_kl            | 0.0029854956 |
|    clip_fraction        | 0.00908      |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.66        |
|    explained_variance   | 0.784        |
|    learning_rate        | 3.13e-05     |
|    loss                 | -0.00762     |
|    n_updates            | 1040         |
|    policy_gradient_loss | -0.0028      |
|    std                  | 0.914        |
|    value_loss           | 0.000216     |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 592          |
|    iterations           | 106          |
|    time_elapsed         | 366          |
|    total_timesteps      | 217088       |
| train/                  |              |
|    approx_kl            | 0.0017222442 |
|    clip_fraction        | 0.00327      |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.66        |
|    explained_variance   | 0.846        |
|    learning_rate        | 3.13e-05     |
|    loss                 | 0.00384      |
|    n_updates            | 1050         |
|    policy_gradient_loss | -0.00249     |
|    std                  | 0.913        |
|    value_loss           | 0.000282     |
------------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 593         |
|    iterations           | 107         |
|    time_elapsed         | 369         |
|    total_timesteps      | 219136      |
| train/                  |             |
|    approx_kl            | 0.002972624 |
|    clip_fraction        | 0.015       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.65       |
|    explained_variance   | 0.827       |
|    learning_rate        | 3.13e-05    |
|    loss                 | -0.00666    |
|    n_updates            | 1060        |
|    policy_gradient_loss | -0.00349    |
|    std                  | 0.911       |
|    value_loss           | 0.000193    |
-----------------------------------------
Eval num_timesteps=220000, episode_reward=-1.00 +/- 0.00
Episode length: 500.00 +/- 0.00
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 500          |
|    mean_reward          | -1           |
| time/                   |              |
|    total_timesteps      | 220000       |
| train/                  |              |
|    approx_kl            | 0.0041070418 |
|    clip_fraction        | 0.0151       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.65        |
|    explained_variance   | 0.733        |
|    learning_rate        | 3.13e-05     |
|    loss                 | -0.0236      |
|    n_updates            | 1070         |
|    policy_gradient_loss | -0.00325     |
|    std                  | 0.912        |
|    value_loss           | 0.000344     |
------------------------------------------
-------------------------------
| time/              |        |
|    fps             | 591    |
|    iterations      | 108    |
|    time_elapsed    | 374    |
|    total_timesteps | 221184 |
-------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 591          |
|    iterations           | 109          |
|    time_elapsed         | 377          |
|    total_timesteps      | 223232       |
| train/                  |              |
|    approx_kl            | 0.0033409318 |
|    clip_fraction        | 0.00679      |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.65        |
|    explained_variance   | 0.809        |
|    learning_rate        | 3.13e-05     |
|    loss                 | -0.00274     |
|    n_updates            | 1080         |
|    policy_gradient_loss | -0.00194     |
|    std                  | 0.91         |
|    value_loss           | 0.000326     |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 592          |
|    iterations           | 110          |
|    time_elapsed         | 380          |
|    total_timesteps      | 225280       |
| train/                  |              |
|    approx_kl            | 0.0041588536 |
|    clip_fraction        | 0.0145       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.65        |
|    explained_variance   | 0.0954       |
|    learning_rate        | 3.13e-05     |
|    loss                 | 0.00917      |
|    n_updates            | 1090         |
|    policy_gradient_loss | -0.00312     |
|    std                  | 0.909        |
|    value_loss           | 0.00102      |
------------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 592         |
|    iterations           | 111         |
|    time_elapsed         | 383         |
|    total_timesteps      | 227328      |
| train/                  |             |
|    approx_kl            | 0.005154645 |
|    clip_fraction        | 0.0288      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.65       |
|    explained_variance   | 0.898       |
|    learning_rate        | 3.14e-05    |
|    loss                 | -0.0222     |
|    n_updates            | 1100        |
|    policy_gradient_loss | -0.00568    |
|    std                  | 0.91        |
|    value_loss           | 0.000219    |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 593         |
|    iterations           | 112         |
|    time_elapsed         | 386         |
|    total_timesteps      | 229376      |
| train/                  |             |
|    approx_kl            | 0.003964356 |
|    clip_fraction        | 0.00723     |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.65       |
|    explained_variance   | 0.904       |
|    learning_rate        | 3.14e-05    |
|    loss                 | 0.00148     |
|    n_updates            | 1110        |
|    policy_gradient_loss | -0.0036     |
|    std                  | 0.909       |
|    value_loss           | 0.000547    |
-----------------------------------------
Eval num_timesteps=230000, episode_reward=-1.00 +/- 0.00
Episode length: 500.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 500         |
|    mean_reward          | -1          |
| time/                   |             |
|    total_timesteps      | 230000      |
| train/                  |             |
|    approx_kl            | 0.002272395 |
|    clip_fraction        | 0.00542     |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.65       |
|    explained_variance   | 0.834       |
|    learning_rate        | 3.14e-05    |
|    loss                 | 0.00427     |
|    n_updates            | 1120        |
|    policy_gradient_loss | -0.00237    |
|    std                  | 0.908       |
|    value_loss           | 0.000276    |
-----------------------------------------
-------------------------------
| time/              |        |
|    fps             | 591    |
|    iterations      | 113    |
|    time_elapsed    | 391    |
|    total_timesteps | 231424 |
-------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 591         |
|    iterations           | 114         |
|    time_elapsed         | 394         |
|    total_timesteps      | 233472      |
| train/                  |             |
|    approx_kl            | 0.003260683 |
|    clip_fraction        | 0.0155      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.64       |
|    explained_variance   | 0.687       |
|    learning_rate        | 3.14e-05    |
|    loss                 | -0.00849    |
|    n_updates            | 1130        |
|    policy_gradient_loss | -0.00265    |
|    std                  | 0.907       |
|    value_loss           | 0.0002      |
-----------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 592          |
|    iterations           | 115          |
|    time_elapsed         | 397          |
|    total_timesteps      | 235520       |
| train/                  |              |
|    approx_kl            | 0.0028094149 |
|    clip_fraction        | 0.0135       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.64        |
|    explained_variance   | 0.792        |
|    learning_rate        | 3.14e-05     |
|    loss                 | 0.00119      |
|    n_updates            | 1140         |
|    policy_gradient_loss | -0.00218     |
|    std                  | 0.905        |
|    value_loss           | 0.000292     |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 592          |
|    iterations           | 116          |
|    time_elapsed         | 400          |
|    total_timesteps      | 237568       |
| train/                  |              |
|    approx_kl            | 0.0032105516 |
|    clip_fraction        | 0.0126       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.64        |
|    explained_variance   | 0.876        |
|    learning_rate        | 3.14e-05     |
|    loss                 | -0.0126      |
|    n_updates            | 1150         |
|    policy_gradient_loss | -0.00302     |
|    std                  | 0.904        |
|    value_loss           | 0.000181     |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 593          |
|    iterations           | 117          |
|    time_elapsed         | 403          |
|    total_timesteps      | 239616       |
| train/                  |              |
|    approx_kl            | 0.0046797805 |
|    clip_fraction        | 0.0138       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.63        |
|    explained_variance   | 0.789        |
|    learning_rate        | 3.14e-05     |
|    loss                 | -0.0042      |
|    n_updates            | 1160         |
|    policy_gradient_loss | -0.00302     |
|    std                  | 0.903        |
|    value_loss           | 0.000345     |
------------------------------------------
Eval num_timesteps=240000, episode_reward=-1.00 +/- 0.00
Episode length: 500.00 +/- 0.00
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 500          |
|    mean_reward          | -1           |
| time/                   |              |
|    total_timesteps      | 240000       |
| train/                  |              |
|    approx_kl            | 0.0034609963 |
|    clip_fraction        | 0.00454      |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.63        |
|    explained_variance   | 0.728        |
|    learning_rate        | 3.14e-05     |
|    loss                 | -0.00385     |
|    n_updates            | 1170         |
|    policy_gradient_loss | -0.00172     |
|    std                  | 0.902        |
|    value_loss           | 0.00064      |
------------------------------------------
-------------------------------
| time/              |        |
|    fps             | 591    |
|    iterations      | 118    |
|    time_elapsed    | 408    |
|    total_timesteps | 241664 |
-------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 591         |
|    iterations           | 119         |
|    time_elapsed         | 411         |
|    total_timesteps      | 243712      |
| train/                  |             |
|    approx_kl            | 0.003310571 |
|    clip_fraction        | 0.0143      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.63       |
|    explained_variance   | 0.887       |
|    learning_rate        | 3.14e-05    |
|    loss                 | -0.0141     |
|    n_updates            | 1180        |
|    policy_gradient_loss | -0.0035     |
|    std                  | 0.901       |
|    value_loss           | 0.000176    |
-----------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 592          |
|    iterations           | 120          |
|    time_elapsed         | 414          |
|    total_timesteps      | 245760       |
| train/                  |              |
|    approx_kl            | 0.0026593423 |
|    clip_fraction        | 0.00459      |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.63        |
|    explained_variance   | 0.688        |
|    learning_rate        | 3.15e-05     |
|    loss                 | 0.00363      |
|    n_updates            | 1190         |
|    policy_gradient_loss | -0.00199     |
|    std                  | 0.901        |
|    value_loss           | 0.000651     |
------------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 592         |
|    iterations           | 121         |
|    time_elapsed         | 418         |
|    total_timesteps      | 247808      |
| train/                  |             |
|    approx_kl            | 0.002520023 |
|    clip_fraction        | 0.00728     |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.63       |
|    explained_variance   | 0.744       |
|    learning_rate        | 3.15e-05    |
|    loss                 | -0.0091     |
|    n_updates            | 1200        |
|    policy_gradient_loss | -0.00234    |
|    std                  | 0.901       |
|    value_loss           | 0.000335    |
-----------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 593          |
|    iterations           | 122          |
|    time_elapsed         | 421          |
|    total_timesteps      | 249856       |
| train/                  |              |
|    approx_kl            | 0.0030750674 |
|    clip_fraction        | 0.00762      |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.63        |
|    explained_variance   | 0.814        |
|    learning_rate        | 3.15e-05     |
|    loss                 | 0.00256      |
|    n_updates            | 1210         |
|    policy_gradient_loss | -0.00222     |
|    std                  | 0.898        |
|    value_loss           | 0.0002       |
------------------------------------------
Eval num_timesteps=250000, episode_reward=-1.00 +/- 0.00
Episode length: 500.00 +/- 0.00
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 500          |
|    mean_reward          | -1           |
| time/                   |              |
|    total_timesteps      | 250000       |
| train/                  |              |
|    approx_kl            | 0.0027950779 |
|    clip_fraction        | 0.00356      |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.62        |
|    explained_variance   | -0.159       |
|    learning_rate        | 3.15e-05     |
|    loss                 | 0.00985      |
|    n_updates            | 1220         |
|    policy_gradient_loss | -0.0019      |
|    std                  | 0.897        |
|    value_loss           | 0.00044      |
------------------------------------------
-------------------------------
| time/              |        |
|    fps             | 591    |
|    iterations      | 123    |
|    time_elapsed    | 425    |
|    total_timesteps | 251904 |
-------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 591          |
|    iterations           | 124          |
|    time_elapsed         | 429          |
|    total_timesteps      | 253952       |
| train/                  |              |
|    approx_kl            | 0.0046846713 |
|    clip_fraction        | 0.044        |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.62        |
|    explained_variance   | 0.622        |
|    learning_rate        | 3.15e-05     |
|    loss                 | -0.00905     |
|    n_updates            | 1230         |
|    policy_gradient_loss | -0.00589     |
|    std                  | 0.897        |
|    value_loss           | 0.000359     |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 592          |
|    iterations           | 125          |
|    time_elapsed         | 432          |
|    total_timesteps      | 256000       |
| train/                  |              |
|    approx_kl            | 0.0011319472 |
|    clip_fraction        | 4.88e-05     |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.62        |
|    explained_variance   | 0.837        |
|    learning_rate        | 3.15e-05     |
|    loss                 | -0.00545     |
|    n_updates            | 1240         |
|    policy_gradient_loss | -0.000736    |
|    std                  | 0.896        |
|    value_loss           | 0.000249     |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 592          |
|    iterations           | 126          |
|    time_elapsed         | 435          |
|    total_timesteps      | 258048       |
| train/                  |              |
|    approx_kl            | 0.0031649794 |
|    clip_fraction        | 0.00479      |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.62        |
|    explained_variance   | 0.718        |
|    learning_rate        | 3.15e-05     |
|    loss                 | -0.000367    |
|    n_updates            | 1250         |
|    policy_gradient_loss | -0.00282     |
|    std                  | 0.893        |
|    value_loss           | 0.000423     |
------------------------------------------
Eval num_timesteps=260000, episode_reward=-1.00 +/- 0.00
Episode length: 500.00 +/- 0.00
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 500          |
|    mean_reward          | -1           |
| time/                   |              |
|    total_timesteps      | 260000       |
| train/                  |              |
|    approx_kl            | 0.0040069353 |
|    clip_fraction        | 0.0168       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.61        |
|    explained_variance   | 0.887        |
|    learning_rate        | 3.15e-05     |
|    loss                 | 0.0104       |
|    n_updates            | 1260         |
|    policy_gradient_loss | -0.00335     |
|    std                  | 0.893        |
|    value_loss           | 0.000206     |
------------------------------------------
-------------------------------
| time/              |        |
|    fps             | 590    |
|    iterations      | 127    |
|    time_elapsed    | 440    |
|    total_timesteps | 260096 |
-------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 591          |
|    iterations           | 128          |
|    time_elapsed         | 443          |
|    total_timesteps      | 262144       |
| train/                  |              |
|    approx_kl            | 0.0038187853 |
|    clip_fraction        | 0.016        |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.61        |
|    explained_variance   | 0.676        |
|    learning_rate        | 3.16e-05     |
|    loss                 | -0.0177      |
|    n_updates            | 1270         |
|    policy_gradient_loss | -0.00409     |
|    std                  | 0.891        |
|    value_loss           | 0.000315     |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 591          |
|    iterations           | 129          |
|    time_elapsed         | 446          |
|    total_timesteps      | 264192       |
| train/                  |              |
|    approx_kl            | 0.0036851312 |
|    clip_fraction        | 0.011        |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.61        |
|    explained_variance   | 0.838        |
|    learning_rate        | 3.16e-05     |
|    loss                 | -0.00102     |
|    n_updates            | 1280         |
|    policy_gradient_loss | -0.00233     |
|    std                  | 0.89         |
|    value_loss           | 0.000185     |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 592          |
|    iterations           | 130          |
|    time_elapsed         | 449          |
|    total_timesteps      | 266240       |
| train/                  |              |
|    approx_kl            | 0.0019152027 |
|    clip_fraction        | 0.00171      |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.61        |
|    explained_variance   | 0.791        |
|    learning_rate        | 3.16e-05     |
|    loss                 | 0.00101      |
|    n_updates            | 1290         |
|    policy_gradient_loss | -0.00124     |
|    std                  | 0.89         |
|    value_loss           | 0.000246     |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 592          |
|    iterations           | 131          |
|    time_elapsed         | 452          |
|    total_timesteps      | 268288       |
| train/                  |              |
|    approx_kl            | 0.0052806344 |
|    clip_fraction        | 0.0297       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.6         |
|    explained_variance   | 0.778        |
|    learning_rate        | 3.16e-05     |
|    loss                 | 0.00369      |
|    n_updates            | 1300         |
|    policy_gradient_loss | -0.00526     |
|    std                  | 0.889        |
|    value_loss           | 0.000195     |
------------------------------------------
Eval num_timesteps=270000, episode_reward=-1.00 +/- 0.00
Episode length: 500.00 +/- 0.00
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 500          |
|    mean_reward          | -1           |
| time/                   |              |
|    total_timesteps      | 270000       |
| train/                  |              |
|    approx_kl            | 0.0013258336 |
|    clip_fraction        | 0.000439     |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.6         |
|    explained_variance   | 0.757        |
|    learning_rate        | 3.16e-05     |
|    loss                 | 0.00117      |
|    n_updates            | 1310         |
|    policy_gradient_loss | -0.00126     |
|    std                  | 0.889        |
|    value_loss           | 0.000338     |
------------------------------------------
-------------------------------
| time/              |        |
|    fps             | 590    |
|    iterations      | 132    |
|    time_elapsed    | 457    |
|    total_timesteps | 270336 |
-------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 591          |
|    iterations           | 133          |
|    time_elapsed         | 460          |
|    total_timesteps      | 272384       |
| train/                  |              |
|    approx_kl            | 0.0031974826 |
|    clip_fraction        | 0.0179       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.6         |
|    explained_variance   | 0.801        |
|    learning_rate        | 3.16e-05     |
|    loss                 | -0.00726     |
|    n_updates            | 1320         |
|    policy_gradient_loss | -0.00286     |
|    std                  | 0.888        |
|    value_loss           | 0.000293     |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 591          |
|    iterations           | 134          |
|    time_elapsed         | 464          |
|    total_timesteps      | 274432       |
| train/                  |              |
|    approx_kl            | 0.0037877704 |
|    clip_fraction        | 0.00996      |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.6         |
|    explained_variance   | 0.621        |
|    learning_rate        | 3.16e-05     |
|    loss                 | -0.0186      |
|    n_updates            | 1330         |
|    policy_gradient_loss | -0.00273     |
|    std                  | 0.887        |
|    value_loss           | 0.000318     |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 591          |
|    iterations           | 135          |
|    time_elapsed         | 467          |
|    total_timesteps      | 276480       |
| train/                  |              |
|    approx_kl            | 0.0027409485 |
|    clip_fraction        | 0.00513      |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.6         |
|    explained_variance   | 0.759        |
|    learning_rate        | 3.16e-05     |
|    loss                 | 0.00446      |
|    n_updates            | 1340         |
|    policy_gradient_loss | -0.00238     |
|    std                  | 0.886        |
|    value_loss           | 0.00029      |
------------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 592         |
|    iterations           | 136         |
|    time_elapsed         | 470         |
|    total_timesteps      | 278528      |
| train/                  |             |
|    approx_kl            | 0.002348142 |
|    clip_fraction        | 0.00532     |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.59       |
|    explained_variance   | -0.24       |
|    learning_rate        | 3.17e-05    |
|    loss                 | -0.00656    |
|    n_updates            | 1350        |
|    policy_gradient_loss | -0.00256    |
|    std                  | 0.885       |
|    value_loss           | 0.000459    |
-----------------------------------------
Eval num_timesteps=280000, episode_reward=-0.66 +/- 0.69
Episode length: 500.00 +/- 0.00
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 500          |
|    mean_reward          | -0.656       |
| time/                   |              |
|    total_timesteps      | 280000       |
| train/                  |              |
|    approx_kl            | 0.0035763653 |
|    clip_fraction        | 0.0104       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.59        |
|    explained_variance   | 0.757        |
|    learning_rate        | 3.17e-05     |
|    loss                 | 0.0103       |
|    n_updates            | 1360         |
|    policy_gradient_loss | -0.00238     |
|    std                  | 0.884        |
|    value_loss           | 0.000311     |
------------------------------------------
-------------------------------
| time/              |        |
|    fps             | 590    |
|    iterations      | 137    |
|    time_elapsed    | 475    |
|    total_timesteps | 280576 |
-------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 590          |
|    iterations           | 138          |
|    time_elapsed         | 478          |
|    total_timesteps      | 282624       |
| train/                  |              |
|    approx_kl            | 0.0029652808 |
|    clip_fraction        | 0.00542      |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.59        |
|    explained_variance   | 0.783        |
|    learning_rate        | 3.17e-05     |
|    loss                 | -0.00583     |
|    n_updates            | 1370         |
|    policy_gradient_loss | -0.00111     |
|    std                  | 0.883        |
|    value_loss           | 0.000424     |
------------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 591         |
|    iterations           | 139         |
|    time_elapsed         | 481         |
|    total_timesteps      | 284672      |
| train/                  |             |
|    approx_kl            | 0.003707735 |
|    clip_fraction        | 0.0238      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.59       |
|    explained_variance   | 0.148       |
|    learning_rate        | 3.17e-05    |
|    loss                 | -0.00831    |
|    n_updates            | 1380        |
|    policy_gradient_loss | -0.00488    |
|    std                  | 0.883       |
|    value_loss           | 0.000837    |
-----------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 591          |
|    iterations           | 140          |
|    time_elapsed         | 485          |
|    total_timesteps      | 286720       |
| train/                  |              |
|    approx_kl            | 0.0037430075 |
|    clip_fraction        | 0.011        |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.59        |
|    explained_variance   | 0.766        |
|    learning_rate        | 3.17e-05     |
|    loss                 | 0.0056       |
|    n_updates            | 1390         |
|    policy_gradient_loss | -0.00366     |
|    std                  | 0.882        |
|    value_loss           | 0.000326     |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 591          |
|    iterations           | 141          |
|    time_elapsed         | 488          |
|    total_timesteps      | 288768       |
| train/                  |              |
|    approx_kl            | 0.0027493092 |
|    clip_fraction        | 0.00361      |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.58        |
|    explained_variance   | 0.844        |
|    learning_rate        | 3.17e-05     |
|    loss                 | -0.00218     |
|    n_updates            | 1400         |
|    policy_gradient_loss | -0.00213     |
|    std                  | 0.88         |
|    value_loss           | 0.000448     |
------------------------------------------
box reached target
Eval num_timesteps=290000, episode_reward=0.68 +/- 2.63
Episode length: 447.80 +/- 104.40
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 448          |
|    mean_reward          | 0.679        |
| time/                   |              |
|    total_timesteps      | 290000       |
| train/                  |              |
|    approx_kl            | 0.0030190374 |
|    clip_fraction        | 0.00688      |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.58        |
|    explained_variance   | 0.74         |
|    learning_rate        | 3.17e-05     |
|    loss                 | -0.0145      |
|    n_updates            | 1410         |
|    policy_gradient_loss | -0.00298     |
|    std                  | 0.878        |
|    value_loss           | 0.000357     |
------------------------------------------
New best mean reward!
-------------------------------
| time/              |        |
|    fps             | 590    |
|    iterations      | 142    |
|    time_elapsed    | 492    |
|    total_timesteps | 290816 |
-------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 590         |
|    iterations           | 143         |
|    time_elapsed         | 495         |
|    total_timesteps      | 292864      |
| train/                  |             |
|    approx_kl            | 0.005249548 |
|    clip_fraction        | 0.0182      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.58       |
|    explained_variance   | 0.675       |
|    learning_rate        | 3.17e-05    |
|    loss                 | -0.0193     |
|    n_updates            | 1420        |
|    policy_gradient_loss | -0.0039     |
|    std                  | 0.876       |
|    value_loss           | 0.000291    |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 590         |
|    iterations           | 144         |
|    time_elapsed         | 499         |
|    total_timesteps      | 294912      |
| train/                  |             |
|    approx_kl            | 0.002838246 |
|    clip_fraction        | 0.00781     |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.57       |
|    explained_variance   | 0.834       |
|    learning_rate        | 3.18e-05    |
|    loss                 | 0.00245     |
|    n_updates            | 1430        |
|    policy_gradient_loss | -0.00213    |
|    std                  | 0.875       |
|    value_loss           | 0.000487    |
-----------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 591          |
|    iterations           | 145          |
|    time_elapsed         | 502          |
|    total_timesteps      | 296960       |
| train/                  |              |
|    approx_kl            | 0.0017334921 |
|    clip_fraction        | 0.00723      |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.57        |
|    explained_variance   | 0.683        |
|    learning_rate        | 3.18e-05     |
|    loss                 | -0.00169     |
|    n_updates            | 1440         |
|    policy_gradient_loss | -0.00162     |
|    std                  | 0.876        |
|    value_loss           | 0.000433     |
------------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 591        |
|    iterations           | 146        |
|    time_elapsed         | 505        |
|    total_timesteps      | 299008     |
| train/                  |            |
|    approx_kl            | 0.00279462 |
|    clip_fraction        | 0.00898    |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.57      |
|    explained_variance   | 0.772      |
|    learning_rate        | 3.18e-05   |
|    loss                 | 0.00736    |
|    n_updates            | 1450       |
|    policy_gradient_loss | -0.00233   |
|    std                  | 0.876      |
|    value_loss           | 0.000244   |
----------------------------------------
Eval num_timesteps=300000, episode_reward=-0.74 +/- 0.52
Episode length: 500.00 +/- 0.00
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 500          |
|    mean_reward          | -0.742       |
| time/                   |              |
|    total_timesteps      | 300000       |
| train/                  |              |
|    approx_kl            | 0.0031164666 |
|    clip_fraction        | 0.00635      |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.57        |
|    explained_variance   | 0.736        |
|    learning_rate        | 3.18e-05     |
|    loss                 | 0.00479      |
|    n_updates            | 1460         |
|    policy_gradient_loss | -0.00232     |
|    std                  | 0.876        |
|    value_loss           | 0.000298     |
------------------------------------------
box reached target
-------------------------------
| time/              |        |
|    fps             | 590    |
|    iterations      | 147    |
|    time_elapsed    | 510    |
|    total_timesteps | 301056 |
-------------------------------
-------------------------------------------
| time/                   |               |
|    fps                  | 590           |
|    iterations           | 148           |
|    time_elapsed         | 513           |
|    total_timesteps      | 303104        |
| train/                  |               |
|    approx_kl            | 0.00062976824 |
|    clip_fraction        | 0.000146      |
|    clip_range           | 0.2           |
|    entropy_loss         | -2.57         |
|    explained_variance   | 0.504         |
|    learning_rate        | 3.18e-05      |
|    loss                 | 0.0562        |
|    n_updates            | 1470          |
|    policy_gradient_loss | -0.00072      |
|    std                  | 0.874         |
|    value_loss           | 0.0484        |
-------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 590          |
|    iterations           | 149          |
|    time_elapsed         | 516          |
|    total_timesteps      | 305152       |
| train/                  |              |
|    approx_kl            | 0.0054022567 |
|    clip_fraction        | 0.0258       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.57        |
|    explained_variance   | 0.866        |
|    learning_rate        | 3.18e-05     |
|    loss                 | 0.00477      |
|    n_updates            | 1480         |
|    policy_gradient_loss | -0.00417     |
|    std                  | 0.875        |
|    value_loss           | 0.000243     |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 591          |
|    iterations           | 150          |
|    time_elapsed         | 519          |
|    total_timesteps      | 307200       |
| train/                  |              |
|    approx_kl            | 0.0046490147 |
|    clip_fraction        | 0.0257       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.57        |
|    explained_variance   | 0.767        |
|    learning_rate        | 3.18e-05     |
|    loss                 | 0.00076      |
|    n_updates            | 1490         |
|    policy_gradient_loss | -0.00881     |
|    std                  | 0.873        |
|    value_loss           | 0.0013       |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 591          |
|    iterations           | 151          |
|    time_elapsed         | 522          |
|    total_timesteps      | 309248       |
| train/                  |              |
|    approx_kl            | 0.0051814094 |
|    clip_fraction        | 0.0232       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.57        |
|    explained_variance   | 0.795        |
|    learning_rate        | 3.18e-05     |
|    loss                 | -0.00689     |
|    n_updates            | 1500         |
|    policy_gradient_loss | -0.00561     |
|    std                  | 0.872        |
|    value_loss           | 0.000424     |
------------------------------------------
Eval num_timesteps=310000, episode_reward=-1.00 +/- 0.00
Episode length: 500.00 +/- 0.00
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 500          |
|    mean_reward          | -1           |
| time/                   |              |
|    total_timesteps      | 310000       |
| train/                  |              |
|    approx_kl            | 0.0043186815 |
|    clip_fraction        | 0.0186       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.56        |
|    explained_variance   | 0.907        |
|    learning_rate        | 3.19e-05     |
|    loss                 | -0.0196      |
|    n_updates            | 1510         |
|    policy_gradient_loss | -0.00416     |
|    std                  | 0.871        |
|    value_loss           | 0.000217     |
------------------------------------------
-------------------------------
| time/              |        |
|    fps             | 590    |
|    iterations      | 152    |
|    time_elapsed    | 527    |
|    total_timesteps | 311296 |
-------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 590          |
|    iterations           | 153          |
|    time_elapsed         | 530          |
|    total_timesteps      | 313344       |
| train/                  |              |
|    approx_kl            | 0.0031344462 |
|    clip_fraction        | 0.0128       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.56        |
|    explained_variance   | 0.925        |
|    learning_rate        | 3.19e-05     |
|    loss                 | -0.0143      |
|    n_updates            | 1520         |
|    policy_gradient_loss | -0.00433     |
|    std                  | 0.871        |
|    value_loss           | 0.000804     |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 590          |
|    iterations           | 154          |
|    time_elapsed         | 533          |
|    total_timesteps      | 315392       |
| train/                  |              |
|    approx_kl            | 0.0016622638 |
|    clip_fraction        | 0.00161      |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.56        |
|    explained_variance   | 0.715        |
|    learning_rate        | 3.19e-05     |
|    loss                 | 0.00952      |
|    n_updates            | 1530         |
|    policy_gradient_loss | -0.000725    |
|    std                  | 0.871        |
|    value_loss           | 0.000871     |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 591          |
|    iterations           | 155          |
|    time_elapsed         | 536          |
|    total_timesteps      | 317440       |
| train/                  |              |
|    approx_kl            | 0.0032941038 |
|    clip_fraction        | 0.0108       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.56        |
|    explained_variance   | 0.907        |
|    learning_rate        | 3.19e-05     |
|    loss                 | -0.00546     |
|    n_updates            | 1540         |
|    policy_gradient_loss | -0.00298     |
|    std                  | 0.872        |
|    value_loss           | 0.000648     |
------------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 591         |
|    iterations           | 156         |
|    time_elapsed         | 540         |
|    total_timesteps      | 319488      |
| train/                  |             |
|    approx_kl            | 0.004700061 |
|    clip_fraction        | 0.0139      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.56       |
|    explained_variance   | 0.84        |
|    learning_rate        | 3.19e-05    |
|    loss                 | -0.00448    |
|    n_updates            | 1550        |
|    policy_gradient_loss | -0.00373    |
|    std                  | 0.871       |
|    value_loss           | 0.000286    |
-----------------------------------------
box reached target
box reached target
Eval num_timesteps=320000, episode_reward=1.61 +/- 3.20
Episode length: 381.80 +/- 144.79
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 382         |
|    mean_reward          | 1.61        |
| time/                   |             |
|    total_timesteps      | 320000      |
| train/                  |             |
|    approx_kl            | 0.002530719 |
|    clip_fraction        | 0.00435     |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.56       |
|    explained_variance   | 0.863       |
|    learning_rate        | 3.19e-05    |
|    loss                 | 0.00626     |
|    n_updates            | 1560        |
|    policy_gradient_loss | -0.00212    |
|    std                  | 0.872       |
|    value_loss           | 0.000312    |
-----------------------------------------
New best mean reward!
-------------------------------
| time/              |        |
|    fps             | 590    |
|    iterations      | 157    |
|    time_elapsed    | 544    |
|    total_timesteps | 321536 |
-------------------------------
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 590          |
|    iterations           | 158          |
|    time_elapsed         | 547          |
|    total_timesteps      | 323584       |
| train/                  |              |
|    approx_kl            | 0.0036042805 |
|    clip_fraction        | 0.0167       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.56        |
|    explained_variance   | 0.952        |
|    learning_rate        | 3.19e-05     |
|    loss                 | -0.00103     |
|    n_updates            | 1570         |
|    policy_gradient_loss | -0.00404     |
|    std                  | 0.871        |
|    value_loss           | 0.00166      |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 591          |
|    iterations           | 159          |
|    time_elapsed         | 550          |
|    total_timesteps      | 325632       |
| train/                  |              |
|    approx_kl            | 0.0019019584 |
|    clip_fraction        | 0.00449      |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.56        |
|    explained_variance   | -0.255       |
|    learning_rate        | 3.19e-05     |
|    loss                 | -0.0114      |
|    n_updates            | 1580         |
|    policy_gradient_loss | -0.00207     |
|    std                  | 0.868        |
|    value_loss           | 0.0889       |
------------------------------------------
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 591          |
|    iterations           | 160          |
|    time_elapsed         | 553          |
|    total_timesteps      | 327680       |
| train/                  |              |
|    approx_kl            | 0.0035898257 |
|    clip_fraction        | 0.00796      |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.56        |
|    explained_variance   | 0.897        |
|    learning_rate        | 3.2e-05      |
|    loss                 | -0.00303     |
|    n_updates            | 1590         |
|    policy_gradient_loss | -0.00151     |
|    std                  | 0.869        |
|    value_loss           | 0.00068      |
------------------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 591         |
|    iterations           | 161         |
|    time_elapsed         | 557         |
|    total_timesteps      | 329728      |
| train/                  |             |
|    approx_kl            | 0.001571235 |
|    clip_fraction        | 0.00166     |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.55       |
|    explained_variance   | 0.176       |
|    learning_rate        | 3.2e-05     |
|    loss                 | 0.00652     |
|    n_updates            | 1600        |
|    policy_gradient_loss | -0.00129    |
|    std                  | 0.867       |
|    value_loss           | 0.0736      |
-----------------------------------------
box reached target
Eval num_timesteps=330000, episode_reward=0.32 +/- 2.65
Episode length: 473.20 +/- 53.60
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 473          |
|    mean_reward          | 0.323        |
| time/                   |              |
|    total_timesteps      | 330000       |
| train/                  |              |
|    approx_kl            | 0.0032240576 |
|    clip_fraction        | 0.00649      |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.55        |
|    explained_variance   | 0.51         |
|    learning_rate        | 3.2e-05      |
|    loss                 | 0.0114       |
|    n_updates            | 1610         |
|    policy_gradient_loss | -0.0028      |
|    std                  | 0.864        |
|    value_loss           | 0.0567       |
------------------------------------------
-------------------------------
| time/              |        |
|    fps             | 590    |
|    iterations      | 162    |
|    time_elapsed    | 561    |
|    total_timesteps | 331776 |
-------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 590          |
|    iterations           | 163          |
|    time_elapsed         | 564          |
|    total_timesteps      | 333824       |
| train/                  |              |
|    approx_kl            | 0.0021194296 |
|    clip_fraction        | 0.00425      |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.54        |
|    explained_variance   | 0.842        |
|    learning_rate        | 3.2e-05      |
|    loss                 | 0.00368      |
|    n_updates            | 1620         |
|    policy_gradient_loss | -0.00192     |
|    std                  | 0.863        |
|    value_loss           | 0.00192      |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 591          |
|    iterations           | 164          |
|    time_elapsed         | 568          |
|    total_timesteps      | 335872       |
| train/                  |              |
|    approx_kl            | 0.0025781202 |
|    clip_fraction        | 0.00815      |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.54        |
|    explained_variance   | 0.817        |
|    learning_rate        | 3.2e-05      |
|    loss                 | 0.00806      |
|    n_updates            | 1630         |
|    policy_gradient_loss | -0.00373     |
|    std                  | 0.862        |
|    value_loss           | 0.00243      |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 591          |
|    iterations           | 165          |
|    time_elapsed         | 571          |
|    total_timesteps      | 337920       |
| train/                  |              |
|    approx_kl            | 0.0038311498 |
|    clip_fraction        | 0.00713      |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.54        |
|    explained_variance   | 0.88         |
|    learning_rate        | 3.2e-05      |
|    loss                 | -0.00453     |
|    n_updates            | 1640         |
|    policy_gradient_loss | -0.00236     |
|    std                  | 0.862        |
|    value_loss           | 0.000567     |
------------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 591         |
|    iterations           | 166         |
|    time_elapsed         | 574         |
|    total_timesteps      | 339968      |
| train/                  |             |
|    approx_kl            | 0.005058213 |
|    clip_fraction        | 0.0184      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.54       |
|    explained_variance   | 0.867       |
|    learning_rate        | 3.2e-05     |
|    loss                 | 0.00669     |
|    n_updates            | 1650        |
|    policy_gradient_loss | -0.00338    |
|    std                  | 0.861       |
|    value_loss           | 0.00266     |
-----------------------------------------
box reached target
Eval num_timesteps=340000, episode_reward=0.51 +/- 2.47
Episode length: 436.20 +/- 127.60
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 436          |
|    mean_reward          | 0.506        |
| time/                   |              |
|    total_timesteps      | 340000       |
| train/                  |              |
|    approx_kl            | 0.0024504066 |
|    clip_fraction        | 0.00386      |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.54        |
|    explained_variance   | 0.919        |
|    learning_rate        | 3.2e-05      |
|    loss                 | 0.00262      |
|    n_updates            | 1660         |
|    policy_gradient_loss | -0.00178     |
|    std                  | 0.86         |
|    value_loss           | 0.00344      |
------------------------------------------
-------------------------------
| time/              |        |
|    fps             | 590    |
|    iterations      | 167    |
|    time_elapsed    | 578    |
|    total_timesteps | 342016 |
-------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 591         |
|    iterations           | 168         |
|    time_elapsed         | 582         |
|    total_timesteps      | 344064      |
| train/                  |             |
|    approx_kl            | 0.002824355 |
|    clip_fraction        | 0.0203      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.54       |
|    explained_variance   | 0.924       |
|    learning_rate        | 3.21e-05    |
|    loss                 | -0.00291    |
|    n_updates            | 1670        |
|    policy_gradient_loss | -0.00441    |
|    std                  | 0.861       |
|    value_loss           | 0.00153     |
-----------------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 591         |
|    iterations           | 169         |
|    time_elapsed         | 585         |
|    total_timesteps      | 346112      |
| train/                  |             |
|    approx_kl            | 0.005977884 |
|    clip_fraction        | 0.0321      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.54       |
|    explained_variance   | 0.893       |
|    learning_rate        | 3.21e-05    |
|    loss                 | 0.000781    |
|    n_updates            | 1680        |
|    policy_gradient_loss | -0.0054     |
|    std                  | 0.861       |
|    value_loss           | 0.000345    |
-----------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 591          |
|    iterations           | 170          |
|    time_elapsed         | 588          |
|    total_timesteps      | 348160       |
| train/                  |              |
|    approx_kl            | 0.0006483917 |
|    clip_fraction        | 0            |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.54        |
|    explained_variance   | -0.149       |
|    learning_rate        | 3.21e-05     |
|    loss                 | 0.00448      |
|    n_updates            | 1690         |
|    policy_gradient_loss | -0.000407    |
|    std                  | 0.86         |
|    value_loss           | 0.0703       |
------------------------------------------
Eval num_timesteps=350000, episode_reward=-1.00 +/- 0.00
Episode length: 500.00 +/- 0.00
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 500          |
|    mean_reward          | -1           |
| time/                   |              |
|    total_timesteps      | 350000       |
| train/                  |              |
|    approx_kl            | 0.0033943425 |
|    clip_fraction        | 0.0101       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.54        |
|    explained_variance   | 0.818        |
|    learning_rate        | 3.21e-05     |
|    loss                 | -0.00577     |
|    n_updates            | 1700         |
|    policy_gradient_loss | -0.00357     |
|    std                  | 0.859        |
|    value_loss           | 0.00079      |
------------------------------------------
-------------------------------
| time/              |        |
|    fps             | 590    |
|    iterations      | 171    |
|    time_elapsed    | 593    |
|    total_timesteps | 350208 |
-------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 590          |
|    iterations           | 172          |
|    time_elapsed         | 596          |
|    total_timesteps      | 352256       |
| train/                  |              |
|    approx_kl            | 0.0042619104 |
|    clip_fraction        | 0.00977      |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.53        |
|    explained_variance   | 0.502        |
|    learning_rate        | 3.21e-05     |
|    loss                 | 0.0299       |
|    n_updates            | 1710         |
|    policy_gradient_loss | -0.004       |
|    std                  | 0.855        |
|    value_loss           | 0.00109      |
------------------------------------------
box reached target
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 591         |
|    iterations           | 173         |
|    time_elapsed         | 599         |
|    total_timesteps      | 354304      |
| train/                  |             |
|    approx_kl            | 0.004414381 |
|    clip_fraction        | 0.0141      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.52       |
|    explained_variance   | 0.826       |
|    learning_rate        | 3.21e-05    |
|    loss                 | -0.00542    |
|    n_updates            | 1720        |
|    policy_gradient_loss | -0.00311    |
|    std                  | 0.853       |
|    value_loss           | 0.000449    |
-----------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 591          |
|    iterations           | 174          |
|    time_elapsed         | 602          |
|    total_timesteps      | 356352       |
| train/                  |              |
|    approx_kl            | 0.0009944963 |
|    clip_fraction        | 0.0019       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.52        |
|    explained_variance   | 0.423        |
|    learning_rate        | 3.21e-05     |
|    loss                 | 0.00635      |
|    n_updates            | 1730         |
|    policy_gradient_loss | -0.00145     |
|    std                  | 0.852        |
|    value_loss           | 0.105        |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 591          |
|    iterations           | 175          |
|    time_elapsed         | 605          |
|    total_timesteps      | 358400       |
| train/                  |              |
|    approx_kl            | 0.0031912006 |
|    clip_fraction        | 0.0117       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.52        |
|    explained_variance   | 0.8          |
|    learning_rate        | 3.21e-05     |
|    loss                 | -0.0148      |
|    n_updates            | 1740         |
|    policy_gradient_loss | -0.00278     |
|    std                  | 0.852        |
|    value_loss           | 0.000379     |
------------------------------------------
Eval num_timesteps=360000, episode_reward=-1.00 +/- 0.00
Episode length: 500.00 +/- 0.00
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 500          |
|    mean_reward          | -1           |
| time/                   |              |
|    total_timesteps      | 360000       |
| train/                  |              |
|    approx_kl            | 0.0041938764 |
|    clip_fraction        | 0.0165       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.52        |
|    explained_variance   | 0.809        |
|    learning_rate        | 3.22e-05     |
|    loss                 | -0.0075      |
|    n_updates            | 1750         |
|    policy_gradient_loss | -0.0041      |
|    std                  | 0.851        |
|    value_loss           | 0.000322     |
------------------------------------------
box reached target
-------------------------------
| time/              |        |
|    fps             | 590    |
|    iterations      | 176    |
|    time_elapsed    | 610    |
|    total_timesteps | 360448 |
-------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 590          |
|    iterations           | 177          |
|    time_elapsed         | 613          |
|    total_timesteps      | 362496       |
| train/                  |              |
|    approx_kl            | 0.0037832218 |
|    clip_fraction        | 0.00879      |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.51        |
|    explained_variance   | 0.824        |
|    learning_rate        | 3.22e-05     |
|    loss                 | 0.0223       |
|    n_updates            | 1760         |
|    policy_gradient_loss | -0.00233     |
|    std                  | 0.848        |
|    value_loss           | 0.0312       |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 591          |
|    iterations           | 178          |
|    time_elapsed         | 616          |
|    total_timesteps      | 364544       |
| train/                  |              |
|    approx_kl            | 0.0049910056 |
|    clip_fraction        | 0.0296       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.51        |
|    explained_variance   | 0.791        |
|    learning_rate        | 3.22e-05     |
|    loss                 | -0.0128      |
|    n_updates            | 1770         |
|    policy_gradient_loss | -0.00545     |
|    std                  | 0.848        |
|    value_loss           | 0.00119      |
------------------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 591         |
|    iterations           | 179         |
|    time_elapsed         | 619         |
|    total_timesteps      | 366592      |
| train/                  |             |
|    approx_kl            | 0.006316765 |
|    clip_fraction        | 0.0326      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.51       |
|    explained_variance   | 0.763       |
|    learning_rate        | 3.22e-05    |
|    loss                 | -0.0106     |
|    n_updates            | 1780        |
|    policy_gradient_loss | -0.00629    |
|    std                  | 0.847       |
|    value_loss           | 0.000865    |
-----------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 591          |
|    iterations           | 180          |
|    time_elapsed         | 623          |
|    total_timesteps      | 368640       |
| train/                  |              |
|    approx_kl            | 0.0032481072 |
|    clip_fraction        | 0.00303      |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.5         |
|    explained_variance   | 0.878        |
|    learning_rate        | 3.22e-05     |
|    loss                 | -0.0135      |
|    n_updates            | 1790         |
|    policy_gradient_loss | -0.00187     |
|    std                  | 0.844        |
|    value_loss           | 0.0187       |
------------------------------------------
box reached target
Eval num_timesteps=370000, episode_reward=0.28 +/- 2.56
Episode length: 434.20 +/- 131.60
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 434         |
|    mean_reward          | 0.278       |
| time/                   |             |
|    total_timesteps      | 370000      |
| train/                  |             |
|    approx_kl            | 0.003011127 |
|    clip_fraction        | 0.0117      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.5        |
|    explained_variance   | 0.919       |
|    learning_rate        | 3.22e-05    |
|    loss                 | -0.0117     |
|    n_updates            | 1800        |
|    policy_gradient_loss | -0.00402    |
|    std                  | 0.843       |
|    value_loss           | 0.00464     |
-----------------------------------------
-------------------------------
| time/              |        |
|    fps             | 590    |
|    iterations      | 181    |
|    time_elapsed    | 627    |
|    total_timesteps | 370688 |
-------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 590          |
|    iterations           | 182          |
|    time_elapsed         | 630          |
|    total_timesteps      | 372736       |
| train/                  |              |
|    approx_kl            | 0.0031072446 |
|    clip_fraction        | 0.00615      |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.5         |
|    explained_variance   | 0.896        |
|    learning_rate        | 3.22e-05     |
|    loss                 | 0.0124       |
|    n_updates            | 1810         |
|    policy_gradient_loss | -0.00228     |
|    std                  | 0.843        |
|    value_loss           | 0.000735     |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 591          |
|    iterations           | 183          |
|    time_elapsed         | 633          |
|    total_timesteps      | 374784       |
| train/                  |              |
|    approx_kl            | 0.0019176635 |
|    clip_fraction        | 0.00293      |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.5         |
|    explained_variance   | 0.913        |
|    learning_rate        | 3.22e-05     |
|    loss                 | -0.0146      |
|    n_updates            | 1820         |
|    policy_gradient_loss | -0.00154     |
|    std                  | 0.845        |
|    value_loss           | 0.000453     |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 591          |
|    iterations           | 184          |
|    time_elapsed         | 637          |
|    total_timesteps      | 376832       |
| train/                  |              |
|    approx_kl            | 0.0018593029 |
|    clip_fraction        | 0.00195      |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.5         |
|    explained_variance   | 0.891        |
|    learning_rate        | 3.22e-05     |
|    loss                 | -0.00167     |
|    n_updates            | 1830         |
|    policy_gradient_loss | -0.00202     |
|    std                  | 0.846        |
|    value_loss           | 0.000268     |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 591          |
|    iterations           | 185          |
|    time_elapsed         | 640          |
|    total_timesteps      | 378880       |
| train/                  |              |
|    approx_kl            | 0.0032217507 |
|    clip_fraction        | 0.00884      |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.5         |
|    explained_variance   | 0.867        |
|    learning_rate        | 3.23e-05     |
|    loss                 | -0.0128      |
|    n_updates            | 1840         |
|    policy_gradient_loss | -0.00174     |
|    std                  | 0.846        |
|    value_loss           | 0.00288      |
------------------------------------------
Eval num_timesteps=380000, episode_reward=-1.00 +/- 0.00
Episode length: 500.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 500         |
|    mean_reward          | -1          |
| time/                   |             |
|    total_timesteps      | 380000      |
| train/                  |             |
|    approx_kl            | 0.003410603 |
|    clip_fraction        | 0.00811     |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.5        |
|    explained_variance   | 0.707       |
|    learning_rate        | 3.23e-05    |
|    loss                 | -0.0227     |
|    n_updates            | 1850        |
|    policy_gradient_loss | -0.00308    |
|    std                  | 0.845       |
|    value_loss           | 0.000577    |
-----------------------------------------
-------------------------------
| time/              |        |
|    fps             | 590    |
|    iterations      | 186    |
|    time_elapsed    | 644    |
|    total_timesteps | 380928 |
-------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 590         |
|    iterations           | 187         |
|    time_elapsed         | 648         |
|    total_timesteps      | 382976      |
| train/                  |             |
|    approx_kl            | 0.002669633 |
|    clip_fraction        | 0.00869     |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.5        |
|    explained_variance   | 0.862       |
|    learning_rate        | 3.23e-05    |
|    loss                 | -0.0107     |
|    n_updates            | 1860        |
|    policy_gradient_loss | -0.0021     |
|    std                  | 0.846       |
|    value_loss           | 0.000563    |
-----------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 591          |
|    iterations           | 188          |
|    time_elapsed         | 651          |
|    total_timesteps      | 385024       |
| train/                  |              |
|    approx_kl            | 0.0052093742 |
|    clip_fraction        | 0.0389       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.5         |
|    explained_variance   | 0.91         |
|    learning_rate        | 3.23e-05     |
|    loss                 | -0.000717    |
|    n_updates            | 1870         |
|    policy_gradient_loss | -0.00471     |
|    std                  | 0.847        |
|    value_loss           | 0.000137     |
------------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 591        |
|    iterations           | 189        |
|    time_elapsed         | 654        |
|    total_timesteps      | 387072     |
| train/                  |            |
|    approx_kl            | 0.00523025 |
|    clip_fraction        | 0.0188     |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.5       |
|    explained_variance   | 0.848      |
|    learning_rate        | 3.23e-05   |
|    loss                 | -0.0159    |
|    n_updates            | 1880       |
|    policy_gradient_loss | -0.00438   |
|    std                  | 0.846      |
|    value_loss           | 0.000343   |
----------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 591          |
|    iterations           | 190          |
|    time_elapsed         | 657          |
|    total_timesteps      | 389120       |
| train/                  |              |
|    approx_kl            | 0.0045413617 |
|    clip_fraction        | 0.019        |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.5         |
|    explained_variance   | 0.405        |
|    learning_rate        | 3.23e-05     |
|    loss                 | 0.0231       |
|    n_updates            | 1890         |
|    policy_gradient_loss | -0.00539     |
|    std                  | 0.843        |
|    value_loss           | 0.00135      |
------------------------------------------
box reached target
Eval num_timesteps=390000, episode_reward=0.29 +/- 2.59
Episode length: 430.60 +/- 138.80
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 431          |
|    mean_reward          | 0.293        |
| time/                   |              |
|    total_timesteps      | 390000       |
| train/                  |              |
|    approx_kl            | 0.0046529677 |
|    clip_fraction        | 0.0288       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.49        |
|    explained_variance   | 0.822        |
|    learning_rate        | 3.23e-05     |
|    loss                 | -0.00461     |
|    n_updates            | 1900         |
|    policy_gradient_loss | -0.00478     |
|    std                  | 0.842        |
|    value_loss           | 0.000272     |
------------------------------------------
-------------------------------
| time/              |        |
|    fps             | 590    |
|    iterations      | 191    |
|    time_elapsed    | 662    |
|    total_timesteps | 391168 |
-------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 591          |
|    iterations           | 192          |
|    time_elapsed         | 665          |
|    total_timesteps      | 393216       |
| train/                  |              |
|    approx_kl            | 0.0032550672 |
|    clip_fraction        | 0.0129       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.49        |
|    explained_variance   | 0.859        |
|    learning_rate        | 3.23e-05     |
|    loss                 | -0.0382      |
|    n_updates            | 1910         |
|    policy_gradient_loss | -0.00291     |
|    std                  | 0.842        |
|    value_loss           | 0.000459     |
------------------------------------------
box reached target
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 591         |
|    iterations           | 193         |
|    time_elapsed         | 668         |
|    total_timesteps      | 395264      |
| train/                  |             |
|    approx_kl            | 0.007013795 |
|    clip_fraction        | 0.043       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.49       |
|    explained_variance   | 0.803       |
|    learning_rate        | 3.24e-05    |
|    loss                 | -0.0304     |
|    n_updates            | 1920        |
|    policy_gradient_loss | -0.00843    |
|    std                  | 0.841       |
|    value_loss           | 0.000201    |
-----------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 591        |
|    iterations           | 194        |
|    time_elapsed         | 671        |
|    total_timesteps      | 397312     |
| train/                  |            |
|    approx_kl            | 0.00105291 |
|    clip_fraction        | 0.000195   |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.49      |
|    explained_variance   | 0.688      |
|    learning_rate        | 3.24e-05   |
|    loss                 | 0.0208     |
|    n_updates            | 1930       |
|    policy_gradient_loss | -0.00142   |
|    std                  | 0.84       |
|    value_loss           | 0.0697     |
----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 591         |
|    iterations           | 195         |
|    time_elapsed         | 674         |
|    total_timesteps      | 399360      |
| train/                  |             |
|    approx_kl            | 0.004159865 |
|    clip_fraction        | 0.0201      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.49       |
|    explained_variance   | 0.881       |
|    learning_rate        | 3.24e-05    |
|    loss                 | -0.0157     |
|    n_updates            | 1940        |
|    policy_gradient_loss | -0.00312    |
|    std                  | 0.84        |
|    value_loss           | 0.000667    |
-----------------------------------------
Eval num_timesteps=400000, episode_reward=-0.82 +/- 0.36
Episode length: 500.00 +/- 0.00
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 500          |
|    mean_reward          | -0.818       |
| time/                   |              |
|    total_timesteps      | 400000       |
| train/                  |              |
|    approx_kl            | 0.0033387416 |
|    clip_fraction        | 0.0102       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.49        |
|    explained_variance   | 0.893        |
|    learning_rate        | 3.24e-05     |
|    loss                 | -0.0114      |
|    n_updates            | 1950         |
|    policy_gradient_loss | -0.00198     |
|    std                  | 0.84         |
|    value_loss           | 0.00112      |
------------------------------------------
box reached target
-------------------------------
| time/              |        |
|    fps             | 590    |
|    iterations      | 196    |
|    time_elapsed    | 679    |
|    total_timesteps | 401408 |
-------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 591          |
|    iterations           | 197          |
|    time_elapsed         | 682          |
|    total_timesteps      | 403456       |
| train/                  |              |
|    approx_kl            | 0.0008236399 |
|    clip_fraction        | 4.88e-05     |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.49        |
|    explained_variance   | 0.889        |
|    learning_rate        | 3.24e-05     |
|    loss                 | 0.0183       |
|    n_updates            | 1960         |
|    policy_gradient_loss | -0.000334    |
|    std                  | 0.84         |
|    value_loss           | 0.0255       |
------------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 591         |
|    iterations           | 198         |
|    time_elapsed         | 685         |
|    total_timesteps      | 405504      |
| train/                  |             |
|    approx_kl            | 0.005697538 |
|    clip_fraction        | 0.0417      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.49       |
|    explained_variance   | 0.879       |
|    learning_rate        | 3.24e-05    |
|    loss                 | 0.00723     |
|    n_updates            | 1970        |
|    policy_gradient_loss | -0.00594    |
|    std                  | 0.839       |
|    value_loss           | 0.000696    |
-----------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 591          |
|    iterations           | 199          |
|    time_elapsed         | 688          |
|    total_timesteps      | 407552       |
| train/                  |              |
|    approx_kl            | 0.0040156823 |
|    clip_fraction        | 0.0165       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.49        |
|    explained_variance   | 0.904        |
|    learning_rate        | 3.24e-05     |
|    loss                 | 0.0178       |
|    n_updates            | 1980         |
|    policy_gradient_loss | -0.00218     |
|    std                  | 0.84         |
|    value_loss           | 0.00196      |
------------------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 591         |
|    iterations           | 200         |
|    time_elapsed         | 692         |
|    total_timesteps      | 409600      |
| train/                  |             |
|    approx_kl            | 0.003229937 |
|    clip_fraction        | 0.00889     |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.49       |
|    explained_variance   | 0.947       |
|    learning_rate        | 3.24e-05    |
|    loss                 | 0.00742     |
|    n_updates            | 1990        |
|    policy_gradient_loss | -0.00333    |
|    std                  | 0.84        |
|    value_loss           | 0.00107     |
-----------------------------------------
Eval num_timesteps=410000, episode_reward=-0.78 +/- 0.44
Episode length: 500.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 500         |
|    mean_reward          | -0.779      |
| time/                   |             |
|    total_timesteps      | 410000      |
| train/                  |             |
|    approx_kl            | 0.002118328 |
|    clip_fraction        | 0.00303     |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.49       |
|    explained_variance   | 0.871       |
|    learning_rate        | 3.25e-05    |
|    loss                 | 0.0203      |
|    n_updates            | 2000        |
|    policy_gradient_loss | -0.00225    |
|    std                  | 0.838       |
|    value_loss           | 0.0309      |
-----------------------------------------
-------------------------------
| time/              |        |
|    fps             | 590    |
|    iterations      | 201    |
|    time_elapsed    | 696    |
|    total_timesteps | 411648 |
-------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 591         |
|    iterations           | 202         |
|    time_elapsed         | 699         |
|    total_timesteps      | 413696      |
| train/                  |             |
|    approx_kl            | 0.005273853 |
|    clip_fraction        | 0.0214      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.48       |
|    explained_variance   | 0.973       |
|    learning_rate        | 3.25e-05    |
|    loss                 | -0.0229     |
|    n_updates            | 2010        |
|    policy_gradient_loss | -0.00331    |
|    std                  | 0.836       |
|    value_loss           | 0.00155     |
-----------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 591          |
|    iterations           | 203          |
|    time_elapsed         | 703          |
|    total_timesteps      | 415744       |
| train/                  |              |
|    approx_kl            | 0.0028372137 |
|    clip_fraction        | 0.00679      |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.48        |
|    explained_variance   | 0.92         |
|    learning_rate        | 3.25e-05     |
|    loss                 | -0.00396     |
|    n_updates            | 2020         |
|    policy_gradient_loss | -0.00119     |
|    std                  | 0.839        |
|    value_loss           | 0.00325      |
------------------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 591         |
|    iterations           | 204         |
|    time_elapsed         | 706         |
|    total_timesteps      | 417792      |
| train/                  |             |
|    approx_kl            | 0.003760709 |
|    clip_fraction        | 0.0185      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.49       |
|    explained_variance   | 0.897       |
|    learning_rate        | 3.25e-05    |
|    loss                 | 0.0203      |
|    n_updates            | 2030        |
|    policy_gradient_loss | -0.00218    |
|    std                  | 0.839       |
|    value_loss           | 0.000567    |
-----------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 591          |
|    iterations           | 205          |
|    time_elapsed         | 709          |
|    total_timesteps      | 419840       |
| train/                  |              |
|    approx_kl            | 0.0034690541 |
|    clip_fraction        | 0.0118       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.48        |
|    explained_variance   | 0.951        |
|    learning_rate        | 3.25e-05     |
|    loss                 | -0.0179      |
|    n_updates            | 2040         |
|    policy_gradient_loss | -0.00233     |
|    std                  | 0.835        |
|    value_loss           | 0.0111       |
------------------------------------------
box reached target
Eval num_timesteps=420000, episode_reward=0.53 +/- 2.46
Episode length: 436.00 +/- 128.00
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 436          |
|    mean_reward          | 0.531        |
| time/                   |              |
|    total_timesteps      | 420000       |
| train/                  |              |
|    approx_kl            | 0.0043014726 |
|    clip_fraction        | 0.0306       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.48        |
|    explained_variance   | 0.914        |
|    learning_rate        | 3.25e-05     |
|    loss                 | -0.0168      |
|    n_updates            | 2050         |
|    policy_gradient_loss | -0.00642     |
|    std                  | 0.834        |
|    value_loss           | 0.000837     |
------------------------------------------
-------------------------------
| time/              |        |
|    fps             | 590    |
|    iterations      | 206    |
|    time_elapsed    | 713    |
|    total_timesteps | 421888 |
-------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 591          |
|    iterations           | 207          |
|    time_elapsed         | 717          |
|    total_timesteps      | 423936       |
| train/                  |              |
|    approx_kl            | 0.0033405297 |
|    clip_fraction        | 0.0133       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.47        |
|    explained_variance   | 0.943        |
|    learning_rate        | 3.25e-05     |
|    loss                 | -0.019       |
|    n_updates            | 2060         |
|    policy_gradient_loss | -0.00315     |
|    std                  | 0.834        |
|    value_loss           | 0.00412      |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 591          |
|    iterations           | 208          |
|    time_elapsed         | 720          |
|    total_timesteps      | 425984       |
| train/                  |              |
|    approx_kl            | 0.0056809695 |
|    clip_fraction        | 0.0238       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.47        |
|    explained_variance   | 0.833        |
|    learning_rate        | 3.25e-05     |
|    loss                 | 0.00946      |
|    n_updates            | 2070         |
|    policy_gradient_loss | -0.00359     |
|    std                  | 0.831        |
|    value_loss           | 0.000675     |
------------------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 591         |
|    iterations           | 209         |
|    time_elapsed         | 723         |
|    total_timesteps      | 428032      |
| train/                  |             |
|    approx_kl            | 0.005193281 |
|    clip_fraction        | 0.0195      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.47       |
|    explained_variance   | 0.889       |
|    learning_rate        | 3.26e-05    |
|    loss                 | -0.0153     |
|    n_updates            | 2080        |
|    policy_gradient_loss | -0.00393    |
|    std                  | 0.831       |
|    value_loss           | 0.000442    |
-----------------------------------------
box reached target
Eval num_timesteps=430000, episode_reward=0.27 +/- 2.53
Episode length: 436.00 +/- 128.00
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 436          |
|    mean_reward          | 0.266        |
| time/                   |              |
|    total_timesteps      | 430000       |
| train/                  |              |
|    approx_kl            | 0.0014813379 |
|    clip_fraction        | 0.000977     |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.46        |
|    explained_variance   | 0.864        |
|    learning_rate        | 3.26e-05     |
|    loss                 | -0.00794     |
|    n_updates            | 2090         |
|    policy_gradient_loss | -0.000552    |
|    std                  | 0.83         |
|    value_loss           | 0.0215       |
------------------------------------------
-------------------------------
| time/              |        |
|    fps             | 590    |
|    iterations      | 210    |
|    time_elapsed    | 727    |
|    total_timesteps | 430080 |
-------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 591          |
|    iterations           | 211          |
|    time_elapsed         | 731          |
|    total_timesteps      | 432128       |
| train/                  |              |
|    approx_kl            | 0.0036881082 |
|    clip_fraction        | 0.0138       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.46        |
|    explained_variance   | 0.873        |
|    learning_rate        | 3.26e-05     |
|    loss                 | 0.0187       |
|    n_updates            | 2100         |
|    policy_gradient_loss | -0.00276     |
|    std                  | 0.829        |
|    value_loss           | 0.000353     |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 591          |
|    iterations           | 212          |
|    time_elapsed         | 734          |
|    total_timesteps      | 434176       |
| train/                  |              |
|    approx_kl            | 0.0043606726 |
|    clip_fraction        | 0.0204       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.46        |
|    explained_variance   | 0.811        |
|    learning_rate        | 3.26e-05     |
|    loss                 | 0.00512      |
|    n_updates            | 2110         |
|    policy_gradient_loss | -0.00438     |
|    std                  | 0.828        |
|    value_loss           | 0.000359     |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 591          |
|    iterations           | 213          |
|    time_elapsed         | 737          |
|    total_timesteps      | 436224       |
| train/                  |              |
|    approx_kl            | 0.0035222145 |
|    clip_fraction        | 0.0106       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.46        |
|    explained_variance   | 0.874        |
|    learning_rate        | 3.26e-05     |
|    loss                 | -0.0159      |
|    n_updates            | 2120         |
|    policy_gradient_loss | -0.00244     |
|    std                  | 0.828        |
|    value_loss           | 0.000648     |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 591          |
|    iterations           | 214          |
|    time_elapsed         | 740          |
|    total_timesteps      | 438272       |
| train/                  |              |
|    approx_kl            | 0.0054574357 |
|    clip_fraction        | 0.0358       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.46        |
|    explained_variance   | 0.862        |
|    learning_rate        | 3.26e-05     |
|    loss                 | 0.0121       |
|    n_updates            | 2130         |
|    policy_gradient_loss | -0.00401     |
|    std                  | 0.828        |
|    value_loss           | 0.000436     |
------------------------------------------
box reached target
Eval num_timesteps=440000, episode_reward=0.30 +/- 2.60
Episode length: 469.80 +/- 60.40
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 470          |
|    mean_reward          | 0.298        |
| time/                   |              |
|    total_timesteps      | 440000       |
| train/                  |              |
|    approx_kl            | 0.0025880416 |
|    clip_fraction        | 0.00723      |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.46        |
|    explained_variance   | 0.853        |
|    learning_rate        | 3.26e-05     |
|    loss                 | -0.00293     |
|    n_updates            | 2140         |
|    policy_gradient_loss | -0.00208     |
|    std                  | 0.826        |
|    value_loss           | 0.000406     |
------------------------------------------
-------------------------------
| time/              |        |
|    fps             | 590    |
|    iterations      | 215    |
|    time_elapsed    | 745    |
|    total_timesteps | 440320 |
-------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 591         |
|    iterations           | 216         |
|    time_elapsed         | 748         |
|    total_timesteps      | 442368      |
| train/                  |             |
|    approx_kl            | 0.003973877 |
|    clip_fraction        | 0.0115      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.45       |
|    explained_variance   | 0.193       |
|    learning_rate        | 3.26e-05    |
|    loss                 | -0.0158     |
|    n_updates            | 2150        |
|    policy_gradient_loss | -0.00247    |
|    std                  | 0.825       |
|    value_loss           | 0.00164     |
-----------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 591          |
|    iterations           | 217          |
|    time_elapsed         | 751          |
|    total_timesteps      | 444416       |
| train/                  |              |
|    approx_kl            | 0.0026480828 |
|    clip_fraction        | 0.00508      |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.45        |
|    explained_variance   | 0.858        |
|    learning_rate        | 3.27e-05     |
|    loss                 | 0.00168      |
|    n_updates            | 2160         |
|    policy_gradient_loss | -0.00221     |
|    std                  | 0.824        |
|    value_loss           | 0.000414     |
------------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 591         |
|    iterations           | 218         |
|    time_elapsed         | 754         |
|    total_timesteps      | 446464      |
| train/                  |             |
|    approx_kl            | 0.004347975 |
|    clip_fraction        | 0.0187      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.45       |
|    explained_variance   | 0.837       |
|    learning_rate        | 3.27e-05    |
|    loss                 | -0.00423    |
|    n_updates            | 2170        |
|    policy_gradient_loss | -0.00481    |
|    std                  | 0.824       |
|    value_loss           | 0.00033     |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 591         |
|    iterations           | 219         |
|    time_elapsed         | 757         |
|    total_timesteps      | 448512      |
| train/                  |             |
|    approx_kl            | 0.006736233 |
|    clip_fraction        | 0.0405      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.45       |
|    explained_variance   | 0.881       |
|    learning_rate        | 3.27e-05    |
|    loss                 | -0.0115     |
|    n_updates            | 2180        |
|    policy_gradient_loss | -0.00682    |
|    std                  | 0.823       |
|    value_loss           | 0.000422    |
-----------------------------------------
box reached target
Eval num_timesteps=450000, episode_reward=-1.00 +/- 0.00
Episode length: 500.00 +/- 0.00
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 500          |
|    mean_reward          | -1           |
| time/                   |              |
|    total_timesteps      | 450000       |
| train/                  |              |
|    approx_kl            | 0.0041784868 |
|    clip_fraction        | 0.0245       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.45        |
|    explained_variance   | 0.936        |
|    learning_rate        | 3.27e-05     |
|    loss                 | -0.000606    |
|    n_updates            | 2190         |
|    policy_gradient_loss | -0.00572     |
|    std                  | 0.824        |
|    value_loss           | 0.00281      |
------------------------------------------
-------------------------------
| time/              |        |
|    fps             | 590    |
|    iterations      | 220    |
|    time_elapsed    | 762    |
|    total_timesteps | 450560 |
-------------------------------
box reached target
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 591          |
|    iterations           | 221          |
|    time_elapsed         | 765          |
|    total_timesteps      | 452608       |
| train/                  |              |
|    approx_kl            | 0.0008092873 |
|    clip_fraction        | 4.88e-05     |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.45        |
|    explained_variance   | 0.903        |
|    learning_rate        | 3.27e-05     |
|    loss                 | 0.0213       |
|    n_updates            | 2200         |
|    policy_gradient_loss | -0.000634    |
|    std                  | 0.823        |
|    value_loss           | 0.0165       |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 591          |
|    iterations           | 222          |
|    time_elapsed         | 768          |
|    total_timesteps      | 454656       |
| train/                  |              |
|    approx_kl            | 0.0018357174 |
|    clip_fraction        | 0.00308      |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.45        |
|    explained_variance   | 0.264        |
|    learning_rate        | 3.27e-05     |
|    loss                 | 0.192        |
|    n_updates            | 2210         |
|    policy_gradient_loss | -0.00135     |
|    std                  | 0.82         |
|    value_loss           | 0.171        |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 591          |
|    iterations           | 223          |
|    time_elapsed         | 771          |
|    total_timesteps      | 456704       |
| train/                  |              |
|    approx_kl            | 0.0037629378 |
|    clip_fraction        | 0.0266       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.44        |
|    explained_variance   | 0.915        |
|    learning_rate        | 3.27e-05     |
|    loss                 | -0.00812     |
|    n_updates            | 2220         |
|    policy_gradient_loss | -0.00264     |
|    std                  | 0.821        |
|    value_loss           | 0.000365     |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 591          |
|    iterations           | 224          |
|    time_elapsed         | 774          |
|    total_timesteps      | 458752       |
| train/                  |              |
|    approx_kl            | 0.0055303723 |
|    clip_fraction        | 0.0315       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.44        |
|    explained_variance   | 0.821        |
|    learning_rate        | 3.27e-05     |
|    loss                 | -0.00836     |
|    n_updates            | 2230         |
|    policy_gradient_loss | -0.00459     |
|    std                  | 0.821        |
|    value_loss           | 0.000523     |
------------------------------------------
Eval num_timesteps=460000, episode_reward=-1.00 +/- 0.00
Episode length: 500.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 500         |
|    mean_reward          | -1          |
| time/                   |             |
|    total_timesteps      | 460000      |
| train/                  |             |
|    approx_kl            | 0.004555194 |
|    clip_fraction        | 0.0261      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.44       |
|    explained_variance   | 0.874       |
|    learning_rate        | 3.28e-05    |
|    loss                 | 0.0118      |
|    n_updates            | 2240        |
|    policy_gradient_loss | -0.00485    |
|    std                  | 0.821       |
|    value_loss           | 0.000419    |
-----------------------------------------
-------------------------------
| time/              |        |
|    fps             | 590    |
|    iterations      | 225    |
|    time_elapsed    | 779    |
|    total_timesteps | 460800 |
-------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 591          |
|    iterations           | 226          |
|    time_elapsed         | 782          |
|    total_timesteps      | 462848       |
| train/                  |              |
|    approx_kl            | 0.0040780166 |
|    clip_fraction        | 0.0175       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.45        |
|    explained_variance   | 0.961        |
|    learning_rate        | 3.28e-05     |
|    loss                 | -0.0067      |
|    n_updates            | 2250         |
|    policy_gradient_loss | -0.00202     |
|    std                  | 0.823        |
|    value_loss           | 0.000922     |
------------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 591         |
|    iterations           | 227         |
|    time_elapsed         | 786         |
|    total_timesteps      | 464896      |
| train/                  |             |
|    approx_kl            | 0.003644264 |
|    clip_fraction        | 0.0169      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.45       |
|    explained_variance   | 0.817       |
|    learning_rate        | 3.28e-05    |
|    loss                 | -0.00104    |
|    n_updates            | 2260        |
|    policy_gradient_loss | -0.00491    |
|    std                  | 0.824       |
|    value_loss           | 0.000455    |
-----------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 591          |
|    iterations           | 228          |
|    time_elapsed         | 789          |
|    total_timesteps      | 466944       |
| train/                  |              |
|    approx_kl            | 0.0046769464 |
|    clip_fraction        | 0.0297       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.45        |
|    explained_variance   | 0.886        |
|    learning_rate        | 3.28e-05     |
|    loss                 | 0.00497      |
|    n_updates            | 2270         |
|    policy_gradient_loss | -0.00602     |
|    std                  | 0.822        |
|    value_loss           | 0.000341     |
------------------------------------------
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 591          |
|    iterations           | 229          |
|    time_elapsed         | 792          |
|    total_timesteps      | 468992       |
| train/                  |              |
|    approx_kl            | 0.0049636755 |
|    clip_fraction        | 0.0282       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.44        |
|    explained_variance   | 0.889        |
|    learning_rate        | 3.28e-05     |
|    loss                 | 8.07e-05     |
|    n_updates            | 2280         |
|    policy_gradient_loss | -0.00351     |
|    std                  | 0.821        |
|    value_loss           | 0.000937     |
------------------------------------------
box reached target
Eval num_timesteps=470000, episode_reward=0.30 +/- 2.61
Episode length: 434.40 +/- 131.20
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 434          |
|    mean_reward          | 0.303        |
| time/                   |              |
|    total_timesteps      | 470000       |
| train/                  |              |
|    approx_kl            | 0.0040924666 |
|    clip_fraction        | 0.0155       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.44        |
|    explained_variance   | 0.0621       |
|    learning_rate        | 3.28e-05     |
|    loss                 | -0.0251      |
|    n_updates            | 2290         |
|    policy_gradient_loss | -0.00345     |
|    std                  | 0.82         |
|    value_loss           | 0.0736       |
------------------------------------------
-------------------------------
| time/              |        |
|    fps             | 591    |
|    iterations      | 230    |
|    time_elapsed    | 796    |
|    total_timesteps | 471040 |
-------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 591          |
|    iterations           | 231          |
|    time_elapsed         | 799          |
|    total_timesteps      | 473088       |
| train/                  |              |
|    approx_kl            | 0.0031853938 |
|    clip_fraction        | 0.0116       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.44        |
|    explained_variance   | 0.809        |
|    learning_rate        | 3.28e-05     |
|    loss                 | -0.0109      |
|    n_updates            | 2300         |
|    policy_gradient_loss | -0.00184     |
|    std                  | 0.822        |
|    value_loss           | 0.00248      |
------------------------------------------
box reached target
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 591          |
|    iterations           | 232          |
|    time_elapsed         | 803          |
|    total_timesteps      | 475136       |
| train/                  |              |
|    approx_kl            | 0.0022962382 |
|    clip_fraction        | 0.00723      |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.44        |
|    explained_variance   | 0.876        |
|    learning_rate        | 3.28e-05     |
|    loss                 | -0.00669     |
|    n_updates            | 2310         |
|    policy_gradient_loss | -0.00356     |
|    std                  | 0.822        |
|    value_loss           | 0.000758     |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 591          |
|    iterations           | 233          |
|    time_elapsed         | 806          |
|    total_timesteps      | 477184       |
| train/                  |              |
|    approx_kl            | 0.0016491376 |
|    clip_fraction        | 0.00532      |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.44        |
|    explained_variance   | 0.13         |
|    learning_rate        | 3.29e-05     |
|    loss                 | 0.064        |
|    n_updates            | 2320         |
|    policy_gradient_loss | -0.00343     |
|    std                  | 0.819        |
|    value_loss           | 0.16         |
------------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 592         |
|    iterations           | 234         |
|    time_elapsed         | 809         |
|    total_timesteps      | 479232      |
| train/                  |             |
|    approx_kl            | 0.004297597 |
|    clip_fraction        | 0.0114      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.44       |
|    explained_variance   | 0.83        |
|    learning_rate        | 3.29e-05    |
|    loss                 | 0.015       |
|    n_updates            | 2330        |
|    policy_gradient_loss | -0.00367    |
|    std                  | 0.817       |
|    value_loss           | 0.00625     |
-----------------------------------------
box reached target
Eval num_timesteps=480000, episode_reward=0.44 +/- 2.75
Episode length: 449.20 +/- 101.60
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 449          |
|    mean_reward          | 0.445        |
| time/                   |              |
|    total_timesteps      | 480000       |
| train/                  |              |
|    approx_kl            | 0.0038452777 |
|    clip_fraction        | 0.0147       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.43        |
|    explained_variance   | 0.826        |
|    learning_rate        | 3.29e-05     |
|    loss                 | -0.0126      |
|    n_updates            | 2340         |
|    policy_gradient_loss | -0.00359     |
|    std                  | 0.818        |
|    value_loss           | 0.00237      |
------------------------------------------
-------------------------------
| time/              |        |
|    fps             | 591    |
|    iterations      | 235    |
|    time_elapsed    | 814    |
|    total_timesteps | 481280 |
-------------------------------
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 591          |
|    iterations           | 236          |
|    time_elapsed         | 817          |
|    total_timesteps      | 483328       |
| train/                  |              |
|    approx_kl            | 0.0035404689 |
|    clip_fraction        | 0.00981      |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.43        |
|    explained_variance   | 0.905        |
|    learning_rate        | 3.29e-05     |
|    loss                 | -0.000442    |
|    n_updates            | 2350         |
|    policy_gradient_loss | -0.00246     |
|    std                  | 0.817        |
|    value_loss           | 0.00129      |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 591          |
|    iterations           | 237          |
|    time_elapsed         | 820          |
|    total_timesteps      | 485376       |
| train/                  |              |
|    approx_kl            | 0.0025950386 |
|    clip_fraction        | 0.00918      |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.43        |
|    explained_variance   | 0.724        |
|    learning_rate        | 3.29e-05     |
|    loss                 | -0.0227      |
|    n_updates            | 2360         |
|    policy_gradient_loss | -0.0014      |
|    std                  | 0.814        |
|    value_loss           | 0.0242       |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 591          |
|    iterations           | 238          |
|    time_elapsed         | 823          |
|    total_timesteps      | 487424       |
| train/                  |              |
|    approx_kl            | 0.0040399525 |
|    clip_fraction        | 0.0154       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.43        |
|    explained_variance   | 0.835        |
|    learning_rate        | 3.29e-05     |
|    loss                 | 0.0172       |
|    n_updates            | 2370         |
|    policy_gradient_loss | -0.00288     |
|    std                  | 0.815        |
|    value_loss           | 0.000609     |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 592          |
|    iterations           | 239          |
|    time_elapsed         | 826          |
|    total_timesteps      | 489472       |
| train/                  |              |
|    approx_kl            | 0.0025189652 |
|    clip_fraction        | 0.00737      |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.43        |
|    explained_variance   | 0.817        |
|    learning_rate        | 3.29e-05     |
|    loss                 | -0.00551     |
|    n_updates            | 2380         |
|    policy_gradient_loss | -0.00219     |
|    std                  | 0.816        |
|    value_loss           | 0.00737      |
------------------------------------------
Eval num_timesteps=490000, episode_reward=-1.00 +/- 0.00
Episode length: 500.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 500         |
|    mean_reward          | -1          |
| time/                   |             |
|    total_timesteps      | 490000      |
| train/                  |             |
|    approx_kl            | 0.005885976 |
|    clip_fraction        | 0.0416      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.43       |
|    explained_variance   | 0.866       |
|    learning_rate        | 3.29e-05    |
|    loss                 | -0.00241    |
|    n_updates            | 2390        |
|    policy_gradient_loss | -0.00638    |
|    std                  | 0.815       |
|    value_loss           | 0.000747    |
-----------------------------------------
box reached target
-------------------------------
| time/              |        |
|    fps             | 591    |
|    iterations      | 240    |
|    time_elapsed    | 831    |
|    total_timesteps | 491520 |
-------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 591          |
|    iterations           | 241          |
|    time_elapsed         | 834          |
|    total_timesteps      | 493568       |
| train/                  |              |
|    approx_kl            | 0.0013209342 |
|    clip_fraction        | 0.00181      |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.43        |
|    explained_variance   | -0.651       |
|    learning_rate        | 3.29e-05     |
|    loss                 | 0.0104       |
|    n_updates            | 2400         |
|    policy_gradient_loss | -0.000633    |
|    std                  | 0.815        |
|    value_loss           | 0.119        |
------------------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 591         |
|    iterations           | 242         |
|    time_elapsed         | 837         |
|    total_timesteps      | 495616      |
| train/                  |             |
|    approx_kl            | 0.004577154 |
|    clip_fraction        | 0.0198      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.43       |
|    explained_variance   | 0.808       |
|    learning_rate        | 3.3e-05     |
|    loss                 | -0.014      |
|    n_updates            | 2410        |
|    policy_gradient_loss | -0.00182    |
|    std                  | 0.815       |
|    value_loss           | 0.000718    |
-----------------------------------------
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 591          |
|    iterations           | 243          |
|    time_elapsed         | 840          |
|    total_timesteps      | 497664       |
| train/                  |              |
|    approx_kl            | 0.0036546548 |
|    clip_fraction        | 0.0102       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.43        |
|    explained_variance   | 0.376        |
|    learning_rate        | 3.3e-05      |
|    loss                 | 0.0344       |
|    n_updates            | 2420         |
|    policy_gradient_loss | -0.00202     |
|    std                  | 0.815        |
|    value_loss           | 0.0479       |
------------------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 592         |
|    iterations           | 244         |
|    time_elapsed         | 843         |
|    total_timesteps      | 499712      |
| train/                  |             |
|    approx_kl            | 0.002395229 |
|    clip_fraction        | 0.00664     |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.42       |
|    explained_variance   | 0.883       |
|    learning_rate        | 3.3e-05     |
|    loss                 | 0.0245      |
|    n_updates            | 2430        |
|    policy_gradient_loss | -0.00244    |
|    std                  | 0.812       |
|    value_loss           | 0.0176      |
-----------------------------------------
Eval num_timesteps=500000, episode_reward=-1.00 +/- 0.00
Episode length: 500.00 +/- 0.00
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 500          |
|    mean_reward          | -1           |
| time/                   |              |
|    total_timesteps      | 500000       |
| train/                  |              |
|    approx_kl            | 0.0016700426 |
|    clip_fraction        | 0.00166      |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.42        |
|    explained_variance   | 0.404        |
|    learning_rate        | 3.3e-05      |
|    loss                 | 0.0536       |
|    n_updates            | 2440         |
|    policy_gradient_loss | -0.000477    |
|    std                  | 0.809        |
|    value_loss           | 0.0629       |
------------------------------------------
box reached target
-------------------------------
| time/              |        |
|    fps             | 591    |
|    iterations      | 245    |
|    time_elapsed    | 848    |
|    total_timesteps | 501760 |
-------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 591          |
|    iterations           | 246          |
|    time_elapsed         | 851          |
|    total_timesteps      | 503808       |
| train/                  |              |
|    approx_kl            | 0.0017112945 |
|    clip_fraction        | 0.00962      |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.41        |
|    explained_variance   | 0.844        |
|    learning_rate        | 3.3e-05      |
|    loss                 | -0.00559     |
|    n_updates            | 2450         |
|    policy_gradient_loss | -0.00456     |
|    std                  | 0.808        |
|    value_loss           | 0.0401       |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 591          |
|    iterations           | 247          |
|    time_elapsed         | 855          |
|    total_timesteps      | 505856       |
| train/                  |              |
|    approx_kl            | 0.0027731017 |
|    clip_fraction        | 0.0131       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.41        |
|    explained_variance   | 0.786        |
|    learning_rate        | 3.3e-05      |
|    loss                 | -0.00679     |
|    n_updates            | 2460         |
|    policy_gradient_loss | -0.00389     |
|    std                  | 0.807        |
|    value_loss           | 0.00171      |
------------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 591         |
|    iterations           | 248         |
|    time_elapsed         | 858         |
|    total_timesteps      | 507904      |
| train/                  |             |
|    approx_kl            | 0.002403732 |
|    clip_fraction        | 0.0105      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.41       |
|    explained_variance   | 0.906       |
|    learning_rate        | 3.3e-05     |
|    loss                 | -0.00135    |
|    n_updates            | 2470        |
|    policy_gradient_loss | -0.00183    |
|    std                  | 0.806       |
|    value_loss           | 0.000762    |
-----------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 592          |
|    iterations           | 249          |
|    time_elapsed         | 861          |
|    total_timesteps      | 509952       |
| train/                  |              |
|    approx_kl            | 0.0049887197 |
|    clip_fraction        | 0.0451       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.41        |
|    explained_variance   | 0.923        |
|    learning_rate        | 3.3e-05      |
|    loss                 | -0.00303     |
|    n_updates            | 2480         |
|    policy_gradient_loss | -0.00864     |
|    std                  | 0.809        |
|    value_loss           | 0.00433      |
------------------------------------------
Eval num_timesteps=510000, episode_reward=-1.00 +/- 0.00
Episode length: 500.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 500         |
|    mean_reward          | -1          |
| time/                   |             |
|    total_timesteps      | 510000      |
| train/                  |             |
|    approx_kl            | 0.002644965 |
|    clip_fraction        | 0.0064      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.41       |
|    explained_variance   | 0.815       |
|    learning_rate        | 3.31e-05    |
|    loss                 | -0.00928    |
|    n_updates            | 2490        |
|    policy_gradient_loss | -0.00264    |
|    std                  | 0.809       |
|    value_loss           | 0.000584    |
-----------------------------------------
-------------------------------
| time/              |        |
|    fps             | 591    |
|    iterations      | 250    |
|    time_elapsed    | 866    |
|    total_timesteps | 512000 |
-------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 591          |
|    iterations           | 251          |
|    time_elapsed         | 869          |
|    total_timesteps      | 514048       |
| train/                  |              |
|    approx_kl            | 0.0021206792 |
|    clip_fraction        | 0.00317      |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.41        |
|    explained_variance   | 0.774        |
|    learning_rate        | 3.31e-05     |
|    loss                 | 0.000114     |
|    n_updates            | 2500         |
|    policy_gradient_loss | -0.00221     |
|    std                  | 0.809        |
|    value_loss           | 0.000594     |
------------------------------------------
box reached target
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 591          |
|    iterations           | 252          |
|    time_elapsed         | 872          |
|    total_timesteps      | 516096       |
| train/                  |              |
|    approx_kl            | 0.0043036435 |
|    clip_fraction        | 0.0287       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.41        |
|    explained_variance   | 0.907        |
|    learning_rate        | 3.31e-05     |
|    loss                 | -0.00102     |
|    n_updates            | 2510         |
|    policy_gradient_loss | -0.00429     |
|    std                  | 0.809        |
|    value_loss           | 0.00134      |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 591          |
|    iterations           | 253          |
|    time_elapsed         | 875          |
|    total_timesteps      | 518144       |
| train/                  |              |
|    approx_kl            | 0.0011605406 |
|    clip_fraction        | 0.00161      |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.41        |
|    explained_variance   | 0.365        |
|    learning_rate        | 3.31e-05     |
|    loss                 | 0.217        |
|    n_updates            | 2520         |
|    policy_gradient_loss | -0.00169     |
|    std                  | 0.808        |
|    value_loss           | 0.126        |
------------------------------------------
box reached target
box reached target
Eval num_timesteps=520000, episode_reward=0.39 +/- 2.61
Episode length: 438.20 +/- 123.60
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 438          |
|    mean_reward          | 0.392        |
| time/                   |              |
|    total_timesteps      | 520000       |
| train/                  |              |
|    approx_kl            | 0.0013517153 |
|    clip_fraction        | 0.00132      |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.41        |
|    explained_variance   | 0.889        |
|    learning_rate        | 3.31e-05     |
|    loss                 | -0.00274     |
|    n_updates            | 2530         |
|    policy_gradient_loss | -0.00124     |
|    std                  | 0.808        |
|    value_loss           | 0.00291      |
------------------------------------------
-------------------------------
| time/              |        |
|    fps             | 591    |
|    iterations      | 254    |
|    time_elapsed    | 880    |
|    total_timesteps | 520192 |
-------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 591          |
|    iterations           | 255          |
|    time_elapsed         | 883          |
|    total_timesteps      | 522240       |
| train/                  |              |
|    approx_kl            | 0.0041961055 |
|    clip_fraction        | 0.0148       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.41        |
|    explained_variance   | 0.721        |
|    learning_rate        | 3.31e-05     |
|    loss                 | -0.00344     |
|    n_updates            | 2540         |
|    policy_gradient_loss | -0.00189     |
|    std                  | 0.808        |
|    value_loss           | 0.0321       |
------------------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 591         |
|    iterations           | 256         |
|    time_elapsed         | 886         |
|    total_timesteps      | 524288      |
| train/                  |             |
|    approx_kl            | 0.004280619 |
|    clip_fraction        | 0.00957     |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.41       |
|    explained_variance   | 0.717       |
|    learning_rate        | 3.31e-05    |
|    loss                 | -0.00588    |
|    n_updates            | 2550        |
|    policy_gradient_loss | -0.00355    |
|    std                  | 0.808       |
|    value_loss           | 0.00326     |
-----------------------------------------
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 591          |
|    iterations           | 257          |
|    time_elapsed         | 889          |
|    total_timesteps      | 526336       |
| train/                  |              |
|    approx_kl            | 0.0031778757 |
|    clip_fraction        | 0.0165       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.41        |
|    explained_variance   | 0.119        |
|    learning_rate        | 3.31e-05     |
|    loss                 | 0.105        |
|    n_updates            | 2560         |
|    policy_gradient_loss | -0.00583     |
|    std                  | 0.805        |
|    value_loss           | 0.059        |
------------------------------------------
box reached target
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 591          |
|    iterations           | 258          |
|    time_elapsed         | 892          |
|    total_timesteps      | 528384       |
| train/                  |              |
|    approx_kl            | 0.0042796973 |
|    clip_fraction        | 0.0167       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.4         |
|    explained_variance   | 0.363        |
|    learning_rate        | 3.32e-05     |
|    loss                 | 0.0389       |
|    n_updates            | 2570         |
|    policy_gradient_loss | -0.00368     |
|    std                  | 0.804        |
|    value_loss           | 0.0424       |
------------------------------------------
Eval num_timesteps=530000, episode_reward=-1.00 +/- 0.00
Episode length: 500.00 +/- 0.00
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 500          |
|    mean_reward          | -1           |
| time/                   |              |
|    total_timesteps      | 530000       |
| train/                  |              |
|    approx_kl            | 0.0011403653 |
|    clip_fraction        | 0.00176      |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.4         |
|    explained_variance   | 0.222        |
|    learning_rate        | 3.32e-05     |
|    loss                 | 0.0145       |
|    n_updates            | 2580         |
|    policy_gradient_loss | -0.000549    |
|    std                  | 0.803        |
|    value_loss           | 0.127        |
------------------------------------------
-------------------------------
| time/              |        |
|    fps             | 591    |
|    iterations      | 259    |
|    time_elapsed    | 897    |
|    total_timesteps | 530432 |
-------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 591         |
|    iterations           | 260         |
|    time_elapsed         | 900         |
|    total_timesteps      | 532480      |
| train/                  |             |
|    approx_kl            | 0.006302368 |
|    clip_fraction        | 0.0315      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.4        |
|    explained_variance   | 0.913       |
|    learning_rate        | 3.32e-05    |
|    loss                 | 0.0224      |
|    n_updates            | 2590        |
|    policy_gradient_loss | -0.00498    |
|    std                  | 0.803       |
|    value_loss           | 0.00262     |
-----------------------------------------
box reached target
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 591          |
|    iterations           | 261          |
|    time_elapsed         | 903          |
|    total_timesteps      | 534528       |
| train/                  |              |
|    approx_kl            | 0.0034035887 |
|    clip_fraction        | 0.0102       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.4         |
|    explained_variance   | 0.61         |
|    learning_rate        | 3.32e-05     |
|    loss                 | 0.0147       |
|    n_updates            | 2600         |
|    policy_gradient_loss | -0.00146     |
|    std                  | 0.802        |
|    value_loss           | 0.0427       |
------------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 591         |
|    iterations           | 262         |
|    time_elapsed         | 906         |
|    total_timesteps      | 536576      |
| train/                  |             |
|    approx_kl            | 0.004367928 |
|    clip_fraction        | 0.0182      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.39       |
|    explained_variance   | 0.593       |
|    learning_rate        | 3.32e-05    |
|    loss                 | -0.0284     |
|    n_updates            | 2610        |
|    policy_gradient_loss | -0.00355    |
|    std                  | 0.799       |
|    value_loss           | 0.0821      |
-----------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 591          |
|    iterations           | 263          |
|    time_elapsed         | 910          |
|    total_timesteps      | 538624       |
| train/                  |              |
|    approx_kl            | 0.0036118878 |
|    clip_fraction        | 0.0152       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.39        |
|    explained_variance   | 0.869        |
|    learning_rate        | 3.32e-05     |
|    loss                 | -0.00866     |
|    n_updates            | 2620         |
|    policy_gradient_loss | -0.0037      |
|    std                  | 0.799        |
|    value_loss           | 0.00136      |
------------------------------------------
box reached target
box reached target
Eval num_timesteps=540000, episode_reward=1.55 +/- 3.12
Episode length: 363.60 +/- 167.29
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 364          |
|    mean_reward          | 1.55         |
| time/                   |              |
|    total_timesteps      | 540000       |
| train/                  |              |
|    approx_kl            | 0.0041690757 |
|    clip_fraction        | 0.0165       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.39        |
|    explained_variance   | 0.823        |
|    learning_rate        | 3.32e-05     |
|    loss                 | 0.00638      |
|    n_updates            | 2630         |
|    policy_gradient_loss | -0.00417     |
|    std                  | 0.8          |
|    value_loss           | 0.00203      |
------------------------------------------
-------------------------------
| time/              |        |
|    fps             | 591    |
|    iterations      | 264    |
|    time_elapsed    | 914    |
|    total_timesteps | 540672 |
-------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 591         |
|    iterations           | 265         |
|    time_elapsed         | 917         |
|    total_timesteps      | 542720      |
| train/                  |             |
|    approx_kl            | 0.003046537 |
|    clip_fraction        | 0.0147      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.39       |
|    explained_variance   | 0.915       |
|    learning_rate        | 3.32e-05    |
|    loss                 | -0.00747    |
|    n_updates            | 2640        |
|    policy_gradient_loss | -0.0057     |
|    std                  | 0.799       |
|    value_loss           | 0.000718    |
-----------------------------------------
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 591          |
|    iterations           | 266          |
|    time_elapsed         | 920          |
|    total_timesteps      | 544768       |
| train/                  |              |
|    approx_kl            | 0.0052650627 |
|    clip_fraction        | 0.0167       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.39        |
|    explained_variance   | -0.0767      |
|    learning_rate        | 3.33e-05     |
|    loss                 | 0.00394      |
|    n_updates            | 2650         |
|    policy_gradient_loss | -0.00348     |
|    std                  | 0.799        |
|    value_loss           | 0.0814       |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 591          |
|    iterations           | 267          |
|    time_elapsed         | 923          |
|    total_timesteps      | 546816       |
| train/                  |              |
|    approx_kl            | 0.0031094882 |
|    clip_fraction        | 0.00581      |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.39        |
|    explained_variance   | 0.0481       |
|    learning_rate        | 3.33e-05     |
|    loss                 | 0.00319      |
|    n_updates            | 2660         |
|    policy_gradient_loss | -0.00147     |
|    std                  | 0.798        |
|    value_loss           | 0.0508       |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 592          |
|    iterations           | 268          |
|    time_elapsed         | 927          |
|    total_timesteps      | 548864       |
| train/                  |              |
|    approx_kl            | 0.0033030706 |
|    clip_fraction        | 0.00908      |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.38        |
|    explained_variance   | 0.783        |
|    learning_rate        | 3.33e-05     |
|    loss                 | -0.00404     |
|    n_updates            | 2670         |
|    policy_gradient_loss | -0.00229     |
|    std                  | 0.797        |
|    value_loss           | 0.00102      |
------------------------------------------
box reached target
Eval num_timesteps=550000, episode_reward=0.51 +/- 2.50
Episode length: 438.00 +/- 124.00
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 438          |
|    mean_reward          | 0.514        |
| time/                   |              |
|    total_timesteps      | 550000       |
| train/                  |              |
|    approx_kl            | 0.0052197813 |
|    clip_fraction        | 0.0199       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.38        |
|    explained_variance   | 0.9          |
|    learning_rate        | 3.33e-05     |
|    loss                 | 0.00624      |
|    n_updates            | 2680         |
|    policy_gradient_loss | -0.00371     |
|    std                  | 0.797        |
|    value_loss           | 0.00136      |
------------------------------------------
-------------------------------
| time/              |        |
|    fps             | 591    |
|    iterations      | 269    |
|    time_elapsed    | 931    |
|    total_timesteps | 550912 |
-------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 591         |
|    iterations           | 270         |
|    time_elapsed         | 934         |
|    total_timesteps      | 552960      |
| train/                  |             |
|    approx_kl            | 0.005852433 |
|    clip_fraction        | 0.0442      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.38       |
|    explained_variance   | 0.556       |
|    learning_rate        | 3.33e-05    |
|    loss                 | 0.0212      |
|    n_updates            | 2690        |
|    policy_gradient_loss | -0.00502    |
|    std                  | 0.796       |
|    value_loss           | 0.00127     |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 591         |
|    iterations           | 271         |
|    time_elapsed         | 937         |
|    total_timesteps      | 555008      |
| train/                  |             |
|    approx_kl            | 0.003267229 |
|    clip_fraction        | 0.0135      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.38       |
|    explained_variance   | 0.814       |
|    learning_rate        | 3.33e-05    |
|    loss                 | 0.0108      |
|    n_updates            | 2700        |
|    policy_gradient_loss | -0.00276    |
|    std                  | 0.797       |
|    value_loss           | 0.00122     |
-----------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 591          |
|    iterations           | 272          |
|    time_elapsed         | 941          |
|    total_timesteps      | 557056       |
| train/                  |              |
|    approx_kl            | 0.0021785183 |
|    clip_fraction        | 0.00942      |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.38        |
|    explained_variance   | 0.948        |
|    learning_rate        | 3.33e-05     |
|    loss                 | 0.00143      |
|    n_updates            | 2710         |
|    policy_gradient_loss | -0.00267     |
|    std                  | 0.795        |
|    value_loss           | 0.00101      |
------------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 592         |
|    iterations           | 273         |
|    time_elapsed         | 944         |
|    total_timesteps      | 559104      |
| train/                  |             |
|    approx_kl            | 0.005064484 |
|    clip_fraction        | 0.0267      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.38       |
|    explained_variance   | 0.926       |
|    learning_rate        | 3.33e-05    |
|    loss                 | -0.0106     |
|    n_updates            | 2720        |
|    policy_gradient_loss | -0.00379    |
|    std                  | 0.794       |
|    value_loss           | 0.00079     |
-----------------------------------------
Eval num_timesteps=560000, episode_reward=-0.72 +/- 0.57
Episode length: 500.00 +/- 0.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 500        |
|    mean_reward          | -0.717     |
| time/                   |            |
|    total_timesteps      | 560000     |
| train/                  |            |
|    approx_kl            | 0.00560541 |
|    clip_fraction        | 0.0337     |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.37      |
|    explained_variance   | 0.638      |
|    learning_rate        | 3.34e-05   |
|    loss                 | -0.0192    |
|    n_updates            | 2730       |
|    policy_gradient_loss | -0.00568   |
|    std                  | 0.792      |
|    value_loss           | 0.000855   |
----------------------------------------
-------------------------------
| time/              |        |
|    fps             | 591    |
|    iterations      | 274    |
|    time_elapsed    | 949    |
|    total_timesteps | 561152 |
-------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 591          |
|    iterations           | 275          |
|    time_elapsed         | 952          |
|    total_timesteps      | 563200       |
| train/                  |              |
|    approx_kl            | 0.0053147776 |
|    clip_fraction        | 0.0322       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.37        |
|    explained_variance   | 0.855        |
|    learning_rate        | 3.34e-05     |
|    loss                 | -0.000846    |
|    n_updates            | 2740         |
|    policy_gradient_loss | -0.00533     |
|    std                  | 0.791        |
|    value_loss           | 0.00172      |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 591          |
|    iterations           | 276          |
|    time_elapsed         | 955          |
|    total_timesteps      | 565248       |
| train/                  |              |
|    approx_kl            | 0.0028319564 |
|    clip_fraction        | 0.00913      |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.37        |
|    explained_variance   | 0.845        |
|    learning_rate        | 3.34e-05     |
|    loss                 | -0.0161      |
|    n_updates            | 2750         |
|    policy_gradient_loss | -0.00425     |
|    std                  | 0.791        |
|    value_loss           | 0.00145      |
------------------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 591         |
|    iterations           | 277         |
|    time_elapsed         | 958         |
|    total_timesteps      | 567296      |
| train/                  |             |
|    approx_kl            | 0.004394565 |
|    clip_fraction        | 0.0191      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.37       |
|    explained_variance   | 0.875       |
|    learning_rate        | 3.34e-05    |
|    loss                 | 0.0206      |
|    n_updates            | 2760        |
|    policy_gradient_loss | -0.00337    |
|    std                  | 0.791       |
|    value_loss           | 0.00065     |
-----------------------------------------
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 592          |
|    iterations           | 278          |
|    time_elapsed         | 961          |
|    total_timesteps      | 569344       |
| train/                  |              |
|    approx_kl            | 0.0041063055 |
|    clip_fraction        | 0.0119       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.36        |
|    explained_variance   | 0.618        |
|    learning_rate        | 3.34e-05     |
|    loss                 | 0.0663       |
|    n_updates            | 2770         |
|    policy_gradient_loss | -0.00121     |
|    std                  | 0.789        |
|    value_loss           | 0.0348       |
------------------------------------------
box reached target
Eval num_timesteps=570000, episode_reward=-1.00 +/- 0.00
Episode length: 500.00 +/- 0.00
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 500          |
|    mean_reward          | -1           |
| time/                   |              |
|    total_timesteps      | 570000       |
| train/                  |              |
|    approx_kl            | 0.0035752915 |
|    clip_fraction        | 0.0158       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.36        |
|    explained_variance   | 0.653        |
|    learning_rate        | 3.34e-05     |
|    loss                 | 0.0223       |
|    n_updates            | 2780         |
|    policy_gradient_loss | -0.00531     |
|    std                  | 0.787        |
|    value_loss           | 0.0296       |
------------------------------------------
-------------------------------
| time/              |        |
|    fps             | 591    |
|    iterations      | 279    |
|    time_elapsed    | 966    |
|    total_timesteps | 571392 |
-------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 591          |
|    iterations           | 280          |
|    time_elapsed         | 969          |
|    total_timesteps      | 573440       |
| train/                  |              |
|    approx_kl            | 0.0036305233 |
|    clip_fraction        | 0.0175       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.36        |
|    explained_variance   | 0.378        |
|    learning_rate        | 3.34e-05     |
|    loss                 | -0.00171     |
|    n_updates            | 2790         |
|    policy_gradient_loss | -0.00588     |
|    std                  | 0.786        |
|    value_loss           | 0.0316       |
------------------------------------------
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 591          |
|    iterations           | 281          |
|    time_elapsed         | 972          |
|    total_timesteps      | 575488       |
| train/                  |              |
|    approx_kl            | 0.0028416738 |
|    clip_fraction        | 0.00996      |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.35        |
|    explained_variance   | 0.919        |
|    learning_rate        | 3.34e-05     |
|    loss                 | 0.00426      |
|    n_updates            | 2800         |
|    policy_gradient_loss | -0.00175     |
|    std                  | 0.785        |
|    value_loss           | 0.00164      |
------------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 591         |
|    iterations           | 282         |
|    time_elapsed         | 975         |
|    total_timesteps      | 577536      |
| train/                  |             |
|    approx_kl            | 0.004769629 |
|    clip_fraction        | 0.0229      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.35       |
|    explained_variance   | 0.268       |
|    learning_rate        | 3.35e-05    |
|    loss                 | -0.0309     |
|    n_updates            | 2810        |
|    policy_gradient_loss | -0.0035     |
|    std                  | 0.784       |
|    value_loss           | 0.0522      |
-----------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 591          |
|    iterations           | 283          |
|    time_elapsed         | 979          |
|    total_timesteps      | 579584       |
| train/                  |              |
|    approx_kl            | 0.0051378654 |
|    clip_fraction        | 0.0283       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.35        |
|    explained_variance   | 0.74         |
|    learning_rate        | 3.35e-05     |
|    loss                 | 0.000228     |
|    n_updates            | 2820         |
|    policy_gradient_loss | -0.00403     |
|    std                  | 0.783        |
|    value_loss           | 0.00108      |
------------------------------------------
box reached target
box reached target
Eval num_timesteps=580000, episode_reward=1.62 +/- 3.06
Episode length: 376.00 +/- 153.21
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 376          |
|    mean_reward          | 1.62         |
| time/                   |              |
|    total_timesteps      | 580000       |
| train/                  |              |
|    approx_kl            | 0.0015016771 |
|    clip_fraction        | 0.00142      |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.34        |
|    explained_variance   | 0.874        |
|    learning_rate        | 3.35e-05     |
|    loss                 | -0.0103      |
|    n_updates            | 2830         |
|    policy_gradient_loss | -0.000904    |
|    std                  | 0.782        |
|    value_loss           | 0.00309      |
------------------------------------------
New best mean reward!
-------------------------------
| time/              |        |
|    fps             | 591    |
|    iterations      | 284    |
|    time_elapsed    | 983    |
|    total_timesteps | 581632 |
-------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 591          |
|    iterations           | 285          |
|    time_elapsed         | 986          |
|    total_timesteps      | 583680       |
| train/                  |              |
|    approx_kl            | 0.0039427537 |
|    clip_fraction        | 0.0104       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.34        |
|    explained_variance   | 0.918        |
|    learning_rate        | 3.35e-05     |
|    loss                 | -0.00941     |
|    n_updates            | 2840         |
|    policy_gradient_loss | -0.0038      |
|    std                  | 0.781        |
|    value_loss           | 0.00118      |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 591          |
|    iterations           | 286          |
|    time_elapsed         | 989          |
|    total_timesteps      | 585728       |
| train/                  |              |
|    approx_kl            | 0.0043712594 |
|    clip_fraction        | 0.0166       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.34        |
|    explained_variance   | 0.892        |
|    learning_rate        | 3.35e-05     |
|    loss                 | 0.00749      |
|    n_updates            | 2850         |
|    policy_gradient_loss | -0.00366     |
|    std                  | 0.782        |
|    value_loss           | 0.00115      |
------------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 591         |
|    iterations           | 287         |
|    time_elapsed         | 992         |
|    total_timesteps      | 587776      |
| train/                  |             |
|    approx_kl            | 0.005187096 |
|    clip_fraction        | 0.0261      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.34       |
|    explained_variance   | 0.741       |
|    learning_rate        | 3.35e-05    |
|    loss                 | -0.00626    |
|    n_updates            | 2860        |
|    policy_gradient_loss | -0.00488    |
|    std                  | 0.782       |
|    value_loss           | 0.00082     |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 592         |
|    iterations           | 288         |
|    time_elapsed         | 996         |
|    total_timesteps      | 589824      |
| train/                  |             |
|    approx_kl            | 0.006424952 |
|    clip_fraction        | 0.0362      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.34       |
|    explained_variance   | 0.817       |
|    learning_rate        | 3.35e-05    |
|    loss                 | -0.000563   |
|    n_updates            | 2870        |
|    policy_gradient_loss | -0.00574    |
|    std                  | 0.781       |
|    value_loss           | 0.000646    |
-----------------------------------------
Eval num_timesteps=590000, episode_reward=-0.84 +/- 0.33
Episode length: 500.00 +/- 0.00
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 500          |
|    mean_reward          | -0.837       |
| time/                   |              |
|    total_timesteps      | 590000       |
| train/                  |              |
|    approx_kl            | 0.0043778596 |
|    clip_fraction        | 0.0185       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.34        |
|    explained_variance   | 0.918        |
|    learning_rate        | 3.35e-05     |
|    loss                 | 0.0253       |
|    n_updates            | 2880         |
|    policy_gradient_loss | -0.00356     |
|    std                  | 0.783        |
|    value_loss           | 0.000749     |
------------------------------------------
box reached target
box reached target
-------------------------------
| time/              |        |
|    fps             | 591    |
|    iterations      | 289    |
|    time_elapsed    | 1000   |
|    total_timesteps | 591872 |
-------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 591          |
|    iterations           | 290          |
|    time_elapsed         | 1003         |
|    total_timesteps      | 593920       |
| train/                  |              |
|    approx_kl            | 0.0038111354 |
|    clip_fraction        | 0.0132       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.34        |
|    explained_variance   | 0.621        |
|    learning_rate        | 3.36e-05     |
|    loss                 | 0.105        |
|    n_updates            | 2890         |
|    policy_gradient_loss | -0.00231     |
|    std                  | 0.782        |
|    value_loss           | 0.0756       |
------------------------------------------
box reached target
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 591          |
|    iterations           | 291          |
|    time_elapsed         | 1007         |
|    total_timesteps      | 595968       |
| train/                  |              |
|    approx_kl            | 0.0014563801 |
|    clip_fraction        | 0.00366      |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.34        |
|    explained_variance   | 0.888        |
|    learning_rate        | 3.36e-05     |
|    loss                 | -0.00894     |
|    n_updates            | 2900         |
|    policy_gradient_loss | -0.000773    |
|    std                  | 0.781        |
|    value_loss           | 0.00195      |
------------------------------------------
box reached target
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 591         |
|    iterations           | 292         |
|    time_elapsed         | 1010        |
|    total_timesteps      | 598016      |
| train/                  |             |
|    approx_kl            | 0.002248698 |
|    clip_fraction        | 0.00488     |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.34       |
|    explained_variance   | 0.611       |
|    learning_rate        | 3.36e-05    |
|    loss                 | -0.00392    |
|    n_updates            | 2910        |
|    policy_gradient_loss | -0.00251    |
|    std                  | 0.778       |
|    value_loss           | 0.0986      |
-----------------------------------------
box reached target
Eval num_timesteps=600000, episode_reward=0.27 +/- 2.54
Episode length: 432.60 +/- 134.80
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 433          |
|    mean_reward          | 0.268        |
| time/                   |              |
|    total_timesteps      | 600000       |
| train/                  |              |
|    approx_kl            | 0.0018797929 |
|    clip_fraction        | 0.0022       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.33        |
|    explained_variance   | 0.43         |
|    learning_rate        | 3.36e-05     |
|    loss                 | 0.00121      |
|    n_updates            | 2920         |
|    policy_gradient_loss | -0.00101     |
|    std                  | 0.776        |
|    value_loss           | 0.091        |
------------------------------------------
-------------------------------
| time/              |        |
|    fps             | 591    |
|    iterations      | 293    |
|    time_elapsed    | 1014   |
|    total_timesteps | 600064 |
-------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 591          |
|    iterations           | 294          |
|    time_elapsed         | 1018         |
|    total_timesteps      | 602112       |
| train/                  |              |
|    approx_kl            | 0.0041707973 |
|    clip_fraction        | 0.0289       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.33        |
|    explained_variance   | 0.917        |
|    learning_rate        | 3.36e-05     |
|    loss                 | 0.00458      |
|    n_updates            | 2930         |
|    policy_gradient_loss | -0.00546     |
|    std                  | 0.777        |
|    value_loss           | 0.00211      |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 591          |
|    iterations           | 295          |
|    time_elapsed         | 1021         |
|    total_timesteps      | 604160       |
| train/                  |              |
|    approx_kl            | 0.0026963425 |
|    clip_fraction        | 0.00728      |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.33        |
|    explained_variance   | 0.767        |
|    learning_rate        | 3.36e-05     |
|    loss                 | 0.0183       |
|    n_updates            | 2940         |
|    policy_gradient_loss | -0.00137     |
|    std                  | 0.776        |
|    value_loss           | 0.0052       |
------------------------------------------
----------------------------------------
| time/                   |            |
|    fps                  | 591        |
|    iterations           | 296        |
|    time_elapsed         | 1024       |
|    total_timesteps      | 606208     |
| train/                  |            |
|    approx_kl            | 0.00493671 |
|    clip_fraction        | 0.0296     |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.33      |
|    explained_variance   | 0.946      |
|    learning_rate        | 3.36e-05   |
|    loss                 | 0.0231     |
|    n_updates            | 2950       |
|    policy_gradient_loss | -0.00453   |
|    std                  | 0.776      |
|    value_loss           | 0.00281    |
----------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 591          |
|    iterations           | 297          |
|    time_elapsed         | 1027         |
|    total_timesteps      | 608256       |
| train/                  |              |
|    approx_kl            | 0.0035250909 |
|    clip_fraction        | 0.0131       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.33        |
|    explained_variance   | 0.887        |
|    learning_rate        | 3.36e-05     |
|    loss                 | 0.00905      |
|    n_updates            | 2960         |
|    policy_gradient_loss | -0.00377     |
|    std                  | 0.777        |
|    value_loss           | 0.00744      |
------------------------------------------
box reached target
Eval num_timesteps=610000, episode_reward=0.59 +/- 2.62
Episode length: 445.80 +/- 108.40
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 446          |
|    mean_reward          | 0.593        |
| time/                   |              |
|    total_timesteps      | 610000       |
| train/                  |              |
|    approx_kl            | 0.0032082777 |
|    clip_fraction        | 0.00615      |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.33        |
|    explained_variance   | 0.863        |
|    learning_rate        | 3.36e-05     |
|    loss                 | 0.00106      |
|    n_updates            | 2970         |
|    policy_gradient_loss | -0.00267     |
|    std                  | 0.776        |
|    value_loss           | 0.000567     |
------------------------------------------
-------------------------------
| time/              |        |
|    fps             | 591    |
|    iterations      | 298    |
|    time_elapsed    | 1032   |
|    total_timesteps | 610304 |
-------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 591         |
|    iterations           | 299         |
|    time_elapsed         | 1035        |
|    total_timesteps      | 612352      |
| train/                  |             |
|    approx_kl            | 0.003610596 |
|    clip_fraction        | 0.0128      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.33       |
|    explained_variance   | 0.902       |
|    learning_rate        | 3.37e-05    |
|    loss                 | -0.0348     |
|    n_updates            | 2980        |
|    policy_gradient_loss | -0.00384    |
|    std                  | 0.777       |
|    value_loss           | 0.000685    |
-----------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 591          |
|    iterations           | 300          |
|    time_elapsed         | 1038         |
|    total_timesteps      | 614400       |
| train/                  |              |
|    approx_kl            | 0.0025299308 |
|    clip_fraction        | 0.00679      |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.33        |
|    explained_variance   | 0.805        |
|    learning_rate        | 3.37e-05     |
|    loss                 | 0.00295      |
|    n_updates            | 2990         |
|    policy_gradient_loss | -0.00175     |
|    std                  | 0.775        |
|    value_loss           | 0.02         |
------------------------------------------
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 591          |
|    iterations           | 301          |
|    time_elapsed         | 1041         |
|    total_timesteps      | 616448       |
| train/                  |              |
|    approx_kl            | 0.0027159585 |
|    clip_fraction        | 0.00454      |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.33        |
|    explained_variance   | 0.921        |
|    learning_rate        | 3.37e-05     |
|    loss                 | -0.00122     |
|    n_updates            | 3000         |
|    policy_gradient_loss | -0.00197     |
|    std                  | 0.775        |
|    value_loss           | 0.000688     |
------------------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 592         |
|    iterations           | 302         |
|    time_elapsed         | 1044        |
|    total_timesteps      | 618496      |
| train/                  |             |
|    approx_kl            | 0.003870827 |
|    clip_fraction        | 0.0229      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.32       |
|    explained_variance   | 0.365       |
|    learning_rate        | 3.37e-05    |
|    loss                 | -0.00849    |
|    n_updates            | 3010        |
|    policy_gradient_loss | -0.00198    |
|    std                  | 0.772       |
|    value_loss           | 0.0537      |
-----------------------------------------
box reached target
box reached target
box reached target
box reached target
Eval num_timesteps=620000, episode_reward=1.80 +/- 3.06
Episode length: 379.40 +/- 150.36
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 379          |
|    mean_reward          | 1.8          |
| time/                   |              |
|    total_timesteps      | 620000       |
| train/                  |              |
|    approx_kl            | 0.0037654466 |
|    clip_fraction        | 0.0186       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.32        |
|    explained_variance   | 0.47         |
|    learning_rate        | 3.37e-05     |
|    loss                 | 0.031        |
|    n_updates            | 3020         |
|    policy_gradient_loss | -0.00335     |
|    std                  | 0.773        |
|    value_loss           | 0.0584       |
------------------------------------------
New best mean reward!
-------------------------------
| time/              |        |
|    fps             | 591    |
|    iterations      | 303    |
|    time_elapsed    | 1049   |
|    total_timesteps | 620544 |
-------------------------------
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 591          |
|    iterations           | 304          |
|    time_elapsed         | 1052         |
|    total_timesteps      | 622592       |
| train/                  |              |
|    approx_kl            | 0.0035438635 |
|    clip_fraction        | 0.0125       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.32        |
|    explained_variance   | 0.835        |
|    learning_rate        | 3.37e-05     |
|    loss                 | 0.0617       |
|    n_updates            | 3030         |
|    policy_gradient_loss | -0.00205     |
|    std                  | 0.771        |
|    value_loss           | 0.0413       |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 591          |
|    iterations           | 305          |
|    time_elapsed         | 1055         |
|    total_timesteps      | 624640       |
| train/                  |              |
|    approx_kl            | 0.0018670214 |
|    clip_fraction        | 0.00151      |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.31        |
|    explained_variance   | 0.756        |
|    learning_rate        | 3.37e-05     |
|    loss                 | 0.0549       |
|    n_updates            | 3040         |
|    policy_gradient_loss | -0.000876    |
|    std                  | 0.769        |
|    value_loss           | 0.0452       |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 592          |
|    iterations           | 306          |
|    time_elapsed         | 1058         |
|    total_timesteps      | 626688       |
| train/                  |              |
|    approx_kl            | 0.0023591626 |
|    clip_fraction        | 0.0042       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.31        |
|    explained_variance   | 0.876        |
|    learning_rate        | 3.37e-05     |
|    loss                 | -0.0145      |
|    n_updates            | 3050         |
|    policy_gradient_loss | -0.00174     |
|    std                  | 0.77         |
|    value_loss           | 0.00331      |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 592          |
|    iterations           | 307          |
|    time_elapsed         | 1061         |
|    total_timesteps      | 628736       |
| train/                  |              |
|    approx_kl            | 0.0046905577 |
|    clip_fraction        | 0.0258       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.31        |
|    explained_variance   | 0.95         |
|    learning_rate        | 3.38e-05     |
|    loss                 | 0.00142      |
|    n_updates            | 3060         |
|    policy_gradient_loss | -0.00402     |
|    std                  | 0.771        |
|    value_loss           | 0.00245      |
------------------------------------------
Eval num_timesteps=630000, episode_reward=-0.75 +/- 0.50
Episode length: 500.00 +/- 0.00
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 500          |
|    mean_reward          | -0.752       |
| time/                   |              |
|    total_timesteps      | 630000       |
| train/                  |              |
|    approx_kl            | 0.0032837247 |
|    clip_fraction        | 0.0102       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.31        |
|    explained_variance   | 0.942        |
|    learning_rate        | 3.38e-05     |
|    loss                 | 0.0029       |
|    n_updates            | 3070         |
|    policy_gradient_loss | -0.00168     |
|    std                  | 0.771        |
|    value_loss           | 0.0043       |
------------------------------------------
-------------------------------
| time/              |        |
|    fps             | 591    |
|    iterations      | 308    |
|    time_elapsed    | 1066   |
|    total_timesteps | 630784 |
-------------------------------
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 591          |
|    iterations           | 309          |
|    time_elapsed         | 1069         |
|    total_timesteps      | 632832       |
| train/                  |              |
|    approx_kl            | 0.0046588806 |
|    clip_fraction        | 0.0172       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.32        |
|    explained_variance   | 0.86         |
|    learning_rate        | 3.38e-05     |
|    loss                 | -0.00303     |
|    n_updates            | 3080         |
|    policy_gradient_loss | -0.00306     |
|    std                  | 0.772        |
|    value_loss           | 0.00146      |
------------------------------------------
box reached target
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 591         |
|    iterations           | 310         |
|    time_elapsed         | 1072        |
|    total_timesteps      | 634880      |
| train/                  |             |
|    approx_kl            | 0.003914907 |
|    clip_fraction        | 0.0166      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.31       |
|    explained_variance   | 0.842       |
|    learning_rate        | 3.38e-05    |
|    loss                 | 0.00221     |
|    n_updates            | 3090        |
|    policy_gradient_loss | -0.00319    |
|    std                  | 0.77        |
|    value_loss           | 0.0369      |
-----------------------------------------
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 591          |
|    iterations           | 311          |
|    time_elapsed         | 1076         |
|    total_timesteps      | 636928       |
| train/                  |              |
|    approx_kl            | 0.0015089151 |
|    clip_fraction        | 0.0022       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.31        |
|    explained_variance   | 0.725        |
|    learning_rate        | 3.38e-05     |
|    loss                 | 0.002        |
|    n_updates            | 3100         |
|    policy_gradient_loss | -0.00087     |
|    std                  | 0.768        |
|    value_loss           | 0.0933       |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 592          |
|    iterations           | 312          |
|    time_elapsed         | 1079         |
|    total_timesteps      | 638976       |
| train/                  |              |
|    approx_kl            | 0.0041858684 |
|    clip_fraction        | 0.0173       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.31        |
|    explained_variance   | 0.891        |
|    learning_rate        | 3.38e-05     |
|    loss                 | -0.00347     |
|    n_updates            | 3110         |
|    policy_gradient_loss | -0.00476     |
|    std                  | 0.767        |
|    value_loss           | 0.0087       |
------------------------------------------
box reached target
box reached target
Eval num_timesteps=640000, episode_reward=0.38 +/- 2.75
Episode length: 451.20 +/- 97.60
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 451         |
|    mean_reward          | 0.375       |
| time/                   |             |
|    total_timesteps      | 640000      |
| train/                  |             |
|    approx_kl            | 0.003971269 |
|    clip_fraction        | 0.0272      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.31       |
|    explained_variance   | 0.861       |
|    learning_rate        | 3.38e-05    |
|    loss                 | 0.00708     |
|    n_updates            | 3120        |
|    policy_gradient_loss | -0.00413    |
|    std                  | 0.767       |
|    value_loss           | 0.00266     |
-----------------------------------------
box reached target
-------------------------------
| time/              |        |
|    fps             | 591    |
|    iterations      | 313    |
|    time_elapsed    | 1083   |
|    total_timesteps | 641024 |
-------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 591          |
|    iterations           | 314          |
|    time_elapsed         | 1086         |
|    total_timesteps      | 643072       |
| train/                  |              |
|    approx_kl            | 0.0054534297 |
|    clip_fraction        | 0.0286       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.31        |
|    explained_variance   | 0.624        |
|    learning_rate        | 3.38e-05     |
|    loss                 | 0.0367       |
|    n_updates            | 3130         |
|    policy_gradient_loss | -0.0027      |
|    std                  | 0.767        |
|    value_loss           | 0.0844       |
------------------------------------------
box reached target
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 591          |
|    iterations           | 315          |
|    time_elapsed         | 1090         |
|    total_timesteps      | 645120       |
| train/                  |              |
|    approx_kl            | 0.0042629465 |
|    clip_fraction        | 0.0143       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.3         |
|    explained_variance   | 0.873        |
|    learning_rate        | 3.39e-05     |
|    loss                 | 0.00165      |
|    n_updates            | 3140         |
|    policy_gradient_loss | -0.0027      |
|    std                  | 0.765        |
|    value_loss           | 0.00317      |
------------------------------------------
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 591          |
|    iterations           | 316          |
|    time_elapsed         | 1093         |
|    total_timesteps      | 647168       |
| train/                  |              |
|    approx_kl            | 0.0025900307 |
|    clip_fraction        | 0.00591      |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.3         |
|    explained_variance   | 0.495        |
|    learning_rate        | 3.39e-05     |
|    loss                 | 0.0346       |
|    n_updates            | 3150         |
|    policy_gradient_loss | -0.00128     |
|    std                  | 0.765        |
|    value_loss           | 0.109        |
------------------------------------------
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 592          |
|    iterations           | 317          |
|    time_elapsed         | 1096         |
|    total_timesteps      | 649216       |
| train/                  |              |
|    approx_kl            | 0.0045942264 |
|    clip_fraction        | 0.0146       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.3         |
|    explained_variance   | 0.822        |
|    learning_rate        | 3.39e-05     |
|    loss                 | 0.0275       |
|    n_updates            | 3160         |
|    policy_gradient_loss | -0.00247     |
|    std                  | 0.763        |
|    value_loss           | 0.0242       |
------------------------------------------
box reached target
box reached target
Eval num_timesteps=650000, episode_reward=1.84 +/- 2.93
Episode length: 369.20 +/- 161.04
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 369          |
|    mean_reward          | 1.84         |
| time/                   |              |
|    total_timesteps      | 650000       |
| train/                  |              |
|    approx_kl            | 0.0018801434 |
|    clip_fraction        | 0.00308      |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.29        |
|    explained_variance   | 0.811        |
|    learning_rate        | 3.39e-05     |
|    loss                 | 0.0525       |
|    n_updates            | 3170         |
|    policy_gradient_loss | -0.00206     |
|    std                  | 0.762        |
|    value_loss           | 0.0319       |
------------------------------------------
New best mean reward!
box reached target
-------------------------------
| time/              |        |
|    fps             | 591    |
|    iterations      | 318    |
|    time_elapsed    | 1100   |
|    total_timesteps | 651264 |
-------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 591         |
|    iterations           | 319         |
|    time_elapsed         | 1103        |
|    total_timesteps      | 653312      |
| train/                  |             |
|    approx_kl            | 0.002073426 |
|    clip_fraction        | 0.002       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.29       |
|    explained_variance   | 0.944       |
|    learning_rate        | 3.39e-05    |
|    loss                 | -0.00357    |
|    n_updates            | 3180        |
|    policy_gradient_loss | -0.00184    |
|    std                  | 0.762       |
|    value_loss           | 0.0112      |
-----------------------------------------
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 591          |
|    iterations           | 320          |
|    time_elapsed         | 1107         |
|    total_timesteps      | 655360       |
| train/                  |              |
|    approx_kl            | 0.0040462543 |
|    clip_fraction        | 0.0268       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.29        |
|    explained_variance   | 0.883        |
|    learning_rate        | 3.39e-05     |
|    loss                 | 0.0164       |
|    n_updates            | 3190         |
|    policy_gradient_loss | -0.00367     |
|    std                  | 0.763        |
|    value_loss           | 0.000734     |
------------------------------------------
box reached target
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 592          |
|    iterations           | 321          |
|    time_elapsed         | 1110         |
|    total_timesteps      | 657408       |
| train/                  |              |
|    approx_kl            | 0.0032407849 |
|    clip_fraction        | 0.00972      |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.29        |
|    explained_variance   | 0.866        |
|    learning_rate        | 3.39e-05     |
|    loss                 | 0.000602     |
|    n_updates            | 3200         |
|    policy_gradient_loss | -0.00249     |
|    std                  | 0.761        |
|    value_loss           | 0.0287       |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 592          |
|    iterations           | 322          |
|    time_elapsed         | 1113         |
|    total_timesteps      | 659456       |
| train/                  |              |
|    approx_kl            | 0.0030128593 |
|    clip_fraction        | 0.0125       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.29        |
|    explained_variance   | 0.955        |
|    learning_rate        | 3.39e-05     |
|    loss                 | 0.0133       |
|    n_updates            | 3210         |
|    policy_gradient_loss | -0.00288     |
|    std                  | 0.759        |
|    value_loss           | 0.0161       |
------------------------------------------
Eval num_timesteps=660000, episode_reward=-0.85 +/- 0.30
Episode length: 500.00 +/- 0.00
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 500          |
|    mean_reward          | -0.85        |
| time/                   |              |
|    total_timesteps      | 660000       |
| train/                  |              |
|    approx_kl            | 0.0033497845 |
|    clip_fraction        | 0.0144       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.28        |
|    explained_variance   | 0.914        |
|    learning_rate        | 3.4e-05      |
|    loss                 | -0.00649     |
|    n_updates            | 3220         |
|    policy_gradient_loss | -0.0028      |
|    std                  | 0.759        |
|    value_loss           | 0.0019       |
------------------------------------------
-------------------------------
| time/              |        |
|    fps             | 591    |
|    iterations      | 323    |
|    time_elapsed    | 1118   |
|    total_timesteps | 661504 |
-------------------------------
box reached target
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 591         |
|    iterations           | 324         |
|    time_elapsed         | 1121        |
|    total_timesteps      | 663552      |
| train/                  |             |
|    approx_kl            | 0.004194351 |
|    clip_fraction        | 0.0181      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.28       |
|    explained_variance   | 0.9         |
|    learning_rate        | 3.4e-05     |
|    loss                 | 0.0183      |
|    n_updates            | 3230        |
|    policy_gradient_loss | -0.00366    |
|    std                  | 0.759       |
|    value_loss           | 0.00165     |
-----------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 591          |
|    iterations           | 325          |
|    time_elapsed         | 1124         |
|    total_timesteps      | 665600       |
| train/                  |              |
|    approx_kl            | 0.0041717123 |
|    clip_fraction        | 0.0142       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.28        |
|    explained_variance   | 0.843        |
|    learning_rate        | 3.4e-05      |
|    loss                 | 0.0215       |
|    n_updates            | 3240         |
|    policy_gradient_loss | -0.00229     |
|    std                  | 0.757        |
|    value_loss           | 0.0411       |
------------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 592         |
|    iterations           | 326         |
|    time_elapsed         | 1127        |
|    total_timesteps      | 667648      |
| train/                  |             |
|    approx_kl            | 0.005235563 |
|    clip_fraction        | 0.0372      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.28       |
|    explained_variance   | 0.804       |
|    learning_rate        | 3.4e-05     |
|    loss                 | 0.00901     |
|    n_updates            | 3250        |
|    policy_gradient_loss | -0.00497    |
|    std                  | 0.758       |
|    value_loss           | 0.00407     |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 592         |
|    iterations           | 327         |
|    time_elapsed         | 1130        |
|    total_timesteps      | 669696      |
| train/                  |             |
|    approx_kl            | 0.004589288 |
|    clip_fraction        | 0.0382      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.28       |
|    explained_variance   | 0.864       |
|    learning_rate        | 3.4e-05     |
|    loss                 | -0.00159    |
|    n_updates            | 3260        |
|    policy_gradient_loss | -0.00513    |
|    std                  | 0.758       |
|    value_loss           | 0.000871    |
-----------------------------------------
Eval num_timesteps=670000, episode_reward=-0.53 +/- 0.58
Episode length: 500.00 +/- 0.00
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 500          |
|    mean_reward          | -0.529       |
| time/                   |              |
|    total_timesteps      | 670000       |
| train/                  |              |
|    approx_kl            | 0.0052795527 |
|    clip_fraction        | 0.0396       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.28        |
|    explained_variance   | 0.89         |
|    learning_rate        | 3.4e-05      |
|    loss                 | 0.0204       |
|    n_updates            | 3270         |
|    policy_gradient_loss | -0.00572     |
|    std                  | 0.758        |
|    value_loss           | 0.000638     |
------------------------------------------
-------------------------------
| time/              |        |
|    fps             | 591    |
|    iterations      | 328    |
|    time_elapsed    | 1135   |
|    total_timesteps | 671744 |
-------------------------------
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 591          |
|    iterations           | 329          |
|    time_elapsed         | 1138         |
|    total_timesteps      | 673792       |
| train/                  |              |
|    approx_kl            | 0.0046599824 |
|    clip_fraction        | 0.0222       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.28        |
|    explained_variance   | 0.889        |
|    learning_rate        | 3.4e-05      |
|    loss                 | -0.022       |
|    n_updates            | 3280         |
|    policy_gradient_loss | -0.00341     |
|    std                  | 0.757        |
|    value_loss           | 0.00106      |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 591          |
|    iterations           | 330          |
|    time_elapsed         | 1141         |
|    total_timesteps      | 675840       |
| train/                  |              |
|    approx_kl            | 0.0025335725 |
|    clip_fraction        | 0.00767      |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.28        |
|    explained_variance   | 0.836        |
|    learning_rate        | 3.4e-05      |
|    loss                 | -0.0035      |
|    n_updates            | 3290         |
|    policy_gradient_loss | -0.00226     |
|    std                  | 0.755        |
|    value_loss           | 0.0342       |
------------------------------------------
box reached target
box reached target
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 591          |
|    iterations           | 331          |
|    time_elapsed         | 1145         |
|    total_timesteps      | 677888       |
| train/                  |              |
|    approx_kl            | 0.0042009917 |
|    clip_fraction        | 0.0242       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.27        |
|    explained_variance   | 0.886        |
|    learning_rate        | 3.41e-05     |
|    loss                 | 0.00764      |
|    n_updates            | 3300         |
|    policy_gradient_loss | -0.00469     |
|    std                  | 0.756        |
|    value_loss           | 0.000697     |
------------------------------------------
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 592          |
|    iterations           | 332          |
|    time_elapsed         | 1148         |
|    total_timesteps      | 679936       |
| train/                  |              |
|    approx_kl            | 0.0024999462 |
|    clip_fraction        | 0.00562      |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.27        |
|    explained_variance   | 0.786        |
|    learning_rate        | 3.41e-05     |
|    loss                 | 0.0234       |
|    n_updates            | 3310         |
|    policy_gradient_loss | -0.0026      |
|    std                  | 0.754        |
|    value_loss           | 0.0859       |
------------------------------------------
box reached target
box reached target
Eval num_timesteps=680000, episode_reward=1.90 +/- 3.00
Episode length: 379.80 +/- 147.54
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 380          |
|    mean_reward          | 1.9          |
| time/                   |              |
|    total_timesteps      | 680000       |
| train/                  |              |
|    approx_kl            | 0.0022900836 |
|    clip_fraction        | 0.00366      |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.27        |
|    explained_variance   | 0.954        |
|    learning_rate        | 3.41e-05     |
|    loss                 | -0.00263     |
|    n_updates            | 3320         |
|    policy_gradient_loss | -0.00212     |
|    std                  | 0.751        |
|    value_loss           | 0.0164       |
------------------------------------------
New best mean reward!
box reached target
-------------------------------
| time/              |        |
|    fps             | 591    |
|    iterations      | 333    |
|    time_elapsed    | 1152   |
|    total_timesteps | 681984 |
-------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 591         |
|    iterations           | 334         |
|    time_elapsed         | 1155        |
|    total_timesteps      | 684032      |
| train/                  |             |
|    approx_kl            | 0.003818524 |
|    clip_fraction        | 0.0119      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.26       |
|    explained_variance   | 0.938       |
|    learning_rate        | 3.41e-05    |
|    loss                 | -0.000878   |
|    n_updates            | 3330        |
|    policy_gradient_loss | -0.00236    |
|    std                  | 0.748       |
|    value_loss           | 0.0106      |
-----------------------------------------
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 591          |
|    iterations           | 335          |
|    time_elapsed         | 1159         |
|    total_timesteps      | 686080       |
| train/                  |              |
|    approx_kl            | 0.0023881202 |
|    clip_fraction        | 0.00732      |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.25        |
|    explained_variance   | 0.929        |
|    learning_rate        | 3.41e-05     |
|    loss                 | 0.00953      |
|    n_updates            | 3340         |
|    policy_gradient_loss | -0.00233     |
|    std                  | 0.745        |
|    value_loss           | 0.00117      |
------------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 592         |
|    iterations           | 336         |
|    time_elapsed         | 1162        |
|    total_timesteps      | 688128      |
| train/                  |             |
|    approx_kl            | 0.004109279 |
|    clip_fraction        | 0.0105      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.24       |
|    explained_variance   | 0.845       |
|    learning_rate        | 3.41e-05    |
|    loss                 | 0.00973     |
|    n_updates            | 3350        |
|    policy_gradient_loss | -0.00231    |
|    std                  | 0.744       |
|    value_loss           | 0.0193      |
-----------------------------------------
box reached target
box reached target
box reached target
box reached target
box reached target
Eval num_timesteps=690000, episode_reward=1.92 +/- 3.00
Episode length: 368.60 +/- 161.19
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 369          |
|    mean_reward          | 1.92         |
| time/                   |              |
|    total_timesteps      | 690000       |
| train/                  |              |
|    approx_kl            | 0.0049896003 |
|    clip_fraction        | 0.03         |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.24        |
|    explained_variance   | 0.904        |
|    learning_rate        | 3.41e-05     |
|    loss                 | -0.000422    |
|    n_updates            | 3360         |
|    policy_gradient_loss | -0.00492     |
|    std                  | 0.744        |
|    value_loss           | 0.00475      |
------------------------------------------
New best mean reward!
-------------------------------
| time/              |        |
|    fps             | 591    |
|    iterations      | 337    |
|    time_elapsed    | 1166   |
|    total_timesteps | 690176 |
-------------------------------
box reached target
box reached target
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 591          |
|    iterations           | 338          |
|    time_elapsed         | 1169         |
|    total_timesteps      | 692224       |
| train/                  |              |
|    approx_kl            | 0.0054263114 |
|    clip_fraction        | 0.0201       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.24        |
|    explained_variance   | 0.529        |
|    learning_rate        | 3.41e-05     |
|    loss                 | 0.185        |
|    n_updates            | 3370         |
|    policy_gradient_loss | -0.00222     |
|    std                  | 0.742        |
|    value_loss           | 0.136        |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 591          |
|    iterations           | 339          |
|    time_elapsed         | 1172         |
|    total_timesteps      | 694272       |
| train/                  |              |
|    approx_kl            | 0.0018348988 |
|    clip_fraction        | 0.00142      |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.23        |
|    explained_variance   | 0.859        |
|    learning_rate        | 3.42e-05     |
|    loss                 | -0.00607     |
|    n_updates            | 3380         |
|    policy_gradient_loss | -0.00134     |
|    std                  | 0.739        |
|    value_loss           | 0.0638       |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 592          |
|    iterations           | 340          |
|    time_elapsed         | 1175         |
|    total_timesteps      | 696320       |
| train/                  |              |
|    approx_kl            | 0.0045849383 |
|    clip_fraction        | 0.0228       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.23        |
|    explained_variance   | 0.921        |
|    learning_rate        | 3.42e-05     |
|    loss                 | 0.00202      |
|    n_updates            | 3390         |
|    policy_gradient_loss | -0.00338     |
|    std                  | 0.738        |
|    value_loss           | 0.00223      |
------------------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 592         |
|    iterations           | 341         |
|    time_elapsed         | 1179        |
|    total_timesteps      | 698368      |
| train/                  |             |
|    approx_kl            | 0.004914427 |
|    clip_fraction        | 0.0322      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.23       |
|    explained_variance   | 0.857       |
|    learning_rate        | 3.42e-05    |
|    loss                 | -0.00323    |
|    n_updates            | 3400        |
|    policy_gradient_loss | -0.00354    |
|    std                  | 0.738       |
|    value_loss           | 0.00952     |
-----------------------------------------
Eval num_timesteps=700000, episode_reward=-0.70 +/- 0.61
Episode length: 500.00 +/- 0.00
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 500          |
|    mean_reward          | -0.696       |
| time/                   |              |
|    total_timesteps      | 700000       |
| train/                  |              |
|    approx_kl            | 0.0039239144 |
|    clip_fraction        | 0.014        |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.22        |
|    explained_variance   | 0.385        |
|    learning_rate        | 3.42e-05     |
|    loss                 | 0.000116     |
|    n_updates            | 3410         |
|    policy_gradient_loss | -0.0035      |
|    std                  | 0.736        |
|    value_loss           | 0.0401       |
------------------------------------------
box reached target
-------------------------------
| time/              |        |
|    fps             | 591    |
|    iterations      | 342    |
|    time_elapsed    | 1183   |
|    total_timesteps | 700416 |
-------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 591         |
|    iterations           | 343         |
|    time_elapsed         | 1187        |
|    total_timesteps      | 702464      |
| train/                  |             |
|    approx_kl            | 0.002359619 |
|    clip_fraction        | 0.00166     |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.22       |
|    explained_variance   | 0.547       |
|    learning_rate        | 3.42e-05    |
|    loss                 | 0.0163      |
|    n_updates            | 3420        |
|    policy_gradient_loss | -0.000938   |
|    std                  | 0.736       |
|    value_loss           | 0.0418      |
-----------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 591          |
|    iterations           | 344          |
|    time_elapsed         | 1190         |
|    total_timesteps      | 704512       |
| train/                  |              |
|    approx_kl            | 0.0049138647 |
|    clip_fraction        | 0.0188       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.22        |
|    explained_variance   | 0.824        |
|    learning_rate        | 3.42e-05     |
|    loss                 | -0.00345     |
|    n_updates            | 3430         |
|    policy_gradient_loss | -0.00275     |
|    std                  | 0.737        |
|    value_loss           | 0.00098      |
------------------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 592         |
|    iterations           | 345         |
|    time_elapsed         | 1193        |
|    total_timesteps      | 706560      |
| train/                  |             |
|    approx_kl            | 0.003144371 |
|    clip_fraction        | 0.00972     |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.22       |
|    explained_variance   | 0.93        |
|    learning_rate        | 3.42e-05    |
|    loss                 | -0.00418    |
|    n_updates            | 3440        |
|    policy_gradient_loss | -0.00236    |
|    std                  | 0.736       |
|    value_loss           | 0.0038      |
-----------------------------------------
box reached target
box reached target
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 592          |
|    iterations           | 346          |
|    time_elapsed         | 1196         |
|    total_timesteps      | 708608       |
| train/                  |              |
|    approx_kl            | 0.0029465347 |
|    clip_fraction        | 0.00732      |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.22        |
|    explained_variance   | 0.612        |
|    learning_rate        | 3.42e-05     |
|    loss                 | 0.0157       |
|    n_updates            | 3450         |
|    policy_gradient_loss | -0.00109     |
|    std                  | 0.734        |
|    value_loss           | 0.0371       |
------------------------------------------
box reached target
Eval num_timesteps=710000, episode_reward=-1.00 +/- 0.00
Episode length: 500.00 +/- 0.00
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 500          |
|    mean_reward          | -1           |
| time/                   |              |
|    total_timesteps      | 710000       |
| train/                  |              |
|    approx_kl            | 0.0029512392 |
|    clip_fraction        | 0.00918      |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.22        |
|    explained_variance   | 0.821        |
|    learning_rate        | 3.43e-05     |
|    loss                 | -0.0147      |
|    n_updates            | 3460         |
|    policy_gradient_loss | -0.00306     |
|    std                  | 0.734        |
|    value_loss           | 0.0652       |
------------------------------------------
-------------------------------
| time/              |        |
|    fps             | 591    |
|    iterations      | 347    |
|    time_elapsed    | 1201   |
|    total_timesteps | 710656 |
-------------------------------
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 591          |
|    iterations           | 348          |
|    time_elapsed         | 1204         |
|    total_timesteps      | 712704       |
| train/                  |              |
|    approx_kl            | 0.0033134907 |
|    clip_fraction        | 0.00859      |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.22        |
|    explained_variance   | 0.897        |
|    learning_rate        | 3.43e-05     |
|    loss                 | 0.0337       |
|    n_updates            | 3470         |
|    policy_gradient_loss | -0.00132     |
|    std                  | 0.734        |
|    value_loss           | 0.0254       |
------------------------------------------
box reached target
box reached target
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 591         |
|    iterations           | 349         |
|    time_elapsed         | 1207        |
|    total_timesteps      | 714752      |
| train/                  |             |
|    approx_kl            | 0.002012793 |
|    clip_fraction        | 0.00269     |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.21       |
|    explained_variance   | 0.594       |
|    learning_rate        | 3.43e-05    |
|    loss                 | 0.021       |
|    n_updates            | 3480        |
|    policy_gradient_loss | -0.00147    |
|    std                  | 0.731       |
|    value_loss           | 0.0365      |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 591         |
|    iterations           | 350         |
|    time_elapsed         | 1210        |
|    total_timesteps      | 716800      |
| train/                  |             |
|    approx_kl            | 0.002895147 |
|    clip_fraction        | 0.00879     |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.21       |
|    explained_variance   | 0.925       |
|    learning_rate        | 3.43e-05    |
|    loss                 | -0.00753    |
|    n_updates            | 3490        |
|    policy_gradient_loss | -0.00233    |
|    std                  | 0.73        |
|    value_loss           | 0.0312      |
-----------------------------------------
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 592          |
|    iterations           | 351          |
|    time_elapsed         | 1214         |
|    total_timesteps      | 718848       |
| train/                  |              |
|    approx_kl            | 0.0024795989 |
|    clip_fraction        | 0.00591      |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.2         |
|    explained_variance   | 0.878        |
|    learning_rate        | 3.43e-05     |
|    loss                 | -0.000869    |
|    n_updates            | 3500         |
|    policy_gradient_loss | -0.00206     |
|    std                  | 0.73         |
|    value_loss           | 0.00526      |
------------------------------------------
box reached target
box reached target
Eval num_timesteps=720000, episode_reward=0.52 +/- 2.59
Episode length: 449.40 +/- 101.20
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 449          |
|    mean_reward          | 0.516        |
| time/                   |              |
|    total_timesteps      | 720000       |
| train/                  |              |
|    approx_kl            | 0.0023798724 |
|    clip_fraction        | 0.00771      |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.2         |
|    explained_variance   | 0.917        |
|    learning_rate        | 3.43e-05     |
|    loss                 | -0.00595     |
|    n_updates            | 3510         |
|    policy_gradient_loss | -0.00277     |
|    std                  | 0.728        |
|    value_loss           | 0.0139       |
------------------------------------------
-------------------------------
| time/              |        |
|    fps             | 591    |
|    iterations      | 352    |
|    time_elapsed    | 1218   |
|    total_timesteps | 720896 |
-------------------------------
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 591          |
|    iterations           | 353          |
|    time_elapsed         | 1221         |
|    total_timesteps      | 722944       |
| train/                  |              |
|    approx_kl            | 0.0032136354 |
|    clip_fraction        | 0.0131       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.2         |
|    explained_variance   | 0.83         |
|    learning_rate        | 3.43e-05     |
|    loss                 | -0.0032      |
|    n_updates            | 3520         |
|    policy_gradient_loss | -0.00366     |
|    std                  | 0.727        |
|    value_loss           | 0.0228       |
------------------------------------------
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 591          |
|    iterations           | 354          |
|    time_elapsed         | 1224         |
|    total_timesteps      | 724992       |
| train/                  |              |
|    approx_kl            | 0.0049424004 |
|    clip_fraction        | 0.023        |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.19        |
|    explained_variance   | 0.879        |
|    learning_rate        | 3.43e-05     |
|    loss                 | 0.000495     |
|    n_updates            | 3530         |
|    policy_gradient_loss | -0.00349     |
|    std                  | 0.726        |
|    value_loss           | 0.0157       |
------------------------------------------
box reached target
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 591          |
|    iterations           | 355          |
|    time_elapsed         | 1228         |
|    total_timesteps      | 727040       |
| train/                  |              |
|    approx_kl            | 0.0030797021 |
|    clip_fraction        | 0.0061       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.19        |
|    explained_variance   | 0.911        |
|    learning_rate        | 3.43e-05     |
|    loss                 | 0.00474      |
|    n_updates            | 3540         |
|    policy_gradient_loss | -0.00109     |
|    std                  | 0.724        |
|    value_loss           | 0.0155       |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 592          |
|    iterations           | 356          |
|    time_elapsed         | 1231         |
|    total_timesteps      | 729088       |
| train/                  |              |
|    approx_kl            | 0.0034865187 |
|    clip_fraction        | 0.0201       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.19        |
|    explained_variance   | 0.918        |
|    learning_rate        | 3.44e-05     |
|    loss                 | 3.65e-05     |
|    n_updates            | 3550         |
|    policy_gradient_loss | -0.00225     |
|    std                  | 0.723        |
|    value_loss           | 0.0202       |
------------------------------------------
Eval num_timesteps=730000, episode_reward=-0.79 +/- 0.41
Episode length: 500.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 500         |
|    mean_reward          | -0.794      |
| time/                   |             |
|    total_timesteps      | 730000      |
| train/                  |             |
|    approx_kl            | 0.005759032 |
|    clip_fraction        | 0.0433      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.19       |
|    explained_variance   | 0.906       |
|    learning_rate        | 3.44e-05    |
|    loss                 | -0.0255     |
|    n_updates            | 3560        |
|    policy_gradient_loss | -0.00618    |
|    std                  | 0.724       |
|    value_loss           | 0.00281     |
-----------------------------------------
-------------------------------
| time/              |        |
|    fps             | 591    |
|    iterations      | 357    |
|    time_elapsed    | 1236   |
|    total_timesteps | 731136 |
-------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 591          |
|    iterations           | 358          |
|    time_elapsed         | 1239         |
|    total_timesteps      | 733184       |
| train/                  |              |
|    approx_kl            | 0.0034232447 |
|    clip_fraction        | 0.0152       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.19        |
|    explained_variance   | 0.82         |
|    learning_rate        | 3.44e-05     |
|    loss                 | -0.00332     |
|    n_updates            | 3570         |
|    policy_gradient_loss | -0.00375     |
|    std                  | 0.722        |
|    value_loss           | 0.000647     |
------------------------------------------
box reached target
box reached target
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 591          |
|    iterations           | 359          |
|    time_elapsed         | 1242         |
|    total_timesteps      | 735232       |
| train/                  |              |
|    approx_kl            | 0.0035488703 |
|    clip_fraction        | 0.0124       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.18        |
|    explained_variance   | 0.84         |
|    learning_rate        | 3.44e-05     |
|    loss                 | -0.00839     |
|    n_updates            | 3580         |
|    policy_gradient_loss | -0.00301     |
|    std                  | 0.724        |
|    value_loss           | 0.00861      |
------------------------------------------
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 591          |
|    iterations           | 360          |
|    time_elapsed         | 1245         |
|    total_timesteps      | 737280       |
| train/                  |              |
|    approx_kl            | 0.0048647095 |
|    clip_fraction        | 0.0246       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.19        |
|    explained_variance   | 0.909        |
|    learning_rate        | 3.44e-05     |
|    loss                 | 0.0125       |
|    n_updates            | 3590         |
|    policy_gradient_loss | -0.00218     |
|    std                  | 0.722        |
|    value_loss           | 0.0328       |
------------------------------------------
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 592          |
|    iterations           | 361          |
|    time_elapsed         | 1248         |
|    total_timesteps      | 739328       |
| train/                  |              |
|    approx_kl            | 0.0043327273 |
|    clip_fraction        | 0.0176       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.18        |
|    explained_variance   | 0.96         |
|    learning_rate        | 3.44e-05     |
|    loss                 | 0.00369      |
|    n_updates            | 3600         |
|    policy_gradient_loss | -0.00469     |
|    std                  | 0.721        |
|    value_loss           | 0.00624      |
------------------------------------------
box reached target
Eval num_timesteps=740000, episode_reward=0.37 +/- 2.50
Episode length: 429.20 +/- 141.60
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 429         |
|    mean_reward          | 0.366       |
| time/                   |             |
|    total_timesteps      | 740000      |
| train/                  |             |
|    approx_kl            | 0.004363307 |
|    clip_fraction        | 0.0294      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.18       |
|    explained_variance   | 0.869       |
|    learning_rate        | 3.44e-05    |
|    loss                 | 0.00925     |
|    n_updates            | 3610        |
|    policy_gradient_loss | -0.00467    |
|    std                  | 0.72        |
|    value_loss           | 0.0102      |
-----------------------------------------
-------------------------------
| time/              |        |
|    fps             | 591    |
|    iterations      | 362    |
|    time_elapsed    | 1253   |
|    total_timesteps | 741376 |
-------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 591          |
|    iterations           | 363          |
|    time_elapsed         | 1256         |
|    total_timesteps      | 743424       |
| train/                  |              |
|    approx_kl            | 0.0045164833 |
|    clip_fraction        | 0.0288       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.18        |
|    explained_variance   | 0.873        |
|    learning_rate        | 3.44e-05     |
|    loss                 | 0.0181       |
|    n_updates            | 3620         |
|    policy_gradient_loss | -0.00346     |
|    std                  | 0.72         |
|    value_loss           | 0.00468      |
------------------------------------------
box reached target
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 591         |
|    iterations           | 364         |
|    time_elapsed         | 1259        |
|    total_timesteps      | 745472      |
| train/                  |             |
|    approx_kl            | 0.006118322 |
|    clip_fraction        | 0.0497      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.18       |
|    explained_variance   | 0.925       |
|    learning_rate        | 3.45e-05    |
|    loss                 | -0.0316     |
|    n_updates            | 3630        |
|    policy_gradient_loss | -0.0076     |
|    std                  | 0.721       |
|    value_loss           | 0.00168     |
-----------------------------------------
box reached target
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 591          |
|    iterations           | 365          |
|    time_elapsed         | 1262         |
|    total_timesteps      | 747520       |
| train/                  |              |
|    approx_kl            | 0.0030815997 |
|    clip_fraction        | 0.00913      |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.18        |
|    explained_variance   | 0.871        |
|    learning_rate        | 3.45e-05     |
|    loss                 | 0.01         |
|    n_updates            | 3640         |
|    policy_gradient_loss | -0.00173     |
|    std                  | 0.721        |
|    value_loss           | 0.0604       |
------------------------------------------
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 592          |
|    iterations           | 366          |
|    time_elapsed         | 1266         |
|    total_timesteps      | 749568       |
| train/                  |              |
|    approx_kl            | 0.0011015623 |
|    clip_fraction        | 0.000537     |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.18        |
|    explained_variance   | 0.786        |
|    learning_rate        | 3.45e-05     |
|    loss                 | 0.0599       |
|    n_updates            | 3650         |
|    policy_gradient_loss | -0.00144     |
|    std                  | 0.719        |
|    value_loss           | 0.0506       |
------------------------------------------
box reached target
box reached target
Eval num_timesteps=750000, episode_reward=0.37 +/- 2.52
Episode length: 435.60 +/- 128.80
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 436          |
|    mean_reward          | 0.367        |
| time/                   |              |
|    total_timesteps      | 750000       |
| train/                  |              |
|    approx_kl            | 0.0039966935 |
|    clip_fraction        | 0.0115       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.17        |
|    explained_variance   | 0.834        |
|    learning_rate        | 3.45e-05     |
|    loss                 | 0.000292     |
|    n_updates            | 3660         |
|    policy_gradient_loss | -0.00425     |
|    std                  | 0.719        |
|    value_loss           | 0.0358       |
------------------------------------------
-------------------------------
| time/              |        |
|    fps             | 591    |
|    iterations      | 367    |
|    time_elapsed    | 1270   |
|    total_timesteps | 751616 |
-------------------------------
box reached target
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 591         |
|    iterations           | 368         |
|    time_elapsed         | 1273        |
|    total_timesteps      | 753664      |
| train/                  |             |
|    approx_kl            | 0.001423049 |
|    clip_fraction        | 0.00239     |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.17       |
|    explained_variance   | 0.802       |
|    learning_rate        | 3.45e-05    |
|    loss                 | -0.00379    |
|    n_updates            | 3670        |
|    policy_gradient_loss | -0.00159    |
|    std                  | 0.715       |
|    value_loss           | 0.023       |
-----------------------------------------
box reached target
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 591          |
|    iterations           | 369          |
|    time_elapsed         | 1276         |
|    total_timesteps      | 755712       |
| train/                  |              |
|    approx_kl            | 0.0042222855 |
|    clip_fraction        | 0.0139       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.16        |
|    explained_variance   | 0.938        |
|    learning_rate        | 3.45e-05     |
|    loss                 | 0.0234       |
|    n_updates            | 3680         |
|    policy_gradient_loss | -0.00241     |
|    std                  | 0.714        |
|    value_loss           | 0.0192       |
------------------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 591         |
|    iterations           | 370         |
|    time_elapsed         | 1280        |
|    total_timesteps      | 757760      |
| train/                  |             |
|    approx_kl            | 0.003710259 |
|    clip_fraction        | 0.0217      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.16       |
|    explained_variance   | 0.931       |
|    learning_rate        | 3.45e-05    |
|    loss                 | -0.0143     |
|    n_updates            | 3690        |
|    policy_gradient_loss | -0.0046     |
|    std                  | 0.712       |
|    value_loss           | 0.0145      |
-----------------------------------------
box reached target
box reached target
box reached target
box reached target
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 592          |
|    iterations           | 371          |
|    time_elapsed         | 1283         |
|    total_timesteps      | 759808       |
| train/                  |              |
|    approx_kl            | 0.0041534184 |
|    clip_fraction        | 0.0254       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.15        |
|    explained_variance   | 0.84         |
|    learning_rate        | 3.45e-05     |
|    loss                 | -0.021       |
|    n_updates            | 3700         |
|    policy_gradient_loss | -0.00382     |
|    std                  | 0.711        |
|    value_loss           | 0.0346       |
------------------------------------------
box reached target
Eval num_timesteps=760000, episode_reward=0.52 +/- 2.64
Episode length: 448.80 +/- 102.40
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 449          |
|    mean_reward          | 0.52         |
| time/                   |              |
|    total_timesteps      | 760000       |
| train/                  |              |
|    approx_kl            | 0.0047122156 |
|    clip_fraction        | 0.025        |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.15        |
|    explained_variance   | 0.753        |
|    learning_rate        | 3.46e-05     |
|    loss                 | 0.0332       |
|    n_updates            | 3710         |
|    policy_gradient_loss | -0.0041      |
|    std                  | 0.71         |
|    value_loss           | 0.124        |
------------------------------------------
box reached target
-------------------------------
| time/              |        |
|    fps             | 591    |
|    iterations      | 372    |
|    time_elapsed    | 1287   |
|    total_timesteps | 761856 |
-------------------------------
box reached target
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 591         |
|    iterations           | 373         |
|    time_elapsed         | 1291        |
|    total_timesteps      | 763904      |
| train/                  |             |
|    approx_kl            | 0.003229848 |
|    clip_fraction        | 0.00967     |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.15       |
|    explained_variance   | 0.86        |
|    learning_rate        | 3.46e-05    |
|    loss                 | 0.00709     |
|    n_updates            | 3720        |
|    policy_gradient_loss | -0.00221    |
|    std                  | 0.71        |
|    value_loss           | 0.0346      |
-----------------------------------------
box reached target
box reached target
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 591          |
|    iterations           | 374          |
|    time_elapsed         | 1294         |
|    total_timesteps      | 765952       |
| train/                  |              |
|    approx_kl            | 0.0023585828 |
|    clip_fraction        | 0.00537      |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.15        |
|    explained_variance   | 0.93         |
|    learning_rate        | 3.46e-05     |
|    loss                 | 0.0167       |
|    n_updates            | 3730         |
|    policy_gradient_loss | -0.00211     |
|    std                  | 0.709        |
|    value_loss           | 0.0186       |
------------------------------------------
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 591          |
|    iterations           | 375          |
|    time_elapsed         | 1297         |
|    total_timesteps      | 768000       |
| train/                  |              |
|    approx_kl            | 0.0064227935 |
|    clip_fraction        | 0.0562       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.14        |
|    explained_variance   | 0.974        |
|    learning_rate        | 3.46e-05     |
|    loss                 | -0.0234      |
|    n_updates            | 3740         |
|    policy_gradient_loss | -0.00759     |
|    std                  | 0.706        |
|    value_loss           | 0.0123       |
------------------------------------------
box reached target
box reached target
Eval num_timesteps=770000, episode_reward=2.09 +/- 2.91
Episode length: 384.80 +/- 144.45
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 385         |
|    mean_reward          | 2.09        |
| time/                   |             |
|    total_timesteps      | 770000      |
| train/                  |             |
|    approx_kl            | 0.002874489 |
|    clip_fraction        | 0.0199      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.14       |
|    explained_variance   | 0.961       |
|    learning_rate        | 3.46e-05    |
|    loss                 | 0.000658    |
|    n_updates            | 3750        |
|    policy_gradient_loss | -0.00483    |
|    std                  | 0.706       |
|    value_loss           | 0.0104      |
-----------------------------------------
New best mean reward!
-------------------------------
| time/              |        |
|    fps             | 591    |
|    iterations      | 376    |
|    time_elapsed    | 1301   |
|    total_timesteps | 770048 |
-------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 591          |
|    iterations           | 377          |
|    time_elapsed         | 1304         |
|    total_timesteps      | 772096       |
| train/                  |              |
|    approx_kl            | 0.0039331946 |
|    clip_fraction        | 0.0245       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.14        |
|    explained_variance   | 0.861        |
|    learning_rate        | 3.46e-05     |
|    loss                 | -0.016       |
|    n_updates            | 3760         |
|    policy_gradient_loss | -0.00359     |
|    std                  | 0.706        |
|    value_loss           | 0.00138      |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 591          |
|    iterations           | 378          |
|    time_elapsed         | 1308         |
|    total_timesteps      | 774144       |
| train/                  |              |
|    approx_kl            | 0.0030498048 |
|    clip_fraction        | 0.00854      |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.14        |
|    explained_variance   | 0.946        |
|    learning_rate        | 3.46e-05     |
|    loss                 | 0.0027       |
|    n_updates            | 3770         |
|    policy_gradient_loss | -0.00192     |
|    std                  | 0.707        |
|    value_loss           | 0.00104      |
------------------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 591         |
|    iterations           | 379         |
|    time_elapsed         | 1311        |
|    total_timesteps      | 776192      |
| train/                  |             |
|    approx_kl            | 0.005359378 |
|    clip_fraction        | 0.033       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.14       |
|    explained_variance   | 0.785       |
|    learning_rate        | 3.46e-05    |
|    loss                 | -0.0236     |
|    n_updates            | 3780        |
|    policy_gradient_loss | -0.0051     |
|    std                  | 0.708       |
|    value_loss           | 0.00136     |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 592         |
|    iterations           | 380         |
|    time_elapsed         | 1314        |
|    total_timesteps      | 778240      |
| train/                  |             |
|    approx_kl            | 0.004094111 |
|    clip_fraction        | 0.0195      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.14       |
|    explained_variance   | 0.947       |
|    learning_rate        | 3.47e-05    |
|    loss                 | 0.0162      |
|    n_updates            | 3790        |
|    policy_gradient_loss | -0.00249    |
|    std                  | 0.708       |
|    value_loss           | 0.011       |
-----------------------------------------
box reached target
box reached target
box reached target
box reached target
Eval num_timesteps=780000, episode_reward=4.22 +/- 2.61
Episode length: 242.60 +/- 132.83
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 243         |
|    mean_reward          | 4.22        |
| time/                   |             |
|    total_timesteps      | 780000      |
| train/                  |             |
|    approx_kl            | 0.004142128 |
|    clip_fraction        | 0.0317      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.14       |
|    explained_variance   | 0.911       |
|    learning_rate        | 3.47e-05    |
|    loss                 | -0.0284     |
|    n_updates            | 3800        |
|    policy_gradient_loss | -0.00409    |
|    std                  | 0.708       |
|    value_loss           | 0.0047      |
-----------------------------------------
New best mean reward!
-------------------------------
| time/              |        |
|    fps             | 591    |
|    iterations      | 381    |
|    time_elapsed    | 1318   |
|    total_timesteps | 780288 |
-------------------------------
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 592          |
|    iterations           | 382          |
|    time_elapsed         | 1321         |
|    total_timesteps      | 782336       |
| train/                  |              |
|    approx_kl            | 0.0041453214 |
|    clip_fraction        | 0.0258       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.14        |
|    explained_variance   | 0.941        |
|    learning_rate        | 3.47e-05     |
|    loss                 | -0.00914     |
|    n_updates            | 3810         |
|    policy_gradient_loss | -0.0053      |
|    std                  | 0.708        |
|    value_loss           | 0.00315      |
------------------------------------------
box reached target
box reached target
box reached target
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 592          |
|    iterations           | 383          |
|    time_elapsed         | 1324         |
|    total_timesteps      | 784384       |
| train/                  |              |
|    approx_kl            | 0.0025399784 |
|    clip_fraction        | 0.00732      |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.14        |
|    explained_variance   | 0.937        |
|    learning_rate        | 3.47e-05     |
|    loss                 | -0.0151      |
|    n_updates            | 3820         |
|    policy_gradient_loss | -0.00245     |
|    std                  | 0.706        |
|    value_loss           | 0.0185       |
------------------------------------------
box reached target
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 592          |
|    iterations           | 384          |
|    time_elapsed         | 1327         |
|    total_timesteps      | 786432       |
| train/                  |              |
|    approx_kl            | 0.0034956117 |
|    clip_fraction        | 0.0167       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.13        |
|    explained_variance   | 0.92         |
|    learning_rate        | 3.47e-05     |
|    loss                 | -0.00697     |
|    n_updates            | 3830         |
|    policy_gradient_loss | -0.00378     |
|    std                  | 0.704        |
|    value_loss           | 0.0375       |
------------------------------------------
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 592          |
|    iterations           | 385          |
|    time_elapsed         | 1330         |
|    total_timesteps      | 788480       |
| train/                  |              |
|    approx_kl            | 0.0035949678 |
|    clip_fraction        | 0.0152       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.13        |
|    explained_variance   | 0.908        |
|    learning_rate        | 3.47e-05     |
|    loss                 | -0.0126      |
|    n_updates            | 3840         |
|    policy_gradient_loss | -0.00201     |
|    std                  | 0.702        |
|    value_loss           | 0.02         |
------------------------------------------
box reached target
Eval num_timesteps=790000, episode_reward=-1.00 +/- 0.00
Episode length: 500.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 500         |
|    mean_reward          | -1          |
| time/                   |             |
|    total_timesteps      | 790000      |
| train/                  |             |
|    approx_kl            | 0.004713444 |
|    clip_fraction        | 0.0325      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.13       |
|    explained_variance   | 0.963       |
|    learning_rate        | 3.47e-05    |
|    loss                 | 0.0211      |
|    n_updates            | 3850        |
|    policy_gradient_loss | -0.0062     |
|    std                  | 0.702       |
|    value_loss           | 0.0053      |
-----------------------------------------
-------------------------------
| time/              |        |
|    fps             | 591    |
|    iterations      | 386    |
|    time_elapsed    | 1335   |
|    total_timesteps | 790528 |
-------------------------------
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 591          |
|    iterations           | 387          |
|    time_elapsed         | 1338         |
|    total_timesteps      | 792576       |
| train/                  |              |
|    approx_kl            | 0.0032165702 |
|    clip_fraction        | 0.0113       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.13        |
|    explained_variance   | 0.747        |
|    learning_rate        | 3.47e-05     |
|    loss                 | 0.0079       |
|    n_updates            | 3860         |
|    policy_gradient_loss | -0.00263     |
|    std                  | 0.703        |
|    value_loss           | 0.0429       |
------------------------------------------
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 592          |
|    iterations           | 388          |
|    time_elapsed         | 1342         |
|    total_timesteps      | 794624       |
| train/                  |              |
|    approx_kl            | 0.0031166486 |
|    clip_fraction        | 0.00913      |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.13        |
|    explained_variance   | 0.972        |
|    learning_rate        | 3.48e-05     |
|    loss                 | -0.01        |
|    n_updates            | 3870         |
|    policy_gradient_loss | -0.00143     |
|    std                  | 0.702        |
|    value_loss           | 0.00227      |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 592          |
|    iterations           | 389          |
|    time_elapsed         | 1345         |
|    total_timesteps      | 796672       |
| train/                  |              |
|    approx_kl            | 0.0015545161 |
|    clip_fraction        | 0.00156      |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.13        |
|    explained_variance   | 0.965        |
|    learning_rate        | 3.48e-05     |
|    loss                 | -0.00248     |
|    n_updates            | 3880         |
|    policy_gradient_loss | -0.00104     |
|    std                  | 0.702        |
|    value_loss           | 0.00662      |
------------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 592         |
|    iterations           | 390         |
|    time_elapsed         | 1348        |
|    total_timesteps      | 798720      |
| train/                  |             |
|    approx_kl            | 0.003997176 |
|    clip_fraction        | 0.021       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.12       |
|    explained_variance   | 0.95        |
|    learning_rate        | 3.48e-05    |
|    loss                 | -0.0186     |
|    n_updates            | 3890        |
|    policy_gradient_loss | -0.00265    |
|    std                  | 0.701       |
|    value_loss           | 0.00258     |
-----------------------------------------
box reached target
Eval num_timesteps=800000, episode_reward=-1.01 +/- 0.01
Episode length: 500.00 +/- 0.00
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 500          |
|    mean_reward          | -1.01        |
| time/                   |              |
|    total_timesteps      | 800000       |
| train/                  |              |
|    approx_kl            | 0.0048210113 |
|    clip_fraction        | 0.0301       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.12        |
|    explained_variance   | 0.951        |
|    learning_rate        | 3.48e-05     |
|    loss                 | -0.00354     |
|    n_updates            | 3900         |
|    policy_gradient_loss | -0.00492     |
|    std                  | 0.701        |
|    value_loss           | 0.00281      |
------------------------------------------
-------------------------------
| time/              |        |
|    fps             | 591    |
|    iterations      | 391    |
|    time_elapsed    | 1353   |
|    total_timesteps | 800768 |
-------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 591         |
|    iterations           | 392         |
|    time_elapsed         | 1356        |
|    total_timesteps      | 802816      |
| train/                  |             |
|    approx_kl            | 0.004788424 |
|    clip_fraction        | 0.0177      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.12       |
|    explained_variance   | 0.745       |
|    learning_rate        | 3.48e-05    |
|    loss                 | 0.000861    |
|    n_updates            | 3910        |
|    policy_gradient_loss | -0.0011     |
|    std                  | 0.7         |
|    value_loss           | 0.0191      |
-----------------------------------------
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 592          |
|    iterations           | 393          |
|    time_elapsed         | 1359         |
|    total_timesteps      | 804864       |
| train/                  |              |
|    approx_kl            | 0.0037419866 |
|    clip_fraction        | 0.0199       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.12        |
|    explained_variance   | 0.914        |
|    learning_rate        | 3.48e-05     |
|    loss                 | 0.00908      |
|    n_updates            | 3920         |
|    policy_gradient_loss | -0.00491     |
|    std                  | 0.701        |
|    value_loss           | 0.00137      |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 592          |
|    iterations           | 394          |
|    time_elapsed         | 1362         |
|    total_timesteps      | 806912       |
| train/                  |              |
|    approx_kl            | 0.0035776803 |
|    clip_fraction        | 0.0141       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.12        |
|    explained_variance   | 0.93         |
|    learning_rate        | 3.48e-05     |
|    loss                 | 0.0098       |
|    n_updates            | 3930         |
|    policy_gradient_loss | -0.00285     |
|    std                  | 0.701        |
|    value_loss           | 0.00822      |
------------------------------------------
box reached target
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 592         |
|    iterations           | 395         |
|    time_elapsed         | 1365        |
|    total_timesteps      | 808960      |
| train/                  |             |
|    approx_kl            | 0.003946648 |
|    clip_fraction        | 0.0199      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.12       |
|    explained_variance   | 0.94        |
|    learning_rate        | 3.48e-05    |
|    loss                 | -0.0171     |
|    n_updates            | 3940        |
|    policy_gradient_loss | -0.00326    |
|    std                  | 0.702       |
|    value_loss           | 0.00254     |
-----------------------------------------
box reached target
Eval num_timesteps=810000, episode_reward=0.86 +/- 2.40
Episode length: 433.80 +/- 132.40
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 434        |
|    mean_reward          | 0.859      |
| time/                   |            |
|    total_timesteps      | 810000     |
| train/                  |            |
|    approx_kl            | 0.00412485 |
|    clip_fraction        | 0.0145     |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.12      |
|    explained_variance   | 0.941      |
|    learning_rate        | 3.49e-05   |
|    loss                 | -0.00665   |
|    n_updates            | 3950       |
|    policy_gradient_loss | -0.0018    |
|    std                  | 0.7        |
|    value_loss           | 0.0254     |
----------------------------------------
box reached target
-------------------------------
| time/              |        |
|    fps             | 591    |
|    iterations      | 396    |
|    time_elapsed    | 1370   |
|    total_timesteps | 811008 |
-------------------------------
box reached target
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 591          |
|    iterations           | 397          |
|    time_elapsed         | 1373         |
|    total_timesteps      | 813056       |
| train/                  |              |
|    approx_kl            | 0.0044731973 |
|    clip_fraction        | 0.0225       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.12        |
|    explained_variance   | 0.99         |
|    learning_rate        | 3.49e-05     |
|    loss                 | 0.0072       |
|    n_updates            | 3960         |
|    policy_gradient_loss | -0.00231     |
|    std                  | 0.701        |
|    value_loss           | 0.00384      |
------------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 592         |
|    iterations           | 398         |
|    time_elapsed         | 1376        |
|    total_timesteps      | 815104      |
| train/                  |             |
|    approx_kl            | 0.004090996 |
|    clip_fraction        | 0.0231      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.12       |
|    explained_variance   | 0.647       |
|    learning_rate        | 3.49e-05    |
|    loss                 | -0.00452    |
|    n_updates            | 3970        |
|    policy_gradient_loss | -0.00638    |
|    std                  | 0.701       |
|    value_loss           | 0.081       |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 592         |
|    iterations           | 399         |
|    time_elapsed         | 1379        |
|    total_timesteps      | 817152      |
| train/                  |             |
|    approx_kl            | 0.003059343 |
|    clip_fraction        | 0.00732     |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.12       |
|    explained_variance   | 0.954       |
|    learning_rate        | 3.49e-05    |
|    loss                 | -0.0146     |
|    n_updates            | 3980        |
|    policy_gradient_loss | -0.00349    |
|    std                  | 0.7         |
|    value_loss           | 0.00226     |
-----------------------------------------
box reached target
box reached target
box reached target
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 592          |
|    iterations           | 400          |
|    time_elapsed         | 1382         |
|    total_timesteps      | 819200       |
| train/                  |              |
|    approx_kl            | 0.0010910069 |
|    clip_fraction        | 0.00171      |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.12        |
|    explained_variance   | 0.928        |
|    learning_rate        | 3.49e-05     |
|    loss                 | -0.00743     |
|    n_updates            | 3990         |
|    policy_gradient_loss | -0.00121     |
|    std                  | 0.701        |
|    value_loss           | 0.000883     |
------------------------------------------
box reached target
Eval num_timesteps=820000, episode_reward=0.36 +/- 2.71
Episode length: 444.00 +/- 112.00
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 444          |
|    mean_reward          | 0.357        |
| time/                   |              |
|    total_timesteps      | 820000       |
| train/                  |              |
|    approx_kl            | 0.0028057112 |
|    clip_fraction        | 0.0144       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.12        |
|    explained_variance   | 0.954        |
|    learning_rate        | 3.49e-05     |
|    loss                 | -0.0198      |
|    n_updates            | 4000         |
|    policy_gradient_loss | -0.0029      |
|    std                  | 0.7          |
|    value_loss           | 0.0138       |
------------------------------------------
box reached target
-------------------------------
| time/              |        |
|    fps             | 591    |
|    iterations      | 401    |
|    time_elapsed    | 1387   |
|    total_timesteps | 821248 |
-------------------------------
box reached target
box reached target
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 591         |
|    iterations           | 402         |
|    time_elapsed         | 1390        |
|    total_timesteps      | 823296      |
| train/                  |             |
|    approx_kl            | 0.003256855 |
|    clip_fraction        | 0.0161      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.12       |
|    explained_variance   | 0.916       |
|    learning_rate        | 3.49e-05    |
|    loss                 | -0.00892    |
|    n_updates            | 4010        |
|    policy_gradient_loss | -0.00268    |
|    std                  | 0.699       |
|    value_loss           | 0.0168      |
-----------------------------------------
box reached target
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 592          |
|    iterations           | 403          |
|    time_elapsed         | 1393         |
|    total_timesteps      | 825344       |
| train/                  |              |
|    approx_kl            | 0.0013466894 |
|    clip_fraction        | 0.00444      |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.12        |
|    explained_variance   | 0.937        |
|    learning_rate        | 3.49e-05     |
|    loss                 | -0.0201      |
|    n_updates            | 4020         |
|    policy_gradient_loss | -0.00272     |
|    std                  | 0.698        |
|    value_loss           | 0.0206       |
------------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 592         |
|    iterations           | 404         |
|    time_elapsed         | 1397        |
|    total_timesteps      | 827392      |
| train/                  |             |
|    approx_kl            | 0.005252906 |
|    clip_fraction        | 0.0395      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.11       |
|    explained_variance   | 0.927       |
|    learning_rate        | 3.5e-05     |
|    loss                 | 0.0148      |
|    n_updates            | 4030        |
|    policy_gradient_loss | -0.00351    |
|    std                  | 0.698       |
|    value_loss           | 0.0252      |
-----------------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 592         |
|    iterations           | 405         |
|    time_elapsed         | 1400        |
|    total_timesteps      | 829440      |
| train/                  |             |
|    approx_kl            | 0.003611722 |
|    clip_fraction        | 0.0246      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.11       |
|    explained_variance   | 0.941       |
|    learning_rate        | 3.5e-05     |
|    loss                 | -0.00557    |
|    n_updates            | 4040        |
|    policy_gradient_loss | -0.00477    |
|    std                  | 0.698       |
|    value_loss           | 0.00391     |
-----------------------------------------
box reached target
Eval num_timesteps=830000, episode_reward=0.28 +/- 2.56
Episode length: 439.20 +/- 121.60
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 439          |
|    mean_reward          | 0.282        |
| time/                   |              |
|    total_timesteps      | 830000       |
| train/                  |              |
|    approx_kl            | 0.0029876432 |
|    clip_fraction        | 0.00801      |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.11        |
|    explained_variance   | 0.971        |
|    learning_rate        | 3.5e-05      |
|    loss                 | 0.00379      |
|    n_updates            | 4050         |
|    policy_gradient_loss | -0.0019      |
|    std                  | 0.696        |
|    value_loss           | 0.0133       |
------------------------------------------
-------------------------------
| time/              |        |
|    fps             | 591    |
|    iterations      | 406    |
|    time_elapsed    | 1404   |
|    total_timesteps | 831488 |
-------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 592         |
|    iterations           | 407         |
|    time_elapsed         | 1407        |
|    total_timesteps      | 833536      |
| train/                  |             |
|    approx_kl            | 0.005294144 |
|    clip_fraction        | 0.0271      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.11       |
|    explained_variance   | 0.931       |
|    learning_rate        | 3.5e-05     |
|    loss                 | -0.00694    |
|    n_updates            | 4060        |
|    policy_gradient_loss | -0.00395    |
|    std                  | 0.697       |
|    value_loss           | 0.00148     |
-----------------------------------------
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 592          |
|    iterations           | 408          |
|    time_elapsed         | 1411         |
|    total_timesteps      | 835584       |
| train/                  |              |
|    approx_kl            | 0.0034929197 |
|    clip_fraction        | 0.00942      |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.11        |
|    explained_variance   | 0.915        |
|    learning_rate        | 3.5e-05      |
|    loss                 | -0.00289     |
|    n_updates            | 4070         |
|    policy_gradient_loss | -0.00146     |
|    std                  | 0.698        |
|    value_loss           | 0.0183       |
------------------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 592         |
|    iterations           | 409         |
|    time_elapsed         | 1414        |
|    total_timesteps      | 837632      |
| train/                  |             |
|    approx_kl            | 0.004817674 |
|    clip_fraction        | 0.0306      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.11       |
|    explained_variance   | 0.985       |
|    learning_rate        | 3.5e-05     |
|    loss                 | 0.00268     |
|    n_updates            | 4080        |
|    policy_gradient_loss | -0.00574    |
|    std                  | 0.697       |
|    value_loss           | 0.00255     |
-----------------------------------------
box reached target
box reached target
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 592         |
|    iterations           | 410         |
|    time_elapsed         | 1417        |
|    total_timesteps      | 839680      |
| train/                  |             |
|    approx_kl            | 0.005184022 |
|    clip_fraction        | 0.0275      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.11       |
|    explained_variance   | 0.987       |
|    learning_rate        | 3.5e-05     |
|    loss                 | 0.00465     |
|    n_updates            | 4090        |
|    policy_gradient_loss | -0.00508    |
|    std                  | 0.697       |
|    value_loss           | 0.00265     |
-----------------------------------------
Eval num_timesteps=840000, episode_reward=-0.82 +/- 0.35
Episode length: 500.00 +/- 0.00
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 500          |
|    mean_reward          | -0.823       |
| time/                   |              |
|    total_timesteps      | 840000       |
| train/                  |              |
|    approx_kl            | 0.0032488012 |
|    clip_fraction        | 0.00806      |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.11        |
|    explained_variance   | 0.814        |
|    learning_rate        | 3.5e-05      |
|    loss                 | 0.00344      |
|    n_updates            | 4100         |
|    policy_gradient_loss | -0.00309     |
|    std                  | 0.697        |
|    value_loss           | 0.0685       |
------------------------------------------
-------------------------------
| time/              |        |
|    fps             | 591    |
|    iterations      | 411    |
|    time_elapsed    | 1422   |
|    total_timesteps | 841728 |
-------------------------------
box reached target
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 591          |
|    iterations           | 412          |
|    time_elapsed         | 1425         |
|    total_timesteps      | 843776       |
| train/                  |              |
|    approx_kl            | 0.0025253647 |
|    clip_fraction        | 0.00288      |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.11        |
|    explained_variance   | 0.963        |
|    learning_rate        | 3.51e-05     |
|    loss                 | -0.00347     |
|    n_updates            | 4110         |
|    policy_gradient_loss | -0.000563    |
|    std                  | 0.697        |
|    value_loss           | 0.00146      |
------------------------------------------
box reached target
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 592          |
|    iterations           | 413          |
|    time_elapsed         | 1428         |
|    total_timesteps      | 845824       |
| train/                  |              |
|    approx_kl            | 0.0036123078 |
|    clip_fraction        | 0.0184       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.11        |
|    explained_variance   | 0.852        |
|    learning_rate        | 3.51e-05     |
|    loss                 | 0.0885       |
|    n_updates            | 4120         |
|    policy_gradient_loss | -0.00301     |
|    std                  | 0.695        |
|    value_loss           | 0.0646       |
------------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 592         |
|    iterations           | 414         |
|    time_elapsed         | 1431        |
|    total_timesteps      | 847872      |
| train/                  |             |
|    approx_kl            | 0.004354427 |
|    clip_fraction        | 0.0276      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.1        |
|    explained_variance   | 0.921       |
|    learning_rate        | 3.51e-05    |
|    loss                 | -0.00734    |
|    n_updates            | 4130        |
|    policy_gradient_loss | -0.00385    |
|    std                  | 0.694       |
|    value_loss           | 0.0285      |
-----------------------------------------
box reached target
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 592          |
|    iterations           | 415          |
|    time_elapsed         | 1434         |
|    total_timesteps      | 849920       |
| train/                  |              |
|    approx_kl            | 0.0054861796 |
|    clip_fraction        | 0.0422       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.1         |
|    explained_variance   | 0.9          |
|    learning_rate        | 3.51e-05     |
|    loss                 | -0.0277      |
|    n_updates            | 4140         |
|    policy_gradient_loss | -0.00564     |
|    std                  | 0.695        |
|    value_loss           | 0.00515      |
------------------------------------------
box reached target
Eval num_timesteps=850000, episode_reward=0.69 +/- 2.37
Episode length: 431.40 +/- 137.20
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 431          |
|    mean_reward          | 0.692        |
| time/                   |              |
|    total_timesteps      | 850000       |
| train/                  |              |
|    approx_kl            | 0.0028397772 |
|    clip_fraction        | 0.0112       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.1         |
|    explained_variance   | 0.86         |
|    learning_rate        | 3.51e-05     |
|    loss                 | -0.00725     |
|    n_updates            | 4150         |
|    policy_gradient_loss | -0.00366     |
|    std                  | 0.694        |
|    value_loss           | 0.027        |
------------------------------------------
-------------------------------
| time/              |        |
|    fps             | 591    |
|    iterations      | 416    |
|    time_elapsed    | 1439   |
|    total_timesteps | 851968 |
-------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 591          |
|    iterations           | 417          |
|    time_elapsed         | 1442         |
|    total_timesteps      | 854016       |
| train/                  |              |
|    approx_kl            | 0.0037978382 |
|    clip_fraction        | 0.0157       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.1         |
|    explained_variance   | 0.736        |
|    learning_rate        | 3.51e-05     |
|    loss                 | -0.0127      |
|    n_updates            | 4160         |
|    policy_gradient_loss | -0.0047      |
|    std                  | 0.693        |
|    value_loss           | 0.00117      |
------------------------------------------
box reached target
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 592          |
|    iterations           | 418          |
|    time_elapsed         | 1445         |
|    total_timesteps      | 856064       |
| train/                  |              |
|    approx_kl            | 0.0041259215 |
|    clip_fraction        | 0.021        |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.1         |
|    explained_variance   | 0.922        |
|    learning_rate        | 3.51e-05     |
|    loss                 | -0.00831     |
|    n_updates            | 4170         |
|    policy_gradient_loss | -0.0045      |
|    std                  | 0.694        |
|    value_loss           | 0.00419      |
------------------------------------------
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 592          |
|    iterations           | 419          |
|    time_elapsed         | 1448         |
|    total_timesteps      | 858112       |
| train/                  |              |
|    approx_kl            | 0.0040167407 |
|    clip_fraction        | 0.012        |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.1         |
|    explained_variance   | 0.957        |
|    learning_rate        | 3.51e-05     |
|    loss                 | -0.0154      |
|    n_updates            | 4180         |
|    policy_gradient_loss | -0.00375     |
|    std                  | 0.693        |
|    value_loss           | 0.0179       |
------------------------------------------
box reached target
box reached target
box reached target
Eval num_timesteps=860000, episode_reward=0.31 +/- 2.63
Episode length: 439.80 +/- 120.40
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 440          |
|    mean_reward          | 0.315        |
| time/                   |              |
|    total_timesteps      | 860000       |
| train/                  |              |
|    approx_kl            | 0.0044179196 |
|    clip_fraction        | 0.0178       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.1         |
|    explained_variance   | 0.976        |
|    learning_rate        | 3.51e-05     |
|    loss                 | -0.017       |
|    n_updates            | 4190         |
|    policy_gradient_loss | -0.00456     |
|    std                  | 0.692        |
|    value_loss           | 0.00308      |
------------------------------------------
box reached target
-------------------------------
| time/              |        |
|    fps             | 591    |
|    iterations      | 420    |
|    time_elapsed    | 1453   |
|    total_timesteps | 860160 |
-------------------------------
box reached target
box reached target
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 591          |
|    iterations           | 421          |
|    time_elapsed         | 1456         |
|    total_timesteps      | 862208       |
| train/                  |              |
|    approx_kl            | 0.0015864272 |
|    clip_fraction        | 0.00146      |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.1         |
|    explained_variance   | 0.886        |
|    learning_rate        | 3.52e-05     |
|    loss                 | 0.00874      |
|    n_updates            | 4200         |
|    policy_gradient_loss | -0.000974    |
|    std                  | 0.691        |
|    value_loss           | 0.0578       |
------------------------------------------
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 591          |
|    iterations           | 422          |
|    time_elapsed         | 1459         |
|    total_timesteps      | 864256       |
| train/                  |              |
|    approx_kl            | 0.0056367004 |
|    clip_fraction        | 0.0344       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.09        |
|    explained_variance   | 0.926        |
|    learning_rate        | 3.52e-05     |
|    loss                 | -0.0172      |
|    n_updates            | 4210         |
|    policy_gradient_loss | -0.00386     |
|    std                  | 0.691        |
|    value_loss           | 0.0252       |
------------------------------------------
box reached target
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 592          |
|    iterations           | 423          |
|    time_elapsed         | 1463         |
|    total_timesteps      | 866304       |
| train/                  |              |
|    approx_kl            | 0.0040031048 |
|    clip_fraction        | 0.0247       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.09        |
|    explained_variance   | 0.957        |
|    learning_rate        | 3.52e-05     |
|    loss                 | -0.0154      |
|    n_updates            | 4220         |
|    policy_gradient_loss | -0.0045      |
|    std                  | 0.689        |
|    value_loss           | 0.00473      |
------------------------------------------
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 592          |
|    iterations           | 424          |
|    time_elapsed         | 1466         |
|    total_timesteps      | 868352       |
| train/                  |              |
|    approx_kl            | 0.0025604863 |
|    clip_fraction        | 0.00786      |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.09        |
|    explained_variance   | 0.978        |
|    learning_rate        | 3.52e-05     |
|    loss                 | -0.0341      |
|    n_updates            | 4230         |
|    policy_gradient_loss | -0.00333     |
|    std                  | 0.689        |
|    value_loss           | 0.00908      |
------------------------------------------
box reached target
box reached target
Eval num_timesteps=870000, episode_reward=0.31 +/- 2.62
Episode length: 432.40 +/- 135.20
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 432          |
|    mean_reward          | 0.308        |
| time/                   |              |
|    total_timesteps      | 870000       |
| train/                  |              |
|    approx_kl            | 0.0036246898 |
|    clip_fraction        | 0.0188       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.09        |
|    explained_variance   | 0.973        |
|    learning_rate        | 3.52e-05     |
|    loss                 | -0.00302     |
|    n_updates            | 4240         |
|    policy_gradient_loss | -0.00213     |
|    std                  | 0.689        |
|    value_loss           | 0.00424      |
------------------------------------------
-------------------------------
| time/              |        |
|    fps             | 591    |
|    iterations      | 425    |
|    time_elapsed    | 1470   |
|    total_timesteps | 870400 |
-------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 591         |
|    iterations           | 426         |
|    time_elapsed         | 1473        |
|    total_timesteps      | 872448      |
| train/                  |             |
|    approx_kl            | 0.004372604 |
|    clip_fraction        | 0.0214      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.09       |
|    explained_variance   | 0.965       |
|    learning_rate        | 3.52e-05    |
|    loss                 | -0.0167     |
|    n_updates            | 4250        |
|    policy_gradient_loss | -0.00382    |
|    std                  | 0.688       |
|    value_loss           | 0.00499     |
-----------------------------------------
box reached target
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 592          |
|    iterations           | 427          |
|    time_elapsed         | 1477         |
|    total_timesteps      | 874496       |
| train/                  |              |
|    approx_kl            | 0.0022505904 |
|    clip_fraction        | 0.00229      |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.08        |
|    explained_variance   | 0.658        |
|    learning_rate        | 3.52e-05     |
|    loss                 | -0.000542    |
|    n_updates            | 4260         |
|    policy_gradient_loss | -0.000461    |
|    std                  | 0.687        |
|    value_loss           | 0.0306       |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 592          |
|    iterations           | 428          |
|    time_elapsed         | 1480         |
|    total_timesteps      | 876544       |
| train/                  |              |
|    approx_kl            | 0.0025503086 |
|    clip_fraction        | 0.0104       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.08        |
|    explained_variance   | 0.991        |
|    learning_rate        | 3.52e-05     |
|    loss                 | -0.00132     |
|    n_updates            | 4270         |
|    policy_gradient_loss | -0.00316     |
|    std                  | 0.685        |
|    value_loss           | 0.00398      |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 592          |
|    iterations           | 429          |
|    time_elapsed         | 1483         |
|    total_timesteps      | 878592       |
| train/                  |              |
|    approx_kl            | 0.0030909996 |
|    clip_fraction        | 0.0145       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.08        |
|    explained_variance   | 0.945        |
|    learning_rate        | 3.53e-05     |
|    loss                 | 0.00172      |
|    n_updates            | 4280         |
|    policy_gradient_loss | -0.00223     |
|    std                  | 0.685        |
|    value_loss           | 0.00178      |
------------------------------------------
box reached target
box reached target
box reached target
Eval num_timesteps=880000, episode_reward=1.52 +/- 3.09
Episode length: 357.40 +/- 174.66
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 357          |
|    mean_reward          | 1.52         |
| time/                   |              |
|    total_timesteps      | 880000       |
| train/                  |              |
|    approx_kl            | 0.0054803328 |
|    clip_fraction        | 0.0288       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.07        |
|    explained_variance   | 0.952        |
|    learning_rate        | 3.53e-05     |
|    loss                 | -0.0225      |
|    n_updates            | 4290         |
|    policy_gradient_loss | -0.00567     |
|    std                  | 0.683        |
|    value_loss           | 0.00351      |
------------------------------------------
-------------------------------
| time/              |        |
|    fps             | 591    |
|    iterations      | 430    |
|    time_elapsed    | 1487   |
|    total_timesteps | 880640 |
-------------------------------
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 592          |
|    iterations           | 431          |
|    time_elapsed         | 1490         |
|    total_timesteps      | 882688       |
| train/                  |              |
|    approx_kl            | 0.0032353683 |
|    clip_fraction        | 0.0158       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.07        |
|    explained_variance   | 0.975        |
|    learning_rate        | 3.53e-05     |
|    loss                 | -0.00548     |
|    n_updates            | 4300         |
|    policy_gradient_loss | -0.00268     |
|    std                  | 0.683        |
|    value_loss           | 0.0027       |
------------------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 592         |
|    iterations           | 432         |
|    time_elapsed         | 1494        |
|    total_timesteps      | 884736      |
| train/                  |             |
|    approx_kl            | 0.004630925 |
|    clip_fraction        | 0.0228      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.07       |
|    explained_variance   | 0.926       |
|    learning_rate        | 3.53e-05    |
|    loss                 | 0.00831     |
|    n_updates            | 4310        |
|    policy_gradient_loss | -0.00312    |
|    std                  | 0.683       |
|    value_loss           | 0.00928     |
-----------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 592          |
|    iterations           | 433          |
|    time_elapsed         | 1497         |
|    total_timesteps      | 886784       |
| train/                  |              |
|    approx_kl            | 0.0041094064 |
|    clip_fraction        | 0.0291       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.07        |
|    explained_variance   | 0.958        |
|    learning_rate        | 3.53e-05     |
|    loss                 | -0.0142      |
|    n_updates            | 4320         |
|    policy_gradient_loss | -0.00426     |
|    std                  | 0.683        |
|    value_loss           | 0.00276      |
------------------------------------------
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 592        |
|    iterations           | 434        |
|    time_elapsed         | 1500       |
|    total_timesteps      | 888832     |
| train/                  |            |
|    approx_kl            | 0.00541779 |
|    clip_fraction        | 0.0418     |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.07      |
|    explained_variance   | 0.882      |
|    learning_rate        | 3.53e-05   |
|    loss                 | 0.0168     |
|    n_updates            | 4330       |
|    policy_gradient_loss | -0.00692   |
|    std                  | 0.684      |
|    value_loss           | 0.00348    |
----------------------------------------
box reached target
box reached target
box reached target
box reached target
box reached target
box reached target
Eval num_timesteps=890000, episode_reward=2.90 +/- 3.19
Episode length: 296.00 +/- 167.39
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 296          |
|    mean_reward          | 2.9          |
| time/                   |              |
|    total_timesteps      | 890000       |
| train/                  |              |
|    approx_kl            | 0.0034372227 |
|    clip_fraction        | 0.017        |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.07        |
|    explained_variance   | 0.974        |
|    learning_rate        | 3.53e-05     |
|    loss                 | -0.0023      |
|    n_updates            | 4340         |
|    policy_gradient_loss | -0.00368     |
|    std                  | 0.685        |
|    value_loss           | 0.00555      |
------------------------------------------
-------------------------------
| time/              |        |
|    fps             | 592    |
|    iterations      | 435    |
|    time_elapsed    | 1504   |
|    total_timesteps | 890880 |
-------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 592          |
|    iterations           | 436          |
|    time_elapsed         | 1507         |
|    total_timesteps      | 892928       |
| train/                  |              |
|    approx_kl            | 0.0028331298 |
|    clip_fraction        | 0.0107       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.07        |
|    explained_variance   | 0.921        |
|    learning_rate        | 3.53e-05     |
|    loss                 | 0.00344      |
|    n_updates            | 4350         |
|    policy_gradient_loss | -0.00235     |
|    std                  | 0.684        |
|    value_loss           | 0.0483       |
------------------------------------------
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 592          |
|    iterations           | 437          |
|    time_elapsed         | 1510         |
|    total_timesteps      | 894976       |
| train/                  |              |
|    approx_kl            | 0.0026777752 |
|    clip_fraction        | 0.0107       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.07        |
|    explained_variance   | 0.891        |
|    learning_rate        | 3.54e-05     |
|    loss                 | -0.0105      |
|    n_updates            | 4360         |
|    policy_gradient_loss | -0.00261     |
|    std                  | 0.683        |
|    value_loss           | 0.00185      |
------------------------------------------
box reached target
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 592         |
|    iterations           | 438         |
|    time_elapsed         | 1513        |
|    total_timesteps      | 897024      |
| train/                  |             |
|    approx_kl            | 0.004372289 |
|    clip_fraction        | 0.0137      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.07       |
|    explained_variance   | 0.978       |
|    learning_rate        | 3.54e-05    |
|    loss                 | -0.00565    |
|    n_updates            | 4370        |
|    policy_gradient_loss | -0.00193    |
|    std                  | 0.681       |
|    value_loss           | 0.00468     |
-----------------------------------------
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 592          |
|    iterations           | 439          |
|    time_elapsed         | 1517         |
|    total_timesteps      | 899072       |
| train/                  |              |
|    approx_kl            | 0.0042093187 |
|    clip_fraction        | 0.0206       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.06        |
|    explained_variance   | 0.981        |
|    learning_rate        | 3.54e-05     |
|    loss                 | -0.0277      |
|    n_updates            | 4380         |
|    policy_gradient_loss | -0.00287     |
|    std                  | 0.681        |
|    value_loss           | 0.00636      |
------------------------------------------
box reached target
Eval num_timesteps=900000, episode_reward=0.51 +/- 2.48
Episode length: 428.40 +/- 143.20
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 428         |
|    mean_reward          | 0.506       |
| time/                   |             |
|    total_timesteps      | 900000      |
| train/                  |             |
|    approx_kl            | 0.004144515 |
|    clip_fraction        | 0.0201      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.06       |
|    explained_variance   | 0.977       |
|    learning_rate        | 3.54e-05    |
|    loss                 | -0.0159     |
|    n_updates            | 4390        |
|    policy_gradient_loss | -0.00424    |
|    std                  | 0.681       |
|    value_loss           | 0.00454     |
-----------------------------------------
-------------------------------
| time/              |        |
|    fps             | 592    |
|    iterations      | 440    |
|    time_elapsed    | 1521   |
|    total_timesteps | 901120 |
-------------------------------
box reached target
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 592          |
|    iterations           | 441          |
|    time_elapsed         | 1524         |
|    total_timesteps      | 903168       |
| train/                  |              |
|    approx_kl            | 0.0023514223 |
|    clip_fraction        | 0.0102       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.07        |
|    explained_variance   | 0.981        |
|    learning_rate        | 3.54e-05     |
|    loss                 | -0.0112      |
|    n_updates            | 4400         |
|    policy_gradient_loss | -0.00239     |
|    std                  | 0.682        |
|    value_loss           | 0.00276      |
------------------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 592         |
|    iterations           | 442         |
|    time_elapsed         | 1528        |
|    total_timesteps      | 905216      |
| train/                  |             |
|    approx_kl            | 0.002840417 |
|    clip_fraction        | 0.0122      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.07       |
|    explained_variance   | 0.955       |
|    learning_rate        | 3.54e-05    |
|    loss                 | -0.00467    |
|    n_updates            | 4410        |
|    policy_gradient_loss | -0.00233    |
|    std                  | 0.681       |
|    value_loss           | 0.0146      |
-----------------------------------------
box reached target
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 592         |
|    iterations           | 443         |
|    time_elapsed         | 1531        |
|    total_timesteps      | 907264      |
| train/                  |             |
|    approx_kl            | 0.004239713 |
|    clip_fraction        | 0.0225      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.06       |
|    explained_variance   | 0.977       |
|    learning_rate        | 3.54e-05    |
|    loss                 | -0.000239   |
|    n_updates            | 4420        |
|    policy_gradient_loss | -0.00301    |
|    std                  | 0.682       |
|    value_loss           | 0.00456     |
-----------------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 592         |
|    iterations           | 444         |
|    time_elapsed         | 1534        |
|    total_timesteps      | 909312      |
| train/                  |             |
|    approx_kl            | 0.004014572 |
|    clip_fraction        | 0.0247      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.06       |
|    explained_variance   | 0.984       |
|    learning_rate        | 3.54e-05    |
|    loss                 | 0.000359    |
|    n_updates            | 4430        |
|    policy_gradient_loss | -0.00345    |
|    std                  | 0.68        |
|    value_loss           | 0.00883     |
-----------------------------------------
Eval num_timesteps=910000, episode_reward=-0.70 +/- 0.61
Episode length: 500.00 +/- 0.00
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 500          |
|    mean_reward          | -0.696       |
| time/                   |              |
|    total_timesteps      | 910000       |
| train/                  |              |
|    approx_kl            | 0.0027272606 |
|    clip_fraction        | 0.0119       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.06        |
|    explained_variance   | 0.971        |
|    learning_rate        | 3.55e-05     |
|    loss                 | -0.0312      |
|    n_updates            | 4440         |
|    policy_gradient_loss | -0.00271     |
|    std                  | 0.68         |
|    value_loss           | 0.00694      |
------------------------------------------
box reached target
-------------------------------
| time/              |        |
|    fps             | 592    |
|    iterations      | 445    |
|    time_elapsed    | 1539   |
|    total_timesteps | 911360 |
-------------------------------
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 592          |
|    iterations           | 446          |
|    time_elapsed         | 1542         |
|    total_timesteps      | 913408       |
| train/                  |              |
|    approx_kl            | 0.0027762537 |
|    clip_fraction        | 0.00713      |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.06        |
|    explained_variance   | 0.834        |
|    learning_rate        | 3.55e-05     |
|    loss                 | -0.002       |
|    n_updates            | 4450         |
|    policy_gradient_loss | -0.00125     |
|    std                  | 0.679        |
|    value_loss           | 0.0212       |
------------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 592         |
|    iterations           | 447         |
|    time_elapsed         | 1545        |
|    total_timesteps      | 915456      |
| train/                  |             |
|    approx_kl            | 0.003890507 |
|    clip_fraction        | 0.00854     |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.06       |
|    explained_variance   | 0.898       |
|    learning_rate        | 3.55e-05    |
|    loss                 | 0.000331    |
|    n_updates            | 4460        |
|    policy_gradient_loss | -0.0037     |
|    std                  | 0.679       |
|    value_loss           | 0.00699     |
-----------------------------------------
box reached target
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 592          |
|    iterations           | 448          |
|    time_elapsed         | 1548         |
|    total_timesteps      | 917504       |
| train/                  |              |
|    approx_kl            | 0.0021256786 |
|    clip_fraction        | 0.0107       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.05        |
|    explained_variance   | 0.904        |
|    learning_rate        | 3.55e-05     |
|    loss                 | 0.0247       |
|    n_updates            | 4470         |
|    policy_gradient_loss | -0.00235     |
|    std                  | 0.677        |
|    value_loss           | 0.00277      |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 592          |
|    iterations           | 449          |
|    time_elapsed         | 1551         |
|    total_timesteps      | 919552       |
| train/                  |              |
|    approx_kl            | 0.0032184892 |
|    clip_fraction        | 0.0144       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.05        |
|    explained_variance   | 0.842        |
|    learning_rate        | 3.55e-05     |
|    loss                 | 0.0613       |
|    n_updates            | 4480         |
|    policy_gradient_loss | -0.00368     |
|    std                  | 0.677        |
|    value_loss           | 0.0566       |
------------------------------------------
box reached target
Eval num_timesteps=920000, episode_reward=-0.81 +/- 1.15
Episode length: 500.00 +/- 0.00
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 500          |
|    mean_reward          | -0.809       |
| time/                   |              |
|    total_timesteps      | 920000       |
| train/                  |              |
|    approx_kl            | 0.0073024556 |
|    clip_fraction        | 0.0546       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.05        |
|    explained_variance   | 0.917        |
|    learning_rate        | 3.55e-05     |
|    loss                 | 0.0107       |
|    n_updates            | 4490         |
|    policy_gradient_loss | -0.00816     |
|    std                  | 0.678        |
|    value_loss           | 0.00171      |
------------------------------------------
box reached target
-------------------------------
| time/              |        |
|    fps             | 592    |
|    iterations      | 450    |
|    time_elapsed    | 1556   |
|    total_timesteps | 921600 |
-------------------------------
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 592          |
|    iterations           | 451          |
|    time_elapsed         | 1559         |
|    total_timesteps      | 923648       |
| train/                  |              |
|    approx_kl            | 0.0032148298 |
|    clip_fraction        | 0.014        |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.06        |
|    explained_variance   | 0.931        |
|    learning_rate        | 3.55e-05     |
|    loss                 | 0.0686       |
|    n_updates            | 4500         |
|    policy_gradient_loss | -0.00167     |
|    std                  | 0.679        |
|    value_loss           | 0.0478       |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 592          |
|    iterations           | 452          |
|    time_elapsed         | 1562         |
|    total_timesteps      | 925696       |
| train/                  |              |
|    approx_kl            | 0.0025817107 |
|    clip_fraction        | 0.00977      |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.06        |
|    explained_variance   | 0.894        |
|    learning_rate        | 3.55e-05     |
|    loss                 | 0.00314      |
|    n_updates            | 4510         |
|    policy_gradient_loss | -0.00239     |
|    std                  | 0.678        |
|    value_loss           | 0.0304       |
------------------------------------------
box reached target
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 592          |
|    iterations           | 453          |
|    time_elapsed         | 1566         |
|    total_timesteps      | 927744       |
| train/                  |              |
|    approx_kl            | 0.0053542256 |
|    clip_fraction        | 0.0337       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.06        |
|    explained_variance   | 0.753        |
|    learning_rate        | 3.56e-05     |
|    loss                 | -0.0108      |
|    n_updates            | 4520         |
|    policy_gradient_loss | -0.00421     |
|    std                  | 0.678        |
|    value_loss           | 0.00591      |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 592          |
|    iterations           | 454          |
|    time_elapsed         | 1569         |
|    total_timesteps      | 929792       |
| train/                  |              |
|    approx_kl            | 0.0043885214 |
|    clip_fraction        | 0.0188       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.05        |
|    explained_variance   | 0.891        |
|    learning_rate        | 3.56e-05     |
|    loss                 | -0.00383     |
|    n_updates            | 4530         |
|    policy_gradient_loss | -0.00336     |
|    std                  | 0.677        |
|    value_loss           | 0.0282       |
------------------------------------------
box reached target
box reached target
Eval num_timesteps=930000, episode_reward=-0.01 +/- 2.73
Episode length: 430.20 +/- 139.60
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 430         |
|    mean_reward          | -0.0138     |
| time/                   |             |
|    total_timesteps      | 930000      |
| train/                  |             |
|    approx_kl            | 0.002200962 |
|    clip_fraction        | 0.00835     |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.05       |
|    explained_variance   | 0.893       |
|    learning_rate        | 3.56e-05    |
|    loss                 | -0.00387    |
|    n_updates            | 4540        |
|    policy_gradient_loss | -0.00189    |
|    std                  | 0.678       |
|    value_loss           | 0.00118     |
-----------------------------------------
-------------------------------
| time/              |        |
|    fps             | 592    |
|    iterations      | 455    |
|    time_elapsed    | 1573   |
|    total_timesteps | 931840 |
-------------------------------
box reached target
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 592          |
|    iterations           | 456          |
|    time_elapsed         | 1577         |
|    total_timesteps      | 933888       |
| train/                  |              |
|    approx_kl            | 0.0029582693 |
|    clip_fraction        | 0.00723      |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.05        |
|    explained_variance   | 0.93         |
|    learning_rate        | 3.56e-05     |
|    loss                 | 0.00165      |
|    n_updates            | 4550         |
|    policy_gradient_loss | -0.00411     |
|    std                  | 0.677        |
|    value_loss           | 0.0105       |
------------------------------------------
box reached target
box reached target
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 592          |
|    iterations           | 457          |
|    time_elapsed         | 1580         |
|    total_timesteps      | 935936       |
| train/                  |              |
|    approx_kl            | 0.0029298333 |
|    clip_fraction        | 0.00771      |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.05        |
|    explained_variance   | 0.84         |
|    learning_rate        | 3.56e-05     |
|    loss                 | -0.00724     |
|    n_updates            | 4560         |
|    policy_gradient_loss | -0.00294     |
|    std                  | 0.678        |
|    value_loss           | 0.0439       |
------------------------------------------
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 592          |
|    iterations           | 458          |
|    time_elapsed         | 1583         |
|    total_timesteps      | 937984       |
| train/                  |              |
|    approx_kl            | 0.0029691206 |
|    clip_fraction        | 0.0187       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.05        |
|    explained_variance   | 0.872        |
|    learning_rate        | 3.56e-05     |
|    loss                 | -0.0232      |
|    n_updates            | 4570         |
|    policy_gradient_loss | -0.00273     |
|    std                  | 0.677        |
|    value_loss           | 0.0699       |
------------------------------------------
box reached target
box reached target
Eval num_timesteps=940000, episode_reward=0.27 +/- 2.55
Episode length: 434.00 +/- 132.00
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 434          |
|    mean_reward          | 0.274        |
| time/                   |              |
|    total_timesteps      | 940000       |
| train/                  |              |
|    approx_kl            | 0.0030987419 |
|    clip_fraction        | 0.0143       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.05        |
|    explained_variance   | 0.923        |
|    learning_rate        | 3.56e-05     |
|    loss                 | -0.0187      |
|    n_updates            | 4580         |
|    policy_gradient_loss | -0.00402     |
|    std                  | 0.676        |
|    value_loss           | 0.0165       |
------------------------------------------
-------------------------------
| time/              |        |
|    fps             | 591    |
|    iterations      | 459    |
|    time_elapsed    | 1587   |
|    total_timesteps | 940032 |
-------------------------------
box reached target
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 592          |
|    iterations           | 460          |
|    time_elapsed         | 1591         |
|    total_timesteps      | 942080       |
| train/                  |              |
|    approx_kl            | 0.0053525507 |
|    clip_fraction        | 0.0241       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.05        |
|    explained_variance   | 0.915        |
|    learning_rate        | 3.56e-05     |
|    loss                 | 0.000923     |
|    n_updates            | 4590         |
|    policy_gradient_loss | -0.00518     |
|    std                  | 0.675        |
|    value_loss           | 0.011        |
------------------------------------------
box reached target
box reached target
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 592          |
|    iterations           | 461          |
|    time_elapsed         | 1594         |
|    total_timesteps      | 944128       |
| train/                  |              |
|    approx_kl            | 0.0034762998 |
|    clip_fraction        | 0.0175       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.04        |
|    explained_variance   | 0.79         |
|    learning_rate        | 3.57e-05     |
|    loss                 | 0.00464      |
|    n_updates            | 4600         |
|    policy_gradient_loss | -0.00327     |
|    std                  | 0.673        |
|    value_loss           | 0.0555       |
------------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 592         |
|    iterations           | 462         |
|    time_elapsed         | 1597        |
|    total_timesteps      | 946176      |
| train/                  |             |
|    approx_kl            | 0.006128135 |
|    clip_fraction        | 0.0393      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.04       |
|    explained_variance   | 0.977       |
|    learning_rate        | 3.57e-05    |
|    loss                 | -0.00372    |
|    n_updates            | 4610        |
|    policy_gradient_loss | -0.00616    |
|    std                  | 0.673       |
|    value_loss           | 0.0191      |
-----------------------------------------
box reached target
box reached target
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 592          |
|    iterations           | 463          |
|    time_elapsed         | 1600         |
|    total_timesteps      | 948224       |
| train/                  |              |
|    approx_kl            | 0.0034227152 |
|    clip_fraction        | 0.018        |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.04        |
|    explained_variance   | 0.867        |
|    learning_rate        | 3.57e-05     |
|    loss                 | 0.00074      |
|    n_updates            | 4620         |
|    policy_gradient_loss | -0.00348     |
|    std                  | 0.673        |
|    value_loss           | 0.00324      |
------------------------------------------
box reached target
box reached target
Eval num_timesteps=950000, episode_reward=0.77 +/- 2.35
Episode length: 429.00 +/- 142.00
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 429        |
|    mean_reward          | 0.766      |
| time/                   |            |
|    total_timesteps      | 950000     |
| train/                  |            |
|    approx_kl            | 0.00355708 |
|    clip_fraction        | 0.00835    |
|    clip_range           | 0.2        |
|    entropy_loss         | -2.04      |
|    explained_variance   | 0.961      |
|    learning_rate        | 3.57e-05   |
|    loss                 | 0.0203     |
|    n_updates            | 4630       |
|    policy_gradient_loss | -0.00243   |
|    std                  | 0.672      |
|    value_loss           | 0.0137     |
----------------------------------------
box reached target
-------------------------------
| time/              |        |
|    fps             | 592    |
|    iterations      | 464    |
|    time_elapsed    | 1605   |
|    total_timesteps | 950272 |
-------------------------------
box reached target
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 592          |
|    iterations           | 465          |
|    time_elapsed         | 1608         |
|    total_timesteps      | 952320       |
| train/                  |              |
|    approx_kl            | 0.0022205622 |
|    clip_fraction        | 0.01         |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.04        |
|    explained_variance   | 0.908        |
|    learning_rate        | 3.57e-05     |
|    loss                 | -0.00322     |
|    n_updates            | 4640         |
|    policy_gradient_loss | -0.00154     |
|    std                  | 0.672        |
|    value_loss           | 0.0383       |
------------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 592         |
|    iterations           | 466         |
|    time_elapsed         | 1611        |
|    total_timesteps      | 954368      |
| train/                  |             |
|    approx_kl            | 0.002429224 |
|    clip_fraction        | 0.00571     |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.04       |
|    explained_variance   | 0.859       |
|    learning_rate        | 3.57e-05    |
|    loss                 | 0.027       |
|    n_updates            | 4650        |
|    policy_gradient_loss | -0.00182    |
|    std                  | 0.672       |
|    value_loss           | 0.0587      |
-----------------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 592         |
|    iterations           | 467         |
|    time_elapsed         | 1614        |
|    total_timesteps      | 956416      |
| train/                  |             |
|    approx_kl            | 0.003260797 |
|    clip_fraction        | 0.015       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.04       |
|    explained_variance   | 0.761       |
|    learning_rate        | 3.57e-05    |
|    loss                 | 0.0062      |
|    n_updates            | 4660        |
|    policy_gradient_loss | -0.00397    |
|    std                  | 0.673       |
|    value_loss           | 0.00254     |
-----------------------------------------
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 592          |
|    iterations           | 468          |
|    time_elapsed         | 1617         |
|    total_timesteps      | 958464       |
| train/                  |              |
|    approx_kl            | 0.0038893446 |
|    clip_fraction        | 0.0203       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.04        |
|    explained_variance   | 0.925        |
|    learning_rate        | 3.57e-05     |
|    loss                 | 0.0113       |
|    n_updates            | 4670         |
|    policy_gradient_loss | -0.00335     |
|    std                  | 0.672        |
|    value_loss           | 0.00672      |
------------------------------------------
box reached target
box reached target
Eval num_timesteps=960000, episode_reward=0.59 +/- 2.44
Episode length: 428.60 +/- 142.80
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 429          |
|    mean_reward          | 0.588        |
| time/                   |              |
|    total_timesteps      | 960000       |
| train/                  |              |
|    approx_kl            | 0.0046883677 |
|    clip_fraction        | 0.0227       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.03        |
|    explained_variance   | 0.949        |
|    learning_rate        | 3.58e-05     |
|    loss                 | 0.0128       |
|    n_updates            | 4680         |
|    policy_gradient_loss | -0.00425     |
|    std                  | 0.67         |
|    value_loss           | 0.0113       |
------------------------------------------
box reached target
-------------------------------
| time/              |        |
|    fps             | 592    |
|    iterations      | 469    |
|    time_elapsed    | 1622   |
|    total_timesteps | 960512 |
-------------------------------
box reached target
box reached target
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 592          |
|    iterations           | 470          |
|    time_elapsed         | 1625         |
|    total_timesteps      | 962560       |
| train/                  |              |
|    approx_kl            | 0.0041540107 |
|    clip_fraction        | 0.0326       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.03        |
|    explained_variance   | 0.949        |
|    learning_rate        | 3.58e-05     |
|    loss                 | -0.0227      |
|    n_updates            | 4690         |
|    policy_gradient_loss | -0.00494     |
|    std                  | 0.67         |
|    value_loss           | 0.014        |
------------------------------------------
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 592          |
|    iterations           | 471          |
|    time_elapsed         | 1628         |
|    total_timesteps      | 964608       |
| train/                  |              |
|    approx_kl            | 0.0032848134 |
|    clip_fraction        | 0.0062       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.03        |
|    explained_variance   | 0.896        |
|    learning_rate        | 3.58e-05     |
|    loss                 | 0.00805      |
|    n_updates            | 4700         |
|    policy_gradient_loss | -0.00179     |
|    std                  | 0.669        |
|    value_loss           | 0.0495       |
------------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 592         |
|    iterations           | 472         |
|    time_elapsed         | 1631        |
|    total_timesteps      | 966656      |
| train/                  |             |
|    approx_kl            | 0.005119432 |
|    clip_fraction        | 0.0292      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.03       |
|    explained_variance   | 0.952       |
|    learning_rate        | 3.58e-05    |
|    loss                 | 0.0142      |
|    n_updates            | 4710        |
|    policy_gradient_loss | -0.00686    |
|    std                  | 0.669       |
|    value_loss           | 0.0123      |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 592         |
|    iterations           | 473         |
|    time_elapsed         | 1634        |
|    total_timesteps      | 968704      |
| train/                  |             |
|    approx_kl            | 0.004382357 |
|    clip_fraction        | 0.0355      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.03       |
|    explained_variance   | 0.939       |
|    learning_rate        | 3.58e-05    |
|    loss                 | -0.00373    |
|    n_updates            | 4720        |
|    policy_gradient_loss | -0.00529    |
|    std                  | 0.672       |
|    value_loss           | 0.00391     |
-----------------------------------------
box reached target
box reached target
box reached target
box reached target
box reached target
box reached target
Eval num_timesteps=970000, episode_reward=5.39 +/- 0.13
Episode length: 165.60 +/- 23.06
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 166         |
|    mean_reward          | 5.39        |
| time/                   |             |
|    total_timesteps      | 970000      |
| train/                  |             |
|    approx_kl            | 0.003662986 |
|    clip_fraction        | 0.0189      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.04       |
|    explained_variance   | 0.908       |
|    learning_rate        | 3.58e-05    |
|    loss                 | 0.00765     |
|    n_updates            | 4730        |
|    policy_gradient_loss | -0.00198    |
|    std                  | 0.672       |
|    value_loss           | 0.00256     |
-----------------------------------------
New best mean reward!
box reached target
box reached target
box reached target
-------------------------------
| time/              |        |
|    fps             | 592    |
|    iterations      | 474    |
|    time_elapsed    | 1638   |
|    total_timesteps | 970752 |
-------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 592          |
|    iterations           | 475          |
|    time_elapsed         | 1641         |
|    total_timesteps      | 972800       |
| train/                  |              |
|    approx_kl            | 0.0049439296 |
|    clip_fraction        | 0.0227       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.03        |
|    explained_variance   | 0.894        |
|    learning_rate        | 3.58e-05     |
|    loss                 | -0.0215      |
|    n_updates            | 4740         |
|    policy_gradient_loss | -0.00443     |
|    std                  | 0.67         |
|    value_loss           | 0.0617       |
------------------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 592         |
|    iterations           | 476         |
|    time_elapsed         | 1644        |
|    total_timesteps      | 974848      |
| train/                  |             |
|    approx_kl            | 0.004920097 |
|    clip_fraction        | 0.0281      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.03       |
|    explained_variance   | 0.685       |
|    learning_rate        | 3.58e-05    |
|    loss                 | -0.00895    |
|    n_updates            | 4750        |
|    policy_gradient_loss | -0.00409    |
|    std                  | 0.669       |
|    value_loss           | 0.00263     |
-----------------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 592         |
|    iterations           | 477         |
|    time_elapsed         | 1648        |
|    total_timesteps      | 976896      |
| train/                  |             |
|    approx_kl            | 0.006092211 |
|    clip_fraction        | 0.0472      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.03       |
|    explained_variance   | 0.951       |
|    learning_rate        | 3.58e-05    |
|    loss                 | -0.0113     |
|    n_updates            | 4760        |
|    policy_gradient_loss | -0.00681    |
|    std                  | 0.669       |
|    value_loss           | 0.00575     |
-----------------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 592         |
|    iterations           | 478         |
|    time_elapsed         | 1651        |
|    total_timesteps      | 978944      |
| train/                  |             |
|    approx_kl            | 0.004736035 |
|    clip_fraction        | 0.0259      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.03       |
|    explained_variance   | 0.902       |
|    learning_rate        | 3.59e-05    |
|    loss                 | 0.0075      |
|    n_updates            | 4770        |
|    policy_gradient_loss | -0.00531    |
|    std                  | 0.669       |
|    value_loss           | 0.017       |
-----------------------------------------
box reached target
Eval num_timesteps=980000, episode_reward=0.51 +/- 2.42
Episode length: 430.20 +/- 139.60
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 430          |
|    mean_reward          | 0.513        |
| time/                   |              |
|    total_timesteps      | 980000       |
| train/                  |              |
|    approx_kl            | 0.0030559483 |
|    clip_fraction        | 0.00645      |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.03        |
|    explained_variance   | 0.862        |
|    learning_rate        | 3.59e-05     |
|    loss                 | -0.0213      |
|    n_updates            | 4780         |
|    policy_gradient_loss | -0.00193     |
|    std                  | 0.668        |
|    value_loss           | 0.012        |
------------------------------------------
-------------------------------
| time/              |        |
|    fps             | 592    |
|    iterations      | 479    |
|    time_elapsed    | 1655   |
|    total_timesteps | 980992 |
-------------------------------
box reached target
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 592         |
|    iterations           | 480         |
|    time_elapsed         | 1658        |
|    total_timesteps      | 983040      |
| train/                  |             |
|    approx_kl            | 0.004798434 |
|    clip_fraction        | 0.0292      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.03       |
|    explained_variance   | 0.836       |
|    learning_rate        | 3.59e-05    |
|    loss                 | 0.0161      |
|    n_updates            | 4790        |
|    policy_gradient_loss | -0.00386    |
|    std                  | 0.668       |
|    value_loss           | 0.00881     |
-----------------------------------------
box reached target
box reached target
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 592         |
|    iterations           | 481         |
|    time_elapsed         | 1662        |
|    total_timesteps      | 985088      |
| train/                  |             |
|    approx_kl            | 0.003816278 |
|    clip_fraction        | 0.0218      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.03       |
|    explained_variance   | 0.755       |
|    learning_rate        | 3.59e-05    |
|    loss                 | -0.00991    |
|    n_updates            | 4800        |
|    policy_gradient_loss | -0.00291    |
|    std                  | 0.668       |
|    value_loss           | 0.058       |
-----------------------------------------
box reached target
box reached target
box reached target
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 592         |
|    iterations           | 482         |
|    time_elapsed         | 1665        |
|    total_timesteps      | 987136      |
| train/                  |             |
|    approx_kl            | 0.003294503 |
|    clip_fraction        | 0.0112      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.02       |
|    explained_variance   | 0.98        |
|    learning_rate        | 3.59e-05    |
|    loss                 | 0.00712     |
|    n_updates            | 4810        |
|    policy_gradient_loss | -0.00295    |
|    std                  | 0.667       |
|    value_loss           | 0.012       |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 592         |
|    iterations           | 483         |
|    time_elapsed         | 1668        |
|    total_timesteps      | 989184      |
| train/                  |             |
|    approx_kl            | 0.004057648 |
|    clip_fraction        | 0.0204      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.02       |
|    explained_variance   | 0.869       |
|    learning_rate        | 3.59e-05    |
|    loss                 | -0.00286    |
|    n_updates            | 4820        |
|    policy_gradient_loss | -0.0035     |
|    std                  | 0.667       |
|    value_loss           | 0.0601      |
-----------------------------------------
Eval num_timesteps=990000, episode_reward=-1.36 +/- 0.73
Episode length: 500.00 +/- 0.00
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 500          |
|    mean_reward          | -1.36        |
| time/                   |              |
|    total_timesteps      | 990000       |
| train/                  |              |
|    approx_kl            | 0.0033290188 |
|    clip_fraction        | 0.0185       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.02        |
|    explained_variance   | 0.926        |
|    learning_rate        | 3.59e-05     |
|    loss                 | -0.0175      |
|    n_updates            | 4830         |
|    policy_gradient_loss | -0.0036      |
|    std                  | 0.666        |
|    value_loss           | 0.00637      |
------------------------------------------
box reached target
box reached target
-------------------------------
| time/              |        |
|    fps             | 592    |
|    iterations      | 484    |
|    time_elapsed    | 1673   |
|    total_timesteps | 991232 |
-------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 592         |
|    iterations           | 485         |
|    time_elapsed         | 1676        |
|    total_timesteps      | 993280      |
| train/                  |             |
|    approx_kl            | 0.004206634 |
|    clip_fraction        | 0.022       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.02       |
|    explained_variance   | 0.986       |
|    learning_rate        | 3.59e-05    |
|    loss                 | -0.0134     |
|    n_updates            | 4840        |
|    policy_gradient_loss | -0.00528    |
|    std                  | 0.665       |
|    value_loss           | 0.00623     |
-----------------------------------------
box reached target
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 592         |
|    iterations           | 486         |
|    time_elapsed         | 1679        |
|    total_timesteps      | 995328      |
| train/                  |             |
|    approx_kl            | 0.004729162 |
|    clip_fraction        | 0.0295      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.02       |
|    explained_variance   | 0.939       |
|    learning_rate        | 3.6e-05     |
|    loss                 | -0.0107     |
|    n_updates            | 4850        |
|    policy_gradient_loss | -0.0047     |
|    std                  | 0.665       |
|    value_loss           | 0.00298     |
-----------------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 592         |
|    iterations           | 487         |
|    time_elapsed         | 1682        |
|    total_timesteps      | 997376      |
| train/                  |             |
|    approx_kl            | 0.004959112 |
|    clip_fraction        | 0.025       |
|    clip_range           | 0.2         |
|    entropy_loss         | -2.01       |
|    explained_variance   | 0.959       |
|    learning_rate        | 3.6e-05     |
|    loss                 | -0.0323     |
|    n_updates            | 4860        |
|    policy_gradient_loss | -0.00571    |
|    std                  | 0.663       |
|    value_loss           | 0.0118      |
-----------------------------------------
box reached target
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 592          |
|    iterations           | 488          |
|    time_elapsed         | 1685         |
|    total_timesteps      | 999424       |
| train/                  |              |
|    approx_kl            | 0.0031022064 |
|    clip_fraction        | 0.015        |
|    clip_range           | 0.2          |
|    entropy_loss         | -2.01        |
|    explained_variance   | 0.945        |
|    learning_rate        | 3.6e-05      |
|    loss                 | -0.00404     |
|    n_updates            | 4870         |
|    policy_gradient_loss | -0.00322     |
|    std                  | 0.661        |
|    value_loss           | 0.00749      |
------------------------------------------
box reached target
box reached target
Eval num_timesteps=1000000, episode_reward=1.98 +/- 2.92
Episode length: 367.40 +/- 162.54
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 367         |
|    mean_reward          | 1.98        |
| time/                   |             |
|    total_timesteps      | 1000000     |
| train/                  |             |
|    approx_kl            | 0.003991991 |
|    clip_fraction        | 0.0167      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2          |
|    explained_variance   | 0.98        |
|    learning_rate        | 3.6e-05     |
|    loss                 | -0.00387    |
|    n_updates            | 4880        |
|    policy_gradient_loss | -0.00478    |
|    std                  | 0.66        |
|    value_loss           | 0.00828     |
-----------------------------------------
box reached target
box reached target
--------------------------------
| time/              |         |
|    fps             | 592     |
|    iterations      | 489     |
|    time_elapsed    | 1690    |
|    total_timesteps | 1001472 |
--------------------------------
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 592          |
|    iterations           | 490          |
|    time_elapsed         | 1693         |
|    total_timesteps      | 1003520      |
| train/                  |              |
|    approx_kl            | 0.0016798273 |
|    clip_fraction        | 0.00439      |
|    clip_range           | 0.2          |
|    entropy_loss         | -2           |
|    explained_variance   | 0.96         |
|    learning_rate        | 3.6e-05      |
|    loss                 | 0.00471      |
|    n_updates            | 4890         |
|    policy_gradient_loss | -0.00225     |
|    std                  | 0.659        |
|    value_loss           | 0.00872      |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 592          |
|    iterations           | 491          |
|    time_elapsed         | 1696         |
|    total_timesteps      | 1005568      |
| train/                  |              |
|    approx_kl            | 0.0039720163 |
|    clip_fraction        | 0.0128       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2           |
|    explained_variance   | 0.904        |
|    learning_rate        | 3.6e-05      |
|    loss                 | 0.0234       |
|    n_updates            | 4900         |
|    policy_gradient_loss | -0.00294     |
|    std                  | 0.659        |
|    value_loss           | 0.0286       |
------------------------------------------
box reached target
box reached target
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 592         |
|    iterations           | 492         |
|    time_elapsed         | 1699        |
|    total_timesteps      | 1007616     |
| train/                  |             |
|    approx_kl            | 0.004083193 |
|    clip_fraction        | 0.0124      |
|    clip_range           | 0.2         |
|    entropy_loss         | -2          |
|    explained_variance   | 0.949       |
|    learning_rate        | 3.6e-05     |
|    loss                 | -0.0178     |
|    n_updates            | 4910        |
|    policy_gradient_loss | -0.00199    |
|    std                  | 0.659       |
|    value_loss           | 0.00319     |
-----------------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 592        |
|    iterations           | 493        |
|    time_elapsed         | 1702       |
|    total_timesteps      | 1009664    |
| train/                  |            |
|    approx_kl            | 0.00787066 |
|    clip_fraction        | 0.0691     |
|    clip_range           | 0.2        |
|    entropy_loss         | -2         |
|    explained_variance   | 0.943      |
|    learning_rate        | 3.6e-05    |
|    loss                 | 0.000129   |
|    n_updates            | 4920       |
|    policy_gradient_loss | -0.0066    |
|    std                  | 0.659      |
|    value_loss           | 0.0247     |
----------------------------------------
Eval num_timesteps=1010000, episode_reward=-0.14 +/- 0.73
Episode length: 500.00 +/- 0.00
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 500          |
|    mean_reward          | -0.141       |
| time/                   |              |
|    total_timesteps      | 1010000      |
| train/                  |              |
|    approx_kl            | 0.0025603874 |
|    clip_fraction        | 0.0145       |
|    clip_range           | 0.2          |
|    entropy_loss         | -2           |
|    explained_variance   | 0.922        |
|    learning_rate        | 3.61e-05     |
|    loss                 | -0.00485     |
|    n_updates            | 4930         |
|    policy_gradient_loss | -0.00391     |
|    std                  | 0.657        |
|    value_loss           | 0.0247       |
------------------------------------------
--------------------------------
| time/              |         |
|    fps             | 592     |
|    iterations      | 494     |
|    time_elapsed    | 1707    |
|    total_timesteps | 1011712 |
--------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 592         |
|    iterations           | 495         |
|    time_elapsed         | 1710        |
|    total_timesteps      | 1013760     |
| train/                  |             |
|    approx_kl            | 0.004359234 |
|    clip_fraction        | 0.0297      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.99       |
|    explained_variance   | 0.911       |
|    learning_rate        | 3.61e-05    |
|    loss                 | -0.00828    |
|    n_updates            | 4940        |
|    policy_gradient_loss | -0.00279    |
|    std                  | 0.657       |
|    value_loss           | 0.00209     |
-----------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 592         |
|    iterations           | 496         |
|    time_elapsed         | 1713        |
|    total_timesteps      | 1015808     |
| train/                  |             |
|    approx_kl            | 0.004339194 |
|    clip_fraction        | 0.0291      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.99       |
|    explained_variance   | 0.935       |
|    learning_rate        | 3.61e-05    |
|    loss                 | 0.012       |
|    n_updates            | 4950        |
|    policy_gradient_loss | -0.00444    |
|    std                  | 0.657       |
|    value_loss           | 0.0117      |
-----------------------------------------
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 592          |
|    iterations           | 497          |
|    time_elapsed         | 1717         |
|    total_timesteps      | 1017856      |
| train/                  |              |
|    approx_kl            | 0.0034105314 |
|    clip_fraction        | 0.0114       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.99        |
|    explained_variance   | 0.929        |
|    learning_rate        | 3.61e-05     |
|    loss                 | -0.0219      |
|    n_updates            | 4960         |
|    policy_gradient_loss | -0.00253     |
|    std                  | 0.657        |
|    value_loss           | 0.00268      |
------------------------------------------
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 592          |
|    iterations           | 498          |
|    time_elapsed         | 1720         |
|    total_timesteps      | 1019904      |
| train/                  |              |
|    approx_kl            | 0.0052441307 |
|    clip_fraction        | 0.0217       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.99        |
|    explained_variance   | 0.931        |
|    learning_rate        | 3.61e-05     |
|    loss                 | 0.0133       |
|    n_updates            | 4970         |
|    policy_gradient_loss | -0.00384     |
|    std                  | 0.656        |
|    value_loss           | 0.018        |
------------------------------------------
Eval num_timesteps=1020000, episode_reward=-1.51 +/- 0.75
Episode length: 500.00 +/- 0.00
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 500         |
|    mean_reward          | -1.51       |
| time/                   |             |
|    total_timesteps      | 1020000     |
| train/                  |             |
|    approx_kl            | 0.004484944 |
|    clip_fraction        | 0.0318      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.99       |
|    explained_variance   | 0.848       |
|    learning_rate        | 3.61e-05    |
|    loss                 | 0.00223     |
|    n_updates            | 4980        |
|    policy_gradient_loss | -0.00465    |
|    std                  | 0.656       |
|    value_loss           | 0.0429      |
-----------------------------------------
box reached target
box reached target
--------------------------------
| time/              |         |
|    fps             | 592     |
|    iterations      | 499     |
|    time_elapsed    | 1725    |
|    total_timesteps | 1021952 |
--------------------------------
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 592          |
|    iterations           | 500          |
|    time_elapsed         | 1728         |
|    total_timesteps      | 1024000      |
| train/                  |              |
|    approx_kl            | 0.0027849618 |
|    clip_fraction        | 0.00937      |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.99        |
|    explained_variance   | 0.965        |
|    learning_rate        | 3.61e-05     |
|    loss                 | 0.000913     |
|    n_updates            | 4990         |
|    policy_gradient_loss | -0.00215     |
|    std                  | 0.655        |
|    value_loss           | 0.0174       |
------------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 592         |
|    iterations           | 501         |
|    time_elapsed         | 1731        |
|    total_timesteps      | 1026048     |
| train/                  |             |
|    approx_kl            | 0.004814466 |
|    clip_fraction        | 0.0231      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.99       |
|    explained_variance   | 0.986       |
|    learning_rate        | 3.61e-05    |
|    loss                 | -0.0251     |
|    n_updates            | 5000        |
|    policy_gradient_loss | -0.00442    |
|    std                  | 0.656       |
|    value_loss           | 0.00243     |
-----------------------------------------
box reached target
box reached target
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 592          |
|    iterations           | 502          |
|    time_elapsed         | 1734         |
|    total_timesteps      | 1028096      |
| train/                  |              |
|    approx_kl            | 0.0043330304 |
|    clip_fraction        | 0.0326       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.99        |
|    explained_variance   | 0.874        |
|    learning_rate        | 3.62e-05     |
|    loss                 | -0.03        |
|    n_updates            | 5010         |
|    policy_gradient_loss | -0.00675     |
|    std                  | 0.657        |
|    value_loss           | 0.00391      |
------------------------------------------
box reached target
box reached target
Eval num_timesteps=1030000, episode_reward=0.60 +/- 2.45
Episode length: 428.40 +/- 143.20
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 428         |
|    mean_reward          | 0.6         |
| time/                   |             |
|    total_timesteps      | 1030000     |
| train/                  |             |
|    approx_kl            | 0.004362555 |
|    clip_fraction        | 0.0164      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.99       |
|    explained_variance   | 0.877       |
|    learning_rate        | 3.62e-05    |
|    loss                 | -0.00889    |
|    n_updates            | 5020        |
|    policy_gradient_loss | -0.00305    |
|    std                  | 0.658       |
|    value_loss           | 0.0444      |
-----------------------------------------
--------------------------------
| time/              |         |
|    fps             | 592     |
|    iterations      | 503     |
|    time_elapsed    | 1739    |
|    total_timesteps | 1030144 |
--------------------------------
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 592          |
|    iterations           | 504          |
|    time_elapsed         | 1742         |
|    total_timesteps      | 1032192      |
| train/                  |              |
|    approx_kl            | 0.0036753304 |
|    clip_fraction        | 0.0208       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.99        |
|    explained_variance   | 0.841        |
|    learning_rate        | 3.62e-05     |
|    loss                 | -0.00401     |
|    n_updates            | 5030         |
|    policy_gradient_loss | -0.00347     |
|    std                  | 0.656        |
|    value_loss           | 0.0323       |
------------------------------------------
box reached target
box reached target
box reached target
box reached target
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 592         |
|    iterations           | 505         |
|    time_elapsed         | 1745        |
|    total_timesteps      | 1034240     |
| train/                  |             |
|    approx_kl            | 0.004819751 |
|    clip_fraction        | 0.0263      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.99       |
|    explained_variance   | 0.981       |
|    learning_rate        | 3.62e-05    |
|    loss                 | -0.0224     |
|    n_updates            | 5040        |
|    policy_gradient_loss | -0.00555    |
|    std                  | 0.655       |
|    value_loss           | 0.00509     |
-----------------------------------------
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 592          |
|    iterations           | 506          |
|    time_elapsed         | 1748         |
|    total_timesteps      | 1036288      |
| train/                  |              |
|    approx_kl            | 0.0037000694 |
|    clip_fraction        | 0.0224       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.99        |
|    explained_variance   | 0.906        |
|    learning_rate        | 3.62e-05     |
|    loss                 | 0.0121       |
|    n_updates            | 5050         |
|    policy_gradient_loss | -0.00541     |
|    std                  | 0.654        |
|    value_loss           | 0.0631       |
------------------------------------------
box reached target
box reached target
box reached target
box reached target
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 592          |
|    iterations           | 507          |
|    time_elapsed         | 1752         |
|    total_timesteps      | 1038336      |
| train/                  |              |
|    approx_kl            | 0.0042303726 |
|    clip_fraction        | 0.0235       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.98        |
|    explained_variance   | 0.955        |
|    learning_rate        | 3.62e-05     |
|    loss                 | -0.00128     |
|    n_updates            | 5060         |
|    policy_gradient_loss | -0.00397     |
|    std                  | 0.654        |
|    value_loss           | 0.00961      |
------------------------------------------
box reached target
box reached target
Eval num_timesteps=1040000, episode_reward=0.97 +/- 2.47
Episode length: 445.20 +/- 109.60
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 445          |
|    mean_reward          | 0.969        |
| time/                   |              |
|    total_timesteps      | 1040000      |
| train/                  |              |
|    approx_kl            | 0.0022025113 |
|    clip_fraction        | 0.00259      |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.98        |
|    explained_variance   | 0.925        |
|    learning_rate        | 3.62e-05     |
|    loss                 | 0.00311      |
|    n_updates            | 5070         |
|    policy_gradient_loss | -0.00145     |
|    std                  | 0.654        |
|    value_loss           | 0.0579       |
------------------------------------------
--------------------------------
| time/              |         |
|    fps             | 592     |
|    iterations      | 508     |
|    time_elapsed    | 1756    |
|    total_timesteps | 1040384 |
--------------------------------
box reached target
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 592          |
|    iterations           | 509          |
|    time_elapsed         | 1759         |
|    total_timesteps      | 1042432      |
| train/                  |              |
|    approx_kl            | 0.0058377953 |
|    clip_fraction        | 0.0444       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.98        |
|    explained_variance   | 0.992        |
|    learning_rate        | 3.62e-05     |
|    loss                 | -0.021       |
|    n_updates            | 5080         |
|    policy_gradient_loss | -0.00712     |
|    std                  | 0.653        |
|    value_loss           | 0.00245      |
------------------------------------------
box reached target
box reached target
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 592          |
|    iterations           | 510          |
|    time_elapsed         | 1762         |
|    total_timesteps      | 1044480      |
| train/                  |              |
|    approx_kl            | 0.0034599009 |
|    clip_fraction        | 0.0268       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.98        |
|    explained_variance   | 0.954        |
|    learning_rate        | 3.63e-05     |
|    loss                 | -0.00862     |
|    n_updates            | 5090         |
|    policy_gradient_loss | -0.00287     |
|    std                  | 0.655        |
|    value_loss           | 0.0113       |
------------------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 592         |
|    iterations           | 511         |
|    time_elapsed         | 1766        |
|    total_timesteps      | 1046528     |
| train/                  |             |
|    approx_kl            | 0.001457771 |
|    clip_fraction        | 0.000928    |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.99       |
|    explained_variance   | 0.814       |
|    learning_rate        | 3.63e-05    |
|    loss                 | 0.0258      |
|    n_updates            | 5100        |
|    policy_gradient_loss | -0.000818   |
|    std                  | 0.654       |
|    value_loss           | 0.11        |
-----------------------------------------
box reached target
box reached target
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 592         |
|    iterations           | 512         |
|    time_elapsed         | 1769        |
|    total_timesteps      | 1048576     |
| train/                  |             |
|    approx_kl            | 0.003256009 |
|    clip_fraction        | 0.0248      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.99       |
|    explained_variance   | 0.975       |
|    learning_rate        | 3.63e-05    |
|    loss                 | 0.0117      |
|    n_updates            | 5110        |
|    policy_gradient_loss | -0.00454    |
|    std                  | 0.655       |
|    value_loss           | 0.00374     |
-----------------------------------------
box reached target
box reached target
Eval num_timesteps=1050000, episode_reward=-0.07 +/- 2.82
Episode length: 435.40 +/- 129.20
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 435          |
|    mean_reward          | -0.0699      |
| time/                   |              |
|    total_timesteps      | 1050000      |
| train/                  |              |
|    approx_kl            | 0.0034873672 |
|    clip_fraction        | 0.0194       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.99        |
|    explained_variance   | 0.92         |
|    learning_rate        | 3.63e-05     |
|    loss                 | 0.0157       |
|    n_updates            | 5120         |
|    policy_gradient_loss | -0.00421     |
|    std                  | 0.653        |
|    value_loss           | 0.0338       |
------------------------------------------
--------------------------------
| time/              |         |
|    fps             | 592     |
|    iterations      | 513     |
|    time_elapsed    | 1773    |
|    total_timesteps | 1050624 |
--------------------------------
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 592          |
|    iterations           | 514          |
|    time_elapsed         | 1777         |
|    total_timesteps      | 1052672      |
| train/                  |              |
|    approx_kl            | 0.0048177023 |
|    clip_fraction        | 0.03         |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.98        |
|    explained_variance   | 0.85         |
|    learning_rate        | 3.63e-05     |
|    loss                 | -0.0221      |
|    n_updates            | 5130         |
|    policy_gradient_loss | -0.00415     |
|    std                  | 0.653        |
|    value_loss           | 0.0196       |
------------------------------------------
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 592          |
|    iterations           | 515          |
|    time_elapsed         | 1780         |
|    total_timesteps      | 1054720      |
| train/                  |              |
|    approx_kl            | 0.0050397543 |
|    clip_fraction        | 0.0332       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.98        |
|    explained_variance   | 0.895        |
|    learning_rate        | 3.63e-05     |
|    loss                 | -0.0192      |
|    n_updates            | 5140         |
|    policy_gradient_loss | -0.00472     |
|    std                  | 0.653        |
|    value_loss           | 0.00889      |
------------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 592         |
|    iterations           | 516         |
|    time_elapsed         | 1783        |
|    total_timesteps      | 1056768     |
| train/                  |             |
|    approx_kl            | 0.004697329 |
|    clip_fraction        | 0.034       |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.98       |
|    explained_variance   | 0.817       |
|    learning_rate        | 3.63e-05    |
|    loss                 | 0.0166      |
|    n_updates            | 5150        |
|    policy_gradient_loss | -0.00231    |
|    std                  | 0.653       |
|    value_loss           | 0.0377      |
-----------------------------------------
box reached target
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 592         |
|    iterations           | 517         |
|    time_elapsed         | 1786        |
|    total_timesteps      | 1058816     |
| train/                  |             |
|    approx_kl            | 0.003041908 |
|    clip_fraction        | 0.00845     |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.98       |
|    explained_variance   | 0.924       |
|    learning_rate        | 3.63e-05    |
|    loss                 | -0.00233    |
|    n_updates            | 5160        |
|    policy_gradient_loss | -0.00292    |
|    std                  | 0.653       |
|    value_loss           | 0.00298     |
-----------------------------------------
box reached target
box reached target
Eval num_timesteps=1060000, episode_reward=0.63 +/- 2.45
Episode length: 441.40 +/- 117.20
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 441          |
|    mean_reward          | 0.633        |
| time/                   |              |
|    total_timesteps      | 1060000      |
| train/                  |              |
|    approx_kl            | 0.0040176194 |
|    clip_fraction        | 0.034        |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.98        |
|    explained_variance   | 0.99         |
|    learning_rate        | 3.64e-05     |
|    loss                 | -0.0173      |
|    n_updates            | 5170         |
|    policy_gradient_loss | -0.00601     |
|    std                  | 0.654        |
|    value_loss           | 0.00813      |
------------------------------------------
--------------------------------
| time/              |         |
|    fps             | 592     |
|    iterations      | 518     |
|    time_elapsed    | 1791    |
|    total_timesteps | 1060864 |
--------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 592        |
|    iterations           | 519        |
|    time_elapsed         | 1794       |
|    total_timesteps      | 1062912    |
| train/                  |            |
|    approx_kl            | 0.00418798 |
|    clip_fraction        | 0.0156     |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.99      |
|    explained_variance   | 0.951      |
|    learning_rate        | 3.64e-05   |
|    loss                 | -0.0134    |
|    n_updates            | 5180       |
|    policy_gradient_loss | -0.00313   |
|    std                  | 0.656      |
|    value_loss           | 0.0263     |
----------------------------------------
box reached target
box reached target
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 592          |
|    iterations           | 520          |
|    time_elapsed         | 1797         |
|    total_timesteps      | 1064960      |
| train/                  |              |
|    approx_kl            | 0.0034450237 |
|    clip_fraction        | 0.012        |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.99        |
|    explained_variance   | 0.903        |
|    learning_rate        | 3.64e-05     |
|    loss                 | 0.00164      |
|    n_updates            | 5190         |
|    policy_gradient_loss | -0.00221     |
|    std                  | 0.656        |
|    value_loss           | 0.0367       |
------------------------------------------
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 592          |
|    iterations           | 521          |
|    time_elapsed         | 1800         |
|    total_timesteps      | 1067008      |
| train/                  |              |
|    approx_kl            | 0.0033063104 |
|    clip_fraction        | 0.00679      |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.99        |
|    explained_variance   | 0.925        |
|    learning_rate        | 3.64e-05     |
|    loss                 | 0.0019       |
|    n_updates            | 5200         |
|    policy_gradient_loss | -0.00362     |
|    std                  | 0.655        |
|    value_loss           | 0.0485       |
------------------------------------------
box reached target
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 592          |
|    iterations           | 522          |
|    time_elapsed         | 1803         |
|    total_timesteps      | 1069056      |
| train/                  |              |
|    approx_kl            | 0.0048178635 |
|    clip_fraction        | 0.0234       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.99        |
|    explained_variance   | 0.88         |
|    learning_rate        | 3.64e-05     |
|    loss                 | -0.0187      |
|    n_updates            | 5210         |
|    policy_gradient_loss | -0.0057      |
|    std                  | 0.654        |
|    value_loss           | 0.0321       |
------------------------------------------
box reached target
box reached target
box reached target
Eval num_timesteps=1070000, episode_reward=2.92 +/- 3.21
Episode length: 304.00 +/- 162.80
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 304          |
|    mean_reward          | 2.92         |
| time/                   |              |
|    total_timesteps      | 1070000      |
| train/                  |              |
|    approx_kl            | 0.0022955495 |
|    clip_fraction        | 0.00898      |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.98        |
|    explained_variance   | 0.833        |
|    learning_rate        | 3.64e-05     |
|    loss                 | 0.00997      |
|    n_updates            | 5220         |
|    policy_gradient_loss | -0.00344     |
|    std                  | 0.653        |
|    value_loss           | 0.0598       |
------------------------------------------
box reached target
--------------------------------
| time/              |         |
|    fps             | 592     |
|    iterations      | 523     |
|    time_elapsed    | 1807    |
|    total_timesteps | 1071104 |
--------------------------------
box reached target
box reached target
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 592          |
|    iterations           | 524          |
|    time_elapsed         | 1811         |
|    total_timesteps      | 1073152      |
| train/                  |              |
|    approx_kl            | 0.0034997445 |
|    clip_fraction        | 0.0216       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.98        |
|    explained_variance   | 0.908        |
|    learning_rate        | 3.64e-05     |
|    loss                 | -0.00967     |
|    n_updates            | 5230         |
|    policy_gradient_loss | -0.00442     |
|    std                  | 0.652        |
|    value_loss           | 0.0266       |
------------------------------------------
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 592          |
|    iterations           | 525          |
|    time_elapsed         | 1814         |
|    total_timesteps      | 1075200      |
| train/                  |              |
|    approx_kl            | 0.0042546447 |
|    clip_fraction        | 0.0263       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.98        |
|    explained_variance   | 0.893        |
|    learning_rate        | 3.64e-05     |
|    loss                 | 0.0252       |
|    n_updates            | 5240         |
|    policy_gradient_loss | -0.00297     |
|    std                  | 0.651        |
|    value_loss           | 0.0568       |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 592          |
|    iterations           | 526          |
|    time_elapsed         | 1817         |
|    total_timesteps      | 1077248      |
| train/                  |              |
|    approx_kl            | 0.0037641143 |
|    clip_fraction        | 0.0192       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.97        |
|    explained_variance   | 0.928        |
|    learning_rate        | 3.65e-05     |
|    loss                 | -0.00482     |
|    n_updates            | 5250         |
|    policy_gradient_loss | -0.0036      |
|    std                  | 0.648        |
|    value_loss           | 0.0075       |
------------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 592         |
|    iterations           | 527         |
|    time_elapsed         | 1820        |
|    total_timesteps      | 1079296     |
| train/                  |             |
|    approx_kl            | 0.004490067 |
|    clip_fraction        | 0.0243      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.97       |
|    explained_variance   | 0.932       |
|    learning_rate        | 3.65e-05    |
|    loss                 | -0.0116     |
|    n_updates            | 5260        |
|    policy_gradient_loss | -0.00499    |
|    std                  | 0.649       |
|    value_loss           | 0.00487     |
-----------------------------------------
box reached target
box reached target
Eval num_timesteps=1080000, episode_reward=1.51 +/- 3.07
Episode length: 359.60 +/- 172.00
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 360          |
|    mean_reward          | 1.51         |
| time/                   |              |
|    total_timesteps      | 1080000      |
| train/                  |              |
|    approx_kl            | 0.0029782779 |
|    clip_fraction        | 0.0154       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.97        |
|    explained_variance   | 0.858        |
|    learning_rate        | 3.65e-05     |
|    loss                 | -0.0182      |
|    n_updates            | 5270         |
|    policy_gradient_loss | -0.00396     |
|    std                  | 0.648        |
|    value_loss           | 0.0046       |
------------------------------------------
--------------------------------
| time/              |         |
|    fps             | 592     |
|    iterations      | 528     |
|    time_elapsed    | 1824    |
|    total_timesteps | 1081344 |
--------------------------------
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 592          |
|    iterations           | 529          |
|    time_elapsed         | 1828         |
|    total_timesteps      | 1083392      |
| train/                  |              |
|    approx_kl            | 0.0025027627 |
|    clip_fraction        | 0.00835      |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.97        |
|    explained_variance   | 0.791        |
|    learning_rate        | 3.65e-05     |
|    loss                 | 0.007        |
|    n_updates            | 5280         |
|    policy_gradient_loss | -0.00175     |
|    std                  | 0.649        |
|    value_loss           | 0.0206       |
------------------------------------------
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 592          |
|    iterations           | 530          |
|    time_elapsed         | 1831         |
|    total_timesteps      | 1085440      |
| train/                  |              |
|    approx_kl            | 0.0038114842 |
|    clip_fraction        | 0.0166       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.97        |
|    explained_variance   | 0.952        |
|    learning_rate        | 3.65e-05     |
|    loss                 | 0.00229      |
|    n_updates            | 5290         |
|    policy_gradient_loss | -0.00187     |
|    std                  | 0.649        |
|    value_loss           | 0.00664      |
------------------------------------------
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 592          |
|    iterations           | 531          |
|    time_elapsed         | 1834         |
|    total_timesteps      | 1087488      |
| train/                  |              |
|    approx_kl            | 0.0033013881 |
|    clip_fraction        | 0.0191       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.97        |
|    explained_variance   | 0.966        |
|    learning_rate        | 3.65e-05     |
|    loss                 | 0.00317      |
|    n_updates            | 5300         |
|    policy_gradient_loss | -0.00496     |
|    std                  | 0.648        |
|    value_loss           | 0.0092       |
------------------------------------------
box reached target
box reached target
box reached target
box reached target
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 592          |
|    iterations           | 532          |
|    time_elapsed         | 1837         |
|    total_timesteps      | 1089536      |
| train/                  |              |
|    approx_kl            | 0.0040620435 |
|    clip_fraction        | 0.0354       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.97        |
|    explained_variance   | 0.91         |
|    learning_rate        | 3.65e-05     |
|    loss                 | -0.0157      |
|    n_updates            | 5310         |
|    policy_gradient_loss | -0.00428     |
|    std                  | 0.647        |
|    value_loss           | 0.0139       |
------------------------------------------
box reached target
box reached target
Eval num_timesteps=1090000, episode_reward=0.58 +/- 2.49
Episode length: 436.40 +/- 127.20
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 436          |
|    mean_reward          | 0.578        |
| time/                   |              |
|    total_timesteps      | 1090000      |
| train/                  |              |
|    approx_kl            | 0.0022847294 |
|    clip_fraction        | 0.00425      |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.96        |
|    explained_variance   | 0.965        |
|    learning_rate        | 3.65e-05     |
|    loss                 | -0.00671     |
|    n_updates            | 5320         |
|    policy_gradient_loss | -0.00205     |
|    std                  | 0.647        |
|    value_loss           | 0.0292       |
------------------------------------------
box reached target
box reached target
--------------------------------
| time/              |         |
|    fps             | 592     |
|    iterations      | 533     |
|    time_elapsed    | 1842    |
|    total_timesteps | 1091584 |
--------------------------------
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 592          |
|    iterations           | 534          |
|    time_elapsed         | 1845         |
|    total_timesteps      | 1093632      |
| train/                  |              |
|    approx_kl            | 0.0041051693 |
|    clip_fraction        | 0.0149       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.96        |
|    explained_variance   | 0.953        |
|    learning_rate        | 3.65e-05     |
|    loss                 | 0.0167       |
|    n_updates            | 5330         |
|    policy_gradient_loss | -0.00388     |
|    std                  | 0.648        |
|    value_loss           | 0.0199       |
------------------------------------------
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 592          |
|    iterations           | 535          |
|    time_elapsed         | 1848         |
|    total_timesteps      | 1095680      |
| train/                  |              |
|    approx_kl            | 0.0032201363 |
|    clip_fraction        | 0.011        |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.97        |
|    explained_variance   | 0.775        |
|    learning_rate        | 3.66e-05     |
|    loss                 | -0.00891     |
|    n_updates            | 5340         |
|    policy_gradient_loss | -0.00374     |
|    std                  | 0.648        |
|    value_loss           | 0.0466       |
------------------------------------------
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 592          |
|    iterations           | 536          |
|    time_elapsed         | 1851         |
|    total_timesteps      | 1097728      |
| train/                  |              |
|    approx_kl            | 0.0046152454 |
|    clip_fraction        | 0.0354       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.96        |
|    explained_variance   | 0.815        |
|    learning_rate        | 3.66e-05     |
|    loss                 | 0.0255       |
|    n_updates            | 5350         |
|    policy_gradient_loss | -0.006       |
|    std                  | 0.647        |
|    value_loss           | 0.0269       |
------------------------------------------
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 592          |
|    iterations           | 537          |
|    time_elapsed         | 1854         |
|    total_timesteps      | 1099776      |
| train/                  |              |
|    approx_kl            | 0.0058497065 |
|    clip_fraction        | 0.0406       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.96        |
|    explained_variance   | 0.844        |
|    learning_rate        | 3.66e-05     |
|    loss                 | 0.022        |
|    n_updates            | 5360         |
|    policy_gradient_loss | -0.00598     |
|    std                  | 0.647        |
|    value_loss           | 0.032        |
------------------------------------------
box reached target
Eval num_timesteps=1100000, episode_reward=0.59 +/- 2.55
Episode length: 450.40 +/- 99.20
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 450          |
|    mean_reward          | 0.593        |
| time/                   |              |
|    total_timesteps      | 1100000      |
| train/                  |              |
|    approx_kl            | 0.0051745293 |
|    clip_fraction        | 0.0335       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.96        |
|    explained_variance   | 0.908        |
|    learning_rate        | 3.66e-05     |
|    loss                 | 0.0141       |
|    n_updates            | 5370         |
|    policy_gradient_loss | -0.00536     |
|    std                  | 0.647        |
|    value_loss           | 0.0175       |
------------------------------------------
box reached target
box reached target
--------------------------------
| time/              |         |
|    fps             | 592     |
|    iterations      | 538     |
|    time_elapsed    | 1859    |
|    total_timesteps | 1101824 |
--------------------------------
box reached target
box reached target
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 592          |
|    iterations           | 539          |
|    time_elapsed         | 1862         |
|    total_timesteps      | 1103872      |
| train/                  |              |
|    approx_kl            | 0.0037463184 |
|    clip_fraction        | 0.0196       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.96        |
|    explained_variance   | 0.935        |
|    learning_rate        | 3.66e-05     |
|    loss                 | 0.0174       |
|    n_updates            | 5380         |
|    policy_gradient_loss | -0.00253     |
|    std                  | 0.647        |
|    value_loss           | 0.0129       |
------------------------------------------
------------------------------------------
| time/                   |              |
|    fps                  | 592          |
|    iterations           | 540          |
|    time_elapsed         | 1865         |
|    total_timesteps      | 1105920      |
| train/                  |              |
|    approx_kl            | 0.0034205175 |
|    clip_fraction        | 0.0125       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.96        |
|    explained_variance   | 0.93         |
|    learning_rate        | 3.66e-05     |
|    loss                 | 0.0134       |
|    n_updates            | 5390         |
|    policy_gradient_loss | -0.00259     |
|    std                  | 0.647        |
|    value_loss           | 0.027        |
------------------------------------------
box reached target
box reached target
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 592          |
|    iterations           | 541          |
|    time_elapsed         | 1868         |
|    total_timesteps      | 1107968      |
| train/                  |              |
|    approx_kl            | 0.0052686916 |
|    clip_fraction        | 0.0453       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.96        |
|    explained_variance   | 0.866        |
|    learning_rate        | 3.66e-05     |
|    loss                 | 0.0164       |
|    n_updates            | 5400         |
|    policy_gradient_loss | -0.00709     |
|    std                  | 0.647        |
|    value_loss           | 0.00235      |
------------------------------------------
box reached target
box reached target
box reached target
box reached target
box reached target
Eval num_timesteps=1110000, episode_reward=3.25 +/- 2.83
Episode length: 309.60 +/- 157.62
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 310          |
|    mean_reward          | 3.25         |
| time/                   |              |
|    total_timesteps      | 1110000      |
| train/                  |              |
|    approx_kl            | 0.0069488105 |
|    clip_fraction        | 0.0625       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.96        |
|    explained_variance   | 0.947        |
|    learning_rate        | 3.66e-05     |
|    loss                 | -0.0207      |
|    n_updates            | 5410         |
|    policy_gradient_loss | -0.00635     |
|    std                  | 0.646        |
|    value_loss           | 0.0155       |
------------------------------------------
--------------------------------
| time/              |         |
|    fps             | 592     |
|    iterations      | 542     |
|    time_elapsed    | 1872    |
|    total_timesteps | 1110016 |
--------------------------------
box reached target
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 592          |
|    iterations           | 543          |
|    time_elapsed         | 1876         |
|    total_timesteps      | 1112064      |
| train/                  |              |
|    approx_kl            | 0.0053028045 |
|    clip_fraction        | 0.025        |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.96        |
|    explained_variance   | 0.823        |
|    learning_rate        | 3.67e-05     |
|    loss                 | 0.00809      |
|    n_updates            | 5420         |
|    policy_gradient_loss | -0.00403     |
|    std                  | 0.644        |
|    value_loss           | 0.0548       |
------------------------------------------
box reached target
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 592          |
|    iterations           | 544          |
|    time_elapsed         | 1879         |
|    total_timesteps      | 1114112      |
| train/                  |              |
|    approx_kl            | 0.0036026142 |
|    clip_fraction        | 0.0235       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.96        |
|    explained_variance   | 0.964        |
|    learning_rate        | 3.67e-05     |
|    loss                 | -0.00482     |
|    n_updates            | 5430         |
|    policy_gradient_loss | -0.00339     |
|    std                  | 0.644        |
|    value_loss           | 0.00801      |
------------------------------------------
box reached target
box reached target
box reached target
box reached target
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 592         |
|    iterations           | 545         |
|    time_elapsed         | 1882        |
|    total_timesteps      | 1116160     |
| train/                  |             |
|    approx_kl            | 0.003048762 |
|    clip_fraction        | 0.0136      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.95       |
|    explained_variance   | 0.967       |
|    learning_rate        | 3.67e-05    |
|    loss                 | -0.012      |
|    n_updates            | 5440        |
|    policy_gradient_loss | -0.00306    |
|    std                  | 0.642       |
|    value_loss           | 0.0135      |
-----------------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 593         |
|    iterations           | 546         |
|    time_elapsed         | 1885        |
|    total_timesteps      | 1118208     |
| train/                  |             |
|    approx_kl            | 0.003952248 |
|    clip_fraction        | 0.0135      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.95       |
|    explained_variance   | 0.956       |
|    learning_rate        | 3.67e-05    |
|    loss                 | -0.00192    |
|    n_updates            | 5450        |
|    policy_gradient_loss | -0.00345    |
|    std                  | 0.64        |
|    value_loss           | 0.0338      |
-----------------------------------------
box reached target
box reached target
box reached target
box reached target
box reached target
Eval num_timesteps=1120000, episode_reward=0.27 +/- 2.54
Episode length: 431.80 +/- 136.40
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 432          |
|    mean_reward          | 0.268        |
| time/                   |              |
|    total_timesteps      | 1120000      |
| train/                  |              |
|    approx_kl            | 0.0056305984 |
|    clip_fraction        | 0.0345       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.94        |
|    explained_variance   | 0.925        |
|    learning_rate        | 3.67e-05     |
|    loss                 | -0.00687     |
|    n_updates            | 5460         |
|    policy_gradient_loss | -0.00367     |
|    std                  | 0.639        |
|    value_loss           | 0.00491      |
------------------------------------------
--------------------------------
| time/              |         |
|    fps             | 592     |
|    iterations      | 547     |
|    time_elapsed    | 1890    |
|    total_timesteps | 1120256 |
--------------------------------
box reached target
box reached target
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 592          |
|    iterations           | 548          |
|    time_elapsed         | 1893         |
|    total_timesteps      | 1122304      |
| train/                  |              |
|    approx_kl            | 0.0040820222 |
|    clip_fraction        | 0.031        |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.94        |
|    explained_variance   | 0.975        |
|    learning_rate        | 3.67e-05     |
|    loss                 | -0.0193      |
|    n_updates            | 5470         |
|    policy_gradient_loss | -0.00576     |
|    std                  | 0.639        |
|    value_loss           | 0.00706      |
------------------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 592         |
|    iterations           | 549         |
|    time_elapsed         | 1896        |
|    total_timesteps      | 1124352     |
| train/                  |             |
|    approx_kl            | 0.004215444 |
|    clip_fraction        | 0.0204      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.94       |
|    explained_variance   | 0.944       |
|    learning_rate        | 3.67e-05    |
|    loss                 | 0.0259      |
|    n_updates            | 5480        |
|    policy_gradient_loss | -0.00281    |
|    std                  | 0.637       |
|    value_loss           | 0.0313      |
-----------------------------------------
box reached target
box reached target
----------------------------------------
| time/                   |            |
|    fps                  | 592        |
|    iterations           | 550        |
|    time_elapsed         | 1899       |
|    total_timesteps      | 1126400    |
| train/                  |            |
|    approx_kl            | 0.00467619 |
|    clip_fraction        | 0.0337     |
|    clip_range           | 0.2        |
|    entropy_loss         | -1.93      |
|    explained_variance   | 0.903      |
|    learning_rate        | 3.67e-05   |
|    loss                 | 0.00565    |
|    n_updates            | 5490       |
|    policy_gradient_loss | -0.00366   |
|    std                  | 0.638      |
|    value_loss           | 0.0173     |
----------------------------------------
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 593          |
|    iterations           | 551          |
|    time_elapsed         | 1902         |
|    total_timesteps      | 1128448      |
| train/                  |              |
|    approx_kl            | 0.0058452683 |
|    clip_fraction        | 0.0552       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.94        |
|    explained_variance   | 0.978        |
|    learning_rate        | 3.68e-05     |
|    loss                 | -0.0302      |
|    n_updates            | 5500         |
|    policy_gradient_loss | -0.00657     |
|    std                  | 0.639        |
|    value_loss           | 0.00486      |
------------------------------------------
box reached target
box reached target
Eval num_timesteps=1130000, episode_reward=1.78 +/- 2.95
Episode length: 374.60 +/- 153.68
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 375          |
|    mean_reward          | 1.78         |
| time/                   |              |
|    total_timesteps      | 1130000      |
| train/                  |              |
|    approx_kl            | 0.0020803385 |
|    clip_fraction        | 0.00581      |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.94        |
|    explained_variance   | 0.885        |
|    learning_rate        | 3.68e-05     |
|    loss                 | 0.00765      |
|    n_updates            | 5510         |
|    policy_gradient_loss | -0.00165     |
|    std                  | 0.639        |
|    value_loss           | 0.0233       |
------------------------------------------
--------------------------------
| time/              |         |
|    fps             | 592     |
|    iterations      | 552     |
|    time_elapsed    | 1907    |
|    total_timesteps | 1130496 |
--------------------------------
box reached target
box reached target
box reached target
box reached target
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 592          |
|    iterations           | 553          |
|    time_elapsed         | 1910         |
|    total_timesteps      | 1132544      |
| train/                  |              |
|    approx_kl            | 0.0051055406 |
|    clip_fraction        | 0.0256       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.94        |
|    explained_variance   | 0.933        |
|    learning_rate        | 3.68e-05     |
|    loss                 | -0.00269     |
|    n_updates            | 5520         |
|    policy_gradient_loss | -0.00273     |
|    std                  | 0.639        |
|    value_loss           | 0.00598      |
------------------------------------------
box reached target
-----------------------------------------
| time/                   |             |
|    fps                  | 592         |
|    iterations           | 554         |
|    time_elapsed         | 1913        |
|    total_timesteps      | 1134592     |
| train/                  |             |
|    approx_kl            | 0.003764973 |
|    clip_fraction        | 0.0182      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.94       |
|    explained_variance   | 0.971       |
|    learning_rate        | 3.68e-05    |
|    loss                 | 0.00182     |
|    n_updates            | 5530        |
|    policy_gradient_loss | -0.00317    |
|    std                  | 0.638       |
|    value_loss           | 0.0314      |
-----------------------------------------
box reached target
box reached target
box reached target
box reached target
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 593          |
|    iterations           | 555          |
|    time_elapsed         | 1916         |
|    total_timesteps      | 1136640      |
| train/                  |              |
|    approx_kl            | 0.0038965777 |
|    clip_fraction        | 0.023        |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.94        |
|    explained_variance   | 0.983        |
|    learning_rate        | 3.68e-05     |
|    loss                 | -0.0205      |
|    n_updates            | 5540         |
|    policy_gradient_loss | -0.00589     |
|    std                  | 0.638        |
|    value_loss           | 0.00107      |
------------------------------------------
-----------------------------------------
| time/                   |             |
|    fps                  | 593         |
|    iterations           | 556         |
|    time_elapsed         | 1919        |
|    total_timesteps      | 1138688     |
| train/                  |             |
|    approx_kl            | 0.004578734 |
|    clip_fraction        | 0.0242      |
|    clip_range           | 0.2         |
|    entropy_loss         | -1.94       |
|    explained_variance   | 0.936       |
|    learning_rate        | 3.68e-05    |
|    loss                 | -0.0106     |
|    n_updates            | 5550        |
|    policy_gradient_loss | -0.00313    |
|    std                  | 0.637       |
|    value_loss           | 0.044       |
-----------------------------------------
box reached target
Eval num_timesteps=1140000, episode_reward=-1.69 +/- 0.88
Episode length: 500.00 +/- 0.00
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 500          |
|    mean_reward          | -1.69        |
| time/                   |              |
|    total_timesteps      | 1140000      |
| train/                  |              |
|    approx_kl            | 0.0041310056 |
|    clip_fraction        | 0.0147       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.94        |
|    explained_variance   | 0.887        |
|    learning_rate        | 3.68e-05     |
|    loss                 | 0.00161      |
|    n_updates            | 5560         |
|    policy_gradient_loss | -0.00323     |
|    std                  | 0.64         |
|    value_loss           | 0.0161       |
------------------------------------------
box reached target
--------------------------------
| time/              |         |
|    fps             | 592     |
|    iterations      | 557     |
|    time_elapsed    | 1924    |
|    total_timesteps | 1140736 |
--------------------------------
box reached target
box reached target
box reached target
------------------------------------------
| time/                   |              |
|    fps                  | 592          |
|    iterations           | 558          |
|    time_elapsed         | 1927         |
|    total_timesteps      | 1142784      |
| train/                  |              |
|    approx_kl            | 0.0036504767 |
|    clip_fraction        | 0.0204       |
|    clip_range           | 0.2          |
|    entropy_loss         | -1.94        |
|    explained_variance   | 0.784        |
|    learning_rate        | 3.68e-05     |
|    loss                 | 0.0129       |
|    n_updates            | 5570         |
|    policy_gradient_loss | -0.00378     |
|    std                  | 0.639        |
|    value_loss           | 0.0869       |
------------------------------------------
